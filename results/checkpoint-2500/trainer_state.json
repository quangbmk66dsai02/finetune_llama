{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 48.07692307692308,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 73.08638763427734,
      "learning_rate": 4.994230769230769e-05,
      "loss": 8.0614,
      "step": 10
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 85.40754699707031,
      "learning_rate": 4.9769230769230775e-05,
      "loss": 6.3047,
      "step": 20
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 88.29999542236328,
      "learning_rate": 4.957692307692308e-05,
      "loss": 3.8694,
      "step": 30
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 38.89631271362305,
      "learning_rate": 4.9384615384615384e-05,
      "loss": 1.1298,
      "step": 40
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 1.9961620569229126,
      "learning_rate": 4.9192307692307694e-05,
      "loss": 0.3781,
      "step": 50
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.6216726303100586,
      "learning_rate": 4.9e-05,
      "loss": 0.2856,
      "step": 60
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 0.4497085213661194,
      "learning_rate": 4.880769230769231e-05,
      "loss": 0.3739,
      "step": 70
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.4203640818595886,
      "learning_rate": 4.861538461538462e-05,
      "loss": 0.291,
      "step": 80
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 1.0806196928024292,
      "learning_rate": 4.8423076923076924e-05,
      "loss": 0.3276,
      "step": 90
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.583793580532074,
      "learning_rate": 4.8230769230769235e-05,
      "loss": 0.2418,
      "step": 100
    },
    {
      "epoch": 2.1153846153846154,
      "grad_norm": 0.5069572329521179,
      "learning_rate": 4.8038461538461546e-05,
      "loss": 0.2295,
      "step": 110
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.538435161113739,
      "learning_rate": 4.784615384615384e-05,
      "loss": 0.3333,
      "step": 120
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.8130010962486267,
      "learning_rate": 4.7653846153846154e-05,
      "loss": 0.3209,
      "step": 130
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 0.49138200283050537,
      "learning_rate": 4.7461538461538465e-05,
      "loss": 0.2162,
      "step": 140
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 0.5657510757446289,
      "learning_rate": 4.726923076923077e-05,
      "loss": 0.2785,
      "step": 150
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.846605122089386,
      "learning_rate": 4.707692307692308e-05,
      "loss": 0.3042,
      "step": 160
    },
    {
      "epoch": 3.269230769230769,
      "grad_norm": 0.5702120065689087,
      "learning_rate": 4.688461538461539e-05,
      "loss": 0.2722,
      "step": 170
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 0.823590099811554,
      "learning_rate": 4.6692307692307695e-05,
      "loss": 0.2703,
      "step": 180
    },
    {
      "epoch": 3.6538461538461537,
      "grad_norm": 0.6007419228553772,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.2634,
      "step": 190
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.7256826162338257,
      "learning_rate": 4.630769230769231e-05,
      "loss": 0.259,
      "step": 200
    },
    {
      "epoch": 4.038461538461538,
      "grad_norm": 0.8137454390525818,
      "learning_rate": 4.6115384615384614e-05,
      "loss": 0.2446,
      "step": 210
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 0.842345118522644,
      "learning_rate": 4.5923076923076924e-05,
      "loss": 0.2548,
      "step": 220
    },
    {
      "epoch": 4.423076923076923,
      "grad_norm": 1.271815299987793,
      "learning_rate": 4.5730769230769235e-05,
      "loss": 0.2428,
      "step": 230
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 0.940091073513031,
      "learning_rate": 4.553846153846154e-05,
      "loss": 0.2317,
      "step": 240
    },
    {
      "epoch": 4.8076923076923075,
      "grad_norm": 1.2849019765853882,
      "learning_rate": 4.534615384615385e-05,
      "loss": 0.3355,
      "step": 250
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9152981042861938,
      "learning_rate": 4.515384615384616e-05,
      "loss": 0.2317,
      "step": 260
    },
    {
      "epoch": 5.1923076923076925,
      "grad_norm": 1.493432879447937,
      "learning_rate": 4.4961538461538465e-05,
      "loss": 0.2569,
      "step": 270
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 0.8277357220649719,
      "learning_rate": 4.476923076923077e-05,
      "loss": 0.2442,
      "step": 280
    },
    {
      "epoch": 5.576923076923077,
      "grad_norm": 0.9635027050971985,
      "learning_rate": 4.457692307692308e-05,
      "loss": 0.213,
      "step": 290
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 1.4070494174957275,
      "learning_rate": 4.4384615384615384e-05,
      "loss": 0.2586,
      "step": 300
    },
    {
      "epoch": 5.961538461538462,
      "grad_norm": 1.1940357685089111,
      "learning_rate": 4.4192307692307695e-05,
      "loss": 0.2598,
      "step": 310
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 1.3206746578216553,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.227,
      "step": 320
    },
    {
      "epoch": 6.346153846153846,
      "grad_norm": 0.804172694683075,
      "learning_rate": 4.380769230769231e-05,
      "loss": 0.2146,
      "step": 330
    },
    {
      "epoch": 6.538461538461538,
      "grad_norm": 1.136977195739746,
      "learning_rate": 4.361538461538462e-05,
      "loss": 0.1758,
      "step": 340
    },
    {
      "epoch": 6.730769230769231,
      "grad_norm": 1.8743103742599487,
      "learning_rate": 4.3423076923076925e-05,
      "loss": 0.3083,
      "step": 350
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 1.0882519483566284,
      "learning_rate": 4.323076923076923e-05,
      "loss": 0.245,
      "step": 360
    },
    {
      "epoch": 7.115384615384615,
      "grad_norm": 1.165528416633606,
      "learning_rate": 4.303846153846154e-05,
      "loss": 0.2083,
      "step": 370
    },
    {
      "epoch": 7.3076923076923075,
      "grad_norm": 1.1019458770751953,
      "learning_rate": 4.284615384615385e-05,
      "loss": 0.233,
      "step": 380
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.4421625137329102,
      "learning_rate": 4.2653846153846154e-05,
      "loss": 0.2229,
      "step": 390
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 1.326894760131836,
      "learning_rate": 4.2461538461538465e-05,
      "loss": 0.2254,
      "step": 400
    },
    {
      "epoch": 7.884615384615385,
      "grad_norm": 1.5137196779251099,
      "learning_rate": 4.226923076923077e-05,
      "loss": 0.2333,
      "step": 410
    },
    {
      "epoch": 8.076923076923077,
      "grad_norm": 1.7171273231506348,
      "learning_rate": 4.207692307692308e-05,
      "loss": 0.2603,
      "step": 420
    },
    {
      "epoch": 8.26923076923077,
      "grad_norm": 1.4162780046463013,
      "learning_rate": 4.188461538461539e-05,
      "loss": 0.1705,
      "step": 430
    },
    {
      "epoch": 8.461538461538462,
      "grad_norm": 2.7482409477233887,
      "learning_rate": 4.169230769230769e-05,
      "loss": 0.3406,
      "step": 440
    },
    {
      "epoch": 8.653846153846153,
      "grad_norm": 1.9039520025253296,
      "learning_rate": 4.15e-05,
      "loss": 0.1358,
      "step": 450
    },
    {
      "epoch": 8.846153846153847,
      "grad_norm": 1.4988137483596802,
      "learning_rate": 4.130769230769231e-05,
      "loss": 0.2034,
      "step": 460
    },
    {
      "epoch": 9.038461538461538,
      "grad_norm": 1.4848182201385498,
      "learning_rate": 4.1115384615384614e-05,
      "loss": 0.2139,
      "step": 470
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 1.457520604133606,
      "learning_rate": 4.0923076923076925e-05,
      "loss": 0.2091,
      "step": 480
    },
    {
      "epoch": 9.423076923076923,
      "grad_norm": 0.981551468372345,
      "learning_rate": 4.0730769230769236e-05,
      "loss": 0.2005,
      "step": 490
    },
    {
      "epoch": 9.615384615384615,
      "grad_norm": 1.9564322233200073,
      "learning_rate": 4.053846153846154e-05,
      "loss": 0.2161,
      "step": 500
    },
    {
      "epoch": 9.615384615384615,
      "eval_loss": 0.1984986662864685,
      "eval_runtime": 4.6022,
      "eval_samples_per_second": 22.598,
      "eval_steps_per_second": 11.299,
      "step": 500
    },
    {
      "epoch": 9.807692307692308,
      "grad_norm": 2.2546892166137695,
      "learning_rate": 4.034615384615385e-05,
      "loss": 0.2039,
      "step": 510
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.495681881904602,
      "learning_rate": 4.0153846153846155e-05,
      "loss": 0.195,
      "step": 520
    },
    {
      "epoch": 10.192307692307692,
      "grad_norm": 1.2719837427139282,
      "learning_rate": 3.996153846153846e-05,
      "loss": 0.1463,
      "step": 530
    },
    {
      "epoch": 10.384615384615385,
      "grad_norm": 2.669473886489868,
      "learning_rate": 3.976923076923077e-05,
      "loss": 0.262,
      "step": 540
    },
    {
      "epoch": 10.576923076923077,
      "grad_norm": 1.8359993696212769,
      "learning_rate": 3.957692307692308e-05,
      "loss": 0.1632,
      "step": 550
    },
    {
      "epoch": 10.76923076923077,
      "grad_norm": 3.0312962532043457,
      "learning_rate": 3.9384615384615384e-05,
      "loss": 0.2369,
      "step": 560
    },
    {
      "epoch": 10.961538461538462,
      "grad_norm": 1.3680799007415771,
      "learning_rate": 3.9192307692307695e-05,
      "loss": 0.1827,
      "step": 570
    },
    {
      "epoch": 11.153846153846153,
      "grad_norm": 1.4646137952804565,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.1912,
      "step": 580
    },
    {
      "epoch": 11.346153846153847,
      "grad_norm": 2.2769627571105957,
      "learning_rate": 3.880769230769231e-05,
      "loss": 0.1886,
      "step": 590
    },
    {
      "epoch": 11.538461538461538,
      "grad_norm": 1.8083101511001587,
      "learning_rate": 3.861538461538462e-05,
      "loss": 0.1791,
      "step": 600
    },
    {
      "epoch": 11.73076923076923,
      "grad_norm": 1.4910862445831299,
      "learning_rate": 3.8423076923076925e-05,
      "loss": 0.2495,
      "step": 610
    },
    {
      "epoch": 11.923076923076923,
      "grad_norm": 2.277247428894043,
      "learning_rate": 3.823076923076923e-05,
      "loss": 0.1443,
      "step": 620
    },
    {
      "epoch": 12.115384615384615,
      "grad_norm": 1.7189388275146484,
      "learning_rate": 3.803846153846154e-05,
      "loss": 0.1076,
      "step": 630
    },
    {
      "epoch": 12.307692307692308,
      "grad_norm": 1.1765216588974,
      "learning_rate": 3.784615384615385e-05,
      "loss": 0.1425,
      "step": 640
    },
    {
      "epoch": 12.5,
      "grad_norm": 3.101548671722412,
      "learning_rate": 3.7653846153846155e-05,
      "loss": 0.1604,
      "step": 650
    },
    {
      "epoch": 12.692307692307692,
      "grad_norm": 1.427392601966858,
      "learning_rate": 3.7461538461538466e-05,
      "loss": 0.1864,
      "step": 660
    },
    {
      "epoch": 12.884615384615385,
      "grad_norm": 3.0274693965911865,
      "learning_rate": 3.726923076923077e-05,
      "loss": 0.2108,
      "step": 670
    },
    {
      "epoch": 13.076923076923077,
      "grad_norm": 1.383907437324524,
      "learning_rate": 3.707692307692308e-05,
      "loss": 0.2463,
      "step": 680
    },
    {
      "epoch": 13.26923076923077,
      "grad_norm": 1.7130125761032104,
      "learning_rate": 3.6884615384615385e-05,
      "loss": 0.1804,
      "step": 690
    },
    {
      "epoch": 13.461538461538462,
      "grad_norm": 2.5565807819366455,
      "learning_rate": 3.6692307692307695e-05,
      "loss": 0.1606,
      "step": 700
    },
    {
      "epoch": 13.653846153846153,
      "grad_norm": 2.7044105529785156,
      "learning_rate": 3.65e-05,
      "loss": 0.1306,
      "step": 710
    },
    {
      "epoch": 13.846153846153847,
      "grad_norm": 1.9137904644012451,
      "learning_rate": 3.630769230769231e-05,
      "loss": 0.2098,
      "step": 720
    },
    {
      "epoch": 14.038461538461538,
      "grad_norm": 3.0112366676330566,
      "learning_rate": 3.6115384615384614e-05,
      "loss": 0.1327,
      "step": 730
    },
    {
      "epoch": 14.23076923076923,
      "grad_norm": 1.6073781251907349,
      "learning_rate": 3.5923076923076925e-05,
      "loss": 0.1363,
      "step": 740
    },
    {
      "epoch": 14.423076923076923,
      "grad_norm": 1.8568027019500732,
      "learning_rate": 3.5730769230769236e-05,
      "loss": 0.1738,
      "step": 750
    },
    {
      "epoch": 14.615384615384615,
      "grad_norm": 1.863745927810669,
      "learning_rate": 3.553846153846154e-05,
      "loss": 0.2044,
      "step": 760
    },
    {
      "epoch": 14.807692307692308,
      "grad_norm": 3.29670786857605,
      "learning_rate": 3.5346153846153844e-05,
      "loss": 0.1449,
      "step": 770
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.0394046306610107,
      "learning_rate": 3.5153846153846155e-05,
      "loss": 0.1413,
      "step": 780
    },
    {
      "epoch": 15.192307692307692,
      "grad_norm": 3.9118733406066895,
      "learning_rate": 3.496153846153846e-05,
      "loss": 0.1332,
      "step": 790
    },
    {
      "epoch": 15.384615384615385,
      "grad_norm": 2.8449764251708984,
      "learning_rate": 3.476923076923077e-05,
      "loss": 0.1355,
      "step": 800
    },
    {
      "epoch": 15.576923076923077,
      "grad_norm": 2.773117780685425,
      "learning_rate": 3.457692307692308e-05,
      "loss": 0.1481,
      "step": 810
    },
    {
      "epoch": 15.76923076923077,
      "grad_norm": 2.5912492275238037,
      "learning_rate": 3.4384615384615385e-05,
      "loss": 0.1604,
      "step": 820
    },
    {
      "epoch": 15.961538461538462,
      "grad_norm": 2.257473945617676,
      "learning_rate": 3.4192307692307696e-05,
      "loss": 0.1958,
      "step": 830
    },
    {
      "epoch": 16.153846153846153,
      "grad_norm": 3.4438087940216064,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0913,
      "step": 840
    },
    {
      "epoch": 16.346153846153847,
      "grad_norm": 3.05470871925354,
      "learning_rate": 3.3807692307692304e-05,
      "loss": 0.1573,
      "step": 850
    },
    {
      "epoch": 16.53846153846154,
      "grad_norm": 4.248789310455322,
      "learning_rate": 3.3615384615384615e-05,
      "loss": 0.1772,
      "step": 860
    },
    {
      "epoch": 16.73076923076923,
      "grad_norm": 2.1607463359832764,
      "learning_rate": 3.3423076923076925e-05,
      "loss": 0.1063,
      "step": 870
    },
    {
      "epoch": 16.923076923076923,
      "grad_norm": 5.758263111114502,
      "learning_rate": 3.323076923076923e-05,
      "loss": 0.1443,
      "step": 880
    },
    {
      "epoch": 17.115384615384617,
      "grad_norm": 4.358857154846191,
      "learning_rate": 3.303846153846154e-05,
      "loss": 0.1976,
      "step": 890
    },
    {
      "epoch": 17.307692307692307,
      "grad_norm": 2.9458835124969482,
      "learning_rate": 3.284615384615385e-05,
      "loss": 0.1384,
      "step": 900
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.2864444255828857,
      "learning_rate": 3.2653846153846155e-05,
      "loss": 0.1379,
      "step": 910
    },
    {
      "epoch": 17.692307692307693,
      "grad_norm": 3.455380439758301,
      "learning_rate": 3.2461538461538466e-05,
      "loss": 0.1221,
      "step": 920
    },
    {
      "epoch": 17.884615384615383,
      "grad_norm": 1.7726374864578247,
      "learning_rate": 3.226923076923077e-05,
      "loss": 0.1401,
      "step": 930
    },
    {
      "epoch": 18.076923076923077,
      "grad_norm": 4.710305213928223,
      "learning_rate": 3.2076923076923074e-05,
      "loss": 0.1126,
      "step": 940
    },
    {
      "epoch": 18.26923076923077,
      "grad_norm": 4.673669338226318,
      "learning_rate": 3.1884615384615385e-05,
      "loss": 0.105,
      "step": 950
    },
    {
      "epoch": 18.46153846153846,
      "grad_norm": 3.849170446395874,
      "learning_rate": 3.1692307692307696e-05,
      "loss": 0.1956,
      "step": 960
    },
    {
      "epoch": 18.653846153846153,
      "grad_norm": 2.110525608062744,
      "learning_rate": 3.15e-05,
      "loss": 0.1103,
      "step": 970
    },
    {
      "epoch": 18.846153846153847,
      "grad_norm": 5.455090045928955,
      "learning_rate": 3.130769230769231e-05,
      "loss": 0.1266,
      "step": 980
    },
    {
      "epoch": 19.03846153846154,
      "grad_norm": 1.4089457988739014,
      "learning_rate": 3.111538461538462e-05,
      "loss": 0.1297,
      "step": 990
    },
    {
      "epoch": 19.23076923076923,
      "grad_norm": 2.338629961013794,
      "learning_rate": 3.0923076923076926e-05,
      "loss": 0.1196,
      "step": 1000
    },
    {
      "epoch": 19.23076923076923,
      "eval_loss": 0.1180962398648262,
      "eval_runtime": 4.6273,
      "eval_samples_per_second": 22.476,
      "eval_steps_per_second": 11.238,
      "step": 1000
    },
    {
      "epoch": 19.423076923076923,
      "grad_norm": 2.3055920600891113,
      "learning_rate": 3.073076923076923e-05,
      "loss": 0.1362,
      "step": 1010
    },
    {
      "epoch": 19.615384615384617,
      "grad_norm": 2.783139705657959,
      "learning_rate": 3.053846153846154e-05,
      "loss": 0.159,
      "step": 1020
    },
    {
      "epoch": 19.807692307692307,
      "grad_norm": 4.600823402404785,
      "learning_rate": 3.0346153846153848e-05,
      "loss": 0.1015,
      "step": 1030
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.072049140930176,
      "learning_rate": 3.0153846153846155e-05,
      "loss": 0.091,
      "step": 1040
    },
    {
      "epoch": 20.192307692307693,
      "grad_norm": 4.554161071777344,
      "learning_rate": 2.9961538461538463e-05,
      "loss": 0.1303,
      "step": 1050
    },
    {
      "epoch": 20.384615384615383,
      "grad_norm": 1.9955320358276367,
      "learning_rate": 2.976923076923077e-05,
      "loss": 0.0845,
      "step": 1060
    },
    {
      "epoch": 20.576923076923077,
      "grad_norm": 3.859790325164795,
      "learning_rate": 2.957692307692308e-05,
      "loss": 0.1079,
      "step": 1070
    },
    {
      "epoch": 20.76923076923077,
      "grad_norm": 2.6111035346984863,
      "learning_rate": 2.938461538461539e-05,
      "loss": 0.147,
      "step": 1080
    },
    {
      "epoch": 20.96153846153846,
      "grad_norm": 2.6791770458221436,
      "learning_rate": 2.919230769230769e-05,
      "loss": 0.1079,
      "step": 1090
    },
    {
      "epoch": 21.153846153846153,
      "grad_norm": 2.9723594188690186,
      "learning_rate": 2.9e-05,
      "loss": 0.1433,
      "step": 1100
    },
    {
      "epoch": 21.346153846153847,
      "grad_norm": 4.007467746734619,
      "learning_rate": 2.8807692307692308e-05,
      "loss": 0.0823,
      "step": 1110
    },
    {
      "epoch": 21.53846153846154,
      "grad_norm": 3.6188457012176514,
      "learning_rate": 2.8615384615384615e-05,
      "loss": 0.1193,
      "step": 1120
    },
    {
      "epoch": 21.73076923076923,
      "grad_norm": 5.175487518310547,
      "learning_rate": 2.8423076923076926e-05,
      "loss": 0.0869,
      "step": 1130
    },
    {
      "epoch": 21.923076923076923,
      "grad_norm": 3.6874773502349854,
      "learning_rate": 2.8230769230769233e-05,
      "loss": 0.141,
      "step": 1140
    },
    {
      "epoch": 22.115384615384617,
      "grad_norm": 2.0937576293945312,
      "learning_rate": 2.803846153846154e-05,
      "loss": 0.0922,
      "step": 1150
    },
    {
      "epoch": 22.307692307692307,
      "grad_norm": 1.8648815155029297,
      "learning_rate": 2.7846153846153848e-05,
      "loss": 0.1028,
      "step": 1160
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.4905972480773926,
      "learning_rate": 2.7653846153846152e-05,
      "loss": 0.083,
      "step": 1170
    },
    {
      "epoch": 22.692307692307693,
      "grad_norm": 2.2865068912506104,
      "learning_rate": 2.746153846153846e-05,
      "loss": 0.149,
      "step": 1180
    },
    {
      "epoch": 22.884615384615383,
      "grad_norm": 3.3390469551086426,
      "learning_rate": 2.726923076923077e-05,
      "loss": 0.0838,
      "step": 1190
    },
    {
      "epoch": 23.076923076923077,
      "grad_norm": 3.0725646018981934,
      "learning_rate": 2.7076923076923078e-05,
      "loss": 0.1332,
      "step": 1200
    },
    {
      "epoch": 23.26923076923077,
      "grad_norm": 6.8280110359191895,
      "learning_rate": 2.6884615384615385e-05,
      "loss": 0.0936,
      "step": 1210
    },
    {
      "epoch": 23.46153846153846,
      "grad_norm": 3.7014694213867188,
      "learning_rate": 2.6692307692307693e-05,
      "loss": 0.1235,
      "step": 1220
    },
    {
      "epoch": 23.653846153846153,
      "grad_norm": 3.7851881980895996,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0816,
      "step": 1230
    },
    {
      "epoch": 23.846153846153847,
      "grad_norm": 3.096809148788452,
      "learning_rate": 2.630769230769231e-05,
      "loss": 0.1192,
      "step": 1240
    },
    {
      "epoch": 24.03846153846154,
      "grad_norm": 1.820398211479187,
      "learning_rate": 2.611538461538462e-05,
      "loss": 0.0738,
      "step": 1250
    },
    {
      "epoch": 24.23076923076923,
      "grad_norm": 3.0900306701660156,
      "learning_rate": 2.5923076923076923e-05,
      "loss": 0.1262,
      "step": 1260
    },
    {
      "epoch": 24.423076923076923,
      "grad_norm": 3.94332218170166,
      "learning_rate": 2.573076923076923e-05,
      "loss": 0.0957,
      "step": 1270
    },
    {
      "epoch": 24.615384615384617,
      "grad_norm": 1.8750073909759521,
      "learning_rate": 2.5538461538461538e-05,
      "loss": 0.0673,
      "step": 1280
    },
    {
      "epoch": 24.807692307692307,
      "grad_norm": 4.883142471313477,
      "learning_rate": 2.534615384615385e-05,
      "loss": 0.0943,
      "step": 1290
    },
    {
      "epoch": 25.0,
      "grad_norm": 4.008222579956055,
      "learning_rate": 2.5153846153846156e-05,
      "loss": 0.1105,
      "step": 1300
    },
    {
      "epoch": 25.192307692307693,
      "grad_norm": 2.1203043460845947,
      "learning_rate": 2.4961538461538463e-05,
      "loss": 0.0745,
      "step": 1310
    },
    {
      "epoch": 25.384615384615383,
      "grad_norm": 3.241255283355713,
      "learning_rate": 2.476923076923077e-05,
      "loss": 0.0778,
      "step": 1320
    },
    {
      "epoch": 25.576923076923077,
      "grad_norm": 2.9409267902374268,
      "learning_rate": 2.4576923076923078e-05,
      "loss": 0.1246,
      "step": 1330
    },
    {
      "epoch": 25.76923076923077,
      "grad_norm": 2.52492356300354,
      "learning_rate": 2.4384615384615386e-05,
      "loss": 0.0771,
      "step": 1340
    },
    {
      "epoch": 25.96153846153846,
      "grad_norm": 5.084774971008301,
      "learning_rate": 2.4192307692307693e-05,
      "loss": 0.1148,
      "step": 1350
    },
    {
      "epoch": 26.153846153846153,
      "grad_norm": 3.8577184677124023,
      "learning_rate": 2.4e-05,
      "loss": 0.113,
      "step": 1360
    },
    {
      "epoch": 26.346153846153847,
      "grad_norm": 3.7466113567352295,
      "learning_rate": 2.3807692307692308e-05,
      "loss": 0.0867,
      "step": 1370
    },
    {
      "epoch": 26.53846153846154,
      "grad_norm": 4.0969977378845215,
      "learning_rate": 2.3615384615384616e-05,
      "loss": 0.0884,
      "step": 1380
    },
    {
      "epoch": 26.73076923076923,
      "grad_norm": 1.4280345439910889,
      "learning_rate": 2.3423076923076926e-05,
      "loss": 0.0703,
      "step": 1390
    },
    {
      "epoch": 26.923076923076923,
      "grad_norm": 4.708035469055176,
      "learning_rate": 2.323076923076923e-05,
      "loss": 0.0696,
      "step": 1400
    },
    {
      "epoch": 27.115384615384617,
      "grad_norm": 1.3241796493530273,
      "learning_rate": 2.3038461538461538e-05,
      "loss": 0.0836,
      "step": 1410
    },
    {
      "epoch": 27.307692307692307,
      "grad_norm": 4.175776958465576,
      "learning_rate": 2.284615384615385e-05,
      "loss": 0.1025,
      "step": 1420
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.7970424890518188,
      "learning_rate": 2.2653846153846156e-05,
      "loss": 0.0662,
      "step": 1430
    },
    {
      "epoch": 27.692307692307693,
      "grad_norm": 5.536386489868164,
      "learning_rate": 2.246153846153846e-05,
      "loss": 0.058,
      "step": 1440
    },
    {
      "epoch": 27.884615384615383,
      "grad_norm": 1.650283694267273,
      "learning_rate": 2.226923076923077e-05,
      "loss": 0.1308,
      "step": 1450
    },
    {
      "epoch": 28.076923076923077,
      "grad_norm": 2.1290123462677,
      "learning_rate": 2.207692307692308e-05,
      "loss": 0.0695,
      "step": 1460
    },
    {
      "epoch": 28.26923076923077,
      "grad_norm": 5.374929428100586,
      "learning_rate": 2.1884615384615386e-05,
      "loss": 0.1322,
      "step": 1470
    },
    {
      "epoch": 28.46153846153846,
      "grad_norm": 3.653223752975464,
      "learning_rate": 2.1692307692307693e-05,
      "loss": 0.0735,
      "step": 1480
    },
    {
      "epoch": 28.653846153846153,
      "grad_norm": 5.25739860534668,
      "learning_rate": 2.15e-05,
      "loss": 0.0743,
      "step": 1490
    },
    {
      "epoch": 28.846153846153847,
      "grad_norm": 3.0909199714660645,
      "learning_rate": 2.1307692307692308e-05,
      "loss": 0.0582,
      "step": 1500
    },
    {
      "epoch": 28.846153846153847,
      "eval_loss": 0.07398353517055511,
      "eval_runtime": 4.6013,
      "eval_samples_per_second": 22.602,
      "eval_steps_per_second": 11.301,
      "step": 1500
    },
    {
      "epoch": 29.03846153846154,
      "grad_norm": 5.395527362823486,
      "learning_rate": 2.111538461538462e-05,
      "loss": 0.0822,
      "step": 1510
    },
    {
      "epoch": 29.23076923076923,
      "grad_norm": 5.15894889831543,
      "learning_rate": 2.0923076923076923e-05,
      "loss": 0.0794,
      "step": 1520
    },
    {
      "epoch": 29.423076923076923,
      "grad_norm": 5.762989521026611,
      "learning_rate": 2.073076923076923e-05,
      "loss": 0.0808,
      "step": 1530
    },
    {
      "epoch": 29.615384615384617,
      "grad_norm": 4.2659125328063965,
      "learning_rate": 2.0538461538461538e-05,
      "loss": 0.0581,
      "step": 1540
    },
    {
      "epoch": 29.807692307692307,
      "grad_norm": 4.990777492523193,
      "learning_rate": 2.034615384615385e-05,
      "loss": 0.0703,
      "step": 1550
    },
    {
      "epoch": 30.0,
      "grad_norm": 5.149178504943848,
      "learning_rate": 2.0153846153846153e-05,
      "loss": 0.0978,
      "step": 1560
    },
    {
      "epoch": 30.192307692307693,
      "grad_norm": 4.783517360687256,
      "learning_rate": 1.996153846153846e-05,
      "loss": 0.0737,
      "step": 1570
    },
    {
      "epoch": 30.384615384615383,
      "grad_norm": 1.3255746364593506,
      "learning_rate": 1.976923076923077e-05,
      "loss": 0.0548,
      "step": 1580
    },
    {
      "epoch": 30.576923076923077,
      "grad_norm": 2.0920093059539795,
      "learning_rate": 1.957692307692308e-05,
      "loss": 0.0669,
      "step": 1590
    },
    {
      "epoch": 30.76923076923077,
      "grad_norm": 3.3796815872192383,
      "learning_rate": 1.9384615384615383e-05,
      "loss": 0.1017,
      "step": 1600
    },
    {
      "epoch": 30.96153846153846,
      "grad_norm": 1.852725863456726,
      "learning_rate": 1.9192307692307694e-05,
      "loss": 0.0786,
      "step": 1610
    },
    {
      "epoch": 31.153846153846153,
      "grad_norm": 2.1034932136535645,
      "learning_rate": 1.9e-05,
      "loss": 0.0569,
      "step": 1620
    },
    {
      "epoch": 31.346153846153847,
      "grad_norm": 2.8683483600616455,
      "learning_rate": 1.880769230769231e-05,
      "loss": 0.0827,
      "step": 1630
    },
    {
      "epoch": 31.53846153846154,
      "grad_norm": 1.6994153261184692,
      "learning_rate": 1.8615384615384616e-05,
      "loss": 0.0936,
      "step": 1640
    },
    {
      "epoch": 31.73076923076923,
      "grad_norm": 3.4894821643829346,
      "learning_rate": 1.8423076923076923e-05,
      "loss": 0.0816,
      "step": 1650
    },
    {
      "epoch": 31.923076923076923,
      "grad_norm": 2.1020472049713135,
      "learning_rate": 1.823076923076923e-05,
      "loss": 0.0553,
      "step": 1660
    },
    {
      "epoch": 32.11538461538461,
      "grad_norm": 1.8080286979675293,
      "learning_rate": 1.803846153846154e-05,
      "loss": 0.0904,
      "step": 1670
    },
    {
      "epoch": 32.30769230769231,
      "grad_norm": 3.53769850730896,
      "learning_rate": 1.7846153846153846e-05,
      "loss": 0.0577,
      "step": 1680
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.861119270324707,
      "learning_rate": 1.7653846153846153e-05,
      "loss": 0.052,
      "step": 1690
    },
    {
      "epoch": 32.69230769230769,
      "grad_norm": 4.433659076690674,
      "learning_rate": 1.7461538461538464e-05,
      "loss": 0.085,
      "step": 1700
    },
    {
      "epoch": 32.88461538461539,
      "grad_norm": 5.337901592254639,
      "learning_rate": 1.726923076923077e-05,
      "loss": 0.0628,
      "step": 1710
    },
    {
      "epoch": 33.07692307692308,
      "grad_norm": 2.886091709136963,
      "learning_rate": 1.7076923076923076e-05,
      "loss": 0.0539,
      "step": 1720
    },
    {
      "epoch": 33.26923076923077,
      "grad_norm": 5.031983852386475,
      "learning_rate": 1.6884615384615386e-05,
      "loss": 0.05,
      "step": 1730
    },
    {
      "epoch": 33.46153846153846,
      "grad_norm": 1.8389332294464111,
      "learning_rate": 1.6692307692307694e-05,
      "loss": 0.0627,
      "step": 1740
    },
    {
      "epoch": 33.65384615384615,
      "grad_norm": 3.5117218494415283,
      "learning_rate": 1.65e-05,
      "loss": 0.1031,
      "step": 1750
    },
    {
      "epoch": 33.84615384615385,
      "grad_norm": 9.365647315979004,
      "learning_rate": 1.630769230769231e-05,
      "loss": 0.0553,
      "step": 1760
    },
    {
      "epoch": 34.03846153846154,
      "grad_norm": 1.9511291980743408,
      "learning_rate": 1.6115384615384616e-05,
      "loss": 0.0998,
      "step": 1770
    },
    {
      "epoch": 34.23076923076923,
      "grad_norm": 4.1590399742126465,
      "learning_rate": 1.5923076923076924e-05,
      "loss": 0.0678,
      "step": 1780
    },
    {
      "epoch": 34.42307692307692,
      "grad_norm": 2.6268980503082275,
      "learning_rate": 1.573076923076923e-05,
      "loss": 0.0486,
      "step": 1790
    },
    {
      "epoch": 34.61538461538461,
      "grad_norm": 4.574725151062012,
      "learning_rate": 1.553846153846154e-05,
      "loss": 0.0532,
      "step": 1800
    },
    {
      "epoch": 34.80769230769231,
      "grad_norm": 4.146461009979248,
      "learning_rate": 1.5346153846153846e-05,
      "loss": 0.0737,
      "step": 1810
    },
    {
      "epoch": 35.0,
      "grad_norm": 3.1273515224456787,
      "learning_rate": 1.5153846153846155e-05,
      "loss": 0.0543,
      "step": 1820
    },
    {
      "epoch": 35.19230769230769,
      "grad_norm": 1.2738227844238281,
      "learning_rate": 1.4961538461538463e-05,
      "loss": 0.0477,
      "step": 1830
    },
    {
      "epoch": 35.38461538461539,
      "grad_norm": 5.033596992492676,
      "learning_rate": 1.4769230769230772e-05,
      "loss": 0.0768,
      "step": 1840
    },
    {
      "epoch": 35.57692307692308,
      "grad_norm": 6.536614418029785,
      "learning_rate": 1.4576923076923077e-05,
      "loss": 0.0856,
      "step": 1850
    },
    {
      "epoch": 35.76923076923077,
      "grad_norm": 1.9814772605895996,
      "learning_rate": 1.4384615384615385e-05,
      "loss": 0.061,
      "step": 1860
    },
    {
      "epoch": 35.96153846153846,
      "grad_norm": 2.0475001335144043,
      "learning_rate": 1.4192307692307694e-05,
      "loss": 0.0517,
      "step": 1870
    },
    {
      "epoch": 36.15384615384615,
      "grad_norm": 4.179853439331055,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0529,
      "step": 1880
    },
    {
      "epoch": 36.34615384615385,
      "grad_norm": 1.2369716167449951,
      "learning_rate": 1.3807692307692307e-05,
      "loss": 0.0452,
      "step": 1890
    },
    {
      "epoch": 36.53846153846154,
      "grad_norm": 4.267375946044922,
      "learning_rate": 1.3615384615384616e-05,
      "loss": 0.0966,
      "step": 1900
    },
    {
      "epoch": 36.73076923076923,
      "grad_norm": 1.7429049015045166,
      "learning_rate": 1.3423076923076924e-05,
      "loss": 0.0582,
      "step": 1910
    },
    {
      "epoch": 36.92307692307692,
      "grad_norm": 4.047639846801758,
      "learning_rate": 1.3230769230769233e-05,
      "loss": 0.0624,
      "step": 1920
    },
    {
      "epoch": 37.11538461538461,
      "grad_norm": 1.3234943151474,
      "learning_rate": 1.3038461538461539e-05,
      "loss": 0.0426,
      "step": 1930
    },
    {
      "epoch": 37.30769230769231,
      "grad_norm": 3.3354015350341797,
      "learning_rate": 1.2846153846153846e-05,
      "loss": 0.055,
      "step": 1940
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.601473093032837,
      "learning_rate": 1.2653846153846155e-05,
      "loss": 0.0657,
      "step": 1950
    },
    {
      "epoch": 37.69230769230769,
      "grad_norm": 1.7784911394119263,
      "learning_rate": 1.2461538461538463e-05,
      "loss": 0.041,
      "step": 1960
    },
    {
      "epoch": 37.88461538461539,
      "grad_norm": 6.52777099609375,
      "learning_rate": 1.226923076923077e-05,
      "loss": 0.097,
      "step": 1970
    },
    {
      "epoch": 38.07692307692308,
      "grad_norm": 1.076709270477295,
      "learning_rate": 1.2076923076923078e-05,
      "loss": 0.0572,
      "step": 1980
    },
    {
      "epoch": 38.26923076923077,
      "grad_norm": 2.5935792922973633,
      "learning_rate": 1.1884615384615385e-05,
      "loss": 0.0554,
      "step": 1990
    },
    {
      "epoch": 38.46153846153846,
      "grad_norm": 3.2852203845977783,
      "learning_rate": 1.1692307692307693e-05,
      "loss": 0.0567,
      "step": 2000
    },
    {
      "epoch": 38.46153846153846,
      "eval_loss": 0.05408039316534996,
      "eval_runtime": 4.6063,
      "eval_samples_per_second": 22.578,
      "eval_steps_per_second": 11.289,
      "step": 2000
    },
    {
      "epoch": 38.65384615384615,
      "grad_norm": 1.2104809284210205,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0639,
      "step": 2010
    },
    {
      "epoch": 38.84615384615385,
      "grad_norm": 1.605981469154358,
      "learning_rate": 1.1307692307692307e-05,
      "loss": 0.0394,
      "step": 2020
    },
    {
      "epoch": 39.03846153846154,
      "grad_norm": 4.67180061340332,
      "learning_rate": 1.1115384615384617e-05,
      "loss": 0.0786,
      "step": 2030
    },
    {
      "epoch": 39.23076923076923,
      "grad_norm": 1.4547770023345947,
      "learning_rate": 1.0923076923076924e-05,
      "loss": 0.0395,
      "step": 2040
    },
    {
      "epoch": 39.42307692307692,
      "grad_norm": 5.224630832672119,
      "learning_rate": 1.0730769230769231e-05,
      "loss": 0.069,
      "step": 2050
    },
    {
      "epoch": 39.61538461538461,
      "grad_norm": 3.520854949951172,
      "learning_rate": 1.0538461538461539e-05,
      "loss": 0.0413,
      "step": 2060
    },
    {
      "epoch": 39.80769230769231,
      "grad_norm": 2.854351282119751,
      "learning_rate": 1.0346153846153846e-05,
      "loss": 0.0543,
      "step": 2070
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.6225274801254272,
      "learning_rate": 1.0153846153846154e-05,
      "loss": 0.0786,
      "step": 2080
    },
    {
      "epoch": 40.19230769230769,
      "grad_norm": 3.7290289402008057,
      "learning_rate": 9.961538461538463e-06,
      "loss": 0.0465,
      "step": 2090
    },
    {
      "epoch": 40.38461538461539,
      "grad_norm": 3.6328816413879395,
      "learning_rate": 9.769230769230769e-06,
      "loss": 0.0656,
      "step": 2100
    },
    {
      "epoch": 40.57692307692308,
      "grad_norm": 1.6041817665100098,
      "learning_rate": 9.576923076923078e-06,
      "loss": 0.0512,
      "step": 2110
    },
    {
      "epoch": 40.76923076923077,
      "grad_norm": 4.702286720275879,
      "learning_rate": 9.384615384615385e-06,
      "loss": 0.0488,
      "step": 2120
    },
    {
      "epoch": 40.96153846153846,
      "grad_norm": 4.0440354347229,
      "learning_rate": 9.192307692307693e-06,
      "loss": 0.0601,
      "step": 2130
    },
    {
      "epoch": 41.15384615384615,
      "grad_norm": 6.67065954208374,
      "learning_rate": 9e-06,
      "loss": 0.0722,
      "step": 2140
    },
    {
      "epoch": 41.34615384615385,
      "grad_norm": 2.0758068561553955,
      "learning_rate": 8.807692307692308e-06,
      "loss": 0.0441,
      "step": 2150
    },
    {
      "epoch": 41.53846153846154,
      "grad_norm": 3.3973727226257324,
      "learning_rate": 8.615384615384615e-06,
      "loss": 0.0667,
      "step": 2160
    },
    {
      "epoch": 41.73076923076923,
      "grad_norm": 3.5461266040802,
      "learning_rate": 8.423076923076924e-06,
      "loss": 0.0683,
      "step": 2170
    },
    {
      "epoch": 41.92307692307692,
      "grad_norm": 1.1601935625076294,
      "learning_rate": 8.23076923076923e-06,
      "loss": 0.0459,
      "step": 2180
    },
    {
      "epoch": 42.11538461538461,
      "grad_norm": 3.9438347816467285,
      "learning_rate": 8.03846153846154e-06,
      "loss": 0.0406,
      "step": 2190
    },
    {
      "epoch": 42.30769230769231,
      "grad_norm": 2.0040066242218018,
      "learning_rate": 7.846153846153847e-06,
      "loss": 0.0456,
      "step": 2200
    },
    {
      "epoch": 42.5,
      "grad_norm": 2.496142864227295,
      "learning_rate": 7.653846153846154e-06,
      "loss": 0.036,
      "step": 2210
    },
    {
      "epoch": 42.69230769230769,
      "grad_norm": 4.898029804229736,
      "learning_rate": 7.4615384615384615e-06,
      "loss": 0.0539,
      "step": 2220
    },
    {
      "epoch": 42.88461538461539,
      "grad_norm": 1.8751403093338013,
      "learning_rate": 7.26923076923077e-06,
      "loss": 0.0532,
      "step": 2230
    },
    {
      "epoch": 43.07692307692308,
      "grad_norm": 3.316807508468628,
      "learning_rate": 7.076923076923076e-06,
      "loss": 0.0834,
      "step": 2240
    },
    {
      "epoch": 43.26923076923077,
      "grad_norm": 2.3106603622436523,
      "learning_rate": 6.8846153846153855e-06,
      "loss": 0.0275,
      "step": 2250
    },
    {
      "epoch": 43.46153846153846,
      "grad_norm": 1.0268032550811768,
      "learning_rate": 6.692307692307692e-06,
      "loss": 0.0439,
      "step": 2260
    },
    {
      "epoch": 43.65384615384615,
      "grad_norm": 3.2366929054260254,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0428,
      "step": 2270
    },
    {
      "epoch": 43.84615384615385,
      "grad_norm": 3.6115009784698486,
      "learning_rate": 6.307692307692308e-06,
      "loss": 0.0706,
      "step": 2280
    },
    {
      "epoch": 44.03846153846154,
      "grad_norm": 2.6586384773254395,
      "learning_rate": 6.115384615384616e-06,
      "loss": 0.0888,
      "step": 2290
    },
    {
      "epoch": 44.23076923076923,
      "grad_norm": 5.120609760284424,
      "learning_rate": 5.923076923076924e-06,
      "loss": 0.0493,
      "step": 2300
    },
    {
      "epoch": 44.42307692307692,
      "grad_norm": 1.9629311561584473,
      "learning_rate": 5.730769230769231e-06,
      "loss": 0.0443,
      "step": 2310
    },
    {
      "epoch": 44.61538461538461,
      "grad_norm": 4.480480670928955,
      "learning_rate": 5.5384615384615385e-06,
      "loss": 0.048,
      "step": 2320
    },
    {
      "epoch": 44.80769230769231,
      "grad_norm": 1.2127535343170166,
      "learning_rate": 5.346153846153847e-06,
      "loss": 0.0334,
      "step": 2330
    },
    {
      "epoch": 45.0,
      "grad_norm": 5.199800491333008,
      "learning_rate": 5.153846153846154e-06,
      "loss": 0.0821,
      "step": 2340
    },
    {
      "epoch": 45.19230769230769,
      "grad_norm": 3.6357431411743164,
      "learning_rate": 4.961538461538462e-06,
      "loss": 0.0392,
      "step": 2350
    },
    {
      "epoch": 45.38461538461539,
      "grad_norm": 3.5149033069610596,
      "learning_rate": 4.769230769230769e-06,
      "loss": 0.0506,
      "step": 2360
    },
    {
      "epoch": 45.57692307692308,
      "grad_norm": 3.0578677654266357,
      "learning_rate": 4.5769230769230775e-06,
      "loss": 0.0664,
      "step": 2370
    },
    {
      "epoch": 45.76923076923077,
      "grad_norm": 2.596158027648926,
      "learning_rate": 4.384615384615385e-06,
      "loss": 0.0478,
      "step": 2380
    },
    {
      "epoch": 45.96153846153846,
      "grad_norm": 6.209922790527344,
      "learning_rate": 4.192307692307692e-06,
      "loss": 0.0592,
      "step": 2390
    },
    {
      "epoch": 46.15384615384615,
      "grad_norm": 4.043296813964844,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.043,
      "step": 2400
    },
    {
      "epoch": 46.34615384615385,
      "grad_norm": 1.4956873655319214,
      "learning_rate": 3.807692307692308e-06,
      "loss": 0.0487,
      "step": 2410
    },
    {
      "epoch": 46.53846153846154,
      "grad_norm": 2.5590720176696777,
      "learning_rate": 3.6153846153846156e-06,
      "loss": 0.0517,
      "step": 2420
    },
    {
      "epoch": 46.73076923076923,
      "grad_norm": 1.0008047819137573,
      "learning_rate": 3.4230769230769234e-06,
      "loss": 0.0434,
      "step": 2430
    },
    {
      "epoch": 46.92307692307692,
      "grad_norm": 1.1545461416244507,
      "learning_rate": 3.230769230769231e-06,
      "loss": 0.0444,
      "step": 2440
    },
    {
      "epoch": 47.11538461538461,
      "grad_norm": 3.767059803009033,
      "learning_rate": 3.0384615384615388e-06,
      "loss": 0.0779,
      "step": 2450
    },
    {
      "epoch": 47.30769230769231,
      "grad_norm": 2.0765202045440674,
      "learning_rate": 2.846153846153846e-06,
      "loss": 0.0518,
      "step": 2460
    },
    {
      "epoch": 47.5,
      "grad_norm": 4.3413214683532715,
      "learning_rate": 2.653846153846154e-06,
      "loss": 0.0702,
      "step": 2470
    },
    {
      "epoch": 47.69230769230769,
      "grad_norm": 4.823135852813721,
      "learning_rate": 2.4615384615384615e-06,
      "loss": 0.0502,
      "step": 2480
    },
    {
      "epoch": 47.88461538461539,
      "grad_norm": 2.3167972564697266,
      "learning_rate": 2.2692307692307694e-06,
      "loss": 0.0323,
      "step": 2490
    },
    {
      "epoch": 48.07692307692308,
      "grad_norm": 1.0024514198303223,
      "learning_rate": 2.076923076923077e-06,
      "loss": 0.0422,
      "step": 2500
    },
    {
      "epoch": 48.07692307692308,
      "eval_loss": 0.04716271162033081,
      "eval_runtime": 4.6252,
      "eval_samples_per_second": 22.485,
      "eval_steps_per_second": 11.243,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.495406739456e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
