{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9996400431948165,
  "eval_steps": 500,
  "global_step": 150000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00019997600287965445,
      "grad_norm": 23.410112380981445,
      "learning_rate": 4.9999000119985605e-05,
      "loss": 7.0936,
      "step": 10
    },
    {
      "epoch": 0.0003999520057593089,
      "grad_norm": 29.896526336669922,
      "learning_rate": 4.9995667186604275e-05,
      "loss": 4.799,
      "step": 20
    },
    {
      "epoch": 0.0005999280086389634,
      "grad_norm": 2.8550190925598145,
      "learning_rate": 4.999233425322295e-05,
      "loss": 1.3813,
      "step": 30
    },
    {
      "epoch": 0.0007999040115186178,
      "grad_norm": 0.2126200795173645,
      "learning_rate": 4.998900131984162e-05,
      "loss": 0.1632,
      "step": 40
    },
    {
      "epoch": 0.0009998800143982722,
      "grad_norm": 0.21073801815509796,
      "learning_rate": 4.998566838646029e-05,
      "loss": 0.1709,
      "step": 50
    },
    {
      "epoch": 0.0011998560172779267,
      "grad_norm": 0.11317990720272064,
      "learning_rate": 4.998233545307897e-05,
      "loss": 0.177,
      "step": 60
    },
    {
      "epoch": 0.001399832020157581,
      "grad_norm": 0.10475204885005951,
      "learning_rate": 4.9979002519697637e-05,
      "loss": 0.1417,
      "step": 70
    },
    {
      "epoch": 0.0015998080230372356,
      "grad_norm": 0.19801636040210724,
      "learning_rate": 4.9975669586316306e-05,
      "loss": 0.1571,
      "step": 80
    },
    {
      "epoch": 0.00179978402591689,
      "grad_norm": 0.12828689813613892,
      "learning_rate": 4.997233665293498e-05,
      "loss": 0.1398,
      "step": 90
    },
    {
      "epoch": 0.0019997600287965443,
      "grad_norm": 0.09040138125419617,
      "learning_rate": 4.996900371955366e-05,
      "loss": 0.1191,
      "step": 100
    },
    {
      "epoch": 0.002199736031676199,
      "grad_norm": 0.10323946177959442,
      "learning_rate": 4.996567078617233e-05,
      "loss": 0.1216,
      "step": 110
    },
    {
      "epoch": 0.0023997120345558534,
      "grad_norm": 0.10942890495061874,
      "learning_rate": 4.9962337852791005e-05,
      "loss": 0.0931,
      "step": 120
    },
    {
      "epoch": 0.0025996880374355076,
      "grad_norm": 0.21863920986652374,
      "learning_rate": 4.9959004919409675e-05,
      "loss": 0.1067,
      "step": 130
    },
    {
      "epoch": 0.002799664040315162,
      "grad_norm": 0.13367818295955658,
      "learning_rate": 4.9955671986028344e-05,
      "loss": 0.128,
      "step": 140
    },
    {
      "epoch": 0.0029996400431948167,
      "grad_norm": 0.1545201987028122,
      "learning_rate": 4.995233905264702e-05,
      "loss": 0.0984,
      "step": 150
    },
    {
      "epoch": 0.0031996160460744712,
      "grad_norm": 0.20213744044303894,
      "learning_rate": 4.994900611926569e-05,
      "loss": 0.0917,
      "step": 160
    },
    {
      "epoch": 0.0033995920489541254,
      "grad_norm": 0.22879138588905334,
      "learning_rate": 4.994567318588436e-05,
      "loss": 0.1213,
      "step": 170
    },
    {
      "epoch": 0.00359956805183378,
      "grad_norm": 0.13312309980392456,
      "learning_rate": 4.9942340252503036e-05,
      "loss": 0.0967,
      "step": 180
    },
    {
      "epoch": 0.0037995440547134345,
      "grad_norm": 0.07325709611177444,
      "learning_rate": 4.9939007319121706e-05,
      "loss": 0.0752,
      "step": 190
    },
    {
      "epoch": 0.003999520057593089,
      "grad_norm": 0.19763867557048798,
      "learning_rate": 4.9935674385740375e-05,
      "loss": 0.0931,
      "step": 200
    },
    {
      "epoch": 0.004199496060472744,
      "grad_norm": 0.1191394031047821,
      "learning_rate": 4.993234145235905e-05,
      "loss": 0.0807,
      "step": 210
    },
    {
      "epoch": 0.004399472063352398,
      "grad_norm": 0.2086421102285385,
      "learning_rate": 4.992900851897773e-05,
      "loss": 0.0602,
      "step": 220
    },
    {
      "epoch": 0.004599448066232052,
      "grad_norm": 0.1688908338546753,
      "learning_rate": 4.99256755855964e-05,
      "loss": 0.0848,
      "step": 230
    },
    {
      "epoch": 0.004799424069111707,
      "grad_norm": 0.14429275691509247,
      "learning_rate": 4.992234265221507e-05,
      "loss": 0.1051,
      "step": 240
    },
    {
      "epoch": 0.004999400071991361,
      "grad_norm": 0.12699206173419952,
      "learning_rate": 4.9919009718833744e-05,
      "loss": 0.2713,
      "step": 250
    },
    {
      "epoch": 0.005199376074871015,
      "grad_norm": 0.12593425810337067,
      "learning_rate": 4.9915676785452413e-05,
      "loss": 0.078,
      "step": 260
    },
    {
      "epoch": 0.00539935207775067,
      "grad_norm": 0.09240490943193436,
      "learning_rate": 4.991234385207108e-05,
      "loss": 0.0848,
      "step": 270
    },
    {
      "epoch": 0.005599328080630324,
      "grad_norm": 0.12059827148914337,
      "learning_rate": 4.990901091868976e-05,
      "loss": 0.1101,
      "step": 280
    },
    {
      "epoch": 0.005799304083509979,
      "grad_norm": 0.1719030737876892,
      "learning_rate": 4.990567798530843e-05,
      "loss": 0.0947,
      "step": 290
    },
    {
      "epoch": 0.005999280086389633,
      "grad_norm": 0.11026125401258469,
      "learning_rate": 4.99023450519271e-05,
      "loss": 0.0701,
      "step": 300
    },
    {
      "epoch": 0.0061992560892692875,
      "grad_norm": 0.134553462266922,
      "learning_rate": 4.989901211854578e-05,
      "loss": 0.1081,
      "step": 310
    },
    {
      "epoch": 0.0063992320921489425,
      "grad_norm": 0.12360858917236328,
      "learning_rate": 4.989567918516445e-05,
      "loss": 0.103,
      "step": 320
    },
    {
      "epoch": 0.006599208095028597,
      "grad_norm": 0.13598304986953735,
      "learning_rate": 4.989234625178312e-05,
      "loss": 0.1374,
      "step": 330
    },
    {
      "epoch": 0.006799184097908251,
      "grad_norm": 0.12661777436733246,
      "learning_rate": 4.98890133184018e-05,
      "loss": 0.0666,
      "step": 340
    },
    {
      "epoch": 0.006999160100787906,
      "grad_norm": 0.1059044599533081,
      "learning_rate": 4.988568038502047e-05,
      "loss": 0.1024,
      "step": 350
    },
    {
      "epoch": 0.00719913610366756,
      "grad_norm": 0.1297239512205124,
      "learning_rate": 4.988234745163914e-05,
      "loss": 0.1209,
      "step": 360
    },
    {
      "epoch": 0.007399112106547214,
      "grad_norm": 0.1452271044254303,
      "learning_rate": 4.987901451825781e-05,
      "loss": 0.0757,
      "step": 370
    },
    {
      "epoch": 0.007599088109426869,
      "grad_norm": 0.10021492093801498,
      "learning_rate": 4.987568158487648e-05,
      "loss": 0.0878,
      "step": 380
    },
    {
      "epoch": 0.007799064112306523,
      "grad_norm": 0.18664810061454773,
      "learning_rate": 4.987234865149515e-05,
      "loss": 0.1185,
      "step": 390
    },
    {
      "epoch": 0.007999040115186177,
      "grad_norm": 0.14547663927078247,
      "learning_rate": 4.986901571811383e-05,
      "loss": 0.0984,
      "step": 400
    },
    {
      "epoch": 0.008199016118065831,
      "grad_norm": 0.0966031402349472,
      "learning_rate": 4.9865682784732505e-05,
      "loss": 0.0704,
      "step": 410
    },
    {
      "epoch": 0.008398992120945487,
      "grad_norm": 0.14360105991363525,
      "learning_rate": 4.9862349851351175e-05,
      "loss": 0.0748,
      "step": 420
    },
    {
      "epoch": 0.008598968123825141,
      "grad_norm": 0.08908971399068832,
      "learning_rate": 4.9859016917969844e-05,
      "loss": 0.0938,
      "step": 430
    },
    {
      "epoch": 0.008798944126704795,
      "grad_norm": 0.14945025742053986,
      "learning_rate": 4.985568398458852e-05,
      "loss": 0.1572,
      "step": 440
    },
    {
      "epoch": 0.00899892012958445,
      "grad_norm": 0.13413916528224945,
      "learning_rate": 4.985235105120719e-05,
      "loss": 0.1083,
      "step": 450
    },
    {
      "epoch": 0.009198896132464104,
      "grad_norm": 0.16070586442947388,
      "learning_rate": 4.984901811782586e-05,
      "loss": 0.1041,
      "step": 460
    },
    {
      "epoch": 0.00939887213534376,
      "grad_norm": 0.16053013503551483,
      "learning_rate": 4.9845685184444536e-05,
      "loss": 0.0812,
      "step": 470
    },
    {
      "epoch": 0.009598848138223414,
      "grad_norm": 0.19265563786029816,
      "learning_rate": 4.9842352251063206e-05,
      "loss": 0.1063,
      "step": 480
    },
    {
      "epoch": 0.009798824141103068,
      "grad_norm": 0.1653614342212677,
      "learning_rate": 4.9839019317681876e-05,
      "loss": 0.084,
      "step": 490
    },
    {
      "epoch": 0.009998800143982722,
      "grad_norm": 0.1531808078289032,
      "learning_rate": 4.983568638430055e-05,
      "loss": 0.094,
      "step": 500
    },
    {
      "epoch": 0.010198776146862376,
      "grad_norm": 0.10056638717651367,
      "learning_rate": 4.983235345091923e-05,
      "loss": 0.1074,
      "step": 510
    },
    {
      "epoch": 0.01039875214974203,
      "grad_norm": 0.1601516306400299,
      "learning_rate": 4.98290205175379e-05,
      "loss": 0.1203,
      "step": 520
    },
    {
      "epoch": 0.010598728152621686,
      "grad_norm": 0.13413557410240173,
      "learning_rate": 4.9825687584156574e-05,
      "loss": 0.0861,
      "step": 530
    },
    {
      "epoch": 0.01079870415550134,
      "grad_norm": 0.08505058288574219,
      "learning_rate": 4.9822354650775244e-05,
      "loss": 0.0829,
      "step": 540
    },
    {
      "epoch": 0.010998680158380994,
      "grad_norm": 0.08306669443845749,
      "learning_rate": 4.9819021717393914e-05,
      "loss": 0.064,
      "step": 550
    },
    {
      "epoch": 0.011198656161260648,
      "grad_norm": 0.12232322245836258,
      "learning_rate": 4.981568878401259e-05,
      "loss": 0.1143,
      "step": 560
    },
    {
      "epoch": 0.011398632164140303,
      "grad_norm": 0.22537526488304138,
      "learning_rate": 4.981235585063126e-05,
      "loss": 0.1353,
      "step": 570
    },
    {
      "epoch": 0.011598608167019958,
      "grad_norm": 0.2183973342180252,
      "learning_rate": 4.980902291724993e-05,
      "loss": 0.0949,
      "step": 580
    },
    {
      "epoch": 0.011798584169899613,
      "grad_norm": 0.14252081513404846,
      "learning_rate": 4.9805689983868606e-05,
      "loss": 0.0992,
      "step": 590
    },
    {
      "epoch": 0.011998560172779267,
      "grad_norm": 0.12970903515815735,
      "learning_rate": 4.9802357050487275e-05,
      "loss": 0.0583,
      "step": 600
    },
    {
      "epoch": 0.01219853617565892,
      "grad_norm": 0.07125766575336456,
      "learning_rate": 4.979902411710595e-05,
      "loss": 0.0787,
      "step": 610
    },
    {
      "epoch": 0.012398512178538575,
      "grad_norm": 0.08743990957736969,
      "learning_rate": 4.979569118372462e-05,
      "loss": 0.0729,
      "step": 620
    },
    {
      "epoch": 0.012598488181418229,
      "grad_norm": 0.15431800484657288,
      "learning_rate": 4.97923582503433e-05,
      "loss": 0.1016,
      "step": 630
    },
    {
      "epoch": 0.012798464184297885,
      "grad_norm": 0.12133553624153137,
      "learning_rate": 4.978902531696197e-05,
      "loss": 0.1433,
      "step": 640
    },
    {
      "epoch": 0.012998440187177539,
      "grad_norm": 0.17931422591209412,
      "learning_rate": 4.978569238358064e-05,
      "loss": 0.1359,
      "step": 650
    },
    {
      "epoch": 0.013198416190057193,
      "grad_norm": 0.16092586517333984,
      "learning_rate": 4.978235945019931e-05,
      "loss": 0.1108,
      "step": 660
    },
    {
      "epoch": 0.013398392192936847,
      "grad_norm": 0.09380336105823517,
      "learning_rate": 4.977902651681798e-05,
      "loss": 0.0816,
      "step": 670
    },
    {
      "epoch": 0.013598368195816501,
      "grad_norm": 0.12208624184131622,
      "learning_rate": 4.977569358343665e-05,
      "loss": 0.0788,
      "step": 680
    },
    {
      "epoch": 0.013798344198696156,
      "grad_norm": 0.09272456914186478,
      "learning_rate": 4.977236065005533e-05,
      "loss": 0.0534,
      "step": 690
    },
    {
      "epoch": 0.013998320201575811,
      "grad_norm": 0.19232109189033508,
      "learning_rate": 4.9769027716674e-05,
      "loss": 0.0731,
      "step": 700
    },
    {
      "epoch": 0.014198296204455466,
      "grad_norm": 0.19530999660491943,
      "learning_rate": 4.976569478329267e-05,
      "loss": 0.0981,
      "step": 710
    },
    {
      "epoch": 0.01439827220733512,
      "grad_norm": 0.2053595632314682,
      "learning_rate": 4.976236184991135e-05,
      "loss": 0.1005,
      "step": 720
    },
    {
      "epoch": 0.014598248210214774,
      "grad_norm": 0.12941111624240875,
      "learning_rate": 4.975902891653002e-05,
      "loss": 0.0711,
      "step": 730
    },
    {
      "epoch": 0.014798224213094428,
      "grad_norm": 0.11051936447620392,
      "learning_rate": 4.975569598314869e-05,
      "loss": 0.0738,
      "step": 740
    },
    {
      "epoch": 0.014998200215974084,
      "grad_norm": 0.145719975233078,
      "learning_rate": 4.975236304976737e-05,
      "loss": 0.1093,
      "step": 750
    },
    {
      "epoch": 0.015198176218853738,
      "grad_norm": 0.13039441406726837,
      "learning_rate": 4.9749030116386037e-05,
      "loss": 0.0646,
      "step": 760
    },
    {
      "epoch": 0.015398152221733392,
      "grad_norm": 0.10043913871049881,
      "learning_rate": 4.9745697183004706e-05,
      "loss": 0.0761,
      "step": 770
    },
    {
      "epoch": 0.015598128224613046,
      "grad_norm": 0.12495042383670807,
      "learning_rate": 4.974236424962338e-05,
      "loss": 0.102,
      "step": 780
    },
    {
      "epoch": 0.015798104227492702,
      "grad_norm": 0.12298885732889175,
      "learning_rate": 4.973903131624205e-05,
      "loss": 0.1224,
      "step": 790
    },
    {
      "epoch": 0.015998080230372354,
      "grad_norm": 0.0840120017528534,
      "learning_rate": 4.973569838286072e-05,
      "loss": 0.1055,
      "step": 800
    },
    {
      "epoch": 0.01619805623325201,
      "grad_norm": 0.1262018233537674,
      "learning_rate": 4.97323654494794e-05,
      "loss": 0.1201,
      "step": 810
    },
    {
      "epoch": 0.016398032236131663,
      "grad_norm": 0.15831339359283447,
      "learning_rate": 4.9729032516098075e-05,
      "loss": 0.0815,
      "step": 820
    },
    {
      "epoch": 0.01659800823901132,
      "grad_norm": 0.16481329500675201,
      "learning_rate": 4.9725699582716744e-05,
      "loss": 0.1115,
      "step": 830
    },
    {
      "epoch": 0.016797984241890974,
      "grad_norm": 0.18216919898986816,
      "learning_rate": 4.9722366649335414e-05,
      "loss": 0.0905,
      "step": 840
    },
    {
      "epoch": 0.016997960244770627,
      "grad_norm": 0.17271225154399872,
      "learning_rate": 4.971903371595409e-05,
      "loss": 0.0724,
      "step": 850
    },
    {
      "epoch": 0.017197936247650283,
      "grad_norm": 0.10964913666248322,
      "learning_rate": 4.971570078257276e-05,
      "loss": 0.0811,
      "step": 860
    },
    {
      "epoch": 0.017397912250529935,
      "grad_norm": 0.1560097485780716,
      "learning_rate": 4.971236784919143e-05,
      "loss": 0.1001,
      "step": 870
    },
    {
      "epoch": 0.01759788825340959,
      "grad_norm": 0.1380445808172226,
      "learning_rate": 4.9709034915810106e-05,
      "loss": 0.0964,
      "step": 880
    },
    {
      "epoch": 0.017797864256289247,
      "grad_norm": 0.0757933035492897,
      "learning_rate": 4.9705701982428775e-05,
      "loss": 0.099,
      "step": 890
    },
    {
      "epoch": 0.0179978402591689,
      "grad_norm": 0.15281422436237335,
      "learning_rate": 4.9702369049047445e-05,
      "loss": 0.1137,
      "step": 900
    },
    {
      "epoch": 0.018197816262048555,
      "grad_norm": 0.12362334132194519,
      "learning_rate": 4.969903611566612e-05,
      "loss": 0.0734,
      "step": 910
    },
    {
      "epoch": 0.018397792264928207,
      "grad_norm": 0.09327398985624313,
      "learning_rate": 4.96957031822848e-05,
      "loss": 0.0998,
      "step": 920
    },
    {
      "epoch": 0.018597768267807863,
      "grad_norm": 0.1071685180068016,
      "learning_rate": 4.969237024890347e-05,
      "loss": 0.0428,
      "step": 930
    },
    {
      "epoch": 0.01879774427068752,
      "grad_norm": 0.11640893667936325,
      "learning_rate": 4.9689037315522144e-05,
      "loss": 0.0658,
      "step": 940
    },
    {
      "epoch": 0.01899772027356717,
      "grad_norm": 0.11495737731456757,
      "learning_rate": 4.9685704382140813e-05,
      "loss": 0.0743,
      "step": 950
    },
    {
      "epoch": 0.019197696276446827,
      "grad_norm": 0.13872061669826508,
      "learning_rate": 4.968237144875948e-05,
      "loss": 0.0854,
      "step": 960
    },
    {
      "epoch": 0.01939767227932648,
      "grad_norm": 0.08358976989984512,
      "learning_rate": 4.967903851537816e-05,
      "loss": 0.0776,
      "step": 970
    },
    {
      "epoch": 0.019597648282206136,
      "grad_norm": 0.10881631076335907,
      "learning_rate": 4.967570558199683e-05,
      "loss": 0.0629,
      "step": 980
    },
    {
      "epoch": 0.019797624285085788,
      "grad_norm": 0.17898984253406525,
      "learning_rate": 4.96723726486155e-05,
      "loss": 0.1061,
      "step": 990
    },
    {
      "epoch": 0.019997600287965444,
      "grad_norm": 0.12042465806007385,
      "learning_rate": 4.9669039715234175e-05,
      "loss": 0.0959,
      "step": 1000
    },
    {
      "epoch": 0.0201975762908451,
      "grad_norm": 0.08139272779226303,
      "learning_rate": 4.9665706781852845e-05,
      "loss": 0.1071,
      "step": 1010
    },
    {
      "epoch": 0.020397552293724752,
      "grad_norm": 0.22474305331707,
      "learning_rate": 4.966237384847152e-05,
      "loss": 0.1056,
      "step": 1020
    },
    {
      "epoch": 0.020597528296604408,
      "grad_norm": 0.15847274661064148,
      "learning_rate": 4.965904091509019e-05,
      "loss": 0.1002,
      "step": 1030
    },
    {
      "epoch": 0.02079750429948406,
      "grad_norm": 0.13725166022777557,
      "learning_rate": 4.965570798170887e-05,
      "loss": 0.0778,
      "step": 1040
    },
    {
      "epoch": 0.020997480302363716,
      "grad_norm": 0.22601616382598877,
      "learning_rate": 4.965237504832754e-05,
      "loss": 0.0882,
      "step": 1050
    },
    {
      "epoch": 0.021197456305243372,
      "grad_norm": 0.08182134479284286,
      "learning_rate": 4.9649042114946206e-05,
      "loss": 0.1291,
      "step": 1060
    },
    {
      "epoch": 0.021397432308123025,
      "grad_norm": 0.21128733456134796,
      "learning_rate": 4.964570918156488e-05,
      "loss": 0.1177,
      "step": 1070
    },
    {
      "epoch": 0.02159740831100268,
      "grad_norm": 0.1648167371749878,
      "learning_rate": 4.964237624818355e-05,
      "loss": 0.1086,
      "step": 1080
    },
    {
      "epoch": 0.021797384313882333,
      "grad_norm": 0.16148030757904053,
      "learning_rate": 4.963904331480222e-05,
      "loss": 0.0845,
      "step": 1090
    },
    {
      "epoch": 0.02199736031676199,
      "grad_norm": 0.09806682914495468,
      "learning_rate": 4.96357103814209e-05,
      "loss": 0.0544,
      "step": 1100
    },
    {
      "epoch": 0.022197336319641645,
      "grad_norm": 0.130342036485672,
      "learning_rate": 4.963237744803957e-05,
      "loss": 0.1061,
      "step": 1110
    },
    {
      "epoch": 0.022397312322521297,
      "grad_norm": 0.11334909498691559,
      "learning_rate": 4.9629044514658244e-05,
      "loss": 0.0771,
      "step": 1120
    },
    {
      "epoch": 0.022597288325400953,
      "grad_norm": 0.07304120808839798,
      "learning_rate": 4.962571158127692e-05,
      "loss": 0.0855,
      "step": 1130
    },
    {
      "epoch": 0.022797264328280605,
      "grad_norm": 0.12850859761238098,
      "learning_rate": 4.962237864789559e-05,
      "loss": 0.0695,
      "step": 1140
    },
    {
      "epoch": 0.02299724033116026,
      "grad_norm": 0.11367307603359222,
      "learning_rate": 4.961904571451426e-05,
      "loss": 0.0611,
      "step": 1150
    },
    {
      "epoch": 0.023197216334039917,
      "grad_norm": 0.1983792930841446,
      "learning_rate": 4.9615712781132936e-05,
      "loss": 0.1042,
      "step": 1160
    },
    {
      "epoch": 0.02339719233691957,
      "grad_norm": 0.1180247962474823,
      "learning_rate": 4.9612379847751606e-05,
      "loss": 0.0717,
      "step": 1170
    },
    {
      "epoch": 0.023597168339799225,
      "grad_norm": 0.10022369772195816,
      "learning_rate": 4.9609046914370276e-05,
      "loss": 0.084,
      "step": 1180
    },
    {
      "epoch": 0.023797144342678878,
      "grad_norm": 0.05797526240348816,
      "learning_rate": 4.960571398098895e-05,
      "loss": 0.0837,
      "step": 1190
    },
    {
      "epoch": 0.023997120345558533,
      "grad_norm": 0.0753994956612587,
      "learning_rate": 4.960238104760762e-05,
      "loss": 0.106,
      "step": 1200
    },
    {
      "epoch": 0.024197096348438186,
      "grad_norm": 0.10758902877569199,
      "learning_rate": 4.959904811422629e-05,
      "loss": 0.066,
      "step": 1210
    },
    {
      "epoch": 0.02439707235131784,
      "grad_norm": 0.10069651901721954,
      "learning_rate": 4.959571518084497e-05,
      "loss": 0.0573,
      "step": 1220
    },
    {
      "epoch": 0.024597048354197498,
      "grad_norm": 0.06339322030544281,
      "learning_rate": 4.9592382247463644e-05,
      "loss": 0.0893,
      "step": 1230
    },
    {
      "epoch": 0.02479702435707715,
      "grad_norm": 0.17023254930973053,
      "learning_rate": 4.9589049314082314e-05,
      "loss": 0.0677,
      "step": 1240
    },
    {
      "epoch": 0.024997000359956806,
      "grad_norm": 0.09902485460042953,
      "learning_rate": 4.958571638070098e-05,
      "loss": 0.0699,
      "step": 1250
    },
    {
      "epoch": 0.025196976362836458,
      "grad_norm": 0.06400386244058609,
      "learning_rate": 4.958238344731966e-05,
      "loss": 0.1841,
      "step": 1260
    },
    {
      "epoch": 0.025396952365716114,
      "grad_norm": 0.19806401431560516,
      "learning_rate": 4.957905051393833e-05,
      "loss": 0.1279,
      "step": 1270
    },
    {
      "epoch": 0.02559692836859577,
      "grad_norm": 0.1157490685582161,
      "learning_rate": 4.9575717580557e-05,
      "loss": 0.0844,
      "step": 1280
    },
    {
      "epoch": 0.025796904371475422,
      "grad_norm": 0.08834012597799301,
      "learning_rate": 4.9572384647175675e-05,
      "loss": 0.054,
      "step": 1290
    },
    {
      "epoch": 0.025996880374355078,
      "grad_norm": 0.19448703527450562,
      "learning_rate": 4.9569051713794345e-05,
      "loss": 0.081,
      "step": 1300
    },
    {
      "epoch": 0.02619685637723473,
      "grad_norm": 0.12328078597784042,
      "learning_rate": 4.9565718780413015e-05,
      "loss": 0.12,
      "step": 1310
    },
    {
      "epoch": 0.026396832380114386,
      "grad_norm": 0.1841973215341568,
      "learning_rate": 4.956238584703169e-05,
      "loss": 0.1274,
      "step": 1320
    },
    {
      "epoch": 0.026596808382994042,
      "grad_norm": 0.1658780872821808,
      "learning_rate": 4.955905291365037e-05,
      "loss": 0.1081,
      "step": 1330
    },
    {
      "epoch": 0.026796784385873695,
      "grad_norm": 0.08180689066648483,
      "learning_rate": 4.955571998026904e-05,
      "loss": 0.0989,
      "step": 1340
    },
    {
      "epoch": 0.02699676038875335,
      "grad_norm": 0.08419797569513321,
      "learning_rate": 4.955238704688771e-05,
      "loss": 0.0709,
      "step": 1350
    },
    {
      "epoch": 0.027196736391633003,
      "grad_norm": 0.19085779786109924,
      "learning_rate": 4.954905411350638e-05,
      "loss": 0.1153,
      "step": 1360
    },
    {
      "epoch": 0.02739671239451266,
      "grad_norm": 0.09457473456859589,
      "learning_rate": 4.954572118012505e-05,
      "loss": 0.0616,
      "step": 1370
    },
    {
      "epoch": 0.02759668839739231,
      "grad_norm": 0.12844450771808624,
      "learning_rate": 4.954238824674373e-05,
      "loss": 0.0933,
      "step": 1380
    },
    {
      "epoch": 0.027796664400271967,
      "grad_norm": 0.1133369728922844,
      "learning_rate": 4.95390553133624e-05,
      "loss": 0.0793,
      "step": 1390
    },
    {
      "epoch": 0.027996640403151623,
      "grad_norm": 0.09689000248908997,
      "learning_rate": 4.953572237998107e-05,
      "loss": 0.0484,
      "step": 1400
    },
    {
      "epoch": 0.028196616406031275,
      "grad_norm": 0.10784848034381866,
      "learning_rate": 4.9532389446599745e-05,
      "loss": 0.0652,
      "step": 1410
    },
    {
      "epoch": 0.02839659240891093,
      "grad_norm": 0.10240046679973602,
      "learning_rate": 4.9529056513218414e-05,
      "loss": 0.2074,
      "step": 1420
    },
    {
      "epoch": 0.028596568411790584,
      "grad_norm": 0.12152966111898422,
      "learning_rate": 4.952572357983709e-05,
      "loss": 0.0785,
      "step": 1430
    },
    {
      "epoch": 0.02879654441467024,
      "grad_norm": 0.08163662999868393,
      "learning_rate": 4.952239064645576e-05,
      "loss": 0.0718,
      "step": 1440
    },
    {
      "epoch": 0.028996520417549895,
      "grad_norm": 0.09713959693908691,
      "learning_rate": 4.9519057713074437e-05,
      "loss": 0.0621,
      "step": 1450
    },
    {
      "epoch": 0.029196496420429548,
      "grad_norm": 0.1530061811208725,
      "learning_rate": 4.9515724779693106e-05,
      "loss": 0.1084,
      "step": 1460
    },
    {
      "epoch": 0.029396472423309204,
      "grad_norm": 0.07062975317239761,
      "learning_rate": 4.9512391846311776e-05,
      "loss": 0.083,
      "step": 1470
    },
    {
      "epoch": 0.029596448426188856,
      "grad_norm": 0.14433516561985016,
      "learning_rate": 4.950905891293045e-05,
      "loss": 0.1155,
      "step": 1480
    },
    {
      "epoch": 0.029796424429068512,
      "grad_norm": 0.11023518443107605,
      "learning_rate": 4.950572597954912e-05,
      "loss": 0.0975,
      "step": 1490
    },
    {
      "epoch": 0.029996400431948168,
      "grad_norm": 0.13589966297149658,
      "learning_rate": 4.950239304616779e-05,
      "loss": 0.1113,
      "step": 1500
    },
    {
      "epoch": 0.03019637643482782,
      "grad_norm": 0.23163749277591705,
      "learning_rate": 4.949906011278647e-05,
      "loss": 0.1169,
      "step": 1510
    },
    {
      "epoch": 0.030396352437707476,
      "grad_norm": 0.07786703109741211,
      "learning_rate": 4.949572717940514e-05,
      "loss": 0.0859,
      "step": 1520
    },
    {
      "epoch": 0.03059632844058713,
      "grad_norm": 0.10599753260612488,
      "learning_rate": 4.9492394246023814e-05,
      "loss": 0.093,
      "step": 1530
    },
    {
      "epoch": 0.030796304443466784,
      "grad_norm": 0.10030261427164078,
      "learning_rate": 4.948906131264249e-05,
      "loss": 0.0719,
      "step": 1540
    },
    {
      "epoch": 0.03099628044634644,
      "grad_norm": 0.16748520731925964,
      "learning_rate": 4.948572837926116e-05,
      "loss": 0.105,
      "step": 1550
    },
    {
      "epoch": 0.031196256449226092,
      "grad_norm": 0.12429725378751755,
      "learning_rate": 4.948239544587983e-05,
      "loss": 0.0978,
      "step": 1560
    },
    {
      "epoch": 0.031396232452105745,
      "grad_norm": 0.08588068187236786,
      "learning_rate": 4.9479062512498506e-05,
      "loss": 0.0562,
      "step": 1570
    },
    {
      "epoch": 0.031596208454985404,
      "grad_norm": 0.13054543733596802,
      "learning_rate": 4.9475729579117175e-05,
      "loss": 0.0906,
      "step": 1580
    },
    {
      "epoch": 0.03179618445786506,
      "grad_norm": 0.17764990031719208,
      "learning_rate": 4.9472396645735845e-05,
      "loss": 0.0533,
      "step": 1590
    },
    {
      "epoch": 0.03199616046074471,
      "grad_norm": 0.15349483489990234,
      "learning_rate": 4.946906371235452e-05,
      "loss": 0.1012,
      "step": 1600
    },
    {
      "epoch": 0.03219613646362437,
      "grad_norm": 0.13230273127555847,
      "learning_rate": 4.946573077897319e-05,
      "loss": 0.0992,
      "step": 1610
    },
    {
      "epoch": 0.03239611246650402,
      "grad_norm": 0.1356164664030075,
      "learning_rate": 4.946239784559186e-05,
      "loss": 0.0718,
      "step": 1620
    },
    {
      "epoch": 0.03259608846938367,
      "grad_norm": 0.06961424648761749,
      "learning_rate": 4.945906491221054e-05,
      "loss": 0.0773,
      "step": 1630
    },
    {
      "epoch": 0.032796064472263325,
      "grad_norm": 0.10869397222995758,
      "learning_rate": 4.9455731978829213e-05,
      "loss": 0.0548,
      "step": 1640
    },
    {
      "epoch": 0.032996040475142985,
      "grad_norm": 0.19371774792671204,
      "learning_rate": 4.945239904544788e-05,
      "loss": 0.1053,
      "step": 1650
    },
    {
      "epoch": 0.03319601647802264,
      "grad_norm": 0.11284562945365906,
      "learning_rate": 4.944906611206655e-05,
      "loss": 0.1064,
      "step": 1660
    },
    {
      "epoch": 0.03339599248090229,
      "grad_norm": 0.22190046310424805,
      "learning_rate": 4.944573317868523e-05,
      "loss": 0.1029,
      "step": 1670
    },
    {
      "epoch": 0.03359596848378195,
      "grad_norm": 0.13227730989456177,
      "learning_rate": 4.94424002453039e-05,
      "loss": 0.053,
      "step": 1680
    },
    {
      "epoch": 0.0337959444866616,
      "grad_norm": 0.1784164011478424,
      "learning_rate": 4.943906731192257e-05,
      "loss": 0.0648,
      "step": 1690
    },
    {
      "epoch": 0.033995920489541254,
      "grad_norm": 0.17938640713691711,
      "learning_rate": 4.9435734378541245e-05,
      "loss": 0.0762,
      "step": 1700
    },
    {
      "epoch": 0.034195896492420906,
      "grad_norm": 0.12753009796142578,
      "learning_rate": 4.9432401445159914e-05,
      "loss": 0.1476,
      "step": 1710
    },
    {
      "epoch": 0.034395872495300565,
      "grad_norm": 0.14522838592529297,
      "learning_rate": 4.9429068511778584e-05,
      "loss": 0.0782,
      "step": 1720
    },
    {
      "epoch": 0.03459584849818022,
      "grad_norm": 0.10650520771741867,
      "learning_rate": 4.942573557839726e-05,
      "loss": 0.1073,
      "step": 1730
    },
    {
      "epoch": 0.03479582450105987,
      "grad_norm": 0.09598314762115479,
      "learning_rate": 4.942240264501594e-05,
      "loss": 0.1015,
      "step": 1740
    },
    {
      "epoch": 0.03499580050393953,
      "grad_norm": 0.12310905009508133,
      "learning_rate": 4.9419069711634606e-05,
      "loss": 0.1149,
      "step": 1750
    },
    {
      "epoch": 0.03519577650681918,
      "grad_norm": 0.09321295469999313,
      "learning_rate": 4.941573677825328e-05,
      "loss": 0.1083,
      "step": 1760
    },
    {
      "epoch": 0.035395752509698834,
      "grad_norm": 0.10703032463788986,
      "learning_rate": 4.941240384487195e-05,
      "loss": 0.079,
      "step": 1770
    },
    {
      "epoch": 0.035595728512578494,
      "grad_norm": 0.1321588009595871,
      "learning_rate": 4.940907091149062e-05,
      "loss": 0.0978,
      "step": 1780
    },
    {
      "epoch": 0.035795704515458146,
      "grad_norm": 0.1153334453701973,
      "learning_rate": 4.94057379781093e-05,
      "loss": 0.0788,
      "step": 1790
    },
    {
      "epoch": 0.0359956805183378,
      "grad_norm": 0.1676114797592163,
      "learning_rate": 4.940240504472797e-05,
      "loss": 0.0663,
      "step": 1800
    },
    {
      "epoch": 0.03619565652121745,
      "grad_norm": 0.11831196397542953,
      "learning_rate": 4.939907211134664e-05,
      "loss": 0.0762,
      "step": 1810
    },
    {
      "epoch": 0.03639563252409711,
      "grad_norm": 0.18396955728530884,
      "learning_rate": 4.9395739177965314e-05,
      "loss": 0.0973,
      "step": 1820
    },
    {
      "epoch": 0.03659560852697676,
      "grad_norm": 0.09889086335897446,
      "learning_rate": 4.9392406244583984e-05,
      "loss": 0.0444,
      "step": 1830
    },
    {
      "epoch": 0.036795584529856415,
      "grad_norm": 0.11377747356891632,
      "learning_rate": 4.938907331120266e-05,
      "loss": 0.0946,
      "step": 1840
    },
    {
      "epoch": 0.036995560532736074,
      "grad_norm": 0.1964343637228012,
      "learning_rate": 4.938574037782133e-05,
      "loss": 0.1162,
      "step": 1850
    },
    {
      "epoch": 0.03719553653561573,
      "grad_norm": 0.1271704137325287,
      "learning_rate": 4.9382407444440006e-05,
      "loss": 0.0822,
      "step": 1860
    },
    {
      "epoch": 0.03739551253849538,
      "grad_norm": 0.15716972947120667,
      "learning_rate": 4.9379074511058676e-05,
      "loss": 0.1292,
      "step": 1870
    },
    {
      "epoch": 0.03759548854137504,
      "grad_norm": 0.11571639776229858,
      "learning_rate": 4.9375741577677345e-05,
      "loss": 0.1404,
      "step": 1880
    },
    {
      "epoch": 0.03779546454425469,
      "grad_norm": 0.06466265767812729,
      "learning_rate": 4.937240864429602e-05,
      "loss": 0.0841,
      "step": 1890
    },
    {
      "epoch": 0.03799544054713434,
      "grad_norm": 0.10683232545852661,
      "learning_rate": 4.936907571091469e-05,
      "loss": 0.1286,
      "step": 1900
    },
    {
      "epoch": 0.038195416550013996,
      "grad_norm": 0.06225966662168503,
      "learning_rate": 4.936574277753336e-05,
      "loss": 0.0868,
      "step": 1910
    },
    {
      "epoch": 0.038395392552893655,
      "grad_norm": 0.12651829421520233,
      "learning_rate": 4.936240984415204e-05,
      "loss": 0.0738,
      "step": 1920
    },
    {
      "epoch": 0.03859536855577331,
      "grad_norm": 0.1716332882642746,
      "learning_rate": 4.935907691077071e-05,
      "loss": 0.1699,
      "step": 1930
    },
    {
      "epoch": 0.03879534455865296,
      "grad_norm": 0.1557389199733734,
      "learning_rate": 4.935574397738938e-05,
      "loss": 0.0835,
      "step": 1940
    },
    {
      "epoch": 0.03899532056153262,
      "grad_norm": 0.14575833082199097,
      "learning_rate": 4.935241104400806e-05,
      "loss": 0.1044,
      "step": 1950
    },
    {
      "epoch": 0.03919529656441227,
      "grad_norm": 0.1504635065793991,
      "learning_rate": 4.934907811062673e-05,
      "loss": 0.0949,
      "step": 1960
    },
    {
      "epoch": 0.039395272567291924,
      "grad_norm": 0.2063717097043991,
      "learning_rate": 4.93457451772454e-05,
      "loss": 0.11,
      "step": 1970
    },
    {
      "epoch": 0.039595248570171576,
      "grad_norm": 0.1332937628030777,
      "learning_rate": 4.9342412243864075e-05,
      "loss": 0.058,
      "step": 1980
    },
    {
      "epoch": 0.039795224573051236,
      "grad_norm": 0.14327092468738556,
      "learning_rate": 4.9339079310482745e-05,
      "loss": 0.1291,
      "step": 1990
    },
    {
      "epoch": 0.03999520057593089,
      "grad_norm": 0.15808022022247314,
      "learning_rate": 4.9335746377101415e-05,
      "loss": 0.0611,
      "step": 2000
    },
    {
      "epoch": 0.04019517657881054,
      "grad_norm": 0.18596315383911133,
      "learning_rate": 4.933241344372009e-05,
      "loss": 0.1044,
      "step": 2010
    },
    {
      "epoch": 0.0403951525816902,
      "grad_norm": 0.09909090399742126,
      "learning_rate": 4.932908051033876e-05,
      "loss": 0.0901,
      "step": 2020
    },
    {
      "epoch": 0.04059512858456985,
      "grad_norm": 0.10783039033412933,
      "learning_rate": 4.932574757695743e-05,
      "loss": 0.0888,
      "step": 2030
    },
    {
      "epoch": 0.040795104587449504,
      "grad_norm": 0.19306936860084534,
      "learning_rate": 4.9322414643576107e-05,
      "loss": 0.0835,
      "step": 2040
    },
    {
      "epoch": 0.040995080590329164,
      "grad_norm": 0.13225363194942474,
      "learning_rate": 4.931908171019478e-05,
      "loss": 0.0915,
      "step": 2050
    },
    {
      "epoch": 0.041195056593208816,
      "grad_norm": 0.136185884475708,
      "learning_rate": 4.931574877681345e-05,
      "loss": 0.0738,
      "step": 2060
    },
    {
      "epoch": 0.04139503259608847,
      "grad_norm": 0.0743403434753418,
      "learning_rate": 4.931241584343212e-05,
      "loss": 0.0786,
      "step": 2070
    },
    {
      "epoch": 0.04159500859896812,
      "grad_norm": 0.08760938048362732,
      "learning_rate": 4.93090829100508e-05,
      "loss": 0.0758,
      "step": 2080
    },
    {
      "epoch": 0.04179498460184778,
      "grad_norm": 0.14257311820983887,
      "learning_rate": 4.930574997666947e-05,
      "loss": 0.1095,
      "step": 2090
    },
    {
      "epoch": 0.04199496060472743,
      "grad_norm": 0.09818441420793533,
      "learning_rate": 4.930241704328814e-05,
      "loss": 0.0813,
      "step": 2100
    },
    {
      "epoch": 0.042194936607607085,
      "grad_norm": 0.130644753575325,
      "learning_rate": 4.9299084109906814e-05,
      "loss": 0.0846,
      "step": 2110
    },
    {
      "epoch": 0.042394912610486744,
      "grad_norm": 0.1182050108909607,
      "learning_rate": 4.9295751176525484e-05,
      "loss": 0.0628,
      "step": 2120
    },
    {
      "epoch": 0.0425948886133664,
      "grad_norm": 0.08834684640169144,
      "learning_rate": 4.9292418243144153e-05,
      "loss": 0.1025,
      "step": 2130
    },
    {
      "epoch": 0.04279486461624605,
      "grad_norm": 0.14033348858356476,
      "learning_rate": 4.9289085309762837e-05,
      "loss": 0.0768,
      "step": 2140
    },
    {
      "epoch": 0.0429948406191257,
      "grad_norm": 0.07966770976781845,
      "learning_rate": 4.9285752376381506e-05,
      "loss": 0.083,
      "step": 2150
    },
    {
      "epoch": 0.04319481662200536,
      "grad_norm": 0.16490428149700165,
      "learning_rate": 4.9282419443000176e-05,
      "loss": 0.0952,
      "step": 2160
    },
    {
      "epoch": 0.04339479262488501,
      "grad_norm": 0.08744516968727112,
      "learning_rate": 4.927908650961885e-05,
      "loss": 0.0765,
      "step": 2170
    },
    {
      "epoch": 0.043594768627764666,
      "grad_norm": 0.13420923054218292,
      "learning_rate": 4.927575357623752e-05,
      "loss": 0.092,
      "step": 2180
    },
    {
      "epoch": 0.043794744630644325,
      "grad_norm": 0.12931647896766663,
      "learning_rate": 4.927242064285619e-05,
      "loss": 0.09,
      "step": 2190
    },
    {
      "epoch": 0.04399472063352398,
      "grad_norm": 0.07658673822879791,
      "learning_rate": 4.926908770947487e-05,
      "loss": 0.1025,
      "step": 2200
    },
    {
      "epoch": 0.04419469663640363,
      "grad_norm": 0.16563528776168823,
      "learning_rate": 4.926575477609354e-05,
      "loss": 0.1055,
      "step": 2210
    },
    {
      "epoch": 0.04439467263928329,
      "grad_norm": 0.2117481231689453,
      "learning_rate": 4.926242184271221e-05,
      "loss": 0.0709,
      "step": 2220
    },
    {
      "epoch": 0.04459464864216294,
      "grad_norm": 0.1255071461200714,
      "learning_rate": 4.9259088909330883e-05,
      "loss": 0.0797,
      "step": 2230
    },
    {
      "epoch": 0.044794624645042594,
      "grad_norm": 0.18185660243034363,
      "learning_rate": 4.925575597594955e-05,
      "loss": 0.1833,
      "step": 2240
    },
    {
      "epoch": 0.044994600647922246,
      "grad_norm": 0.08004982769489288,
      "learning_rate": 4.925242304256823e-05,
      "loss": 0.0748,
      "step": 2250
    },
    {
      "epoch": 0.045194576650801906,
      "grad_norm": 0.0784808099269867,
      "learning_rate": 4.92490901091869e-05,
      "loss": 0.0674,
      "step": 2260
    },
    {
      "epoch": 0.04539455265368156,
      "grad_norm": 0.11665453761816025,
      "learning_rate": 4.9245757175805575e-05,
      "loss": 0.0606,
      "step": 2270
    },
    {
      "epoch": 0.04559452865656121,
      "grad_norm": 0.11252787709236145,
      "learning_rate": 4.9242424242424245e-05,
      "loss": 0.0422,
      "step": 2280
    },
    {
      "epoch": 0.04579450465944087,
      "grad_norm": 0.140457421541214,
      "learning_rate": 4.9239091309042915e-05,
      "loss": 0.111,
      "step": 2290
    },
    {
      "epoch": 0.04599448066232052,
      "grad_norm": 0.22382216155529022,
      "learning_rate": 4.923575837566159e-05,
      "loss": 0.0779,
      "step": 2300
    },
    {
      "epoch": 0.046194456665200175,
      "grad_norm": 0.05591548979282379,
      "learning_rate": 4.923242544228026e-05,
      "loss": 0.1041,
      "step": 2310
    },
    {
      "epoch": 0.046394432668079834,
      "grad_norm": 0.20517727732658386,
      "learning_rate": 4.922909250889893e-05,
      "loss": 0.0665,
      "step": 2320
    },
    {
      "epoch": 0.046594408670959486,
      "grad_norm": 0.2256193459033966,
      "learning_rate": 4.922575957551761e-05,
      "loss": 0.1082,
      "step": 2330
    },
    {
      "epoch": 0.04679438467383914,
      "grad_norm": 0.151744082570076,
      "learning_rate": 4.9222426642136276e-05,
      "loss": 0.0784,
      "step": 2340
    },
    {
      "epoch": 0.04699436067671879,
      "grad_norm": 0.13583225011825562,
      "learning_rate": 4.921909370875495e-05,
      "loss": 0.0728,
      "step": 2350
    },
    {
      "epoch": 0.04719433667959845,
      "grad_norm": 0.07775930315256119,
      "learning_rate": 4.921576077537363e-05,
      "loss": 0.1086,
      "step": 2360
    },
    {
      "epoch": 0.0473943126824781,
      "grad_norm": 0.18822477757930756,
      "learning_rate": 4.92124278419923e-05,
      "loss": 0.0989,
      "step": 2370
    },
    {
      "epoch": 0.047594288685357755,
      "grad_norm": 0.18474139273166656,
      "learning_rate": 4.920909490861097e-05,
      "loss": 0.1094,
      "step": 2380
    },
    {
      "epoch": 0.047794264688237414,
      "grad_norm": 0.15575842559337616,
      "learning_rate": 4.9205761975229645e-05,
      "loss": 0.0976,
      "step": 2390
    },
    {
      "epoch": 0.04799424069111707,
      "grad_norm": 0.092787966132164,
      "learning_rate": 4.9202429041848314e-05,
      "loss": 0.0902,
      "step": 2400
    },
    {
      "epoch": 0.04819421669399672,
      "grad_norm": 0.04844177886843681,
      "learning_rate": 4.9199096108466984e-05,
      "loss": 0.0978,
      "step": 2410
    },
    {
      "epoch": 0.04839419269687637,
      "grad_norm": 0.09012558311223984,
      "learning_rate": 4.919576317508566e-05,
      "loss": 0.1344,
      "step": 2420
    },
    {
      "epoch": 0.04859416869975603,
      "grad_norm": 0.10602602362632751,
      "learning_rate": 4.919243024170433e-05,
      "loss": 0.107,
      "step": 2430
    },
    {
      "epoch": 0.04879414470263568,
      "grad_norm": 0.13815796375274658,
      "learning_rate": 4.9189097308323e-05,
      "loss": 0.0784,
      "step": 2440
    },
    {
      "epoch": 0.048994120705515336,
      "grad_norm": 0.11148868501186371,
      "learning_rate": 4.9185764374941676e-05,
      "loss": 0.1312,
      "step": 2450
    },
    {
      "epoch": 0.049194096708394995,
      "grad_norm": 0.15444082021713257,
      "learning_rate": 4.918243144156035e-05,
      "loss": 0.0899,
      "step": 2460
    },
    {
      "epoch": 0.04939407271127465,
      "grad_norm": 0.13686563074588776,
      "learning_rate": 4.917909850817902e-05,
      "loss": 0.0955,
      "step": 2470
    },
    {
      "epoch": 0.0495940487141543,
      "grad_norm": 0.1704518347978592,
      "learning_rate": 4.917576557479769e-05,
      "loss": 0.0616,
      "step": 2480
    },
    {
      "epoch": 0.04979402471703396,
      "grad_norm": 0.13783366978168488,
      "learning_rate": 4.917243264141637e-05,
      "loss": 0.0813,
      "step": 2490
    },
    {
      "epoch": 0.04999400071991361,
      "grad_norm": 0.15938600897789001,
      "learning_rate": 4.916909970803504e-05,
      "loss": 0.0854,
      "step": 2500
    },
    {
      "epoch": 0.050193976722793264,
      "grad_norm": 0.1348128467798233,
      "learning_rate": 4.916576677465371e-05,
      "loss": 0.1216,
      "step": 2510
    },
    {
      "epoch": 0.050393952725672916,
      "grad_norm": 0.07839182764291763,
      "learning_rate": 4.9162433841272384e-05,
      "loss": 0.0528,
      "step": 2520
    },
    {
      "epoch": 0.050593928728552576,
      "grad_norm": 0.14933128654956818,
      "learning_rate": 4.915910090789105e-05,
      "loss": 0.1161,
      "step": 2530
    },
    {
      "epoch": 0.05079390473143223,
      "grad_norm": 0.11812523007392883,
      "learning_rate": 4.915576797450972e-05,
      "loss": 0.2695,
      "step": 2540
    },
    {
      "epoch": 0.05099388073431188,
      "grad_norm": 0.13664592802524567,
      "learning_rate": 4.9152435041128406e-05,
      "loss": 0.0918,
      "step": 2550
    },
    {
      "epoch": 0.05119385673719154,
      "grad_norm": 0.12778723239898682,
      "learning_rate": 4.9149102107747076e-05,
      "loss": 0.1351,
      "step": 2560
    },
    {
      "epoch": 0.05139383274007119,
      "grad_norm": 0.09479144215583801,
      "learning_rate": 4.9145769174365745e-05,
      "loss": 0.1015,
      "step": 2570
    },
    {
      "epoch": 0.051593808742950845,
      "grad_norm": 0.1841660439968109,
      "learning_rate": 4.914243624098442e-05,
      "loss": 0.0869,
      "step": 2580
    },
    {
      "epoch": 0.0517937847458305,
      "grad_norm": 0.1574735939502716,
      "learning_rate": 4.913910330760309e-05,
      "loss": 0.0916,
      "step": 2590
    },
    {
      "epoch": 0.051993760748710156,
      "grad_norm": 0.15641838312149048,
      "learning_rate": 4.913577037422176e-05,
      "loss": 0.0693,
      "step": 2600
    },
    {
      "epoch": 0.05219373675158981,
      "grad_norm": 0.12050606310367584,
      "learning_rate": 4.913243744084044e-05,
      "loss": 0.0764,
      "step": 2610
    },
    {
      "epoch": 0.05239371275446946,
      "grad_norm": 0.17801456153392792,
      "learning_rate": 4.912910450745911e-05,
      "loss": 0.0663,
      "step": 2620
    },
    {
      "epoch": 0.05259368875734912,
      "grad_norm": 0.12222449481487274,
      "learning_rate": 4.9125771574077777e-05,
      "loss": 0.0972,
      "step": 2630
    },
    {
      "epoch": 0.05279366476022877,
      "grad_norm": 0.1732933521270752,
      "learning_rate": 4.912243864069645e-05,
      "loss": 0.1095,
      "step": 2640
    },
    {
      "epoch": 0.052993640763108425,
      "grad_norm": 0.16115054488182068,
      "learning_rate": 4.911910570731513e-05,
      "loss": 0.0768,
      "step": 2650
    },
    {
      "epoch": 0.053193616765988085,
      "grad_norm": 0.11696033179759979,
      "learning_rate": 4.91157727739338e-05,
      "loss": 0.0871,
      "step": 2660
    },
    {
      "epoch": 0.05339359276886774,
      "grad_norm": 0.15867066383361816,
      "learning_rate": 4.911243984055247e-05,
      "loss": 0.1066,
      "step": 2670
    },
    {
      "epoch": 0.05359356877174739,
      "grad_norm": 0.11176896095275879,
      "learning_rate": 4.9109106907171145e-05,
      "loss": 0.0982,
      "step": 2680
    },
    {
      "epoch": 0.05379354477462704,
      "grad_norm": 0.07946912944316864,
      "learning_rate": 4.9105773973789815e-05,
      "loss": 0.0868,
      "step": 2690
    },
    {
      "epoch": 0.0539935207775067,
      "grad_norm": 0.18891237676143646,
      "learning_rate": 4.9102441040408484e-05,
      "loss": 0.0774,
      "step": 2700
    },
    {
      "epoch": 0.054193496780386353,
      "grad_norm": 0.15982800722122192,
      "learning_rate": 4.909910810702716e-05,
      "loss": 0.1116,
      "step": 2710
    },
    {
      "epoch": 0.054393472783266006,
      "grad_norm": 0.1637011021375656,
      "learning_rate": 4.909577517364583e-05,
      "loss": 0.1083,
      "step": 2720
    },
    {
      "epoch": 0.054593448786145665,
      "grad_norm": 0.09448220580816269,
      "learning_rate": 4.90924422402645e-05,
      "loss": 0.076,
      "step": 2730
    },
    {
      "epoch": 0.05479342478902532,
      "grad_norm": 0.10145962983369827,
      "learning_rate": 4.9089109306883176e-05,
      "loss": 0.1162,
      "step": 2740
    },
    {
      "epoch": 0.05499340079190497,
      "grad_norm": 0.13040444254875183,
      "learning_rate": 4.9085776373501846e-05,
      "loss": 0.1205,
      "step": 2750
    },
    {
      "epoch": 0.05519337679478462,
      "grad_norm": 0.09066622704267502,
      "learning_rate": 4.908244344012052e-05,
      "loss": 0.0809,
      "step": 2760
    },
    {
      "epoch": 0.05539335279766428,
      "grad_norm": 0.0686241015791893,
      "learning_rate": 4.90791105067392e-05,
      "loss": 0.0754,
      "step": 2770
    },
    {
      "epoch": 0.055593328800543934,
      "grad_norm": 0.11458202451467514,
      "learning_rate": 4.907577757335787e-05,
      "loss": 0.0871,
      "step": 2780
    },
    {
      "epoch": 0.055793304803423587,
      "grad_norm": 0.1719529628753662,
      "learning_rate": 4.907244463997654e-05,
      "loss": 0.0942,
      "step": 2790
    },
    {
      "epoch": 0.055993280806303246,
      "grad_norm": 0.08516521006822586,
      "learning_rate": 4.9069111706595214e-05,
      "loss": 0.0676,
      "step": 2800
    },
    {
      "epoch": 0.0561932568091829,
      "grad_norm": 0.14773890376091003,
      "learning_rate": 4.9065778773213884e-05,
      "loss": 0.078,
      "step": 2810
    },
    {
      "epoch": 0.05639323281206255,
      "grad_norm": 0.10109007358551025,
      "learning_rate": 4.9062445839832553e-05,
      "loss": 0.0697,
      "step": 2820
    },
    {
      "epoch": 0.05659320881494221,
      "grad_norm": 0.14995351433753967,
      "learning_rate": 4.905911290645123e-05,
      "loss": 0.0804,
      "step": 2830
    },
    {
      "epoch": 0.05679318481782186,
      "grad_norm": 0.07978255301713943,
      "learning_rate": 4.90557799730699e-05,
      "loss": 0.0546,
      "step": 2840
    },
    {
      "epoch": 0.056993160820701515,
      "grad_norm": 0.13555370271205902,
      "learning_rate": 4.905244703968857e-05,
      "loss": 0.1057,
      "step": 2850
    },
    {
      "epoch": 0.05719313682358117,
      "grad_norm": 0.23994383215904236,
      "learning_rate": 4.9049114106307245e-05,
      "loss": 0.0862,
      "step": 2860
    },
    {
      "epoch": 0.057393112826460826,
      "grad_norm": 0.1548410803079605,
      "learning_rate": 4.904578117292592e-05,
      "loss": 0.0807,
      "step": 2870
    },
    {
      "epoch": 0.05759308882934048,
      "grad_norm": 0.2073475420475006,
      "learning_rate": 4.904244823954459e-05,
      "loss": 0.1163,
      "step": 2880
    },
    {
      "epoch": 0.05779306483222013,
      "grad_norm": 0.23588700592517853,
      "learning_rate": 4.903911530616326e-05,
      "loss": 0.0797,
      "step": 2890
    },
    {
      "epoch": 0.05799304083509979,
      "grad_norm": 0.14031603932380676,
      "learning_rate": 4.903578237278194e-05,
      "loss": 0.0755,
      "step": 2900
    },
    {
      "epoch": 0.05819301683797944,
      "grad_norm": 0.10621270537376404,
      "learning_rate": 4.903244943940061e-05,
      "loss": 0.0943,
      "step": 2910
    },
    {
      "epoch": 0.058392992840859095,
      "grad_norm": 0.15591704845428467,
      "learning_rate": 4.902911650601928e-05,
      "loss": 0.0819,
      "step": 2920
    },
    {
      "epoch": 0.058592968843738755,
      "grad_norm": 0.17420367896556854,
      "learning_rate": 4.902578357263795e-05,
      "loss": 0.0696,
      "step": 2930
    },
    {
      "epoch": 0.05879294484661841,
      "grad_norm": 0.15872161090373993,
      "learning_rate": 4.902245063925662e-05,
      "loss": 0.0698,
      "step": 2940
    },
    {
      "epoch": 0.05899292084949806,
      "grad_norm": 0.20596472918987274,
      "learning_rate": 4.901911770587529e-05,
      "loss": 0.114,
      "step": 2950
    },
    {
      "epoch": 0.05919289685237771,
      "grad_norm": 0.13465425372123718,
      "learning_rate": 4.9015784772493975e-05,
      "loss": 0.1128,
      "step": 2960
    },
    {
      "epoch": 0.05939287285525737,
      "grad_norm": 0.09006524831056595,
      "learning_rate": 4.9012451839112645e-05,
      "loss": 0.0523,
      "step": 2970
    },
    {
      "epoch": 0.059592848858137024,
      "grad_norm": 0.09845341742038727,
      "learning_rate": 4.9009118905731315e-05,
      "loss": 0.1008,
      "step": 2980
    },
    {
      "epoch": 0.059792824861016676,
      "grad_norm": 0.13740703463554382,
      "learning_rate": 4.900578597234999e-05,
      "loss": 0.0765,
      "step": 2990
    },
    {
      "epoch": 0.059992800863896335,
      "grad_norm": 0.06821277737617493,
      "learning_rate": 4.900245303896866e-05,
      "loss": 0.1078,
      "step": 3000
    },
    {
      "epoch": 0.06019277686677599,
      "grad_norm": 0.18989987671375275,
      "learning_rate": 4.899912010558733e-05,
      "loss": 0.0983,
      "step": 3010
    },
    {
      "epoch": 0.06039275286965564,
      "grad_norm": 0.17617012560367584,
      "learning_rate": 4.899578717220601e-05,
      "loss": 0.0871,
      "step": 3020
    },
    {
      "epoch": 0.06059272887253529,
      "grad_norm": 0.1495532989501953,
      "learning_rate": 4.8992454238824676e-05,
      "loss": 0.0587,
      "step": 3030
    },
    {
      "epoch": 0.06079270487541495,
      "grad_norm": 0.10917978733778,
      "learning_rate": 4.8989121305443346e-05,
      "loss": 0.1033,
      "step": 3040
    },
    {
      "epoch": 0.060992680878294604,
      "grad_norm": 0.09975191950798035,
      "learning_rate": 4.898578837206202e-05,
      "loss": 0.1138,
      "step": 3050
    },
    {
      "epoch": 0.06119265688117426,
      "grad_norm": 0.15105625987052917,
      "learning_rate": 4.89824554386807e-05,
      "loss": 0.1023,
      "step": 3060
    },
    {
      "epoch": 0.061392632884053916,
      "grad_norm": 0.11917483061552048,
      "learning_rate": 4.897912250529937e-05,
      "loss": 0.0594,
      "step": 3070
    },
    {
      "epoch": 0.06159260888693357,
      "grad_norm": 0.08620616048574448,
      "learning_rate": 4.897578957191804e-05,
      "loss": 0.063,
      "step": 3080
    },
    {
      "epoch": 0.06179258488981322,
      "grad_norm": 0.16529880464076996,
      "learning_rate": 4.8972456638536714e-05,
      "loss": 0.0787,
      "step": 3090
    },
    {
      "epoch": 0.06199256089269288,
      "grad_norm": 0.12870778143405914,
      "learning_rate": 4.8969123705155384e-05,
      "loss": 0.0777,
      "step": 3100
    },
    {
      "epoch": 0.06219253689557253,
      "grad_norm": 0.13498328626155853,
      "learning_rate": 4.8965790771774054e-05,
      "loss": 0.0818,
      "step": 3110
    },
    {
      "epoch": 0.062392512898452185,
      "grad_norm": 0.10137011110782623,
      "learning_rate": 4.896245783839273e-05,
      "loss": 0.0507,
      "step": 3120
    },
    {
      "epoch": 0.06259248890133184,
      "grad_norm": 0.12998691201210022,
      "learning_rate": 4.89591249050114e-05,
      "loss": 0.0711,
      "step": 3130
    },
    {
      "epoch": 0.06279246490421149,
      "grad_norm": 0.12208924442529678,
      "learning_rate": 4.895579197163007e-05,
      "loss": 0.0574,
      "step": 3140
    },
    {
      "epoch": 0.06299244090709115,
      "grad_norm": 0.0979962944984436,
      "learning_rate": 4.8952459038248746e-05,
      "loss": 0.1191,
      "step": 3150
    },
    {
      "epoch": 0.06319241690997081,
      "grad_norm": 0.1461254507303238,
      "learning_rate": 4.894912610486742e-05,
      "loss": 0.0908,
      "step": 3160
    },
    {
      "epoch": 0.06339239291285045,
      "grad_norm": 0.14552763104438782,
      "learning_rate": 4.894579317148609e-05,
      "loss": 0.0581,
      "step": 3170
    },
    {
      "epoch": 0.06359236891573011,
      "grad_norm": 0.1418987363576889,
      "learning_rate": 4.894246023810477e-05,
      "loss": 0.1009,
      "step": 3180
    },
    {
      "epoch": 0.06379234491860977,
      "grad_norm": 0.07090200483798981,
      "learning_rate": 4.893912730472344e-05,
      "loss": 0.0671,
      "step": 3190
    },
    {
      "epoch": 0.06399232092148942,
      "grad_norm": 0.0994422510266304,
      "learning_rate": 4.893579437134211e-05,
      "loss": 0.0799,
      "step": 3200
    },
    {
      "epoch": 0.06419229692436908,
      "grad_norm": 0.1707819551229477,
      "learning_rate": 4.8932461437960784e-05,
      "loss": 0.0848,
      "step": 3210
    },
    {
      "epoch": 0.06439227292724874,
      "grad_norm": 0.15000326931476593,
      "learning_rate": 4.892912850457945e-05,
      "loss": 0.0958,
      "step": 3220
    },
    {
      "epoch": 0.06459224893012838,
      "grad_norm": 0.12776640057563782,
      "learning_rate": 4.892579557119812e-05,
      "loss": 0.1091,
      "step": 3230
    },
    {
      "epoch": 0.06479222493300804,
      "grad_norm": 0.16786536574363708,
      "learning_rate": 4.89224626378168e-05,
      "loss": 0.097,
      "step": 3240
    },
    {
      "epoch": 0.06499220093588769,
      "grad_norm": 0.09222052246332169,
      "learning_rate": 4.891912970443547e-05,
      "loss": 0.0818,
      "step": 3250
    },
    {
      "epoch": 0.06519217693876735,
      "grad_norm": 0.07536168396472931,
      "learning_rate": 4.891579677105414e-05,
      "loss": 0.0689,
      "step": 3260
    },
    {
      "epoch": 0.065392152941647,
      "grad_norm": 0.21278369426727295,
      "learning_rate": 4.8912463837672815e-05,
      "loss": 0.0925,
      "step": 3270
    },
    {
      "epoch": 0.06559212894452665,
      "grad_norm": 0.240522563457489,
      "learning_rate": 4.890913090429149e-05,
      "loss": 0.1064,
      "step": 3280
    },
    {
      "epoch": 0.06579210494740631,
      "grad_norm": 0.15550988912582397,
      "learning_rate": 4.890579797091016e-05,
      "loss": 0.093,
      "step": 3290
    },
    {
      "epoch": 0.06599208095028597,
      "grad_norm": 0.06338809430599213,
      "learning_rate": 4.890246503752883e-05,
      "loss": 0.0608,
      "step": 3300
    },
    {
      "epoch": 0.06619205695316561,
      "grad_norm": 0.09567704796791077,
      "learning_rate": 4.889913210414751e-05,
      "loss": 0.109,
      "step": 3310
    },
    {
      "epoch": 0.06639203295604527,
      "grad_norm": 0.147528737783432,
      "learning_rate": 4.8895799170766177e-05,
      "loss": 0.0725,
      "step": 3320
    },
    {
      "epoch": 0.06659200895892493,
      "grad_norm": 0.2142830789089203,
      "learning_rate": 4.8892466237384846e-05,
      "loss": 0.1233,
      "step": 3330
    },
    {
      "epoch": 0.06679198496180458,
      "grad_norm": 0.11482908576726913,
      "learning_rate": 4.888913330400352e-05,
      "loss": 0.0836,
      "step": 3340
    },
    {
      "epoch": 0.06699196096468424,
      "grad_norm": 0.16727010905742645,
      "learning_rate": 4.888580037062219e-05,
      "loss": 0.1389,
      "step": 3350
    },
    {
      "epoch": 0.0671919369675639,
      "grad_norm": 0.1033022329211235,
      "learning_rate": 4.888246743724086e-05,
      "loss": 0.1104,
      "step": 3360
    },
    {
      "epoch": 0.06739191297044354,
      "grad_norm": 0.1279410570859909,
      "learning_rate": 4.8879134503859545e-05,
      "loss": 0.1155,
      "step": 3370
    },
    {
      "epoch": 0.0675918889733232,
      "grad_norm": 0.13892865180969238,
      "learning_rate": 4.8875801570478215e-05,
      "loss": 0.1022,
      "step": 3380
    },
    {
      "epoch": 0.06779186497620286,
      "grad_norm": 0.17793726921081543,
      "learning_rate": 4.8872468637096884e-05,
      "loss": 0.0735,
      "step": 3390
    },
    {
      "epoch": 0.06799184097908251,
      "grad_norm": 0.17084622383117676,
      "learning_rate": 4.886913570371556e-05,
      "loss": 0.1013,
      "step": 3400
    },
    {
      "epoch": 0.06819181698196217,
      "grad_norm": 0.05062298849225044,
      "learning_rate": 4.886580277033423e-05,
      "loss": 0.0808,
      "step": 3410
    },
    {
      "epoch": 0.06839179298484181,
      "grad_norm": 0.10029155015945435,
      "learning_rate": 4.88624698369529e-05,
      "loss": 0.0689,
      "step": 3420
    },
    {
      "epoch": 0.06859176898772147,
      "grad_norm": 0.08445868641138077,
      "learning_rate": 4.8859136903571576e-05,
      "loss": 0.1186,
      "step": 3430
    },
    {
      "epoch": 0.06879174499060113,
      "grad_norm": 0.08441733568906784,
      "learning_rate": 4.8855803970190246e-05,
      "loss": 0.0962,
      "step": 3440
    },
    {
      "epoch": 0.06899172099348078,
      "grad_norm": 0.19556665420532227,
      "learning_rate": 4.8852471036808915e-05,
      "loss": 0.0773,
      "step": 3450
    },
    {
      "epoch": 0.06919169699636044,
      "grad_norm": 0.13978752493858337,
      "learning_rate": 4.884913810342759e-05,
      "loss": 0.1055,
      "step": 3460
    },
    {
      "epoch": 0.0693916729992401,
      "grad_norm": 0.13732756674289703,
      "learning_rate": 4.884580517004627e-05,
      "loss": 0.0714,
      "step": 3470
    },
    {
      "epoch": 0.06959164900211974,
      "grad_norm": 0.17388202250003815,
      "learning_rate": 4.884247223666494e-05,
      "loss": 0.1811,
      "step": 3480
    },
    {
      "epoch": 0.0697916250049994,
      "grad_norm": 0.1990502029657364,
      "learning_rate": 4.883913930328361e-05,
      "loss": 0.0778,
      "step": 3490
    },
    {
      "epoch": 0.06999160100787906,
      "grad_norm": 0.08947662264108658,
      "learning_rate": 4.8835806369902284e-05,
      "loss": 0.0762,
      "step": 3500
    },
    {
      "epoch": 0.0701915770107587,
      "grad_norm": 0.07255256921052933,
      "learning_rate": 4.8832473436520953e-05,
      "loss": 0.0569,
      "step": 3510
    },
    {
      "epoch": 0.07039155301363836,
      "grad_norm": 0.18045112490653992,
      "learning_rate": 4.882914050313962e-05,
      "loss": 0.1263,
      "step": 3520
    },
    {
      "epoch": 0.07059152901651802,
      "grad_norm": 0.1761743575334549,
      "learning_rate": 4.88258075697583e-05,
      "loss": 0.092,
      "step": 3530
    },
    {
      "epoch": 0.07079150501939767,
      "grad_norm": 0.06598928570747375,
      "learning_rate": 4.882247463637697e-05,
      "loss": 0.0572,
      "step": 3540
    },
    {
      "epoch": 0.07099148102227733,
      "grad_norm": 0.0995422899723053,
      "learning_rate": 4.881914170299564e-05,
      "loss": 0.0941,
      "step": 3550
    },
    {
      "epoch": 0.07119145702515699,
      "grad_norm": 0.1284051090478897,
      "learning_rate": 4.8815808769614315e-05,
      "loss": 0.1514,
      "step": 3560
    },
    {
      "epoch": 0.07139143302803663,
      "grad_norm": 0.2372371405363083,
      "learning_rate": 4.881247583623299e-05,
      "loss": 0.0919,
      "step": 3570
    },
    {
      "epoch": 0.07159140903091629,
      "grad_norm": 0.1165367066860199,
      "learning_rate": 4.880914290285166e-05,
      "loss": 0.0937,
      "step": 3580
    },
    {
      "epoch": 0.07179138503379595,
      "grad_norm": 0.13115540146827698,
      "learning_rate": 4.880580996947034e-05,
      "loss": 0.1071,
      "step": 3590
    },
    {
      "epoch": 0.0719913610366756,
      "grad_norm": 0.09153343737125397,
      "learning_rate": 4.880247703608901e-05,
      "loss": 0.0751,
      "step": 3600
    },
    {
      "epoch": 0.07219133703955526,
      "grad_norm": 0.07295072823762894,
      "learning_rate": 4.879914410270768e-05,
      "loss": 0.0832,
      "step": 3610
    },
    {
      "epoch": 0.0723913130424349,
      "grad_norm": 0.11183304339647293,
      "learning_rate": 4.879581116932635e-05,
      "loss": 0.1038,
      "step": 3620
    },
    {
      "epoch": 0.07259128904531456,
      "grad_norm": 0.14696328341960907,
      "learning_rate": 4.879247823594502e-05,
      "loss": 0.0512,
      "step": 3630
    },
    {
      "epoch": 0.07279126504819422,
      "grad_norm": 0.08952434360980988,
      "learning_rate": 4.878914530256369e-05,
      "loss": 0.0801,
      "step": 3640
    },
    {
      "epoch": 0.07299124105107387,
      "grad_norm": 0.18523170053958893,
      "learning_rate": 4.878581236918237e-05,
      "loss": 0.1238,
      "step": 3650
    },
    {
      "epoch": 0.07319121705395353,
      "grad_norm": 0.10859804600477219,
      "learning_rate": 4.878247943580104e-05,
      "loss": 0.079,
      "step": 3660
    },
    {
      "epoch": 0.07339119305683318,
      "grad_norm": 0.16905055940151215,
      "learning_rate": 4.8779146502419715e-05,
      "loss": 0.1146,
      "step": 3670
    },
    {
      "epoch": 0.07359116905971283,
      "grad_norm": 0.10487427562475204,
      "learning_rate": 4.8775813569038384e-05,
      "loss": 0.0717,
      "step": 3680
    },
    {
      "epoch": 0.07379114506259249,
      "grad_norm": 0.15561693906784058,
      "learning_rate": 4.877248063565706e-05,
      "loss": 0.0841,
      "step": 3690
    },
    {
      "epoch": 0.07399112106547215,
      "grad_norm": 0.12151559442281723,
      "learning_rate": 4.876914770227573e-05,
      "loss": 0.0705,
      "step": 3700
    },
    {
      "epoch": 0.0741910970683518,
      "grad_norm": 0.13035842776298523,
      "learning_rate": 4.87658147688944e-05,
      "loss": 0.0543,
      "step": 3710
    },
    {
      "epoch": 0.07439107307123145,
      "grad_norm": 0.16502538323402405,
      "learning_rate": 4.8762481835513076e-05,
      "loss": 0.1186,
      "step": 3720
    },
    {
      "epoch": 0.07459104907411111,
      "grad_norm": 0.08629294484853745,
      "learning_rate": 4.8759148902131746e-05,
      "loss": 0.1083,
      "step": 3730
    },
    {
      "epoch": 0.07479102507699076,
      "grad_norm": 0.1802818328142166,
      "learning_rate": 4.8755815968750416e-05,
      "loss": 0.0769,
      "step": 3740
    },
    {
      "epoch": 0.07499100107987042,
      "grad_norm": 0.11555270105600357,
      "learning_rate": 4.875248303536909e-05,
      "loss": 0.0688,
      "step": 3750
    },
    {
      "epoch": 0.07519097708275008,
      "grad_norm": 0.21650198101997375,
      "learning_rate": 4.874915010198776e-05,
      "loss": 0.0988,
      "step": 3760
    },
    {
      "epoch": 0.07539095308562972,
      "grad_norm": 0.22092102468013763,
      "learning_rate": 4.874581716860643e-05,
      "loss": 0.0761,
      "step": 3770
    },
    {
      "epoch": 0.07559092908850938,
      "grad_norm": 0.15176980197429657,
      "learning_rate": 4.874248423522511e-05,
      "loss": 0.0724,
      "step": 3780
    },
    {
      "epoch": 0.07579090509138903,
      "grad_norm": 0.053884316235780716,
      "learning_rate": 4.8739151301843784e-05,
      "loss": 0.0825,
      "step": 3790
    },
    {
      "epoch": 0.07599088109426869,
      "grad_norm": 0.15244363248348236,
      "learning_rate": 4.8735818368462454e-05,
      "loss": 0.0884,
      "step": 3800
    },
    {
      "epoch": 0.07619085709714835,
      "grad_norm": 0.17826230823993683,
      "learning_rate": 4.873248543508113e-05,
      "loss": 0.1235,
      "step": 3810
    },
    {
      "epoch": 0.07639083310002799,
      "grad_norm": 0.07348015159368515,
      "learning_rate": 4.87291525016998e-05,
      "loss": 0.0845,
      "step": 3820
    },
    {
      "epoch": 0.07659080910290765,
      "grad_norm": 0.06981410831212997,
      "learning_rate": 4.872581956831847e-05,
      "loss": 0.0927,
      "step": 3830
    },
    {
      "epoch": 0.07679078510578731,
      "grad_norm": 0.08183317631483078,
      "learning_rate": 4.8722486634937146e-05,
      "loss": 0.0702,
      "step": 3840
    },
    {
      "epoch": 0.07699076110866696,
      "grad_norm": 0.20210328698158264,
      "learning_rate": 4.8719153701555815e-05,
      "loss": 0.1146,
      "step": 3850
    },
    {
      "epoch": 0.07719073711154661,
      "grad_norm": 0.11074209213256836,
      "learning_rate": 4.8715820768174485e-05,
      "loss": 0.0596,
      "step": 3860
    },
    {
      "epoch": 0.07739071311442627,
      "grad_norm": 0.15844032168388367,
      "learning_rate": 4.871248783479316e-05,
      "loss": 0.094,
      "step": 3870
    },
    {
      "epoch": 0.07759068911730592,
      "grad_norm": 0.09555944055318832,
      "learning_rate": 4.870915490141184e-05,
      "loss": 0.0635,
      "step": 3880
    },
    {
      "epoch": 0.07779066512018558,
      "grad_norm": 0.1265825629234314,
      "learning_rate": 4.870582196803051e-05,
      "loss": 0.0842,
      "step": 3890
    },
    {
      "epoch": 0.07799064112306524,
      "grad_norm": 0.11113061755895615,
      "learning_rate": 4.870248903464918e-05,
      "loss": 0.0663,
      "step": 3900
    },
    {
      "epoch": 0.07819061712594488,
      "grad_norm": 0.15261943638324738,
      "learning_rate": 4.869915610126785e-05,
      "loss": 0.092,
      "step": 3910
    },
    {
      "epoch": 0.07839059312882454,
      "grad_norm": 0.1014963760972023,
      "learning_rate": 4.869582316788652e-05,
      "loss": 0.1315,
      "step": 3920
    },
    {
      "epoch": 0.0785905691317042,
      "grad_norm": 0.20341002941131592,
      "learning_rate": 4.869249023450519e-05,
      "loss": 0.0986,
      "step": 3930
    },
    {
      "epoch": 0.07879054513458385,
      "grad_norm": 0.16771335899829865,
      "learning_rate": 4.868915730112387e-05,
      "loss": 0.0866,
      "step": 3940
    },
    {
      "epoch": 0.0789905211374635,
      "grad_norm": 0.12485114485025406,
      "learning_rate": 4.868582436774254e-05,
      "loss": 0.1013,
      "step": 3950
    },
    {
      "epoch": 0.07919049714034315,
      "grad_norm": 0.10615672171115875,
      "learning_rate": 4.868249143436121e-05,
      "loss": 0.0641,
      "step": 3960
    },
    {
      "epoch": 0.07939047314322281,
      "grad_norm": 0.10019678622484207,
      "learning_rate": 4.8679158500979885e-05,
      "loss": 0.0999,
      "step": 3970
    },
    {
      "epoch": 0.07959044914610247,
      "grad_norm": 0.17267154157161713,
      "learning_rate": 4.867582556759856e-05,
      "loss": 0.0961,
      "step": 3980
    },
    {
      "epoch": 0.07979042514898212,
      "grad_norm": 0.10961135476827621,
      "learning_rate": 4.867249263421723e-05,
      "loss": 0.0706,
      "step": 3990
    },
    {
      "epoch": 0.07999040115186178,
      "grad_norm": 0.1327085644006729,
      "learning_rate": 4.86691597008359e-05,
      "loss": 0.0727,
      "step": 4000
    },
    {
      "epoch": 0.08019037715474144,
      "grad_norm": 0.10118837654590607,
      "learning_rate": 4.8665826767454577e-05,
      "loss": 0.0681,
      "step": 4010
    },
    {
      "epoch": 0.08039035315762108,
      "grad_norm": 0.11974183470010757,
      "learning_rate": 4.8662493834073246e-05,
      "loss": 0.0742,
      "step": 4020
    },
    {
      "epoch": 0.08059032916050074,
      "grad_norm": 0.07880057394504547,
      "learning_rate": 4.8659160900691916e-05,
      "loss": 0.0562,
      "step": 4030
    },
    {
      "epoch": 0.0807903051633804,
      "grad_norm": 0.11938952654600143,
      "learning_rate": 4.865582796731059e-05,
      "loss": 0.1009,
      "step": 4040
    },
    {
      "epoch": 0.08099028116626004,
      "grad_norm": 0.12990263104438782,
      "learning_rate": 4.865249503392926e-05,
      "loss": 0.0582,
      "step": 4050
    },
    {
      "epoch": 0.0811902571691397,
      "grad_norm": 0.15343771874904633,
      "learning_rate": 4.864916210054793e-05,
      "loss": 0.0992,
      "step": 4060
    },
    {
      "epoch": 0.08139023317201936,
      "grad_norm": 0.13571251928806305,
      "learning_rate": 4.864582916716661e-05,
      "loss": 0.1201,
      "step": 4070
    },
    {
      "epoch": 0.08159020917489901,
      "grad_norm": 0.09804018586874008,
      "learning_rate": 4.8642496233785284e-05,
      "loss": 0.0685,
      "step": 4080
    },
    {
      "epoch": 0.08179018517777867,
      "grad_norm": 0.1617693454027176,
      "learning_rate": 4.8639163300403954e-05,
      "loss": 0.0666,
      "step": 4090
    },
    {
      "epoch": 0.08199016118065833,
      "grad_norm": 0.22140002250671387,
      "learning_rate": 4.863583036702263e-05,
      "loss": 0.0925,
      "step": 4100
    },
    {
      "epoch": 0.08219013718353797,
      "grad_norm": 0.10407361388206482,
      "learning_rate": 4.86324974336413e-05,
      "loss": 0.0885,
      "step": 4110
    },
    {
      "epoch": 0.08239011318641763,
      "grad_norm": 0.1005735695362091,
      "learning_rate": 4.862916450025997e-05,
      "loss": 0.0687,
      "step": 4120
    },
    {
      "epoch": 0.08259008918929728,
      "grad_norm": 0.09856917709112167,
      "learning_rate": 4.8625831566878646e-05,
      "loss": 0.0514,
      "step": 4130
    },
    {
      "epoch": 0.08279006519217694,
      "grad_norm": 0.19114838540554047,
      "learning_rate": 4.8622498633497315e-05,
      "loss": 0.0773,
      "step": 4140
    },
    {
      "epoch": 0.0829900411950566,
      "grad_norm": 0.06530957669019699,
      "learning_rate": 4.8619165700115985e-05,
      "loss": 0.0671,
      "step": 4150
    },
    {
      "epoch": 0.08319001719793624,
      "grad_norm": 0.17529763281345367,
      "learning_rate": 4.861583276673466e-05,
      "loss": 0.0784,
      "step": 4160
    },
    {
      "epoch": 0.0833899932008159,
      "grad_norm": 0.09376658499240875,
      "learning_rate": 4.861249983335333e-05,
      "loss": 0.1167,
      "step": 4170
    },
    {
      "epoch": 0.08358996920369556,
      "grad_norm": 0.10422980040311813,
      "learning_rate": 4.860916689997201e-05,
      "loss": 0.0815,
      "step": 4180
    },
    {
      "epoch": 0.0837899452065752,
      "grad_norm": 0.1787486970424652,
      "learning_rate": 4.860583396659068e-05,
      "loss": 0.1307,
      "step": 4190
    },
    {
      "epoch": 0.08398992120945487,
      "grad_norm": 0.049716368317604065,
      "learning_rate": 4.8602501033209353e-05,
      "loss": 0.0538,
      "step": 4200
    },
    {
      "epoch": 0.08418989721233452,
      "grad_norm": 0.21336640417575836,
      "learning_rate": 4.859916809982802e-05,
      "loss": 0.0872,
      "step": 4210
    },
    {
      "epoch": 0.08438987321521417,
      "grad_norm": 0.09674768894910812,
      "learning_rate": 4.859583516644669e-05,
      "loss": 0.0631,
      "step": 4220
    },
    {
      "epoch": 0.08458984921809383,
      "grad_norm": 0.11777208000421524,
      "learning_rate": 4.859250223306537e-05,
      "loss": 0.0826,
      "step": 4230
    },
    {
      "epoch": 0.08478982522097349,
      "grad_norm": 0.1360979974269867,
      "learning_rate": 4.858916929968404e-05,
      "loss": 0.0718,
      "step": 4240
    },
    {
      "epoch": 0.08498980122385313,
      "grad_norm": 0.09045692533254623,
      "learning_rate": 4.858583636630271e-05,
      "loss": 0.06,
      "step": 4250
    },
    {
      "epoch": 0.0851897772267328,
      "grad_norm": 0.11894959211349487,
      "learning_rate": 4.8582503432921385e-05,
      "loss": 0.0953,
      "step": 4260
    },
    {
      "epoch": 0.08538975322961245,
      "grad_norm": 0.2450314164161682,
      "learning_rate": 4.8579170499540054e-05,
      "loss": 0.0914,
      "step": 4270
    },
    {
      "epoch": 0.0855897292324921,
      "grad_norm": 0.1274329125881195,
      "learning_rate": 4.8575837566158724e-05,
      "loss": 0.077,
      "step": 4280
    },
    {
      "epoch": 0.08578970523537176,
      "grad_norm": 0.12235549837350845,
      "learning_rate": 4.857250463277741e-05,
      "loss": 0.0939,
      "step": 4290
    },
    {
      "epoch": 0.0859896812382514,
      "grad_norm": 0.09995905309915543,
      "learning_rate": 4.856917169939608e-05,
      "loss": 0.089,
      "step": 4300
    },
    {
      "epoch": 0.08618965724113106,
      "grad_norm": 0.16295026242733002,
      "learning_rate": 4.8565838766014746e-05,
      "loss": 0.0955,
      "step": 4310
    },
    {
      "epoch": 0.08638963324401072,
      "grad_norm": 0.12692849338054657,
      "learning_rate": 4.856250583263342e-05,
      "loss": 0.1045,
      "step": 4320
    },
    {
      "epoch": 0.08658960924689037,
      "grad_norm": 0.147782102227211,
      "learning_rate": 4.855917289925209e-05,
      "loss": 0.0879,
      "step": 4330
    },
    {
      "epoch": 0.08678958524977003,
      "grad_norm": 0.10270849615335464,
      "learning_rate": 4.855583996587076e-05,
      "loss": 0.0798,
      "step": 4340
    },
    {
      "epoch": 0.08698956125264969,
      "grad_norm": 0.15237365663051605,
      "learning_rate": 4.855250703248944e-05,
      "loss": 0.0778,
      "step": 4350
    },
    {
      "epoch": 0.08718953725552933,
      "grad_norm": 0.09638332575559616,
      "learning_rate": 4.854917409910811e-05,
      "loss": 0.0932,
      "step": 4360
    },
    {
      "epoch": 0.08738951325840899,
      "grad_norm": 0.11447416245937347,
      "learning_rate": 4.854584116572678e-05,
      "loss": 0.0885,
      "step": 4370
    },
    {
      "epoch": 0.08758948926128865,
      "grad_norm": 0.14109455049037933,
      "learning_rate": 4.8542508232345454e-05,
      "loss": 0.1002,
      "step": 4380
    },
    {
      "epoch": 0.0877894652641683,
      "grad_norm": 0.1946873515844345,
      "learning_rate": 4.853917529896413e-05,
      "loss": 0.1078,
      "step": 4390
    },
    {
      "epoch": 0.08798944126704795,
      "grad_norm": 0.15583305060863495,
      "learning_rate": 4.85358423655828e-05,
      "loss": 0.083,
      "step": 4400
    },
    {
      "epoch": 0.08818941726992761,
      "grad_norm": 0.08476834744215012,
      "learning_rate": 4.853250943220147e-05,
      "loss": 0.0718,
      "step": 4410
    },
    {
      "epoch": 0.08838939327280726,
      "grad_norm": 0.16137850284576416,
      "learning_rate": 4.8529176498820146e-05,
      "loss": 0.1015,
      "step": 4420
    },
    {
      "epoch": 0.08858936927568692,
      "grad_norm": 0.114189013838768,
      "learning_rate": 4.8525843565438816e-05,
      "loss": 0.0988,
      "step": 4430
    },
    {
      "epoch": 0.08878934527856658,
      "grad_norm": 0.09007184952497482,
      "learning_rate": 4.8522510632057485e-05,
      "loss": 0.0519,
      "step": 4440
    },
    {
      "epoch": 0.08898932128144622,
      "grad_norm": 0.14196550846099854,
      "learning_rate": 4.851917769867616e-05,
      "loss": 0.1109,
      "step": 4450
    },
    {
      "epoch": 0.08918929728432588,
      "grad_norm": 0.10136330872774124,
      "learning_rate": 4.851584476529483e-05,
      "loss": 0.1195,
      "step": 4460
    },
    {
      "epoch": 0.08938927328720553,
      "grad_norm": 0.05602363124489784,
      "learning_rate": 4.85125118319135e-05,
      "loss": 0.0889,
      "step": 4470
    },
    {
      "epoch": 0.08958924929008519,
      "grad_norm": 0.10322939604520798,
      "learning_rate": 4.850917889853218e-05,
      "loss": 0.1087,
      "step": 4480
    },
    {
      "epoch": 0.08978922529296485,
      "grad_norm": 0.09662771970033646,
      "learning_rate": 4.8505845965150854e-05,
      "loss": 0.0753,
      "step": 4490
    },
    {
      "epoch": 0.08998920129584449,
      "grad_norm": 0.18679077923297882,
      "learning_rate": 4.850251303176952e-05,
      "loss": 0.0786,
      "step": 4500
    },
    {
      "epoch": 0.09018917729872415,
      "grad_norm": 0.11614739894866943,
      "learning_rate": 4.84991800983882e-05,
      "loss": 0.0595,
      "step": 4510
    },
    {
      "epoch": 0.09038915330160381,
      "grad_norm": 0.11281979084014893,
      "learning_rate": 4.849584716500687e-05,
      "loss": 0.0778,
      "step": 4520
    },
    {
      "epoch": 0.09058912930448346,
      "grad_norm": 0.1477886289358139,
      "learning_rate": 4.849251423162554e-05,
      "loss": 0.1108,
      "step": 4530
    },
    {
      "epoch": 0.09078910530736312,
      "grad_norm": 0.144053652882576,
      "learning_rate": 4.8489181298244215e-05,
      "loss": 0.0889,
      "step": 4540
    },
    {
      "epoch": 0.09098908131024278,
      "grad_norm": 0.22092962265014648,
      "learning_rate": 4.8485848364862885e-05,
      "loss": 0.1022,
      "step": 4550
    },
    {
      "epoch": 0.09118905731312242,
      "grad_norm": 0.19718733429908752,
      "learning_rate": 4.8482515431481554e-05,
      "loss": 0.1034,
      "step": 4560
    },
    {
      "epoch": 0.09138903331600208,
      "grad_norm": 0.07858085632324219,
      "learning_rate": 4.847918249810023e-05,
      "loss": 0.0917,
      "step": 4570
    },
    {
      "epoch": 0.09158900931888174,
      "grad_norm": 0.1348893791437149,
      "learning_rate": 4.84758495647189e-05,
      "loss": 0.0597,
      "step": 4580
    },
    {
      "epoch": 0.09178898532176138,
      "grad_norm": 0.16026441752910614,
      "learning_rate": 4.847251663133758e-05,
      "loss": 0.053,
      "step": 4590
    },
    {
      "epoch": 0.09198896132464104,
      "grad_norm": 0.09792374819517136,
      "learning_rate": 4.8469183697956247e-05,
      "loss": 0.1063,
      "step": 4600
    },
    {
      "epoch": 0.0921889373275207,
      "grad_norm": 0.1271955966949463,
      "learning_rate": 4.846585076457492e-05,
      "loss": 0.0652,
      "step": 4610
    },
    {
      "epoch": 0.09238891333040035,
      "grad_norm": 0.14755530655384064,
      "learning_rate": 4.846251783119359e-05,
      "loss": 0.0613,
      "step": 4620
    },
    {
      "epoch": 0.09258888933328001,
      "grad_norm": 0.09302597492933273,
      "learning_rate": 4.845918489781226e-05,
      "loss": 0.0945,
      "step": 4630
    },
    {
      "epoch": 0.09278886533615967,
      "grad_norm": 0.21103478968143463,
      "learning_rate": 4.845585196443094e-05,
      "loss": 0.1041,
      "step": 4640
    },
    {
      "epoch": 0.09298884133903931,
      "grad_norm": 0.11834953725337982,
      "learning_rate": 4.845251903104961e-05,
      "loss": 0.0907,
      "step": 4650
    },
    {
      "epoch": 0.09318881734191897,
      "grad_norm": 0.09388022869825363,
      "learning_rate": 4.844918609766828e-05,
      "loss": 0.0892,
      "step": 4660
    },
    {
      "epoch": 0.09338879334479862,
      "grad_norm": 0.2456604540348053,
      "learning_rate": 4.8445853164286954e-05,
      "loss": 0.1157,
      "step": 4670
    },
    {
      "epoch": 0.09358876934767828,
      "grad_norm": 0.07641449570655823,
      "learning_rate": 4.8442520230905624e-05,
      "loss": 0.0975,
      "step": 4680
    },
    {
      "epoch": 0.09378874535055794,
      "grad_norm": 0.14723707735538483,
      "learning_rate": 4.84391872975243e-05,
      "loss": 0.0882,
      "step": 4690
    },
    {
      "epoch": 0.09398872135343758,
      "grad_norm": 0.16801895201206207,
      "learning_rate": 4.8435854364142977e-05,
      "loss": 0.0813,
      "step": 4700
    },
    {
      "epoch": 0.09418869735631724,
      "grad_norm": 0.08565866947174072,
      "learning_rate": 4.8432521430761646e-05,
      "loss": 0.0703,
      "step": 4710
    },
    {
      "epoch": 0.0943886733591969,
      "grad_norm": 0.12929633259773254,
      "learning_rate": 4.8429188497380316e-05,
      "loss": 0.0642,
      "step": 4720
    },
    {
      "epoch": 0.09458864936207655,
      "grad_norm": 0.14286787807941437,
      "learning_rate": 4.842585556399899e-05,
      "loss": 0.0877,
      "step": 4730
    },
    {
      "epoch": 0.0947886253649562,
      "grad_norm": 0.06365455687046051,
      "learning_rate": 4.842252263061766e-05,
      "loss": 0.1145,
      "step": 4740
    },
    {
      "epoch": 0.09498860136783586,
      "grad_norm": 0.08304213732481003,
      "learning_rate": 4.841918969723633e-05,
      "loss": 0.0709,
      "step": 4750
    },
    {
      "epoch": 0.09518857737071551,
      "grad_norm": 0.09915786236524582,
      "learning_rate": 4.841585676385501e-05,
      "loss": 0.0545,
      "step": 4760
    },
    {
      "epoch": 0.09538855337359517,
      "grad_norm": 0.18556086719036102,
      "learning_rate": 4.841252383047368e-05,
      "loss": 0.0949,
      "step": 4770
    },
    {
      "epoch": 0.09558852937647483,
      "grad_norm": 0.24173980951309204,
      "learning_rate": 4.840919089709235e-05,
      "loss": 0.1125,
      "step": 4780
    },
    {
      "epoch": 0.09578850537935447,
      "grad_norm": 0.16513919830322266,
      "learning_rate": 4.8405857963711023e-05,
      "loss": 0.0533,
      "step": 4790
    },
    {
      "epoch": 0.09598848138223413,
      "grad_norm": 0.14564263820648193,
      "learning_rate": 4.84025250303297e-05,
      "loss": 0.1023,
      "step": 4800
    },
    {
      "epoch": 0.0961884573851138,
      "grad_norm": 0.10713417083024979,
      "learning_rate": 4.839919209694837e-05,
      "loss": 0.0654,
      "step": 4810
    },
    {
      "epoch": 0.09638843338799344,
      "grad_norm": 0.18283022940158844,
      "learning_rate": 4.839585916356704e-05,
      "loss": 0.1188,
      "step": 4820
    },
    {
      "epoch": 0.0965884093908731,
      "grad_norm": 0.16772155463695526,
      "learning_rate": 4.8392526230185715e-05,
      "loss": 0.0693,
      "step": 4830
    },
    {
      "epoch": 0.09678838539375274,
      "grad_norm": 0.131936177611351,
      "learning_rate": 4.8389193296804385e-05,
      "loss": 0.0814,
      "step": 4840
    },
    {
      "epoch": 0.0969883613966324,
      "grad_norm": 0.08594629913568497,
      "learning_rate": 4.8385860363423055e-05,
      "loss": 0.1585,
      "step": 4850
    },
    {
      "epoch": 0.09718833739951206,
      "grad_norm": 0.1585947722196579,
      "learning_rate": 4.838252743004173e-05,
      "loss": 0.0976,
      "step": 4860
    },
    {
      "epoch": 0.09738831340239171,
      "grad_norm": 0.1286875307559967,
      "learning_rate": 4.83791944966604e-05,
      "loss": 0.0717,
      "step": 4870
    },
    {
      "epoch": 0.09758828940527137,
      "grad_norm": 0.07412693649530411,
      "learning_rate": 4.837586156327907e-05,
      "loss": 0.0549,
      "step": 4880
    },
    {
      "epoch": 0.09778826540815103,
      "grad_norm": 0.1385129988193512,
      "learning_rate": 4.837252862989775e-05,
      "loss": 0.0744,
      "step": 4890
    },
    {
      "epoch": 0.09798824141103067,
      "grad_norm": 0.08573819696903229,
      "learning_rate": 4.836919569651642e-05,
      "loss": 0.0652,
      "step": 4900
    },
    {
      "epoch": 0.09818821741391033,
      "grad_norm": 0.09658201783895493,
      "learning_rate": 4.836586276313509e-05,
      "loss": 0.2262,
      "step": 4910
    },
    {
      "epoch": 0.09838819341678999,
      "grad_norm": 0.11481739580631256,
      "learning_rate": 4.836252982975377e-05,
      "loss": 0.0797,
      "step": 4920
    },
    {
      "epoch": 0.09858816941966964,
      "grad_norm": 0.11076100915670395,
      "learning_rate": 4.835919689637244e-05,
      "loss": 0.0728,
      "step": 4930
    },
    {
      "epoch": 0.0987881454225493,
      "grad_norm": 0.20247739553451538,
      "learning_rate": 4.835586396299111e-05,
      "loss": 0.0994,
      "step": 4940
    },
    {
      "epoch": 0.09898812142542895,
      "grad_norm": 0.08548648655414581,
      "learning_rate": 4.8352531029609785e-05,
      "loss": 0.0989,
      "step": 4950
    },
    {
      "epoch": 0.0991880974283086,
      "grad_norm": 0.13286283612251282,
      "learning_rate": 4.8349198096228454e-05,
      "loss": 0.0796,
      "step": 4960
    },
    {
      "epoch": 0.09938807343118826,
      "grad_norm": 0.10540670901536942,
      "learning_rate": 4.8345865162847124e-05,
      "loss": 0.0945,
      "step": 4970
    },
    {
      "epoch": 0.09958804943406792,
      "grad_norm": 0.09711484611034393,
      "learning_rate": 4.83425322294658e-05,
      "loss": 0.1045,
      "step": 4980
    },
    {
      "epoch": 0.09978802543694756,
      "grad_norm": 0.21910545229911804,
      "learning_rate": 4.833919929608447e-05,
      "loss": 0.1227,
      "step": 4990
    },
    {
      "epoch": 0.09998800143982722,
      "grad_norm": 0.11442404985427856,
      "learning_rate": 4.8335866362703146e-05,
      "loss": 0.0908,
      "step": 5000
    },
    {
      "epoch": 0.10018797744270687,
      "grad_norm": 0.09329874813556671,
      "learning_rate": 4.8332533429321816e-05,
      "loss": 0.1177,
      "step": 5010
    },
    {
      "epoch": 0.10038795344558653,
      "grad_norm": 0.15303760766983032,
      "learning_rate": 4.832920049594049e-05,
      "loss": 0.0569,
      "step": 5020
    },
    {
      "epoch": 0.10058792944846619,
      "grad_norm": 0.17854875326156616,
      "learning_rate": 4.832586756255916e-05,
      "loss": 0.1111,
      "step": 5030
    },
    {
      "epoch": 0.10078790545134583,
      "grad_norm": 0.13088703155517578,
      "learning_rate": 4.832253462917783e-05,
      "loss": 0.0655,
      "step": 5040
    },
    {
      "epoch": 0.10098788145422549,
      "grad_norm": 0.16494019329547882,
      "learning_rate": 4.831920169579651e-05,
      "loss": 0.0899,
      "step": 5050
    },
    {
      "epoch": 0.10118785745710515,
      "grad_norm": 0.1372511237859726,
      "learning_rate": 4.831586876241518e-05,
      "loss": 0.071,
      "step": 5060
    },
    {
      "epoch": 0.1013878334599848,
      "grad_norm": 0.10834056884050369,
      "learning_rate": 4.831253582903385e-05,
      "loss": 0.1465,
      "step": 5070
    },
    {
      "epoch": 0.10158780946286446,
      "grad_norm": 0.09283233433961868,
      "learning_rate": 4.8309202895652524e-05,
      "loss": 0.07,
      "step": 5080
    },
    {
      "epoch": 0.10178778546574412,
      "grad_norm": 0.12664474546909332,
      "learning_rate": 4.830586996227119e-05,
      "loss": 0.0792,
      "step": 5090
    },
    {
      "epoch": 0.10198776146862376,
      "grad_norm": 0.16987235844135284,
      "learning_rate": 4.830253702888987e-05,
      "loss": 0.0865,
      "step": 5100
    },
    {
      "epoch": 0.10218773747150342,
      "grad_norm": 0.16393551230430603,
      "learning_rate": 4.8299204095508546e-05,
      "loss": 0.063,
      "step": 5110
    },
    {
      "epoch": 0.10238771347438308,
      "grad_norm": 0.15458598732948303,
      "learning_rate": 4.8295871162127216e-05,
      "loss": 0.1163,
      "step": 5120
    },
    {
      "epoch": 0.10258768947726273,
      "grad_norm": 0.10850119590759277,
      "learning_rate": 4.8292538228745885e-05,
      "loss": 0.0719,
      "step": 5130
    },
    {
      "epoch": 0.10278766548014238,
      "grad_norm": 0.05787176638841629,
      "learning_rate": 4.828920529536456e-05,
      "loss": 0.0698,
      "step": 5140
    },
    {
      "epoch": 0.10298764148302204,
      "grad_norm": 0.13410083949565887,
      "learning_rate": 4.828587236198323e-05,
      "loss": 0.0565,
      "step": 5150
    },
    {
      "epoch": 0.10318761748590169,
      "grad_norm": 0.14456774294376373,
      "learning_rate": 4.82825394286019e-05,
      "loss": 0.0663,
      "step": 5160
    },
    {
      "epoch": 0.10338759348878135,
      "grad_norm": 0.09671600908041,
      "learning_rate": 4.827920649522058e-05,
      "loss": 0.1209,
      "step": 5170
    },
    {
      "epoch": 0.103587569491661,
      "grad_norm": 0.12188874930143356,
      "learning_rate": 4.827587356183925e-05,
      "loss": 0.0619,
      "step": 5180
    },
    {
      "epoch": 0.10378754549454065,
      "grad_norm": 0.08883021771907806,
      "learning_rate": 4.8272540628457916e-05,
      "loss": 0.0778,
      "step": 5190
    },
    {
      "epoch": 0.10398752149742031,
      "grad_norm": 0.12485634535551071,
      "learning_rate": 4.826920769507659e-05,
      "loss": 0.0614,
      "step": 5200
    },
    {
      "epoch": 0.10418749750029996,
      "grad_norm": 0.21636268496513367,
      "learning_rate": 4.826587476169527e-05,
      "loss": 0.1115,
      "step": 5210
    },
    {
      "epoch": 0.10438747350317962,
      "grad_norm": 0.19420933723449707,
      "learning_rate": 4.826254182831394e-05,
      "loss": 0.0786,
      "step": 5220
    },
    {
      "epoch": 0.10458744950605928,
      "grad_norm": 0.12799005210399628,
      "learning_rate": 4.825920889493261e-05,
      "loss": 0.1001,
      "step": 5230
    },
    {
      "epoch": 0.10478742550893892,
      "grad_norm": 0.1547611653804779,
      "learning_rate": 4.8255875961551285e-05,
      "loss": 0.085,
      "step": 5240
    },
    {
      "epoch": 0.10498740151181858,
      "grad_norm": 0.18383461236953735,
      "learning_rate": 4.8252543028169954e-05,
      "loss": 0.0548,
      "step": 5250
    },
    {
      "epoch": 0.10518737751469824,
      "grad_norm": 0.071065254509449,
      "learning_rate": 4.8249210094788624e-05,
      "loss": 0.1041,
      "step": 5260
    },
    {
      "epoch": 0.10538735351757789,
      "grad_norm": 0.10050126910209656,
      "learning_rate": 4.82458771614073e-05,
      "loss": 0.0764,
      "step": 5270
    },
    {
      "epoch": 0.10558732952045755,
      "grad_norm": 0.07125697284936905,
      "learning_rate": 4.824254422802597e-05,
      "loss": 0.0472,
      "step": 5280
    },
    {
      "epoch": 0.1057873055233372,
      "grad_norm": 0.12453078478574753,
      "learning_rate": 4.823921129464464e-05,
      "loss": 0.0716,
      "step": 5290
    },
    {
      "epoch": 0.10598728152621685,
      "grad_norm": 0.18338163197040558,
      "learning_rate": 4.8235878361263316e-05,
      "loss": 0.076,
      "step": 5300
    },
    {
      "epoch": 0.10618725752909651,
      "grad_norm": 0.12272538989782333,
      "learning_rate": 4.823254542788199e-05,
      "loss": 0.0963,
      "step": 5310
    },
    {
      "epoch": 0.10638723353197617,
      "grad_norm": 0.19205960631370544,
      "learning_rate": 4.822921249450066e-05,
      "loss": 0.1005,
      "step": 5320
    },
    {
      "epoch": 0.10658720953485581,
      "grad_norm": 0.16343311965465546,
      "learning_rate": 4.822587956111934e-05,
      "loss": 0.0775,
      "step": 5330
    },
    {
      "epoch": 0.10678718553773547,
      "grad_norm": 0.16661128401756287,
      "learning_rate": 4.822254662773801e-05,
      "loss": 0.0977,
      "step": 5340
    },
    {
      "epoch": 0.10698716154061512,
      "grad_norm": 0.11400285363197327,
      "learning_rate": 4.821921369435668e-05,
      "loss": 0.0853,
      "step": 5350
    },
    {
      "epoch": 0.10718713754349478,
      "grad_norm": 0.11684999614953995,
      "learning_rate": 4.8215880760975354e-05,
      "loss": 0.0833,
      "step": 5360
    },
    {
      "epoch": 0.10738711354637444,
      "grad_norm": 0.1534746289253235,
      "learning_rate": 4.8212547827594024e-05,
      "loss": 0.0806,
      "step": 5370
    },
    {
      "epoch": 0.10758708954925408,
      "grad_norm": 0.19167250394821167,
      "learning_rate": 4.820921489421269e-05,
      "loss": 0.0994,
      "step": 5380
    },
    {
      "epoch": 0.10778706555213374,
      "grad_norm": 0.09414055198431015,
      "learning_rate": 4.820588196083137e-05,
      "loss": 0.0539,
      "step": 5390
    },
    {
      "epoch": 0.1079870415550134,
      "grad_norm": 0.11545263975858688,
      "learning_rate": 4.820254902745004e-05,
      "loss": 0.0545,
      "step": 5400
    },
    {
      "epoch": 0.10818701755789305,
      "grad_norm": 0.175850510597229,
      "learning_rate": 4.8199216094068716e-05,
      "loss": 0.0922,
      "step": 5410
    },
    {
      "epoch": 0.10838699356077271,
      "grad_norm": 0.17645345628261566,
      "learning_rate": 4.8195883160687385e-05,
      "loss": 0.107,
      "step": 5420
    },
    {
      "epoch": 0.10858696956365237,
      "grad_norm": 0.09354866296052933,
      "learning_rate": 4.819255022730606e-05,
      "loss": 0.0796,
      "step": 5430
    },
    {
      "epoch": 0.10878694556653201,
      "grad_norm": 0.17926718294620514,
      "learning_rate": 4.818921729392473e-05,
      "loss": 0.0905,
      "step": 5440
    },
    {
      "epoch": 0.10898692156941167,
      "grad_norm": 0.19261156022548676,
      "learning_rate": 4.81858843605434e-05,
      "loss": 0.0874,
      "step": 5450
    },
    {
      "epoch": 0.10918689757229133,
      "grad_norm": 0.1403297781944275,
      "learning_rate": 4.818255142716208e-05,
      "loss": 0.1013,
      "step": 5460
    },
    {
      "epoch": 0.10938687357517098,
      "grad_norm": 0.1134827584028244,
      "learning_rate": 4.817921849378075e-05,
      "loss": 0.0773,
      "step": 5470
    },
    {
      "epoch": 0.10958684957805064,
      "grad_norm": 0.10236471146345139,
      "learning_rate": 4.817588556039942e-05,
      "loss": 0.1043,
      "step": 5480
    },
    {
      "epoch": 0.1097868255809303,
      "grad_norm": 0.17301972210407257,
      "learning_rate": 4.817255262701809e-05,
      "loss": 0.0653,
      "step": 5490
    },
    {
      "epoch": 0.10998680158380994,
      "grad_norm": 0.16644024848937988,
      "learning_rate": 4.816921969363676e-05,
      "loss": 0.0831,
      "step": 5500
    },
    {
      "epoch": 0.1101867775866896,
      "grad_norm": 0.1753850281238556,
      "learning_rate": 4.816588676025544e-05,
      "loss": 0.0919,
      "step": 5510
    },
    {
      "epoch": 0.11038675358956924,
      "grad_norm": 0.1402624398469925,
      "learning_rate": 4.8162553826874115e-05,
      "loss": 0.0912,
      "step": 5520
    },
    {
      "epoch": 0.1105867295924489,
      "grad_norm": 0.1324213445186615,
      "learning_rate": 4.8159220893492785e-05,
      "loss": 0.1203,
      "step": 5530
    },
    {
      "epoch": 0.11078670559532856,
      "grad_norm": 0.11059506237506866,
      "learning_rate": 4.8155887960111455e-05,
      "loss": 0.0668,
      "step": 5540
    },
    {
      "epoch": 0.11098668159820821,
      "grad_norm": 0.14798840880393982,
      "learning_rate": 4.815255502673013e-05,
      "loss": 0.0649,
      "step": 5550
    },
    {
      "epoch": 0.11118665760108787,
      "grad_norm": 0.19265614449977875,
      "learning_rate": 4.81492220933488e-05,
      "loss": 0.1036,
      "step": 5560
    },
    {
      "epoch": 0.11138663360396753,
      "grad_norm": 0.045135319232940674,
      "learning_rate": 4.814588915996747e-05,
      "loss": 0.056,
      "step": 5570
    },
    {
      "epoch": 0.11158660960684717,
      "grad_norm": 0.1970420479774475,
      "learning_rate": 4.814255622658615e-05,
      "loss": 0.1084,
      "step": 5580
    },
    {
      "epoch": 0.11178658560972683,
      "grad_norm": 0.1245456412434578,
      "learning_rate": 4.8139223293204816e-05,
      "loss": 0.0765,
      "step": 5590
    },
    {
      "epoch": 0.11198656161260649,
      "grad_norm": 0.19217617809772491,
      "learning_rate": 4.8135890359823486e-05,
      "loss": 0.0759,
      "step": 5600
    },
    {
      "epoch": 0.11218653761548614,
      "grad_norm": 0.12201909720897675,
      "learning_rate": 4.813255742644216e-05,
      "loss": 0.1064,
      "step": 5610
    },
    {
      "epoch": 0.1123865136183658,
      "grad_norm": 0.06168074533343315,
      "learning_rate": 4.812922449306084e-05,
      "loss": 0.081,
      "step": 5620
    },
    {
      "epoch": 0.11258648962124546,
      "grad_norm": 0.08573954552412033,
      "learning_rate": 4.812589155967951e-05,
      "loss": 0.0402,
      "step": 5630
    },
    {
      "epoch": 0.1127864656241251,
      "grad_norm": 0.06275135278701782,
      "learning_rate": 4.812255862629818e-05,
      "loss": 0.0904,
      "step": 5640
    },
    {
      "epoch": 0.11298644162700476,
      "grad_norm": 0.169375941157341,
      "learning_rate": 4.8119225692916854e-05,
      "loss": 0.102,
      "step": 5650
    },
    {
      "epoch": 0.11318641762988442,
      "grad_norm": 0.09944581985473633,
      "learning_rate": 4.8115892759535524e-05,
      "loss": 0.0722,
      "step": 5660
    },
    {
      "epoch": 0.11338639363276407,
      "grad_norm": 0.1267094910144806,
      "learning_rate": 4.8112559826154194e-05,
      "loss": 0.0829,
      "step": 5670
    },
    {
      "epoch": 0.11358636963564372,
      "grad_norm": 0.10190922766923904,
      "learning_rate": 4.810922689277287e-05,
      "loss": 0.0887,
      "step": 5680
    },
    {
      "epoch": 0.11378634563852338,
      "grad_norm": 0.18874284625053406,
      "learning_rate": 4.810589395939154e-05,
      "loss": 0.149,
      "step": 5690
    },
    {
      "epoch": 0.11398632164140303,
      "grad_norm": 0.09013506770133972,
      "learning_rate": 4.810256102601021e-05,
      "loss": 0.083,
      "step": 5700
    },
    {
      "epoch": 0.11418629764428269,
      "grad_norm": 0.1255398541688919,
      "learning_rate": 4.8099228092628886e-05,
      "loss": 0.0808,
      "step": 5710
    },
    {
      "epoch": 0.11438627364716233,
      "grad_norm": 0.12202166020870209,
      "learning_rate": 4.809589515924756e-05,
      "loss": 0.0953,
      "step": 5720
    },
    {
      "epoch": 0.114586249650042,
      "grad_norm": 0.13201402127742767,
      "learning_rate": 4.809256222586623e-05,
      "loss": 0.104,
      "step": 5730
    },
    {
      "epoch": 0.11478622565292165,
      "grad_norm": 0.11680600047111511,
      "learning_rate": 4.808922929248491e-05,
      "loss": 0.0861,
      "step": 5740
    },
    {
      "epoch": 0.1149862016558013,
      "grad_norm": 0.20934166014194489,
      "learning_rate": 4.808589635910358e-05,
      "loss": 0.1133,
      "step": 5750
    },
    {
      "epoch": 0.11518617765868096,
      "grad_norm": 0.1062658503651619,
      "learning_rate": 4.808256342572225e-05,
      "loss": 0.0562,
      "step": 5760
    },
    {
      "epoch": 0.11538615366156062,
      "grad_norm": 0.09485477209091187,
      "learning_rate": 4.8079230492340924e-05,
      "loss": 0.1054,
      "step": 5770
    },
    {
      "epoch": 0.11558612966444026,
      "grad_norm": 0.15754270553588867,
      "learning_rate": 4.807589755895959e-05,
      "loss": 0.0865,
      "step": 5780
    },
    {
      "epoch": 0.11578610566731992,
      "grad_norm": 0.07470463216304779,
      "learning_rate": 4.807256462557826e-05,
      "loss": 0.0831,
      "step": 5790
    },
    {
      "epoch": 0.11598608167019958,
      "grad_norm": 0.08209836483001709,
      "learning_rate": 4.806923169219694e-05,
      "loss": 0.0846,
      "step": 5800
    },
    {
      "epoch": 0.11618605767307923,
      "grad_norm": 0.10082528740167618,
      "learning_rate": 4.806589875881561e-05,
      "loss": 0.0359,
      "step": 5810
    },
    {
      "epoch": 0.11638603367595889,
      "grad_norm": 0.21098022162914276,
      "learning_rate": 4.8062565825434285e-05,
      "loss": 0.0896,
      "step": 5820
    },
    {
      "epoch": 0.11658600967883855,
      "grad_norm": 0.1057276725769043,
      "learning_rate": 4.8059232892052955e-05,
      "loss": 0.0446,
      "step": 5830
    },
    {
      "epoch": 0.11678598568171819,
      "grad_norm": 0.11703168600797653,
      "learning_rate": 4.805589995867163e-05,
      "loss": 0.0922,
      "step": 5840
    },
    {
      "epoch": 0.11698596168459785,
      "grad_norm": 0.0522182434797287,
      "learning_rate": 4.80525670252903e-05,
      "loss": 0.0552,
      "step": 5850
    },
    {
      "epoch": 0.11718593768747751,
      "grad_norm": 0.12678809463977814,
      "learning_rate": 4.804923409190897e-05,
      "loss": 0.1021,
      "step": 5860
    },
    {
      "epoch": 0.11738591369035715,
      "grad_norm": 0.16926735639572144,
      "learning_rate": 4.804590115852765e-05,
      "loss": 0.0995,
      "step": 5870
    },
    {
      "epoch": 0.11758588969323681,
      "grad_norm": 0.11565837264060974,
      "learning_rate": 4.8042568225146316e-05,
      "loss": 0.0713,
      "step": 5880
    },
    {
      "epoch": 0.11778586569611646,
      "grad_norm": 0.08982927352190018,
      "learning_rate": 4.8039235291764986e-05,
      "loss": 0.0846,
      "step": 5890
    },
    {
      "epoch": 0.11798584169899612,
      "grad_norm": 0.1310236006975174,
      "learning_rate": 4.803590235838366e-05,
      "loss": 0.0666,
      "step": 5900
    },
    {
      "epoch": 0.11818581770187578,
      "grad_norm": 0.07010581344366074,
      "learning_rate": 4.803256942500233e-05,
      "loss": 0.0693,
      "step": 5910
    },
    {
      "epoch": 0.11838579370475542,
      "grad_norm": 0.08839374035596848,
      "learning_rate": 4.802923649162101e-05,
      "loss": 0.0597,
      "step": 5920
    },
    {
      "epoch": 0.11858576970763508,
      "grad_norm": 0.1727067232131958,
      "learning_rate": 4.8025903558239685e-05,
      "loss": 0.0576,
      "step": 5930
    },
    {
      "epoch": 0.11878574571051474,
      "grad_norm": 0.1361655741930008,
      "learning_rate": 4.8022570624858355e-05,
      "loss": 0.097,
      "step": 5940
    },
    {
      "epoch": 0.11898572171339439,
      "grad_norm": 0.12460222840309143,
      "learning_rate": 4.8019237691477024e-05,
      "loss": 0.0843,
      "step": 5950
    },
    {
      "epoch": 0.11918569771627405,
      "grad_norm": 0.23992757499217987,
      "learning_rate": 4.80159047580957e-05,
      "loss": 0.092,
      "step": 5960
    },
    {
      "epoch": 0.1193856737191537,
      "grad_norm": 0.06863145530223846,
      "learning_rate": 4.801257182471437e-05,
      "loss": 0.0695,
      "step": 5970
    },
    {
      "epoch": 0.11958564972203335,
      "grad_norm": 0.12454859912395477,
      "learning_rate": 4.800923889133304e-05,
      "loss": 0.0734,
      "step": 5980
    },
    {
      "epoch": 0.11978562572491301,
      "grad_norm": 0.17630428075790405,
      "learning_rate": 4.8005905957951716e-05,
      "loss": 0.0798,
      "step": 5990
    },
    {
      "epoch": 0.11998560172779267,
      "grad_norm": 0.13514181971549988,
      "learning_rate": 4.8002573024570386e-05,
      "loss": 0.0592,
      "step": 6000
    },
    {
      "epoch": 0.12018557773067232,
      "grad_norm": 0.10707264393568039,
      "learning_rate": 4.7999240091189055e-05,
      "loss": 0.0777,
      "step": 6010
    },
    {
      "epoch": 0.12038555373355198,
      "grad_norm": 0.17029938101768494,
      "learning_rate": 4.799590715780773e-05,
      "loss": 0.096,
      "step": 6020
    },
    {
      "epoch": 0.12058552973643163,
      "grad_norm": 0.12469183653593063,
      "learning_rate": 4.799257422442641e-05,
      "loss": 0.0802,
      "step": 6030
    },
    {
      "epoch": 0.12078550573931128,
      "grad_norm": 0.07606510818004608,
      "learning_rate": 4.798924129104508e-05,
      "loss": 0.0699,
      "step": 6040
    },
    {
      "epoch": 0.12098548174219094,
      "grad_norm": 0.14366558194160461,
      "learning_rate": 4.798590835766375e-05,
      "loss": 0.0972,
      "step": 6050
    },
    {
      "epoch": 0.12118545774507058,
      "grad_norm": 0.20260551571846008,
      "learning_rate": 4.7982575424282424e-05,
      "loss": 0.0987,
      "step": 6060
    },
    {
      "epoch": 0.12138543374795024,
      "grad_norm": 0.05458954721689224,
      "learning_rate": 4.7979242490901093e-05,
      "loss": 0.0536,
      "step": 6070
    },
    {
      "epoch": 0.1215854097508299,
      "grad_norm": 0.2557484805583954,
      "learning_rate": 4.797590955751976e-05,
      "loss": 0.1096,
      "step": 6080
    },
    {
      "epoch": 0.12178538575370955,
      "grad_norm": 0.10549099743366241,
      "learning_rate": 4.797257662413844e-05,
      "loss": 0.1085,
      "step": 6090
    },
    {
      "epoch": 0.12198536175658921,
      "grad_norm": 0.20138877630233765,
      "learning_rate": 4.796924369075711e-05,
      "loss": 0.113,
      "step": 6100
    },
    {
      "epoch": 0.12218533775946887,
      "grad_norm": 0.21961237490177155,
      "learning_rate": 4.796591075737578e-05,
      "loss": 0.0775,
      "step": 6110
    },
    {
      "epoch": 0.12238531376234851,
      "grad_norm": 0.11378040164709091,
      "learning_rate": 4.796257782399446e-05,
      "loss": 0.0594,
      "step": 6120
    },
    {
      "epoch": 0.12258528976522817,
      "grad_norm": 0.15457534790039062,
      "learning_rate": 4.795924489061313e-05,
      "loss": 0.0778,
      "step": 6130
    },
    {
      "epoch": 0.12278526576810783,
      "grad_norm": 0.07187783718109131,
      "learning_rate": 4.79559119572318e-05,
      "loss": 0.0619,
      "step": 6140
    },
    {
      "epoch": 0.12298524177098748,
      "grad_norm": 0.170822873711586,
      "learning_rate": 4.795257902385048e-05,
      "loss": 0.0762,
      "step": 6150
    },
    {
      "epoch": 0.12318521777386714,
      "grad_norm": 0.10396549850702286,
      "learning_rate": 4.794924609046915e-05,
      "loss": 0.2799,
      "step": 6160
    },
    {
      "epoch": 0.1233851937767468,
      "grad_norm": 0.19180580973625183,
      "learning_rate": 4.794591315708782e-05,
      "loss": 0.0628,
      "step": 6170
    },
    {
      "epoch": 0.12358516977962644,
      "grad_norm": 0.16398023068904877,
      "learning_rate": 4.794258022370649e-05,
      "loss": 0.0705,
      "step": 6180
    },
    {
      "epoch": 0.1237851457825061,
      "grad_norm": 0.2096758633852005,
      "learning_rate": 4.793924729032516e-05,
      "loss": 0.107,
      "step": 6190
    },
    {
      "epoch": 0.12398512178538576,
      "grad_norm": 0.16770823299884796,
      "learning_rate": 4.793591435694383e-05,
      "loss": 0.0934,
      "step": 6200
    },
    {
      "epoch": 0.1241850977882654,
      "grad_norm": 0.12317803502082825,
      "learning_rate": 4.793258142356251e-05,
      "loss": 0.0897,
      "step": 6210
    },
    {
      "epoch": 0.12438507379114506,
      "grad_norm": 0.18443138897418976,
      "learning_rate": 4.792924849018118e-05,
      "loss": 0.092,
      "step": 6220
    },
    {
      "epoch": 0.12458504979402471,
      "grad_norm": 0.07748865336179733,
      "learning_rate": 4.7925915556799855e-05,
      "loss": 0.0815,
      "step": 6230
    },
    {
      "epoch": 0.12478502579690437,
      "grad_norm": 0.1183646097779274,
      "learning_rate": 4.7922582623418524e-05,
      "loss": 0.054,
      "step": 6240
    },
    {
      "epoch": 0.12498500179978403,
      "grad_norm": 0.16259877383708954,
      "learning_rate": 4.79192496900372e-05,
      "loss": 0.0835,
      "step": 6250
    },
    {
      "epoch": 0.1251849778026637,
      "grad_norm": 0.1303790807723999,
      "learning_rate": 4.791591675665587e-05,
      "loss": 0.0567,
      "step": 6260
    },
    {
      "epoch": 0.12538495380554335,
      "grad_norm": 0.07674747705459595,
      "learning_rate": 4.791258382327454e-05,
      "loss": 0.0769,
      "step": 6270
    },
    {
      "epoch": 0.12558492980842298,
      "grad_norm": 0.08249716460704803,
      "learning_rate": 4.7909250889893216e-05,
      "loss": 0.0774,
      "step": 6280
    },
    {
      "epoch": 0.12578490581130264,
      "grad_norm": 0.18782687187194824,
      "learning_rate": 4.7905917956511886e-05,
      "loss": 0.284,
      "step": 6290
    },
    {
      "epoch": 0.1259848818141823,
      "grad_norm": 0.08978763222694397,
      "learning_rate": 4.7902585023130556e-05,
      "loss": 0.0516,
      "step": 6300
    },
    {
      "epoch": 0.12618485781706196,
      "grad_norm": 0.15390551090240479,
      "learning_rate": 4.789925208974923e-05,
      "loss": 0.0779,
      "step": 6310
    },
    {
      "epoch": 0.12638483381994162,
      "grad_norm": 0.12623003125190735,
      "learning_rate": 4.78959191563679e-05,
      "loss": 0.1069,
      "step": 6320
    },
    {
      "epoch": 0.12658480982282125,
      "grad_norm": 0.19447918236255646,
      "learning_rate": 4.789258622298658e-05,
      "loss": 0.0852,
      "step": 6330
    },
    {
      "epoch": 0.1267847858257009,
      "grad_norm": 0.14064829051494598,
      "learning_rate": 4.7889253289605254e-05,
      "loss": 0.1111,
      "step": 6340
    },
    {
      "epoch": 0.12698476182858057,
      "grad_norm": 0.14160913228988647,
      "learning_rate": 4.7885920356223924e-05,
      "loss": 0.1362,
      "step": 6350
    },
    {
      "epoch": 0.12718473783146023,
      "grad_norm": 0.15412083268165588,
      "learning_rate": 4.7882587422842594e-05,
      "loss": 0.0974,
      "step": 6360
    },
    {
      "epoch": 0.12738471383433989,
      "grad_norm": 0.1770278960466385,
      "learning_rate": 4.787925448946127e-05,
      "loss": 0.0937,
      "step": 6370
    },
    {
      "epoch": 0.12758468983721954,
      "grad_norm": 0.22277478873729706,
      "learning_rate": 4.787592155607994e-05,
      "loss": 0.1611,
      "step": 6380
    },
    {
      "epoch": 0.12778466584009918,
      "grad_norm": 0.07008972764015198,
      "learning_rate": 4.787258862269861e-05,
      "loss": 0.0772,
      "step": 6390
    },
    {
      "epoch": 0.12798464184297884,
      "grad_norm": 0.09645133465528488,
      "learning_rate": 4.7869255689317286e-05,
      "loss": 0.0837,
      "step": 6400
    },
    {
      "epoch": 0.1281846178458585,
      "grad_norm": 0.12909512221813202,
      "learning_rate": 4.7865922755935955e-05,
      "loss": 0.0935,
      "step": 6410
    },
    {
      "epoch": 0.12838459384873815,
      "grad_norm": 0.13672561943531036,
      "learning_rate": 4.7862589822554625e-05,
      "loss": 0.0814,
      "step": 6420
    },
    {
      "epoch": 0.1285845698516178,
      "grad_norm": 0.0798104852437973,
      "learning_rate": 4.78592568891733e-05,
      "loss": 0.075,
      "step": 6430
    },
    {
      "epoch": 0.12878454585449747,
      "grad_norm": 0.18743817508220673,
      "learning_rate": 4.785592395579198e-05,
      "loss": 0.0888,
      "step": 6440
    },
    {
      "epoch": 0.1289845218573771,
      "grad_norm": 0.07043823599815369,
      "learning_rate": 4.785259102241065e-05,
      "loss": 0.0965,
      "step": 6450
    },
    {
      "epoch": 0.12918449786025676,
      "grad_norm": 0.1426430493593216,
      "learning_rate": 4.784925808902932e-05,
      "loss": 0.1048,
      "step": 6460
    },
    {
      "epoch": 0.12938447386313642,
      "grad_norm": 0.12361116707324982,
      "learning_rate": 4.784592515564799e-05,
      "loss": 0.0655,
      "step": 6470
    },
    {
      "epoch": 0.12958444986601608,
      "grad_norm": 0.08270073682069778,
      "learning_rate": 4.784259222226666e-05,
      "loss": 0.0966,
      "step": 6480
    },
    {
      "epoch": 0.12978442586889574,
      "grad_norm": 0.14016884565353394,
      "learning_rate": 4.783925928888533e-05,
      "loss": 0.0621,
      "step": 6490
    },
    {
      "epoch": 0.12998440187177537,
      "grad_norm": 0.18826353549957275,
      "learning_rate": 4.783592635550401e-05,
      "loss": 0.1043,
      "step": 6500
    },
    {
      "epoch": 0.13018437787465503,
      "grad_norm": 0.2210886925458908,
      "learning_rate": 4.783259342212268e-05,
      "loss": 0.093,
      "step": 6510
    },
    {
      "epoch": 0.1303843538775347,
      "grad_norm": 0.08427392691373825,
      "learning_rate": 4.782926048874135e-05,
      "loss": 0.0836,
      "step": 6520
    },
    {
      "epoch": 0.13058432988041435,
      "grad_norm": 0.17578954994678497,
      "learning_rate": 4.782592755536003e-05,
      "loss": 0.114,
      "step": 6530
    },
    {
      "epoch": 0.130784305883294,
      "grad_norm": 0.19717846810817719,
      "learning_rate": 4.78225946219787e-05,
      "loss": 0.1058,
      "step": 6540
    },
    {
      "epoch": 0.13098428188617367,
      "grad_norm": 0.16896657645702362,
      "learning_rate": 4.781926168859737e-05,
      "loss": 0.0877,
      "step": 6550
    },
    {
      "epoch": 0.1311842578890533,
      "grad_norm": 0.06708724051713943,
      "learning_rate": 4.781592875521605e-05,
      "loss": 0.1151,
      "step": 6560
    },
    {
      "epoch": 0.13138423389193296,
      "grad_norm": 0.26873892545700073,
      "learning_rate": 4.7812595821834716e-05,
      "loss": 0.0838,
      "step": 6570
    },
    {
      "epoch": 0.13158420989481262,
      "grad_norm": 0.09165991097688675,
      "learning_rate": 4.7809262888453386e-05,
      "loss": 0.0823,
      "step": 6580
    },
    {
      "epoch": 0.13178418589769228,
      "grad_norm": 0.13767178356647491,
      "learning_rate": 4.780592995507206e-05,
      "loss": 0.1276,
      "step": 6590
    },
    {
      "epoch": 0.13198416190057194,
      "grad_norm": 0.10400520265102386,
      "learning_rate": 4.780259702169073e-05,
      "loss": 0.0752,
      "step": 6600
    },
    {
      "epoch": 0.1321841379034516,
      "grad_norm": 0.1732424944639206,
      "learning_rate": 4.77992640883094e-05,
      "loss": 0.0956,
      "step": 6610
    },
    {
      "epoch": 0.13238411390633123,
      "grad_norm": 0.11162865161895752,
      "learning_rate": 4.779593115492808e-05,
      "loss": 0.0792,
      "step": 6620
    },
    {
      "epoch": 0.1325840899092109,
      "grad_norm": 0.08644213527441025,
      "learning_rate": 4.7792598221546755e-05,
      "loss": 0.0901,
      "step": 6630
    },
    {
      "epoch": 0.13278406591209055,
      "grad_norm": 0.14117585122585297,
      "learning_rate": 4.7789265288165424e-05,
      "loss": 0.0712,
      "step": 6640
    },
    {
      "epoch": 0.1329840419149702,
      "grad_norm": 0.09430567175149918,
      "learning_rate": 4.7785932354784094e-05,
      "loss": 0.5357,
      "step": 6650
    },
    {
      "epoch": 0.13318401791784987,
      "grad_norm": 0.17065884172916412,
      "learning_rate": 4.778259942140277e-05,
      "loss": 0.0869,
      "step": 6660
    },
    {
      "epoch": 0.1333839939207295,
      "grad_norm": 0.11639023572206497,
      "learning_rate": 4.777926648802144e-05,
      "loss": 0.1182,
      "step": 6670
    },
    {
      "epoch": 0.13358396992360916,
      "grad_norm": 0.21483348309993744,
      "learning_rate": 4.777593355464011e-05,
      "loss": 0.1063,
      "step": 6680
    },
    {
      "epoch": 0.13378394592648882,
      "grad_norm": 0.11969857662916183,
      "learning_rate": 4.7772600621258786e-05,
      "loss": 0.0665,
      "step": 6690
    },
    {
      "epoch": 0.13398392192936848,
      "grad_norm": 0.06815138459205627,
      "learning_rate": 4.7769267687877455e-05,
      "loss": 0.0591,
      "step": 6700
    },
    {
      "epoch": 0.13418389793224814,
      "grad_norm": 0.12627248466014862,
      "learning_rate": 4.7765934754496125e-05,
      "loss": 0.1203,
      "step": 6710
    },
    {
      "epoch": 0.1343838739351278,
      "grad_norm": 0.09021274000406265,
      "learning_rate": 4.77626018211148e-05,
      "loss": 0.0783,
      "step": 6720
    },
    {
      "epoch": 0.13458384993800743,
      "grad_norm": 0.10832527279853821,
      "learning_rate": 4.775926888773347e-05,
      "loss": 0.09,
      "step": 6730
    },
    {
      "epoch": 0.1347838259408871,
      "grad_norm": 0.08285150676965714,
      "learning_rate": 4.775593595435215e-05,
      "loss": 0.0554,
      "step": 6740
    },
    {
      "epoch": 0.13498380194376675,
      "grad_norm": 0.1262257993221283,
      "learning_rate": 4.7752603020970824e-05,
      "loss": 0.0639,
      "step": 6750
    },
    {
      "epoch": 0.1351837779466464,
      "grad_norm": 0.07472056895494461,
      "learning_rate": 4.7749270087589493e-05,
      "loss": 0.1357,
      "step": 6760
    },
    {
      "epoch": 0.13538375394952606,
      "grad_norm": 0.089993417263031,
      "learning_rate": 4.774593715420816e-05,
      "loss": 0.0563,
      "step": 6770
    },
    {
      "epoch": 0.13558372995240572,
      "grad_norm": 0.06925475597381592,
      "learning_rate": 4.774260422082684e-05,
      "loss": 0.0851,
      "step": 6780
    },
    {
      "epoch": 0.13578370595528536,
      "grad_norm": 0.09053490310907364,
      "learning_rate": 4.773927128744551e-05,
      "loss": 0.0721,
      "step": 6790
    },
    {
      "epoch": 0.13598368195816501,
      "grad_norm": 0.15915367007255554,
      "learning_rate": 4.773593835406418e-05,
      "loss": 0.109,
      "step": 6800
    },
    {
      "epoch": 0.13618365796104467,
      "grad_norm": 0.09926852583885193,
      "learning_rate": 4.7732605420682855e-05,
      "loss": 0.1037,
      "step": 6810
    },
    {
      "epoch": 0.13638363396392433,
      "grad_norm": 0.20442812144756317,
      "learning_rate": 4.7729272487301525e-05,
      "loss": 0.1028,
      "step": 6820
    },
    {
      "epoch": 0.136583609966804,
      "grad_norm": 0.19155673682689667,
      "learning_rate": 4.7725939553920194e-05,
      "loss": 0.076,
      "step": 6830
    },
    {
      "epoch": 0.13678358596968362,
      "grad_norm": 0.14170773327350616,
      "learning_rate": 4.772260662053887e-05,
      "loss": 0.0717,
      "step": 6840
    },
    {
      "epoch": 0.13698356197256328,
      "grad_norm": 0.11954762041568756,
      "learning_rate": 4.771927368715755e-05,
      "loss": 0.0679,
      "step": 6850
    },
    {
      "epoch": 0.13718353797544294,
      "grad_norm": 0.1291046440601349,
      "learning_rate": 4.771594075377622e-05,
      "loss": 0.0779,
      "step": 6860
    },
    {
      "epoch": 0.1373835139783226,
      "grad_norm": 0.10773006081581116,
      "learning_rate": 4.7712607820394886e-05,
      "loss": 0.0846,
      "step": 6870
    },
    {
      "epoch": 0.13758348998120226,
      "grad_norm": 0.21628999710083008,
      "learning_rate": 4.770927488701356e-05,
      "loss": 0.1107,
      "step": 6880
    },
    {
      "epoch": 0.13778346598408192,
      "grad_norm": 0.17455880343914032,
      "learning_rate": 4.770594195363223e-05,
      "loss": 0.0922,
      "step": 6890
    },
    {
      "epoch": 0.13798344198696155,
      "grad_norm": 0.10352502018213272,
      "learning_rate": 4.77026090202509e-05,
      "loss": 0.1132,
      "step": 6900
    },
    {
      "epoch": 0.1381834179898412,
      "grad_norm": 0.17506107687950134,
      "learning_rate": 4.769927608686958e-05,
      "loss": 0.1004,
      "step": 6910
    },
    {
      "epoch": 0.13838339399272087,
      "grad_norm": 0.17396235466003418,
      "learning_rate": 4.769594315348825e-05,
      "loss": 0.0891,
      "step": 6920
    },
    {
      "epoch": 0.13858336999560053,
      "grad_norm": 0.12123249471187592,
      "learning_rate": 4.769261022010692e-05,
      "loss": 0.0723,
      "step": 6930
    },
    {
      "epoch": 0.1387833459984802,
      "grad_norm": 0.08428800851106644,
      "learning_rate": 4.76892772867256e-05,
      "loss": 0.0996,
      "step": 6940
    },
    {
      "epoch": 0.13898332200135985,
      "grad_norm": 0.189899742603302,
      "learning_rate": 4.768594435334427e-05,
      "loss": 0.0797,
      "step": 6950
    },
    {
      "epoch": 0.13918329800423948,
      "grad_norm": 0.1589406281709671,
      "learning_rate": 4.768261141996294e-05,
      "loss": 0.1055,
      "step": 6960
    },
    {
      "epoch": 0.13938327400711914,
      "grad_norm": 0.1513049155473709,
      "learning_rate": 4.7679278486581616e-05,
      "loss": 0.0924,
      "step": 6970
    },
    {
      "epoch": 0.1395832500099988,
      "grad_norm": 0.10258638113737106,
      "learning_rate": 4.7675945553200286e-05,
      "loss": 0.0704,
      "step": 6980
    },
    {
      "epoch": 0.13978322601287846,
      "grad_norm": 0.06699943542480469,
      "learning_rate": 4.7672612619818956e-05,
      "loss": 0.0771,
      "step": 6990
    },
    {
      "epoch": 0.13998320201575812,
      "grad_norm": 0.10556912422180176,
      "learning_rate": 4.766927968643763e-05,
      "loss": 0.0747,
      "step": 7000
    },
    {
      "epoch": 0.14018317801863775,
      "grad_norm": 0.12748965620994568,
      "learning_rate": 4.76659467530563e-05,
      "loss": 0.0868,
      "step": 7010
    },
    {
      "epoch": 0.1403831540215174,
      "grad_norm": 0.19624657928943634,
      "learning_rate": 4.766261381967497e-05,
      "loss": 0.0859,
      "step": 7020
    },
    {
      "epoch": 0.14058313002439707,
      "grad_norm": 0.06799402087926865,
      "learning_rate": 4.765928088629365e-05,
      "loss": 0.0653,
      "step": 7030
    },
    {
      "epoch": 0.14078310602727673,
      "grad_norm": 0.13011643290519714,
      "learning_rate": 4.7655947952912324e-05,
      "loss": 0.0536,
      "step": 7040
    },
    {
      "epoch": 0.1409830820301564,
      "grad_norm": 0.05028494447469711,
      "learning_rate": 4.7652615019530994e-05,
      "loss": 0.0976,
      "step": 7050
    },
    {
      "epoch": 0.14118305803303605,
      "grad_norm": 0.14749765396118164,
      "learning_rate": 4.764928208614966e-05,
      "loss": 0.0515,
      "step": 7060
    },
    {
      "epoch": 0.14138303403591568,
      "grad_norm": 0.08602075278759003,
      "learning_rate": 4.764594915276834e-05,
      "loss": 0.0653,
      "step": 7070
    },
    {
      "epoch": 0.14158301003879534,
      "grad_norm": 0.1138535737991333,
      "learning_rate": 4.764261621938701e-05,
      "loss": 0.052,
      "step": 7080
    },
    {
      "epoch": 0.141782986041675,
      "grad_norm": 0.07786449790000916,
      "learning_rate": 4.763928328600568e-05,
      "loss": 0.1029,
      "step": 7090
    },
    {
      "epoch": 0.14198296204455466,
      "grad_norm": 0.09885934740304947,
      "learning_rate": 4.7635950352624355e-05,
      "loss": 0.0909,
      "step": 7100
    },
    {
      "epoch": 0.14218293804743432,
      "grad_norm": 0.1899832785129547,
      "learning_rate": 4.7632617419243025e-05,
      "loss": 0.0643,
      "step": 7110
    },
    {
      "epoch": 0.14238291405031397,
      "grad_norm": 0.06500506401062012,
      "learning_rate": 4.7629284485861694e-05,
      "loss": 0.0605,
      "step": 7120
    },
    {
      "epoch": 0.1425828900531936,
      "grad_norm": 0.1411897987127304,
      "learning_rate": 4.762595155248037e-05,
      "loss": 0.0933,
      "step": 7130
    },
    {
      "epoch": 0.14278286605607327,
      "grad_norm": 0.15919175744056702,
      "learning_rate": 4.762261861909905e-05,
      "loss": 0.1055,
      "step": 7140
    },
    {
      "epoch": 0.14298284205895292,
      "grad_norm": 0.07243296504020691,
      "learning_rate": 4.761928568571772e-05,
      "loss": 0.0649,
      "step": 7150
    },
    {
      "epoch": 0.14318281806183258,
      "grad_norm": 0.18552547693252563,
      "learning_rate": 4.761595275233639e-05,
      "loss": 0.0727,
      "step": 7160
    },
    {
      "epoch": 0.14338279406471224,
      "grad_norm": 0.12465286999940872,
      "learning_rate": 4.761261981895506e-05,
      "loss": 0.0854,
      "step": 7170
    },
    {
      "epoch": 0.1435827700675919,
      "grad_norm": 0.10723931342363358,
      "learning_rate": 4.760928688557373e-05,
      "loss": 0.0802,
      "step": 7180
    },
    {
      "epoch": 0.14378274607047153,
      "grad_norm": 0.0924801453948021,
      "learning_rate": 4.760595395219241e-05,
      "loss": 0.0894,
      "step": 7190
    },
    {
      "epoch": 0.1439827220733512,
      "grad_norm": 0.18922725319862366,
      "learning_rate": 4.760262101881108e-05,
      "loss": 0.0777,
      "step": 7200
    },
    {
      "epoch": 0.14418269807623085,
      "grad_norm": 0.1552170068025589,
      "learning_rate": 4.759928808542975e-05,
      "loss": 0.0792,
      "step": 7210
    },
    {
      "epoch": 0.1443826740791105,
      "grad_norm": 0.12058254331350327,
      "learning_rate": 4.7595955152048424e-05,
      "loss": 0.0769,
      "step": 7220
    },
    {
      "epoch": 0.14458265008199017,
      "grad_norm": 0.15599489212036133,
      "learning_rate": 4.7592622218667094e-05,
      "loss": 0.0539,
      "step": 7230
    },
    {
      "epoch": 0.1447826260848698,
      "grad_norm": 0.14044500887393951,
      "learning_rate": 4.7589289285285764e-05,
      "loss": 0.0591,
      "step": 7240
    },
    {
      "epoch": 0.14498260208774946,
      "grad_norm": 0.18972744047641754,
      "learning_rate": 4.758595635190444e-05,
      "loss": 0.1028,
      "step": 7250
    },
    {
      "epoch": 0.14518257809062912,
      "grad_norm": 0.1605544537305832,
      "learning_rate": 4.7582623418523116e-05,
      "loss": 0.1069,
      "step": 7260
    },
    {
      "epoch": 0.14538255409350878,
      "grad_norm": 0.12315686792135239,
      "learning_rate": 4.7579290485141786e-05,
      "loss": 0.0791,
      "step": 7270
    },
    {
      "epoch": 0.14558253009638844,
      "grad_norm": 0.18003413081169128,
      "learning_rate": 4.7575957551760456e-05,
      "loss": 0.0706,
      "step": 7280
    },
    {
      "epoch": 0.1457825060992681,
      "grad_norm": 0.13816604018211365,
      "learning_rate": 4.757262461837913e-05,
      "loss": 0.0899,
      "step": 7290
    },
    {
      "epoch": 0.14598248210214773,
      "grad_norm": 0.23954185843467712,
      "learning_rate": 4.75692916849978e-05,
      "loss": 0.0904,
      "step": 7300
    },
    {
      "epoch": 0.1461824581050274,
      "grad_norm": 0.11532197892665863,
      "learning_rate": 4.756595875161647e-05,
      "loss": 0.0737,
      "step": 7310
    },
    {
      "epoch": 0.14638243410790705,
      "grad_norm": 0.10357989370822906,
      "learning_rate": 4.756262581823515e-05,
      "loss": 0.0631,
      "step": 7320
    },
    {
      "epoch": 0.1465824101107867,
      "grad_norm": 0.11703266948461533,
      "learning_rate": 4.755929288485382e-05,
      "loss": 0.0914,
      "step": 7330
    },
    {
      "epoch": 0.14678238611366637,
      "grad_norm": 0.07315335422754288,
      "learning_rate": 4.755595995147249e-05,
      "loss": 0.0678,
      "step": 7340
    },
    {
      "epoch": 0.14698236211654603,
      "grad_norm": 0.17706234753131866,
      "learning_rate": 4.755262701809117e-05,
      "loss": 0.0796,
      "step": 7350
    },
    {
      "epoch": 0.14718233811942566,
      "grad_norm": 0.1603991687297821,
      "learning_rate": 4.754929408470984e-05,
      "loss": 0.0838,
      "step": 7360
    },
    {
      "epoch": 0.14738231412230532,
      "grad_norm": 0.08694936335086823,
      "learning_rate": 4.754596115132851e-05,
      "loss": 0.0797,
      "step": 7370
    },
    {
      "epoch": 0.14758229012518498,
      "grad_norm": 0.10761752724647522,
      "learning_rate": 4.7542628217947186e-05,
      "loss": 0.0446,
      "step": 7380
    },
    {
      "epoch": 0.14778226612806464,
      "grad_norm": 0.09657485038042068,
      "learning_rate": 4.7539295284565855e-05,
      "loss": 0.093,
      "step": 7390
    },
    {
      "epoch": 0.1479822421309443,
      "grad_norm": 0.16506478190422058,
      "learning_rate": 4.7535962351184525e-05,
      "loss": 0.085,
      "step": 7400
    },
    {
      "epoch": 0.14818221813382393,
      "grad_norm": 0.15830904245376587,
      "learning_rate": 4.75326294178032e-05,
      "loss": 0.0849,
      "step": 7410
    },
    {
      "epoch": 0.1483821941367036,
      "grad_norm": 0.22387519478797913,
      "learning_rate": 4.752929648442187e-05,
      "loss": 0.0878,
      "step": 7420
    },
    {
      "epoch": 0.14858217013958325,
      "grad_norm": 0.06991984695196152,
      "learning_rate": 4.752596355104054e-05,
      "loss": 0.0685,
      "step": 7430
    },
    {
      "epoch": 0.1487821461424629,
      "grad_norm": 0.11325492709875107,
      "learning_rate": 4.752263061765922e-05,
      "loss": 0.0599,
      "step": 7440
    },
    {
      "epoch": 0.14898212214534257,
      "grad_norm": 0.1828165203332901,
      "learning_rate": 4.7519297684277893e-05,
      "loss": 0.1213,
      "step": 7450
    },
    {
      "epoch": 0.14918209814822223,
      "grad_norm": 0.11666736751794815,
      "learning_rate": 4.751596475089656e-05,
      "loss": 0.0775,
      "step": 7460
    },
    {
      "epoch": 0.14938207415110186,
      "grad_norm": 0.0864063948392868,
      "learning_rate": 4.751263181751523e-05,
      "loss": 0.0903,
      "step": 7470
    },
    {
      "epoch": 0.14958205015398152,
      "grad_norm": 0.1415911465883255,
      "learning_rate": 4.750929888413391e-05,
      "loss": 0.0672,
      "step": 7480
    },
    {
      "epoch": 0.14978202615686118,
      "grad_norm": 0.13675297796726227,
      "learning_rate": 4.750596595075258e-05,
      "loss": 0.0754,
      "step": 7490
    },
    {
      "epoch": 0.14998200215974083,
      "grad_norm": 0.06086377799510956,
      "learning_rate": 4.750263301737125e-05,
      "loss": 0.0634,
      "step": 7500
    },
    {
      "epoch": 0.1501819781626205,
      "grad_norm": 0.08775434643030167,
      "learning_rate": 4.7499300083989925e-05,
      "loss": 0.0993,
      "step": 7510
    },
    {
      "epoch": 0.15038195416550015,
      "grad_norm": 0.12409933656454086,
      "learning_rate": 4.7495967150608594e-05,
      "loss": 0.0642,
      "step": 7520
    },
    {
      "epoch": 0.15058193016837979,
      "grad_norm": 0.06284251809120178,
      "learning_rate": 4.7492634217227264e-05,
      "loss": 0.0966,
      "step": 7530
    },
    {
      "epoch": 0.15078190617125944,
      "grad_norm": 0.17093674838542938,
      "learning_rate": 4.748930128384594e-05,
      "loss": 0.0652,
      "step": 7540
    },
    {
      "epoch": 0.1509818821741391,
      "grad_norm": 0.1164979487657547,
      "learning_rate": 4.748596835046462e-05,
      "loss": 0.1155,
      "step": 7550
    },
    {
      "epoch": 0.15118185817701876,
      "grad_norm": 0.0975644513964653,
      "learning_rate": 4.7482635417083286e-05,
      "loss": 0.0853,
      "step": 7560
    },
    {
      "epoch": 0.15138183417989842,
      "grad_norm": 0.10459467023611069,
      "learning_rate": 4.747930248370196e-05,
      "loss": 0.0847,
      "step": 7570
    },
    {
      "epoch": 0.15158181018277805,
      "grad_norm": 0.16510415077209473,
      "learning_rate": 4.747596955032063e-05,
      "loss": 0.1023,
      "step": 7580
    },
    {
      "epoch": 0.1517817861856577,
      "grad_norm": 0.1210542693734169,
      "learning_rate": 4.74726366169393e-05,
      "loss": 0.0634,
      "step": 7590
    },
    {
      "epoch": 0.15198176218853737,
      "grad_norm": 0.16944946348667145,
      "learning_rate": 4.746930368355798e-05,
      "loss": 0.0853,
      "step": 7600
    },
    {
      "epoch": 0.15218173819141703,
      "grad_norm": 0.12540389597415924,
      "learning_rate": 4.746597075017665e-05,
      "loss": 0.0843,
      "step": 7610
    },
    {
      "epoch": 0.1523817141942967,
      "grad_norm": 0.10539598762989044,
      "learning_rate": 4.746263781679532e-05,
      "loss": 0.1072,
      "step": 7620
    },
    {
      "epoch": 0.15258169019717635,
      "grad_norm": 0.24929498136043549,
      "learning_rate": 4.7459304883413994e-05,
      "loss": 0.1131,
      "step": 7630
    },
    {
      "epoch": 0.15278166620005598,
      "grad_norm": 0.1872515231370926,
      "learning_rate": 4.7455971950032664e-05,
      "loss": 0.0587,
      "step": 7640
    },
    {
      "epoch": 0.15298164220293564,
      "grad_norm": 0.11219426244497299,
      "learning_rate": 4.745263901665134e-05,
      "loss": 0.0924,
      "step": 7650
    },
    {
      "epoch": 0.1531816182058153,
      "grad_norm": 0.172134131193161,
      "learning_rate": 4.744930608327001e-05,
      "loss": 0.0818,
      "step": 7660
    },
    {
      "epoch": 0.15338159420869496,
      "grad_norm": 0.12164323031902313,
      "learning_rate": 4.7445973149888686e-05,
      "loss": 0.087,
      "step": 7670
    },
    {
      "epoch": 0.15358157021157462,
      "grad_norm": 0.13794472813606262,
      "learning_rate": 4.7442640216507356e-05,
      "loss": 0.0686,
      "step": 7680
    },
    {
      "epoch": 0.15378154621445428,
      "grad_norm": 0.19641900062561035,
      "learning_rate": 4.7439307283126025e-05,
      "loss": 0.0699,
      "step": 7690
    },
    {
      "epoch": 0.1539815222173339,
      "grad_norm": 0.19027216732501984,
      "learning_rate": 4.74359743497447e-05,
      "loss": 0.1215,
      "step": 7700
    },
    {
      "epoch": 0.15418149822021357,
      "grad_norm": 0.23067252337932587,
      "learning_rate": 4.743264141636337e-05,
      "loss": 0.0683,
      "step": 7710
    },
    {
      "epoch": 0.15438147422309323,
      "grad_norm": 0.07501481473445892,
      "learning_rate": 4.742930848298204e-05,
      "loss": 0.1304,
      "step": 7720
    },
    {
      "epoch": 0.1545814502259729,
      "grad_norm": 0.046511441469192505,
      "learning_rate": 4.742597554960072e-05,
      "loss": 0.0909,
      "step": 7730
    },
    {
      "epoch": 0.15478142622885255,
      "grad_norm": 0.13560089468955994,
      "learning_rate": 4.742264261621939e-05,
      "loss": 0.0729,
      "step": 7740
    },
    {
      "epoch": 0.15498140223173218,
      "grad_norm": 0.174320787191391,
      "learning_rate": 4.7419309682838056e-05,
      "loss": 0.0936,
      "step": 7750
    },
    {
      "epoch": 0.15518137823461184,
      "grad_norm": 0.23421745002269745,
      "learning_rate": 4.741597674945674e-05,
      "loss": 0.1567,
      "step": 7760
    },
    {
      "epoch": 0.1553813542374915,
      "grad_norm": 0.10427789390087128,
      "learning_rate": 4.741264381607541e-05,
      "loss": 0.1537,
      "step": 7770
    },
    {
      "epoch": 0.15558133024037116,
      "grad_norm": 0.09756677597761154,
      "learning_rate": 4.740931088269408e-05,
      "loss": 0.1321,
      "step": 7780
    },
    {
      "epoch": 0.15578130624325082,
      "grad_norm": 0.13960212469100952,
      "learning_rate": 4.7405977949312755e-05,
      "loss": 0.0467,
      "step": 7790
    },
    {
      "epoch": 0.15598128224613048,
      "grad_norm": 0.14399489760398865,
      "learning_rate": 4.7402645015931425e-05,
      "loss": 0.0614,
      "step": 7800
    },
    {
      "epoch": 0.1561812582490101,
      "grad_norm": 0.17759321630001068,
      "learning_rate": 4.7399312082550094e-05,
      "loss": 0.0633,
      "step": 7810
    },
    {
      "epoch": 0.15638123425188977,
      "grad_norm": 0.17000311613082886,
      "learning_rate": 4.739597914916877e-05,
      "loss": 0.1026,
      "step": 7820
    },
    {
      "epoch": 0.15658121025476943,
      "grad_norm": 0.20735344290733337,
      "learning_rate": 4.739264621578744e-05,
      "loss": 0.0522,
      "step": 7830
    },
    {
      "epoch": 0.15678118625764909,
      "grad_norm": 0.15533429384231567,
      "learning_rate": 4.738931328240611e-05,
      "loss": 0.0781,
      "step": 7840
    },
    {
      "epoch": 0.15698116226052874,
      "grad_norm": 0.08580967038869858,
      "learning_rate": 4.7385980349024786e-05,
      "loss": 0.0734,
      "step": 7850
    },
    {
      "epoch": 0.1571811382634084,
      "grad_norm": 0.10712169110774994,
      "learning_rate": 4.738264741564346e-05,
      "loss": 0.0533,
      "step": 7860
    },
    {
      "epoch": 0.15738111426628804,
      "grad_norm": 0.1137625053524971,
      "learning_rate": 4.737931448226213e-05,
      "loss": 0.1221,
      "step": 7870
    },
    {
      "epoch": 0.1575810902691677,
      "grad_norm": 0.10869966447353363,
      "learning_rate": 4.73759815488808e-05,
      "loss": 0.0629,
      "step": 7880
    },
    {
      "epoch": 0.15778106627204735,
      "grad_norm": 0.09241010993719101,
      "learning_rate": 4.737264861549948e-05,
      "loss": 0.0604,
      "step": 7890
    },
    {
      "epoch": 0.157981042274927,
      "grad_norm": 0.0956166535615921,
      "learning_rate": 4.736931568211815e-05,
      "loss": 0.0716,
      "step": 7900
    },
    {
      "epoch": 0.15818101827780667,
      "grad_norm": 0.19680911302566528,
      "learning_rate": 4.736598274873682e-05,
      "loss": 0.1036,
      "step": 7910
    },
    {
      "epoch": 0.1583809942806863,
      "grad_norm": 0.08032389730215073,
      "learning_rate": 4.7362649815355494e-05,
      "loss": 0.0881,
      "step": 7920
    },
    {
      "epoch": 0.15858097028356596,
      "grad_norm": 0.07359424233436584,
      "learning_rate": 4.7359316881974164e-05,
      "loss": 0.0981,
      "step": 7930
    },
    {
      "epoch": 0.15878094628644562,
      "grad_norm": 0.07016943395137787,
      "learning_rate": 4.735598394859283e-05,
      "loss": 0.0648,
      "step": 7940
    },
    {
      "epoch": 0.15898092228932528,
      "grad_norm": 0.08942824602127075,
      "learning_rate": 4.735265101521151e-05,
      "loss": 0.0924,
      "step": 7950
    },
    {
      "epoch": 0.15918089829220494,
      "grad_norm": 0.19463777542114258,
      "learning_rate": 4.7349318081830186e-05,
      "loss": 0.1,
      "step": 7960
    },
    {
      "epoch": 0.1593808742950846,
      "grad_norm": 0.12722338736057281,
      "learning_rate": 4.7345985148448856e-05,
      "loss": 0.0794,
      "step": 7970
    },
    {
      "epoch": 0.15958085029796423,
      "grad_norm": 0.08069426566362381,
      "learning_rate": 4.734265221506753e-05,
      "loss": 0.0562,
      "step": 7980
    },
    {
      "epoch": 0.1597808263008439,
      "grad_norm": 0.1956893354654312,
      "learning_rate": 4.73393192816862e-05,
      "loss": 0.1109,
      "step": 7990
    },
    {
      "epoch": 0.15998080230372355,
      "grad_norm": 0.1263783723115921,
      "learning_rate": 4.733598634830487e-05,
      "loss": 0.0681,
      "step": 8000
    },
    {
      "epoch": 0.1601807783066032,
      "grad_norm": 0.09620934724807739,
      "learning_rate": 4.733265341492355e-05,
      "loss": 0.0641,
      "step": 8010
    },
    {
      "epoch": 0.16038075430948287,
      "grad_norm": 0.1727786362171173,
      "learning_rate": 4.732932048154222e-05,
      "loss": 0.1144,
      "step": 8020
    },
    {
      "epoch": 0.16058073031236253,
      "grad_norm": 0.21984179317951202,
      "learning_rate": 4.732598754816089e-05,
      "loss": 0.0484,
      "step": 8030
    },
    {
      "epoch": 0.16078070631524216,
      "grad_norm": 0.12985186278820038,
      "learning_rate": 4.732265461477956e-05,
      "loss": 0.0462,
      "step": 8040
    },
    {
      "epoch": 0.16098068231812182,
      "grad_norm": 0.08566584438085556,
      "learning_rate": 4.731932168139823e-05,
      "loss": 0.0547,
      "step": 8050
    },
    {
      "epoch": 0.16118065832100148,
      "grad_norm": 0.09947578608989716,
      "learning_rate": 4.731598874801691e-05,
      "loss": 0.0807,
      "step": 8060
    },
    {
      "epoch": 0.16138063432388114,
      "grad_norm": 0.22700126469135284,
      "learning_rate": 4.731265581463558e-05,
      "loss": 0.0892,
      "step": 8070
    },
    {
      "epoch": 0.1615806103267608,
      "grad_norm": 0.19337153434753418,
      "learning_rate": 4.7309322881254255e-05,
      "loss": 0.0963,
      "step": 8080
    },
    {
      "epoch": 0.16178058632964043,
      "grad_norm": 0.08551271259784698,
      "learning_rate": 4.7305989947872925e-05,
      "loss": 0.0768,
      "step": 8090
    },
    {
      "epoch": 0.1619805623325201,
      "grad_norm": 0.10094145685434341,
      "learning_rate": 4.7302657014491595e-05,
      "loss": 0.1225,
      "step": 8100
    },
    {
      "epoch": 0.16218053833539975,
      "grad_norm": 0.16826094686985016,
      "learning_rate": 4.729932408111027e-05,
      "loss": 0.1003,
      "step": 8110
    },
    {
      "epoch": 0.1623805143382794,
      "grad_norm": 0.11635394394397736,
      "learning_rate": 4.729599114772894e-05,
      "loss": 0.0802,
      "step": 8120
    },
    {
      "epoch": 0.16258049034115907,
      "grad_norm": 0.10849089920520782,
      "learning_rate": 4.729265821434761e-05,
      "loss": 0.0873,
      "step": 8130
    },
    {
      "epoch": 0.16278046634403873,
      "grad_norm": 0.09848854690790176,
      "learning_rate": 4.728932528096629e-05,
      "loss": 0.0587,
      "step": 8140
    },
    {
      "epoch": 0.16298044234691836,
      "grad_norm": 0.12983374297618866,
      "learning_rate": 4.7285992347584956e-05,
      "loss": 0.077,
      "step": 8150
    },
    {
      "epoch": 0.16318041834979802,
      "grad_norm": 0.16848024725914001,
      "learning_rate": 4.728265941420363e-05,
      "loss": 0.12,
      "step": 8160
    },
    {
      "epoch": 0.16338039435267768,
      "grad_norm": 0.16019946336746216,
      "learning_rate": 4.727932648082231e-05,
      "loss": 0.1059,
      "step": 8170
    },
    {
      "epoch": 0.16358037035555734,
      "grad_norm": 0.05013589560985565,
      "learning_rate": 4.727599354744098e-05,
      "loss": 0.0658,
      "step": 8180
    },
    {
      "epoch": 0.163780346358437,
      "grad_norm": 0.1933797150850296,
      "learning_rate": 4.727266061405965e-05,
      "loss": 0.0863,
      "step": 8190
    },
    {
      "epoch": 0.16398032236131665,
      "grad_norm": 0.1425338238477707,
      "learning_rate": 4.7269327680678325e-05,
      "loss": 0.2395,
      "step": 8200
    },
    {
      "epoch": 0.1641802983641963,
      "grad_norm": 0.117530956864357,
      "learning_rate": 4.7265994747296994e-05,
      "loss": 0.0787,
      "step": 8210
    },
    {
      "epoch": 0.16438027436707595,
      "grad_norm": 0.12298890948295593,
      "learning_rate": 4.7262661813915664e-05,
      "loss": 0.0908,
      "step": 8220
    },
    {
      "epoch": 0.1645802503699556,
      "grad_norm": 0.16499942541122437,
      "learning_rate": 4.725932888053434e-05,
      "loss": 0.0501,
      "step": 8230
    },
    {
      "epoch": 0.16478022637283526,
      "grad_norm": 0.12978875637054443,
      "learning_rate": 4.725599594715301e-05,
      "loss": 0.1411,
      "step": 8240
    },
    {
      "epoch": 0.16498020237571492,
      "grad_norm": 0.05968787893652916,
      "learning_rate": 4.725266301377168e-05,
      "loss": 0.062,
      "step": 8250
    },
    {
      "epoch": 0.16518017837859456,
      "grad_norm": 0.09375683218240738,
      "learning_rate": 4.7249330080390356e-05,
      "loss": 0.1303,
      "step": 8260
    },
    {
      "epoch": 0.16538015438147421,
      "grad_norm": 0.11799801886081696,
      "learning_rate": 4.724599714700903e-05,
      "loss": 0.0977,
      "step": 8270
    },
    {
      "epoch": 0.16558013038435387,
      "grad_norm": 0.18077915906906128,
      "learning_rate": 4.72426642136277e-05,
      "loss": 0.0791,
      "step": 8280
    },
    {
      "epoch": 0.16578010638723353,
      "grad_norm": 0.11313305795192719,
      "learning_rate": 4.723933128024637e-05,
      "loss": 0.0925,
      "step": 8290
    },
    {
      "epoch": 0.1659800823901132,
      "grad_norm": 0.12271776795387268,
      "learning_rate": 4.723599834686505e-05,
      "loss": 0.0799,
      "step": 8300
    },
    {
      "epoch": 0.16618005839299285,
      "grad_norm": 0.1013801321387291,
      "learning_rate": 4.723266541348372e-05,
      "loss": 0.0948,
      "step": 8310
    },
    {
      "epoch": 0.16638003439587248,
      "grad_norm": 0.10669925063848495,
      "learning_rate": 4.722933248010239e-05,
      "loss": 0.0513,
      "step": 8320
    },
    {
      "epoch": 0.16658001039875214,
      "grad_norm": 0.15256322920322418,
      "learning_rate": 4.7225999546721064e-05,
      "loss": 0.0643,
      "step": 8330
    },
    {
      "epoch": 0.1667799864016318,
      "grad_norm": 0.11442533880472183,
      "learning_rate": 4.722266661333973e-05,
      "loss": 0.0812,
      "step": 8340
    },
    {
      "epoch": 0.16697996240451146,
      "grad_norm": 0.11624165624380112,
      "learning_rate": 4.72193336799584e-05,
      "loss": 0.0815,
      "step": 8350
    },
    {
      "epoch": 0.16717993840739112,
      "grad_norm": 0.16898104548454285,
      "learning_rate": 4.721600074657708e-05,
      "loss": 0.0661,
      "step": 8360
    },
    {
      "epoch": 0.16737991441027078,
      "grad_norm": 0.12855452299118042,
      "learning_rate": 4.7212667813195756e-05,
      "loss": 0.1356,
      "step": 8370
    },
    {
      "epoch": 0.1675798904131504,
      "grad_norm": 0.15451855957508087,
      "learning_rate": 4.7209334879814425e-05,
      "loss": 0.0772,
      "step": 8380
    },
    {
      "epoch": 0.16777986641603007,
      "grad_norm": 0.10805560648441315,
      "learning_rate": 4.72060019464331e-05,
      "loss": 0.0973,
      "step": 8390
    },
    {
      "epoch": 0.16797984241890973,
      "grad_norm": 0.06293141841888428,
      "learning_rate": 4.720266901305177e-05,
      "loss": 0.16,
      "step": 8400
    },
    {
      "epoch": 0.1681798184217894,
      "grad_norm": 0.17091946303844452,
      "learning_rate": 4.719933607967044e-05,
      "loss": 0.071,
      "step": 8410
    },
    {
      "epoch": 0.16837979442466905,
      "grad_norm": 0.18648207187652588,
      "learning_rate": 4.719600314628912e-05,
      "loss": 0.107,
      "step": 8420
    },
    {
      "epoch": 0.16857977042754868,
      "grad_norm": 0.15113766491413116,
      "learning_rate": 4.719267021290779e-05,
      "loss": 0.1095,
      "step": 8430
    },
    {
      "epoch": 0.16877974643042834,
      "grad_norm": 0.1418159306049347,
      "learning_rate": 4.7189337279526456e-05,
      "loss": 0.1038,
      "step": 8440
    },
    {
      "epoch": 0.168979722433308,
      "grad_norm": 0.07174120098352432,
      "learning_rate": 4.718600434614513e-05,
      "loss": 0.0986,
      "step": 8450
    },
    {
      "epoch": 0.16917969843618766,
      "grad_norm": 0.1743304282426834,
      "learning_rate": 4.71826714127638e-05,
      "loss": 0.1062,
      "step": 8460
    },
    {
      "epoch": 0.16937967443906732,
      "grad_norm": 0.08074738085269928,
      "learning_rate": 4.717933847938248e-05,
      "loss": 0.1215,
      "step": 8470
    },
    {
      "epoch": 0.16957965044194698,
      "grad_norm": 0.2058774083852768,
      "learning_rate": 4.717600554600115e-05,
      "loss": 0.0802,
      "step": 8480
    },
    {
      "epoch": 0.1697796264448266,
      "grad_norm": 0.1676207035779953,
      "learning_rate": 4.7172672612619825e-05,
      "loss": 0.1236,
      "step": 8490
    },
    {
      "epoch": 0.16997960244770627,
      "grad_norm": 0.12379276007413864,
      "learning_rate": 4.7169339679238494e-05,
      "loss": 0.1013,
      "step": 8500
    },
    {
      "epoch": 0.17017957845058593,
      "grad_norm": 0.17141374945640564,
      "learning_rate": 4.7166006745857164e-05,
      "loss": 0.1084,
      "step": 8510
    },
    {
      "epoch": 0.1703795544534656,
      "grad_norm": 0.15627849102020264,
      "learning_rate": 4.716267381247584e-05,
      "loss": 0.0862,
      "step": 8520
    },
    {
      "epoch": 0.17057953045634525,
      "grad_norm": 0.14614194631576538,
      "learning_rate": 4.715934087909451e-05,
      "loss": 0.0797,
      "step": 8530
    },
    {
      "epoch": 0.1707795064592249,
      "grad_norm": 0.15019181370735168,
      "learning_rate": 4.715600794571318e-05,
      "loss": 0.0859,
      "step": 8540
    },
    {
      "epoch": 0.17097948246210454,
      "grad_norm": 0.1838536560535431,
      "learning_rate": 4.7152675012331856e-05,
      "loss": 0.1038,
      "step": 8550
    },
    {
      "epoch": 0.1711794584649842,
      "grad_norm": 0.17062939703464508,
      "learning_rate": 4.7149342078950526e-05,
      "loss": 0.0679,
      "step": 8560
    },
    {
      "epoch": 0.17137943446786386,
      "grad_norm": 0.2555902898311615,
      "learning_rate": 4.71460091455692e-05,
      "loss": 0.1204,
      "step": 8570
    },
    {
      "epoch": 0.17157941047074352,
      "grad_norm": 0.04939716309309006,
      "learning_rate": 4.714267621218788e-05,
      "loss": 0.071,
      "step": 8580
    },
    {
      "epoch": 0.17177938647362317,
      "grad_norm": 0.13829782605171204,
      "learning_rate": 4.713934327880655e-05,
      "loss": 0.1181,
      "step": 8590
    },
    {
      "epoch": 0.1719793624765028,
      "grad_norm": 0.1239456906914711,
      "learning_rate": 4.713601034542522e-05,
      "loss": 0.0737,
      "step": 8600
    },
    {
      "epoch": 0.17217933847938247,
      "grad_norm": 0.08453356474637985,
      "learning_rate": 4.7132677412043894e-05,
      "loss": 0.0465,
      "step": 8610
    },
    {
      "epoch": 0.17237931448226212,
      "grad_norm": 0.15788602828979492,
      "learning_rate": 4.7129344478662564e-05,
      "loss": 0.0849,
      "step": 8620
    },
    {
      "epoch": 0.17257929048514178,
      "grad_norm": 0.1097681000828743,
      "learning_rate": 4.712601154528123e-05,
      "loss": 0.0453,
      "step": 8630
    },
    {
      "epoch": 0.17277926648802144,
      "grad_norm": 0.09439781308174133,
      "learning_rate": 4.712267861189991e-05,
      "loss": 0.0902,
      "step": 8640
    },
    {
      "epoch": 0.1729792424909011,
      "grad_norm": 0.12895074486732483,
      "learning_rate": 4.711934567851858e-05,
      "loss": 0.0615,
      "step": 8650
    },
    {
      "epoch": 0.17317921849378073,
      "grad_norm": 0.11777327209711075,
      "learning_rate": 4.711601274513725e-05,
      "loss": 0.0587,
      "step": 8660
    },
    {
      "epoch": 0.1733791944966604,
      "grad_norm": 0.1346411257982254,
      "learning_rate": 4.7112679811755925e-05,
      "loss": 0.1135,
      "step": 8670
    },
    {
      "epoch": 0.17357917049954005,
      "grad_norm": 0.10149995237588882,
      "learning_rate": 4.71093468783746e-05,
      "loss": 0.1074,
      "step": 8680
    },
    {
      "epoch": 0.1737791465024197,
      "grad_norm": 0.1759578436613083,
      "learning_rate": 4.710601394499327e-05,
      "loss": 0.0658,
      "step": 8690
    },
    {
      "epoch": 0.17397912250529937,
      "grad_norm": 0.1893422156572342,
      "learning_rate": 4.710268101161194e-05,
      "loss": 0.0645,
      "step": 8700
    },
    {
      "epoch": 0.17417909850817903,
      "grad_norm": 0.11231102794408798,
      "learning_rate": 4.709934807823062e-05,
      "loss": 0.0573,
      "step": 8710
    },
    {
      "epoch": 0.17437907451105866,
      "grad_norm": 0.14045073091983795,
      "learning_rate": 4.709601514484929e-05,
      "loss": 0.1352,
      "step": 8720
    },
    {
      "epoch": 0.17457905051393832,
      "grad_norm": 0.11359598487615585,
      "learning_rate": 4.7092682211467957e-05,
      "loss": 0.0723,
      "step": 8730
    },
    {
      "epoch": 0.17477902651681798,
      "grad_norm": 0.21317614614963531,
      "learning_rate": 4.708934927808663e-05,
      "loss": 0.0935,
      "step": 8740
    },
    {
      "epoch": 0.17497900251969764,
      "grad_norm": 0.1336679607629776,
      "learning_rate": 4.70860163447053e-05,
      "loss": 0.0747,
      "step": 8750
    },
    {
      "epoch": 0.1751789785225773,
      "grad_norm": 0.17782163619995117,
      "learning_rate": 4.708268341132397e-05,
      "loss": 0.0934,
      "step": 8760
    },
    {
      "epoch": 0.17537895452545693,
      "grad_norm": 0.05926087126135826,
      "learning_rate": 4.707935047794265e-05,
      "loss": 0.0707,
      "step": 8770
    },
    {
      "epoch": 0.1755789305283366,
      "grad_norm": 0.06633433699607849,
      "learning_rate": 4.7076017544561325e-05,
      "loss": 0.0723,
      "step": 8780
    },
    {
      "epoch": 0.17577890653121625,
      "grad_norm": 0.11043962836265564,
      "learning_rate": 4.7072684611179995e-05,
      "loss": 0.0628,
      "step": 8790
    },
    {
      "epoch": 0.1759788825340959,
      "grad_norm": 0.20240676403045654,
      "learning_rate": 4.7069351677798664e-05,
      "loss": 0.1098,
      "step": 8800
    },
    {
      "epoch": 0.17617885853697557,
      "grad_norm": 0.0689617320895195,
      "learning_rate": 4.706601874441734e-05,
      "loss": 0.0471,
      "step": 8810
    },
    {
      "epoch": 0.17637883453985523,
      "grad_norm": 0.05522722378373146,
      "learning_rate": 4.706268581103601e-05,
      "loss": 0.0683,
      "step": 8820
    },
    {
      "epoch": 0.17657881054273486,
      "grad_norm": 0.19832292199134827,
      "learning_rate": 4.705935287765468e-05,
      "loss": 0.0865,
      "step": 8830
    },
    {
      "epoch": 0.17677878654561452,
      "grad_norm": 0.1201603040099144,
      "learning_rate": 4.7056019944273356e-05,
      "loss": 0.0732,
      "step": 8840
    },
    {
      "epoch": 0.17697876254849418,
      "grad_norm": 0.17944099009037018,
      "learning_rate": 4.7052687010892026e-05,
      "loss": 0.0902,
      "step": 8850
    },
    {
      "epoch": 0.17717873855137384,
      "grad_norm": 0.14019812643527985,
      "learning_rate": 4.70493540775107e-05,
      "loss": 0.0628,
      "step": 8860
    },
    {
      "epoch": 0.1773787145542535,
      "grad_norm": 0.16961269080638885,
      "learning_rate": 4.704602114412937e-05,
      "loss": 0.0955,
      "step": 8870
    },
    {
      "epoch": 0.17757869055713316,
      "grad_norm": 0.12610608339309692,
      "learning_rate": 4.704268821074805e-05,
      "loss": 0.0925,
      "step": 8880
    },
    {
      "epoch": 0.1777786665600128,
      "grad_norm": 0.10193788260221481,
      "learning_rate": 4.703935527736672e-05,
      "loss": 0.0773,
      "step": 8890
    },
    {
      "epoch": 0.17797864256289245,
      "grad_norm": 0.05574914067983627,
      "learning_rate": 4.7036022343985394e-05,
      "loss": 0.0532,
      "step": 8900
    },
    {
      "epoch": 0.1781786185657721,
      "grad_norm": 0.10051582753658295,
      "learning_rate": 4.7032689410604064e-05,
      "loss": 0.098,
      "step": 8910
    },
    {
      "epoch": 0.17837859456865177,
      "grad_norm": 0.11134138703346252,
      "learning_rate": 4.7029356477222734e-05,
      "loss": 0.0671,
      "step": 8920
    },
    {
      "epoch": 0.17857857057153143,
      "grad_norm": 0.11904864013195038,
      "learning_rate": 4.702602354384141e-05,
      "loss": 0.1298,
      "step": 8930
    },
    {
      "epoch": 0.17877854657441106,
      "grad_norm": 0.12428709119558334,
      "learning_rate": 4.702269061046008e-05,
      "loss": 0.087,
      "step": 8940
    },
    {
      "epoch": 0.17897852257729072,
      "grad_norm": 0.167074054479599,
      "learning_rate": 4.701935767707875e-05,
      "loss": 0.0797,
      "step": 8950
    },
    {
      "epoch": 0.17917849858017038,
      "grad_norm": 0.10361865162849426,
      "learning_rate": 4.7016024743697426e-05,
      "loss": 0.0698,
      "step": 8960
    },
    {
      "epoch": 0.17937847458305003,
      "grad_norm": 0.09038946777582169,
      "learning_rate": 4.7012691810316095e-05,
      "loss": 0.0907,
      "step": 8970
    },
    {
      "epoch": 0.1795784505859297,
      "grad_norm": 0.17917145788669586,
      "learning_rate": 4.700935887693477e-05,
      "loss": 0.0542,
      "step": 8980
    },
    {
      "epoch": 0.17977842658880935,
      "grad_norm": 0.08082624524831772,
      "learning_rate": 4.700602594355344e-05,
      "loss": 0.0543,
      "step": 8990
    },
    {
      "epoch": 0.17997840259168899,
      "grad_norm": 0.17784667015075684,
      "learning_rate": 4.700269301017212e-05,
      "loss": 0.0803,
      "step": 9000
    },
    {
      "epoch": 0.18017837859456864,
      "grad_norm": 0.09557682275772095,
      "learning_rate": 4.699936007679079e-05,
      "loss": 0.0613,
      "step": 9010
    },
    {
      "epoch": 0.1803783545974483,
      "grad_norm": 0.09403113275766373,
      "learning_rate": 4.699602714340946e-05,
      "loss": 0.0864,
      "step": 9020
    },
    {
      "epoch": 0.18057833060032796,
      "grad_norm": 0.10297001898288727,
      "learning_rate": 4.699269421002813e-05,
      "loss": 0.0792,
      "step": 9030
    },
    {
      "epoch": 0.18077830660320762,
      "grad_norm": 0.20408299565315247,
      "learning_rate": 4.69893612766468e-05,
      "loss": 0.114,
      "step": 9040
    },
    {
      "epoch": 0.18097828260608728,
      "grad_norm": 0.07696758210659027,
      "learning_rate": 4.698602834326547e-05,
      "loss": 0.0668,
      "step": 9050
    },
    {
      "epoch": 0.1811782586089669,
      "grad_norm": 0.07847947627305984,
      "learning_rate": 4.698269540988415e-05,
      "loss": 0.1034,
      "step": 9060
    },
    {
      "epoch": 0.18137823461184657,
      "grad_norm": 0.19243615865707397,
      "learning_rate": 4.697936247650282e-05,
      "loss": 0.065,
      "step": 9070
    },
    {
      "epoch": 0.18157821061472623,
      "grad_norm": 0.2456882894039154,
      "learning_rate": 4.6976029543121495e-05,
      "loss": 0.0948,
      "step": 9080
    },
    {
      "epoch": 0.1817781866176059,
      "grad_norm": 0.11933599412441254,
      "learning_rate": 4.697269660974017e-05,
      "loss": 0.0732,
      "step": 9090
    },
    {
      "epoch": 0.18197816262048555,
      "grad_norm": 0.12141098082065582,
      "learning_rate": 4.696936367635884e-05,
      "loss": 0.0583,
      "step": 9100
    },
    {
      "epoch": 0.1821781386233652,
      "grad_norm": 0.09552600234746933,
      "learning_rate": 4.696603074297751e-05,
      "loss": 0.1017,
      "step": 9110
    },
    {
      "epoch": 0.18237811462624484,
      "grad_norm": 0.15840916335582733,
      "learning_rate": 4.696269780959619e-05,
      "loss": 0.0653,
      "step": 9120
    },
    {
      "epoch": 0.1825780906291245,
      "grad_norm": 0.17052775621414185,
      "learning_rate": 4.6959364876214856e-05,
      "loss": 0.0811,
      "step": 9130
    },
    {
      "epoch": 0.18277806663200416,
      "grad_norm": 0.06569157540798187,
      "learning_rate": 4.6956031942833526e-05,
      "loss": 0.0617,
      "step": 9140
    },
    {
      "epoch": 0.18297804263488382,
      "grad_norm": 0.1218368411064148,
      "learning_rate": 4.69526990094522e-05,
      "loss": 0.0754,
      "step": 9150
    },
    {
      "epoch": 0.18317801863776348,
      "grad_norm": 0.1136712059378624,
      "learning_rate": 4.694936607607087e-05,
      "loss": 0.0766,
      "step": 9160
    },
    {
      "epoch": 0.1833779946406431,
      "grad_norm": 0.0819135308265686,
      "learning_rate": 4.694603314268954e-05,
      "loss": 0.0474,
      "step": 9170
    },
    {
      "epoch": 0.18357797064352277,
      "grad_norm": 0.18317385017871857,
      "learning_rate": 4.694270020930822e-05,
      "loss": 0.1053,
      "step": 9180
    },
    {
      "epoch": 0.18377794664640243,
      "grad_norm": 0.11317608505487442,
      "learning_rate": 4.6939367275926894e-05,
      "loss": 0.1079,
      "step": 9190
    },
    {
      "epoch": 0.1839779226492821,
      "grad_norm": 0.10017601400613785,
      "learning_rate": 4.6936034342545564e-05,
      "loss": 0.1015,
      "step": 9200
    },
    {
      "epoch": 0.18417789865216175,
      "grad_norm": 0.0989634171128273,
      "learning_rate": 4.6932701409164234e-05,
      "loss": 0.1013,
      "step": 9210
    },
    {
      "epoch": 0.1843778746550414,
      "grad_norm": 0.0767897516489029,
      "learning_rate": 4.692936847578291e-05,
      "loss": 0.0944,
      "step": 9220
    },
    {
      "epoch": 0.18457785065792104,
      "grad_norm": 0.10879957675933838,
      "learning_rate": 4.692603554240158e-05,
      "loss": 0.1052,
      "step": 9230
    },
    {
      "epoch": 0.1847778266608007,
      "grad_norm": 0.1490885615348816,
      "learning_rate": 4.692270260902025e-05,
      "loss": 0.0647,
      "step": 9240
    },
    {
      "epoch": 0.18497780266368036,
      "grad_norm": 0.1776765137910843,
      "learning_rate": 4.6919369675638926e-05,
      "loss": 0.1021,
      "step": 9250
    },
    {
      "epoch": 0.18517777866656002,
      "grad_norm": 0.1717197448015213,
      "learning_rate": 4.6916036742257595e-05,
      "loss": 0.0904,
      "step": 9260
    },
    {
      "epoch": 0.18537775466943968,
      "grad_norm": 0.1827760636806488,
      "learning_rate": 4.6912703808876265e-05,
      "loss": 0.1028,
      "step": 9270
    },
    {
      "epoch": 0.18557773067231934,
      "grad_norm": 0.08022279292345047,
      "learning_rate": 4.690937087549494e-05,
      "loss": 0.0837,
      "step": 9280
    },
    {
      "epoch": 0.18577770667519897,
      "grad_norm": 0.1097051352262497,
      "learning_rate": 4.690603794211362e-05,
      "loss": 0.145,
      "step": 9290
    },
    {
      "epoch": 0.18597768267807863,
      "grad_norm": 0.05773312970995903,
      "learning_rate": 4.690270500873229e-05,
      "loss": 0.0539,
      "step": 9300
    },
    {
      "epoch": 0.18617765868095829,
      "grad_norm": 0.050305332988500595,
      "learning_rate": 4.6899372075350964e-05,
      "loss": 0.0474,
      "step": 9310
    },
    {
      "epoch": 0.18637763468383794,
      "grad_norm": 0.09603293985128403,
      "learning_rate": 4.689603914196963e-05,
      "loss": 0.0483,
      "step": 9320
    },
    {
      "epoch": 0.1865776106867176,
      "grad_norm": 0.08211565017700195,
      "learning_rate": 4.68927062085883e-05,
      "loss": 0.0937,
      "step": 9330
    },
    {
      "epoch": 0.18677758668959724,
      "grad_norm": 0.19031932950019836,
      "learning_rate": 4.688937327520698e-05,
      "loss": 0.0831,
      "step": 9340
    },
    {
      "epoch": 0.1869775626924769,
      "grad_norm": 0.07179343700408936,
      "learning_rate": 4.688604034182565e-05,
      "loss": 0.0757,
      "step": 9350
    },
    {
      "epoch": 0.18717753869535655,
      "grad_norm": 0.11539462953805923,
      "learning_rate": 4.688270740844432e-05,
      "loss": 0.0757,
      "step": 9360
    },
    {
      "epoch": 0.1873775146982362,
      "grad_norm": 0.21178856492042542,
      "learning_rate": 4.6879374475062995e-05,
      "loss": 0.1027,
      "step": 9370
    },
    {
      "epoch": 0.18757749070111587,
      "grad_norm": 0.17829549312591553,
      "learning_rate": 4.6876041541681665e-05,
      "loss": 0.0807,
      "step": 9380
    },
    {
      "epoch": 0.18777746670399553,
      "grad_norm": 0.09844235330820084,
      "learning_rate": 4.687270860830034e-05,
      "loss": 0.0718,
      "step": 9390
    },
    {
      "epoch": 0.18797744270687516,
      "grad_norm": 0.1053759977221489,
      "learning_rate": 4.686937567491901e-05,
      "loss": 0.0529,
      "step": 9400
    },
    {
      "epoch": 0.18817741870975482,
      "grad_norm": 0.14240311086177826,
      "learning_rate": 4.686604274153769e-05,
      "loss": 0.089,
      "step": 9410
    },
    {
      "epoch": 0.18837739471263448,
      "grad_norm": 0.08408762514591217,
      "learning_rate": 4.686270980815636e-05,
      "loss": 0.0696,
      "step": 9420
    },
    {
      "epoch": 0.18857737071551414,
      "grad_norm": 0.06114626303315163,
      "learning_rate": 4.6859376874775026e-05,
      "loss": 0.0362,
      "step": 9430
    },
    {
      "epoch": 0.1887773467183938,
      "grad_norm": 0.09320687502622604,
      "learning_rate": 4.68560439413937e-05,
      "loss": 0.0695,
      "step": 9440
    },
    {
      "epoch": 0.18897732272127346,
      "grad_norm": 0.11195839941501617,
      "learning_rate": 4.685271100801237e-05,
      "loss": 0.0637,
      "step": 9450
    },
    {
      "epoch": 0.1891772987241531,
      "grad_norm": 0.1178956851363182,
      "learning_rate": 4.684937807463104e-05,
      "loss": 0.0972,
      "step": 9460
    },
    {
      "epoch": 0.18937727472703275,
      "grad_norm": 0.17783375084400177,
      "learning_rate": 4.684604514124972e-05,
      "loss": 0.0778,
      "step": 9470
    },
    {
      "epoch": 0.1895772507299124,
      "grad_norm": 0.10362302511930466,
      "learning_rate": 4.684271220786839e-05,
      "loss": 0.0721,
      "step": 9480
    },
    {
      "epoch": 0.18977722673279207,
      "grad_norm": 0.10375257581472397,
      "learning_rate": 4.6839379274487064e-05,
      "loss": 0.0526,
      "step": 9490
    },
    {
      "epoch": 0.18997720273567173,
      "grad_norm": 0.11818177253007889,
      "learning_rate": 4.683604634110574e-05,
      "loss": 0.0757,
      "step": 9500
    },
    {
      "epoch": 0.19017717873855136,
      "grad_norm": 0.1910608410835266,
      "learning_rate": 4.683271340772441e-05,
      "loss": 0.0708,
      "step": 9510
    },
    {
      "epoch": 0.19037715474143102,
      "grad_norm": 0.24256068468093872,
      "learning_rate": 4.682938047434308e-05,
      "loss": 0.1586,
      "step": 9520
    },
    {
      "epoch": 0.19057713074431068,
      "grad_norm": 0.11656875163316727,
      "learning_rate": 4.6826047540961756e-05,
      "loss": 0.1113,
      "step": 9530
    },
    {
      "epoch": 0.19077710674719034,
      "grad_norm": 0.13513347506523132,
      "learning_rate": 4.6822714607580426e-05,
      "loss": 0.0906,
      "step": 9540
    },
    {
      "epoch": 0.19097708275007,
      "grad_norm": 0.1528947651386261,
      "learning_rate": 4.6819381674199096e-05,
      "loss": 0.0658,
      "step": 9550
    },
    {
      "epoch": 0.19117705875294966,
      "grad_norm": 0.1310226172208786,
      "learning_rate": 4.681604874081777e-05,
      "loss": 0.0841,
      "step": 9560
    },
    {
      "epoch": 0.1913770347558293,
      "grad_norm": 0.1448613405227661,
      "learning_rate": 4.681271580743644e-05,
      "loss": 0.0835,
      "step": 9570
    },
    {
      "epoch": 0.19157701075870895,
      "grad_norm": 0.18951450288295746,
      "learning_rate": 4.680938287405511e-05,
      "loss": 0.0853,
      "step": 9580
    },
    {
      "epoch": 0.1917769867615886,
      "grad_norm": 0.19913740456104279,
      "learning_rate": 4.680604994067379e-05,
      "loss": 0.0728,
      "step": 9590
    },
    {
      "epoch": 0.19197696276446827,
      "grad_norm": 0.09407032281160355,
      "learning_rate": 4.6802717007292464e-05,
      "loss": 0.095,
      "step": 9600
    },
    {
      "epoch": 0.19217693876734793,
      "grad_norm": 0.15267334878444672,
      "learning_rate": 4.6799384073911134e-05,
      "loss": 0.0856,
      "step": 9610
    },
    {
      "epoch": 0.1923769147702276,
      "grad_norm": 0.24768690764904022,
      "learning_rate": 4.67960511405298e-05,
      "loss": 0.1181,
      "step": 9620
    },
    {
      "epoch": 0.19257689077310722,
      "grad_norm": 0.11083542555570602,
      "learning_rate": 4.679271820714848e-05,
      "loss": 0.0648,
      "step": 9630
    },
    {
      "epoch": 0.19277686677598688,
      "grad_norm": 0.10719207674264908,
      "learning_rate": 4.678938527376715e-05,
      "loss": 0.1018,
      "step": 9640
    },
    {
      "epoch": 0.19297684277886654,
      "grad_norm": 0.16618676483631134,
      "learning_rate": 4.678605234038582e-05,
      "loss": 0.0831,
      "step": 9650
    },
    {
      "epoch": 0.1931768187817462,
      "grad_norm": 0.06492017954587936,
      "learning_rate": 4.6782719407004495e-05,
      "loss": 0.0596,
      "step": 9660
    },
    {
      "epoch": 0.19337679478462586,
      "grad_norm": 0.12687663733959198,
      "learning_rate": 4.6779386473623165e-05,
      "loss": 0.081,
      "step": 9670
    },
    {
      "epoch": 0.1935767707875055,
      "grad_norm": 0.09139736741781235,
      "learning_rate": 4.6776053540241834e-05,
      "loss": 0.082,
      "step": 9680
    },
    {
      "epoch": 0.19377674679038515,
      "grad_norm": 0.17480194568634033,
      "learning_rate": 4.677272060686052e-05,
      "loss": 0.0639,
      "step": 9690
    },
    {
      "epoch": 0.1939767227932648,
      "grad_norm": 0.18054097890853882,
      "learning_rate": 4.676938767347919e-05,
      "loss": 0.1176,
      "step": 9700
    },
    {
      "epoch": 0.19417669879614446,
      "grad_norm": 0.14844302833080292,
      "learning_rate": 4.676605474009786e-05,
      "loss": 0.1239,
      "step": 9710
    },
    {
      "epoch": 0.19437667479902412,
      "grad_norm": 0.06670742481946945,
      "learning_rate": 4.676272180671653e-05,
      "loss": 0.0734,
      "step": 9720
    },
    {
      "epoch": 0.19457665080190378,
      "grad_norm": 0.10947693884372711,
      "learning_rate": 4.67593888733352e-05,
      "loss": 0.1212,
      "step": 9730
    },
    {
      "epoch": 0.19477662680478341,
      "grad_norm": 0.09969346970319748,
      "learning_rate": 4.675605593995387e-05,
      "loss": 0.0714,
      "step": 9740
    },
    {
      "epoch": 0.19497660280766307,
      "grad_norm": 0.09583353251218796,
      "learning_rate": 4.675272300657255e-05,
      "loss": 0.074,
      "step": 9750
    },
    {
      "epoch": 0.19517657881054273,
      "grad_norm": 0.13461942970752716,
      "learning_rate": 4.674939007319122e-05,
      "loss": 0.0994,
      "step": 9760
    },
    {
      "epoch": 0.1953765548134224,
      "grad_norm": 0.23511478304862976,
      "learning_rate": 4.674605713980989e-05,
      "loss": 0.087,
      "step": 9770
    },
    {
      "epoch": 0.19557653081630205,
      "grad_norm": 0.1651603728532791,
      "learning_rate": 4.6742724206428564e-05,
      "loss": 0.1235,
      "step": 9780
    },
    {
      "epoch": 0.1957765068191817,
      "grad_norm": 0.10520698130130768,
      "learning_rate": 4.6739391273047234e-05,
      "loss": 0.083,
      "step": 9790
    },
    {
      "epoch": 0.19597648282206134,
      "grad_norm": 0.0667598769068718,
      "learning_rate": 4.673605833966591e-05,
      "loss": 0.0817,
      "step": 9800
    },
    {
      "epoch": 0.196176458824941,
      "grad_norm": 0.06359513849020004,
      "learning_rate": 4.673272540628458e-05,
      "loss": 0.0746,
      "step": 9810
    },
    {
      "epoch": 0.19637643482782066,
      "grad_norm": 0.16008354723453522,
      "learning_rate": 4.6729392472903256e-05,
      "loss": 0.0799,
      "step": 9820
    },
    {
      "epoch": 0.19657641083070032,
      "grad_norm": 0.12136147916316986,
      "learning_rate": 4.6726059539521926e-05,
      "loss": 0.0767,
      "step": 9830
    },
    {
      "epoch": 0.19677638683357998,
      "grad_norm": 0.16326697170734406,
      "learning_rate": 4.6722726606140596e-05,
      "loss": 0.0777,
      "step": 9840
    },
    {
      "epoch": 0.1969763628364596,
      "grad_norm": 0.13098272681236267,
      "learning_rate": 4.671939367275927e-05,
      "loss": 0.0932,
      "step": 9850
    },
    {
      "epoch": 0.19717633883933927,
      "grad_norm": 0.07080315798521042,
      "learning_rate": 4.671606073937794e-05,
      "loss": 0.0702,
      "step": 9860
    },
    {
      "epoch": 0.19737631484221893,
      "grad_norm": 0.192813441157341,
      "learning_rate": 4.671272780599661e-05,
      "loss": 0.0748,
      "step": 9870
    },
    {
      "epoch": 0.1975762908450986,
      "grad_norm": 0.16955700516700745,
      "learning_rate": 4.670939487261529e-05,
      "loss": 0.0762,
      "step": 9880
    },
    {
      "epoch": 0.19777626684797825,
      "grad_norm": 0.059964023530483246,
      "learning_rate": 4.670606193923396e-05,
      "loss": 0.0868,
      "step": 9890
    },
    {
      "epoch": 0.1979762428508579,
      "grad_norm": 0.07265522330999374,
      "learning_rate": 4.6702729005852634e-05,
      "loss": 0.0932,
      "step": 9900
    },
    {
      "epoch": 0.19817621885373754,
      "grad_norm": 0.06904784590005875,
      "learning_rate": 4.669939607247131e-05,
      "loss": 0.0478,
      "step": 9910
    },
    {
      "epoch": 0.1983761948566172,
      "grad_norm": 0.19595028460025787,
      "learning_rate": 4.669606313908998e-05,
      "loss": 0.0584,
      "step": 9920
    },
    {
      "epoch": 0.19857617085949686,
      "grad_norm": 0.1516915112733841,
      "learning_rate": 4.669273020570865e-05,
      "loss": 0.0837,
      "step": 9930
    },
    {
      "epoch": 0.19877614686237652,
      "grad_norm": 0.08742257207632065,
      "learning_rate": 4.6689397272327326e-05,
      "loss": 0.0959,
      "step": 9940
    },
    {
      "epoch": 0.19897612286525618,
      "grad_norm": 0.07803592085838318,
      "learning_rate": 4.6686064338945995e-05,
      "loss": 0.0982,
      "step": 9950
    },
    {
      "epoch": 0.19917609886813584,
      "grad_norm": 0.14194482564926147,
      "learning_rate": 4.6682731405564665e-05,
      "loss": 0.0787,
      "step": 9960
    },
    {
      "epoch": 0.19937607487101547,
      "grad_norm": 0.11611033976078033,
      "learning_rate": 4.667939847218334e-05,
      "loss": 0.084,
      "step": 9970
    },
    {
      "epoch": 0.19957605087389513,
      "grad_norm": 0.10500045865774155,
      "learning_rate": 4.667606553880201e-05,
      "loss": 0.058,
      "step": 9980
    },
    {
      "epoch": 0.1997760268767748,
      "grad_norm": 0.13282689452171326,
      "learning_rate": 4.667273260542068e-05,
      "loss": 0.0747,
      "step": 9990
    },
    {
      "epoch": 0.19997600287965445,
      "grad_norm": 0.08087855577468872,
      "learning_rate": 4.666939967203936e-05,
      "loss": 0.0495,
      "step": 10000
    },
    {
      "epoch": 0.2001759788825341,
      "grad_norm": 0.15494276583194733,
      "learning_rate": 4.666606673865803e-05,
      "loss": 0.0735,
      "step": 10010
    },
    {
      "epoch": 0.20037595488541374,
      "grad_norm": 0.10793600976467133,
      "learning_rate": 4.66627338052767e-05,
      "loss": 0.1513,
      "step": 10020
    },
    {
      "epoch": 0.2005759308882934,
      "grad_norm": 0.09021292626857758,
      "learning_rate": 4.665940087189537e-05,
      "loss": 0.0572,
      "step": 10030
    },
    {
      "epoch": 0.20077590689117306,
      "grad_norm": 0.20585130155086517,
      "learning_rate": 4.665606793851405e-05,
      "loss": 0.0813,
      "step": 10040
    },
    {
      "epoch": 0.20097588289405272,
      "grad_norm": 0.07140461355447769,
      "learning_rate": 4.665273500513272e-05,
      "loss": 0.1067,
      "step": 10050
    },
    {
      "epoch": 0.20117585889693237,
      "grad_norm": 0.1788938194513321,
      "learning_rate": 4.664940207175139e-05,
      "loss": 0.0602,
      "step": 10060
    },
    {
      "epoch": 0.20137583489981203,
      "grad_norm": 0.06807282567024231,
      "learning_rate": 4.6646069138370065e-05,
      "loss": 0.0775,
      "step": 10070
    },
    {
      "epoch": 0.20157581090269167,
      "grad_norm": 0.23048686981201172,
      "learning_rate": 4.6642736204988734e-05,
      "loss": 0.0907,
      "step": 10080
    },
    {
      "epoch": 0.20177578690557132,
      "grad_norm": 0.08440231531858444,
      "learning_rate": 4.6639403271607404e-05,
      "loss": 0.0645,
      "step": 10090
    },
    {
      "epoch": 0.20197576290845098,
      "grad_norm": 0.23087763786315918,
      "learning_rate": 4.663607033822609e-05,
      "loss": 0.1389,
      "step": 10100
    },
    {
      "epoch": 0.20217573891133064,
      "grad_norm": 0.17640233039855957,
      "learning_rate": 4.663273740484476e-05,
      "loss": 0.0817,
      "step": 10110
    },
    {
      "epoch": 0.2023757149142103,
      "grad_norm": 0.15422983467578888,
      "learning_rate": 4.6629404471463426e-05,
      "loss": 0.0636,
      "step": 10120
    },
    {
      "epoch": 0.20257569091708996,
      "grad_norm": 0.09083980321884155,
      "learning_rate": 4.66260715380821e-05,
      "loss": 0.0577,
      "step": 10130
    },
    {
      "epoch": 0.2027756669199696,
      "grad_norm": 0.13943268358707428,
      "learning_rate": 4.662273860470077e-05,
      "loss": 0.0651,
      "step": 10140
    },
    {
      "epoch": 0.20297564292284925,
      "grad_norm": 0.1319912075996399,
      "learning_rate": 4.661940567131944e-05,
      "loss": 0.0916,
      "step": 10150
    },
    {
      "epoch": 0.2031756189257289,
      "grad_norm": 0.18830232322216034,
      "learning_rate": 4.661607273793812e-05,
      "loss": 0.0528,
      "step": 10160
    },
    {
      "epoch": 0.20337559492860857,
      "grad_norm": 0.05225950479507446,
      "learning_rate": 4.661273980455679e-05,
      "loss": 0.1011,
      "step": 10170
    },
    {
      "epoch": 0.20357557093148823,
      "grad_norm": 0.15145277976989746,
      "learning_rate": 4.660940687117546e-05,
      "loss": 0.0918,
      "step": 10180
    },
    {
      "epoch": 0.20377554693436786,
      "grad_norm": 0.16303403675556183,
      "learning_rate": 4.6606073937794134e-05,
      "loss": 0.0663,
      "step": 10190
    },
    {
      "epoch": 0.20397552293724752,
      "grad_norm": 0.14532668888568878,
      "learning_rate": 4.660274100441281e-05,
      "loss": 0.075,
      "step": 10200
    },
    {
      "epoch": 0.20417549894012718,
      "grad_norm": 0.13714392483234406,
      "learning_rate": 4.659940807103148e-05,
      "loss": 0.0769,
      "step": 10210
    },
    {
      "epoch": 0.20437547494300684,
      "grad_norm": 0.1268046647310257,
      "learning_rate": 4.659607513765015e-05,
      "loss": 0.0852,
      "step": 10220
    },
    {
      "epoch": 0.2045754509458865,
      "grad_norm": 0.19680525362491608,
      "learning_rate": 4.6592742204268826e-05,
      "loss": 0.0829,
      "step": 10230
    },
    {
      "epoch": 0.20477542694876616,
      "grad_norm": 0.09135597199201584,
      "learning_rate": 4.6589409270887496e-05,
      "loss": 0.084,
      "step": 10240
    },
    {
      "epoch": 0.2049754029516458,
      "grad_norm": 0.07262380421161652,
      "learning_rate": 4.6586076337506165e-05,
      "loss": 0.1036,
      "step": 10250
    },
    {
      "epoch": 0.20517537895452545,
      "grad_norm": 0.07037828862667084,
      "learning_rate": 4.658274340412484e-05,
      "loss": 0.0983,
      "step": 10260
    },
    {
      "epoch": 0.2053753549574051,
      "grad_norm": 0.10634155571460724,
      "learning_rate": 4.657941047074351e-05,
      "loss": 0.0552,
      "step": 10270
    },
    {
      "epoch": 0.20557533096028477,
      "grad_norm": 0.12436086684465408,
      "learning_rate": 4.657607753736218e-05,
      "loss": 0.0688,
      "step": 10280
    },
    {
      "epoch": 0.20577530696316443,
      "grad_norm": 0.11737468838691711,
      "learning_rate": 4.657274460398086e-05,
      "loss": 0.0708,
      "step": 10290
    },
    {
      "epoch": 0.2059752829660441,
      "grad_norm": 0.1577257364988327,
      "learning_rate": 4.656941167059953e-05,
      "loss": 0.0958,
      "step": 10300
    },
    {
      "epoch": 0.20617525896892372,
      "grad_norm": 0.08647847175598145,
      "learning_rate": 4.65660787372182e-05,
      "loss": 0.0543,
      "step": 10310
    },
    {
      "epoch": 0.20637523497180338,
      "grad_norm": 0.09785333275794983,
      "learning_rate": 4.656274580383688e-05,
      "loss": 0.0796,
      "step": 10320
    },
    {
      "epoch": 0.20657521097468304,
      "grad_norm": 0.11440668255090714,
      "learning_rate": 4.655941287045555e-05,
      "loss": 0.081,
      "step": 10330
    },
    {
      "epoch": 0.2067751869775627,
      "grad_norm": 0.24391381442546844,
      "learning_rate": 4.655607993707422e-05,
      "loss": 0.0758,
      "step": 10340
    },
    {
      "epoch": 0.20697516298044236,
      "grad_norm": 0.10542139410972595,
      "learning_rate": 4.6552747003692895e-05,
      "loss": 0.0899,
      "step": 10350
    },
    {
      "epoch": 0.207175138983322,
      "grad_norm": 0.06475038826465607,
      "learning_rate": 4.6549414070311565e-05,
      "loss": 0.0768,
      "step": 10360
    },
    {
      "epoch": 0.20737511498620165,
      "grad_norm": 0.1443704217672348,
      "learning_rate": 4.6546081136930234e-05,
      "loss": 0.0533,
      "step": 10370
    },
    {
      "epoch": 0.2075750909890813,
      "grad_norm": 0.1488458514213562,
      "learning_rate": 4.654274820354891e-05,
      "loss": 0.0782,
      "step": 10380
    },
    {
      "epoch": 0.20777506699196097,
      "grad_norm": 0.21103692054748535,
      "learning_rate": 4.653941527016758e-05,
      "loss": 0.1305,
      "step": 10390
    },
    {
      "epoch": 0.20797504299484063,
      "grad_norm": 0.13211436569690704,
      "learning_rate": 4.653608233678625e-05,
      "loss": 0.1,
      "step": 10400
    },
    {
      "epoch": 0.20817501899772028,
      "grad_norm": 0.1545266956090927,
      "learning_rate": 4.6532749403404926e-05,
      "loss": 0.069,
      "step": 10410
    },
    {
      "epoch": 0.20837499500059992,
      "grad_norm": 0.21337665617465973,
      "learning_rate": 4.65294164700236e-05,
      "loss": 0.0579,
      "step": 10420
    },
    {
      "epoch": 0.20857497100347958,
      "grad_norm": 0.12054307758808136,
      "learning_rate": 4.652608353664227e-05,
      "loss": 0.0716,
      "step": 10430
    },
    {
      "epoch": 0.20877494700635923,
      "grad_norm": 0.13929280638694763,
      "learning_rate": 4.652275060326094e-05,
      "loss": 0.0531,
      "step": 10440
    },
    {
      "epoch": 0.2089749230092389,
      "grad_norm": 0.19077591598033905,
      "learning_rate": 4.651941766987962e-05,
      "loss": 0.0585,
      "step": 10450
    },
    {
      "epoch": 0.20917489901211855,
      "grad_norm": 0.11132800579071045,
      "learning_rate": 4.651608473649829e-05,
      "loss": 0.0848,
      "step": 10460
    },
    {
      "epoch": 0.2093748750149982,
      "grad_norm": 0.1447637677192688,
      "learning_rate": 4.651275180311696e-05,
      "loss": 0.0728,
      "step": 10470
    },
    {
      "epoch": 0.20957485101787784,
      "grad_norm": 0.16624003648757935,
      "learning_rate": 4.6509418869735634e-05,
      "loss": 0.0786,
      "step": 10480
    },
    {
      "epoch": 0.2097748270207575,
      "grad_norm": 0.07871215790510178,
      "learning_rate": 4.6506085936354304e-05,
      "loss": 0.0739,
      "step": 10490
    },
    {
      "epoch": 0.20997480302363716,
      "grad_norm": 0.12509046494960785,
      "learning_rate": 4.650275300297297e-05,
      "loss": 0.1162,
      "step": 10500
    },
    {
      "epoch": 0.21017477902651682,
      "grad_norm": 0.18805697560310364,
      "learning_rate": 4.6499420069591656e-05,
      "loss": 0.0631,
      "step": 10510
    },
    {
      "epoch": 0.21037475502939648,
      "grad_norm": 0.05433765426278114,
      "learning_rate": 4.6496087136210326e-05,
      "loss": 0.0627,
      "step": 10520
    },
    {
      "epoch": 0.2105747310322761,
      "grad_norm": 0.09883115440607071,
      "learning_rate": 4.6492754202828996e-05,
      "loss": 0.0685,
      "step": 10530
    },
    {
      "epoch": 0.21077470703515577,
      "grad_norm": 0.13029715418815613,
      "learning_rate": 4.648942126944767e-05,
      "loss": 0.1008,
      "step": 10540
    },
    {
      "epoch": 0.21097468303803543,
      "grad_norm": 0.20762474834918976,
      "learning_rate": 4.648608833606634e-05,
      "loss": 0.116,
      "step": 10550
    },
    {
      "epoch": 0.2111746590409151,
      "grad_norm": 0.13605733215808868,
      "learning_rate": 4.648275540268501e-05,
      "loss": 0.1044,
      "step": 10560
    },
    {
      "epoch": 0.21137463504379475,
      "grad_norm": 0.1448359191417694,
      "learning_rate": 4.647942246930369e-05,
      "loss": 0.0864,
      "step": 10570
    },
    {
      "epoch": 0.2115746110466744,
      "grad_norm": 0.16621141135692596,
      "learning_rate": 4.647608953592236e-05,
      "loss": 0.0903,
      "step": 10580
    },
    {
      "epoch": 0.21177458704955404,
      "grad_norm": 0.20178449153900146,
      "learning_rate": 4.647275660254103e-05,
      "loss": 0.0741,
      "step": 10590
    },
    {
      "epoch": 0.2119745630524337,
      "grad_norm": 0.11856259405612946,
      "learning_rate": 4.64694236691597e-05,
      "loss": 0.0768,
      "step": 10600
    },
    {
      "epoch": 0.21217453905531336,
      "grad_norm": 0.13094696402549744,
      "learning_rate": 4.646609073577838e-05,
      "loss": 0.1015,
      "step": 10610
    },
    {
      "epoch": 0.21237451505819302,
      "grad_norm": 0.12315775454044342,
      "learning_rate": 4.646275780239705e-05,
      "loss": 0.0899,
      "step": 10620
    },
    {
      "epoch": 0.21257449106107268,
      "grad_norm": 0.18419098854064941,
      "learning_rate": 4.645942486901572e-05,
      "loss": 0.111,
      "step": 10630
    },
    {
      "epoch": 0.21277446706395234,
      "grad_norm": 0.10566418617963791,
      "learning_rate": 4.6456091935634395e-05,
      "loss": 0.0513,
      "step": 10640
    },
    {
      "epoch": 0.21297444306683197,
      "grad_norm": 0.07360071688890457,
      "learning_rate": 4.6452759002253065e-05,
      "loss": 0.0693,
      "step": 10650
    },
    {
      "epoch": 0.21317441906971163,
      "grad_norm": 0.08070842176675797,
      "learning_rate": 4.6449426068871735e-05,
      "loss": 0.0733,
      "step": 10660
    },
    {
      "epoch": 0.2133743950725913,
      "grad_norm": 0.10135920345783234,
      "learning_rate": 4.644609313549041e-05,
      "loss": 0.0992,
      "step": 10670
    },
    {
      "epoch": 0.21357437107547095,
      "grad_norm": 0.12650427222251892,
      "learning_rate": 4.644276020210908e-05,
      "loss": 0.1186,
      "step": 10680
    },
    {
      "epoch": 0.2137743470783506,
      "grad_norm": 0.1896597295999527,
      "learning_rate": 4.643942726872775e-05,
      "loss": 0.0605,
      "step": 10690
    },
    {
      "epoch": 0.21397432308123024,
      "grad_norm": 0.13059617578983307,
      "learning_rate": 4.6436094335346427e-05,
      "loss": 0.5536,
      "step": 10700
    },
    {
      "epoch": 0.2141742990841099,
      "grad_norm": 0.1109510138630867,
      "learning_rate": 4.64327614019651e-05,
      "loss": 0.0956,
      "step": 10710
    },
    {
      "epoch": 0.21437427508698956,
      "grad_norm": 0.1275528520345688,
      "learning_rate": 4.642942846858377e-05,
      "loss": 0.0685,
      "step": 10720
    },
    {
      "epoch": 0.21457425108986922,
      "grad_norm": 0.13852515816688538,
      "learning_rate": 4.642609553520245e-05,
      "loss": 0.0998,
      "step": 10730
    },
    {
      "epoch": 0.21477422709274888,
      "grad_norm": 0.16105838119983673,
      "learning_rate": 4.642276260182112e-05,
      "loss": 0.0853,
      "step": 10740
    },
    {
      "epoch": 0.21497420309562854,
      "grad_norm": 0.10133343189954758,
      "learning_rate": 4.641942966843979e-05,
      "loss": 0.0807,
      "step": 10750
    },
    {
      "epoch": 0.21517417909850817,
      "grad_norm": 0.09617491066455841,
      "learning_rate": 4.6416096735058465e-05,
      "loss": 0.0778,
      "step": 10760
    },
    {
      "epoch": 0.21537415510138783,
      "grad_norm": 0.12869751453399658,
      "learning_rate": 4.6412763801677134e-05,
      "loss": 0.0576,
      "step": 10770
    },
    {
      "epoch": 0.21557413110426749,
      "grad_norm": 0.1813686192035675,
      "learning_rate": 4.6409430868295804e-05,
      "loss": 0.0983,
      "step": 10780
    },
    {
      "epoch": 0.21577410710714715,
      "grad_norm": 0.08738000690937042,
      "learning_rate": 4.640609793491448e-05,
      "loss": 0.0536,
      "step": 10790
    },
    {
      "epoch": 0.2159740831100268,
      "grad_norm": 0.13499076664447784,
      "learning_rate": 4.640276500153315e-05,
      "loss": 0.0638,
      "step": 10800
    },
    {
      "epoch": 0.21617405911290646,
      "grad_norm": 0.10294362902641296,
      "learning_rate": 4.639943206815182e-05,
      "loss": 0.1321,
      "step": 10810
    },
    {
      "epoch": 0.2163740351157861,
      "grad_norm": 0.1774848848581314,
      "learning_rate": 4.6396099134770496e-05,
      "loss": 0.056,
      "step": 10820
    },
    {
      "epoch": 0.21657401111866575,
      "grad_norm": 0.11555769294500351,
      "learning_rate": 4.639276620138917e-05,
      "loss": 0.0856,
      "step": 10830
    },
    {
      "epoch": 0.21677398712154541,
      "grad_norm": 0.18710649013519287,
      "learning_rate": 4.638943326800784e-05,
      "loss": 0.0823,
      "step": 10840
    },
    {
      "epoch": 0.21697396312442507,
      "grad_norm": 0.13548168540000916,
      "learning_rate": 4.638610033462651e-05,
      "loss": 0.0847,
      "step": 10850
    },
    {
      "epoch": 0.21717393912730473,
      "grad_norm": 0.10045043379068375,
      "learning_rate": 4.638276740124519e-05,
      "loss": 0.069,
      "step": 10860
    },
    {
      "epoch": 0.21737391513018436,
      "grad_norm": 0.16202497482299805,
      "learning_rate": 4.637943446786386e-05,
      "loss": 0.1068,
      "step": 10870
    },
    {
      "epoch": 0.21757389113306402,
      "grad_norm": 0.08362974971532822,
      "learning_rate": 4.637610153448253e-05,
      "loss": 0.0641,
      "step": 10880
    },
    {
      "epoch": 0.21777386713594368,
      "grad_norm": 0.1745249330997467,
      "learning_rate": 4.6372768601101204e-05,
      "loss": 0.0998,
      "step": 10890
    },
    {
      "epoch": 0.21797384313882334,
      "grad_norm": 0.06766874343156815,
      "learning_rate": 4.636943566771987e-05,
      "loss": 0.4827,
      "step": 10900
    },
    {
      "epoch": 0.218173819141703,
      "grad_norm": 0.09414108842611313,
      "learning_rate": 4.636610273433854e-05,
      "loss": 0.0497,
      "step": 10910
    },
    {
      "epoch": 0.21837379514458266,
      "grad_norm": 0.06275643408298492,
      "learning_rate": 4.6362769800957226e-05,
      "loss": 0.0878,
      "step": 10920
    },
    {
      "epoch": 0.2185737711474623,
      "grad_norm": 0.17884856462478638,
      "learning_rate": 4.6359436867575896e-05,
      "loss": 0.1014,
      "step": 10930
    },
    {
      "epoch": 0.21877374715034195,
      "grad_norm": 0.12634553015232086,
      "learning_rate": 4.6356103934194565e-05,
      "loss": 0.1098,
      "step": 10940
    },
    {
      "epoch": 0.2189737231532216,
      "grad_norm": 0.15363489091396332,
      "learning_rate": 4.635277100081324e-05,
      "loss": 0.0909,
      "step": 10950
    },
    {
      "epoch": 0.21917369915610127,
      "grad_norm": 0.06411600112915039,
      "learning_rate": 4.634943806743191e-05,
      "loss": 0.0654,
      "step": 10960
    },
    {
      "epoch": 0.21937367515898093,
      "grad_norm": 0.09937558323144913,
      "learning_rate": 4.634610513405058e-05,
      "loss": 0.0819,
      "step": 10970
    },
    {
      "epoch": 0.2195736511618606,
      "grad_norm": 0.18468624353408813,
      "learning_rate": 4.634277220066926e-05,
      "loss": 0.0511,
      "step": 10980
    },
    {
      "epoch": 0.21977362716474022,
      "grad_norm": 0.06111864745616913,
      "learning_rate": 4.633943926728793e-05,
      "loss": 0.0843,
      "step": 10990
    },
    {
      "epoch": 0.21997360316761988,
      "grad_norm": 0.1060166284441948,
      "learning_rate": 4.6336106333906596e-05,
      "loss": 0.114,
      "step": 11000
    },
    {
      "epoch": 0.22017357917049954,
      "grad_norm": 0.12422709912061691,
      "learning_rate": 4.633277340052527e-05,
      "loss": 0.0868,
      "step": 11010
    },
    {
      "epoch": 0.2203735551733792,
      "grad_norm": 0.19608870148658752,
      "learning_rate": 4.632944046714395e-05,
      "loss": 0.0984,
      "step": 11020
    },
    {
      "epoch": 0.22057353117625886,
      "grad_norm": 0.12703095376491547,
      "learning_rate": 4.632610753376262e-05,
      "loss": 0.0813,
      "step": 11030
    },
    {
      "epoch": 0.2207735071791385,
      "grad_norm": 0.13800834119319916,
      "learning_rate": 4.632277460038129e-05,
      "loss": 0.084,
      "step": 11040
    },
    {
      "epoch": 0.22097348318201815,
      "grad_norm": 0.0744408369064331,
      "learning_rate": 4.6319441666999965e-05,
      "loss": 0.0581,
      "step": 11050
    },
    {
      "epoch": 0.2211734591848978,
      "grad_norm": 0.10199485719203949,
      "learning_rate": 4.6316108733618634e-05,
      "loss": 0.126,
      "step": 11060
    },
    {
      "epoch": 0.22137343518777747,
      "grad_norm": 0.16034291684627533,
      "learning_rate": 4.6312775800237304e-05,
      "loss": 0.115,
      "step": 11070
    },
    {
      "epoch": 0.22157341119065713,
      "grad_norm": 0.1545228809118271,
      "learning_rate": 4.630944286685598e-05,
      "loss": 0.0686,
      "step": 11080
    },
    {
      "epoch": 0.2217733871935368,
      "grad_norm": 0.06861285120248795,
      "learning_rate": 4.630610993347465e-05,
      "loss": 0.0793,
      "step": 11090
    },
    {
      "epoch": 0.22197336319641642,
      "grad_norm": 0.18365782499313354,
      "learning_rate": 4.630277700009332e-05,
      "loss": 0.1111,
      "step": 11100
    },
    {
      "epoch": 0.22217333919929608,
      "grad_norm": 0.053367920219898224,
      "learning_rate": 4.6299444066711996e-05,
      "loss": 0.0503,
      "step": 11110
    },
    {
      "epoch": 0.22237331520217574,
      "grad_norm": 0.20659613609313965,
      "learning_rate": 4.629611113333067e-05,
      "loss": 0.0918,
      "step": 11120
    },
    {
      "epoch": 0.2225732912050554,
      "grad_norm": 0.09134349226951599,
      "learning_rate": 4.629277819994934e-05,
      "loss": 0.0589,
      "step": 11130
    },
    {
      "epoch": 0.22277326720793506,
      "grad_norm": 0.17910096049308777,
      "learning_rate": 4.628944526656802e-05,
      "loss": 0.1356,
      "step": 11140
    },
    {
      "epoch": 0.22297324321081471,
      "grad_norm": 0.1491554230451584,
      "learning_rate": 4.628611233318669e-05,
      "loss": 0.0693,
      "step": 11150
    },
    {
      "epoch": 0.22317321921369435,
      "grad_norm": 0.06218768656253815,
      "learning_rate": 4.628277939980536e-05,
      "loss": 0.0555,
      "step": 11160
    },
    {
      "epoch": 0.223373195216574,
      "grad_norm": 0.09505628049373627,
      "learning_rate": 4.6279446466424034e-05,
      "loss": 0.0565,
      "step": 11170
    },
    {
      "epoch": 0.22357317121945366,
      "grad_norm": 0.0849929228425026,
      "learning_rate": 4.6276113533042704e-05,
      "loss": 0.0655,
      "step": 11180
    },
    {
      "epoch": 0.22377314722233332,
      "grad_norm": 0.07927288860082626,
      "learning_rate": 4.627278059966137e-05,
      "loss": 0.1264,
      "step": 11190
    },
    {
      "epoch": 0.22397312322521298,
      "grad_norm": 0.17179152369499207,
      "learning_rate": 4.626944766628005e-05,
      "loss": 0.0886,
      "step": 11200
    },
    {
      "epoch": 0.22417309922809264,
      "grad_norm": 0.05711197480559349,
      "learning_rate": 4.626611473289872e-05,
      "loss": 0.075,
      "step": 11210
    },
    {
      "epoch": 0.22437307523097227,
      "grad_norm": 0.1852242648601532,
      "learning_rate": 4.6262781799517396e-05,
      "loss": 0.052,
      "step": 11220
    },
    {
      "epoch": 0.22457305123385193,
      "grad_norm": 0.0974985882639885,
      "learning_rate": 4.6259448866136065e-05,
      "loss": 0.0493,
      "step": 11230
    },
    {
      "epoch": 0.2247730272367316,
      "grad_norm": 0.09806752949953079,
      "learning_rate": 4.625611593275474e-05,
      "loss": 0.0555,
      "step": 11240
    },
    {
      "epoch": 0.22497300323961125,
      "grad_norm": 0.1649547666311264,
      "learning_rate": 4.625278299937341e-05,
      "loss": 0.1197,
      "step": 11250
    },
    {
      "epoch": 0.2251729792424909,
      "grad_norm": 0.15198291838169098,
      "learning_rate": 4.624945006599208e-05,
      "loss": 0.0744,
      "step": 11260
    },
    {
      "epoch": 0.22537295524537054,
      "grad_norm": 0.09594153612852097,
      "learning_rate": 4.624611713261076e-05,
      "loss": 0.1078,
      "step": 11270
    },
    {
      "epoch": 0.2255729312482502,
      "grad_norm": 0.08867206424474716,
      "learning_rate": 4.624278419922943e-05,
      "loss": 0.0717,
      "step": 11280
    },
    {
      "epoch": 0.22577290725112986,
      "grad_norm": 0.0769590213894844,
      "learning_rate": 4.6239451265848097e-05,
      "loss": 0.0445,
      "step": 11290
    },
    {
      "epoch": 0.22597288325400952,
      "grad_norm": 0.10102470964193344,
      "learning_rate": 4.623611833246677e-05,
      "loss": 0.0672,
      "step": 11300
    },
    {
      "epoch": 0.22617285925688918,
      "grad_norm": 0.09834935516119003,
      "learning_rate": 4.623278539908544e-05,
      "loss": 0.0688,
      "step": 11310
    },
    {
      "epoch": 0.22637283525976884,
      "grad_norm": 0.09729558974504471,
      "learning_rate": 4.622945246570411e-05,
      "loss": 0.0556,
      "step": 11320
    },
    {
      "epoch": 0.22657281126264847,
      "grad_norm": 0.17089256644248962,
      "learning_rate": 4.6226119532322795e-05,
      "loss": 0.0619,
      "step": 11330
    },
    {
      "epoch": 0.22677278726552813,
      "grad_norm": 0.1032138392329216,
      "learning_rate": 4.6222786598941465e-05,
      "loss": 0.067,
      "step": 11340
    },
    {
      "epoch": 0.2269727632684078,
      "grad_norm": 0.08466401696205139,
      "learning_rate": 4.6219453665560135e-05,
      "loss": 0.0502,
      "step": 11350
    },
    {
      "epoch": 0.22717273927128745,
      "grad_norm": 0.10808812826871872,
      "learning_rate": 4.621612073217881e-05,
      "loss": 0.0827,
      "step": 11360
    },
    {
      "epoch": 0.2273727152741671,
      "grad_norm": 0.07636711001396179,
      "learning_rate": 4.621278779879748e-05,
      "loss": 0.0605,
      "step": 11370
    },
    {
      "epoch": 0.22757269127704677,
      "grad_norm": 0.09634643793106079,
      "learning_rate": 4.620945486541615e-05,
      "loss": 0.0832,
      "step": 11380
    },
    {
      "epoch": 0.2277726672799264,
      "grad_norm": 0.05764741823077202,
      "learning_rate": 4.6206121932034827e-05,
      "loss": 0.0547,
      "step": 11390
    },
    {
      "epoch": 0.22797264328280606,
      "grad_norm": 0.17001762986183167,
      "learning_rate": 4.6202788998653496e-05,
      "loss": 0.4423,
      "step": 11400
    },
    {
      "epoch": 0.22817261928568572,
      "grad_norm": 0.07353886216878891,
      "learning_rate": 4.6199456065272166e-05,
      "loss": 0.0703,
      "step": 11410
    },
    {
      "epoch": 0.22837259528856538,
      "grad_norm": 0.1128840297460556,
      "learning_rate": 4.619612313189084e-05,
      "loss": 0.0746,
      "step": 11420
    },
    {
      "epoch": 0.22857257129144504,
      "grad_norm": 0.1759076565504074,
      "learning_rate": 4.619279019850952e-05,
      "loss": 0.0777,
      "step": 11430
    },
    {
      "epoch": 0.22877254729432467,
      "grad_norm": 0.124435655772686,
      "learning_rate": 4.618945726512819e-05,
      "loss": 0.1249,
      "step": 11440
    },
    {
      "epoch": 0.22897252329720433,
      "grad_norm": 0.18964031338691711,
      "learning_rate": 4.618612433174686e-05,
      "loss": 0.0924,
      "step": 11450
    },
    {
      "epoch": 0.229172499300084,
      "grad_norm": 0.12162116169929504,
      "learning_rate": 4.6182791398365534e-05,
      "loss": 0.0688,
      "step": 11460
    },
    {
      "epoch": 0.22937247530296365,
      "grad_norm": 0.09709498286247253,
      "learning_rate": 4.6179458464984204e-05,
      "loss": 0.0875,
      "step": 11470
    },
    {
      "epoch": 0.2295724513058433,
      "grad_norm": 0.15989266335964203,
      "learning_rate": 4.6176125531602873e-05,
      "loss": 0.0579,
      "step": 11480
    },
    {
      "epoch": 0.22977242730872297,
      "grad_norm": 0.11393986642360687,
      "learning_rate": 4.617279259822155e-05,
      "loss": 0.0542,
      "step": 11490
    },
    {
      "epoch": 0.2299724033116026,
      "grad_norm": 0.1782037764787674,
      "learning_rate": 4.616945966484022e-05,
      "loss": 0.0817,
      "step": 11500
    },
    {
      "epoch": 0.23017237931448226,
      "grad_norm": 0.28894713521003723,
      "learning_rate": 4.616612673145889e-05,
      "loss": 0.109,
      "step": 11510
    },
    {
      "epoch": 0.23037235531736192,
      "grad_norm": 0.09654577821493149,
      "learning_rate": 4.6162793798077565e-05,
      "loss": 0.0707,
      "step": 11520
    },
    {
      "epoch": 0.23057233132024157,
      "grad_norm": 0.2264842987060547,
      "learning_rate": 4.615946086469624e-05,
      "loss": 0.0773,
      "step": 11530
    },
    {
      "epoch": 0.23077230732312123,
      "grad_norm": 0.08582419157028198,
      "learning_rate": 4.615612793131491e-05,
      "loss": 0.0881,
      "step": 11540
    },
    {
      "epoch": 0.2309722833260009,
      "grad_norm": 0.20549269020557404,
      "learning_rate": 4.615279499793359e-05,
      "loss": 0.0988,
      "step": 11550
    },
    {
      "epoch": 0.23117225932888052,
      "grad_norm": 0.12877005338668823,
      "learning_rate": 4.614946206455226e-05,
      "loss": 0.0741,
      "step": 11560
    },
    {
      "epoch": 0.23137223533176018,
      "grad_norm": 0.15064337849617004,
      "learning_rate": 4.614612913117093e-05,
      "loss": 0.0885,
      "step": 11570
    },
    {
      "epoch": 0.23157221133463984,
      "grad_norm": 0.11228287220001221,
      "learning_rate": 4.6142796197789604e-05,
      "loss": 0.0574,
      "step": 11580
    },
    {
      "epoch": 0.2317721873375195,
      "grad_norm": 0.17934267222881317,
      "learning_rate": 4.613946326440827e-05,
      "loss": 0.0706,
      "step": 11590
    },
    {
      "epoch": 0.23197216334039916,
      "grad_norm": 0.08044256269931793,
      "learning_rate": 4.613613033102694e-05,
      "loss": 0.0729,
      "step": 11600
    },
    {
      "epoch": 0.2321721393432788,
      "grad_norm": 0.19272762537002563,
      "learning_rate": 4.613279739764562e-05,
      "loss": 0.0956,
      "step": 11610
    },
    {
      "epoch": 0.23237211534615845,
      "grad_norm": 0.1337360441684723,
      "learning_rate": 4.612946446426429e-05,
      "loss": 0.1066,
      "step": 11620
    },
    {
      "epoch": 0.2325720913490381,
      "grad_norm": 0.10853425413370132,
      "learning_rate": 4.6126131530882965e-05,
      "loss": 0.0443,
      "step": 11630
    },
    {
      "epoch": 0.23277206735191777,
      "grad_norm": 0.12264042347669601,
      "learning_rate": 4.6122798597501635e-05,
      "loss": 0.0778,
      "step": 11640
    },
    {
      "epoch": 0.23297204335479743,
      "grad_norm": 0.139195516705513,
      "learning_rate": 4.611946566412031e-05,
      "loss": 0.0872,
      "step": 11650
    },
    {
      "epoch": 0.2331720193576771,
      "grad_norm": 0.07238887995481491,
      "learning_rate": 4.611613273073898e-05,
      "loss": 0.0582,
      "step": 11660
    },
    {
      "epoch": 0.23337199536055672,
      "grad_norm": 0.07234565168619156,
      "learning_rate": 4.611279979735765e-05,
      "loss": 0.0683,
      "step": 11670
    },
    {
      "epoch": 0.23357197136343638,
      "grad_norm": 0.10963961482048035,
      "learning_rate": 4.610946686397633e-05,
      "loss": 0.1171,
      "step": 11680
    },
    {
      "epoch": 0.23377194736631604,
      "grad_norm": 0.07761301100254059,
      "learning_rate": 4.6106133930594996e-05,
      "loss": 0.0738,
      "step": 11690
    },
    {
      "epoch": 0.2339719233691957,
      "grad_norm": 0.10673917084932327,
      "learning_rate": 4.6102800997213666e-05,
      "loss": 0.0703,
      "step": 11700
    },
    {
      "epoch": 0.23417189937207536,
      "grad_norm": 0.1465964913368225,
      "learning_rate": 4.609946806383234e-05,
      "loss": 0.0879,
      "step": 11710
    },
    {
      "epoch": 0.23437187537495502,
      "grad_norm": 0.0905466079711914,
      "learning_rate": 4.609613513045101e-05,
      "loss": 0.063,
      "step": 11720
    },
    {
      "epoch": 0.23457185137783465,
      "grad_norm": 0.17783500254154205,
      "learning_rate": 4.609280219706969e-05,
      "loss": 0.0694,
      "step": 11730
    },
    {
      "epoch": 0.2347718273807143,
      "grad_norm": 0.10291591286659241,
      "learning_rate": 4.6089469263688365e-05,
      "loss": 0.0953,
      "step": 11740
    },
    {
      "epoch": 0.23497180338359397,
      "grad_norm": 0.09949437528848648,
      "learning_rate": 4.6086136330307034e-05,
      "loss": 0.0732,
      "step": 11750
    },
    {
      "epoch": 0.23517177938647363,
      "grad_norm": 0.12598983943462372,
      "learning_rate": 4.6082803396925704e-05,
      "loss": 0.0799,
      "step": 11760
    },
    {
      "epoch": 0.2353717553893533,
      "grad_norm": 0.15123499929904938,
      "learning_rate": 4.607947046354438e-05,
      "loss": 0.0614,
      "step": 11770
    },
    {
      "epoch": 0.23557173139223292,
      "grad_norm": 0.14117690920829773,
      "learning_rate": 4.607613753016305e-05,
      "loss": 0.0649,
      "step": 11780
    },
    {
      "epoch": 0.23577170739511258,
      "grad_norm": 0.11879003793001175,
      "learning_rate": 4.607280459678172e-05,
      "loss": 0.057,
      "step": 11790
    },
    {
      "epoch": 0.23597168339799224,
      "grad_norm": 0.12198492884635925,
      "learning_rate": 4.6069471663400396e-05,
      "loss": 0.0867,
      "step": 11800
    },
    {
      "epoch": 0.2361716594008719,
      "grad_norm": 0.12298724055290222,
      "learning_rate": 4.6066138730019066e-05,
      "loss": 0.0924,
      "step": 11810
    },
    {
      "epoch": 0.23637163540375156,
      "grad_norm": 0.10410431772470474,
      "learning_rate": 4.6062805796637735e-05,
      "loss": 0.0872,
      "step": 11820
    },
    {
      "epoch": 0.23657161140663122,
      "grad_norm": 0.15204598009586334,
      "learning_rate": 4.605947286325641e-05,
      "loss": 0.0722,
      "step": 11830
    },
    {
      "epoch": 0.23677158740951085,
      "grad_norm": 0.14702771604061127,
      "learning_rate": 4.605613992987509e-05,
      "loss": 0.0617,
      "step": 11840
    },
    {
      "epoch": 0.2369715634123905,
      "grad_norm": 0.110091432929039,
      "learning_rate": 4.605280699649376e-05,
      "loss": 0.08,
      "step": 11850
    },
    {
      "epoch": 0.23717153941527017,
      "grad_norm": 0.15427711606025696,
      "learning_rate": 4.604947406311243e-05,
      "loss": 0.0888,
      "step": 11860
    },
    {
      "epoch": 0.23737151541814983,
      "grad_norm": 0.1854914277791977,
      "learning_rate": 4.6046141129731104e-05,
      "loss": 0.0905,
      "step": 11870
    },
    {
      "epoch": 0.23757149142102948,
      "grad_norm": 0.17716597020626068,
      "learning_rate": 4.604280819634977e-05,
      "loss": 0.0868,
      "step": 11880
    },
    {
      "epoch": 0.23777146742390914,
      "grad_norm": 0.07964497059583664,
      "learning_rate": 4.603947526296844e-05,
      "loss": 0.0437,
      "step": 11890
    },
    {
      "epoch": 0.23797144342678878,
      "grad_norm": 0.08858074247837067,
      "learning_rate": 4.603614232958712e-05,
      "loss": 0.065,
      "step": 11900
    },
    {
      "epoch": 0.23817141942966844,
      "grad_norm": 0.15155939757823944,
      "learning_rate": 4.603280939620579e-05,
      "loss": 0.0786,
      "step": 11910
    },
    {
      "epoch": 0.2383713954325481,
      "grad_norm": 0.1264711171388626,
      "learning_rate": 4.602947646282446e-05,
      "loss": 0.0797,
      "step": 11920
    },
    {
      "epoch": 0.23857137143542775,
      "grad_norm": 0.09350904822349548,
      "learning_rate": 4.6026143529443135e-05,
      "loss": 0.0813,
      "step": 11930
    },
    {
      "epoch": 0.2387713474383074,
      "grad_norm": 0.1160922721028328,
      "learning_rate": 4.602281059606181e-05,
      "loss": 0.0814,
      "step": 11940
    },
    {
      "epoch": 0.23897132344118704,
      "grad_norm": 0.12448910623788834,
      "learning_rate": 4.601947766268048e-05,
      "loss": 0.0915,
      "step": 11950
    },
    {
      "epoch": 0.2391712994440667,
      "grad_norm": 0.1250043362379074,
      "learning_rate": 4.601614472929916e-05,
      "loss": 0.0891,
      "step": 11960
    },
    {
      "epoch": 0.23937127544694636,
      "grad_norm": 0.14651428163051605,
      "learning_rate": 4.601281179591783e-05,
      "loss": 0.0821,
      "step": 11970
    },
    {
      "epoch": 0.23957125144982602,
      "grad_norm": 0.07647878676652908,
      "learning_rate": 4.6009478862536497e-05,
      "loss": 0.0723,
      "step": 11980
    },
    {
      "epoch": 0.23977122745270568,
      "grad_norm": 0.10586124658584595,
      "learning_rate": 4.600614592915517e-05,
      "loss": 0.0576,
      "step": 11990
    },
    {
      "epoch": 0.23997120345558534,
      "grad_norm": 0.1949082314968109,
      "learning_rate": 4.600281299577384e-05,
      "loss": 0.0918,
      "step": 12000
    },
    {
      "epoch": 0.24017117945846497,
      "grad_norm": 0.20677663385868073,
      "learning_rate": 4.599948006239251e-05,
      "loss": 0.0913,
      "step": 12010
    },
    {
      "epoch": 0.24037115546134463,
      "grad_norm": 0.11766922473907471,
      "learning_rate": 4.599614712901119e-05,
      "loss": 0.0571,
      "step": 12020
    },
    {
      "epoch": 0.2405711314642243,
      "grad_norm": 0.07635153084993362,
      "learning_rate": 4.599281419562986e-05,
      "loss": 0.1162,
      "step": 12030
    },
    {
      "epoch": 0.24077110746710395,
      "grad_norm": 0.10289810597896576,
      "learning_rate": 4.5989481262248535e-05,
      "loss": 0.0951,
      "step": 12040
    },
    {
      "epoch": 0.2409710834699836,
      "grad_norm": 0.18329551815986633,
      "learning_rate": 4.5986148328867204e-05,
      "loss": 0.0917,
      "step": 12050
    },
    {
      "epoch": 0.24117105947286327,
      "grad_norm": 0.0692296177148819,
      "learning_rate": 4.598281539548588e-05,
      "loss": 0.0858,
      "step": 12060
    },
    {
      "epoch": 0.2413710354757429,
      "grad_norm": 0.1569194197654724,
      "learning_rate": 4.597948246210455e-05,
      "loss": 0.082,
      "step": 12070
    },
    {
      "epoch": 0.24157101147862256,
      "grad_norm": 0.11479111015796661,
      "learning_rate": 4.597614952872322e-05,
      "loss": 0.0864,
      "step": 12080
    },
    {
      "epoch": 0.24177098748150222,
      "grad_norm": 0.14848753809928894,
      "learning_rate": 4.5972816595341896e-05,
      "loss": 0.0732,
      "step": 12090
    },
    {
      "epoch": 0.24197096348438188,
      "grad_norm": 0.06950994580984116,
      "learning_rate": 4.5969483661960566e-05,
      "loss": 0.0666,
      "step": 12100
    },
    {
      "epoch": 0.24217093948726154,
      "grad_norm": 0.09675636142492294,
      "learning_rate": 4.5966150728579235e-05,
      "loss": 0.0583,
      "step": 12110
    },
    {
      "epoch": 0.24237091549014117,
      "grad_norm": 0.052050378173589706,
      "learning_rate": 4.596281779519791e-05,
      "loss": 0.0672,
      "step": 12120
    },
    {
      "epoch": 0.24257089149302083,
      "grad_norm": 0.07130676507949829,
      "learning_rate": 4.595948486181658e-05,
      "loss": 0.0609,
      "step": 12130
    },
    {
      "epoch": 0.2427708674959005,
      "grad_norm": 0.1545201689004898,
      "learning_rate": 4.595615192843526e-05,
      "loss": 0.103,
      "step": 12140
    },
    {
      "epoch": 0.24297084349878015,
      "grad_norm": 0.0915013924241066,
      "learning_rate": 4.5952818995053934e-05,
      "loss": 0.0866,
      "step": 12150
    },
    {
      "epoch": 0.2431708195016598,
      "grad_norm": 0.16970597207546234,
      "learning_rate": 4.5949486061672604e-05,
      "loss": 0.0821,
      "step": 12160
    },
    {
      "epoch": 0.24337079550453947,
      "grad_norm": 0.17927022278308868,
      "learning_rate": 4.5946153128291273e-05,
      "loss": 0.1001,
      "step": 12170
    },
    {
      "epoch": 0.2435707715074191,
      "grad_norm": 0.08032652735710144,
      "learning_rate": 4.594282019490995e-05,
      "loss": 0.0681,
      "step": 12180
    },
    {
      "epoch": 0.24377074751029876,
      "grad_norm": 0.13494236767292023,
      "learning_rate": 4.593948726152862e-05,
      "loss": 0.1179,
      "step": 12190
    },
    {
      "epoch": 0.24397072351317842,
      "grad_norm": 0.16632135212421417,
      "learning_rate": 4.593615432814729e-05,
      "loss": 0.0909,
      "step": 12200
    },
    {
      "epoch": 0.24417069951605808,
      "grad_norm": 0.08435647934675217,
      "learning_rate": 4.5932821394765966e-05,
      "loss": 0.0612,
      "step": 12210
    },
    {
      "epoch": 0.24437067551893774,
      "grad_norm": 0.10341954976320267,
      "learning_rate": 4.5929488461384635e-05,
      "loss": 0.0664,
      "step": 12220
    },
    {
      "epoch": 0.2445706515218174,
      "grad_norm": 0.10872012376785278,
      "learning_rate": 4.5926155528003305e-05,
      "loss": 0.0932,
      "step": 12230
    },
    {
      "epoch": 0.24477062752469703,
      "grad_norm": 0.06993653625249863,
      "learning_rate": 4.592282259462198e-05,
      "loss": 0.0596,
      "step": 12240
    },
    {
      "epoch": 0.24497060352757669,
      "grad_norm": 0.10506793111562729,
      "learning_rate": 4.591948966124066e-05,
      "loss": 0.0814,
      "step": 12250
    },
    {
      "epoch": 0.24517057953045635,
      "grad_norm": 0.1059173047542572,
      "learning_rate": 4.591615672785933e-05,
      "loss": 0.0794,
      "step": 12260
    },
    {
      "epoch": 0.245370555533336,
      "grad_norm": 0.22829876840114594,
      "learning_rate": 4.5912823794478e-05,
      "loss": 0.076,
      "step": 12270
    },
    {
      "epoch": 0.24557053153621566,
      "grad_norm": 0.15552176535129547,
      "learning_rate": 4.590949086109667e-05,
      "loss": 0.0491,
      "step": 12280
    },
    {
      "epoch": 0.2457705075390953,
      "grad_norm": 0.1423410177230835,
      "learning_rate": 4.590615792771534e-05,
      "loss": 0.0507,
      "step": 12290
    },
    {
      "epoch": 0.24597048354197495,
      "grad_norm": 0.15878050029277802,
      "learning_rate": 4.590282499433401e-05,
      "loss": 0.0746,
      "step": 12300
    },
    {
      "epoch": 0.24617045954485461,
      "grad_norm": 0.13364467024803162,
      "learning_rate": 4.589949206095269e-05,
      "loss": 0.0958,
      "step": 12310
    },
    {
      "epoch": 0.24637043554773427,
      "grad_norm": 0.23408684134483337,
      "learning_rate": 4.589615912757136e-05,
      "loss": 0.1019,
      "step": 12320
    },
    {
      "epoch": 0.24657041155061393,
      "grad_norm": 0.06673078238964081,
      "learning_rate": 4.589282619419003e-05,
      "loss": 0.0768,
      "step": 12330
    },
    {
      "epoch": 0.2467703875534936,
      "grad_norm": 0.1800823211669922,
      "learning_rate": 4.5889493260808704e-05,
      "loss": 0.0802,
      "step": 12340
    },
    {
      "epoch": 0.24697036355637322,
      "grad_norm": 0.09493463486433029,
      "learning_rate": 4.588616032742738e-05,
      "loss": 0.0753,
      "step": 12350
    },
    {
      "epoch": 0.24717033955925288,
      "grad_norm": 0.07902420312166214,
      "learning_rate": 4.588282739404605e-05,
      "loss": 0.1107,
      "step": 12360
    },
    {
      "epoch": 0.24737031556213254,
      "grad_norm": 0.07942022383213043,
      "learning_rate": 4.587949446066473e-05,
      "loss": 0.0822,
      "step": 12370
    },
    {
      "epoch": 0.2475702915650122,
      "grad_norm": 0.12327796220779419,
      "learning_rate": 4.5876161527283396e-05,
      "loss": 0.0812,
      "step": 12380
    },
    {
      "epoch": 0.24777026756789186,
      "grad_norm": 0.08639124035835266,
      "learning_rate": 4.5872828593902066e-05,
      "loss": 0.081,
      "step": 12390
    },
    {
      "epoch": 0.24797024357077152,
      "grad_norm": 0.1320534348487854,
      "learning_rate": 4.586949566052074e-05,
      "loss": 0.0836,
      "step": 12400
    },
    {
      "epoch": 0.24817021957365115,
      "grad_norm": 0.0805651992559433,
      "learning_rate": 4.586616272713941e-05,
      "loss": 0.0547,
      "step": 12410
    },
    {
      "epoch": 0.2483701955765308,
      "grad_norm": 0.1640382707118988,
      "learning_rate": 4.586282979375808e-05,
      "loss": 0.0587,
      "step": 12420
    },
    {
      "epoch": 0.24857017157941047,
      "grad_norm": 0.10069623589515686,
      "learning_rate": 4.585949686037676e-05,
      "loss": 0.0673,
      "step": 12430
    },
    {
      "epoch": 0.24877014758229013,
      "grad_norm": 0.06009780243039131,
      "learning_rate": 4.585616392699543e-05,
      "loss": 0.1004,
      "step": 12440
    },
    {
      "epoch": 0.2489701235851698,
      "grad_norm": 0.10203126072883606,
      "learning_rate": 4.5852830993614104e-05,
      "loss": 0.0531,
      "step": 12450
    },
    {
      "epoch": 0.24917009958804942,
      "grad_norm": 0.15982884168624878,
      "learning_rate": 4.5849498060232774e-05,
      "loss": 0.0634,
      "step": 12460
    },
    {
      "epoch": 0.24937007559092908,
      "grad_norm": 0.10152517259120941,
      "learning_rate": 4.584616512685145e-05,
      "loss": 0.0659,
      "step": 12470
    },
    {
      "epoch": 0.24957005159380874,
      "grad_norm": 0.10381334275007248,
      "learning_rate": 4.584283219347012e-05,
      "loss": 0.0768,
      "step": 12480
    },
    {
      "epoch": 0.2497700275966884,
      "grad_norm": 0.1499212384223938,
      "learning_rate": 4.583949926008879e-05,
      "loss": 0.0894,
      "step": 12490
    },
    {
      "epoch": 0.24997000359956806,
      "grad_norm": 0.1124415397644043,
      "learning_rate": 4.5836166326707466e-05,
      "loss": 0.1154,
      "step": 12500
    },
    {
      "epoch": 0.2501699796024477,
      "grad_norm": 0.11906880140304565,
      "learning_rate": 4.5832833393326135e-05,
      "loss": 0.0707,
      "step": 12510
    },
    {
      "epoch": 0.2503699556053274,
      "grad_norm": 0.16219279170036316,
      "learning_rate": 4.5829500459944805e-05,
      "loss": 0.1071,
      "step": 12520
    },
    {
      "epoch": 0.250569931608207,
      "grad_norm": 0.09451179951429367,
      "learning_rate": 4.582616752656348e-05,
      "loss": 0.0933,
      "step": 12530
    },
    {
      "epoch": 0.2507699076110867,
      "grad_norm": 0.09831549972295761,
      "learning_rate": 4.582283459318215e-05,
      "loss": 0.1048,
      "step": 12540
    },
    {
      "epoch": 0.2509698836139663,
      "grad_norm": 0.14062923192977905,
      "learning_rate": 4.581950165980083e-05,
      "loss": 0.0988,
      "step": 12550
    },
    {
      "epoch": 0.25116985961684596,
      "grad_norm": 0.09723260998725891,
      "learning_rate": 4.5816168726419504e-05,
      "loss": 0.0676,
      "step": 12560
    },
    {
      "epoch": 0.25136983561972565,
      "grad_norm": 0.16426266729831696,
      "learning_rate": 4.581283579303817e-05,
      "loss": 0.0912,
      "step": 12570
    },
    {
      "epoch": 0.2515698116226053,
      "grad_norm": 0.06313051283359528,
      "learning_rate": 4.580950285965684e-05,
      "loss": 0.0617,
      "step": 12580
    },
    {
      "epoch": 0.25176978762548496,
      "grad_norm": 0.11342702805995941,
      "learning_rate": 4.580616992627552e-05,
      "loss": 0.0914,
      "step": 12590
    },
    {
      "epoch": 0.2519697636283646,
      "grad_norm": 0.195522278547287,
      "learning_rate": 4.580283699289419e-05,
      "loss": 0.1078,
      "step": 12600
    },
    {
      "epoch": 0.2521697396312442,
      "grad_norm": 0.04352579265832901,
      "learning_rate": 4.579950405951286e-05,
      "loss": 0.0613,
      "step": 12610
    },
    {
      "epoch": 0.2523697156341239,
      "grad_norm": 0.16213391721248627,
      "learning_rate": 4.5796171126131535e-05,
      "loss": 0.104,
      "step": 12620
    },
    {
      "epoch": 0.25256969163700355,
      "grad_norm": 0.10991089046001434,
      "learning_rate": 4.5792838192750205e-05,
      "loss": 0.0671,
      "step": 12630
    },
    {
      "epoch": 0.25276966763988323,
      "grad_norm": 0.07174990326166153,
      "learning_rate": 4.5789505259368874e-05,
      "loss": 0.108,
      "step": 12640
    },
    {
      "epoch": 0.25296964364276286,
      "grad_norm": 0.10271620005369186,
      "learning_rate": 4.578617232598755e-05,
      "loss": 0.1142,
      "step": 12650
    },
    {
      "epoch": 0.2531696196456425,
      "grad_norm": 0.18322432041168213,
      "learning_rate": 4.578283939260623e-05,
      "loss": 0.0787,
      "step": 12660
    },
    {
      "epoch": 0.2533695956485222,
      "grad_norm": 0.09499047696590424,
      "learning_rate": 4.5779506459224897e-05,
      "loss": 0.1167,
      "step": 12670
    },
    {
      "epoch": 0.2535695716514018,
      "grad_norm": 0.13560113310813904,
      "learning_rate": 4.5776173525843566e-05,
      "loss": 0.0749,
      "step": 12680
    },
    {
      "epoch": 0.2537695476542815,
      "grad_norm": 0.17944347858428955,
      "learning_rate": 4.577284059246224e-05,
      "loss": 0.0585,
      "step": 12690
    },
    {
      "epoch": 0.25396952365716113,
      "grad_norm": 0.12932737171649933,
      "learning_rate": 4.576950765908091e-05,
      "loss": 0.0585,
      "step": 12700
    },
    {
      "epoch": 0.2541694996600408,
      "grad_norm": 0.18176427483558655,
      "learning_rate": 4.576617472569958e-05,
      "loss": 0.0988,
      "step": 12710
    },
    {
      "epoch": 0.25436947566292045,
      "grad_norm": 0.15103571116924286,
      "learning_rate": 4.576284179231826e-05,
      "loss": 0.0918,
      "step": 12720
    },
    {
      "epoch": 0.2545694516658001,
      "grad_norm": 0.06835024803876877,
      "learning_rate": 4.575950885893693e-05,
      "loss": 0.0717,
      "step": 12730
    },
    {
      "epoch": 0.25476942766867977,
      "grad_norm": 0.12781894207000732,
      "learning_rate": 4.57561759255556e-05,
      "loss": 0.0992,
      "step": 12740
    },
    {
      "epoch": 0.2549694036715594,
      "grad_norm": 0.16664034128189087,
      "learning_rate": 4.575284299217428e-05,
      "loss": 0.0933,
      "step": 12750
    },
    {
      "epoch": 0.2551693796744391,
      "grad_norm": 0.08780322223901749,
      "learning_rate": 4.574951005879295e-05,
      "loss": 0.0714,
      "step": 12760
    },
    {
      "epoch": 0.2553693556773187,
      "grad_norm": 0.2050013691186905,
      "learning_rate": 4.574617712541162e-05,
      "loss": 0.0676,
      "step": 12770
    },
    {
      "epoch": 0.25556933168019835,
      "grad_norm": 0.13879986107349396,
      "learning_rate": 4.5742844192030296e-05,
      "loss": 0.09,
      "step": 12780
    },
    {
      "epoch": 0.25576930768307804,
      "grad_norm": 0.13758805394172668,
      "learning_rate": 4.5739511258648966e-05,
      "loss": 0.0707,
      "step": 12790
    },
    {
      "epoch": 0.25596928368595767,
      "grad_norm": 0.15960747003555298,
      "learning_rate": 4.5736178325267635e-05,
      "loss": 0.1125,
      "step": 12800
    },
    {
      "epoch": 0.25616925968883736,
      "grad_norm": 0.2215038686990738,
      "learning_rate": 4.573284539188631e-05,
      "loss": 0.3327,
      "step": 12810
    },
    {
      "epoch": 0.256369235691717,
      "grad_norm": 0.19113735854625702,
      "learning_rate": 4.572951245850498e-05,
      "loss": 0.0744,
      "step": 12820
    },
    {
      "epoch": 0.2565692116945966,
      "grad_norm": 0.13272979855537415,
      "learning_rate": 4.572617952512365e-05,
      "loss": 0.0616,
      "step": 12830
    },
    {
      "epoch": 0.2567691876974763,
      "grad_norm": 0.14635628461837769,
      "learning_rate": 4.572284659174233e-05,
      "loss": 0.0996,
      "step": 12840
    },
    {
      "epoch": 0.25696916370035594,
      "grad_norm": 0.12118247896432877,
      "learning_rate": 4.5719513658361e-05,
      "loss": 0.0996,
      "step": 12850
    },
    {
      "epoch": 0.2571691397032356,
      "grad_norm": 0.12267035245895386,
      "learning_rate": 4.5716180724979673e-05,
      "loss": 0.0768,
      "step": 12860
    },
    {
      "epoch": 0.25736911570611526,
      "grad_norm": 0.10110431164503098,
      "learning_rate": 4.571284779159834e-05,
      "loss": 0.0616,
      "step": 12870
    },
    {
      "epoch": 0.25756909170899495,
      "grad_norm": 0.08574504405260086,
      "learning_rate": 4.570951485821702e-05,
      "loss": 0.0734,
      "step": 12880
    },
    {
      "epoch": 0.2577690677118746,
      "grad_norm": 0.09648288786411285,
      "learning_rate": 4.570618192483569e-05,
      "loss": 0.1058,
      "step": 12890
    },
    {
      "epoch": 0.2579690437147542,
      "grad_norm": 0.08171501755714417,
      "learning_rate": 4.570284899145436e-05,
      "loss": 0.0385,
      "step": 12900
    },
    {
      "epoch": 0.2581690197176339,
      "grad_norm": 0.14946971833705902,
      "learning_rate": 4.5699516058073035e-05,
      "loss": 0.0713,
      "step": 12910
    },
    {
      "epoch": 0.25836899572051353,
      "grad_norm": 0.17657290399074554,
      "learning_rate": 4.5696183124691705e-05,
      "loss": 0.1552,
      "step": 12920
    },
    {
      "epoch": 0.2585689717233932,
      "grad_norm": 0.15221914649009705,
      "learning_rate": 4.5692850191310374e-05,
      "loss": 0.1133,
      "step": 12930
    },
    {
      "epoch": 0.25876894772627285,
      "grad_norm": 0.1580951064825058,
      "learning_rate": 4.568951725792905e-05,
      "loss": 0.1083,
      "step": 12940
    },
    {
      "epoch": 0.2589689237291525,
      "grad_norm": 0.1968843787908554,
      "learning_rate": 4.568618432454772e-05,
      "loss": 0.1047,
      "step": 12950
    },
    {
      "epoch": 0.25916889973203217,
      "grad_norm": 0.14848320186138153,
      "learning_rate": 4.56828513911664e-05,
      "loss": 0.0675,
      "step": 12960
    },
    {
      "epoch": 0.2593688757349118,
      "grad_norm": 0.16055141389369965,
      "learning_rate": 4.567951845778507e-05,
      "loss": 0.0769,
      "step": 12970
    },
    {
      "epoch": 0.2595688517377915,
      "grad_norm": 0.11328542977571487,
      "learning_rate": 4.567618552440374e-05,
      "loss": 0.0591,
      "step": 12980
    },
    {
      "epoch": 0.2597688277406711,
      "grad_norm": 0.119608074426651,
      "learning_rate": 4.567285259102241e-05,
      "loss": 0.0735,
      "step": 12990
    },
    {
      "epoch": 0.25996880374355075,
      "grad_norm": 0.05768049135804176,
      "learning_rate": 4.566951965764109e-05,
      "loss": 0.1328,
      "step": 13000
    },
    {
      "epoch": 0.26016877974643043,
      "grad_norm": 0.16204017400741577,
      "learning_rate": 4.566618672425976e-05,
      "loss": 0.0535,
      "step": 13010
    },
    {
      "epoch": 0.26036875574931007,
      "grad_norm": 0.06690206378698349,
      "learning_rate": 4.566285379087843e-05,
      "loss": 0.0459,
      "step": 13020
    },
    {
      "epoch": 0.26056873175218975,
      "grad_norm": 0.17089679837226868,
      "learning_rate": 4.5659520857497104e-05,
      "loss": 0.1184,
      "step": 13030
    },
    {
      "epoch": 0.2607687077550694,
      "grad_norm": 0.06463563442230225,
      "learning_rate": 4.5656187924115774e-05,
      "loss": 0.0559,
      "step": 13040
    },
    {
      "epoch": 0.26096868375794907,
      "grad_norm": 0.07315722852945328,
      "learning_rate": 4.5652854990734444e-05,
      "loss": 0.0568,
      "step": 13050
    },
    {
      "epoch": 0.2611686597608287,
      "grad_norm": 0.11692392826080322,
      "learning_rate": 4.564952205735312e-05,
      "loss": 0.0948,
      "step": 13060
    },
    {
      "epoch": 0.26136863576370833,
      "grad_norm": 0.14257213473320007,
      "learning_rate": 4.5646189123971796e-05,
      "loss": 0.1181,
      "step": 13070
    },
    {
      "epoch": 0.261568611766588,
      "grad_norm": 0.07048133760690689,
      "learning_rate": 4.5642856190590466e-05,
      "loss": 0.0964,
      "step": 13080
    },
    {
      "epoch": 0.26176858776946765,
      "grad_norm": 0.08156528323888779,
      "learning_rate": 4.5639523257209136e-05,
      "loss": 0.1178,
      "step": 13090
    },
    {
      "epoch": 0.26196856377234734,
      "grad_norm": 0.19443804025650024,
      "learning_rate": 4.563619032382781e-05,
      "loss": 0.0815,
      "step": 13100
    },
    {
      "epoch": 0.26216853977522697,
      "grad_norm": 0.1851467490196228,
      "learning_rate": 4.563285739044648e-05,
      "loss": 0.0984,
      "step": 13110
    },
    {
      "epoch": 0.2623685157781066,
      "grad_norm": 0.10843094438314438,
      "learning_rate": 4.562952445706515e-05,
      "loss": 0.0917,
      "step": 13120
    },
    {
      "epoch": 0.2625684917809863,
      "grad_norm": 0.0662502571940422,
      "learning_rate": 4.562619152368383e-05,
      "loss": 0.0689,
      "step": 13130
    },
    {
      "epoch": 0.2627684677838659,
      "grad_norm": 0.17532281577587128,
      "learning_rate": 4.56228585903025e-05,
      "loss": 0.0885,
      "step": 13140
    },
    {
      "epoch": 0.2629684437867456,
      "grad_norm": 0.06632989645004272,
      "learning_rate": 4.561952565692117e-05,
      "loss": 0.0671,
      "step": 13150
    },
    {
      "epoch": 0.26316841978962524,
      "grad_norm": 0.1860606074333191,
      "learning_rate": 4.561619272353985e-05,
      "loss": 0.1102,
      "step": 13160
    },
    {
      "epoch": 0.2633683957925049,
      "grad_norm": 0.10002931207418442,
      "learning_rate": 4.561285979015852e-05,
      "loss": 0.0862,
      "step": 13170
    },
    {
      "epoch": 0.26356837179538456,
      "grad_norm": 0.16520999372005463,
      "learning_rate": 4.560952685677719e-05,
      "loss": 0.0853,
      "step": 13180
    },
    {
      "epoch": 0.2637683477982642,
      "grad_norm": 0.12641653418540955,
      "learning_rate": 4.5606193923395866e-05,
      "loss": 0.0823,
      "step": 13190
    },
    {
      "epoch": 0.2639683238011439,
      "grad_norm": 0.08112569898366928,
      "learning_rate": 4.5602860990014535e-05,
      "loss": 0.0959,
      "step": 13200
    },
    {
      "epoch": 0.2641682998040235,
      "grad_norm": 0.11975858360528946,
      "learning_rate": 4.5599528056633205e-05,
      "loss": 0.1002,
      "step": 13210
    },
    {
      "epoch": 0.2643682758069032,
      "grad_norm": 0.06325535476207733,
      "learning_rate": 4.559619512325188e-05,
      "loss": 0.0758,
      "step": 13220
    },
    {
      "epoch": 0.26456825180978283,
      "grad_norm": 0.11355915665626526,
      "learning_rate": 4.559286218987055e-05,
      "loss": 0.0617,
      "step": 13230
    },
    {
      "epoch": 0.26476822781266246,
      "grad_norm": 0.1309615671634674,
      "learning_rate": 4.558952925648922e-05,
      "loss": 0.073,
      "step": 13240
    },
    {
      "epoch": 0.26496820381554215,
      "grad_norm": 0.13784651458263397,
      "learning_rate": 4.55861963231079e-05,
      "loss": 0.0663,
      "step": 13250
    },
    {
      "epoch": 0.2651681798184218,
      "grad_norm": 0.18239548802375793,
      "learning_rate": 4.5582863389726567e-05,
      "loss": 0.0918,
      "step": 13260
    },
    {
      "epoch": 0.26536815582130147,
      "grad_norm": 0.16216973960399628,
      "learning_rate": 4.557953045634524e-05,
      "loss": 0.0975,
      "step": 13270
    },
    {
      "epoch": 0.2655681318241811,
      "grad_norm": 0.09897271543741226,
      "learning_rate": 4.557619752296391e-05,
      "loss": 0.0477,
      "step": 13280
    },
    {
      "epoch": 0.26576810782706073,
      "grad_norm": 0.14629128575325012,
      "learning_rate": 4.557286458958259e-05,
      "loss": 0.0677,
      "step": 13290
    },
    {
      "epoch": 0.2659680838299404,
      "grad_norm": 0.1326245218515396,
      "learning_rate": 4.556953165620126e-05,
      "loss": 0.1001,
      "step": 13300
    },
    {
      "epoch": 0.26616805983282005,
      "grad_norm": 0.10217706114053726,
      "learning_rate": 4.556619872281993e-05,
      "loss": 0.0817,
      "step": 13310
    },
    {
      "epoch": 0.26636803583569973,
      "grad_norm": 0.1299702227115631,
      "learning_rate": 4.5562865789438605e-05,
      "loss": 0.0618,
      "step": 13320
    },
    {
      "epoch": 0.26656801183857937,
      "grad_norm": 0.16786688566207886,
      "learning_rate": 4.5559532856057274e-05,
      "loss": 0.0961,
      "step": 13330
    },
    {
      "epoch": 0.266767987841459,
      "grad_norm": 0.06423480063676834,
      "learning_rate": 4.5556199922675944e-05,
      "loss": 0.108,
      "step": 13340
    },
    {
      "epoch": 0.2669679638443387,
      "grad_norm": 0.09611375629901886,
      "learning_rate": 4.555286698929462e-05,
      "loss": 0.0858,
      "step": 13350
    },
    {
      "epoch": 0.2671679398472183,
      "grad_norm": 0.18428635597229004,
      "learning_rate": 4.554953405591329e-05,
      "loss": 0.134,
      "step": 13360
    },
    {
      "epoch": 0.267367915850098,
      "grad_norm": 0.140594944357872,
      "learning_rate": 4.5546201122531966e-05,
      "loss": 0.0816,
      "step": 13370
    },
    {
      "epoch": 0.26756789185297764,
      "grad_norm": 0.09746012091636658,
      "learning_rate": 4.554286818915064e-05,
      "loss": 0.0557,
      "step": 13380
    },
    {
      "epoch": 0.2677678678558573,
      "grad_norm": 0.17164014279842377,
      "learning_rate": 4.553953525576931e-05,
      "loss": 0.0518,
      "step": 13390
    },
    {
      "epoch": 0.26796784385873695,
      "grad_norm": 0.08937951177358627,
      "learning_rate": 4.553620232238798e-05,
      "loss": 0.0744,
      "step": 13400
    },
    {
      "epoch": 0.2681678198616166,
      "grad_norm": 0.10110066831111908,
      "learning_rate": 4.553286938900666e-05,
      "loss": 0.1123,
      "step": 13410
    },
    {
      "epoch": 0.2683677958644963,
      "grad_norm": 0.09487117826938629,
      "learning_rate": 4.552953645562533e-05,
      "loss": 0.036,
      "step": 13420
    },
    {
      "epoch": 0.2685677718673759,
      "grad_norm": 0.1410437673330307,
      "learning_rate": 4.5526203522244e-05,
      "loss": 0.0866,
      "step": 13430
    },
    {
      "epoch": 0.2687677478702556,
      "grad_norm": 0.07768091559410095,
      "learning_rate": 4.5522870588862674e-05,
      "loss": 0.0798,
      "step": 13440
    },
    {
      "epoch": 0.2689677238731352,
      "grad_norm": 0.08697628974914551,
      "learning_rate": 4.5519537655481343e-05,
      "loss": 0.0659,
      "step": 13450
    },
    {
      "epoch": 0.26916769987601485,
      "grad_norm": 0.10997067391872406,
      "learning_rate": 4.551620472210001e-05,
      "loss": 0.0646,
      "step": 13460
    },
    {
      "epoch": 0.26936767587889454,
      "grad_norm": 0.1380244493484497,
      "learning_rate": 4.551287178871869e-05,
      "loss": 0.0845,
      "step": 13470
    },
    {
      "epoch": 0.2695676518817742,
      "grad_norm": 0.15100222826004028,
      "learning_rate": 4.5509538855337366e-05,
      "loss": 0.0856,
      "step": 13480
    },
    {
      "epoch": 0.26976762788465386,
      "grad_norm": 0.14899079501628876,
      "learning_rate": 4.5506205921956035e-05,
      "loss": 0.0891,
      "step": 13490
    },
    {
      "epoch": 0.2699676038875335,
      "grad_norm": 0.15186424553394318,
      "learning_rate": 4.5502872988574705e-05,
      "loss": 0.0717,
      "step": 13500
    },
    {
      "epoch": 0.2701675798904131,
      "grad_norm": 0.08235607296228409,
      "learning_rate": 4.549954005519338e-05,
      "loss": 0.0473,
      "step": 13510
    },
    {
      "epoch": 0.2703675558932928,
      "grad_norm": 0.07855095714330673,
      "learning_rate": 4.549620712181205e-05,
      "loss": 0.0528,
      "step": 13520
    },
    {
      "epoch": 0.27056753189617244,
      "grad_norm": 0.16448776423931122,
      "learning_rate": 4.549287418843072e-05,
      "loss": 0.1205,
      "step": 13530
    },
    {
      "epoch": 0.27076750789905213,
      "grad_norm": 0.1276785284280777,
      "learning_rate": 4.54895412550494e-05,
      "loss": 0.0783,
      "step": 13540
    },
    {
      "epoch": 0.27096748390193176,
      "grad_norm": 0.12876920402050018,
      "learning_rate": 4.548620832166807e-05,
      "loss": 0.0932,
      "step": 13550
    },
    {
      "epoch": 0.27116745990481145,
      "grad_norm": 0.1117299422621727,
      "learning_rate": 4.5482875388286736e-05,
      "loss": 0.1313,
      "step": 13560
    },
    {
      "epoch": 0.2713674359076911,
      "grad_norm": 0.1493796706199646,
      "learning_rate": 4.547954245490541e-05,
      "loss": 0.0778,
      "step": 13570
    },
    {
      "epoch": 0.2715674119105707,
      "grad_norm": 0.07385299354791641,
      "learning_rate": 4.547620952152409e-05,
      "loss": 0.073,
      "step": 13580
    },
    {
      "epoch": 0.2717673879134504,
      "grad_norm": 0.15697874128818512,
      "learning_rate": 4.547287658814276e-05,
      "loss": 0.0631,
      "step": 13590
    },
    {
      "epoch": 0.27196736391633003,
      "grad_norm": 0.09739609062671661,
      "learning_rate": 4.546954365476143e-05,
      "loss": 0.08,
      "step": 13600
    },
    {
      "epoch": 0.2721673399192097,
      "grad_norm": 0.1481143832206726,
      "learning_rate": 4.5466210721380105e-05,
      "loss": 0.0901,
      "step": 13610
    },
    {
      "epoch": 0.27236731592208935,
      "grad_norm": 0.147789865732193,
      "learning_rate": 4.5462877787998774e-05,
      "loss": 0.0743,
      "step": 13620
    },
    {
      "epoch": 0.272567291924969,
      "grad_norm": 0.06421057879924774,
      "learning_rate": 4.545954485461745e-05,
      "loss": 0.0785,
      "step": 13630
    },
    {
      "epoch": 0.27276726792784867,
      "grad_norm": 0.20947182178497314,
      "learning_rate": 4.545621192123612e-05,
      "loss": 0.0811,
      "step": 13640
    },
    {
      "epoch": 0.2729672439307283,
      "grad_norm": 0.08978728950023651,
      "learning_rate": 4.545287898785479e-05,
      "loss": 0.0646,
      "step": 13650
    },
    {
      "epoch": 0.273167219933608,
      "grad_norm": 0.07611938565969467,
      "learning_rate": 4.5449546054473466e-05,
      "loss": 0.0994,
      "step": 13660
    },
    {
      "epoch": 0.2733671959364876,
      "grad_norm": 0.07733873277902603,
      "learning_rate": 4.544621312109214e-05,
      "loss": 0.1039,
      "step": 13670
    },
    {
      "epoch": 0.27356717193936725,
      "grad_norm": 0.08828481286764145,
      "learning_rate": 4.544288018771081e-05,
      "loss": 0.0871,
      "step": 13680
    },
    {
      "epoch": 0.27376714794224694,
      "grad_norm": 0.08816534280776978,
      "learning_rate": 4.543954725432948e-05,
      "loss": 0.0894,
      "step": 13690
    },
    {
      "epoch": 0.27396712394512657,
      "grad_norm": 0.0621679425239563,
      "learning_rate": 4.543621432094816e-05,
      "loss": 0.0716,
      "step": 13700
    },
    {
      "epoch": 0.27416709994800625,
      "grad_norm": 0.087357297539711,
      "learning_rate": 4.543288138756683e-05,
      "loss": 0.0984,
      "step": 13710
    },
    {
      "epoch": 0.2743670759508859,
      "grad_norm": 0.15872463583946228,
      "learning_rate": 4.54295484541855e-05,
      "loss": 0.0694,
      "step": 13720
    },
    {
      "epoch": 0.2745670519537656,
      "grad_norm": 0.22286708652973175,
      "learning_rate": 4.5426215520804174e-05,
      "loss": 0.0953,
      "step": 13730
    },
    {
      "epoch": 0.2747670279566452,
      "grad_norm": 0.05873242765665054,
      "learning_rate": 4.5422882587422844e-05,
      "loss": 0.0572,
      "step": 13740
    },
    {
      "epoch": 0.27496700395952484,
      "grad_norm": 0.17195968329906464,
      "learning_rate": 4.541954965404151e-05,
      "loss": 0.0801,
      "step": 13750
    },
    {
      "epoch": 0.2751669799624045,
      "grad_norm": 0.0855385884642601,
      "learning_rate": 4.541621672066019e-05,
      "loss": 0.0702,
      "step": 13760
    },
    {
      "epoch": 0.27536695596528415,
      "grad_norm": 0.12703481316566467,
      "learning_rate": 4.541288378727886e-05,
      "loss": 0.062,
      "step": 13770
    },
    {
      "epoch": 0.27556693196816384,
      "grad_norm": 0.08710359781980515,
      "learning_rate": 4.5409550853897536e-05,
      "loss": 0.0666,
      "step": 13780
    },
    {
      "epoch": 0.2757669079710435,
      "grad_norm": 0.14214448630809784,
      "learning_rate": 4.5406217920516205e-05,
      "loss": 0.0594,
      "step": 13790
    },
    {
      "epoch": 0.2759668839739231,
      "grad_norm": 0.11278467625379562,
      "learning_rate": 4.540288498713488e-05,
      "loss": 0.0504,
      "step": 13800
    },
    {
      "epoch": 0.2761668599768028,
      "grad_norm": 0.16689662635326385,
      "learning_rate": 4.539955205375355e-05,
      "loss": 0.0909,
      "step": 13810
    },
    {
      "epoch": 0.2763668359796824,
      "grad_norm": 0.08654666692018509,
      "learning_rate": 4.539621912037222e-05,
      "loss": 0.0766,
      "step": 13820
    },
    {
      "epoch": 0.2765668119825621,
      "grad_norm": 0.08270096778869629,
      "learning_rate": 4.53928861869909e-05,
      "loss": 0.0967,
      "step": 13830
    },
    {
      "epoch": 0.27676678798544174,
      "grad_norm": 0.13317759335041046,
      "learning_rate": 4.538955325360957e-05,
      "loss": 0.0872,
      "step": 13840
    },
    {
      "epoch": 0.2769667639883214,
      "grad_norm": 0.17771245539188385,
      "learning_rate": 4.5386220320228237e-05,
      "loss": 0.0673,
      "step": 13850
    },
    {
      "epoch": 0.27716673999120106,
      "grad_norm": 0.11114978790283203,
      "learning_rate": 4.538288738684691e-05,
      "loss": 0.093,
      "step": 13860
    },
    {
      "epoch": 0.2773667159940807,
      "grad_norm": 0.19604967534542084,
      "learning_rate": 4.537955445346558e-05,
      "loss": 0.0888,
      "step": 13870
    },
    {
      "epoch": 0.2775666919969604,
      "grad_norm": 0.14794039726257324,
      "learning_rate": 4.537622152008426e-05,
      "loss": 0.0639,
      "step": 13880
    },
    {
      "epoch": 0.27776666799984,
      "grad_norm": 0.1623731106519699,
      "learning_rate": 4.5372888586702935e-05,
      "loss": 0.0979,
      "step": 13890
    },
    {
      "epoch": 0.2779666440027197,
      "grad_norm": 0.08157781511545181,
      "learning_rate": 4.5369555653321605e-05,
      "loss": 0.0863,
      "step": 13900
    },
    {
      "epoch": 0.27816662000559933,
      "grad_norm": 0.10263818502426147,
      "learning_rate": 4.5366222719940275e-05,
      "loss": 0.0917,
      "step": 13910
    },
    {
      "epoch": 0.27836659600847896,
      "grad_norm": 0.14997415244579315,
      "learning_rate": 4.536288978655895e-05,
      "loss": 0.1063,
      "step": 13920
    },
    {
      "epoch": 0.27856657201135865,
      "grad_norm": 0.10423517227172852,
      "learning_rate": 4.535955685317762e-05,
      "loss": 0.117,
      "step": 13930
    },
    {
      "epoch": 0.2787665480142383,
      "grad_norm": 0.08009976148605347,
      "learning_rate": 4.535622391979629e-05,
      "loss": 0.0623,
      "step": 13940
    },
    {
      "epoch": 0.27896652401711797,
      "grad_norm": 0.10770529508590698,
      "learning_rate": 4.5352890986414967e-05,
      "loss": 0.1012,
      "step": 13950
    },
    {
      "epoch": 0.2791665000199976,
      "grad_norm": 0.11204152554273605,
      "learning_rate": 4.5349558053033636e-05,
      "loss": 0.0849,
      "step": 13960
    },
    {
      "epoch": 0.27936647602287723,
      "grad_norm": 0.1448361575603485,
      "learning_rate": 4.5346225119652306e-05,
      "loss": 0.0731,
      "step": 13970
    },
    {
      "epoch": 0.2795664520257569,
      "grad_norm": 0.1869506686925888,
      "learning_rate": 4.534289218627098e-05,
      "loss": 0.0827,
      "step": 13980
    },
    {
      "epoch": 0.27976642802863655,
      "grad_norm": 0.13193638622760773,
      "learning_rate": 4.533955925288966e-05,
      "loss": 0.0974,
      "step": 13990
    },
    {
      "epoch": 0.27996640403151624,
      "grad_norm": 0.13669757544994354,
      "learning_rate": 4.533622631950833e-05,
      "loss": 0.0681,
      "step": 14000
    },
    {
      "epoch": 0.28016638003439587,
      "grad_norm": 0.11997279524803162,
      "learning_rate": 4.5332893386127e-05,
      "loss": 0.074,
      "step": 14010
    },
    {
      "epoch": 0.2803663560372755,
      "grad_norm": 0.11055401712656021,
      "learning_rate": 4.5329560452745674e-05,
      "loss": 0.0616,
      "step": 14020
    },
    {
      "epoch": 0.2805663320401552,
      "grad_norm": 0.20913085341453552,
      "learning_rate": 4.5326227519364344e-05,
      "loss": 0.1091,
      "step": 14030
    },
    {
      "epoch": 0.2807663080430348,
      "grad_norm": 0.1890796720981598,
      "learning_rate": 4.5322894585983013e-05,
      "loss": 0.1092,
      "step": 14040
    },
    {
      "epoch": 0.2809662840459145,
      "grad_norm": 0.08962832391262054,
      "learning_rate": 4.531956165260169e-05,
      "loss": 0.0563,
      "step": 14050
    },
    {
      "epoch": 0.28116626004879414,
      "grad_norm": 0.12369496375322342,
      "learning_rate": 4.531622871922036e-05,
      "loss": 0.081,
      "step": 14060
    },
    {
      "epoch": 0.2813662360516738,
      "grad_norm": 0.14996540546417236,
      "learning_rate": 4.531289578583903e-05,
      "loss": 0.0961,
      "step": 14070
    },
    {
      "epoch": 0.28156621205455346,
      "grad_norm": 0.13010641932487488,
      "learning_rate": 4.530956285245771e-05,
      "loss": 0.0756,
      "step": 14080
    },
    {
      "epoch": 0.2817661880574331,
      "grad_norm": 0.14620915055274963,
      "learning_rate": 4.530622991907638e-05,
      "loss": 0.1034,
      "step": 14090
    },
    {
      "epoch": 0.2819661640603128,
      "grad_norm": 0.11148379743099213,
      "learning_rate": 4.530289698569505e-05,
      "loss": 0.0737,
      "step": 14100
    },
    {
      "epoch": 0.2821661400631924,
      "grad_norm": 0.10115381330251694,
      "learning_rate": 4.529956405231373e-05,
      "loss": 0.0564,
      "step": 14110
    },
    {
      "epoch": 0.2823661160660721,
      "grad_norm": 0.09928631782531738,
      "learning_rate": 4.52962311189324e-05,
      "loss": 0.0855,
      "step": 14120
    },
    {
      "epoch": 0.2825660920689517,
      "grad_norm": 0.1371624618768692,
      "learning_rate": 4.529289818555107e-05,
      "loss": 0.1239,
      "step": 14130
    },
    {
      "epoch": 0.28276606807183136,
      "grad_norm": 0.11654035747051239,
      "learning_rate": 4.5289565252169743e-05,
      "loss": 0.1158,
      "step": 14140
    },
    {
      "epoch": 0.28296604407471104,
      "grad_norm": 0.09644632786512375,
      "learning_rate": 4.528623231878841e-05,
      "loss": 0.0777,
      "step": 14150
    },
    {
      "epoch": 0.2831660200775907,
      "grad_norm": 0.1843784600496292,
      "learning_rate": 4.528289938540708e-05,
      "loss": 0.0994,
      "step": 14160
    },
    {
      "epoch": 0.28336599608047036,
      "grad_norm": 0.05515194311738014,
      "learning_rate": 4.527956645202576e-05,
      "loss": 0.0602,
      "step": 14170
    },
    {
      "epoch": 0.28356597208335,
      "grad_norm": 0.09695183485746384,
      "learning_rate": 4.5276233518644435e-05,
      "loss": 0.078,
      "step": 14180
    },
    {
      "epoch": 0.2837659480862297,
      "grad_norm": 0.05575692281126976,
      "learning_rate": 4.5272900585263105e-05,
      "loss": 0.0833,
      "step": 14190
    },
    {
      "epoch": 0.2839659240891093,
      "grad_norm": 0.07521317899227142,
      "learning_rate": 4.5269567651881775e-05,
      "loss": 0.0826,
      "step": 14200
    },
    {
      "epoch": 0.28416590009198894,
      "grad_norm": 0.19637931883335114,
      "learning_rate": 4.526623471850045e-05,
      "loss": 0.093,
      "step": 14210
    },
    {
      "epoch": 0.28436587609486863,
      "grad_norm": 0.07305237650871277,
      "learning_rate": 4.526290178511912e-05,
      "loss": 0.0685,
      "step": 14220
    },
    {
      "epoch": 0.28456585209774826,
      "grad_norm": 0.15131588280200958,
      "learning_rate": 4.525956885173779e-05,
      "loss": 0.1084,
      "step": 14230
    },
    {
      "epoch": 0.28476582810062795,
      "grad_norm": 0.08880506455898285,
      "learning_rate": 4.525623591835647e-05,
      "loss": 0.068,
      "step": 14240
    },
    {
      "epoch": 0.2849658041035076,
      "grad_norm": 0.12563444674015045,
      "learning_rate": 4.5252902984975136e-05,
      "loss": 0.0421,
      "step": 14250
    },
    {
      "epoch": 0.2851657801063872,
      "grad_norm": 0.12019255757331848,
      "learning_rate": 4.5249570051593806e-05,
      "loss": 0.0705,
      "step": 14260
    },
    {
      "epoch": 0.2853657561092669,
      "grad_norm": 0.190172478556633,
      "learning_rate": 4.524623711821248e-05,
      "loss": 0.1073,
      "step": 14270
    },
    {
      "epoch": 0.28556573211214653,
      "grad_norm": 0.15395720303058624,
      "learning_rate": 4.524290418483115e-05,
      "loss": 0.0828,
      "step": 14280
    },
    {
      "epoch": 0.2857657081150262,
      "grad_norm": 0.06297784298658371,
      "learning_rate": 4.523957125144983e-05,
      "loss": 0.0586,
      "step": 14290
    },
    {
      "epoch": 0.28596568411790585,
      "grad_norm": 0.1663609743118286,
      "learning_rate": 4.5236238318068505e-05,
      "loss": 0.0641,
      "step": 14300
    },
    {
      "epoch": 0.2861656601207855,
      "grad_norm": 0.23276717960834503,
      "learning_rate": 4.5232905384687174e-05,
      "loss": 0.1013,
      "step": 14310
    },
    {
      "epoch": 0.28636563612366517,
      "grad_norm": 0.187546506524086,
      "learning_rate": 4.5229572451305844e-05,
      "loss": 0.0881,
      "step": 14320
    },
    {
      "epoch": 0.2865656121265448,
      "grad_norm": 0.22426997125148773,
      "learning_rate": 4.522623951792452e-05,
      "loss": 0.0879,
      "step": 14330
    },
    {
      "epoch": 0.2867655881294245,
      "grad_norm": 0.1772635579109192,
      "learning_rate": 4.522290658454319e-05,
      "loss": 0.0669,
      "step": 14340
    },
    {
      "epoch": 0.2869655641323041,
      "grad_norm": 0.10978659242391586,
      "learning_rate": 4.521957365116186e-05,
      "loss": 0.0911,
      "step": 14350
    },
    {
      "epoch": 0.2871655401351838,
      "grad_norm": 0.16976937651634216,
      "learning_rate": 4.5216240717780536e-05,
      "loss": 0.0724,
      "step": 14360
    },
    {
      "epoch": 0.28736551613806344,
      "grad_norm": 0.11211501061916351,
      "learning_rate": 4.5212907784399206e-05,
      "loss": 0.0863,
      "step": 14370
    },
    {
      "epoch": 0.28756549214094307,
      "grad_norm": 0.162245512008667,
      "learning_rate": 4.5209574851017875e-05,
      "loss": 0.0545,
      "step": 14380
    },
    {
      "epoch": 0.28776546814382276,
      "grad_norm": 0.1576404571533203,
      "learning_rate": 4.520624191763655e-05,
      "loss": 0.0667,
      "step": 14390
    },
    {
      "epoch": 0.2879654441467024,
      "grad_norm": 0.18696044385433197,
      "learning_rate": 4.520290898425523e-05,
      "loss": 0.0723,
      "step": 14400
    },
    {
      "epoch": 0.2881654201495821,
      "grad_norm": 0.12241850793361664,
      "learning_rate": 4.51995760508739e-05,
      "loss": 0.0981,
      "step": 14410
    },
    {
      "epoch": 0.2883653961524617,
      "grad_norm": 0.1391100436449051,
      "learning_rate": 4.519624311749257e-05,
      "loss": 0.1014,
      "step": 14420
    },
    {
      "epoch": 0.28856537215534134,
      "grad_norm": 0.1594936102628708,
      "learning_rate": 4.5192910184111244e-05,
      "loss": 0.1172,
      "step": 14430
    },
    {
      "epoch": 0.288765348158221,
      "grad_norm": 0.13414336740970612,
      "learning_rate": 4.518957725072991e-05,
      "loss": 0.0699,
      "step": 14440
    },
    {
      "epoch": 0.28896532416110066,
      "grad_norm": 0.08204855024814606,
      "learning_rate": 4.518624431734858e-05,
      "loss": 0.0878,
      "step": 14450
    },
    {
      "epoch": 0.28916530016398034,
      "grad_norm": 0.12937282025814056,
      "learning_rate": 4.518291138396726e-05,
      "loss": 0.0695,
      "step": 14460
    },
    {
      "epoch": 0.28936527616686,
      "grad_norm": 0.18637238442897797,
      "learning_rate": 4.517957845058593e-05,
      "loss": 0.1035,
      "step": 14470
    },
    {
      "epoch": 0.2895652521697396,
      "grad_norm": 0.20821411907672882,
      "learning_rate": 4.51762455172046e-05,
      "loss": 0.0637,
      "step": 14480
    },
    {
      "epoch": 0.2897652281726193,
      "grad_norm": 0.11429175734519958,
      "learning_rate": 4.517291258382328e-05,
      "loss": 0.0712,
      "step": 14490
    },
    {
      "epoch": 0.2899652041754989,
      "grad_norm": 0.11889401078224182,
      "learning_rate": 4.516957965044195e-05,
      "loss": 0.0677,
      "step": 14500
    },
    {
      "epoch": 0.2901651801783786,
      "grad_norm": 0.10741648077964783,
      "learning_rate": 4.516624671706062e-05,
      "loss": 0.077,
      "step": 14510
    },
    {
      "epoch": 0.29036515618125824,
      "grad_norm": 0.08829330652952194,
      "learning_rate": 4.51629137836793e-05,
      "loss": 0.0779,
      "step": 14520
    },
    {
      "epoch": 0.29056513218413793,
      "grad_norm": 0.19766798615455627,
      "learning_rate": 4.515958085029797e-05,
      "loss": 0.0815,
      "step": 14530
    },
    {
      "epoch": 0.29076510818701756,
      "grad_norm": 0.1730974316596985,
      "learning_rate": 4.5156247916916637e-05,
      "loss": 0.0833,
      "step": 14540
    },
    {
      "epoch": 0.2909650841898972,
      "grad_norm": 0.10174860805273056,
      "learning_rate": 4.515291498353531e-05,
      "loss": 0.3065,
      "step": 14550
    },
    {
      "epoch": 0.2911650601927769,
      "grad_norm": 0.09619923681020737,
      "learning_rate": 4.514958205015398e-05,
      "loss": 0.0465,
      "step": 14560
    },
    {
      "epoch": 0.2913650361956565,
      "grad_norm": 0.10399091243743896,
      "learning_rate": 4.514624911677265e-05,
      "loss": 0.061,
      "step": 14570
    },
    {
      "epoch": 0.2915650121985362,
      "grad_norm": 0.12501855194568634,
      "learning_rate": 4.514291618339133e-05,
      "loss": 0.0932,
      "step": 14580
    },
    {
      "epoch": 0.29176498820141583,
      "grad_norm": 0.20401807129383087,
      "learning_rate": 4.5139583250010005e-05,
      "loss": 0.1167,
      "step": 14590
    },
    {
      "epoch": 0.29196496420429546,
      "grad_norm": 0.09558036923408508,
      "learning_rate": 4.5136250316628675e-05,
      "loss": 0.0746,
      "step": 14600
    },
    {
      "epoch": 0.29216494020717515,
      "grad_norm": 0.16864106059074402,
      "learning_rate": 4.5132917383247344e-05,
      "loss": 0.0775,
      "step": 14610
    },
    {
      "epoch": 0.2923649162100548,
      "grad_norm": 0.09687743335962296,
      "learning_rate": 4.512958444986602e-05,
      "loss": 0.0633,
      "step": 14620
    },
    {
      "epoch": 0.29256489221293447,
      "grad_norm": 0.08702052384614944,
      "learning_rate": 4.512625151648469e-05,
      "loss": 0.0953,
      "step": 14630
    },
    {
      "epoch": 0.2927648682158141,
      "grad_norm": 0.13820789754390717,
      "learning_rate": 4.512291858310336e-05,
      "loss": 0.0671,
      "step": 14640
    },
    {
      "epoch": 0.29296484421869373,
      "grad_norm": 0.07294619083404541,
      "learning_rate": 4.5119585649722036e-05,
      "loss": 0.0509,
      "step": 14650
    },
    {
      "epoch": 0.2931648202215734,
      "grad_norm": 0.22411847114562988,
      "learning_rate": 4.5116252716340706e-05,
      "loss": 0.0811,
      "step": 14660
    },
    {
      "epoch": 0.29336479622445305,
      "grad_norm": 0.10720919817686081,
      "learning_rate": 4.5112919782959375e-05,
      "loss": 0.2742,
      "step": 14670
    },
    {
      "epoch": 0.29356477222733274,
      "grad_norm": 0.08033624291419983,
      "learning_rate": 4.510958684957805e-05,
      "loss": 0.0731,
      "step": 14680
    },
    {
      "epoch": 0.29376474823021237,
      "grad_norm": 0.22665518522262573,
      "learning_rate": 4.510625391619673e-05,
      "loss": 0.0948,
      "step": 14690
    },
    {
      "epoch": 0.29396472423309206,
      "grad_norm": 0.09006612747907639,
      "learning_rate": 4.51029209828154e-05,
      "loss": 0.0725,
      "step": 14700
    },
    {
      "epoch": 0.2941647002359717,
      "grad_norm": 0.06462610512971878,
      "learning_rate": 4.5099588049434074e-05,
      "loss": 0.0706,
      "step": 14710
    },
    {
      "epoch": 0.2943646762388513,
      "grad_norm": 0.14931736886501312,
      "learning_rate": 4.5096255116052744e-05,
      "loss": 0.0855,
      "step": 14720
    },
    {
      "epoch": 0.294564652241731,
      "grad_norm": 0.09377628564834595,
      "learning_rate": 4.5092922182671413e-05,
      "loss": 0.1061,
      "step": 14730
    },
    {
      "epoch": 0.29476462824461064,
      "grad_norm": 0.0966879203915596,
      "learning_rate": 4.508958924929009e-05,
      "loss": 0.1053,
      "step": 14740
    },
    {
      "epoch": 0.2949646042474903,
      "grad_norm": 0.1988658756017685,
      "learning_rate": 4.508625631590876e-05,
      "loss": 0.0787,
      "step": 14750
    },
    {
      "epoch": 0.29516458025036996,
      "grad_norm": 0.10004904866218567,
      "learning_rate": 4.508292338252743e-05,
      "loss": 0.0769,
      "step": 14760
    },
    {
      "epoch": 0.2953645562532496,
      "grad_norm": 0.1795569509267807,
      "learning_rate": 4.5079590449146105e-05,
      "loss": 0.0945,
      "step": 14770
    },
    {
      "epoch": 0.2955645322561293,
      "grad_norm": 0.060308169573545456,
      "learning_rate": 4.5076257515764775e-05,
      "loss": 0.0417,
      "step": 14780
    },
    {
      "epoch": 0.2957645082590089,
      "grad_norm": 0.07861779630184174,
      "learning_rate": 4.5072924582383445e-05,
      "loss": 0.0619,
      "step": 14790
    },
    {
      "epoch": 0.2959644842618886,
      "grad_norm": 0.08009718358516693,
      "learning_rate": 4.506959164900212e-05,
      "loss": 0.0447,
      "step": 14800
    },
    {
      "epoch": 0.2961644602647682,
      "grad_norm": 0.09878809750080109,
      "learning_rate": 4.50662587156208e-05,
      "loss": 0.1028,
      "step": 14810
    },
    {
      "epoch": 0.29636443626764786,
      "grad_norm": 0.2468862384557724,
      "learning_rate": 4.506292578223947e-05,
      "loss": 0.1326,
      "step": 14820
    },
    {
      "epoch": 0.29656441227052754,
      "grad_norm": 0.19510942697525024,
      "learning_rate": 4.505959284885814e-05,
      "loss": 0.1147,
      "step": 14830
    },
    {
      "epoch": 0.2967643882734072,
      "grad_norm": 0.16525647044181824,
      "learning_rate": 4.505625991547681e-05,
      "loss": 0.0754,
      "step": 14840
    },
    {
      "epoch": 0.29696436427628686,
      "grad_norm": 0.1136632189154625,
      "learning_rate": 4.505292698209548e-05,
      "loss": 0.0572,
      "step": 14850
    },
    {
      "epoch": 0.2971643402791665,
      "grad_norm": 0.10522650182247162,
      "learning_rate": 4.504959404871415e-05,
      "loss": 0.0632,
      "step": 14860
    },
    {
      "epoch": 0.2973643162820462,
      "grad_norm": 0.16346843540668488,
      "learning_rate": 4.504626111533283e-05,
      "loss": 0.1131,
      "step": 14870
    },
    {
      "epoch": 0.2975642922849258,
      "grad_norm": 0.04454033449292183,
      "learning_rate": 4.50429281819515e-05,
      "loss": 0.081,
      "step": 14880
    },
    {
      "epoch": 0.29776426828780544,
      "grad_norm": 0.16608989238739014,
      "learning_rate": 4.503959524857017e-05,
      "loss": 0.0767,
      "step": 14890
    },
    {
      "epoch": 0.29796424429068513,
      "grad_norm": 0.0787724107503891,
      "learning_rate": 4.503626231518885e-05,
      "loss": 0.0713,
      "step": 14900
    },
    {
      "epoch": 0.29816422029356476,
      "grad_norm": 0.09373391419649124,
      "learning_rate": 4.503292938180752e-05,
      "loss": 0.0762,
      "step": 14910
    },
    {
      "epoch": 0.29836419629644445,
      "grad_norm": 0.17686252295970917,
      "learning_rate": 4.502959644842619e-05,
      "loss": 0.0822,
      "step": 14920
    },
    {
      "epoch": 0.2985641722993241,
      "grad_norm": 0.11839741468429565,
      "learning_rate": 4.502626351504487e-05,
      "loss": 0.0811,
      "step": 14930
    },
    {
      "epoch": 0.2987641483022037,
      "grad_norm": 0.0934511348605156,
      "learning_rate": 4.5022930581663536e-05,
      "loss": 0.0764,
      "step": 14940
    },
    {
      "epoch": 0.2989641243050834,
      "grad_norm": 0.14566656947135925,
      "learning_rate": 4.5019597648282206e-05,
      "loss": 0.0661,
      "step": 14950
    },
    {
      "epoch": 0.29916410030796303,
      "grad_norm": 0.1455751359462738,
      "learning_rate": 4.501626471490088e-05,
      "loss": 0.0896,
      "step": 14960
    },
    {
      "epoch": 0.2993640763108427,
      "grad_norm": 0.15474066138267517,
      "learning_rate": 4.501293178151955e-05,
      "loss": 0.0906,
      "step": 14970
    },
    {
      "epoch": 0.29956405231372235,
      "grad_norm": 0.13943520188331604,
      "learning_rate": 4.500959884813822e-05,
      "loss": 0.0901,
      "step": 14980
    },
    {
      "epoch": 0.299764028316602,
      "grad_norm": 0.13509967923164368,
      "learning_rate": 4.50062659147569e-05,
      "loss": 0.0775,
      "step": 14990
    },
    {
      "epoch": 0.29996400431948167,
      "grad_norm": 0.14928367733955383,
      "learning_rate": 4.5002932981375574e-05,
      "loss": 0.076,
      "step": 15000
    },
    {
      "epoch": 0.3001639803223613,
      "grad_norm": 0.20895914733409882,
      "learning_rate": 4.4999600047994244e-05,
      "loss": 0.0793,
      "step": 15010
    },
    {
      "epoch": 0.300363956325241,
      "grad_norm": 0.1762317270040512,
      "learning_rate": 4.4996267114612914e-05,
      "loss": 0.0964,
      "step": 15020
    },
    {
      "epoch": 0.3005639323281206,
      "grad_norm": 0.0924450233578682,
      "learning_rate": 4.499293418123159e-05,
      "loss": 0.1908,
      "step": 15030
    },
    {
      "epoch": 0.3007639083310003,
      "grad_norm": 0.10469820350408554,
      "learning_rate": 4.498960124785026e-05,
      "loss": 0.0738,
      "step": 15040
    },
    {
      "epoch": 0.30096388433387994,
      "grad_norm": 0.05051849037408829,
      "learning_rate": 4.498626831446893e-05,
      "loss": 0.0686,
      "step": 15050
    },
    {
      "epoch": 0.30116386033675957,
      "grad_norm": 0.1456705629825592,
      "learning_rate": 4.4982935381087606e-05,
      "loss": 0.0478,
      "step": 15060
    },
    {
      "epoch": 0.30136383633963926,
      "grad_norm": 0.07202745229005814,
      "learning_rate": 4.4979602447706275e-05,
      "loss": 0.0721,
      "step": 15070
    },
    {
      "epoch": 0.3015638123425189,
      "grad_norm": 0.08597353845834732,
      "learning_rate": 4.4976269514324945e-05,
      "loss": 0.0695,
      "step": 15080
    },
    {
      "epoch": 0.3017637883453986,
      "grad_norm": 0.09755362570285797,
      "learning_rate": 4.497293658094362e-05,
      "loss": 0.0574,
      "step": 15090
    },
    {
      "epoch": 0.3019637643482782,
      "grad_norm": 0.23042991757392883,
      "learning_rate": 4.49696036475623e-05,
      "loss": 0.1241,
      "step": 15100
    },
    {
      "epoch": 0.30216374035115784,
      "grad_norm": 0.06952077150344849,
      "learning_rate": 4.496627071418097e-05,
      "loss": 0.0665,
      "step": 15110
    },
    {
      "epoch": 0.3023637163540375,
      "grad_norm": 0.18882420659065247,
      "learning_rate": 4.4962937780799644e-05,
      "loss": 0.0845,
      "step": 15120
    },
    {
      "epoch": 0.30256369235691716,
      "grad_norm": 0.07467304170131683,
      "learning_rate": 4.495960484741831e-05,
      "loss": 0.0782,
      "step": 15130
    },
    {
      "epoch": 0.30276366835979684,
      "grad_norm": 0.1951853185892105,
      "learning_rate": 4.495627191403698e-05,
      "loss": 0.1024,
      "step": 15140
    },
    {
      "epoch": 0.3029636443626765,
      "grad_norm": 0.11990473419427872,
      "learning_rate": 4.495293898065566e-05,
      "loss": 0.0814,
      "step": 15150
    },
    {
      "epoch": 0.3031636203655561,
      "grad_norm": 0.20619776844978333,
      "learning_rate": 4.494960604727433e-05,
      "loss": 0.0861,
      "step": 15160
    },
    {
      "epoch": 0.3033635963684358,
      "grad_norm": 0.05691160261631012,
      "learning_rate": 4.4946273113893e-05,
      "loss": 0.0564,
      "step": 15170
    },
    {
      "epoch": 0.3035635723713154,
      "grad_norm": 0.0922079011797905,
      "learning_rate": 4.4942940180511675e-05,
      "loss": 0.0418,
      "step": 15180
    },
    {
      "epoch": 0.3037635483741951,
      "grad_norm": 0.1039922758936882,
      "learning_rate": 4.4939607247130345e-05,
      "loss": 0.0568,
      "step": 15190
    },
    {
      "epoch": 0.30396352437707475,
      "grad_norm": 0.08931510150432587,
      "learning_rate": 4.493627431374902e-05,
      "loss": 0.1013,
      "step": 15200
    },
    {
      "epoch": 0.30416350037995443,
      "grad_norm": 0.09235842525959015,
      "learning_rate": 4.493294138036769e-05,
      "loss": 0.0702,
      "step": 15210
    },
    {
      "epoch": 0.30436347638283406,
      "grad_norm": 0.19794891774654388,
      "learning_rate": 4.492960844698637e-05,
      "loss": 0.082,
      "step": 15220
    },
    {
      "epoch": 0.3045634523857137,
      "grad_norm": 0.07977387309074402,
      "learning_rate": 4.4926275513605037e-05,
      "loss": 0.0749,
      "step": 15230
    },
    {
      "epoch": 0.3047634283885934,
      "grad_norm": 0.08660775423049927,
      "learning_rate": 4.4922942580223706e-05,
      "loss": 0.0946,
      "step": 15240
    },
    {
      "epoch": 0.304963404391473,
      "grad_norm": 0.06310515850782394,
      "learning_rate": 4.491960964684238e-05,
      "loss": 0.0522,
      "step": 15250
    },
    {
      "epoch": 0.3051633803943527,
      "grad_norm": 0.09053501486778259,
      "learning_rate": 4.491627671346105e-05,
      "loss": 0.0617,
      "step": 15260
    },
    {
      "epoch": 0.30536335639723233,
      "grad_norm": 0.07336311787366867,
      "learning_rate": 4.491294378007972e-05,
      "loss": 0.0681,
      "step": 15270
    },
    {
      "epoch": 0.30556333240011196,
      "grad_norm": 0.09533599764108658,
      "learning_rate": 4.49096108466984e-05,
      "loss": 0.0453,
      "step": 15280
    },
    {
      "epoch": 0.30576330840299165,
      "grad_norm": 0.05114132538437843,
      "learning_rate": 4.490627791331707e-05,
      "loss": 0.0498,
      "step": 15290
    },
    {
      "epoch": 0.3059632844058713,
      "grad_norm": 0.17213967442512512,
      "learning_rate": 4.490294497993574e-05,
      "loss": 0.0745,
      "step": 15300
    },
    {
      "epoch": 0.30616326040875097,
      "grad_norm": 0.19444090127944946,
      "learning_rate": 4.489961204655442e-05,
      "loss": 0.121,
      "step": 15310
    },
    {
      "epoch": 0.3063632364116306,
      "grad_norm": 0.11698006838560104,
      "learning_rate": 4.489627911317309e-05,
      "loss": 0.1967,
      "step": 15320
    },
    {
      "epoch": 0.30656321241451023,
      "grad_norm": 0.19090870022773743,
      "learning_rate": 4.489294617979176e-05,
      "loss": 0.0887,
      "step": 15330
    },
    {
      "epoch": 0.3067631884173899,
      "grad_norm": 0.10995402187108994,
      "learning_rate": 4.4889613246410436e-05,
      "loss": 0.0658,
      "step": 15340
    },
    {
      "epoch": 0.30696316442026955,
      "grad_norm": 0.08930832147598267,
      "learning_rate": 4.4886280313029106e-05,
      "loss": 0.106,
      "step": 15350
    },
    {
      "epoch": 0.30716314042314924,
      "grad_norm": 0.15708351135253906,
      "learning_rate": 4.4882947379647775e-05,
      "loss": 0.0941,
      "step": 15360
    },
    {
      "epoch": 0.30736311642602887,
      "grad_norm": 0.19132213294506073,
      "learning_rate": 4.487961444626645e-05,
      "loss": 0.0819,
      "step": 15370
    },
    {
      "epoch": 0.30756309242890856,
      "grad_norm": 0.1275278478860855,
      "learning_rate": 4.487628151288512e-05,
      "loss": 0.1063,
      "step": 15380
    },
    {
      "epoch": 0.3077630684317882,
      "grad_norm": 0.09640411287546158,
      "learning_rate": 4.487294857950379e-05,
      "loss": 0.0462,
      "step": 15390
    },
    {
      "epoch": 0.3079630444346678,
      "grad_norm": 0.16613216698169708,
      "learning_rate": 4.486961564612247e-05,
      "loss": 0.104,
      "step": 15400
    },
    {
      "epoch": 0.3081630204375475,
      "grad_norm": 0.13346561789512634,
      "learning_rate": 4.4866282712741144e-05,
      "loss": 0.439,
      "step": 15410
    },
    {
      "epoch": 0.30836299644042714,
      "grad_norm": 0.10446885228157043,
      "learning_rate": 4.4862949779359813e-05,
      "loss": 0.0847,
      "step": 15420
    },
    {
      "epoch": 0.3085629724433068,
      "grad_norm": 0.09273283928632736,
      "learning_rate": 4.485961684597848e-05,
      "loss": 0.0769,
      "step": 15430
    },
    {
      "epoch": 0.30876294844618646,
      "grad_norm": 0.16170400381088257,
      "learning_rate": 4.485628391259716e-05,
      "loss": 0.1212,
      "step": 15440
    },
    {
      "epoch": 0.3089629244490661,
      "grad_norm": 0.06346078217029572,
      "learning_rate": 4.485295097921583e-05,
      "loss": 0.1211,
      "step": 15450
    },
    {
      "epoch": 0.3091629004519458,
      "grad_norm": 0.14709822833538055,
      "learning_rate": 4.48496180458345e-05,
      "loss": 0.081,
      "step": 15460
    },
    {
      "epoch": 0.3093628764548254,
      "grad_norm": 0.0678248479962349,
      "learning_rate": 4.4846285112453175e-05,
      "loss": 0.0744,
      "step": 15470
    },
    {
      "epoch": 0.3095628524577051,
      "grad_norm": 0.14319053292274475,
      "learning_rate": 4.4842952179071845e-05,
      "loss": 0.0811,
      "step": 15480
    },
    {
      "epoch": 0.3097628284605847,
      "grad_norm": 0.08937214314937592,
      "learning_rate": 4.4839619245690514e-05,
      "loss": 0.0957,
      "step": 15490
    },
    {
      "epoch": 0.30996280446346436,
      "grad_norm": 0.12384883314371109,
      "learning_rate": 4.483628631230919e-05,
      "loss": 0.0825,
      "step": 15500
    },
    {
      "epoch": 0.31016278046634405,
      "grad_norm": 0.07077911496162415,
      "learning_rate": 4.483295337892787e-05,
      "loss": 0.0469,
      "step": 15510
    },
    {
      "epoch": 0.3103627564692237,
      "grad_norm": 0.08349382877349854,
      "learning_rate": 4.482962044554654e-05,
      "loss": 0.08,
      "step": 15520
    },
    {
      "epoch": 0.31056273247210336,
      "grad_norm": 0.11557581275701523,
      "learning_rate": 4.482628751216521e-05,
      "loss": 0.0736,
      "step": 15530
    },
    {
      "epoch": 0.310762708474983,
      "grad_norm": 0.22027555108070374,
      "learning_rate": 4.482295457878388e-05,
      "loss": 0.1026,
      "step": 15540
    },
    {
      "epoch": 0.3109626844778627,
      "grad_norm": 0.13824883103370667,
      "learning_rate": 4.481962164540255e-05,
      "loss": 0.0639,
      "step": 15550
    },
    {
      "epoch": 0.3111626604807423,
      "grad_norm": 0.14617590606212616,
      "learning_rate": 4.481628871202123e-05,
      "loss": 0.0879,
      "step": 15560
    },
    {
      "epoch": 0.31136263648362195,
      "grad_norm": 0.0602169930934906,
      "learning_rate": 4.48129557786399e-05,
      "loss": 0.069,
      "step": 15570
    },
    {
      "epoch": 0.31156261248650163,
      "grad_norm": 0.16633358597755432,
      "learning_rate": 4.480962284525857e-05,
      "loss": 0.1143,
      "step": 15580
    },
    {
      "epoch": 0.31176258848938126,
      "grad_norm": 0.16897405683994293,
      "learning_rate": 4.4806289911877244e-05,
      "loss": 0.0872,
      "step": 15590
    },
    {
      "epoch": 0.31196256449226095,
      "grad_norm": 0.08289876580238342,
      "learning_rate": 4.4802956978495914e-05,
      "loss": 0.1233,
      "step": 15600
    },
    {
      "epoch": 0.3121625404951406,
      "grad_norm": 0.11127781122922897,
      "learning_rate": 4.479962404511459e-05,
      "loss": 0.0783,
      "step": 15610
    },
    {
      "epoch": 0.3123625164980202,
      "grad_norm": 0.16918794810771942,
      "learning_rate": 4.479629111173326e-05,
      "loss": 0.1138,
      "step": 15620
    },
    {
      "epoch": 0.3125624925008999,
      "grad_norm": 0.19308501482009888,
      "learning_rate": 4.4792958178351936e-05,
      "loss": 0.1022,
      "step": 15630
    },
    {
      "epoch": 0.31276246850377953,
      "grad_norm": 0.09457241743803024,
      "learning_rate": 4.4789625244970606e-05,
      "loss": 0.0836,
      "step": 15640
    },
    {
      "epoch": 0.3129624445066592,
      "grad_norm": 0.13439567387104034,
      "learning_rate": 4.4786292311589276e-05,
      "loss": 0.0928,
      "step": 15650
    },
    {
      "epoch": 0.31316242050953885,
      "grad_norm": 0.1289622038602829,
      "learning_rate": 4.478295937820795e-05,
      "loss": 0.0827,
      "step": 15660
    },
    {
      "epoch": 0.3133623965124185,
      "grad_norm": 0.11012082546949387,
      "learning_rate": 4.477962644482662e-05,
      "loss": 0.0834,
      "step": 15670
    },
    {
      "epoch": 0.31356237251529817,
      "grad_norm": 0.16134147346019745,
      "learning_rate": 4.477629351144529e-05,
      "loss": 0.102,
      "step": 15680
    },
    {
      "epoch": 0.3137623485181778,
      "grad_norm": 0.06938037276268005,
      "learning_rate": 4.477296057806397e-05,
      "loss": 0.0722,
      "step": 15690
    },
    {
      "epoch": 0.3139623245210575,
      "grad_norm": 0.06684783846139908,
      "learning_rate": 4.476962764468264e-05,
      "loss": 0.0646,
      "step": 15700
    },
    {
      "epoch": 0.3141623005239371,
      "grad_norm": 0.06364583969116211,
      "learning_rate": 4.4766294711301314e-05,
      "loss": 0.0581,
      "step": 15710
    },
    {
      "epoch": 0.3143622765268168,
      "grad_norm": 0.061428964138031006,
      "learning_rate": 4.476296177791999e-05,
      "loss": 0.0772,
      "step": 15720
    },
    {
      "epoch": 0.31456225252969644,
      "grad_norm": 0.08943769335746765,
      "learning_rate": 4.475962884453866e-05,
      "loss": 0.0652,
      "step": 15730
    },
    {
      "epoch": 0.31476222853257607,
      "grad_norm": 0.19304871559143066,
      "learning_rate": 4.475629591115733e-05,
      "loss": 0.0984,
      "step": 15740
    },
    {
      "epoch": 0.31496220453545576,
      "grad_norm": 0.09983609616756439,
      "learning_rate": 4.4752962977776006e-05,
      "loss": 0.0864,
      "step": 15750
    },
    {
      "epoch": 0.3151621805383354,
      "grad_norm": 0.10015682131052017,
      "learning_rate": 4.4749630044394675e-05,
      "loss": 0.0744,
      "step": 15760
    },
    {
      "epoch": 0.3153621565412151,
      "grad_norm": 0.17252099514007568,
      "learning_rate": 4.4746297111013345e-05,
      "loss": 0.109,
      "step": 15770
    },
    {
      "epoch": 0.3155621325440947,
      "grad_norm": 0.14190536737442017,
      "learning_rate": 4.474296417763202e-05,
      "loss": 0.0845,
      "step": 15780
    },
    {
      "epoch": 0.31576210854697434,
      "grad_norm": 0.07814235240221024,
      "learning_rate": 4.473963124425069e-05,
      "loss": 0.085,
      "step": 15790
    },
    {
      "epoch": 0.315962084549854,
      "grad_norm": 0.18180809915065765,
      "learning_rate": 4.473629831086936e-05,
      "loss": 0.5505,
      "step": 15800
    },
    {
      "epoch": 0.31616206055273366,
      "grad_norm": 0.11905256658792496,
      "learning_rate": 4.473296537748804e-05,
      "loss": 0.0395,
      "step": 15810
    },
    {
      "epoch": 0.31636203655561335,
      "grad_norm": 0.12873654067516327,
      "learning_rate": 4.472963244410671e-05,
      "loss": 0.064,
      "step": 15820
    },
    {
      "epoch": 0.316562012558493,
      "grad_norm": 0.10364294052124023,
      "learning_rate": 4.472629951072538e-05,
      "loss": 0.1152,
      "step": 15830
    },
    {
      "epoch": 0.3167619885613726,
      "grad_norm": 0.1751035451889038,
      "learning_rate": 4.472296657734405e-05,
      "loss": 0.0765,
      "step": 15840
    },
    {
      "epoch": 0.3169619645642523,
      "grad_norm": 0.12277458608150482,
      "learning_rate": 4.471963364396273e-05,
      "loss": 0.1491,
      "step": 15850
    },
    {
      "epoch": 0.31716194056713193,
      "grad_norm": 0.14173442125320435,
      "learning_rate": 4.47163007105814e-05,
      "loss": 0.0935,
      "step": 15860
    },
    {
      "epoch": 0.3173619165700116,
      "grad_norm": 0.09161881357431412,
      "learning_rate": 4.471296777720007e-05,
      "loss": 0.0724,
      "step": 15870
    },
    {
      "epoch": 0.31756189257289125,
      "grad_norm": 0.09070127457380295,
      "learning_rate": 4.4709634843818745e-05,
      "loss": 0.0933,
      "step": 15880
    },
    {
      "epoch": 0.31776186857577093,
      "grad_norm": 0.08612406253814697,
      "learning_rate": 4.4706301910437414e-05,
      "loss": 0.0773,
      "step": 15890
    },
    {
      "epoch": 0.31796184457865057,
      "grad_norm": 0.04832714423537254,
      "learning_rate": 4.4702968977056084e-05,
      "loss": 0.0576,
      "step": 15900
    },
    {
      "epoch": 0.3181618205815302,
      "grad_norm": 0.1055484488606453,
      "learning_rate": 4.469963604367476e-05,
      "loss": 0.061,
      "step": 15910
    },
    {
      "epoch": 0.3183617965844099,
      "grad_norm": 0.08927614986896515,
      "learning_rate": 4.4696303110293437e-05,
      "loss": 0.0818,
      "step": 15920
    },
    {
      "epoch": 0.3185617725872895,
      "grad_norm": 0.1979941427707672,
      "learning_rate": 4.4692970176912106e-05,
      "loss": 0.0809,
      "step": 15930
    },
    {
      "epoch": 0.3187617485901692,
      "grad_norm": 0.20874598622322083,
      "learning_rate": 4.468963724353078e-05,
      "loss": 0.0881,
      "step": 15940
    },
    {
      "epoch": 0.31896172459304883,
      "grad_norm": 0.07670596987009048,
      "learning_rate": 4.468630431014945e-05,
      "loss": 0.0465,
      "step": 15950
    },
    {
      "epoch": 0.31916170059592847,
      "grad_norm": 0.17913950979709625,
      "learning_rate": 4.468297137676812e-05,
      "loss": 0.1352,
      "step": 15960
    },
    {
      "epoch": 0.31936167659880815,
      "grad_norm": 0.13812731206417084,
      "learning_rate": 4.46796384433868e-05,
      "loss": 0.0724,
      "step": 15970
    },
    {
      "epoch": 0.3195616526016878,
      "grad_norm": 0.05763520672917366,
      "learning_rate": 4.467630551000547e-05,
      "loss": 0.0375,
      "step": 15980
    },
    {
      "epoch": 0.31976162860456747,
      "grad_norm": 0.16926419734954834,
      "learning_rate": 4.467297257662414e-05,
      "loss": 0.099,
      "step": 15990
    },
    {
      "epoch": 0.3199616046074471,
      "grad_norm": 0.09625041484832764,
      "learning_rate": 4.4669639643242814e-05,
      "loss": 0.067,
      "step": 16000
    },
    {
      "epoch": 0.32016158061032673,
      "grad_norm": 0.07806232571601868,
      "learning_rate": 4.4666306709861483e-05,
      "loss": 0.0849,
      "step": 16010
    },
    {
      "epoch": 0.3203615566132064,
      "grad_norm": 0.17589908838272095,
      "learning_rate": 4.466297377648016e-05,
      "loss": 0.0799,
      "step": 16020
    },
    {
      "epoch": 0.32056153261608605,
      "grad_norm": 0.14163492619991302,
      "learning_rate": 4.465964084309883e-05,
      "loss": 0.1041,
      "step": 16030
    },
    {
      "epoch": 0.32076150861896574,
      "grad_norm": 0.19155943393707275,
      "learning_rate": 4.4656307909717506e-05,
      "loss": 0.0734,
      "step": 16040
    },
    {
      "epoch": 0.32096148462184537,
      "grad_norm": 0.15920181572437286,
      "learning_rate": 4.4652974976336175e-05,
      "loss": 0.1024,
      "step": 16050
    },
    {
      "epoch": 0.32116146062472506,
      "grad_norm": 0.12430737167596817,
      "learning_rate": 4.4649642042954845e-05,
      "loss": 0.0504,
      "step": 16060
    },
    {
      "epoch": 0.3213614366276047,
      "grad_norm": 0.12626442313194275,
      "learning_rate": 4.464630910957352e-05,
      "loss": 0.0798,
      "step": 16070
    },
    {
      "epoch": 0.3215614126304843,
      "grad_norm": 0.15516790747642517,
      "learning_rate": 4.464297617619219e-05,
      "loss": 0.1096,
      "step": 16080
    },
    {
      "epoch": 0.321761388633364,
      "grad_norm": 0.19996358454227448,
      "learning_rate": 4.463964324281086e-05,
      "loss": 0.1107,
      "step": 16090
    },
    {
      "epoch": 0.32196136463624364,
      "grad_norm": 0.11076948791742325,
      "learning_rate": 4.463631030942954e-05,
      "loss": 0.101,
      "step": 16100
    },
    {
      "epoch": 0.32216134063912333,
      "grad_norm": 0.12538276612758636,
      "learning_rate": 4.463297737604821e-05,
      "loss": 0.0814,
      "step": 16110
    },
    {
      "epoch": 0.32236131664200296,
      "grad_norm": 0.20191462337970734,
      "learning_rate": 4.462964444266688e-05,
      "loss": 0.0775,
      "step": 16120
    },
    {
      "epoch": 0.3225612926448826,
      "grad_norm": 0.15072748064994812,
      "learning_rate": 4.462631150928556e-05,
      "loss": 0.0392,
      "step": 16130
    },
    {
      "epoch": 0.3227612686477623,
      "grad_norm": 0.1685873121023178,
      "learning_rate": 4.462297857590423e-05,
      "loss": 0.0758,
      "step": 16140
    },
    {
      "epoch": 0.3229612446506419,
      "grad_norm": 0.14135059714317322,
      "learning_rate": 4.46196456425229e-05,
      "loss": 0.0671,
      "step": 16150
    },
    {
      "epoch": 0.3231612206535216,
      "grad_norm": 0.08405502885580063,
      "learning_rate": 4.4616312709141575e-05,
      "loss": 0.064,
      "step": 16160
    },
    {
      "epoch": 0.32336119665640123,
      "grad_norm": 0.089595265686512,
      "learning_rate": 4.4612979775760245e-05,
      "loss": 0.0481,
      "step": 16170
    },
    {
      "epoch": 0.32356117265928086,
      "grad_norm": 0.09844312071800232,
      "learning_rate": 4.4609646842378914e-05,
      "loss": 0.0852,
      "step": 16180
    },
    {
      "epoch": 0.32376114866216055,
      "grad_norm": 0.17648592591285706,
      "learning_rate": 4.460631390899759e-05,
      "loss": 0.0658,
      "step": 16190
    },
    {
      "epoch": 0.3239611246650402,
      "grad_norm": 0.1460392326116562,
      "learning_rate": 4.460298097561626e-05,
      "loss": 0.0718,
      "step": 16200
    },
    {
      "epoch": 0.32416110066791987,
      "grad_norm": 0.0756417065858841,
      "learning_rate": 4.459964804223493e-05,
      "loss": 0.0993,
      "step": 16210
    },
    {
      "epoch": 0.3243610766707995,
      "grad_norm": 0.15812242031097412,
      "learning_rate": 4.4596315108853606e-05,
      "loss": 0.054,
      "step": 16220
    },
    {
      "epoch": 0.3245610526736792,
      "grad_norm": 0.191848024725914,
      "learning_rate": 4.459298217547228e-05,
      "loss": 0.1058,
      "step": 16230
    },
    {
      "epoch": 0.3247610286765588,
      "grad_norm": 0.11469683796167374,
      "learning_rate": 4.458964924209095e-05,
      "loss": 0.1026,
      "step": 16240
    },
    {
      "epoch": 0.32496100467943845,
      "grad_norm": 0.1541953682899475,
      "learning_rate": 4.458631630870962e-05,
      "loss": 0.0538,
      "step": 16250
    },
    {
      "epoch": 0.32516098068231813,
      "grad_norm": 0.11235572397708893,
      "learning_rate": 4.45829833753283e-05,
      "loss": 0.0639,
      "step": 16260
    },
    {
      "epoch": 0.32536095668519777,
      "grad_norm": 0.056457363069057465,
      "learning_rate": 4.457965044194697e-05,
      "loss": 0.0501,
      "step": 16270
    },
    {
      "epoch": 0.32556093268807745,
      "grad_norm": 0.1246158704161644,
      "learning_rate": 4.457631750856564e-05,
      "loss": 0.0952,
      "step": 16280
    },
    {
      "epoch": 0.3257609086909571,
      "grad_norm": 0.19392605125904083,
      "learning_rate": 4.4572984575184314e-05,
      "loss": 0.075,
      "step": 16290
    },
    {
      "epoch": 0.3259608846938367,
      "grad_norm": 0.11796416342258453,
      "learning_rate": 4.4569651641802984e-05,
      "loss": 0.4721,
      "step": 16300
    },
    {
      "epoch": 0.3261608606967164,
      "grad_norm": 0.08425825089216232,
      "learning_rate": 4.456631870842165e-05,
      "loss": 0.0873,
      "step": 16310
    },
    {
      "epoch": 0.32636083669959604,
      "grad_norm": 0.164861261844635,
      "learning_rate": 4.456298577504033e-05,
      "loss": 0.1058,
      "step": 16320
    },
    {
      "epoch": 0.3265608127024757,
      "grad_norm": 0.1113162487745285,
      "learning_rate": 4.4559652841659006e-05,
      "loss": 0.0766,
      "step": 16330
    },
    {
      "epoch": 0.32676078870535535,
      "grad_norm": 0.16002830862998962,
      "learning_rate": 4.4556319908277676e-05,
      "loss": 0.0992,
      "step": 16340
    },
    {
      "epoch": 0.326960764708235,
      "grad_norm": 0.2298901528120041,
      "learning_rate": 4.455298697489635e-05,
      "loss": 0.0815,
      "step": 16350
    },
    {
      "epoch": 0.3271607407111147,
      "grad_norm": 0.1589726209640503,
      "learning_rate": 4.454965404151502e-05,
      "loss": 0.1103,
      "step": 16360
    },
    {
      "epoch": 0.3273607167139943,
      "grad_norm": 0.11970237642526627,
      "learning_rate": 4.454632110813369e-05,
      "loss": 0.0944,
      "step": 16370
    },
    {
      "epoch": 0.327560692716874,
      "grad_norm": 0.1838485300540924,
      "learning_rate": 4.454298817475237e-05,
      "loss": 0.0448,
      "step": 16380
    },
    {
      "epoch": 0.3277606687197536,
      "grad_norm": 0.17266549170017242,
      "learning_rate": 4.453965524137104e-05,
      "loss": 0.0952,
      "step": 16390
    },
    {
      "epoch": 0.3279606447226333,
      "grad_norm": 0.0943673700094223,
      "learning_rate": 4.453632230798971e-05,
      "loss": 0.061,
      "step": 16400
    },
    {
      "epoch": 0.32816062072551294,
      "grad_norm": 0.09786402434110641,
      "learning_rate": 4.453298937460838e-05,
      "loss": 0.0622,
      "step": 16410
    },
    {
      "epoch": 0.3283605967283926,
      "grad_norm": 0.1039835661649704,
      "learning_rate": 4.452965644122705e-05,
      "loss": 0.0998,
      "step": 16420
    },
    {
      "epoch": 0.32856057273127226,
      "grad_norm": 0.15672098100185394,
      "learning_rate": 4.452632350784573e-05,
      "loss": 0.0936,
      "step": 16430
    },
    {
      "epoch": 0.3287605487341519,
      "grad_norm": 0.140455961227417,
      "learning_rate": 4.45229905744644e-05,
      "loss": 0.0447,
      "step": 16440
    },
    {
      "epoch": 0.3289605247370316,
      "grad_norm": 0.1380470097064972,
      "learning_rate": 4.4519657641083075e-05,
      "loss": 0.089,
      "step": 16450
    },
    {
      "epoch": 0.3291605007399112,
      "grad_norm": 0.1578015387058258,
      "learning_rate": 4.4516324707701745e-05,
      "loss": 0.0853,
      "step": 16460
    },
    {
      "epoch": 0.32936047674279084,
      "grad_norm": 0.08958117663860321,
      "learning_rate": 4.4512991774320414e-05,
      "loss": 0.0795,
      "step": 16470
    },
    {
      "epoch": 0.32956045274567053,
      "grad_norm": 0.08008044213056564,
      "learning_rate": 4.450965884093909e-05,
      "loss": 0.064,
      "step": 16480
    },
    {
      "epoch": 0.32976042874855016,
      "grad_norm": 0.11834926158189774,
      "learning_rate": 4.450632590755776e-05,
      "loss": 0.0997,
      "step": 16490
    },
    {
      "epoch": 0.32996040475142985,
      "grad_norm": 0.11161217838525772,
      "learning_rate": 4.450299297417643e-05,
      "loss": 0.0911,
      "step": 16500
    },
    {
      "epoch": 0.3301603807543095,
      "grad_norm": 0.18984933197498322,
      "learning_rate": 4.4499660040795107e-05,
      "loss": 0.1008,
      "step": 16510
    },
    {
      "epoch": 0.3303603567571891,
      "grad_norm": 0.14792075753211975,
      "learning_rate": 4.4496327107413776e-05,
      "loss": 0.0754,
      "step": 16520
    },
    {
      "epoch": 0.3305603327600688,
      "grad_norm": 0.12042262405157089,
      "learning_rate": 4.449299417403245e-05,
      "loss": 0.058,
      "step": 16530
    },
    {
      "epoch": 0.33076030876294843,
      "grad_norm": 0.15986819565296173,
      "learning_rate": 4.448966124065113e-05,
      "loss": 0.0723,
      "step": 16540
    },
    {
      "epoch": 0.3309602847658281,
      "grad_norm": 0.06339488178491592,
      "learning_rate": 4.44863283072698e-05,
      "loss": 0.0791,
      "step": 16550
    },
    {
      "epoch": 0.33116026076870775,
      "grad_norm": 0.19859600067138672,
      "learning_rate": 4.448299537388847e-05,
      "loss": 0.0915,
      "step": 16560
    },
    {
      "epoch": 0.33136023677158744,
      "grad_norm": 0.2495104968547821,
      "learning_rate": 4.4479662440507145e-05,
      "loss": 0.1022,
      "step": 16570
    },
    {
      "epoch": 0.33156021277446707,
      "grad_norm": 0.08020786941051483,
      "learning_rate": 4.4476329507125814e-05,
      "loss": 0.0768,
      "step": 16580
    },
    {
      "epoch": 0.3317601887773467,
      "grad_norm": 0.08404678851366043,
      "learning_rate": 4.4472996573744484e-05,
      "loss": 0.0802,
      "step": 16590
    },
    {
      "epoch": 0.3319601647802264,
      "grad_norm": 0.19447065889835358,
      "learning_rate": 4.446966364036316e-05,
      "loss": 0.0726,
      "step": 16600
    },
    {
      "epoch": 0.332160140783106,
      "grad_norm": 0.11907213181257248,
      "learning_rate": 4.446633070698183e-05,
      "loss": 0.1082,
      "step": 16610
    },
    {
      "epoch": 0.3323601167859857,
      "grad_norm": 0.1482226550579071,
      "learning_rate": 4.44629977736005e-05,
      "loss": 0.0523,
      "step": 16620
    },
    {
      "epoch": 0.33256009278886534,
      "grad_norm": 0.15388406813144684,
      "learning_rate": 4.4459664840219176e-05,
      "loss": 0.0441,
      "step": 16630
    },
    {
      "epoch": 0.33276006879174497,
      "grad_norm": 0.16695235669612885,
      "learning_rate": 4.445633190683785e-05,
      "loss": 0.0823,
      "step": 16640
    },
    {
      "epoch": 0.33296004479462465,
      "grad_norm": 0.11516621708869934,
      "learning_rate": 4.445299897345652e-05,
      "loss": 0.0735,
      "step": 16650
    },
    {
      "epoch": 0.3331600207975043,
      "grad_norm": 0.11384212970733643,
      "learning_rate": 4.444966604007519e-05,
      "loss": 0.0557,
      "step": 16660
    },
    {
      "epoch": 0.333359996800384,
      "grad_norm": 0.09112538397312164,
      "learning_rate": 4.444633310669387e-05,
      "loss": 0.1039,
      "step": 16670
    },
    {
      "epoch": 0.3335599728032636,
      "grad_norm": 0.13550393283367157,
      "learning_rate": 4.444300017331254e-05,
      "loss": 0.0523,
      "step": 16680
    },
    {
      "epoch": 0.33375994880614324,
      "grad_norm": 0.13849101960659027,
      "learning_rate": 4.443966723993121e-05,
      "loss": 0.0812,
      "step": 16690
    },
    {
      "epoch": 0.3339599248090229,
      "grad_norm": 0.12235457450151443,
      "learning_rate": 4.4436334306549883e-05,
      "loss": 0.0706,
      "step": 16700
    },
    {
      "epoch": 0.33415990081190255,
      "grad_norm": 0.07023543864488602,
      "learning_rate": 4.443300137316855e-05,
      "loss": 0.0602,
      "step": 16710
    },
    {
      "epoch": 0.33435987681478224,
      "grad_norm": 0.1768151968717575,
      "learning_rate": 4.442966843978722e-05,
      "loss": 0.0715,
      "step": 16720
    },
    {
      "epoch": 0.3345598528176619,
      "grad_norm": 0.11190155148506165,
      "learning_rate": 4.4426335506405906e-05,
      "loss": 0.0554,
      "step": 16730
    },
    {
      "epoch": 0.33475982882054156,
      "grad_norm": 0.17236566543579102,
      "learning_rate": 4.4423002573024575e-05,
      "loss": 0.1106,
      "step": 16740
    },
    {
      "epoch": 0.3349598048234212,
      "grad_norm": 0.13282467424869537,
      "learning_rate": 4.4419669639643245e-05,
      "loss": 0.0671,
      "step": 16750
    },
    {
      "epoch": 0.3351597808263008,
      "grad_norm": 0.11090895533561707,
      "learning_rate": 4.441633670626192e-05,
      "loss": 0.0577,
      "step": 16760
    },
    {
      "epoch": 0.3353597568291805,
      "grad_norm": 0.16557452082633972,
      "learning_rate": 4.441300377288059e-05,
      "loss": 0.1147,
      "step": 16770
    },
    {
      "epoch": 0.33555973283206014,
      "grad_norm": 0.15130724012851715,
      "learning_rate": 4.440967083949926e-05,
      "loss": 0.0888,
      "step": 16780
    },
    {
      "epoch": 0.33575970883493983,
      "grad_norm": 0.1423121839761734,
      "learning_rate": 4.440633790611794e-05,
      "loss": 0.0814,
      "step": 16790
    },
    {
      "epoch": 0.33595968483781946,
      "grad_norm": 0.16701394319534302,
      "learning_rate": 4.440300497273661e-05,
      "loss": 0.053,
      "step": 16800
    },
    {
      "epoch": 0.3361596608406991,
      "grad_norm": 0.047294165939092636,
      "learning_rate": 4.4399672039355276e-05,
      "loss": 0.2139,
      "step": 16810
    },
    {
      "epoch": 0.3363596368435788,
      "grad_norm": 0.14931902289390564,
      "learning_rate": 4.439633910597395e-05,
      "loss": 0.1193,
      "step": 16820
    },
    {
      "epoch": 0.3365596128464584,
      "grad_norm": 0.11793766170740128,
      "learning_rate": 4.439300617259262e-05,
      "loss": 0.0874,
      "step": 16830
    },
    {
      "epoch": 0.3367595888493381,
      "grad_norm": 0.09564761072397232,
      "learning_rate": 4.43896732392113e-05,
      "loss": 0.0963,
      "step": 16840
    },
    {
      "epoch": 0.33695956485221773,
      "grad_norm": 0.08978481590747833,
      "learning_rate": 4.438634030582997e-05,
      "loss": 0.0816,
      "step": 16850
    },
    {
      "epoch": 0.33715954085509736,
      "grad_norm": 0.17132577300071716,
      "learning_rate": 4.4383007372448645e-05,
      "loss": 0.0783,
      "step": 16860
    },
    {
      "epoch": 0.33735951685797705,
      "grad_norm": 0.11172614246606827,
      "learning_rate": 4.4379674439067314e-05,
      "loss": 0.0874,
      "step": 16870
    },
    {
      "epoch": 0.3375594928608567,
      "grad_norm": 0.10781677067279816,
      "learning_rate": 4.4376341505685984e-05,
      "loss": 0.0617,
      "step": 16880
    },
    {
      "epoch": 0.33775946886373637,
      "grad_norm": 0.09746836870908737,
      "learning_rate": 4.437300857230466e-05,
      "loss": 0.051,
      "step": 16890
    },
    {
      "epoch": 0.337959444866616,
      "grad_norm": 0.17567293345928192,
      "learning_rate": 4.436967563892333e-05,
      "loss": 0.0701,
      "step": 16900
    },
    {
      "epoch": 0.3381594208694957,
      "grad_norm": 0.09454154968261719,
      "learning_rate": 4.4366342705542e-05,
      "loss": 0.063,
      "step": 16910
    },
    {
      "epoch": 0.3383593968723753,
      "grad_norm": 0.1622515469789505,
      "learning_rate": 4.4363009772160676e-05,
      "loss": 0.0935,
      "step": 16920
    },
    {
      "epoch": 0.33855937287525495,
      "grad_norm": 0.19054526090621948,
      "learning_rate": 4.4359676838779346e-05,
      "loss": 0.0772,
      "step": 16930
    },
    {
      "epoch": 0.33875934887813464,
      "grad_norm": 0.08360576629638672,
      "learning_rate": 4.435634390539802e-05,
      "loss": 0.1028,
      "step": 16940
    },
    {
      "epoch": 0.33895932488101427,
      "grad_norm": 0.22688154876232147,
      "learning_rate": 4.43530109720167e-05,
      "loss": 0.1147,
      "step": 16950
    },
    {
      "epoch": 0.33915930088389395,
      "grad_norm": 0.17279593646526337,
      "learning_rate": 4.434967803863537e-05,
      "loss": 0.102,
      "step": 16960
    },
    {
      "epoch": 0.3393592768867736,
      "grad_norm": 0.05889343470335007,
      "learning_rate": 4.434634510525404e-05,
      "loss": 0.0966,
      "step": 16970
    },
    {
      "epoch": 0.3395592528896532,
      "grad_norm": 0.16628073155879974,
      "learning_rate": 4.4343012171872714e-05,
      "loss": 0.0846,
      "step": 16980
    },
    {
      "epoch": 0.3397592288925329,
      "grad_norm": 0.0606718510389328,
      "learning_rate": 4.4339679238491384e-05,
      "loss": 0.1147,
      "step": 16990
    },
    {
      "epoch": 0.33995920489541254,
      "grad_norm": 0.07619933784008026,
      "learning_rate": 4.433634630511005e-05,
      "loss": 0.0375,
      "step": 17000
    },
    {
      "epoch": 0.3401591808982922,
      "grad_norm": 0.09464144706726074,
      "learning_rate": 4.433301337172873e-05,
      "loss": 0.1013,
      "step": 17010
    },
    {
      "epoch": 0.34035915690117186,
      "grad_norm": 0.11601273715496063,
      "learning_rate": 4.43296804383474e-05,
      "loss": 0.0853,
      "step": 17020
    },
    {
      "epoch": 0.3405591329040515,
      "grad_norm": 0.11466757208108902,
      "learning_rate": 4.432634750496607e-05,
      "loss": 0.0519,
      "step": 17030
    },
    {
      "epoch": 0.3407591089069312,
      "grad_norm": 0.1895318627357483,
      "learning_rate": 4.4323014571584745e-05,
      "loss": 0.0484,
      "step": 17040
    },
    {
      "epoch": 0.3409590849098108,
      "grad_norm": 0.10437782108783722,
      "learning_rate": 4.431968163820342e-05,
      "loss": 0.084,
      "step": 17050
    },
    {
      "epoch": 0.3411590609126905,
      "grad_norm": 0.07619989663362503,
      "learning_rate": 4.431634870482209e-05,
      "loss": 0.0811,
      "step": 17060
    },
    {
      "epoch": 0.3413590369155701,
      "grad_norm": 0.13032065331935883,
      "learning_rate": 4.431301577144076e-05,
      "loss": 0.0918,
      "step": 17070
    },
    {
      "epoch": 0.3415590129184498,
      "grad_norm": 0.08606194704771042,
      "learning_rate": 4.430968283805944e-05,
      "loss": 0.0671,
      "step": 17080
    },
    {
      "epoch": 0.34175898892132944,
      "grad_norm": 0.08600181341171265,
      "learning_rate": 4.430634990467811e-05,
      "loss": 0.0629,
      "step": 17090
    },
    {
      "epoch": 0.3419589649242091,
      "grad_norm": 0.11361128091812134,
      "learning_rate": 4.4303016971296776e-05,
      "loss": 0.0858,
      "step": 17100
    },
    {
      "epoch": 0.34215894092708876,
      "grad_norm": 0.11682423949241638,
      "learning_rate": 4.429968403791545e-05,
      "loss": 0.0821,
      "step": 17110
    },
    {
      "epoch": 0.3423589169299684,
      "grad_norm": 0.17858260869979858,
      "learning_rate": 4.429635110453412e-05,
      "loss": 0.1042,
      "step": 17120
    },
    {
      "epoch": 0.3425588929328481,
      "grad_norm": 0.10048224031925201,
      "learning_rate": 4.429301817115279e-05,
      "loss": 0.1005,
      "step": 17130
    },
    {
      "epoch": 0.3427588689357277,
      "grad_norm": 0.18109923601150513,
      "learning_rate": 4.4289685237771475e-05,
      "loss": 0.1087,
      "step": 17140
    },
    {
      "epoch": 0.34295884493860734,
      "grad_norm": 0.06616944819688797,
      "learning_rate": 4.4286352304390145e-05,
      "loss": 0.0695,
      "step": 17150
    },
    {
      "epoch": 0.34315882094148703,
      "grad_norm": 0.07836529612541199,
      "learning_rate": 4.4283019371008815e-05,
      "loss": 0.1104,
      "step": 17160
    },
    {
      "epoch": 0.34335879694436666,
      "grad_norm": 0.1309528797864914,
      "learning_rate": 4.427968643762749e-05,
      "loss": 0.0682,
      "step": 17170
    },
    {
      "epoch": 0.34355877294724635,
      "grad_norm": 0.0729554295539856,
      "learning_rate": 4.427635350424616e-05,
      "loss": 0.0738,
      "step": 17180
    },
    {
      "epoch": 0.343758748950126,
      "grad_norm": 0.20331591367721558,
      "learning_rate": 4.427302057086483e-05,
      "loss": 0.0718,
      "step": 17190
    },
    {
      "epoch": 0.3439587249530056,
      "grad_norm": 0.09472294896841049,
      "learning_rate": 4.4269687637483507e-05,
      "loss": 0.0646,
      "step": 17200
    },
    {
      "epoch": 0.3441587009558853,
      "grad_norm": 0.0716954693198204,
      "learning_rate": 4.4266354704102176e-05,
      "loss": 0.0689,
      "step": 17210
    },
    {
      "epoch": 0.34435867695876493,
      "grad_norm": 0.10906171053647995,
      "learning_rate": 4.4263021770720846e-05,
      "loss": 0.0995,
      "step": 17220
    },
    {
      "epoch": 0.3445586529616446,
      "grad_norm": 0.09218768775463104,
      "learning_rate": 4.425968883733952e-05,
      "loss": 0.0657,
      "step": 17230
    },
    {
      "epoch": 0.34475862896452425,
      "grad_norm": 0.05554773658514023,
      "learning_rate": 4.42563559039582e-05,
      "loss": 0.0977,
      "step": 17240
    },
    {
      "epoch": 0.34495860496740394,
      "grad_norm": 0.1691540628671646,
      "learning_rate": 4.425302297057687e-05,
      "loss": 0.0898,
      "step": 17250
    },
    {
      "epoch": 0.34515858097028357,
      "grad_norm": 0.162702277302742,
      "learning_rate": 4.424969003719554e-05,
      "loss": 0.0926,
      "step": 17260
    },
    {
      "epoch": 0.3453585569731632,
      "grad_norm": 0.13749147951602936,
      "learning_rate": 4.4246357103814214e-05,
      "loss": 0.0747,
      "step": 17270
    },
    {
      "epoch": 0.3455585329760429,
      "grad_norm": 0.12924960255622864,
      "learning_rate": 4.4243024170432884e-05,
      "loss": 0.0934,
      "step": 17280
    },
    {
      "epoch": 0.3457585089789225,
      "grad_norm": 0.2087831348180771,
      "learning_rate": 4.4239691237051553e-05,
      "loss": 0.1009,
      "step": 17290
    },
    {
      "epoch": 0.3459584849818022,
      "grad_norm": 0.16441859304904938,
      "learning_rate": 4.423635830367023e-05,
      "loss": 0.0748,
      "step": 17300
    },
    {
      "epoch": 0.34615846098468184,
      "grad_norm": 0.13951422274112701,
      "learning_rate": 4.42330253702889e-05,
      "loss": 0.1008,
      "step": 17310
    },
    {
      "epoch": 0.34635843698756147,
      "grad_norm": 0.07809103280305862,
      "learning_rate": 4.422969243690757e-05,
      "loss": 0.1072,
      "step": 17320
    },
    {
      "epoch": 0.34655841299044116,
      "grad_norm": 0.09178699553012848,
      "learning_rate": 4.4226359503526245e-05,
      "loss": 0.0644,
      "step": 17330
    },
    {
      "epoch": 0.3467583889933208,
      "grad_norm": 0.11489009112119675,
      "learning_rate": 4.4223026570144915e-05,
      "loss": 0.0769,
      "step": 17340
    },
    {
      "epoch": 0.3469583649962005,
      "grad_norm": 0.15778154134750366,
      "learning_rate": 4.421969363676359e-05,
      "loss": 0.0609,
      "step": 17350
    },
    {
      "epoch": 0.3471583409990801,
      "grad_norm": 0.1005539819598198,
      "learning_rate": 4.421636070338227e-05,
      "loss": 0.1073,
      "step": 17360
    },
    {
      "epoch": 0.34735831700195974,
      "grad_norm": 0.10273802280426025,
      "learning_rate": 4.421302777000094e-05,
      "loss": 0.0971,
      "step": 17370
    },
    {
      "epoch": 0.3475582930048394,
      "grad_norm": 0.1047137901186943,
      "learning_rate": 4.420969483661961e-05,
      "loss": 0.083,
      "step": 17380
    },
    {
      "epoch": 0.34775826900771906,
      "grad_norm": 0.14595922827720642,
      "learning_rate": 4.4206361903238283e-05,
      "loss": 0.0841,
      "step": 17390
    },
    {
      "epoch": 0.34795824501059874,
      "grad_norm": 0.15460698306560516,
      "learning_rate": 4.420302896985695e-05,
      "loss": 0.0917,
      "step": 17400
    },
    {
      "epoch": 0.3481582210134784,
      "grad_norm": 0.1603063941001892,
      "learning_rate": 4.419969603647562e-05,
      "loss": 0.0852,
      "step": 17410
    },
    {
      "epoch": 0.34835819701635806,
      "grad_norm": 0.05570944398641586,
      "learning_rate": 4.41963631030943e-05,
      "loss": 0.0857,
      "step": 17420
    },
    {
      "epoch": 0.3485581730192377,
      "grad_norm": 0.10428334027528763,
      "learning_rate": 4.419303016971297e-05,
      "loss": 0.1235,
      "step": 17430
    },
    {
      "epoch": 0.3487581490221173,
      "grad_norm": 0.13997882604599,
      "learning_rate": 4.418969723633164e-05,
      "loss": 0.0693,
      "step": 17440
    },
    {
      "epoch": 0.348958125024997,
      "grad_norm": 0.1770062893629074,
      "learning_rate": 4.4186364302950315e-05,
      "loss": 0.095,
      "step": 17450
    },
    {
      "epoch": 0.34915810102787664,
      "grad_norm": 0.16460314393043518,
      "learning_rate": 4.418303136956899e-05,
      "loss": 0.1024,
      "step": 17460
    },
    {
      "epoch": 0.34935807703075633,
      "grad_norm": 0.09637793898582458,
      "learning_rate": 4.417969843618766e-05,
      "loss": 0.0985,
      "step": 17470
    },
    {
      "epoch": 0.34955805303363596,
      "grad_norm": 0.08845104277133942,
      "learning_rate": 4.417636550280633e-05,
      "loss": 0.0449,
      "step": 17480
    },
    {
      "epoch": 0.3497580290365156,
      "grad_norm": 0.14554888010025024,
      "learning_rate": 4.417303256942501e-05,
      "loss": 0.0772,
      "step": 17490
    },
    {
      "epoch": 0.3499580050393953,
      "grad_norm": 0.09620162099599838,
      "learning_rate": 4.4169699636043676e-05,
      "loss": 0.0859,
      "step": 17500
    },
    {
      "epoch": 0.3501579810422749,
      "grad_norm": 0.07007471472024918,
      "learning_rate": 4.4166366702662346e-05,
      "loss": 0.0915,
      "step": 17510
    },
    {
      "epoch": 0.3503579570451546,
      "grad_norm": 0.10475227981805801,
      "learning_rate": 4.416303376928102e-05,
      "loss": 0.0511,
      "step": 17520
    },
    {
      "epoch": 0.35055793304803423,
      "grad_norm": 0.10932621359825134,
      "learning_rate": 4.415970083589969e-05,
      "loss": 0.0774,
      "step": 17530
    },
    {
      "epoch": 0.35075790905091386,
      "grad_norm": 0.09276746213436127,
      "learning_rate": 4.415636790251836e-05,
      "loss": 0.0679,
      "step": 17540
    },
    {
      "epoch": 0.35095788505379355,
      "grad_norm": 0.10415097326040268,
      "learning_rate": 4.4153034969137045e-05,
      "loss": 0.0802,
      "step": 17550
    },
    {
      "epoch": 0.3511578610566732,
      "grad_norm": 0.0728205144405365,
      "learning_rate": 4.4149702035755714e-05,
      "loss": 0.0551,
      "step": 17560
    },
    {
      "epoch": 0.35135783705955287,
      "grad_norm": 0.09792003035545349,
      "learning_rate": 4.4146369102374384e-05,
      "loss": 0.0901,
      "step": 17570
    },
    {
      "epoch": 0.3515578130624325,
      "grad_norm": 0.11956165730953217,
      "learning_rate": 4.414303616899306e-05,
      "loss": 0.0783,
      "step": 17580
    },
    {
      "epoch": 0.3517577890653122,
      "grad_norm": 0.2426895797252655,
      "learning_rate": 4.413970323561173e-05,
      "loss": 0.0951,
      "step": 17590
    },
    {
      "epoch": 0.3519577650681918,
      "grad_norm": 0.1280674934387207,
      "learning_rate": 4.41363703022304e-05,
      "loss": 0.095,
      "step": 17600
    },
    {
      "epoch": 0.35215774107107145,
      "grad_norm": 0.13111276924610138,
      "learning_rate": 4.4133037368849076e-05,
      "loss": 0.1182,
      "step": 17610
    },
    {
      "epoch": 0.35235771707395114,
      "grad_norm": 0.09162067621946335,
      "learning_rate": 4.4129704435467746e-05,
      "loss": 0.0675,
      "step": 17620
    },
    {
      "epoch": 0.35255769307683077,
      "grad_norm": 0.14519576728343964,
      "learning_rate": 4.4126371502086415e-05,
      "loss": 0.085,
      "step": 17630
    },
    {
      "epoch": 0.35275766907971046,
      "grad_norm": 0.08934694528579712,
      "learning_rate": 4.412303856870509e-05,
      "loss": 0.0632,
      "step": 17640
    },
    {
      "epoch": 0.3529576450825901,
      "grad_norm": 0.08062721788883209,
      "learning_rate": 4.411970563532377e-05,
      "loss": 0.0564,
      "step": 17650
    },
    {
      "epoch": 0.3531576210854697,
      "grad_norm": 0.1575869470834732,
      "learning_rate": 4.411637270194244e-05,
      "loss": 0.0673,
      "step": 17660
    },
    {
      "epoch": 0.3533575970883494,
      "grad_norm": 0.14965960383415222,
      "learning_rate": 4.411303976856111e-05,
      "loss": 0.0526,
      "step": 17670
    },
    {
      "epoch": 0.35355757309122904,
      "grad_norm": 0.15616396069526672,
      "learning_rate": 4.4109706835179784e-05,
      "loss": 0.065,
      "step": 17680
    },
    {
      "epoch": 0.3537575490941087,
      "grad_norm": 0.174534872174263,
      "learning_rate": 4.410637390179845e-05,
      "loss": 0.111,
      "step": 17690
    },
    {
      "epoch": 0.35395752509698836,
      "grad_norm": 0.14595791697502136,
      "learning_rate": 4.410304096841712e-05,
      "loss": 0.0594,
      "step": 17700
    },
    {
      "epoch": 0.354157501099868,
      "grad_norm": 0.0957566499710083,
      "learning_rate": 4.40997080350358e-05,
      "loss": 0.0869,
      "step": 17710
    },
    {
      "epoch": 0.3543574771027477,
      "grad_norm": 0.09591489285230637,
      "learning_rate": 4.409637510165447e-05,
      "loss": 0.0722,
      "step": 17720
    },
    {
      "epoch": 0.3545574531056273,
      "grad_norm": 0.20464810729026794,
      "learning_rate": 4.409304216827314e-05,
      "loss": 0.1277,
      "step": 17730
    },
    {
      "epoch": 0.354757429108507,
      "grad_norm": 0.08566299080848694,
      "learning_rate": 4.4089709234891815e-05,
      "loss": 0.0669,
      "step": 17740
    },
    {
      "epoch": 0.3549574051113866,
      "grad_norm": 0.08489464223384857,
      "learning_rate": 4.408637630151049e-05,
      "loss": 0.0754,
      "step": 17750
    },
    {
      "epoch": 0.3551573811142663,
      "grad_norm": 0.12032880634069443,
      "learning_rate": 4.408304336812916e-05,
      "loss": 0.0735,
      "step": 17760
    },
    {
      "epoch": 0.35535735711714594,
      "grad_norm": 0.16275689005851746,
      "learning_rate": 4.407971043474784e-05,
      "loss": 0.0711,
      "step": 17770
    },
    {
      "epoch": 0.3555573331200256,
      "grad_norm": 0.10818348079919815,
      "learning_rate": 4.407637750136651e-05,
      "loss": 0.086,
      "step": 17780
    },
    {
      "epoch": 0.35575730912290526,
      "grad_norm": 0.07672597467899323,
      "learning_rate": 4.4073044567985176e-05,
      "loss": 0.0662,
      "step": 17790
    },
    {
      "epoch": 0.3559572851257849,
      "grad_norm": 0.10843273252248764,
      "learning_rate": 4.406971163460385e-05,
      "loss": 0.0806,
      "step": 17800
    },
    {
      "epoch": 0.3561572611286646,
      "grad_norm": 0.08501159399747849,
      "learning_rate": 4.406637870122252e-05,
      "loss": 0.088,
      "step": 17810
    },
    {
      "epoch": 0.3563572371315442,
      "grad_norm": 0.12761661410331726,
      "learning_rate": 4.406304576784119e-05,
      "loss": 0.0791,
      "step": 17820
    },
    {
      "epoch": 0.35655721313442384,
      "grad_norm": 0.06079796329140663,
      "learning_rate": 4.405971283445987e-05,
      "loss": 0.0883,
      "step": 17830
    },
    {
      "epoch": 0.35675718913730353,
      "grad_norm": 0.18137000501155853,
      "learning_rate": 4.405637990107854e-05,
      "loss": 0.1161,
      "step": 17840
    },
    {
      "epoch": 0.35695716514018316,
      "grad_norm": 0.060401588678359985,
      "learning_rate": 4.405304696769721e-05,
      "loss": 0.0557,
      "step": 17850
    },
    {
      "epoch": 0.35715714114306285,
      "grad_norm": 0.22786732017993927,
      "learning_rate": 4.4049714034315884e-05,
      "loss": 0.1156,
      "step": 17860
    },
    {
      "epoch": 0.3573571171459425,
      "grad_norm": 0.17929846048355103,
      "learning_rate": 4.404638110093456e-05,
      "loss": 0.0913,
      "step": 17870
    },
    {
      "epoch": 0.3575570931488221,
      "grad_norm": 0.1072763055562973,
      "learning_rate": 4.404304816755323e-05,
      "loss": 0.0719,
      "step": 17880
    },
    {
      "epoch": 0.3577570691517018,
      "grad_norm": 0.07672805339097977,
      "learning_rate": 4.40397152341719e-05,
      "loss": 0.0513,
      "step": 17890
    },
    {
      "epoch": 0.35795704515458143,
      "grad_norm": 0.18259751796722412,
      "learning_rate": 4.4036382300790576e-05,
      "loss": 0.0977,
      "step": 17900
    },
    {
      "epoch": 0.3581570211574611,
      "grad_norm": 0.11604283004999161,
      "learning_rate": 4.4033049367409246e-05,
      "loss": 0.0598,
      "step": 17910
    },
    {
      "epoch": 0.35835699716034075,
      "grad_norm": 0.06213854253292084,
      "learning_rate": 4.4029716434027915e-05,
      "loss": 0.084,
      "step": 17920
    },
    {
      "epoch": 0.35855697316322044,
      "grad_norm": 0.16915132105350494,
      "learning_rate": 4.402638350064659e-05,
      "loss": 0.1022,
      "step": 17930
    },
    {
      "epoch": 0.35875694916610007,
      "grad_norm": 0.12140949070453644,
      "learning_rate": 4.402305056726526e-05,
      "loss": 0.0777,
      "step": 17940
    },
    {
      "epoch": 0.3589569251689797,
      "grad_norm": 0.12461774051189423,
      "learning_rate": 4.401971763388393e-05,
      "loss": 0.0807,
      "step": 17950
    },
    {
      "epoch": 0.3591569011718594,
      "grad_norm": 0.16450569033622742,
      "learning_rate": 4.4016384700502614e-05,
      "loss": 0.0868,
      "step": 17960
    },
    {
      "epoch": 0.359356877174739,
      "grad_norm": 0.09750815480947495,
      "learning_rate": 4.4013051767121284e-05,
      "loss": 0.0925,
      "step": 17970
    },
    {
      "epoch": 0.3595568531776187,
      "grad_norm": 0.10370921343564987,
      "learning_rate": 4.4009718833739953e-05,
      "loss": 0.0737,
      "step": 17980
    },
    {
      "epoch": 0.35975682918049834,
      "grad_norm": 0.06683602184057236,
      "learning_rate": 4.400638590035863e-05,
      "loss": 0.0582,
      "step": 17990
    },
    {
      "epoch": 0.35995680518337797,
      "grad_norm": 0.08785027265548706,
      "learning_rate": 4.40030529669773e-05,
      "loss": 0.0991,
      "step": 18000
    },
    {
      "epoch": 0.36015678118625766,
      "grad_norm": 0.08517413586378098,
      "learning_rate": 4.399972003359597e-05,
      "loss": 0.0902,
      "step": 18010
    },
    {
      "epoch": 0.3603567571891373,
      "grad_norm": 0.04789523035287857,
      "learning_rate": 4.3996387100214645e-05,
      "loss": 0.0871,
      "step": 18020
    },
    {
      "epoch": 0.360556733192017,
      "grad_norm": 0.16209539771080017,
      "learning_rate": 4.3993054166833315e-05,
      "loss": 0.1036,
      "step": 18030
    },
    {
      "epoch": 0.3607567091948966,
      "grad_norm": 0.14723248779773712,
      "learning_rate": 4.3989721233451985e-05,
      "loss": 0.0601,
      "step": 18040
    },
    {
      "epoch": 0.36095668519777624,
      "grad_norm": 0.17268329858779907,
      "learning_rate": 4.398638830007066e-05,
      "loss": 0.0767,
      "step": 18050
    },
    {
      "epoch": 0.3611566612006559,
      "grad_norm": 0.10814330726861954,
      "learning_rate": 4.398305536668934e-05,
      "loss": 0.0588,
      "step": 18060
    },
    {
      "epoch": 0.36135663720353556,
      "grad_norm": 0.26970937848091125,
      "learning_rate": 4.397972243330801e-05,
      "loss": 0.1911,
      "step": 18070
    },
    {
      "epoch": 0.36155661320641524,
      "grad_norm": 0.10978115350008011,
      "learning_rate": 4.397638949992668e-05,
      "loss": 0.0793,
      "step": 18080
    },
    {
      "epoch": 0.3617565892092949,
      "grad_norm": 0.16612428426742554,
      "learning_rate": 4.397305656654535e-05,
      "loss": 0.1069,
      "step": 18090
    },
    {
      "epoch": 0.36195656521217456,
      "grad_norm": 0.11923837661743164,
      "learning_rate": 4.396972363316402e-05,
      "loss": 0.0954,
      "step": 18100
    },
    {
      "epoch": 0.3621565412150542,
      "grad_norm": 0.10054786503314972,
      "learning_rate": 4.396639069978269e-05,
      "loss": 0.0746,
      "step": 18110
    },
    {
      "epoch": 0.3623565172179338,
      "grad_norm": 0.1097598597407341,
      "learning_rate": 4.396305776640137e-05,
      "loss": 0.062,
      "step": 18120
    },
    {
      "epoch": 0.3625564932208135,
      "grad_norm": 0.1451510488986969,
      "learning_rate": 4.395972483302004e-05,
      "loss": 0.0826,
      "step": 18130
    },
    {
      "epoch": 0.36275646922369315,
      "grad_norm": 0.1000317707657814,
      "learning_rate": 4.395639189963871e-05,
      "loss": 0.0539,
      "step": 18140
    },
    {
      "epoch": 0.36295644522657283,
      "grad_norm": 0.07757526636123657,
      "learning_rate": 4.3953058966257384e-05,
      "loss": 0.0828,
      "step": 18150
    },
    {
      "epoch": 0.36315642122945246,
      "grad_norm": 0.10009555518627167,
      "learning_rate": 4.394972603287606e-05,
      "loss": 0.0728,
      "step": 18160
    },
    {
      "epoch": 0.3633563972323321,
      "grad_norm": 0.15605084598064423,
      "learning_rate": 4.394639309949473e-05,
      "loss": 0.0745,
      "step": 18170
    },
    {
      "epoch": 0.3635563732352118,
      "grad_norm": 0.14990201592445374,
      "learning_rate": 4.394306016611341e-05,
      "loss": 0.0453,
      "step": 18180
    },
    {
      "epoch": 0.3637563492380914,
      "grad_norm": 0.1645805835723877,
      "learning_rate": 4.3939727232732076e-05,
      "loss": 0.0781,
      "step": 18190
    },
    {
      "epoch": 0.3639563252409711,
      "grad_norm": 0.15401694178581238,
      "learning_rate": 4.3936394299350746e-05,
      "loss": 0.0585,
      "step": 18200
    },
    {
      "epoch": 0.36415630124385073,
      "grad_norm": 0.05783647671341896,
      "learning_rate": 4.393306136596942e-05,
      "loss": 0.0656,
      "step": 18210
    },
    {
      "epoch": 0.3643562772467304,
      "grad_norm": 0.16280557215213776,
      "learning_rate": 4.392972843258809e-05,
      "loss": 0.0928,
      "step": 18220
    },
    {
      "epoch": 0.36455625324961005,
      "grad_norm": 0.14505070447921753,
      "learning_rate": 4.392639549920676e-05,
      "loss": 0.0591,
      "step": 18230
    },
    {
      "epoch": 0.3647562292524897,
      "grad_norm": 0.08045412600040436,
      "learning_rate": 4.392306256582544e-05,
      "loss": 0.0738,
      "step": 18240
    },
    {
      "epoch": 0.36495620525536937,
      "grad_norm": 0.11486097425222397,
      "learning_rate": 4.391972963244411e-05,
      "loss": 0.083,
      "step": 18250
    },
    {
      "epoch": 0.365156181258249,
      "grad_norm": 0.08352460712194443,
      "learning_rate": 4.3916396699062784e-05,
      "loss": 0.0659,
      "step": 18260
    },
    {
      "epoch": 0.3653561572611287,
      "grad_norm": 0.12484230101108551,
      "learning_rate": 4.3913063765681454e-05,
      "loss": 0.0639,
      "step": 18270
    },
    {
      "epoch": 0.3655561332640083,
      "grad_norm": 0.18617087602615356,
      "learning_rate": 4.390973083230013e-05,
      "loss": 0.0689,
      "step": 18280
    },
    {
      "epoch": 0.36575610926688795,
      "grad_norm": 0.1418967992067337,
      "learning_rate": 4.39063978989188e-05,
      "loss": 0.0999,
      "step": 18290
    },
    {
      "epoch": 0.36595608526976764,
      "grad_norm": 0.12407772988080978,
      "learning_rate": 4.390306496553747e-05,
      "loss": 0.0957,
      "step": 18300
    },
    {
      "epoch": 0.36615606127264727,
      "grad_norm": 0.20997555553913116,
      "learning_rate": 4.3899732032156146e-05,
      "loss": 0.1009,
      "step": 18310
    },
    {
      "epoch": 0.36635603727552696,
      "grad_norm": 0.08703699707984924,
      "learning_rate": 4.3896399098774815e-05,
      "loss": 0.0552,
      "step": 18320
    },
    {
      "epoch": 0.3665560132784066,
      "grad_norm": 0.1537027508020401,
      "learning_rate": 4.3893066165393485e-05,
      "loss": 0.0897,
      "step": 18330
    },
    {
      "epoch": 0.3667559892812862,
      "grad_norm": 0.10748234391212463,
      "learning_rate": 4.388973323201216e-05,
      "loss": 0.0995,
      "step": 18340
    },
    {
      "epoch": 0.3669559652841659,
      "grad_norm": 0.11369530111551285,
      "learning_rate": 4.388640029863083e-05,
      "loss": 0.0831,
      "step": 18350
    },
    {
      "epoch": 0.36715594128704554,
      "grad_norm": 0.1703193485736847,
      "learning_rate": 4.38830673652495e-05,
      "loss": 0.0989,
      "step": 18360
    },
    {
      "epoch": 0.3673559172899252,
      "grad_norm": 0.080325648188591,
      "learning_rate": 4.387973443186818e-05,
      "loss": 0.0532,
      "step": 18370
    },
    {
      "epoch": 0.36755589329280486,
      "grad_norm": 0.0662597268819809,
      "learning_rate": 4.387640149848685e-05,
      "loss": 0.0933,
      "step": 18380
    },
    {
      "epoch": 0.36775586929568455,
      "grad_norm": 0.13335581123828888,
      "learning_rate": 4.387306856510552e-05,
      "loss": 0.0877,
      "step": 18390
    },
    {
      "epoch": 0.3679558452985642,
      "grad_norm": 0.09143690019845963,
      "learning_rate": 4.38697356317242e-05,
      "loss": 0.0965,
      "step": 18400
    },
    {
      "epoch": 0.3681558213014438,
      "grad_norm": 0.11281826347112656,
      "learning_rate": 4.386640269834287e-05,
      "loss": 0.0645,
      "step": 18410
    },
    {
      "epoch": 0.3683557973043235,
      "grad_norm": 0.08424457162618637,
      "learning_rate": 4.386306976496154e-05,
      "loss": 0.0468,
      "step": 18420
    },
    {
      "epoch": 0.3685557733072031,
      "grad_norm": 0.06442994624376297,
      "learning_rate": 4.3859736831580215e-05,
      "loss": 0.066,
      "step": 18430
    },
    {
      "epoch": 0.3687557493100828,
      "grad_norm": 0.096366748213768,
      "learning_rate": 4.3856403898198884e-05,
      "loss": 0.0662,
      "step": 18440
    },
    {
      "epoch": 0.36895572531296245,
      "grad_norm": 0.17635731399059296,
      "learning_rate": 4.3853070964817554e-05,
      "loss": 0.093,
      "step": 18450
    },
    {
      "epoch": 0.3691557013158421,
      "grad_norm": 0.1984340399503708,
      "learning_rate": 4.384973803143623e-05,
      "loss": 0.0723,
      "step": 18460
    },
    {
      "epoch": 0.36935567731872176,
      "grad_norm": 0.14403465390205383,
      "learning_rate": 4.384640509805491e-05,
      "loss": 0.0703,
      "step": 18470
    },
    {
      "epoch": 0.3695556533216014,
      "grad_norm": 0.15138031542301178,
      "learning_rate": 4.3843072164673577e-05,
      "loss": 0.1031,
      "step": 18480
    },
    {
      "epoch": 0.3697556293244811,
      "grad_norm": 0.14190205931663513,
      "learning_rate": 4.3839739231292246e-05,
      "loss": 0.2428,
      "step": 18490
    },
    {
      "epoch": 0.3699556053273607,
      "grad_norm": 0.15315809845924377,
      "learning_rate": 4.383640629791092e-05,
      "loss": 0.0552,
      "step": 18500
    },
    {
      "epoch": 0.37015558133024035,
      "grad_norm": 0.09432131797075272,
      "learning_rate": 4.383307336452959e-05,
      "loss": 0.079,
      "step": 18510
    },
    {
      "epoch": 0.37035555733312003,
      "grad_norm": 0.10932791978120804,
      "learning_rate": 4.382974043114826e-05,
      "loss": 0.1411,
      "step": 18520
    },
    {
      "epoch": 0.37055553333599967,
      "grad_norm": 0.1788230985403061,
      "learning_rate": 4.382640749776694e-05,
      "loss": 0.1133,
      "step": 18530
    },
    {
      "epoch": 0.37075550933887935,
      "grad_norm": 0.18732264637947083,
      "learning_rate": 4.382307456438561e-05,
      "loss": 0.1077,
      "step": 18540
    },
    {
      "epoch": 0.370955485341759,
      "grad_norm": 0.09273866564035416,
      "learning_rate": 4.381974163100428e-05,
      "loss": 0.0759,
      "step": 18550
    },
    {
      "epoch": 0.37115546134463867,
      "grad_norm": 0.1416684091091156,
      "learning_rate": 4.3816408697622954e-05,
      "loss": 0.0668,
      "step": 18560
    },
    {
      "epoch": 0.3713554373475183,
      "grad_norm": 0.1688273400068283,
      "learning_rate": 4.381307576424163e-05,
      "loss": 0.206,
      "step": 18570
    },
    {
      "epoch": 0.37155541335039793,
      "grad_norm": 0.08413077145814896,
      "learning_rate": 4.38097428308603e-05,
      "loss": 0.087,
      "step": 18580
    },
    {
      "epoch": 0.3717553893532776,
      "grad_norm": 0.10188055038452148,
      "learning_rate": 4.380640989747897e-05,
      "loss": 0.085,
      "step": 18590
    },
    {
      "epoch": 0.37195536535615725,
      "grad_norm": 0.05803379788994789,
      "learning_rate": 4.3803076964097646e-05,
      "loss": 0.0969,
      "step": 18600
    },
    {
      "epoch": 0.37215534135903694,
      "grad_norm": 0.127935528755188,
      "learning_rate": 4.3799744030716315e-05,
      "loss": 0.0912,
      "step": 18610
    },
    {
      "epoch": 0.37235531736191657,
      "grad_norm": 0.09871579706668854,
      "learning_rate": 4.3796411097334985e-05,
      "loss": 0.0786,
      "step": 18620
    },
    {
      "epoch": 0.3725552933647962,
      "grad_norm": 0.10549675673246384,
      "learning_rate": 4.379307816395366e-05,
      "loss": 0.0938,
      "step": 18630
    },
    {
      "epoch": 0.3727552693676759,
      "grad_norm": 0.10064300894737244,
      "learning_rate": 4.378974523057233e-05,
      "loss": 0.1089,
      "step": 18640
    },
    {
      "epoch": 0.3729552453705555,
      "grad_norm": 0.11912692338228226,
      "learning_rate": 4.378641229719101e-05,
      "loss": 0.0948,
      "step": 18650
    },
    {
      "epoch": 0.3731552213734352,
      "grad_norm": 0.08278437703847885,
      "learning_rate": 4.378307936380968e-05,
      "loss": 0.0957,
      "step": 18660
    },
    {
      "epoch": 0.37335519737631484,
      "grad_norm": 0.19704541563987732,
      "learning_rate": 4.3779746430428353e-05,
      "loss": 0.0989,
      "step": 18670
    },
    {
      "epoch": 0.37355517337919447,
      "grad_norm": 0.25656524300575256,
      "learning_rate": 4.377641349704702e-05,
      "loss": 0.0917,
      "step": 18680
    },
    {
      "epoch": 0.37375514938207416,
      "grad_norm": 0.21262836456298828,
      "learning_rate": 4.37730805636657e-05,
      "loss": 0.0637,
      "step": 18690
    },
    {
      "epoch": 0.3739551253849538,
      "grad_norm": 0.08945450186729431,
      "learning_rate": 4.376974763028437e-05,
      "loss": 0.0667,
      "step": 18700
    },
    {
      "epoch": 0.3741551013878335,
      "grad_norm": 0.05931912735104561,
      "learning_rate": 4.376641469690304e-05,
      "loss": 0.0871,
      "step": 18710
    },
    {
      "epoch": 0.3743550773907131,
      "grad_norm": 0.20874649286270142,
      "learning_rate": 4.3763081763521715e-05,
      "loss": 0.1486,
      "step": 18720
    },
    {
      "epoch": 0.3745550533935928,
      "grad_norm": 0.10093728452920914,
      "learning_rate": 4.3759748830140385e-05,
      "loss": 0.1078,
      "step": 18730
    },
    {
      "epoch": 0.3747550293964724,
      "grad_norm": 0.07524336129426956,
      "learning_rate": 4.3756415896759054e-05,
      "loss": 0.0602,
      "step": 18740
    },
    {
      "epoch": 0.37495500539935206,
      "grad_norm": 0.07225923985242844,
      "learning_rate": 4.375308296337773e-05,
      "loss": 0.0671,
      "step": 18750
    },
    {
      "epoch": 0.37515498140223175,
      "grad_norm": 0.03649118170142174,
      "learning_rate": 4.37497500299964e-05,
      "loss": 0.0546,
      "step": 18760
    },
    {
      "epoch": 0.3753549574051114,
      "grad_norm": 0.06258703023195267,
      "learning_rate": 4.374641709661508e-05,
      "loss": 0.1043,
      "step": 18770
    },
    {
      "epoch": 0.37555493340799107,
      "grad_norm": 0.13722780346870422,
      "learning_rate": 4.3743084163233746e-05,
      "loss": 0.0853,
      "step": 18780
    },
    {
      "epoch": 0.3757549094108707,
      "grad_norm": 0.11354431509971619,
      "learning_rate": 4.373975122985242e-05,
      "loss": 0.0727,
      "step": 18790
    },
    {
      "epoch": 0.37595488541375033,
      "grad_norm": 0.15433849394321442,
      "learning_rate": 4.373641829647109e-05,
      "loss": 0.0835,
      "step": 18800
    },
    {
      "epoch": 0.37615486141663,
      "grad_norm": 0.1606333702802658,
      "learning_rate": 4.373308536308976e-05,
      "loss": 0.0775,
      "step": 18810
    },
    {
      "epoch": 0.37635483741950965,
      "grad_norm": 0.16420818865299225,
      "learning_rate": 4.372975242970844e-05,
      "loss": 0.1104,
      "step": 18820
    },
    {
      "epoch": 0.37655481342238933,
      "grad_norm": 0.08088216185569763,
      "learning_rate": 4.372641949632711e-05,
      "loss": 0.0681,
      "step": 18830
    },
    {
      "epoch": 0.37675478942526897,
      "grad_norm": 0.11857482045888901,
      "learning_rate": 4.372308656294578e-05,
      "loss": 0.1062,
      "step": 18840
    },
    {
      "epoch": 0.3769547654281486,
      "grad_norm": 0.13470157980918884,
      "learning_rate": 4.3719753629564454e-05,
      "loss": 0.0887,
      "step": 18850
    },
    {
      "epoch": 0.3771547414310283,
      "grad_norm": 0.10384128242731094,
      "learning_rate": 4.3716420696183124e-05,
      "loss": 0.1079,
      "step": 18860
    },
    {
      "epoch": 0.3773547174339079,
      "grad_norm": 0.11484798789024353,
      "learning_rate": 4.371308776280179e-05,
      "loss": 0.0562,
      "step": 18870
    },
    {
      "epoch": 0.3775546934367876,
      "grad_norm": 0.12171564996242523,
      "learning_rate": 4.3709754829420476e-05,
      "loss": 0.1085,
      "step": 18880
    },
    {
      "epoch": 0.37775466943966723,
      "grad_norm": 0.06944740563631058,
      "learning_rate": 4.3706421896039146e-05,
      "loss": 0.063,
      "step": 18890
    },
    {
      "epoch": 0.3779546454425469,
      "grad_norm": 0.1454615443944931,
      "learning_rate": 4.3703088962657816e-05,
      "loss": 0.106,
      "step": 18900
    },
    {
      "epoch": 0.37815462144542655,
      "grad_norm": 0.08690345287322998,
      "learning_rate": 4.369975602927649e-05,
      "loss": 0.0614,
      "step": 18910
    },
    {
      "epoch": 0.3783545974483062,
      "grad_norm": 0.10399582982063293,
      "learning_rate": 4.369642309589516e-05,
      "loss": 0.0878,
      "step": 18920
    },
    {
      "epoch": 0.37855457345118587,
      "grad_norm": 0.22481675446033478,
      "learning_rate": 4.369309016251383e-05,
      "loss": 0.0818,
      "step": 18930
    },
    {
      "epoch": 0.3787545494540655,
      "grad_norm": 0.16028420627117157,
      "learning_rate": 4.368975722913251e-05,
      "loss": 0.0891,
      "step": 18940
    },
    {
      "epoch": 0.3789545254569452,
      "grad_norm": 0.1346941441297531,
      "learning_rate": 4.368642429575118e-05,
      "loss": 0.1042,
      "step": 18950
    },
    {
      "epoch": 0.3791545014598248,
      "grad_norm": 0.06171807646751404,
      "learning_rate": 4.368309136236985e-05,
      "loss": 0.0666,
      "step": 18960
    },
    {
      "epoch": 0.37935447746270445,
      "grad_norm": 0.15050368010997772,
      "learning_rate": 4.367975842898852e-05,
      "loss": 0.0775,
      "step": 18970
    },
    {
      "epoch": 0.37955445346558414,
      "grad_norm": 0.16015610098838806,
      "learning_rate": 4.36764254956072e-05,
      "loss": 0.0968,
      "step": 18980
    },
    {
      "epoch": 0.37975442946846377,
      "grad_norm": 0.07364262640476227,
      "learning_rate": 4.367309256222587e-05,
      "loss": 0.0536,
      "step": 18990
    },
    {
      "epoch": 0.37995440547134346,
      "grad_norm": 0.06276281177997589,
      "learning_rate": 4.366975962884454e-05,
      "loss": 0.0585,
      "step": 19000
    },
    {
      "epoch": 0.3801543814742231,
      "grad_norm": 0.07401032745838165,
      "learning_rate": 4.3666426695463215e-05,
      "loss": 0.0891,
      "step": 19010
    },
    {
      "epoch": 0.3803543574771027,
      "grad_norm": 0.21273155510425568,
      "learning_rate": 4.3663093762081885e-05,
      "loss": 0.0621,
      "step": 19020
    },
    {
      "epoch": 0.3805543334799824,
      "grad_norm": 0.08385566622018814,
      "learning_rate": 4.3659760828700554e-05,
      "loss": 0.1074,
      "step": 19030
    },
    {
      "epoch": 0.38075430948286204,
      "grad_norm": 0.22426673769950867,
      "learning_rate": 4.365642789531923e-05,
      "loss": 0.1013,
      "step": 19040
    },
    {
      "epoch": 0.38095428548574173,
      "grad_norm": 0.09578163176774979,
      "learning_rate": 4.36530949619379e-05,
      "loss": 0.0544,
      "step": 19050
    },
    {
      "epoch": 0.38115426148862136,
      "grad_norm": 0.10116304457187653,
      "learning_rate": 4.364976202855657e-05,
      "loss": 0.0779,
      "step": 19060
    },
    {
      "epoch": 0.38135423749150105,
      "grad_norm": 0.20357666909694672,
      "learning_rate": 4.3646429095175246e-05,
      "loss": 0.0597,
      "step": 19070
    },
    {
      "epoch": 0.3815542134943807,
      "grad_norm": 0.07863336056470871,
      "learning_rate": 4.364309616179392e-05,
      "loss": 0.0903,
      "step": 19080
    },
    {
      "epoch": 0.3817541894972603,
      "grad_norm": 0.07494542002677917,
      "learning_rate": 4.363976322841259e-05,
      "loss": 0.0715,
      "step": 19090
    },
    {
      "epoch": 0.38195416550014,
      "grad_norm": 0.10306910425424576,
      "learning_rate": 4.363643029503127e-05,
      "loss": 0.0952,
      "step": 19100
    },
    {
      "epoch": 0.38215414150301963,
      "grad_norm": 0.1849047690629959,
      "learning_rate": 4.363309736164994e-05,
      "loss": 0.0762,
      "step": 19110
    },
    {
      "epoch": 0.3823541175058993,
      "grad_norm": 0.10111857205629349,
      "learning_rate": 4.362976442826861e-05,
      "loss": 0.059,
      "step": 19120
    },
    {
      "epoch": 0.38255409350877895,
      "grad_norm": 0.08429399877786636,
      "learning_rate": 4.3626431494887284e-05,
      "loss": 0.0701,
      "step": 19130
    },
    {
      "epoch": 0.3827540695116586,
      "grad_norm": 0.10962323844432831,
      "learning_rate": 4.3623098561505954e-05,
      "loss": 0.0931,
      "step": 19140
    },
    {
      "epoch": 0.38295404551453827,
      "grad_norm": 0.09832774847745895,
      "learning_rate": 4.3619765628124624e-05,
      "loss": 0.0911,
      "step": 19150
    },
    {
      "epoch": 0.3831540215174179,
      "grad_norm": 0.1015033945441246,
      "learning_rate": 4.36164326947433e-05,
      "loss": 0.0617,
      "step": 19160
    },
    {
      "epoch": 0.3833539975202976,
      "grad_norm": 0.15788108110427856,
      "learning_rate": 4.361309976136197e-05,
      "loss": 0.1511,
      "step": 19170
    },
    {
      "epoch": 0.3835539735231772,
      "grad_norm": 0.10007914155721664,
      "learning_rate": 4.3609766827980646e-05,
      "loss": 0.0984,
      "step": 19180
    },
    {
      "epoch": 0.38375394952605685,
      "grad_norm": 0.061394061893224716,
      "learning_rate": 4.3606433894599316e-05,
      "loss": 0.0713,
      "step": 19190
    },
    {
      "epoch": 0.38395392552893653,
      "grad_norm": 0.1025390699505806,
      "learning_rate": 4.360310096121799e-05,
      "loss": 0.0643,
      "step": 19200
    },
    {
      "epoch": 0.38415390153181617,
      "grad_norm": 0.09443269670009613,
      "learning_rate": 4.359976802783666e-05,
      "loss": 0.0679,
      "step": 19210
    },
    {
      "epoch": 0.38435387753469585,
      "grad_norm": 0.09718930721282959,
      "learning_rate": 4.359643509445533e-05,
      "loss": 0.0831,
      "step": 19220
    },
    {
      "epoch": 0.3845538535375755,
      "grad_norm": 0.18733462691307068,
      "learning_rate": 4.359310216107401e-05,
      "loss": 0.0797,
      "step": 19230
    },
    {
      "epoch": 0.3847538295404552,
      "grad_norm": 0.16139836609363556,
      "learning_rate": 4.358976922769268e-05,
      "loss": 0.3472,
      "step": 19240
    },
    {
      "epoch": 0.3849538055433348,
      "grad_norm": 0.1157628744840622,
      "learning_rate": 4.358643629431135e-05,
      "loss": 0.0548,
      "step": 19250
    },
    {
      "epoch": 0.38515378154621444,
      "grad_norm": 0.0939205214381218,
      "learning_rate": 4.358310336093002e-05,
      "loss": 0.0642,
      "step": 19260
    },
    {
      "epoch": 0.3853537575490941,
      "grad_norm": 0.06213018670678139,
      "learning_rate": 4.357977042754869e-05,
      "loss": 0.0723,
      "step": 19270
    },
    {
      "epoch": 0.38555373355197375,
      "grad_norm": 0.15003380179405212,
      "learning_rate": 4.357643749416737e-05,
      "loss": 0.0931,
      "step": 19280
    },
    {
      "epoch": 0.38575370955485344,
      "grad_norm": 0.11885804682970047,
      "learning_rate": 4.3573104560786046e-05,
      "loss": 0.0607,
      "step": 19290
    },
    {
      "epoch": 0.3859536855577331,
      "grad_norm": 0.056306399405002594,
      "learning_rate": 4.3569771627404715e-05,
      "loss": 0.0605,
      "step": 19300
    },
    {
      "epoch": 0.3861536615606127,
      "grad_norm": 0.10063289105892181,
      "learning_rate": 4.3566438694023385e-05,
      "loss": 0.0727,
      "step": 19310
    },
    {
      "epoch": 0.3863536375634924,
      "grad_norm": 0.13210657238960266,
      "learning_rate": 4.356310576064206e-05,
      "loss": 0.1356,
      "step": 19320
    },
    {
      "epoch": 0.386553613566372,
      "grad_norm": 0.19352838397026062,
      "learning_rate": 4.355977282726073e-05,
      "loss": 0.0837,
      "step": 19330
    },
    {
      "epoch": 0.3867535895692517,
      "grad_norm": 0.09397530555725098,
      "learning_rate": 4.35564398938794e-05,
      "loss": 0.0798,
      "step": 19340
    },
    {
      "epoch": 0.38695356557213134,
      "grad_norm": 0.1069328561425209,
      "learning_rate": 4.355310696049808e-05,
      "loss": 0.0894,
      "step": 19350
    },
    {
      "epoch": 0.387153541575011,
      "grad_norm": 0.20001916587352753,
      "learning_rate": 4.354977402711675e-05,
      "loss": 0.103,
      "step": 19360
    },
    {
      "epoch": 0.38735351757789066,
      "grad_norm": 0.17408467829227448,
      "learning_rate": 4.3546441093735416e-05,
      "loss": 0.0882,
      "step": 19370
    },
    {
      "epoch": 0.3875534935807703,
      "grad_norm": 0.09950099140405655,
      "learning_rate": 4.354310816035409e-05,
      "loss": 0.0547,
      "step": 19380
    },
    {
      "epoch": 0.38775346958365,
      "grad_norm": 0.08654916286468506,
      "learning_rate": 4.353977522697277e-05,
      "loss": 0.1012,
      "step": 19390
    },
    {
      "epoch": 0.3879534455865296,
      "grad_norm": 0.08305252343416214,
      "learning_rate": 4.353644229359144e-05,
      "loss": 0.0539,
      "step": 19400
    },
    {
      "epoch": 0.3881534215894093,
      "grad_norm": 0.13430845737457275,
      "learning_rate": 4.353310936021011e-05,
      "loss": 0.0458,
      "step": 19410
    },
    {
      "epoch": 0.38835339759228893,
      "grad_norm": 0.15140993893146515,
      "learning_rate": 4.3529776426828785e-05,
      "loss": 0.0759,
      "step": 19420
    },
    {
      "epoch": 0.38855337359516856,
      "grad_norm": 0.06722825020551682,
      "learning_rate": 4.3526443493447454e-05,
      "loss": 0.0666,
      "step": 19430
    },
    {
      "epoch": 0.38875334959804825,
      "grad_norm": 0.06276962161064148,
      "learning_rate": 4.3523110560066124e-05,
      "loss": 0.1717,
      "step": 19440
    },
    {
      "epoch": 0.3889533256009279,
      "grad_norm": 0.1548633724451065,
      "learning_rate": 4.35197776266848e-05,
      "loss": 0.1342,
      "step": 19450
    },
    {
      "epoch": 0.38915330160380757,
      "grad_norm": 0.11886697262525558,
      "learning_rate": 4.351644469330347e-05,
      "loss": 0.1031,
      "step": 19460
    },
    {
      "epoch": 0.3893532776066872,
      "grad_norm": 0.1554584950208664,
      "learning_rate": 4.351311175992214e-05,
      "loss": 0.1051,
      "step": 19470
    },
    {
      "epoch": 0.38955325360956683,
      "grad_norm": 0.1717648208141327,
      "learning_rate": 4.3509778826540816e-05,
      "loss": 0.0716,
      "step": 19480
    },
    {
      "epoch": 0.3897532296124465,
      "grad_norm": 0.07335333526134491,
      "learning_rate": 4.350644589315949e-05,
      "loss": 0.0811,
      "step": 19490
    },
    {
      "epoch": 0.38995320561532615,
      "grad_norm": 0.06971430033445358,
      "learning_rate": 4.350311295977816e-05,
      "loss": 0.0781,
      "step": 19500
    },
    {
      "epoch": 0.39015318161820584,
      "grad_norm": 0.0651034265756607,
      "learning_rate": 4.349978002639684e-05,
      "loss": 0.1219,
      "step": 19510
    },
    {
      "epoch": 0.39035315762108547,
      "grad_norm": 0.15386243164539337,
      "learning_rate": 4.349644709301551e-05,
      "loss": 0.0878,
      "step": 19520
    },
    {
      "epoch": 0.3905531336239651,
      "grad_norm": 0.20875431597232819,
      "learning_rate": 4.349311415963418e-05,
      "loss": 0.0562,
      "step": 19530
    },
    {
      "epoch": 0.3907531096268448,
      "grad_norm": 0.07414203137159348,
      "learning_rate": 4.3489781226252854e-05,
      "loss": 0.0969,
      "step": 19540
    },
    {
      "epoch": 0.3909530856297244,
      "grad_norm": 0.19878043234348297,
      "learning_rate": 4.3486448292871524e-05,
      "loss": 0.0828,
      "step": 19550
    },
    {
      "epoch": 0.3911530616326041,
      "grad_norm": 0.09939158707857132,
      "learning_rate": 4.348311535949019e-05,
      "loss": 0.0811,
      "step": 19560
    },
    {
      "epoch": 0.39135303763548374,
      "grad_norm": 0.20347380638122559,
      "learning_rate": 4.347978242610887e-05,
      "loss": 0.1198,
      "step": 19570
    },
    {
      "epoch": 0.3915530136383634,
      "grad_norm": 0.15163929760456085,
      "learning_rate": 4.347644949272754e-05,
      "loss": 0.0942,
      "step": 19580
    },
    {
      "epoch": 0.39175298964124305,
      "grad_norm": 0.10187096893787384,
      "learning_rate": 4.3473116559346216e-05,
      "loss": 0.0694,
      "step": 19590
    },
    {
      "epoch": 0.3919529656441227,
      "grad_norm": 0.12511765956878662,
      "learning_rate": 4.3469783625964885e-05,
      "loss": 0.0873,
      "step": 19600
    },
    {
      "epoch": 0.3921529416470024,
      "grad_norm": 0.07712223380804062,
      "learning_rate": 4.346645069258356e-05,
      "loss": 0.0785,
      "step": 19610
    },
    {
      "epoch": 0.392352917649882,
      "grad_norm": 0.08426939696073532,
      "learning_rate": 4.346311775920223e-05,
      "loss": 0.046,
      "step": 19620
    },
    {
      "epoch": 0.3925528936527617,
      "grad_norm": 0.16941648721694946,
      "learning_rate": 4.34597848258209e-05,
      "loss": 0.1198,
      "step": 19630
    },
    {
      "epoch": 0.3927528696556413,
      "grad_norm": 0.0652775913476944,
      "learning_rate": 4.345645189243958e-05,
      "loss": 0.0905,
      "step": 19640
    },
    {
      "epoch": 0.39295284565852096,
      "grad_norm": 0.19749648869037628,
      "learning_rate": 4.345311895905825e-05,
      "loss": 0.1207,
      "step": 19650
    },
    {
      "epoch": 0.39315282166140064,
      "grad_norm": 0.2121201604604721,
      "learning_rate": 4.3449786025676916e-05,
      "loss": 0.0869,
      "step": 19660
    },
    {
      "epoch": 0.3933527976642803,
      "grad_norm": 0.09116604179143906,
      "learning_rate": 4.344645309229559e-05,
      "loss": 0.0566,
      "step": 19670
    },
    {
      "epoch": 0.39355277366715996,
      "grad_norm": 0.17823423445224762,
      "learning_rate": 4.344312015891426e-05,
      "loss": 0.0796,
      "step": 19680
    },
    {
      "epoch": 0.3937527496700396,
      "grad_norm": 0.12494024634361267,
      "learning_rate": 4.343978722553294e-05,
      "loss": 0.0947,
      "step": 19690
    },
    {
      "epoch": 0.3939527256729192,
      "grad_norm": 0.17128045856952667,
      "learning_rate": 4.3436454292151615e-05,
      "loss": 0.0713,
      "step": 19700
    },
    {
      "epoch": 0.3941527016757989,
      "grad_norm": 0.12192664295434952,
      "learning_rate": 4.3433121358770285e-05,
      "loss": 0.0789,
      "step": 19710
    },
    {
      "epoch": 0.39435267767867854,
      "grad_norm": 0.15703031420707703,
      "learning_rate": 4.3429788425388954e-05,
      "loss": 0.0689,
      "step": 19720
    },
    {
      "epoch": 0.39455265368155823,
      "grad_norm": 0.1349639594554901,
      "learning_rate": 4.342645549200763e-05,
      "loss": 0.1,
      "step": 19730
    },
    {
      "epoch": 0.39475262968443786,
      "grad_norm": 0.1651698350906372,
      "learning_rate": 4.34231225586263e-05,
      "loss": 0.0658,
      "step": 19740
    },
    {
      "epoch": 0.39495260568731755,
      "grad_norm": 0.09158064424991608,
      "learning_rate": 4.341978962524497e-05,
      "loss": 0.0926,
      "step": 19750
    },
    {
      "epoch": 0.3951525816901972,
      "grad_norm": 0.16069729626178741,
      "learning_rate": 4.3416456691863646e-05,
      "loss": 0.0853,
      "step": 19760
    },
    {
      "epoch": 0.3953525576930768,
      "grad_norm": 0.1197396069765091,
      "learning_rate": 4.3413123758482316e-05,
      "loss": 0.0734,
      "step": 19770
    },
    {
      "epoch": 0.3955525336959565,
      "grad_norm": 0.13055235147476196,
      "learning_rate": 4.3409790825100986e-05,
      "loss": 0.0719,
      "step": 19780
    },
    {
      "epoch": 0.39575250969883613,
      "grad_norm": 0.1615140438079834,
      "learning_rate": 4.340645789171966e-05,
      "loss": 0.0624,
      "step": 19790
    },
    {
      "epoch": 0.3959524857017158,
      "grad_norm": 0.08859789371490479,
      "learning_rate": 4.340312495833834e-05,
      "loss": 0.0682,
      "step": 19800
    },
    {
      "epoch": 0.39615246170459545,
      "grad_norm": 0.11853878945112228,
      "learning_rate": 4.339979202495701e-05,
      "loss": 0.0807,
      "step": 19810
    },
    {
      "epoch": 0.3963524377074751,
      "grad_norm": 0.11849190294742584,
      "learning_rate": 4.339645909157568e-05,
      "loss": 0.0871,
      "step": 19820
    },
    {
      "epoch": 0.39655241371035477,
      "grad_norm": 0.14171817898750305,
      "learning_rate": 4.3393126158194354e-05,
      "loss": 0.0644,
      "step": 19830
    },
    {
      "epoch": 0.3967523897132344,
      "grad_norm": 0.09757246822118759,
      "learning_rate": 4.3389793224813024e-05,
      "loss": 0.0868,
      "step": 19840
    },
    {
      "epoch": 0.3969523657161141,
      "grad_norm": 0.16252246499061584,
      "learning_rate": 4.338646029143169e-05,
      "loss": 0.0532,
      "step": 19850
    },
    {
      "epoch": 0.3971523417189937,
      "grad_norm": 0.1351824402809143,
      "learning_rate": 4.338312735805037e-05,
      "loss": 0.0429,
      "step": 19860
    },
    {
      "epoch": 0.39735231772187335,
      "grad_norm": 0.0949709415435791,
      "learning_rate": 4.337979442466904e-05,
      "loss": 0.0658,
      "step": 19870
    },
    {
      "epoch": 0.39755229372475304,
      "grad_norm": 0.13229437172412872,
      "learning_rate": 4.337646149128771e-05,
      "loss": 0.1031,
      "step": 19880
    },
    {
      "epoch": 0.39775226972763267,
      "grad_norm": 0.09634756296873093,
      "learning_rate": 4.3373128557906385e-05,
      "loss": 0.0926,
      "step": 19890
    },
    {
      "epoch": 0.39795224573051236,
      "grad_norm": 0.15347272157669067,
      "learning_rate": 4.336979562452506e-05,
      "loss": 0.0777,
      "step": 19900
    },
    {
      "epoch": 0.398152221733392,
      "grad_norm": 0.07876121997833252,
      "learning_rate": 4.336646269114373e-05,
      "loss": 0.0626,
      "step": 19910
    },
    {
      "epoch": 0.3983521977362717,
      "grad_norm": 0.09907745569944382,
      "learning_rate": 4.336312975776241e-05,
      "loss": 0.0555,
      "step": 19920
    },
    {
      "epoch": 0.3985521737391513,
      "grad_norm": 0.1770290583372116,
      "learning_rate": 4.335979682438108e-05,
      "loss": 0.4555,
      "step": 19930
    },
    {
      "epoch": 0.39875214974203094,
      "grad_norm": 0.10206075012683868,
      "learning_rate": 4.335646389099975e-05,
      "loss": 0.0512,
      "step": 19940
    },
    {
      "epoch": 0.3989521257449106,
      "grad_norm": 0.21094144880771637,
      "learning_rate": 4.3353130957618423e-05,
      "loss": 0.1297,
      "step": 19950
    },
    {
      "epoch": 0.39915210174779026,
      "grad_norm": 0.19800002872943878,
      "learning_rate": 4.334979802423709e-05,
      "loss": 0.0998,
      "step": 19960
    },
    {
      "epoch": 0.39935207775066994,
      "grad_norm": 0.051819540560245514,
      "learning_rate": 4.334646509085576e-05,
      "loss": 0.0893,
      "step": 19970
    },
    {
      "epoch": 0.3995520537535496,
      "grad_norm": 0.14192597568035126,
      "learning_rate": 4.334313215747444e-05,
      "loss": 0.0625,
      "step": 19980
    },
    {
      "epoch": 0.3997520297564292,
      "grad_norm": 0.13994096219539642,
      "learning_rate": 4.333979922409311e-05,
      "loss": 0.0483,
      "step": 19990
    },
    {
      "epoch": 0.3999520057593089,
      "grad_norm": 0.16893528401851654,
      "learning_rate": 4.3336466290711785e-05,
      "loss": 0.1062,
      "step": 20000
    },
    {
      "epoch": 0.4001519817621885,
      "grad_norm": 0.08026322722434998,
      "learning_rate": 4.3333133357330455e-05,
      "loss": 0.0893,
      "step": 20010
    },
    {
      "epoch": 0.4003519577650682,
      "grad_norm": 0.18090462684631348,
      "learning_rate": 4.332980042394913e-05,
      "loss": 0.2162,
      "step": 20020
    },
    {
      "epoch": 0.40055193376794784,
      "grad_norm": 0.16364598274230957,
      "learning_rate": 4.33264674905678e-05,
      "loss": 0.095,
      "step": 20030
    },
    {
      "epoch": 0.4007519097708275,
      "grad_norm": 0.10998973995447159,
      "learning_rate": 4.332313455718647e-05,
      "loss": 0.0939,
      "step": 20040
    },
    {
      "epoch": 0.40095188577370716,
      "grad_norm": 0.07689420878887177,
      "learning_rate": 4.331980162380515e-05,
      "loss": 0.0888,
      "step": 20050
    },
    {
      "epoch": 0.4011518617765868,
      "grad_norm": 0.13386820256710052,
      "learning_rate": 4.3316468690423816e-05,
      "loss": 0.0651,
      "step": 20060
    },
    {
      "epoch": 0.4013518377794665,
      "grad_norm": 0.07532382756471634,
      "learning_rate": 4.3313135757042486e-05,
      "loss": 0.0766,
      "step": 20070
    },
    {
      "epoch": 0.4015518137823461,
      "grad_norm": 0.14568418264389038,
      "learning_rate": 4.330980282366116e-05,
      "loss": 0.0878,
      "step": 20080
    },
    {
      "epoch": 0.4017517897852258,
      "grad_norm": 0.11381971091032028,
      "learning_rate": 4.330646989027983e-05,
      "loss": 0.0989,
      "step": 20090
    },
    {
      "epoch": 0.40195176578810543,
      "grad_norm": 0.12738268077373505,
      "learning_rate": 4.330313695689851e-05,
      "loss": 0.0692,
      "step": 20100
    },
    {
      "epoch": 0.40215174179098506,
      "grad_norm": 0.08748994767665863,
      "learning_rate": 4.3299804023517185e-05,
      "loss": 0.0557,
      "step": 20110
    },
    {
      "epoch": 0.40235171779386475,
      "grad_norm": 0.21594588458538055,
      "learning_rate": 4.3296471090135854e-05,
      "loss": 0.1035,
      "step": 20120
    },
    {
      "epoch": 0.4025516937967444,
      "grad_norm": 0.14285895228385925,
      "learning_rate": 4.3293138156754524e-05,
      "loss": 0.0816,
      "step": 20130
    },
    {
      "epoch": 0.40275166979962407,
      "grad_norm": 0.10786177217960358,
      "learning_rate": 4.32898052233732e-05,
      "loss": 0.0779,
      "step": 20140
    },
    {
      "epoch": 0.4029516458025037,
      "grad_norm": 0.10724695771932602,
      "learning_rate": 4.328647228999187e-05,
      "loss": 0.0832,
      "step": 20150
    },
    {
      "epoch": 0.40315162180538333,
      "grad_norm": 0.21604065597057343,
      "learning_rate": 4.328313935661054e-05,
      "loss": 0.1397,
      "step": 20160
    },
    {
      "epoch": 0.403351597808263,
      "grad_norm": 0.09545543044805527,
      "learning_rate": 4.3279806423229216e-05,
      "loss": 0.0839,
      "step": 20170
    },
    {
      "epoch": 0.40355157381114265,
      "grad_norm": 0.07021606713533401,
      "learning_rate": 4.3276473489847886e-05,
      "loss": 0.0807,
      "step": 20180
    },
    {
      "epoch": 0.40375154981402234,
      "grad_norm": 0.1513420194387436,
      "learning_rate": 4.3273140556466555e-05,
      "loss": 0.1105,
      "step": 20190
    },
    {
      "epoch": 0.40395152581690197,
      "grad_norm": 0.0814286321401596,
      "learning_rate": 4.326980762308523e-05,
      "loss": 0.0451,
      "step": 20200
    },
    {
      "epoch": 0.4041515018197816,
      "grad_norm": 0.20183883607387543,
      "learning_rate": 4.326647468970391e-05,
      "loss": 0.0965,
      "step": 20210
    },
    {
      "epoch": 0.4043514778226613,
      "grad_norm": 0.1209963858127594,
      "learning_rate": 4.326314175632258e-05,
      "loss": 0.0803,
      "step": 20220
    },
    {
      "epoch": 0.4045514538255409,
      "grad_norm": 0.1387399286031723,
      "learning_rate": 4.325980882294125e-05,
      "loss": 0.0815,
      "step": 20230
    },
    {
      "epoch": 0.4047514298284206,
      "grad_norm": 0.1648416966199875,
      "learning_rate": 4.3256475889559924e-05,
      "loss": 0.2274,
      "step": 20240
    },
    {
      "epoch": 0.40495140583130024,
      "grad_norm": 0.23928983509540558,
      "learning_rate": 4.325314295617859e-05,
      "loss": 0.1138,
      "step": 20250
    },
    {
      "epoch": 0.4051513818341799,
      "grad_norm": 0.08193910866975784,
      "learning_rate": 4.324981002279726e-05,
      "loss": 0.0479,
      "step": 20260
    },
    {
      "epoch": 0.40535135783705956,
      "grad_norm": 0.15872961282730103,
      "learning_rate": 4.324647708941594e-05,
      "loss": 0.0953,
      "step": 20270
    },
    {
      "epoch": 0.4055513338399392,
      "grad_norm": 0.1501849740743637,
      "learning_rate": 4.324314415603461e-05,
      "loss": 0.0941,
      "step": 20280
    },
    {
      "epoch": 0.4057513098428189,
      "grad_norm": 0.10364747792482376,
      "learning_rate": 4.323981122265328e-05,
      "loss": 0.0851,
      "step": 20290
    },
    {
      "epoch": 0.4059512858456985,
      "grad_norm": 0.0778132751584053,
      "learning_rate": 4.323647828927196e-05,
      "loss": 0.0764,
      "step": 20300
    },
    {
      "epoch": 0.4061512618485782,
      "grad_norm": 0.08744098991155624,
      "learning_rate": 4.323314535589063e-05,
      "loss": 0.056,
      "step": 20310
    },
    {
      "epoch": 0.4063512378514578,
      "grad_norm": 0.06125892326235771,
      "learning_rate": 4.32298124225093e-05,
      "loss": 0.0579,
      "step": 20320
    },
    {
      "epoch": 0.40655121385433746,
      "grad_norm": 0.1626187264919281,
      "learning_rate": 4.322647948912798e-05,
      "loss": 0.1034,
      "step": 20330
    },
    {
      "epoch": 0.40675118985721714,
      "grad_norm": 0.11348696798086166,
      "learning_rate": 4.322314655574665e-05,
      "loss": 0.0976,
      "step": 20340
    },
    {
      "epoch": 0.4069511658600968,
      "grad_norm": 0.16618600487709045,
      "learning_rate": 4.3219813622365316e-05,
      "loss": 0.0943,
      "step": 20350
    },
    {
      "epoch": 0.40715114186297646,
      "grad_norm": 0.11169286072254181,
      "learning_rate": 4.321648068898399e-05,
      "loss": 0.0858,
      "step": 20360
    },
    {
      "epoch": 0.4073511178658561,
      "grad_norm": 0.20917436480522156,
      "learning_rate": 4.321314775560266e-05,
      "loss": 0.0665,
      "step": 20370
    },
    {
      "epoch": 0.4075510938687357,
      "grad_norm": 0.15619057416915894,
      "learning_rate": 4.320981482222133e-05,
      "loss": 0.0835,
      "step": 20380
    },
    {
      "epoch": 0.4077510698716154,
      "grad_norm": 0.10770941525697708,
      "learning_rate": 4.320648188884001e-05,
      "loss": 0.0599,
      "step": 20390
    },
    {
      "epoch": 0.40795104587449504,
      "grad_norm": 0.06687606126070023,
      "learning_rate": 4.320314895545868e-05,
      "loss": 0.0976,
      "step": 20400
    },
    {
      "epoch": 0.40815102187737473,
      "grad_norm": 0.13412675261497498,
      "learning_rate": 4.3199816022077354e-05,
      "loss": 0.0579,
      "step": 20410
    },
    {
      "epoch": 0.40835099788025436,
      "grad_norm": 0.06895971298217773,
      "learning_rate": 4.3196483088696024e-05,
      "loss": 0.0598,
      "step": 20420
    },
    {
      "epoch": 0.40855097388313405,
      "grad_norm": 0.12852059304714203,
      "learning_rate": 4.31931501553147e-05,
      "loss": 0.0856,
      "step": 20430
    },
    {
      "epoch": 0.4087509498860137,
      "grad_norm": 0.14408034086227417,
      "learning_rate": 4.318981722193337e-05,
      "loss": 0.0642,
      "step": 20440
    },
    {
      "epoch": 0.4089509258888933,
      "grad_norm": 0.1539684385061264,
      "learning_rate": 4.318648428855204e-05,
      "loss": 0.0859,
      "step": 20450
    },
    {
      "epoch": 0.409150901891773,
      "grad_norm": 0.07960931956768036,
      "learning_rate": 4.3183151355170716e-05,
      "loss": 0.1006,
      "step": 20460
    },
    {
      "epoch": 0.40935087789465263,
      "grad_norm": 0.22564205527305603,
      "learning_rate": 4.3179818421789386e-05,
      "loss": 0.1032,
      "step": 20470
    },
    {
      "epoch": 0.4095508538975323,
      "grad_norm": 0.1620844155550003,
      "learning_rate": 4.3176485488408055e-05,
      "loss": 0.1136,
      "step": 20480
    },
    {
      "epoch": 0.40975082990041195,
      "grad_norm": 0.18490910530090332,
      "learning_rate": 4.317315255502673e-05,
      "loss": 0.0841,
      "step": 20490
    },
    {
      "epoch": 0.4099508059032916,
      "grad_norm": 0.10760753601789474,
      "learning_rate": 4.31698196216454e-05,
      "loss": 0.1054,
      "step": 20500
    },
    {
      "epoch": 0.41015078190617127,
      "grad_norm": 0.19468176364898682,
      "learning_rate": 4.316648668826408e-05,
      "loss": 0.1091,
      "step": 20510
    },
    {
      "epoch": 0.4103507579090509,
      "grad_norm": 0.09878608584403992,
      "learning_rate": 4.3163153754882754e-05,
      "loss": 0.0688,
      "step": 20520
    },
    {
      "epoch": 0.4105507339119306,
      "grad_norm": 0.1388186365365982,
      "learning_rate": 4.3159820821501424e-05,
      "loss": 0.0893,
      "step": 20530
    },
    {
      "epoch": 0.4107507099148102,
      "grad_norm": 0.1633012741804123,
      "learning_rate": 4.315648788812009e-05,
      "loss": 0.107,
      "step": 20540
    },
    {
      "epoch": 0.41095068591768985,
      "grad_norm": 0.164754718542099,
      "learning_rate": 4.315315495473877e-05,
      "loss": 0.0889,
      "step": 20550
    },
    {
      "epoch": 0.41115066192056954,
      "grad_norm": 0.15121951699256897,
      "learning_rate": 4.314982202135744e-05,
      "loss": 0.0929,
      "step": 20560
    },
    {
      "epoch": 0.41135063792344917,
      "grad_norm": 0.14956526458263397,
      "learning_rate": 4.314648908797611e-05,
      "loss": 0.0683,
      "step": 20570
    },
    {
      "epoch": 0.41155061392632886,
      "grad_norm": 0.10109569132328033,
      "learning_rate": 4.3143156154594785e-05,
      "loss": 0.0721,
      "step": 20580
    },
    {
      "epoch": 0.4117505899292085,
      "grad_norm": 0.10579200834035873,
      "learning_rate": 4.3139823221213455e-05,
      "loss": 0.034,
      "step": 20590
    },
    {
      "epoch": 0.4119505659320882,
      "grad_norm": 0.08660244196653366,
      "learning_rate": 4.3136490287832125e-05,
      "loss": 0.0798,
      "step": 20600
    },
    {
      "epoch": 0.4121505419349678,
      "grad_norm": 0.06534380465745926,
      "learning_rate": 4.31331573544508e-05,
      "loss": 0.0524,
      "step": 20610
    },
    {
      "epoch": 0.41235051793784744,
      "grad_norm": 0.13601937890052795,
      "learning_rate": 4.312982442106948e-05,
      "loss": 0.0682,
      "step": 20620
    },
    {
      "epoch": 0.4125504939407271,
      "grad_norm": 0.11364296823740005,
      "learning_rate": 4.312649148768815e-05,
      "loss": 0.0726,
      "step": 20630
    },
    {
      "epoch": 0.41275046994360676,
      "grad_norm": 0.15799151360988617,
      "learning_rate": 4.312315855430682e-05,
      "loss": 0.1027,
      "step": 20640
    },
    {
      "epoch": 0.41295044594648644,
      "grad_norm": 0.10652349889278412,
      "learning_rate": 4.311982562092549e-05,
      "loss": 0.0694,
      "step": 20650
    },
    {
      "epoch": 0.4131504219493661,
      "grad_norm": 0.10969797521829605,
      "learning_rate": 4.311649268754416e-05,
      "loss": 0.0954,
      "step": 20660
    },
    {
      "epoch": 0.4133503979522457,
      "grad_norm": 0.12794509530067444,
      "learning_rate": 4.311315975416283e-05,
      "loss": 0.0728,
      "step": 20670
    },
    {
      "epoch": 0.4135503739551254,
      "grad_norm": 0.06411225348711014,
      "learning_rate": 4.310982682078151e-05,
      "loss": 0.0562,
      "step": 20680
    },
    {
      "epoch": 0.413750349958005,
      "grad_norm": 0.0714678168296814,
      "learning_rate": 4.310649388740018e-05,
      "loss": 0.0944,
      "step": 20690
    },
    {
      "epoch": 0.4139503259608847,
      "grad_norm": 0.07953256368637085,
      "learning_rate": 4.310316095401885e-05,
      "loss": 0.0906,
      "step": 20700
    },
    {
      "epoch": 0.41415030196376434,
      "grad_norm": 0.1093125268816948,
      "learning_rate": 4.309982802063753e-05,
      "loss": 0.0375,
      "step": 20710
    },
    {
      "epoch": 0.414350277966644,
      "grad_norm": 0.10736488550901413,
      "learning_rate": 4.30964950872562e-05,
      "loss": 0.0766,
      "step": 20720
    },
    {
      "epoch": 0.41455025396952366,
      "grad_norm": 0.059816066175699234,
      "learning_rate": 4.309316215387487e-05,
      "loss": 0.0727,
      "step": 20730
    },
    {
      "epoch": 0.4147502299724033,
      "grad_norm": 0.16176314651966095,
      "learning_rate": 4.308982922049355e-05,
      "loss": 0.1133,
      "step": 20740
    },
    {
      "epoch": 0.414950205975283,
      "grad_norm": 0.09831495583057404,
      "learning_rate": 4.3086496287112216e-05,
      "loss": 0.0895,
      "step": 20750
    },
    {
      "epoch": 0.4151501819781626,
      "grad_norm": 0.10490725189447403,
      "learning_rate": 4.3083163353730886e-05,
      "loss": 0.0731,
      "step": 20760
    },
    {
      "epoch": 0.4153501579810423,
      "grad_norm": 0.09019185602664948,
      "learning_rate": 4.307983042034956e-05,
      "loss": 0.0836,
      "step": 20770
    },
    {
      "epoch": 0.41555013398392193,
      "grad_norm": 0.08978550136089325,
      "learning_rate": 4.307649748696823e-05,
      "loss": 0.2284,
      "step": 20780
    },
    {
      "epoch": 0.41575010998680156,
      "grad_norm": 0.1324373483657837,
      "learning_rate": 4.30731645535869e-05,
      "loss": 0.0626,
      "step": 20790
    },
    {
      "epoch": 0.41595008598968125,
      "grad_norm": 0.07012729346752167,
      "learning_rate": 4.306983162020558e-05,
      "loss": 0.0791,
      "step": 20800
    },
    {
      "epoch": 0.4161500619925609,
      "grad_norm": 0.16047833859920502,
      "learning_rate": 4.3066498686824254e-05,
      "loss": 0.0635,
      "step": 20810
    },
    {
      "epoch": 0.41635003799544057,
      "grad_norm": 0.08345530182123184,
      "learning_rate": 4.3063165753442924e-05,
      "loss": 0.0505,
      "step": 20820
    },
    {
      "epoch": 0.4165500139983202,
      "grad_norm": 0.12440119683742523,
      "learning_rate": 4.3059832820061594e-05,
      "loss": 0.0564,
      "step": 20830
    },
    {
      "epoch": 0.41674999000119983,
      "grad_norm": 0.09156443923711777,
      "learning_rate": 4.305649988668027e-05,
      "loss": 0.0921,
      "step": 20840
    },
    {
      "epoch": 0.4169499660040795,
      "grad_norm": 0.07745246589183807,
      "learning_rate": 4.305316695329894e-05,
      "loss": 0.0866,
      "step": 20850
    },
    {
      "epoch": 0.41714994200695915,
      "grad_norm": 0.1585182547569275,
      "learning_rate": 4.304983401991761e-05,
      "loss": 0.0706,
      "step": 20860
    },
    {
      "epoch": 0.41734991800983884,
      "grad_norm": 0.0958416759967804,
      "learning_rate": 4.3046501086536286e-05,
      "loss": 0.1023,
      "step": 20870
    },
    {
      "epoch": 0.41754989401271847,
      "grad_norm": 0.17567375302314758,
      "learning_rate": 4.3043168153154955e-05,
      "loss": 0.0785,
      "step": 20880
    },
    {
      "epoch": 0.4177498700155981,
      "grad_norm": 0.1557350754737854,
      "learning_rate": 4.3039835219773625e-05,
      "loss": 0.0563,
      "step": 20890
    },
    {
      "epoch": 0.4179498460184778,
      "grad_norm": 0.15063469111919403,
      "learning_rate": 4.30365022863923e-05,
      "loss": 0.0813,
      "step": 20900
    },
    {
      "epoch": 0.4181498220213574,
      "grad_norm": 0.11355938017368317,
      "learning_rate": 4.303316935301097e-05,
      "loss": 0.0654,
      "step": 20910
    },
    {
      "epoch": 0.4183497980242371,
      "grad_norm": 0.1206035315990448,
      "learning_rate": 4.302983641962965e-05,
      "loss": 0.1115,
      "step": 20920
    },
    {
      "epoch": 0.41854977402711674,
      "grad_norm": 0.17374679446220398,
      "learning_rate": 4.3026503486248324e-05,
      "loss": 0.1038,
      "step": 20930
    },
    {
      "epoch": 0.4187497500299964,
      "grad_norm": 0.045266736298799515,
      "learning_rate": 4.302317055286699e-05,
      "loss": 0.0577,
      "step": 20940
    },
    {
      "epoch": 0.41894972603287606,
      "grad_norm": 0.06236552447080612,
      "learning_rate": 4.301983761948566e-05,
      "loss": 0.08,
      "step": 20950
    },
    {
      "epoch": 0.4191497020357557,
      "grad_norm": 0.2483816146850586,
      "learning_rate": 4.301650468610434e-05,
      "loss": 0.0784,
      "step": 20960
    },
    {
      "epoch": 0.4193496780386354,
      "grad_norm": 0.21098271012306213,
      "learning_rate": 4.301317175272301e-05,
      "loss": 0.1223,
      "step": 20970
    },
    {
      "epoch": 0.419549654041515,
      "grad_norm": 0.08656452596187592,
      "learning_rate": 4.300983881934168e-05,
      "loss": 0.0417,
      "step": 20980
    },
    {
      "epoch": 0.4197496300443947,
      "grad_norm": 0.0865752249956131,
      "learning_rate": 4.3006505885960355e-05,
      "loss": 0.078,
      "step": 20990
    },
    {
      "epoch": 0.4199496060472743,
      "grad_norm": 0.1401377022266388,
      "learning_rate": 4.3003172952579024e-05,
      "loss": 0.0829,
      "step": 21000
    },
    {
      "epoch": 0.42014958205015396,
      "grad_norm": 0.08405640721321106,
      "learning_rate": 4.2999840019197694e-05,
      "loss": 0.078,
      "step": 21010
    },
    {
      "epoch": 0.42034955805303365,
      "grad_norm": 0.1030266284942627,
      "learning_rate": 4.299650708581637e-05,
      "loss": 0.0641,
      "step": 21020
    },
    {
      "epoch": 0.4205495340559133,
      "grad_norm": 0.10126641392707825,
      "learning_rate": 4.299317415243505e-05,
      "loss": 0.057,
      "step": 21030
    },
    {
      "epoch": 0.42074951005879296,
      "grad_norm": 0.1346251368522644,
      "learning_rate": 4.2989841219053716e-05,
      "loss": 0.0821,
      "step": 21040
    },
    {
      "epoch": 0.4209494860616726,
      "grad_norm": 0.1621331125497818,
      "learning_rate": 4.2986508285672386e-05,
      "loss": 0.0861,
      "step": 21050
    },
    {
      "epoch": 0.4211494620645522,
      "grad_norm": 0.20040220022201538,
      "learning_rate": 4.298317535229106e-05,
      "loss": 0.0758,
      "step": 21060
    },
    {
      "epoch": 0.4213494380674319,
      "grad_norm": 0.10130349546670914,
      "learning_rate": 4.297984241890973e-05,
      "loss": 0.0696,
      "step": 21070
    },
    {
      "epoch": 0.42154941407031155,
      "grad_norm": 0.09152237325906754,
      "learning_rate": 4.29765094855284e-05,
      "loss": 0.0829,
      "step": 21080
    },
    {
      "epoch": 0.42174939007319123,
      "grad_norm": 0.11771150678396225,
      "learning_rate": 4.297317655214708e-05,
      "loss": 0.0737,
      "step": 21090
    },
    {
      "epoch": 0.42194936607607086,
      "grad_norm": 0.07401566207408905,
      "learning_rate": 4.296984361876575e-05,
      "loss": 0.0808,
      "step": 21100
    },
    {
      "epoch": 0.42214934207895055,
      "grad_norm": 0.13229277729988098,
      "learning_rate": 4.296651068538442e-05,
      "loss": 0.0746,
      "step": 21110
    },
    {
      "epoch": 0.4223493180818302,
      "grad_norm": 0.07207723706960678,
      "learning_rate": 4.29631777520031e-05,
      "loss": 0.0966,
      "step": 21120
    },
    {
      "epoch": 0.4225492940847098,
      "grad_norm": 0.11694718152284622,
      "learning_rate": 4.295984481862177e-05,
      "loss": 0.0617,
      "step": 21130
    },
    {
      "epoch": 0.4227492700875895,
      "grad_norm": 0.13750813901424408,
      "learning_rate": 4.295651188524044e-05,
      "loss": 0.0478,
      "step": 21140
    },
    {
      "epoch": 0.42294924609046913,
      "grad_norm": 0.1540576070547104,
      "learning_rate": 4.2953178951859116e-05,
      "loss": 0.0894,
      "step": 21150
    },
    {
      "epoch": 0.4231492220933488,
      "grad_norm": 0.11072862893342972,
      "learning_rate": 4.2949846018477786e-05,
      "loss": 0.0867,
      "step": 21160
    },
    {
      "epoch": 0.42334919809622845,
      "grad_norm": 0.23581279814243317,
      "learning_rate": 4.2946513085096455e-05,
      "loss": 0.1113,
      "step": 21170
    },
    {
      "epoch": 0.4235491740991081,
      "grad_norm": 0.06664764881134033,
      "learning_rate": 4.294318015171513e-05,
      "loss": 0.082,
      "step": 21180
    },
    {
      "epoch": 0.42374915010198777,
      "grad_norm": 0.1538783609867096,
      "learning_rate": 4.29398472183338e-05,
      "loss": 0.1057,
      "step": 21190
    },
    {
      "epoch": 0.4239491261048674,
      "grad_norm": 0.1223919540643692,
      "learning_rate": 4.293651428495247e-05,
      "loss": 0.0686,
      "step": 21200
    },
    {
      "epoch": 0.4241491021077471,
      "grad_norm": 0.12879043817520142,
      "learning_rate": 4.293318135157115e-05,
      "loss": 0.0687,
      "step": 21210
    },
    {
      "epoch": 0.4243490781106267,
      "grad_norm": 0.09030558913946152,
      "learning_rate": 4.2929848418189824e-05,
      "loss": 0.0729,
      "step": 21220
    },
    {
      "epoch": 0.42454905411350635,
      "grad_norm": 0.18893106281757355,
      "learning_rate": 4.292651548480849e-05,
      "loss": 0.0748,
      "step": 21230
    },
    {
      "epoch": 0.42474903011638604,
      "grad_norm": 0.14438951015472412,
      "learning_rate": 4.292318255142716e-05,
      "loss": 0.1029,
      "step": 21240
    },
    {
      "epoch": 0.42494900611926567,
      "grad_norm": 0.1877078115940094,
      "learning_rate": 4.291984961804584e-05,
      "loss": 0.1078,
      "step": 21250
    },
    {
      "epoch": 0.42514898212214536,
      "grad_norm": 0.09826701134443283,
      "learning_rate": 4.291651668466451e-05,
      "loss": 0.0659,
      "step": 21260
    },
    {
      "epoch": 0.425348958125025,
      "grad_norm": 0.1607363373041153,
      "learning_rate": 4.291318375128318e-05,
      "loss": 0.0455,
      "step": 21270
    },
    {
      "epoch": 0.4255489341279047,
      "grad_norm": 0.08070490509271622,
      "learning_rate": 4.2909850817901855e-05,
      "loss": 0.085,
      "step": 21280
    },
    {
      "epoch": 0.4257489101307843,
      "grad_norm": 0.09950917214155197,
      "learning_rate": 4.2906517884520525e-05,
      "loss": 0.1099,
      "step": 21290
    },
    {
      "epoch": 0.42594888613366394,
      "grad_norm": 0.10440364480018616,
      "learning_rate": 4.2903184951139194e-05,
      "loss": 0.0795,
      "step": 21300
    },
    {
      "epoch": 0.4261488621365436,
      "grad_norm": 0.05058390647172928,
      "learning_rate": 4.289985201775787e-05,
      "loss": 0.074,
      "step": 21310
    },
    {
      "epoch": 0.42634883813942326,
      "grad_norm": 0.10628951340913773,
      "learning_rate": 4.289651908437654e-05,
      "loss": 0.0832,
      "step": 21320
    },
    {
      "epoch": 0.42654881414230295,
      "grad_norm": 0.05729280039668083,
      "learning_rate": 4.289318615099522e-05,
      "loss": 0.0879,
      "step": 21330
    },
    {
      "epoch": 0.4267487901451826,
      "grad_norm": 0.1726388782262802,
      "learning_rate": 4.288985321761389e-05,
      "loss": 0.0731,
      "step": 21340
    },
    {
      "epoch": 0.4269487661480622,
      "grad_norm": 0.08852803707122803,
      "learning_rate": 4.288652028423256e-05,
      "loss": 0.0613,
      "step": 21350
    },
    {
      "epoch": 0.4271487421509419,
      "grad_norm": 0.06747845560312271,
      "learning_rate": 4.288318735085123e-05,
      "loss": 0.0511,
      "step": 21360
    },
    {
      "epoch": 0.4273487181538215,
      "grad_norm": 0.10711602866649628,
      "learning_rate": 4.287985441746991e-05,
      "loss": 0.0578,
      "step": 21370
    },
    {
      "epoch": 0.4275486941567012,
      "grad_norm": 0.07469506561756134,
      "learning_rate": 4.287652148408858e-05,
      "loss": 0.0896,
      "step": 21380
    },
    {
      "epoch": 0.42774867015958085,
      "grad_norm": 0.19322548806667328,
      "learning_rate": 4.287318855070725e-05,
      "loss": 0.0943,
      "step": 21390
    },
    {
      "epoch": 0.4279486461624605,
      "grad_norm": 0.0534198097884655,
      "learning_rate": 4.2869855617325924e-05,
      "loss": 0.0639,
      "step": 21400
    },
    {
      "epoch": 0.42814862216534016,
      "grad_norm": 0.1215834990143776,
      "learning_rate": 4.2866522683944594e-05,
      "loss": 0.0763,
      "step": 21410
    },
    {
      "epoch": 0.4283485981682198,
      "grad_norm": 0.25212928652763367,
      "learning_rate": 4.2863189750563264e-05,
      "loss": 0.1009,
      "step": 21420
    },
    {
      "epoch": 0.4285485741710995,
      "grad_norm": 0.12522514164447784,
      "learning_rate": 4.285985681718194e-05,
      "loss": 0.0561,
      "step": 21430
    },
    {
      "epoch": 0.4287485501739791,
      "grad_norm": 0.07454919815063477,
      "learning_rate": 4.2856523883800616e-05,
      "loss": 0.1066,
      "step": 21440
    },
    {
      "epoch": 0.4289485261768588,
      "grad_norm": 0.06336376070976257,
      "learning_rate": 4.2853190950419286e-05,
      "loss": 0.0396,
      "step": 21450
    },
    {
      "epoch": 0.42914850217973843,
      "grad_norm": 0.08495486527681351,
      "learning_rate": 4.2849858017037956e-05,
      "loss": 0.0819,
      "step": 21460
    },
    {
      "epoch": 0.42934847818261807,
      "grad_norm": 0.16000987589359283,
      "learning_rate": 4.284652508365663e-05,
      "loss": 0.0552,
      "step": 21470
    },
    {
      "epoch": 0.42954845418549775,
      "grad_norm": 0.14589469134807587,
      "learning_rate": 4.28431921502753e-05,
      "loss": 0.0723,
      "step": 21480
    },
    {
      "epoch": 0.4297484301883774,
      "grad_norm": 0.06416333466768265,
      "learning_rate": 4.283985921689397e-05,
      "loss": 0.091,
      "step": 21490
    },
    {
      "epoch": 0.42994840619125707,
      "grad_norm": 0.10006538778543472,
      "learning_rate": 4.283652628351265e-05,
      "loss": 0.1132,
      "step": 21500
    },
    {
      "epoch": 0.4301483821941367,
      "grad_norm": 0.11753296852111816,
      "learning_rate": 4.283319335013132e-05,
      "loss": 0.0887,
      "step": 21510
    },
    {
      "epoch": 0.43034835819701633,
      "grad_norm": 0.061429452151060104,
      "learning_rate": 4.282986041674999e-05,
      "loss": 0.0284,
      "step": 21520
    },
    {
      "epoch": 0.430548334199896,
      "grad_norm": 0.2783922851085663,
      "learning_rate": 4.282652748336867e-05,
      "loss": 0.1037,
      "step": 21530
    },
    {
      "epoch": 0.43074831020277565,
      "grad_norm": 0.17612603306770325,
      "learning_rate": 4.282319454998734e-05,
      "loss": 0.073,
      "step": 21540
    },
    {
      "epoch": 0.43094828620565534,
      "grad_norm": 0.16076980531215668,
      "learning_rate": 4.281986161660601e-05,
      "loss": 0.058,
      "step": 21550
    },
    {
      "epoch": 0.43114826220853497,
      "grad_norm": 0.2018125355243683,
      "learning_rate": 4.2816528683224686e-05,
      "loss": 0.061,
      "step": 21560
    },
    {
      "epoch": 0.4313482382114146,
      "grad_norm": 0.0535910464823246,
      "learning_rate": 4.2813195749843355e-05,
      "loss": 0.0538,
      "step": 21570
    },
    {
      "epoch": 0.4315482142142943,
      "grad_norm": 0.1944887936115265,
      "learning_rate": 4.2809862816462025e-05,
      "loss": 0.2525,
      "step": 21580
    },
    {
      "epoch": 0.4317481902171739,
      "grad_norm": 0.11926472932100296,
      "learning_rate": 4.28065298830807e-05,
      "loss": 0.0809,
      "step": 21590
    },
    {
      "epoch": 0.4319481662200536,
      "grad_norm": 0.1453918218612671,
      "learning_rate": 4.280319694969937e-05,
      "loss": 0.0799,
      "step": 21600
    },
    {
      "epoch": 0.43214814222293324,
      "grad_norm": 0.17810508608818054,
      "learning_rate": 4.279986401631804e-05,
      "loss": 0.0893,
      "step": 21610
    },
    {
      "epoch": 0.4323481182258129,
      "grad_norm": 0.06904373317956924,
      "learning_rate": 4.279653108293672e-05,
      "loss": 0.1074,
      "step": 21620
    },
    {
      "epoch": 0.43254809422869256,
      "grad_norm": 0.13709133863449097,
      "learning_rate": 4.279319814955539e-05,
      "loss": 0.0674,
      "step": 21630
    },
    {
      "epoch": 0.4327480702315722,
      "grad_norm": 0.1535109579563141,
      "learning_rate": 4.278986521617406e-05,
      "loss": 0.0714,
      "step": 21640
    },
    {
      "epoch": 0.4329480462344519,
      "grad_norm": 0.1138584166765213,
      "learning_rate": 4.278653228279273e-05,
      "loss": 0.0684,
      "step": 21650
    },
    {
      "epoch": 0.4331480222373315,
      "grad_norm": 0.13306573033332825,
      "learning_rate": 4.278319934941141e-05,
      "loss": 0.0702,
      "step": 21660
    },
    {
      "epoch": 0.4333479982402112,
      "grad_norm": 0.09632747620344162,
      "learning_rate": 4.277986641603008e-05,
      "loss": 0.0978,
      "step": 21670
    },
    {
      "epoch": 0.43354797424309083,
      "grad_norm": 0.11342506110668182,
      "learning_rate": 4.277653348264875e-05,
      "loss": 0.0602,
      "step": 21680
    },
    {
      "epoch": 0.43374795024597046,
      "grad_norm": 0.06304744631052017,
      "learning_rate": 4.2773200549267424e-05,
      "loss": 0.0619,
      "step": 21690
    },
    {
      "epoch": 0.43394792624885015,
      "grad_norm": 0.11101794987916946,
      "learning_rate": 4.2769867615886094e-05,
      "loss": 0.0634,
      "step": 21700
    },
    {
      "epoch": 0.4341479022517298,
      "grad_norm": 0.1121414378285408,
      "learning_rate": 4.2766534682504764e-05,
      "loss": 0.0624,
      "step": 21710
    },
    {
      "epoch": 0.43434787825460947,
      "grad_norm": 0.1915120929479599,
      "learning_rate": 4.276320174912344e-05,
      "loss": 0.074,
      "step": 21720
    },
    {
      "epoch": 0.4345478542574891,
      "grad_norm": 0.0368947833776474,
      "learning_rate": 4.2759868815742116e-05,
      "loss": 0.096,
      "step": 21730
    },
    {
      "epoch": 0.43474783026036873,
      "grad_norm": 0.1512521356344223,
      "learning_rate": 4.2756535882360786e-05,
      "loss": 0.0734,
      "step": 21740
    },
    {
      "epoch": 0.4349478062632484,
      "grad_norm": 0.08999638259410858,
      "learning_rate": 4.275320294897946e-05,
      "loss": 0.0913,
      "step": 21750
    },
    {
      "epoch": 0.43514778226612805,
      "grad_norm": 0.19026492536067963,
      "learning_rate": 4.274987001559813e-05,
      "loss": 0.0547,
      "step": 21760
    },
    {
      "epoch": 0.43534775826900773,
      "grad_norm": 0.12805688381195068,
      "learning_rate": 4.27465370822168e-05,
      "loss": 0.064,
      "step": 21770
    },
    {
      "epoch": 0.43554773427188737,
      "grad_norm": 0.13971473276615143,
      "learning_rate": 4.274320414883548e-05,
      "loss": 0.0595,
      "step": 21780
    },
    {
      "epoch": 0.43574771027476705,
      "grad_norm": 0.1346622109413147,
      "learning_rate": 4.273987121545415e-05,
      "loss": 0.085,
      "step": 21790
    },
    {
      "epoch": 0.4359476862776467,
      "grad_norm": 0.08740413933992386,
      "learning_rate": 4.273653828207282e-05,
      "loss": 0.0533,
      "step": 21800
    },
    {
      "epoch": 0.4361476622805263,
      "grad_norm": 0.16997236013412476,
      "learning_rate": 4.2733205348691494e-05,
      "loss": 0.1105,
      "step": 21810
    },
    {
      "epoch": 0.436347638283406,
      "grad_norm": 0.13919076323509216,
      "learning_rate": 4.272987241531016e-05,
      "loss": 0.1179,
      "step": 21820
    },
    {
      "epoch": 0.43654761428628563,
      "grad_norm": 0.059156812727451324,
      "learning_rate": 4.272653948192883e-05,
      "loss": 0.0592,
      "step": 21830
    },
    {
      "epoch": 0.4367475902891653,
      "grad_norm": 0.08021296560764313,
      "learning_rate": 4.272320654854751e-05,
      "loss": 0.039,
      "step": 21840
    },
    {
      "epoch": 0.43694756629204495,
      "grad_norm": 0.17530594766139984,
      "learning_rate": 4.2719873615166186e-05,
      "loss": 0.0849,
      "step": 21850
    },
    {
      "epoch": 0.4371475422949246,
      "grad_norm": 0.07532472908496857,
      "learning_rate": 4.2716540681784855e-05,
      "loss": 0.0691,
      "step": 21860
    },
    {
      "epoch": 0.43734751829780427,
      "grad_norm": 0.17767024040222168,
      "learning_rate": 4.2713207748403525e-05,
      "loss": 0.0713,
      "step": 21870
    },
    {
      "epoch": 0.4375474943006839,
      "grad_norm": 0.13350211083889008,
      "learning_rate": 4.27098748150222e-05,
      "loss": 0.0804,
      "step": 21880
    },
    {
      "epoch": 0.4377474703035636,
      "grad_norm": 0.11947336047887802,
      "learning_rate": 4.270654188164087e-05,
      "loss": 0.0716,
      "step": 21890
    },
    {
      "epoch": 0.4379474463064432,
      "grad_norm": 0.1468781679868698,
      "learning_rate": 4.270320894825954e-05,
      "loss": 0.0817,
      "step": 21900
    },
    {
      "epoch": 0.43814742230932285,
      "grad_norm": 0.20921359956264496,
      "learning_rate": 4.269987601487822e-05,
      "loss": 0.0821,
      "step": 21910
    },
    {
      "epoch": 0.43834739831220254,
      "grad_norm": 0.15483522415161133,
      "learning_rate": 4.2696543081496887e-05,
      "loss": 0.0745,
      "step": 21920
    },
    {
      "epoch": 0.4385473743150822,
      "grad_norm": 0.08430319279432297,
      "learning_rate": 4.2693210148115556e-05,
      "loss": 0.0809,
      "step": 21930
    },
    {
      "epoch": 0.43874735031796186,
      "grad_norm": 0.07796616852283478,
      "learning_rate": 4.268987721473424e-05,
      "loss": 0.0484,
      "step": 21940
    },
    {
      "epoch": 0.4389473263208415,
      "grad_norm": 0.08815623074769974,
      "learning_rate": 4.268654428135291e-05,
      "loss": 0.0702,
      "step": 21950
    },
    {
      "epoch": 0.4391473023237212,
      "grad_norm": 0.07423727959394455,
      "learning_rate": 4.268321134797158e-05,
      "loss": 0.0634,
      "step": 21960
    },
    {
      "epoch": 0.4393472783266008,
      "grad_norm": 0.20572473108768463,
      "learning_rate": 4.2679878414590255e-05,
      "loss": 0.0719,
      "step": 21970
    },
    {
      "epoch": 0.43954725432948044,
      "grad_norm": 0.12137418240308762,
      "learning_rate": 4.2676545481208925e-05,
      "loss": 0.1155,
      "step": 21980
    },
    {
      "epoch": 0.43974723033236013,
      "grad_norm": 0.17345766723155975,
      "learning_rate": 4.2673212547827594e-05,
      "loss": 0.0811,
      "step": 21990
    },
    {
      "epoch": 0.43994720633523976,
      "grad_norm": 0.08613697439432144,
      "learning_rate": 4.266987961444627e-05,
      "loss": 0.0988,
      "step": 22000
    },
    {
      "epoch": 0.44014718233811945,
      "grad_norm": 0.11091642826795578,
      "learning_rate": 4.266654668106494e-05,
      "loss": 0.0719,
      "step": 22010
    },
    {
      "epoch": 0.4403471583409991,
      "grad_norm": 0.1480891853570938,
      "learning_rate": 4.266321374768361e-05,
      "loss": 0.0732,
      "step": 22020
    },
    {
      "epoch": 0.4405471343438787,
      "grad_norm": 0.16289122402668,
      "learning_rate": 4.2659880814302286e-05,
      "loss": 0.0689,
      "step": 22030
    },
    {
      "epoch": 0.4407471103467584,
      "grad_norm": 0.08981522917747498,
      "learning_rate": 4.265654788092096e-05,
      "loss": 0.0701,
      "step": 22040
    },
    {
      "epoch": 0.44094708634963803,
      "grad_norm": 0.06089656800031662,
      "learning_rate": 4.265321494753963e-05,
      "loss": 0.0396,
      "step": 22050
    },
    {
      "epoch": 0.4411470623525177,
      "grad_norm": 0.0794517993927002,
      "learning_rate": 4.26498820141583e-05,
      "loss": 0.0815,
      "step": 22060
    },
    {
      "epoch": 0.44134703835539735,
      "grad_norm": 0.1008862555027008,
      "learning_rate": 4.264654908077698e-05,
      "loss": 0.074,
      "step": 22070
    },
    {
      "epoch": 0.441547014358277,
      "grad_norm": 0.07867198437452316,
      "learning_rate": 4.264321614739565e-05,
      "loss": 0.0424,
      "step": 22080
    },
    {
      "epoch": 0.44174699036115667,
      "grad_norm": 0.11109031736850739,
      "learning_rate": 4.264021650735246e-05,
      "loss": 0.0947,
      "step": 22090
    },
    {
      "epoch": 0.4419469663640363,
      "grad_norm": 0.1687295287847519,
      "learning_rate": 4.2636883573971126e-05,
      "loss": 0.0916,
      "step": 22100
    },
    {
      "epoch": 0.442146942366916,
      "grad_norm": 0.1255536675453186,
      "learning_rate": 4.2633550640589796e-05,
      "loss": 0.0674,
      "step": 22110
    },
    {
      "epoch": 0.4423469183697956,
      "grad_norm": 0.18823865056037903,
      "learning_rate": 4.263021770720847e-05,
      "loss": 0.0663,
      "step": 22120
    },
    {
      "epoch": 0.4425468943726753,
      "grad_norm": 0.10713297128677368,
      "learning_rate": 4.262688477382714e-05,
      "loss": 0.0536,
      "step": 22130
    },
    {
      "epoch": 0.44274687037555494,
      "grad_norm": 0.21185792982578278,
      "learning_rate": 4.262355184044581e-05,
      "loss": 0.1241,
      "step": 22140
    },
    {
      "epoch": 0.44294684637843457,
      "grad_norm": 0.09724979102611542,
      "learning_rate": 4.262021890706449e-05,
      "loss": 0.1079,
      "step": 22150
    },
    {
      "epoch": 0.44314682238131425,
      "grad_norm": 0.10131844878196716,
      "learning_rate": 4.2616885973683164e-05,
      "loss": 0.0906,
      "step": 22160
    },
    {
      "epoch": 0.4433467983841939,
      "grad_norm": 0.08869527280330658,
      "learning_rate": 4.2613553040301834e-05,
      "loss": 0.0963,
      "step": 22170
    },
    {
      "epoch": 0.4435467743870736,
      "grad_norm": 0.07923472672700882,
      "learning_rate": 4.2610220106920504e-05,
      "loss": 0.0834,
      "step": 22180
    },
    {
      "epoch": 0.4437467503899532,
      "grad_norm": 0.15210062265396118,
      "learning_rate": 4.260688717353918e-05,
      "loss": 0.0803,
      "step": 22190
    },
    {
      "epoch": 0.44394672639283284,
      "grad_norm": 0.17135083675384521,
      "learning_rate": 4.260355424015785e-05,
      "loss": 0.0709,
      "step": 22200
    },
    {
      "epoch": 0.4441467023957125,
      "grad_norm": 0.18444916605949402,
      "learning_rate": 4.260022130677652e-05,
      "loss": 0.0543,
      "step": 22210
    },
    {
      "epoch": 0.44434667839859215,
      "grad_norm": 0.148348867893219,
      "learning_rate": 4.2596888373395196e-05,
      "loss": 0.0726,
      "step": 22220
    },
    {
      "epoch": 0.44454665440147184,
      "grad_norm": 0.14080630242824554,
      "learning_rate": 4.2593555440013865e-05,
      "loss": 0.0735,
      "step": 22230
    },
    {
      "epoch": 0.4447466304043515,
      "grad_norm": 0.10843472927808762,
      "learning_rate": 4.2590222506632535e-05,
      "loss": 0.0464,
      "step": 22240
    },
    {
      "epoch": 0.44494660640723116,
      "grad_norm": 0.10354437679052353,
      "learning_rate": 4.258688957325121e-05,
      "loss": 0.0937,
      "step": 22250
    },
    {
      "epoch": 0.4451465824101108,
      "grad_norm": 0.09910813719034195,
      "learning_rate": 4.258355663986989e-05,
      "loss": 0.079,
      "step": 22260
    },
    {
      "epoch": 0.4453465584129904,
      "grad_norm": 0.11495742946863174,
      "learning_rate": 4.258022370648856e-05,
      "loss": 0.0724,
      "step": 22270
    },
    {
      "epoch": 0.4455465344158701,
      "grad_norm": 0.11605577915906906,
      "learning_rate": 4.2576890773107234e-05,
      "loss": 0.0789,
      "step": 22280
    },
    {
      "epoch": 0.44574651041874974,
      "grad_norm": 0.0828605368733406,
      "learning_rate": 4.25735578397259e-05,
      "loss": 0.0796,
      "step": 22290
    },
    {
      "epoch": 0.44594648642162943,
      "grad_norm": 0.149351105093956,
      "learning_rate": 4.257022490634457e-05,
      "loss": 0.0848,
      "step": 22300
    },
    {
      "epoch": 0.44614646242450906,
      "grad_norm": 0.09565592557191849,
      "learning_rate": 4.256689197296325e-05,
      "loss": 0.0586,
      "step": 22310
    },
    {
      "epoch": 0.4463464384273887,
      "grad_norm": 0.13026770949363708,
      "learning_rate": 4.256355903958192e-05,
      "loss": 0.0768,
      "step": 22320
    },
    {
      "epoch": 0.4465464144302684,
      "grad_norm": 0.11518370360136032,
      "learning_rate": 4.256022610620059e-05,
      "loss": 0.1246,
      "step": 22330
    },
    {
      "epoch": 0.446746390433148,
      "grad_norm": 0.05803794786334038,
      "learning_rate": 4.2556893172819265e-05,
      "loss": 0.0816,
      "step": 22340
    },
    {
      "epoch": 0.4469463664360277,
      "grad_norm": 0.2071969211101532,
      "learning_rate": 4.2553560239437934e-05,
      "loss": 0.1174,
      "step": 22350
    },
    {
      "epoch": 0.44714634243890733,
      "grad_norm": 0.085490383207798,
      "learning_rate": 4.2550227306056604e-05,
      "loss": 0.0878,
      "step": 22360
    },
    {
      "epoch": 0.44734631844178696,
      "grad_norm": 0.07448532432317734,
      "learning_rate": 4.254689437267528e-05,
      "loss": 0.0597,
      "step": 22370
    },
    {
      "epoch": 0.44754629444466665,
      "grad_norm": 0.07891754060983658,
      "learning_rate": 4.254356143929396e-05,
      "loss": 0.0774,
      "step": 22380
    },
    {
      "epoch": 0.4477462704475463,
      "grad_norm": 0.12658469378948212,
      "learning_rate": 4.2540228505912626e-05,
      "loss": 0.0587,
      "step": 22390
    },
    {
      "epoch": 0.44794624645042597,
      "grad_norm": 0.1980435699224472,
      "learning_rate": 4.2536895572531296e-05,
      "loss": 0.0776,
      "step": 22400
    },
    {
      "epoch": 0.4481462224533056,
      "grad_norm": 0.11564081907272339,
      "learning_rate": 4.253356263914997e-05,
      "loss": 0.0435,
      "step": 22410
    },
    {
      "epoch": 0.4483461984561853,
      "grad_norm": 0.04800204560160637,
      "learning_rate": 4.253022970576864e-05,
      "loss": 0.227,
      "step": 22420
    },
    {
      "epoch": 0.4485461744590649,
      "grad_norm": 0.21385949850082397,
      "learning_rate": 4.252689677238731e-05,
      "loss": 0.1073,
      "step": 22430
    },
    {
      "epoch": 0.44874615046194455,
      "grad_norm": 0.08266784995794296,
      "learning_rate": 4.252356383900599e-05,
      "loss": 0.0597,
      "step": 22440
    },
    {
      "epoch": 0.44894612646482424,
      "grad_norm": 0.19295887649059296,
      "learning_rate": 4.252023090562466e-05,
      "loss": 0.0865,
      "step": 22450
    },
    {
      "epoch": 0.44914610246770387,
      "grad_norm": 0.17362014949321747,
      "learning_rate": 4.251689797224333e-05,
      "loss": 0.0816,
      "step": 22460
    },
    {
      "epoch": 0.44934607847058355,
      "grad_norm": 0.13325117528438568,
      "learning_rate": 4.251356503886201e-05,
      "loss": 0.0728,
      "step": 22470
    },
    {
      "epoch": 0.4495460544734632,
      "grad_norm": 0.10425335168838501,
      "learning_rate": 4.251023210548068e-05,
      "loss": 0.1031,
      "step": 22480
    },
    {
      "epoch": 0.4497460304763428,
      "grad_norm": 0.15960562229156494,
      "learning_rate": 4.250689917209935e-05,
      "loss": 0.1029,
      "step": 22490
    },
    {
      "epoch": 0.4499460064792225,
      "grad_norm": 0.07014884799718857,
      "learning_rate": 4.2503566238718026e-05,
      "loss": 0.0788,
      "step": 22500
    },
    {
      "epoch": 0.45014598248210214,
      "grad_norm": 0.14984752237796783,
      "learning_rate": 4.2500233305336696e-05,
      "loss": 0.1244,
      "step": 22510
    },
    {
      "epoch": 0.4503459584849818,
      "grad_norm": 0.1487598866224289,
      "learning_rate": 4.2496900371955365e-05,
      "loss": 0.058,
      "step": 22520
    },
    {
      "epoch": 0.45054593448786145,
      "grad_norm": 0.18346373736858368,
      "learning_rate": 4.249356743857404e-05,
      "loss": 0.1068,
      "step": 22530
    },
    {
      "epoch": 0.4507459104907411,
      "grad_norm": 0.1562090963125229,
      "learning_rate": 4.249023450519271e-05,
      "loss": 0.0909,
      "step": 22540
    },
    {
      "epoch": 0.4509458864936208,
      "grad_norm": 0.16725385189056396,
      "learning_rate": 4.248690157181138e-05,
      "loss": 0.0702,
      "step": 22550
    },
    {
      "epoch": 0.4511458624965004,
      "grad_norm": 0.0790264829993248,
      "learning_rate": 4.248356863843006e-05,
      "loss": 0.0655,
      "step": 22560
    },
    {
      "epoch": 0.4513458384993801,
      "grad_norm": 0.14342845976352692,
      "learning_rate": 4.2480235705048734e-05,
      "loss": 0.0627,
      "step": 22570
    },
    {
      "epoch": 0.4515458145022597,
      "grad_norm": 0.11885713040828705,
      "learning_rate": 4.24769027716674e-05,
      "loss": 0.0836,
      "step": 22580
    },
    {
      "epoch": 0.4517457905051394,
      "grad_norm": 0.1380840390920639,
      "learning_rate": 4.247356983828607e-05,
      "loss": 0.075,
      "step": 22590
    },
    {
      "epoch": 0.45194576650801904,
      "grad_norm": 0.14546874165534973,
      "learning_rate": 4.247023690490475e-05,
      "loss": 0.1094,
      "step": 22600
    },
    {
      "epoch": 0.4521457425108987,
      "grad_norm": 0.11251001060009003,
      "learning_rate": 4.246690397152342e-05,
      "loss": 0.0668,
      "step": 22610
    },
    {
      "epoch": 0.45234571851377836,
      "grad_norm": 0.07140446454286575,
      "learning_rate": 4.246357103814209e-05,
      "loss": 0.0804,
      "step": 22620
    },
    {
      "epoch": 0.452545694516658,
      "grad_norm": 0.04418933019042015,
      "learning_rate": 4.2460238104760765e-05,
      "loss": 0.0627,
      "step": 22630
    },
    {
      "epoch": 0.4527456705195377,
      "grad_norm": 0.08015435934066772,
      "learning_rate": 4.2456905171379435e-05,
      "loss": 0.0509,
      "step": 22640
    },
    {
      "epoch": 0.4529456465224173,
      "grad_norm": 0.09842109680175781,
      "learning_rate": 4.2453572237998104e-05,
      "loss": 0.0814,
      "step": 22650
    },
    {
      "epoch": 0.45314562252529694,
      "grad_norm": 0.1646272987127304,
      "learning_rate": 4.245023930461678e-05,
      "loss": 0.0834,
      "step": 22660
    },
    {
      "epoch": 0.45334559852817663,
      "grad_norm": 0.09612568467855453,
      "learning_rate": 4.244690637123546e-05,
      "loss": 0.0698,
      "step": 22670
    },
    {
      "epoch": 0.45354557453105626,
      "grad_norm": 0.06816558539867401,
      "learning_rate": 4.2443573437854127e-05,
      "loss": 0.0839,
      "step": 22680
    },
    {
      "epoch": 0.45374555053393595,
      "grad_norm": 0.1609392613172531,
      "learning_rate": 4.24402405044728e-05,
      "loss": 0.1395,
      "step": 22690
    },
    {
      "epoch": 0.4539455265368156,
      "grad_norm": 0.06593845039606094,
      "learning_rate": 4.243690757109147e-05,
      "loss": 0.0536,
      "step": 22700
    },
    {
      "epoch": 0.4541455025396952,
      "grad_norm": 0.15552546083927155,
      "learning_rate": 4.243357463771014e-05,
      "loss": 0.0843,
      "step": 22710
    },
    {
      "epoch": 0.4543454785425749,
      "grad_norm": 0.10313219577074051,
      "learning_rate": 4.243024170432882e-05,
      "loss": 0.0712,
      "step": 22720
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.23686011135578156,
      "learning_rate": 4.242690877094749e-05,
      "loss": 0.0889,
      "step": 22730
    },
    {
      "epoch": 0.4547454305483342,
      "grad_norm": 0.1620236486196518,
      "learning_rate": 4.242357583756616e-05,
      "loss": 0.1054,
      "step": 22740
    },
    {
      "epoch": 0.45494540655121385,
      "grad_norm": 0.11405918002128601,
      "learning_rate": 4.2420242904184834e-05,
      "loss": 0.0956,
      "step": 22750
    },
    {
      "epoch": 0.45514538255409354,
      "grad_norm": 0.08211646229028702,
      "learning_rate": 4.2416909970803504e-05,
      "loss": 0.0954,
      "step": 22760
    },
    {
      "epoch": 0.45534535855697317,
      "grad_norm": 0.110955148935318,
      "learning_rate": 4.241357703742218e-05,
      "loss": 0.0861,
      "step": 22770
    },
    {
      "epoch": 0.4555453345598528,
      "grad_norm": 0.13674196600914001,
      "learning_rate": 4.241024410404085e-05,
      "loss": 0.0769,
      "step": 22780
    },
    {
      "epoch": 0.4557453105627325,
      "grad_norm": 0.08453356474637985,
      "learning_rate": 4.2406911170659526e-05,
      "loss": 0.1002,
      "step": 22790
    },
    {
      "epoch": 0.4559452865656121,
      "grad_norm": 0.1832975447177887,
      "learning_rate": 4.2403578237278196e-05,
      "loss": 0.0728,
      "step": 22800
    },
    {
      "epoch": 0.4561452625684918,
      "grad_norm": 0.09592408686876297,
      "learning_rate": 4.2400245303896865e-05,
      "loss": 0.0801,
      "step": 22810
    },
    {
      "epoch": 0.45634523857137144,
      "grad_norm": 0.08790503442287445,
      "learning_rate": 4.239691237051554e-05,
      "loss": 0.1218,
      "step": 22820
    },
    {
      "epoch": 0.45654521457425107,
      "grad_norm": 0.08717198669910431,
      "learning_rate": 4.239357943713421e-05,
      "loss": 0.0686,
      "step": 22830
    },
    {
      "epoch": 0.45674519057713076,
      "grad_norm": 0.11206135898828506,
      "learning_rate": 4.239024650375288e-05,
      "loss": 0.0858,
      "step": 22840
    },
    {
      "epoch": 0.4569451665800104,
      "grad_norm": 0.21131093800067902,
      "learning_rate": 4.238691357037156e-05,
      "loss": 0.0958,
      "step": 22850
    },
    {
      "epoch": 0.4571451425828901,
      "grad_norm": 0.07117316871881485,
      "learning_rate": 4.238358063699023e-05,
      "loss": 0.0682,
      "step": 22860
    },
    {
      "epoch": 0.4573451185857697,
      "grad_norm": 0.09491343796253204,
      "learning_rate": 4.23802477036089e-05,
      "loss": 0.0617,
      "step": 22870
    },
    {
      "epoch": 0.45754509458864934,
      "grad_norm": 0.137027308344841,
      "learning_rate": 4.237691477022758e-05,
      "loss": 0.0908,
      "step": 22880
    },
    {
      "epoch": 0.457745070591529,
      "grad_norm": 0.16549304127693176,
      "learning_rate": 4.237358183684625e-05,
      "loss": 0.065,
      "step": 22890
    },
    {
      "epoch": 0.45794504659440866,
      "grad_norm": 0.1721935272216797,
      "learning_rate": 4.237024890346492e-05,
      "loss": 0.0859,
      "step": 22900
    },
    {
      "epoch": 0.45814502259728834,
      "grad_norm": 0.18286758661270142,
      "learning_rate": 4.2366915970083596e-05,
      "loss": 0.0711,
      "step": 22910
    },
    {
      "epoch": 0.458344998600168,
      "grad_norm": 0.1805359274148941,
      "learning_rate": 4.2363583036702265e-05,
      "loss": 0.1113,
      "step": 22920
    },
    {
      "epoch": 0.45854497460304766,
      "grad_norm": 0.18373869359493256,
      "learning_rate": 4.2360250103320935e-05,
      "loss": 0.0884,
      "step": 22930
    },
    {
      "epoch": 0.4587449506059273,
      "grad_norm": 0.15337742865085602,
      "learning_rate": 4.235691716993961e-05,
      "loss": 0.0603,
      "step": 22940
    },
    {
      "epoch": 0.4589449266088069,
      "grad_norm": 0.10365710407495499,
      "learning_rate": 4.235358423655828e-05,
      "loss": 0.0824,
      "step": 22950
    },
    {
      "epoch": 0.4591449026116866,
      "grad_norm": 0.07066857814788818,
      "learning_rate": 4.235025130317695e-05,
      "loss": 0.1027,
      "step": 22960
    },
    {
      "epoch": 0.45934487861456624,
      "grad_norm": 0.08277454227209091,
      "learning_rate": 4.234691836979563e-05,
      "loss": 0.0613,
      "step": 22970
    },
    {
      "epoch": 0.45954485461744593,
      "grad_norm": 0.11115678399801254,
      "learning_rate": 4.23435854364143e-05,
      "loss": 0.0741,
      "step": 22980
    },
    {
      "epoch": 0.45974483062032556,
      "grad_norm": 0.1627645045518875,
      "learning_rate": 4.23405857963711e-05,
      "loss": 0.0803,
      "step": 22990
    },
    {
      "epoch": 0.4599448066232052,
      "grad_norm": 0.09729819744825363,
      "learning_rate": 4.233725286298978e-05,
      "loss": 0.0734,
      "step": 23000
    },
    {
      "epoch": 0.4601447826260849,
      "grad_norm": 0.12370067834854126,
      "learning_rate": 4.233391992960845e-05,
      "loss": 0.0732,
      "step": 23010
    },
    {
      "epoch": 0.4603447586289645,
      "grad_norm": 0.20362557470798492,
      "learning_rate": 4.233058699622712e-05,
      "loss": 0.1064,
      "step": 23020
    },
    {
      "epoch": 0.4605447346318442,
      "grad_norm": 0.12241530418395996,
      "learning_rate": 4.23272540628458e-05,
      "loss": 0.0819,
      "step": 23030
    },
    {
      "epoch": 0.46074471063472383,
      "grad_norm": 0.21041655540466309,
      "learning_rate": 4.232392112946447e-05,
      "loss": 0.1095,
      "step": 23040
    },
    {
      "epoch": 0.46094468663760346,
      "grad_norm": 0.17942120134830475,
      "learning_rate": 4.2320588196083136e-05,
      "loss": 0.1134,
      "step": 23050
    },
    {
      "epoch": 0.46114466264048315,
      "grad_norm": 0.1401391178369522,
      "learning_rate": 4.231725526270181e-05,
      "loss": 0.09,
      "step": 23060
    },
    {
      "epoch": 0.4613446386433628,
      "grad_norm": 0.10089718550443649,
      "learning_rate": 4.231392232932048e-05,
      "loss": 0.0481,
      "step": 23070
    },
    {
      "epoch": 0.46154461464624247,
      "grad_norm": 0.16195538640022278,
      "learning_rate": 4.231058939593915e-05,
      "loss": 0.0568,
      "step": 23080
    },
    {
      "epoch": 0.4617445906491221,
      "grad_norm": 0.10316620767116547,
      "learning_rate": 4.230725646255783e-05,
      "loss": 0.0489,
      "step": 23090
    },
    {
      "epoch": 0.4619445666520018,
      "grad_norm": 0.13671919703483582,
      "learning_rate": 4.2303923529176505e-05,
      "loss": 0.0933,
      "step": 23100
    },
    {
      "epoch": 0.4621445426548814,
      "grad_norm": 0.055225443094968796,
      "learning_rate": 4.2300590595795174e-05,
      "loss": 0.1185,
      "step": 23110
    },
    {
      "epoch": 0.46234451865776105,
      "grad_norm": 0.19215339422225952,
      "learning_rate": 4.2297257662413844e-05,
      "loss": 0.0577,
      "step": 23120
    },
    {
      "epoch": 0.46254449466064074,
      "grad_norm": 0.13091421127319336,
      "learning_rate": 4.229392472903252e-05,
      "loss": 0.0577,
      "step": 23130
    },
    {
      "epoch": 0.46274447066352037,
      "grad_norm": 0.11086364835500717,
      "learning_rate": 4.229059179565119e-05,
      "loss": 0.0364,
      "step": 23140
    },
    {
      "epoch": 0.46294444666640006,
      "grad_norm": 0.12676489353179932,
      "learning_rate": 4.228725886226986e-05,
      "loss": 0.0715,
      "step": 23150
    },
    {
      "epoch": 0.4631444226692797,
      "grad_norm": 0.23307488858699799,
      "learning_rate": 4.2283925928888536e-05,
      "loss": 0.0975,
      "step": 23160
    },
    {
      "epoch": 0.4633443986721593,
      "grad_norm": 0.05982969328761101,
      "learning_rate": 4.2280592995507206e-05,
      "loss": 0.0585,
      "step": 23170
    },
    {
      "epoch": 0.463544374675039,
      "grad_norm": 0.2089715451002121,
      "learning_rate": 4.2277260062125875e-05,
      "loss": 0.081,
      "step": 23180
    },
    {
      "epoch": 0.46374435067791864,
      "grad_norm": 0.1791439801454544,
      "learning_rate": 4.227392712874455e-05,
      "loss": 0.0846,
      "step": 23190
    },
    {
      "epoch": 0.4639443266807983,
      "grad_norm": 0.09796780347824097,
      "learning_rate": 4.227059419536323e-05,
      "loss": 0.0966,
      "step": 23200
    },
    {
      "epoch": 0.46414430268367796,
      "grad_norm": 0.0732710063457489,
      "learning_rate": 4.22672612619819e-05,
      "loss": 0.0674,
      "step": 23210
    },
    {
      "epoch": 0.4643442786865576,
      "grad_norm": 0.12064573168754578,
      "learning_rate": 4.2263928328600574e-05,
      "loss": 0.0667,
      "step": 23220
    },
    {
      "epoch": 0.4645442546894373,
      "grad_norm": 0.0854940414428711,
      "learning_rate": 4.2260595395219244e-05,
      "loss": 0.0412,
      "step": 23230
    },
    {
      "epoch": 0.4647442306923169,
      "grad_norm": 0.15081964433193207,
      "learning_rate": 4.225726246183791e-05,
      "loss": 0.0991,
      "step": 23240
    },
    {
      "epoch": 0.4649442066951966,
      "grad_norm": 0.0682770237326622,
      "learning_rate": 4.225392952845659e-05,
      "loss": 0.0605,
      "step": 23250
    },
    {
      "epoch": 0.4651441826980762,
      "grad_norm": 0.13625390827655792,
      "learning_rate": 4.225059659507526e-05,
      "loss": 0.0657,
      "step": 23260
    },
    {
      "epoch": 0.4653441587009559,
      "grad_norm": 0.050598546862602234,
      "learning_rate": 4.224726366169393e-05,
      "loss": 0.0887,
      "step": 23270
    },
    {
      "epoch": 0.46554413470383554,
      "grad_norm": 0.06544103473424911,
      "learning_rate": 4.2243930728312605e-05,
      "loss": 0.0559,
      "step": 23280
    },
    {
      "epoch": 0.4657441107067152,
      "grad_norm": 0.16005243360996246,
      "learning_rate": 4.2240597794931275e-05,
      "loss": 0.0884,
      "step": 23290
    },
    {
      "epoch": 0.46594408670959486,
      "grad_norm": 0.16642078757286072,
      "learning_rate": 4.2237264861549945e-05,
      "loss": 0.0679,
      "step": 23300
    },
    {
      "epoch": 0.4661440627124745,
      "grad_norm": 0.19836431741714478,
      "learning_rate": 4.223393192816862e-05,
      "loss": 0.0901,
      "step": 23310
    },
    {
      "epoch": 0.4663440387153542,
      "grad_norm": 0.06377667188644409,
      "learning_rate": 4.22305989947873e-05,
      "loss": 0.1064,
      "step": 23320
    },
    {
      "epoch": 0.4665440147182338,
      "grad_norm": 0.0691252276301384,
      "learning_rate": 4.222726606140597e-05,
      "loss": 0.0541,
      "step": 23330
    },
    {
      "epoch": 0.46674399072111344,
      "grad_norm": 0.11283612251281738,
      "learning_rate": 4.2223933128024637e-05,
      "loss": 0.0666,
      "step": 23340
    },
    {
      "epoch": 0.46694396672399313,
      "grad_norm": 0.08970649540424347,
      "learning_rate": 4.222060019464331e-05,
      "loss": 0.1124,
      "step": 23350
    },
    {
      "epoch": 0.46714394272687276,
      "grad_norm": 0.08711222559213638,
      "learning_rate": 4.221726726126198e-05,
      "loss": 0.0476,
      "step": 23360
    },
    {
      "epoch": 0.46734391872975245,
      "grad_norm": 0.1466260552406311,
      "learning_rate": 4.221393432788065e-05,
      "loss": 0.1018,
      "step": 23370
    },
    {
      "epoch": 0.4675438947326321,
      "grad_norm": 0.1419747769832611,
      "learning_rate": 4.221060139449933e-05,
      "loss": 0.1144,
      "step": 23380
    },
    {
      "epoch": 0.4677438707355117,
      "grad_norm": 0.10862068086862564,
      "learning_rate": 4.2207268461118e-05,
      "loss": 0.0594,
      "step": 23390
    },
    {
      "epoch": 0.4679438467383914,
      "grad_norm": 0.10170502960681915,
      "learning_rate": 4.220393552773667e-05,
      "loss": 0.0543,
      "step": 23400
    },
    {
      "epoch": 0.46814382274127103,
      "grad_norm": 0.07651271671056747,
      "learning_rate": 4.220060259435535e-05,
      "loss": 0.0368,
      "step": 23410
    },
    {
      "epoch": 0.4683437987441507,
      "grad_norm": 0.09425043314695358,
      "learning_rate": 4.219726966097402e-05,
      "loss": 0.1018,
      "step": 23420
    },
    {
      "epoch": 0.46854377474703035,
      "grad_norm": 0.10464778542518616,
      "learning_rate": 4.219393672759269e-05,
      "loss": 0.1164,
      "step": 23430
    },
    {
      "epoch": 0.46874375074991004,
      "grad_norm": 0.07530265301465988,
      "learning_rate": 4.219060379421137e-05,
      "loss": 0.078,
      "step": 23440
    },
    {
      "epoch": 0.46894372675278967,
      "grad_norm": 0.07597643882036209,
      "learning_rate": 4.2187270860830036e-05,
      "loss": 0.2033,
      "step": 23450
    },
    {
      "epoch": 0.4691437027556693,
      "grad_norm": 0.08296167105436325,
      "learning_rate": 4.2183937927448706e-05,
      "loss": 0.0847,
      "step": 23460
    },
    {
      "epoch": 0.469343678758549,
      "grad_norm": 0.13807803392410278,
      "learning_rate": 4.218060499406738e-05,
      "loss": 0.1043,
      "step": 23470
    },
    {
      "epoch": 0.4695436547614286,
      "grad_norm": 0.056865718215703964,
      "learning_rate": 4.217727206068605e-05,
      "loss": 0.0587,
      "step": 23480
    },
    {
      "epoch": 0.4697436307643083,
      "grad_norm": 0.16687078773975372,
      "learning_rate": 4.217393912730472e-05,
      "loss": 0.0908,
      "step": 23490
    },
    {
      "epoch": 0.46994360676718794,
      "grad_norm": 0.10856612771749496,
      "learning_rate": 4.21706061939234e-05,
      "loss": 0.0786,
      "step": 23500
    },
    {
      "epoch": 0.47014358277006757,
      "grad_norm": 0.11183284968137741,
      "learning_rate": 4.2167273260542074e-05,
      "loss": 0.0655,
      "step": 23510
    },
    {
      "epoch": 0.47034355877294726,
      "grad_norm": 0.11282974481582642,
      "learning_rate": 4.2163940327160744e-05,
      "loss": 0.0893,
      "step": 23520
    },
    {
      "epoch": 0.4705435347758269,
      "grad_norm": 0.0754796713590622,
      "learning_rate": 4.2160607393779413e-05,
      "loss": 0.0732,
      "step": 23530
    },
    {
      "epoch": 0.4707435107787066,
      "grad_norm": 0.13660098612308502,
      "learning_rate": 4.215727446039809e-05,
      "loss": 0.0604,
      "step": 23540
    },
    {
      "epoch": 0.4709434867815862,
      "grad_norm": 0.051440976560115814,
      "learning_rate": 4.215394152701676e-05,
      "loss": 0.0476,
      "step": 23550
    },
    {
      "epoch": 0.47114346278446584,
      "grad_norm": 0.0760817900300026,
      "learning_rate": 4.215060859363543e-05,
      "loss": 0.0566,
      "step": 23560
    },
    {
      "epoch": 0.4713434387873455,
      "grad_norm": 0.1698375940322876,
      "learning_rate": 4.2147275660254106e-05,
      "loss": 0.0867,
      "step": 23570
    },
    {
      "epoch": 0.47154341479022516,
      "grad_norm": 0.11417357623577118,
      "learning_rate": 4.2143942726872775e-05,
      "loss": 0.1141,
      "step": 23580
    },
    {
      "epoch": 0.47174339079310484,
      "grad_norm": 0.09330368787050247,
      "learning_rate": 4.2140609793491445e-05,
      "loss": 0.0824,
      "step": 23590
    },
    {
      "epoch": 0.4719433667959845,
      "grad_norm": 0.10427381098270416,
      "learning_rate": 4.213727686011012e-05,
      "loss": 0.0597,
      "step": 23600
    },
    {
      "epoch": 0.47214334279886416,
      "grad_norm": 0.20982104539871216,
      "learning_rate": 4.21339439267288e-05,
      "loss": 0.0885,
      "step": 23610
    },
    {
      "epoch": 0.4723433188017438,
      "grad_norm": 0.2032596915960312,
      "learning_rate": 4.213061099334747e-05,
      "loss": 0.0776,
      "step": 23620
    },
    {
      "epoch": 0.4725432948046234,
      "grad_norm": 0.0919906497001648,
      "learning_rate": 4.2127278059966144e-05,
      "loss": 0.0627,
      "step": 23630
    },
    {
      "epoch": 0.4727432708075031,
      "grad_norm": 0.11997602134943008,
      "learning_rate": 4.212394512658481e-05,
      "loss": 0.0939,
      "step": 23640
    },
    {
      "epoch": 0.47294324681038274,
      "grad_norm": 0.21733130514621735,
      "learning_rate": 4.212061219320348e-05,
      "loss": 0.1065,
      "step": 23650
    },
    {
      "epoch": 0.47314322281326243,
      "grad_norm": 0.19195671379566193,
      "learning_rate": 4.211727925982216e-05,
      "loss": 0.1368,
      "step": 23660
    },
    {
      "epoch": 0.47334319881614206,
      "grad_norm": 0.1615113466978073,
      "learning_rate": 4.211394632644083e-05,
      "loss": 0.0859,
      "step": 23670
    },
    {
      "epoch": 0.4735431748190217,
      "grad_norm": 0.05223901569843292,
      "learning_rate": 4.21106133930595e-05,
      "loss": 0.092,
      "step": 23680
    },
    {
      "epoch": 0.4737431508219014,
      "grad_norm": 0.20120054483413696,
      "learning_rate": 4.2107280459678175e-05,
      "loss": 0.0907,
      "step": 23690
    },
    {
      "epoch": 0.473943126824781,
      "grad_norm": 0.1772221177816391,
      "learning_rate": 4.2103947526296844e-05,
      "loss": 0.0987,
      "step": 23700
    },
    {
      "epoch": 0.4741431028276607,
      "grad_norm": 0.12236891686916351,
      "learning_rate": 4.210061459291552e-05,
      "loss": 0.0623,
      "step": 23710
    },
    {
      "epoch": 0.47434307883054033,
      "grad_norm": 0.17850634455680847,
      "learning_rate": 4.209728165953419e-05,
      "loss": 0.0816,
      "step": 23720
    },
    {
      "epoch": 0.47454305483341996,
      "grad_norm": 0.17098690569400787,
      "learning_rate": 4.209394872615287e-05,
      "loss": 0.1258,
      "step": 23730
    },
    {
      "epoch": 0.47474303083629965,
      "grad_norm": 0.10934619605541229,
      "learning_rate": 4.2090615792771536e-05,
      "loss": 0.0658,
      "step": 23740
    },
    {
      "epoch": 0.4749430068391793,
      "grad_norm": 0.16806885600090027,
      "learning_rate": 4.2087282859390206e-05,
      "loss": 0.0911,
      "step": 23750
    },
    {
      "epoch": 0.47514298284205897,
      "grad_norm": 0.19090156257152557,
      "learning_rate": 4.208394992600888e-05,
      "loss": 0.0679,
      "step": 23760
    },
    {
      "epoch": 0.4753429588449386,
      "grad_norm": 0.2501142621040344,
      "learning_rate": 4.208061699262755e-05,
      "loss": 0.0832,
      "step": 23770
    },
    {
      "epoch": 0.4755429348478183,
      "grad_norm": 0.08259104192256927,
      "learning_rate": 4.207728405924622e-05,
      "loss": 0.1499,
      "step": 23780
    },
    {
      "epoch": 0.4757429108506979,
      "grad_norm": 0.13639035820960999,
      "learning_rate": 4.20739511258649e-05,
      "loss": 0.0634,
      "step": 23790
    },
    {
      "epoch": 0.47594288685357755,
      "grad_norm": 0.08098772168159485,
      "learning_rate": 4.207061819248357e-05,
      "loss": 0.0688,
      "step": 23800
    },
    {
      "epoch": 0.47614286285645724,
      "grad_norm": 0.17981454730033875,
      "learning_rate": 4.206728525910224e-05,
      "loss": 0.0796,
      "step": 23810
    },
    {
      "epoch": 0.47634283885933687,
      "grad_norm": 0.06791429221630096,
      "learning_rate": 4.206395232572092e-05,
      "loss": 0.0563,
      "step": 23820
    },
    {
      "epoch": 0.47654281486221656,
      "grad_norm": 0.05775264650583267,
      "learning_rate": 4.206061939233959e-05,
      "loss": 0.0658,
      "step": 23830
    },
    {
      "epoch": 0.4767427908650962,
      "grad_norm": 0.13020050525665283,
      "learning_rate": 4.205728645895826e-05,
      "loss": 0.076,
      "step": 23840
    },
    {
      "epoch": 0.4769427668679758,
      "grad_norm": 0.12524257600307465,
      "learning_rate": 4.2053953525576936e-05,
      "loss": 0.0781,
      "step": 23850
    },
    {
      "epoch": 0.4771427428708555,
      "grad_norm": 0.0904037281870842,
      "learning_rate": 4.2050620592195606e-05,
      "loss": 0.1116,
      "step": 23860
    },
    {
      "epoch": 0.47734271887373514,
      "grad_norm": 0.09666113555431366,
      "learning_rate": 4.2047287658814275e-05,
      "loss": 0.103,
      "step": 23870
    },
    {
      "epoch": 0.4775426948766148,
      "grad_norm": 0.09893908351659775,
      "learning_rate": 4.204395472543295e-05,
      "loss": 0.05,
      "step": 23880
    },
    {
      "epoch": 0.47774267087949446,
      "grad_norm": 0.1384839415550232,
      "learning_rate": 4.204062179205162e-05,
      "loss": 0.0923,
      "step": 23890
    },
    {
      "epoch": 0.4779426468823741,
      "grad_norm": 0.08696869015693665,
      "learning_rate": 4.203728885867029e-05,
      "loss": 0.0683,
      "step": 23900
    },
    {
      "epoch": 0.4781426228852538,
      "grad_norm": 0.10439686477184296,
      "learning_rate": 4.203395592528897e-05,
      "loss": 0.086,
      "step": 23910
    },
    {
      "epoch": 0.4783425988881334,
      "grad_norm": 0.1651775985956192,
      "learning_rate": 4.2030622991907644e-05,
      "loss": 0.1153,
      "step": 23920
    },
    {
      "epoch": 0.4785425748910131,
      "grad_norm": 0.11906101554632187,
      "learning_rate": 4.202729005852631e-05,
      "loss": 0.0772,
      "step": 23930
    },
    {
      "epoch": 0.4787425508938927,
      "grad_norm": 0.1143069639801979,
      "learning_rate": 4.202395712514498e-05,
      "loss": 0.0564,
      "step": 23940
    },
    {
      "epoch": 0.4789425268967724,
      "grad_norm": 0.11218331754207611,
      "learning_rate": 4.202062419176366e-05,
      "loss": 0.0831,
      "step": 23950
    },
    {
      "epoch": 0.47914250289965205,
      "grad_norm": 0.12467843294143677,
      "learning_rate": 4.201729125838233e-05,
      "loss": 0.0743,
      "step": 23960
    },
    {
      "epoch": 0.4793424789025317,
      "grad_norm": 0.1237456426024437,
      "learning_rate": 4.2013958325001e-05,
      "loss": 0.0519,
      "step": 23970
    },
    {
      "epoch": 0.47954245490541136,
      "grad_norm": 0.09597713500261307,
      "learning_rate": 4.2010625391619675e-05,
      "loss": 0.0708,
      "step": 23980
    },
    {
      "epoch": 0.479742430908291,
      "grad_norm": 0.198468416929245,
      "learning_rate": 4.2007292458238345e-05,
      "loss": 0.0682,
      "step": 23990
    },
    {
      "epoch": 0.4799424069111707,
      "grad_norm": 0.18710240721702576,
      "learning_rate": 4.2003959524857014e-05,
      "loss": 0.0987,
      "step": 24000
    },
    {
      "epoch": 0.4801423829140503,
      "grad_norm": 0.11204130202531815,
      "learning_rate": 4.200062659147569e-05,
      "loss": 0.0899,
      "step": 24010
    },
    {
      "epoch": 0.48034235891692995,
      "grad_norm": 0.08013062179088593,
      "learning_rate": 4.199729365809437e-05,
      "loss": 0.0487,
      "step": 24020
    },
    {
      "epoch": 0.48054233491980963,
      "grad_norm": 0.07070784270763397,
      "learning_rate": 4.1993960724713037e-05,
      "loss": 0.0521,
      "step": 24030
    },
    {
      "epoch": 0.48074231092268926,
      "grad_norm": 0.08182350546121597,
      "learning_rate": 4.199062779133171e-05,
      "loss": 0.0403,
      "step": 24040
    },
    {
      "epoch": 0.48094228692556895,
      "grad_norm": 0.15433436632156372,
      "learning_rate": 4.198729485795038e-05,
      "loss": 0.0802,
      "step": 24050
    },
    {
      "epoch": 0.4811422629284486,
      "grad_norm": 0.15569570660591125,
      "learning_rate": 4.198396192456905e-05,
      "loss": 0.0745,
      "step": 24060
    },
    {
      "epoch": 0.4813422389313282,
      "grad_norm": 0.15573638677597046,
      "learning_rate": 4.198062899118773e-05,
      "loss": 0.0669,
      "step": 24070
    },
    {
      "epoch": 0.4815422149342079,
      "grad_norm": 0.11950018256902695,
      "learning_rate": 4.19772960578064e-05,
      "loss": 0.0557,
      "step": 24080
    },
    {
      "epoch": 0.48174219093708753,
      "grad_norm": 0.21093924343585968,
      "learning_rate": 4.197396312442507e-05,
      "loss": 0.0774,
      "step": 24090
    },
    {
      "epoch": 0.4819421669399672,
      "grad_norm": 0.2046295404434204,
      "learning_rate": 4.1970630191043744e-05,
      "loss": 0.0998,
      "step": 24100
    },
    {
      "epoch": 0.48214214294284685,
      "grad_norm": 0.29088976979255676,
      "learning_rate": 4.1967297257662414e-05,
      "loss": 0.1184,
      "step": 24110
    },
    {
      "epoch": 0.48234211894572654,
      "grad_norm": 0.07616577297449112,
      "learning_rate": 4.196396432428109e-05,
      "loss": 0.0764,
      "step": 24120
    },
    {
      "epoch": 0.48254209494860617,
      "grad_norm": 0.11819426715373993,
      "learning_rate": 4.196063139089976e-05,
      "loss": 0.0805,
      "step": 24130
    },
    {
      "epoch": 0.4827420709514858,
      "grad_norm": 0.06354344636201859,
      "learning_rate": 4.1957298457518436e-05,
      "loss": 0.0697,
      "step": 24140
    },
    {
      "epoch": 0.4829420469543655,
      "grad_norm": 0.09124767780303955,
      "learning_rate": 4.1953965524137106e-05,
      "loss": 0.0751,
      "step": 24150
    },
    {
      "epoch": 0.4831420229572451,
      "grad_norm": 0.21933691203594208,
      "learning_rate": 4.1950632590755775e-05,
      "loss": 0.0771,
      "step": 24160
    },
    {
      "epoch": 0.4833419989601248,
      "grad_norm": 0.1440661996603012,
      "learning_rate": 4.194729965737445e-05,
      "loss": 0.0765,
      "step": 24170
    },
    {
      "epoch": 0.48354197496300444,
      "grad_norm": 0.20846685767173767,
      "learning_rate": 4.194396672399312e-05,
      "loss": 0.1102,
      "step": 24180
    },
    {
      "epoch": 0.48374195096588407,
      "grad_norm": 0.053530219942331314,
      "learning_rate": 4.194063379061179e-05,
      "loss": 0.0849,
      "step": 24190
    },
    {
      "epoch": 0.48394192696876376,
      "grad_norm": 0.09989065676927567,
      "learning_rate": 4.193730085723047e-05,
      "loss": 0.0806,
      "step": 24200
    },
    {
      "epoch": 0.4841419029716434,
      "grad_norm": 0.05321745201945305,
      "learning_rate": 4.193396792384914e-05,
      "loss": 0.0624,
      "step": 24210
    },
    {
      "epoch": 0.4843418789745231,
      "grad_norm": 0.11715970188379288,
      "learning_rate": 4.1930634990467814e-05,
      "loss": 0.1215,
      "step": 24220
    },
    {
      "epoch": 0.4845418549774027,
      "grad_norm": 0.0802256241440773,
      "learning_rate": 4.192730205708649e-05,
      "loss": 0.0661,
      "step": 24230
    },
    {
      "epoch": 0.48474183098028234,
      "grad_norm": 0.19037742912769318,
      "learning_rate": 4.192396912370516e-05,
      "loss": 0.0773,
      "step": 24240
    },
    {
      "epoch": 0.484941806983162,
      "grad_norm": 0.18089799582958221,
      "learning_rate": 4.192063619032383e-05,
      "loss": 0.0539,
      "step": 24250
    },
    {
      "epoch": 0.48514178298604166,
      "grad_norm": 0.11971299350261688,
      "learning_rate": 4.1917303256942506e-05,
      "loss": 0.1027,
      "step": 24260
    },
    {
      "epoch": 0.48534175898892135,
      "grad_norm": 0.12625843286514282,
      "learning_rate": 4.1913970323561175e-05,
      "loss": 0.0655,
      "step": 24270
    },
    {
      "epoch": 0.485541734991801,
      "grad_norm": 0.07615607976913452,
      "learning_rate": 4.1910637390179845e-05,
      "loss": 0.0794,
      "step": 24280
    },
    {
      "epoch": 0.48574171099468066,
      "grad_norm": 0.13277468085289001,
      "learning_rate": 4.190730445679852e-05,
      "loss": 0.086,
      "step": 24290
    },
    {
      "epoch": 0.4859416869975603,
      "grad_norm": 0.19465872645378113,
      "learning_rate": 4.190397152341719e-05,
      "loss": 0.0478,
      "step": 24300
    },
    {
      "epoch": 0.4861416630004399,
      "grad_norm": 0.08903210610151291,
      "learning_rate": 4.190063859003586e-05,
      "loss": 0.0493,
      "step": 24310
    },
    {
      "epoch": 0.4863416390033196,
      "grad_norm": 0.10186227411031723,
      "learning_rate": 4.189730565665454e-05,
      "loss": 0.0507,
      "step": 24320
    },
    {
      "epoch": 0.48654161500619925,
      "grad_norm": 0.08416431397199631,
      "learning_rate": 4.189430601661134e-05,
      "loss": 0.0998,
      "step": 24330
    },
    {
      "epoch": 0.48674159100907893,
      "grad_norm": 0.1388212889432907,
      "learning_rate": 4.1890973083230015e-05,
      "loss": 0.0535,
      "step": 24340
    },
    {
      "epoch": 0.48694156701195856,
      "grad_norm": 0.12365023791790009,
      "learning_rate": 4.188764014984869e-05,
      "loss": 0.0916,
      "step": 24350
    },
    {
      "epoch": 0.4871415430148382,
      "grad_norm": 0.19962728023529053,
      "learning_rate": 4.188430721646736e-05,
      "loss": 0.3414,
      "step": 24360
    },
    {
      "epoch": 0.4873415190177179,
      "grad_norm": 0.11413531750440598,
      "learning_rate": 4.188097428308603e-05,
      "loss": 0.267,
      "step": 24370
    },
    {
      "epoch": 0.4875414950205975,
      "grad_norm": 0.20113694667816162,
      "learning_rate": 4.187764134970471e-05,
      "loss": 0.0824,
      "step": 24380
    },
    {
      "epoch": 0.4877414710234772,
      "grad_norm": 0.21494969725608826,
      "learning_rate": 4.187430841632338e-05,
      "loss": 0.1233,
      "step": 24390
    },
    {
      "epoch": 0.48794144702635683,
      "grad_norm": 0.04080812260508537,
      "learning_rate": 4.1870975482942046e-05,
      "loss": 0.0862,
      "step": 24400
    },
    {
      "epoch": 0.48814142302923647,
      "grad_norm": 0.07501360028982162,
      "learning_rate": 4.186764254956072e-05,
      "loss": 0.0574,
      "step": 24410
    },
    {
      "epoch": 0.48834139903211615,
      "grad_norm": 0.0862451121211052,
      "learning_rate": 4.186430961617939e-05,
      "loss": 0.0786,
      "step": 24420
    },
    {
      "epoch": 0.4885413750349958,
      "grad_norm": 0.0733250305056572,
      "learning_rate": 4.186097668279806e-05,
      "loss": 0.1067,
      "step": 24430
    },
    {
      "epoch": 0.48874135103787547,
      "grad_norm": 0.10503200441598892,
      "learning_rate": 4.185764374941674e-05,
      "loss": 0.0877,
      "step": 24440
    },
    {
      "epoch": 0.4889413270407551,
      "grad_norm": 0.08814358711242676,
      "learning_rate": 4.1854310816035415e-05,
      "loss": 0.0912,
      "step": 24450
    },
    {
      "epoch": 0.4891413030436348,
      "grad_norm": 0.05672541633248329,
      "learning_rate": 4.1850977882654084e-05,
      "loss": 0.0753,
      "step": 24460
    },
    {
      "epoch": 0.4893412790465144,
      "grad_norm": 0.08684466779232025,
      "learning_rate": 4.1847644949272754e-05,
      "loss": 0.0802,
      "step": 24470
    },
    {
      "epoch": 0.48954125504939405,
      "grad_norm": 0.08002875000238419,
      "learning_rate": 4.184431201589143e-05,
      "loss": 0.0725,
      "step": 24480
    },
    {
      "epoch": 0.48974123105227374,
      "grad_norm": 0.0612143836915493,
      "learning_rate": 4.18409790825101e-05,
      "loss": 0.07,
      "step": 24490
    },
    {
      "epoch": 0.48994120705515337,
      "grad_norm": 0.11395163089036942,
      "learning_rate": 4.183764614912877e-05,
      "loss": 0.0876,
      "step": 24500
    },
    {
      "epoch": 0.49014118305803306,
      "grad_norm": 0.10550035536289215,
      "learning_rate": 4.1834313215747446e-05,
      "loss": 0.0794,
      "step": 24510
    },
    {
      "epoch": 0.4903411590609127,
      "grad_norm": 0.07585737854242325,
      "learning_rate": 4.1830980282366116e-05,
      "loss": 0.0787,
      "step": 24520
    },
    {
      "epoch": 0.4905411350637923,
      "grad_norm": 0.12358735501766205,
      "learning_rate": 4.1827647348984785e-05,
      "loss": 0.0605,
      "step": 24530
    },
    {
      "epoch": 0.490741111066672,
      "grad_norm": 0.20749516785144806,
      "learning_rate": 4.182431441560346e-05,
      "loss": 0.1114,
      "step": 24540
    },
    {
      "epoch": 0.49094108706955164,
      "grad_norm": 0.06121720373630524,
      "learning_rate": 4.182098148222214e-05,
      "loss": 0.0393,
      "step": 24550
    },
    {
      "epoch": 0.4911410630724313,
      "grad_norm": 0.11420592665672302,
      "learning_rate": 4.181764854884081e-05,
      "loss": 0.0988,
      "step": 24560
    },
    {
      "epoch": 0.49134103907531096,
      "grad_norm": 0.12813806533813477,
      "learning_rate": 4.1814315615459484e-05,
      "loss": 0.0829,
      "step": 24570
    },
    {
      "epoch": 0.4915410150781906,
      "grad_norm": 0.10566268116235733,
      "learning_rate": 4.1810982682078154e-05,
      "loss": 0.0626,
      "step": 24580
    },
    {
      "epoch": 0.4917409910810703,
      "grad_norm": 0.06508838385343552,
      "learning_rate": 4.180764974869682e-05,
      "loss": 0.0863,
      "step": 24590
    },
    {
      "epoch": 0.4919409670839499,
      "grad_norm": 0.10459421575069427,
      "learning_rate": 4.18043168153155e-05,
      "loss": 0.0905,
      "step": 24600
    },
    {
      "epoch": 0.4921409430868296,
      "grad_norm": 0.0898984968662262,
      "learning_rate": 4.180098388193417e-05,
      "loss": 0.047,
      "step": 24610
    },
    {
      "epoch": 0.49234091908970923,
      "grad_norm": 0.13122960925102234,
      "learning_rate": 4.179765094855284e-05,
      "loss": 0.0827,
      "step": 24620
    },
    {
      "epoch": 0.4925408950925889,
      "grad_norm": 0.19707828760147095,
      "learning_rate": 4.1794318015171515e-05,
      "loss": 0.1053,
      "step": 24630
    },
    {
      "epoch": 0.49274087109546855,
      "grad_norm": 0.0474962517619133,
      "learning_rate": 4.1790985081790185e-05,
      "loss": 0.127,
      "step": 24640
    },
    {
      "epoch": 0.4929408470983482,
      "grad_norm": 0.12877948582172394,
      "learning_rate": 4.1787985441746994e-05,
      "loss": 0.1205,
      "step": 24650
    },
    {
      "epoch": 0.49314082310122787,
      "grad_norm": 0.13591700792312622,
      "learning_rate": 4.178465250836566e-05,
      "loss": 0.0647,
      "step": 24660
    },
    {
      "epoch": 0.4933407991041075,
      "grad_norm": 0.1181502491235733,
      "learning_rate": 4.178131957498433e-05,
      "loss": 0.0885,
      "step": 24670
    },
    {
      "epoch": 0.4935407751069872,
      "grad_norm": 0.11240878701210022,
      "learning_rate": 4.177798664160301e-05,
      "loss": 0.0907,
      "step": 24680
    },
    {
      "epoch": 0.4937407511098668,
      "grad_norm": 0.08795914053916931,
      "learning_rate": 4.1774653708221686e-05,
      "loss": 0.0451,
      "step": 24690
    },
    {
      "epoch": 0.49394072711274645,
      "grad_norm": 0.13256603479385376,
      "learning_rate": 4.1771320774840355e-05,
      "loss": 0.1136,
      "step": 24700
    },
    {
      "epoch": 0.49414070311562613,
      "grad_norm": 0.17520543932914734,
      "learning_rate": 4.1767987841459025e-05,
      "loss": 0.1088,
      "step": 24710
    },
    {
      "epoch": 0.49434067911850577,
      "grad_norm": 0.13108578324317932,
      "learning_rate": 4.17646549080777e-05,
      "loss": 0.0803,
      "step": 24720
    },
    {
      "epoch": 0.49454065512138545,
      "grad_norm": 0.09411007910966873,
      "learning_rate": 4.176132197469637e-05,
      "loss": 0.0577,
      "step": 24730
    },
    {
      "epoch": 0.4947406311242651,
      "grad_norm": 0.09095130860805511,
      "learning_rate": 4.175798904131504e-05,
      "loss": 0.0775,
      "step": 24740
    },
    {
      "epoch": 0.4949406071271447,
      "grad_norm": 0.0728943720459938,
      "learning_rate": 4.175465610793372e-05,
      "loss": 0.0487,
      "step": 24750
    },
    {
      "epoch": 0.4951405831300244,
      "grad_norm": 0.09950674325227737,
      "learning_rate": 4.1751323174552387e-05,
      "loss": 0.04,
      "step": 24760
    },
    {
      "epoch": 0.49534055913290403,
      "grad_norm": 0.0725361779332161,
      "learning_rate": 4.1747990241171056e-05,
      "loss": 0.0724,
      "step": 24770
    },
    {
      "epoch": 0.4955405351357837,
      "grad_norm": 0.04936021938920021,
      "learning_rate": 4.174465730778974e-05,
      "loss": 0.0938,
      "step": 24780
    },
    {
      "epoch": 0.49574051113866335,
      "grad_norm": 0.18034325540065765,
      "learning_rate": 4.174132437440841e-05,
      "loss": 0.1097,
      "step": 24790
    },
    {
      "epoch": 0.49594048714154304,
      "grad_norm": 0.08156377822160721,
      "learning_rate": 4.173799144102708e-05,
      "loss": 0.0648,
      "step": 24800
    },
    {
      "epoch": 0.49614046314442267,
      "grad_norm": 0.1162065863609314,
      "learning_rate": 4.1734658507645755e-05,
      "loss": 0.0693,
      "step": 24810
    },
    {
      "epoch": 0.4963404391473023,
      "grad_norm": 0.08866667747497559,
      "learning_rate": 4.1731325574264425e-05,
      "loss": 0.084,
      "step": 24820
    },
    {
      "epoch": 0.496540415150182,
      "grad_norm": 0.048603639006614685,
      "learning_rate": 4.1727992640883094e-05,
      "loss": 0.0508,
      "step": 24830
    },
    {
      "epoch": 0.4967403911530616,
      "grad_norm": 0.2107250690460205,
      "learning_rate": 4.172465970750177e-05,
      "loss": 0.1682,
      "step": 24840
    },
    {
      "epoch": 0.4969403671559413,
      "grad_norm": 0.1617426723241806,
      "learning_rate": 4.172132677412044e-05,
      "loss": 0.069,
      "step": 24850
    },
    {
      "epoch": 0.49714034315882094,
      "grad_norm": 0.1160857304930687,
      "learning_rate": 4.171799384073911e-05,
      "loss": 0.0932,
      "step": 24860
    },
    {
      "epoch": 0.4973403191617006,
      "grad_norm": 0.10527515411376953,
      "learning_rate": 4.1714660907357786e-05,
      "loss": 0.0893,
      "step": 24870
    },
    {
      "epoch": 0.49754029516458026,
      "grad_norm": 0.18646185100078583,
      "learning_rate": 4.171132797397646e-05,
      "loss": 0.1165,
      "step": 24880
    },
    {
      "epoch": 0.4977402711674599,
      "grad_norm": 0.1650754064321518,
      "learning_rate": 4.170799504059513e-05,
      "loss": 0.0719,
      "step": 24890
    },
    {
      "epoch": 0.4979402471703396,
      "grad_norm": 0.08780740946531296,
      "learning_rate": 4.17046621072138e-05,
      "loss": 0.0834,
      "step": 24900
    },
    {
      "epoch": 0.4981402231732192,
      "grad_norm": 0.11990295350551605,
      "learning_rate": 4.170132917383248e-05,
      "loss": 0.11,
      "step": 24910
    },
    {
      "epoch": 0.49834019917609884,
      "grad_norm": 0.14652608335018158,
      "learning_rate": 4.169799624045115e-05,
      "loss": 0.0926,
      "step": 24920
    },
    {
      "epoch": 0.49854017517897853,
      "grad_norm": 0.15258319675922394,
      "learning_rate": 4.169466330706982e-05,
      "loss": 0.0542,
      "step": 24930
    },
    {
      "epoch": 0.49874015118185816,
      "grad_norm": 0.16438770294189453,
      "learning_rate": 4.1691330373688494e-05,
      "loss": 0.058,
      "step": 24940
    },
    {
      "epoch": 0.49894012718473785,
      "grad_norm": 0.07488595694303513,
      "learning_rate": 4.1687997440307163e-05,
      "loss": 0.0571,
      "step": 24950
    },
    {
      "epoch": 0.4991401031876175,
      "grad_norm": 0.1155276745557785,
      "learning_rate": 4.168466450692583e-05,
      "loss": 0.0461,
      "step": 24960
    },
    {
      "epoch": 0.49934007919049717,
      "grad_norm": 0.1658962517976761,
      "learning_rate": 4.168133157354451e-05,
      "loss": 0.1131,
      "step": 24970
    },
    {
      "epoch": 0.4995400551933768,
      "grad_norm": 0.07236140966415405,
      "learning_rate": 4.1677998640163186e-05,
      "loss": 0.0949,
      "step": 24980
    },
    {
      "epoch": 0.49974003119625643,
      "grad_norm": 0.17394599318504333,
      "learning_rate": 4.1674665706781855e-05,
      "loss": 0.0863,
      "step": 24990
    },
    {
      "epoch": 0.4999400071991361,
      "grad_norm": 0.08378708362579346,
      "learning_rate": 4.167133277340053e-05,
      "loss": 0.1032,
      "step": 25000
    },
    {
      "epoch": 0.5001399832020158,
      "grad_norm": 0.13145712018013,
      "learning_rate": 4.16679998400192e-05,
      "loss": 0.0581,
      "step": 25010
    },
    {
      "epoch": 0.5003399592048954,
      "grad_norm": 0.10461924970149994,
      "learning_rate": 4.166466690663787e-05,
      "loss": 0.0519,
      "step": 25020
    },
    {
      "epoch": 0.5005399352077751,
      "grad_norm": 0.1793629229068756,
      "learning_rate": 4.166133397325655e-05,
      "loss": 0.0783,
      "step": 25030
    },
    {
      "epoch": 0.5007399112106548,
      "grad_norm": 0.17244262993335724,
      "learning_rate": 4.165800103987522e-05,
      "loss": 0.0541,
      "step": 25040
    },
    {
      "epoch": 0.5009398872135343,
      "grad_norm": 0.10160719603300095,
      "learning_rate": 4.165466810649389e-05,
      "loss": 0.0589,
      "step": 25050
    },
    {
      "epoch": 0.501139863216414,
      "grad_norm": 0.15678541362285614,
      "learning_rate": 4.165133517311256e-05,
      "loss": 0.0815,
      "step": 25060
    },
    {
      "epoch": 0.5013398392192937,
      "grad_norm": 0.1329432725906372,
      "learning_rate": 4.164800223973123e-05,
      "loss": 0.0621,
      "step": 25070
    },
    {
      "epoch": 0.5015398152221734,
      "grad_norm": 0.2271825522184372,
      "learning_rate": 4.164466930634991e-05,
      "loss": 0.0986,
      "step": 25080
    },
    {
      "epoch": 0.501739791225053,
      "grad_norm": 0.20978333055973053,
      "learning_rate": 4.164133637296858e-05,
      "loss": 0.1338,
      "step": 25090
    },
    {
      "epoch": 0.5019397672279327,
      "grad_norm": 0.10496948659420013,
      "learning_rate": 4.1638003439587255e-05,
      "loss": 0.0636,
      "step": 25100
    },
    {
      "epoch": 0.5021397432308123,
      "grad_norm": 0.10190096497535706,
      "learning_rate": 4.1634670506205925e-05,
      "loss": 0.1062,
      "step": 25110
    },
    {
      "epoch": 0.5023397192336919,
      "grad_norm": 0.10823866724967957,
      "learning_rate": 4.1631337572824594e-05,
      "loss": 0.0724,
      "step": 25120
    },
    {
      "epoch": 0.5025396952365716,
      "grad_norm": 0.07196568697690964,
      "learning_rate": 4.162800463944327e-05,
      "loss": 0.0531,
      "step": 25130
    },
    {
      "epoch": 0.5027396712394513,
      "grad_norm": 0.1341681033372879,
      "learning_rate": 4.162467170606194e-05,
      "loss": 0.0996,
      "step": 25140
    },
    {
      "epoch": 0.5029396472423309,
      "grad_norm": 0.08227868378162384,
      "learning_rate": 4.162133877268061e-05,
      "loss": 0.065,
      "step": 25150
    },
    {
      "epoch": 0.5031396232452106,
      "grad_norm": 0.10020740330219269,
      "learning_rate": 4.1618005839299286e-05,
      "loss": 0.0717,
      "step": 25160
    },
    {
      "epoch": 0.5033395992480902,
      "grad_norm": 0.15016323328018188,
      "learning_rate": 4.1614672905917956e-05,
      "loss": 0.0591,
      "step": 25170
    },
    {
      "epoch": 0.5035395752509699,
      "grad_norm": 0.14401207864284515,
      "learning_rate": 4.1611339972536626e-05,
      "loss": 0.0653,
      "step": 25180
    },
    {
      "epoch": 0.5037395512538495,
      "grad_norm": 0.14711464941501617,
      "learning_rate": 4.160800703915531e-05,
      "loss": 0.0908,
      "step": 25190
    },
    {
      "epoch": 0.5039395272567292,
      "grad_norm": 0.07703850418329239,
      "learning_rate": 4.160467410577398e-05,
      "loss": 0.071,
      "step": 25200
    },
    {
      "epoch": 0.5041395032596089,
      "grad_norm": 0.06799131631851196,
      "learning_rate": 4.160134117239265e-05,
      "loss": 0.0825,
      "step": 25210
    },
    {
      "epoch": 0.5043394792624885,
      "grad_norm": 0.04482273757457733,
      "learning_rate": 4.1598008239011324e-05,
      "loss": 0.0911,
      "step": 25220
    },
    {
      "epoch": 0.5045394552653681,
      "grad_norm": 0.0728515088558197,
      "learning_rate": 4.1594675305629994e-05,
      "loss": 0.1009,
      "step": 25230
    },
    {
      "epoch": 0.5047394312682478,
      "grad_norm": 0.12101620435714722,
      "learning_rate": 4.1591342372248664e-05,
      "loss": 0.0847,
      "step": 25240
    },
    {
      "epoch": 0.5049394072711275,
      "grad_norm": 0.14117112755775452,
      "learning_rate": 4.158800943886734e-05,
      "loss": 0.0541,
      "step": 25250
    },
    {
      "epoch": 0.5051393832740071,
      "grad_norm": 0.08831939101219177,
      "learning_rate": 4.158467650548601e-05,
      "loss": 0.0966,
      "step": 25260
    },
    {
      "epoch": 0.5053393592768868,
      "grad_norm": 0.09770066291093826,
      "learning_rate": 4.158134357210468e-05,
      "loss": 0.053,
      "step": 25270
    },
    {
      "epoch": 0.5055393352797665,
      "grad_norm": 0.08503403514623642,
      "learning_rate": 4.1578010638723356e-05,
      "loss": 0.0634,
      "step": 25280
    },
    {
      "epoch": 0.505739311282646,
      "grad_norm": 0.07922528684139252,
      "learning_rate": 4.157467770534203e-05,
      "loss": 0.0768,
      "step": 25290
    },
    {
      "epoch": 0.5059392872855257,
      "grad_norm": 0.11336156725883484,
      "learning_rate": 4.15713447719607e-05,
      "loss": 0.0855,
      "step": 25300
    },
    {
      "epoch": 0.5061392632884054,
      "grad_norm": 0.15755711495876312,
      "learning_rate": 4.156801183857937e-05,
      "loss": 0.1009,
      "step": 25310
    },
    {
      "epoch": 0.506339239291285,
      "grad_norm": 0.09939656406641006,
      "learning_rate": 4.156467890519805e-05,
      "loss": 0.0993,
      "step": 25320
    },
    {
      "epoch": 0.5065392152941647,
      "grad_norm": 0.1655711829662323,
      "learning_rate": 4.156134597181672e-05,
      "loss": 0.0802,
      "step": 25330
    },
    {
      "epoch": 0.5067391912970444,
      "grad_norm": 0.07854752987623215,
      "learning_rate": 4.155801303843539e-05,
      "loss": 0.0823,
      "step": 25340
    },
    {
      "epoch": 0.506939167299924,
      "grad_norm": 0.15973331034183502,
      "learning_rate": 4.155468010505406e-05,
      "loss": 0.1168,
      "step": 25350
    },
    {
      "epoch": 0.5071391433028036,
      "grad_norm": 0.062402497977018356,
      "learning_rate": 4.155134717167273e-05,
      "loss": 0.6255,
      "step": 25360
    },
    {
      "epoch": 0.5073391193056833,
      "grad_norm": 0.18072234094142914,
      "learning_rate": 4.15480142382914e-05,
      "loss": 0.0887,
      "step": 25370
    },
    {
      "epoch": 0.507539095308563,
      "grad_norm": 0.08396998047828674,
      "learning_rate": 4.154468130491008e-05,
      "loss": 0.0392,
      "step": 25380
    },
    {
      "epoch": 0.5077390713114426,
      "grad_norm": 0.07715877145528793,
      "learning_rate": 4.1541348371528755e-05,
      "loss": 0.1061,
      "step": 25390
    },
    {
      "epoch": 0.5079390473143223,
      "grad_norm": 0.1398199200630188,
      "learning_rate": 4.1538015438147425e-05,
      "loss": 0.0677,
      "step": 25400
    },
    {
      "epoch": 0.508139023317202,
      "grad_norm": 0.12175900489091873,
      "learning_rate": 4.15346825047661e-05,
      "loss": 0.0699,
      "step": 25410
    },
    {
      "epoch": 0.5083389993200816,
      "grad_norm": 0.10324064642190933,
      "learning_rate": 4.153134957138477e-05,
      "loss": 0.0827,
      "step": 25420
    },
    {
      "epoch": 0.5085389753229612,
      "grad_norm": 0.10481294989585876,
      "learning_rate": 4.152801663800344e-05,
      "loss": 0.0687,
      "step": 25430
    },
    {
      "epoch": 0.5087389513258409,
      "grad_norm": 0.05938822403550148,
      "learning_rate": 4.152468370462212e-05,
      "loss": 0.0582,
      "step": 25440
    },
    {
      "epoch": 0.5089389273287206,
      "grad_norm": 0.053744662553071976,
      "learning_rate": 4.1521350771240787e-05,
      "loss": 0.0697,
      "step": 25450
    },
    {
      "epoch": 0.5091389033316002,
      "grad_norm": 0.14787940680980682,
      "learning_rate": 4.1518017837859456e-05,
      "loss": 0.0622,
      "step": 25460
    },
    {
      "epoch": 0.5093388793344799,
      "grad_norm": 0.1744660586118698,
      "learning_rate": 4.151468490447813e-05,
      "loss": 0.1167,
      "step": 25470
    },
    {
      "epoch": 0.5095388553373595,
      "grad_norm": 0.12831969559192657,
      "learning_rate": 4.15113519710968e-05,
      "loss": 0.0963,
      "step": 25480
    },
    {
      "epoch": 0.5097388313402391,
      "grad_norm": 0.06728725135326385,
      "learning_rate": 4.150801903771548e-05,
      "loss": 0.0727,
      "step": 25490
    },
    {
      "epoch": 0.5099388073431188,
      "grad_norm": 0.057457420974969864,
      "learning_rate": 4.150468610433415e-05,
      "loss": 0.0933,
      "step": 25500
    },
    {
      "epoch": 0.5101387833459985,
      "grad_norm": 0.09888385981321335,
      "learning_rate": 4.1501353170952825e-05,
      "loss": 0.0459,
      "step": 25510
    },
    {
      "epoch": 0.5103387593488782,
      "grad_norm": 0.1635754108428955,
      "learning_rate": 4.1498020237571494e-05,
      "loss": 0.0971,
      "step": 25520
    },
    {
      "epoch": 0.5105387353517578,
      "grad_norm": 0.10653703659772873,
      "learning_rate": 4.1494687304190164e-05,
      "loss": 0.0644,
      "step": 25530
    },
    {
      "epoch": 0.5107387113546374,
      "grad_norm": 0.1361658126115799,
      "learning_rate": 4.149135437080884e-05,
      "loss": 0.0836,
      "step": 25540
    },
    {
      "epoch": 0.5109386873575171,
      "grad_norm": 0.10422450304031372,
      "learning_rate": 4.148802143742751e-05,
      "loss": 0.0923,
      "step": 25550
    },
    {
      "epoch": 0.5111386633603967,
      "grad_norm": 0.19353069365024567,
      "learning_rate": 4.148468850404618e-05,
      "loss": 0.0884,
      "step": 25560
    },
    {
      "epoch": 0.5113386393632764,
      "grad_norm": 0.18017974495887756,
      "learning_rate": 4.1481355570664856e-05,
      "loss": 0.0811,
      "step": 25570
    },
    {
      "epoch": 0.5115386153661561,
      "grad_norm": 0.1445755958557129,
      "learning_rate": 4.1478022637283525e-05,
      "loss": 0.0939,
      "step": 25580
    },
    {
      "epoch": 0.5117385913690358,
      "grad_norm": 0.18794085085391998,
      "learning_rate": 4.14746897039022e-05,
      "loss": 0.1109,
      "step": 25590
    },
    {
      "epoch": 0.5119385673719153,
      "grad_norm": 0.08639691770076752,
      "learning_rate": 4.147135677052088e-05,
      "loss": 0.0755,
      "step": 25600
    },
    {
      "epoch": 0.512138543374795,
      "grad_norm": 0.18012066185474396,
      "learning_rate": 4.146802383713955e-05,
      "loss": 0.103,
      "step": 25610
    },
    {
      "epoch": 0.5123385193776747,
      "grad_norm": 0.06714468449354172,
      "learning_rate": 4.146469090375822e-05,
      "loss": 0.0619,
      "step": 25620
    },
    {
      "epoch": 0.5125384953805543,
      "grad_norm": 0.09952444583177567,
      "learning_rate": 4.1461357970376894e-05,
      "loss": 0.078,
      "step": 25630
    },
    {
      "epoch": 0.512738471383434,
      "grad_norm": 0.08136534690856934,
      "learning_rate": 4.1458025036995563e-05,
      "loss": 0.1218,
      "step": 25640
    },
    {
      "epoch": 0.5129384473863137,
      "grad_norm": 0.13095363974571228,
      "learning_rate": 4.145469210361423e-05,
      "loss": 0.1051,
      "step": 25650
    },
    {
      "epoch": 0.5131384233891932,
      "grad_norm": 0.07305184751749039,
      "learning_rate": 4.145135917023291e-05,
      "loss": 0.0657,
      "step": 25660
    },
    {
      "epoch": 0.5133383993920729,
      "grad_norm": 0.058509811758995056,
      "learning_rate": 4.144802623685158e-05,
      "loss": 0.0718,
      "step": 25670
    },
    {
      "epoch": 0.5135383753949526,
      "grad_norm": 0.05606797710061073,
      "learning_rate": 4.144469330347025e-05,
      "loss": 0.0645,
      "step": 25680
    },
    {
      "epoch": 0.5137383513978323,
      "grad_norm": 0.1311648190021515,
      "learning_rate": 4.1441360370088925e-05,
      "loss": 0.0662,
      "step": 25690
    },
    {
      "epoch": 0.5139383274007119,
      "grad_norm": 0.0712742954492569,
      "learning_rate": 4.14380274367076e-05,
      "loss": 0.0618,
      "step": 25700
    },
    {
      "epoch": 0.5141383034035916,
      "grad_norm": 0.20084606111049652,
      "learning_rate": 4.143469450332627e-05,
      "loss": 0.0777,
      "step": 25710
    },
    {
      "epoch": 0.5143382794064713,
      "grad_norm": 0.11188318580389023,
      "learning_rate": 4.143136156994494e-05,
      "loss": 0.0689,
      "step": 25720
    },
    {
      "epoch": 0.5145382554093508,
      "grad_norm": 0.15930168330669403,
      "learning_rate": 4.142802863656362e-05,
      "loss": 0.0783,
      "step": 25730
    },
    {
      "epoch": 0.5147382314122305,
      "grad_norm": 0.08250530064105988,
      "learning_rate": 4.142469570318229e-05,
      "loss": 0.069,
      "step": 25740
    },
    {
      "epoch": 0.5149382074151102,
      "grad_norm": 0.07317661494016647,
      "learning_rate": 4.1421362769800956e-05,
      "loss": 0.0536,
      "step": 25750
    },
    {
      "epoch": 0.5151381834179899,
      "grad_norm": 0.1460966318845749,
      "learning_rate": 4.141802983641963e-05,
      "loss": 0.0692,
      "step": 25760
    },
    {
      "epoch": 0.5153381594208695,
      "grad_norm": 0.1968037486076355,
      "learning_rate": 4.14146969030383e-05,
      "loss": 0.0833,
      "step": 25770
    },
    {
      "epoch": 0.5155381354237492,
      "grad_norm": 0.15828150510787964,
      "learning_rate": 4.141136396965697e-05,
      "loss": 0.0729,
      "step": 25780
    },
    {
      "epoch": 0.5157381114266288,
      "grad_norm": 0.08252233266830444,
      "learning_rate": 4.140803103627565e-05,
      "loss": 0.0863,
      "step": 25790
    },
    {
      "epoch": 0.5159380874295084,
      "grad_norm": 0.09703903645277023,
      "learning_rate": 4.1404698102894325e-05,
      "loss": 0.0639,
      "step": 25800
    },
    {
      "epoch": 0.5161380634323881,
      "grad_norm": 0.08578351885080338,
      "learning_rate": 4.1401365169512994e-05,
      "loss": 0.0515,
      "step": 25810
    },
    {
      "epoch": 0.5163380394352678,
      "grad_norm": 0.10816024988889694,
      "learning_rate": 4.139803223613167e-05,
      "loss": 0.0824,
      "step": 25820
    },
    {
      "epoch": 0.5165380154381474,
      "grad_norm": 0.11952515691518784,
      "learning_rate": 4.139469930275034e-05,
      "loss": 0.0697,
      "step": 25830
    },
    {
      "epoch": 0.5167379914410271,
      "grad_norm": 0.1726321429014206,
      "learning_rate": 4.139136636936901e-05,
      "loss": 0.0635,
      "step": 25840
    },
    {
      "epoch": 0.5169379674439067,
      "grad_norm": 0.07323164492845535,
      "learning_rate": 4.1388033435987686e-05,
      "loss": 0.0541,
      "step": 25850
    },
    {
      "epoch": 0.5171379434467864,
      "grad_norm": 0.14268288016319275,
      "learning_rate": 4.1384700502606356e-05,
      "loss": 0.0715,
      "step": 25860
    },
    {
      "epoch": 0.517337919449666,
      "grad_norm": 0.16474570333957672,
      "learning_rate": 4.1381367569225026e-05,
      "loss": 0.0489,
      "step": 25870
    },
    {
      "epoch": 0.5175378954525457,
      "grad_norm": 0.08678936958312988,
      "learning_rate": 4.13780346358437e-05,
      "loss": 0.1104,
      "step": 25880
    },
    {
      "epoch": 0.5177378714554254,
      "grad_norm": 0.12611745297908783,
      "learning_rate": 4.137470170246237e-05,
      "loss": 0.0872,
      "step": 25890
    },
    {
      "epoch": 0.517937847458305,
      "grad_norm": 0.13237904012203217,
      "learning_rate": 4.137136876908105e-05,
      "loss": 0.0919,
      "step": 25900
    },
    {
      "epoch": 0.5181378234611846,
      "grad_norm": 0.18873150646686554,
      "learning_rate": 4.136803583569972e-05,
      "loss": 0.0791,
      "step": 25910
    },
    {
      "epoch": 0.5183377994640643,
      "grad_norm": 0.054041240364313126,
      "learning_rate": 4.1364702902318394e-05,
      "loss": 0.1024,
      "step": 25920
    },
    {
      "epoch": 0.518537775466944,
      "grad_norm": 0.10105755925178528,
      "learning_rate": 4.1361369968937064e-05,
      "loss": 0.0926,
      "step": 25930
    },
    {
      "epoch": 0.5187377514698236,
      "grad_norm": 0.07894980907440186,
      "learning_rate": 4.135803703555573e-05,
      "loss": 0.071,
      "step": 25940
    },
    {
      "epoch": 0.5189377274727033,
      "grad_norm": 0.16884209215641022,
      "learning_rate": 4.135470410217441e-05,
      "loss": 0.096,
      "step": 25950
    },
    {
      "epoch": 0.519137703475583,
      "grad_norm": 0.15493887662887573,
      "learning_rate": 4.135137116879308e-05,
      "loss": 0.0644,
      "step": 25960
    },
    {
      "epoch": 0.5193376794784625,
      "grad_norm": 0.16664087772369385,
      "learning_rate": 4.134803823541175e-05,
      "loss": 0.0958,
      "step": 25970
    },
    {
      "epoch": 0.5195376554813422,
      "grad_norm": 0.17663486301898956,
      "learning_rate": 4.1344705302030425e-05,
      "loss": 0.0902,
      "step": 25980
    },
    {
      "epoch": 0.5197376314842219,
      "grad_norm": 0.11518541723489761,
      "learning_rate": 4.1341372368649095e-05,
      "loss": 0.0822,
      "step": 25990
    },
    {
      "epoch": 0.5199376074871015,
      "grad_norm": 0.09870143234729767,
      "learning_rate": 4.133803943526777e-05,
      "loss": 0.0944,
      "step": 26000
    },
    {
      "epoch": 0.5201375834899812,
      "grad_norm": 0.09953665733337402,
      "learning_rate": 4.133470650188645e-05,
      "loss": 0.0928,
      "step": 26010
    },
    {
      "epoch": 0.5203375594928609,
      "grad_norm": 0.13184326887130737,
      "learning_rate": 4.133137356850512e-05,
      "loss": 0.093,
      "step": 26020
    },
    {
      "epoch": 0.5205375354957406,
      "grad_norm": 0.15456707775592804,
      "learning_rate": 4.132804063512379e-05,
      "loss": 0.0695,
      "step": 26030
    },
    {
      "epoch": 0.5207375114986201,
      "grad_norm": 0.08930708467960358,
      "learning_rate": 4.132470770174246e-05,
      "loss": 0.0923,
      "step": 26040
    },
    {
      "epoch": 0.5209374875014998,
      "grad_norm": 0.11744499951601028,
      "learning_rate": 4.132137476836113e-05,
      "loss": 0.0653,
      "step": 26050
    },
    {
      "epoch": 0.5211374635043795,
      "grad_norm": 0.08859564363956451,
      "learning_rate": 4.13180418349798e-05,
      "loss": 0.0613,
      "step": 26060
    },
    {
      "epoch": 0.5213374395072591,
      "grad_norm": 0.05540716275572777,
      "learning_rate": 4.131470890159848e-05,
      "loss": 0.0921,
      "step": 26070
    },
    {
      "epoch": 0.5215374155101388,
      "grad_norm": 0.14227257668972015,
      "learning_rate": 4.131137596821715e-05,
      "loss": 0.0897,
      "step": 26080
    },
    {
      "epoch": 0.5217373915130185,
      "grad_norm": 0.07800354808568954,
      "learning_rate": 4.130804303483582e-05,
      "loss": 0.0891,
      "step": 26090
    },
    {
      "epoch": 0.5219373675158981,
      "grad_norm": 0.12821568548679352,
      "learning_rate": 4.1304710101454495e-05,
      "loss": 0.0737,
      "step": 26100
    },
    {
      "epoch": 0.5221373435187777,
      "grad_norm": 0.17380402982234955,
      "learning_rate": 4.130137716807317e-05,
      "loss": 0.0652,
      "step": 26110
    },
    {
      "epoch": 0.5223373195216574,
      "grad_norm": 0.11218955367803574,
      "learning_rate": 4.129804423469184e-05,
      "loss": 0.0943,
      "step": 26120
    },
    {
      "epoch": 0.5225372955245371,
      "grad_norm": 0.16184048354625702,
      "learning_rate": 4.129471130131051e-05,
      "loss": 0.083,
      "step": 26130
    },
    {
      "epoch": 0.5227372715274167,
      "grad_norm": 0.08413539081811905,
      "learning_rate": 4.1291378367929187e-05,
      "loss": 0.088,
      "step": 26140
    },
    {
      "epoch": 0.5229372475302964,
      "grad_norm": 0.19952723383903503,
      "learning_rate": 4.1288045434547856e-05,
      "loss": 0.0881,
      "step": 26150
    },
    {
      "epoch": 0.523137223533176,
      "grad_norm": 0.14303722977638245,
      "learning_rate": 4.1284712501166526e-05,
      "loss": 0.0881,
      "step": 26160
    },
    {
      "epoch": 0.5233371995360556,
      "grad_norm": 0.2182018756866455,
      "learning_rate": 4.12813795677852e-05,
      "loss": 0.1151,
      "step": 26170
    },
    {
      "epoch": 0.5235371755389353,
      "grad_norm": 0.12079634517431259,
      "learning_rate": 4.127804663440387e-05,
      "loss": 0.1023,
      "step": 26180
    },
    {
      "epoch": 0.523737151541815,
      "grad_norm": 0.16691893339157104,
      "learning_rate": 4.127471370102254e-05,
      "loss": 0.0773,
      "step": 26190
    },
    {
      "epoch": 0.5239371275446947,
      "grad_norm": 0.051201362162828445,
      "learning_rate": 4.127138076764122e-05,
      "loss": 0.0587,
      "step": 26200
    },
    {
      "epoch": 0.5241371035475743,
      "grad_norm": 0.09237460047006607,
      "learning_rate": 4.1268047834259894e-05,
      "loss": 0.1087,
      "step": 26210
    },
    {
      "epoch": 0.5243370795504539,
      "grad_norm": 0.04399176314473152,
      "learning_rate": 4.1264714900878564e-05,
      "loss": 0.157,
      "step": 26220
    },
    {
      "epoch": 0.5245370555533336,
      "grad_norm": 0.15363311767578125,
      "learning_rate": 4.1261381967497233e-05,
      "loss": 0.0718,
      "step": 26230
    },
    {
      "epoch": 0.5247370315562132,
      "grad_norm": 0.11697594821453094,
      "learning_rate": 4.125804903411591e-05,
      "loss": 0.0883,
      "step": 26240
    },
    {
      "epoch": 0.5249370075590929,
      "grad_norm": 0.09080856293439865,
      "learning_rate": 4.125471610073458e-05,
      "loss": 0.0749,
      "step": 26250
    },
    {
      "epoch": 0.5251369835619726,
      "grad_norm": 0.130168616771698,
      "learning_rate": 4.1251383167353256e-05,
      "loss": 0.072,
      "step": 26260
    },
    {
      "epoch": 0.5253369595648523,
      "grad_norm": 0.13488639891147614,
      "learning_rate": 4.1248050233971925e-05,
      "loss": 0.0546,
      "step": 26270
    },
    {
      "epoch": 0.5255369355677318,
      "grad_norm": 0.18276245892047882,
      "learning_rate": 4.1244717300590595e-05,
      "loss": 0.0649,
      "step": 26280
    },
    {
      "epoch": 0.5257369115706115,
      "grad_norm": 0.08902350813150406,
      "learning_rate": 4.124138436720927e-05,
      "loss": 0.0969,
      "step": 26290
    },
    {
      "epoch": 0.5259368875734912,
      "grad_norm": 0.16450618207454681,
      "learning_rate": 4.123805143382794e-05,
      "loss": 0.085,
      "step": 26300
    },
    {
      "epoch": 0.5261368635763708,
      "grad_norm": 0.07503237575292587,
      "learning_rate": 4.123471850044662e-05,
      "loss": 0.0714,
      "step": 26310
    },
    {
      "epoch": 0.5263368395792505,
      "grad_norm": 0.16629232466220856,
      "learning_rate": 4.123138556706529e-05,
      "loss": 0.0879,
      "step": 26320
    },
    {
      "epoch": 0.5265368155821302,
      "grad_norm": 0.05952979624271393,
      "learning_rate": 4.1228052633683963e-05,
      "loss": 0.0785,
      "step": 26330
    },
    {
      "epoch": 0.5267367915850097,
      "grad_norm": 0.14892658591270447,
      "learning_rate": 4.122471970030263e-05,
      "loss": 0.0712,
      "step": 26340
    },
    {
      "epoch": 0.5269367675878894,
      "grad_norm": 0.19216519594192505,
      "learning_rate": 4.12213867669213e-05,
      "loss": 0.0874,
      "step": 26350
    },
    {
      "epoch": 0.5271367435907691,
      "grad_norm": 0.19535645842552185,
      "learning_rate": 4.121805383353998e-05,
      "loss": 0.1003,
      "step": 26360
    },
    {
      "epoch": 0.5273367195936488,
      "grad_norm": 0.15697187185287476,
      "learning_rate": 4.121472090015865e-05,
      "loss": 0.1037,
      "step": 26370
    },
    {
      "epoch": 0.5275366955965284,
      "grad_norm": 0.11079835891723633,
      "learning_rate": 4.121138796677732e-05,
      "loss": 0.0907,
      "step": 26380
    },
    {
      "epoch": 0.5277366715994081,
      "grad_norm": 0.08114981651306152,
      "learning_rate": 4.1208055033395995e-05,
      "loss": 0.0527,
      "step": 26390
    },
    {
      "epoch": 0.5279366476022878,
      "grad_norm": 0.13518984615802765,
      "learning_rate": 4.1204722100014664e-05,
      "loss": 0.0768,
      "step": 26400
    },
    {
      "epoch": 0.5281366236051673,
      "grad_norm": 0.15340912342071533,
      "learning_rate": 4.120138916663334e-05,
      "loss": 0.0545,
      "step": 26410
    },
    {
      "epoch": 0.528336599608047,
      "grad_norm": 0.1872173249721527,
      "learning_rate": 4.119805623325201e-05,
      "loss": 0.0868,
      "step": 26420
    },
    {
      "epoch": 0.5285365756109267,
      "grad_norm": 0.1155579537153244,
      "learning_rate": 4.119472329987069e-05,
      "loss": 0.0883,
      "step": 26430
    },
    {
      "epoch": 0.5287365516138064,
      "grad_norm": 0.08759890496730804,
      "learning_rate": 4.1191390366489356e-05,
      "loss": 0.0532,
      "step": 26440
    },
    {
      "epoch": 0.528936527616686,
      "grad_norm": 0.10457459837198257,
      "learning_rate": 4.1188057433108026e-05,
      "loss": 0.0889,
      "step": 26450
    },
    {
      "epoch": 0.5291365036195657,
      "grad_norm": 0.22485995292663574,
      "learning_rate": 4.11847244997267e-05,
      "loss": 0.0854,
      "step": 26460
    },
    {
      "epoch": 0.5293364796224453,
      "grad_norm": 0.04976881667971611,
      "learning_rate": 4.118139156634537e-05,
      "loss": 0.0677,
      "step": 26470
    },
    {
      "epoch": 0.5295364556253249,
      "grad_norm": 0.08418626338243484,
      "learning_rate": 4.117805863296404e-05,
      "loss": 0.0978,
      "step": 26480
    },
    {
      "epoch": 0.5297364316282046,
      "grad_norm": 0.1690559685230255,
      "learning_rate": 4.117472569958272e-05,
      "loss": 0.0835,
      "step": 26490
    },
    {
      "epoch": 0.5299364076310843,
      "grad_norm": 0.10903022438287735,
      "learning_rate": 4.117139276620139e-05,
      "loss": 0.1115,
      "step": 26500
    },
    {
      "epoch": 0.5301363836339639,
      "grad_norm": 0.10361132025718689,
      "learning_rate": 4.1168059832820064e-05,
      "loss": 0.0628,
      "step": 26510
    },
    {
      "epoch": 0.5303363596368436,
      "grad_norm": 0.2003590613603592,
      "learning_rate": 4.116472689943874e-05,
      "loss": 0.0617,
      "step": 26520
    },
    {
      "epoch": 0.5305363356397232,
      "grad_norm": 0.17958030104637146,
      "learning_rate": 4.116139396605741e-05,
      "loss": 0.1108,
      "step": 26530
    },
    {
      "epoch": 0.5307363116426029,
      "grad_norm": 0.08523649722337723,
      "learning_rate": 4.115806103267608e-05,
      "loss": 0.0508,
      "step": 26540
    },
    {
      "epoch": 0.5309362876454825,
      "grad_norm": 0.20004351437091827,
      "learning_rate": 4.1154728099294756e-05,
      "loss": 0.087,
      "step": 26550
    },
    {
      "epoch": 0.5311362636483622,
      "grad_norm": 0.1274765133857727,
      "learning_rate": 4.1151395165913426e-05,
      "loss": 0.0919,
      "step": 26560
    },
    {
      "epoch": 0.5313362396512419,
      "grad_norm": 0.11777694523334503,
      "learning_rate": 4.1148062232532095e-05,
      "loss": 0.0569,
      "step": 26570
    },
    {
      "epoch": 0.5315362156541215,
      "grad_norm": 0.07576900720596313,
      "learning_rate": 4.114472929915077e-05,
      "loss": 0.0745,
      "step": 26580
    },
    {
      "epoch": 0.5317361916570011,
      "grad_norm": 0.09811857342720032,
      "learning_rate": 4.114139636576944e-05,
      "loss": 0.0837,
      "step": 26590
    },
    {
      "epoch": 0.5319361676598808,
      "grad_norm": 0.17968524992465973,
      "learning_rate": 4.113806343238811e-05,
      "loss": 0.1521,
      "step": 26600
    },
    {
      "epoch": 0.5321361436627605,
      "grad_norm": 0.16048386693000793,
      "learning_rate": 4.113473049900679e-05,
      "loss": 0.0687,
      "step": 26610
    },
    {
      "epoch": 0.5323361196656401,
      "grad_norm": 0.10474957525730133,
      "learning_rate": 4.1131397565625464e-05,
      "loss": 0.1094,
      "step": 26620
    },
    {
      "epoch": 0.5325360956685198,
      "grad_norm": 0.15538012981414795,
      "learning_rate": 4.112806463224413e-05,
      "loss": 0.0727,
      "step": 26630
    },
    {
      "epoch": 0.5327360716713995,
      "grad_norm": 0.12809839844703674,
      "learning_rate": 4.11247316988628e-05,
      "loss": 0.1212,
      "step": 26640
    },
    {
      "epoch": 0.532936047674279,
      "grad_norm": 0.23990163207054138,
      "learning_rate": 4.112139876548148e-05,
      "loss": 0.0911,
      "step": 26650
    },
    {
      "epoch": 0.5331360236771587,
      "grad_norm": 0.13438397645950317,
      "learning_rate": 4.111806583210015e-05,
      "loss": 0.1124,
      "step": 26660
    },
    {
      "epoch": 0.5333359996800384,
      "grad_norm": 0.18098634481430054,
      "learning_rate": 4.111473289871882e-05,
      "loss": 0.0825,
      "step": 26670
    },
    {
      "epoch": 0.533535975682918,
      "grad_norm": 0.06722059100866318,
      "learning_rate": 4.1111399965337495e-05,
      "loss": 0.0865,
      "step": 26680
    },
    {
      "epoch": 0.5337359516857977,
      "grad_norm": 0.04819387197494507,
      "learning_rate": 4.1108067031956165e-05,
      "loss": 0.0712,
      "step": 26690
    },
    {
      "epoch": 0.5339359276886774,
      "grad_norm": 0.07575720548629761,
      "learning_rate": 4.1104734098574834e-05,
      "loss": 0.0643,
      "step": 26700
    },
    {
      "epoch": 0.5341359036915571,
      "grad_norm": 0.16638484597206116,
      "learning_rate": 4.110140116519351e-05,
      "loss": 0.0671,
      "step": 26710
    },
    {
      "epoch": 0.5343358796944366,
      "grad_norm": 0.05590944364666939,
      "learning_rate": 4.109806823181219e-05,
      "loss": 0.0527,
      "step": 26720
    },
    {
      "epoch": 0.5345358556973163,
      "grad_norm": 0.28417259454727173,
      "learning_rate": 4.1094735298430857e-05,
      "loss": 0.1074,
      "step": 26730
    },
    {
      "epoch": 0.534735831700196,
      "grad_norm": 0.07615753263235092,
      "learning_rate": 4.109140236504953e-05,
      "loss": 0.0865,
      "step": 26740
    },
    {
      "epoch": 0.5349358077030756,
      "grad_norm": 0.1552496701478958,
      "learning_rate": 4.10880694316682e-05,
      "loss": 0.0749,
      "step": 26750
    },
    {
      "epoch": 0.5351357837059553,
      "grad_norm": 0.15646876394748688,
      "learning_rate": 4.108473649828687e-05,
      "loss": 0.1037,
      "step": 26760
    },
    {
      "epoch": 0.535335759708835,
      "grad_norm": 0.20298872888088226,
      "learning_rate": 4.108140356490555e-05,
      "loss": 0.0929,
      "step": 26770
    },
    {
      "epoch": 0.5355357357117146,
      "grad_norm": 0.16401050984859467,
      "learning_rate": 4.107807063152422e-05,
      "loss": 0.0619,
      "step": 26780
    },
    {
      "epoch": 0.5357357117145942,
      "grad_norm": 0.11400654166936874,
      "learning_rate": 4.107473769814289e-05,
      "loss": 0.1827,
      "step": 26790
    },
    {
      "epoch": 0.5359356877174739,
      "grad_norm": 0.06518109142780304,
      "learning_rate": 4.1071404764761564e-05,
      "loss": 0.1105,
      "step": 26800
    },
    {
      "epoch": 0.5361356637203536,
      "grad_norm": 0.14569543302059174,
      "learning_rate": 4.1068071831380234e-05,
      "loss": 0.098,
      "step": 26810
    },
    {
      "epoch": 0.5363356397232332,
      "grad_norm": 0.09829763323068619,
      "learning_rate": 4.106473889799891e-05,
      "loss": 0.1022,
      "step": 26820
    },
    {
      "epoch": 0.5365356157261129,
      "grad_norm": 0.06180313974618912,
      "learning_rate": 4.106140596461758e-05,
      "loss": 0.1173,
      "step": 26830
    },
    {
      "epoch": 0.5367355917289925,
      "grad_norm": 0.0803103893995285,
      "learning_rate": 4.1058073031236256e-05,
      "loss": 0.0597,
      "step": 26840
    },
    {
      "epoch": 0.5369355677318721,
      "grad_norm": 0.21809865534305573,
      "learning_rate": 4.1054740097854926e-05,
      "loss": 0.0748,
      "step": 26850
    },
    {
      "epoch": 0.5371355437347518,
      "grad_norm": 0.09109728038311005,
      "learning_rate": 4.1051407164473595e-05,
      "loss": 0.0874,
      "step": 26860
    },
    {
      "epoch": 0.5373355197376315,
      "grad_norm": 0.11068197339773178,
      "learning_rate": 4.104807423109227e-05,
      "loss": 0.0577,
      "step": 26870
    },
    {
      "epoch": 0.5375354957405112,
      "grad_norm": 0.16962549090385437,
      "learning_rate": 4.104474129771094e-05,
      "loss": 0.0593,
      "step": 26880
    },
    {
      "epoch": 0.5377354717433908,
      "grad_norm": 0.05023888871073723,
      "learning_rate": 4.104140836432961e-05,
      "loss": 0.1095,
      "step": 26890
    },
    {
      "epoch": 0.5379354477462704,
      "grad_norm": 0.10968264937400818,
      "learning_rate": 4.103807543094829e-05,
      "loss": 0.0704,
      "step": 26900
    },
    {
      "epoch": 0.5381354237491501,
      "grad_norm": 0.18644824624061584,
      "learning_rate": 4.103474249756696e-05,
      "loss": 0.0764,
      "step": 26910
    },
    {
      "epoch": 0.5383353997520297,
      "grad_norm": 0.10875809192657471,
      "learning_rate": 4.1031409564185633e-05,
      "loss": 0.0571,
      "step": 26920
    },
    {
      "epoch": 0.5385353757549094,
      "grad_norm": 0.21218742430210114,
      "learning_rate": 4.102807663080431e-05,
      "loss": 0.0723,
      "step": 26930
    },
    {
      "epoch": 0.5387353517577891,
      "grad_norm": 0.08307992666959763,
      "learning_rate": 4.102474369742298e-05,
      "loss": 0.0762,
      "step": 26940
    },
    {
      "epoch": 0.5389353277606688,
      "grad_norm": 0.11994610726833344,
      "learning_rate": 4.102141076404165e-05,
      "loss": 0.0943,
      "step": 26950
    },
    {
      "epoch": 0.5391353037635483,
      "grad_norm": 0.13519680500030518,
      "learning_rate": 4.1018077830660325e-05,
      "loss": 0.0616,
      "step": 26960
    },
    {
      "epoch": 0.539335279766428,
      "grad_norm": 0.1862691193819046,
      "learning_rate": 4.1014744897278995e-05,
      "loss": 0.0969,
      "step": 26970
    },
    {
      "epoch": 0.5395352557693077,
      "grad_norm": 0.15533767640590668,
      "learning_rate": 4.1011411963897665e-05,
      "loss": 0.112,
      "step": 26980
    },
    {
      "epoch": 0.5397352317721873,
      "grad_norm": 0.1180841401219368,
      "learning_rate": 4.100807903051634e-05,
      "loss": 0.0869,
      "step": 26990
    },
    {
      "epoch": 0.539935207775067,
      "grad_norm": 0.2163870632648468,
      "learning_rate": 4.100474609713501e-05,
      "loss": 0.1165,
      "step": 27000
    },
    {
      "epoch": 0.5401351837779467,
      "grad_norm": 0.17462700605392456,
      "learning_rate": 4.100141316375368e-05,
      "loss": 0.0809,
      "step": 27010
    },
    {
      "epoch": 0.5403351597808262,
      "grad_norm": 0.1786857545375824,
      "learning_rate": 4.099808023037236e-05,
      "loss": 0.105,
      "step": 27020
    },
    {
      "epoch": 0.5405351357837059,
      "grad_norm": 0.18220007419586182,
      "learning_rate": 4.099474729699103e-05,
      "loss": 0.1258,
      "step": 27030
    },
    {
      "epoch": 0.5407351117865856,
      "grad_norm": 0.14000791311264038,
      "learning_rate": 4.09914143636097e-05,
      "loss": 0.1024,
      "step": 27040
    },
    {
      "epoch": 0.5409350877894653,
      "grad_norm": 0.11911434680223465,
      "learning_rate": 4.098808143022837e-05,
      "loss": 0.058,
      "step": 27050
    },
    {
      "epoch": 0.5411350637923449,
      "grad_norm": 0.20165841281414032,
      "learning_rate": 4.098474849684705e-05,
      "loss": 0.0847,
      "step": 27060
    },
    {
      "epoch": 0.5413350397952246,
      "grad_norm": 0.12666955590248108,
      "learning_rate": 4.098141556346572e-05,
      "loss": 0.1023,
      "step": 27070
    },
    {
      "epoch": 0.5415350157981043,
      "grad_norm": 0.07233293354511261,
      "learning_rate": 4.097808263008439e-05,
      "loss": 0.1091,
      "step": 27080
    },
    {
      "epoch": 0.5417349918009838,
      "grad_norm": 0.07171052694320679,
      "learning_rate": 4.0974749696703064e-05,
      "loss": 0.0674,
      "step": 27090
    },
    {
      "epoch": 0.5419349678038635,
      "grad_norm": 0.07079064846038818,
      "learning_rate": 4.0971416763321734e-05,
      "loss": 0.0739,
      "step": 27100
    },
    {
      "epoch": 0.5421349438067432,
      "grad_norm": 0.09414676576852798,
      "learning_rate": 4.0968083829940404e-05,
      "loss": 0.084,
      "step": 27110
    },
    {
      "epoch": 0.5423349198096229,
      "grad_norm": 0.0781298577785492,
      "learning_rate": 4.096475089655909e-05,
      "loss": 0.0718,
      "step": 27120
    },
    {
      "epoch": 0.5425348958125025,
      "grad_norm": 0.16919393837451935,
      "learning_rate": 4.0961417963177756e-05,
      "loss": 0.104,
      "step": 27130
    },
    {
      "epoch": 0.5427348718153822,
      "grad_norm": 0.08029723912477493,
      "learning_rate": 4.0958085029796426e-05,
      "loss": 0.0767,
      "step": 27140
    },
    {
      "epoch": 0.5429348478182618,
      "grad_norm": 0.06978172063827515,
      "learning_rate": 4.09547520964151e-05,
      "loss": 0.0827,
      "step": 27150
    },
    {
      "epoch": 0.5431348238211414,
      "grad_norm": 0.0656781941652298,
      "learning_rate": 4.095141916303377e-05,
      "loss": 0.0703,
      "step": 27160
    },
    {
      "epoch": 0.5433347998240211,
      "grad_norm": 0.12855862081050873,
      "learning_rate": 4.094808622965244e-05,
      "loss": 0.0746,
      "step": 27170
    },
    {
      "epoch": 0.5435347758269008,
      "grad_norm": 0.14880473911762238,
      "learning_rate": 4.094475329627112e-05,
      "loss": 0.0692,
      "step": 27180
    },
    {
      "epoch": 0.5437347518297804,
      "grad_norm": 0.10537518560886383,
      "learning_rate": 4.094142036288979e-05,
      "loss": 0.0788,
      "step": 27190
    },
    {
      "epoch": 0.5439347278326601,
      "grad_norm": 0.06656230986118317,
      "learning_rate": 4.093808742950846e-05,
      "loss": 0.0617,
      "step": 27200
    },
    {
      "epoch": 0.5441347038355397,
      "grad_norm": 0.06629174202680588,
      "learning_rate": 4.0934754496127134e-05,
      "loss": 0.0584,
      "step": 27210
    },
    {
      "epoch": 0.5443346798384194,
      "grad_norm": 0.11527064442634583,
      "learning_rate": 4.09314215627458e-05,
      "loss": 0.0853,
      "step": 27220
    },
    {
      "epoch": 0.544534655841299,
      "grad_norm": 0.11976291984319687,
      "learning_rate": 4.092808862936448e-05,
      "loss": 0.0756,
      "step": 27230
    },
    {
      "epoch": 0.5447346318441787,
      "grad_norm": 0.10580601543188095,
      "learning_rate": 4.092475569598315e-05,
      "loss": 0.1078,
      "step": 27240
    },
    {
      "epoch": 0.5449346078470584,
      "grad_norm": 0.09286418557167053,
      "learning_rate": 4.0921422762601826e-05,
      "loss": 0.0901,
      "step": 27250
    },
    {
      "epoch": 0.545134583849938,
      "grad_norm": 0.12511278688907623,
      "learning_rate": 4.0918089829220495e-05,
      "loss": 0.0709,
      "step": 27260
    },
    {
      "epoch": 0.5453345598528176,
      "grad_norm": 0.1852731704711914,
      "learning_rate": 4.0914756895839165e-05,
      "loss": 0.0771,
      "step": 27270
    },
    {
      "epoch": 0.5455345358556973,
      "grad_norm": 0.1568754017353058,
      "learning_rate": 4.091142396245784e-05,
      "loss": 0.0747,
      "step": 27280
    },
    {
      "epoch": 0.545734511858577,
      "grad_norm": 0.11380888521671295,
      "learning_rate": 4.090809102907651e-05,
      "loss": 0.0942,
      "step": 27290
    },
    {
      "epoch": 0.5459344878614566,
      "grad_norm": 0.296185165643692,
      "learning_rate": 4.090475809569518e-05,
      "loss": 0.1061,
      "step": 27300
    },
    {
      "epoch": 0.5461344638643363,
      "grad_norm": 0.08291812986135483,
      "learning_rate": 4.090142516231386e-05,
      "loss": 0.0978,
      "step": 27310
    },
    {
      "epoch": 0.546334439867216,
      "grad_norm": 0.20063187181949615,
      "learning_rate": 4.0898092228932527e-05,
      "loss": 0.0672,
      "step": 27320
    },
    {
      "epoch": 0.5465344158700955,
      "grad_norm": 0.13292880356311798,
      "learning_rate": 4.08947592955512e-05,
      "loss": 0.0696,
      "step": 27330
    },
    {
      "epoch": 0.5467343918729752,
      "grad_norm": 0.07900387793779373,
      "learning_rate": 4.089142636216988e-05,
      "loss": 0.0756,
      "step": 27340
    },
    {
      "epoch": 0.5469343678758549,
      "grad_norm": 0.11950918287038803,
      "learning_rate": 4.088809342878855e-05,
      "loss": 0.0899,
      "step": 27350
    },
    {
      "epoch": 0.5471343438787345,
      "grad_norm": 0.11382424086332321,
      "learning_rate": 4.088476049540722e-05,
      "loss": 0.0743,
      "step": 27360
    },
    {
      "epoch": 0.5473343198816142,
      "grad_norm": 0.11314403265714645,
      "learning_rate": 4.0881427562025895e-05,
      "loss": 0.089,
      "step": 27370
    },
    {
      "epoch": 0.5475342958844939,
      "grad_norm": 0.08088487386703491,
      "learning_rate": 4.0878094628644565e-05,
      "loss": 0.0631,
      "step": 27380
    },
    {
      "epoch": 0.5477342718873736,
      "grad_norm": 0.12168166786432266,
      "learning_rate": 4.0874761695263234e-05,
      "loss": 0.1028,
      "step": 27390
    },
    {
      "epoch": 0.5479342478902531,
      "grad_norm": 0.15887317061424255,
      "learning_rate": 4.087142876188191e-05,
      "loss": 0.1467,
      "step": 27400
    },
    {
      "epoch": 0.5481342238931328,
      "grad_norm": 0.07460591197013855,
      "learning_rate": 4.086809582850058e-05,
      "loss": 0.0499,
      "step": 27410
    },
    {
      "epoch": 0.5483341998960125,
      "grad_norm": 0.10004886984825134,
      "learning_rate": 4.086476289511925e-05,
      "loss": 0.052,
      "step": 27420
    },
    {
      "epoch": 0.5485341758988921,
      "grad_norm": 0.05387982726097107,
      "learning_rate": 4.0861429961737926e-05,
      "loss": 0.2174,
      "step": 27430
    },
    {
      "epoch": 0.5487341519017718,
      "grad_norm": 0.12174542248249054,
      "learning_rate": 4.08580970283566e-05,
      "loss": 0.1008,
      "step": 27440
    },
    {
      "epoch": 0.5489341279046515,
      "grad_norm": 0.09793057292699814,
      "learning_rate": 4.085476409497527e-05,
      "loss": 0.0665,
      "step": 27450
    },
    {
      "epoch": 0.5491341039075311,
      "grad_norm": 0.11111614108085632,
      "learning_rate": 4.085143116159394e-05,
      "loss": 0.1054,
      "step": 27460
    },
    {
      "epoch": 0.5493340799104107,
      "grad_norm": 0.2063402533531189,
      "learning_rate": 4.084809822821262e-05,
      "loss": 0.0923,
      "step": 27470
    },
    {
      "epoch": 0.5495340559132904,
      "grad_norm": 0.0994703471660614,
      "learning_rate": 4.084476529483129e-05,
      "loss": 0.0837,
      "step": 27480
    },
    {
      "epoch": 0.5497340319161701,
      "grad_norm": 0.1048237681388855,
      "learning_rate": 4.084143236144996e-05,
      "loss": 0.0613,
      "step": 27490
    },
    {
      "epoch": 0.5499340079190497,
      "grad_norm": 0.17598457634449005,
      "learning_rate": 4.0838099428068634e-05,
      "loss": 0.1133,
      "step": 27500
    },
    {
      "epoch": 0.5501339839219294,
      "grad_norm": 0.20231765508651733,
      "learning_rate": 4.0834766494687303e-05,
      "loss": 0.076,
      "step": 27510
    },
    {
      "epoch": 0.550333959924809,
      "grad_norm": 0.09940052777528763,
      "learning_rate": 4.083143356130597e-05,
      "loss": 0.1004,
      "step": 27520
    },
    {
      "epoch": 0.5505339359276886,
      "grad_norm": 0.16220933198928833,
      "learning_rate": 4.0828100627924656e-05,
      "loss": 0.0738,
      "step": 27530
    },
    {
      "epoch": 0.5507339119305683,
      "grad_norm": 0.1630190908908844,
      "learning_rate": 4.0824767694543326e-05,
      "loss": 0.0553,
      "step": 27540
    },
    {
      "epoch": 0.550933887933448,
      "grad_norm": 0.11809759587049484,
      "learning_rate": 4.0821434761161995e-05,
      "loss": 0.0768,
      "step": 27550
    },
    {
      "epoch": 0.5511338639363277,
      "grad_norm": 0.09166624397039413,
      "learning_rate": 4.081810182778067e-05,
      "loss": 0.0764,
      "step": 27560
    },
    {
      "epoch": 0.5513338399392073,
      "grad_norm": 0.12421643733978271,
      "learning_rate": 4.081476889439934e-05,
      "loss": 0.1305,
      "step": 27570
    },
    {
      "epoch": 0.551533815942087,
      "grad_norm": 0.12879271805286407,
      "learning_rate": 4.081143596101801e-05,
      "loss": 0.0639,
      "step": 27580
    },
    {
      "epoch": 0.5517337919449666,
      "grad_norm": 0.12037547677755356,
      "learning_rate": 4.080810302763669e-05,
      "loss": 0.0628,
      "step": 27590
    },
    {
      "epoch": 0.5519337679478462,
      "grad_norm": 0.10167908668518066,
      "learning_rate": 4.080477009425536e-05,
      "loss": 0.0495,
      "step": 27600
    },
    {
      "epoch": 0.5521337439507259,
      "grad_norm": 0.1440739631652832,
      "learning_rate": 4.080143716087403e-05,
      "loss": 0.0428,
      "step": 27610
    },
    {
      "epoch": 0.5523337199536056,
      "grad_norm": 0.10036496073007584,
      "learning_rate": 4.07981042274927e-05,
      "loss": 0.0772,
      "step": 27620
    },
    {
      "epoch": 0.5525336959564853,
      "grad_norm": 0.10570994764566422,
      "learning_rate": 4.079477129411138e-05,
      "loss": 0.0968,
      "step": 27630
    },
    {
      "epoch": 0.5527336719593648,
      "grad_norm": 0.07476140558719635,
      "learning_rate": 4.079143836073005e-05,
      "loss": 0.0749,
      "step": 27640
    },
    {
      "epoch": 0.5529336479622445,
      "grad_norm": 0.18387693166732788,
      "learning_rate": 4.078810542734872e-05,
      "loss": 0.1135,
      "step": 27650
    },
    {
      "epoch": 0.5531336239651242,
      "grad_norm": 0.08177394419908524,
      "learning_rate": 4.0784772493967395e-05,
      "loss": 0.0562,
      "step": 27660
    },
    {
      "epoch": 0.5533335999680038,
      "grad_norm": 0.07861088216304779,
      "learning_rate": 4.0781439560586065e-05,
      "loss": 0.1014,
      "step": 27670
    },
    {
      "epoch": 0.5535335759708835,
      "grad_norm": 0.06665852665901184,
      "learning_rate": 4.0778106627204734e-05,
      "loss": 0.0554,
      "step": 27680
    },
    {
      "epoch": 0.5537335519737632,
      "grad_norm": 0.1387966424226761,
      "learning_rate": 4.077477369382341e-05,
      "loss": 0.0632,
      "step": 27690
    },
    {
      "epoch": 0.5539335279766427,
      "grad_norm": 0.13380549848079681,
      "learning_rate": 4.077144076044208e-05,
      "loss": 0.0691,
      "step": 27700
    },
    {
      "epoch": 0.5541335039795224,
      "grad_norm": 0.07552611827850342,
      "learning_rate": 4.076810782706075e-05,
      "loss": 0.1247,
      "step": 27710
    },
    {
      "epoch": 0.5543334799824021,
      "grad_norm": 0.11960989981889725,
      "learning_rate": 4.0764774893679426e-05,
      "loss": 0.0865,
      "step": 27720
    },
    {
      "epoch": 0.5545334559852818,
      "grad_norm": 0.12883436679840088,
      "learning_rate": 4.0761441960298096e-05,
      "loss": 0.1042,
      "step": 27730
    },
    {
      "epoch": 0.5547334319881614,
      "grad_norm": 0.15753720700740814,
      "learning_rate": 4.075810902691677e-05,
      "loss": 0.0816,
      "step": 27740
    },
    {
      "epoch": 0.5549334079910411,
      "grad_norm": 0.1765470802783966,
      "learning_rate": 4.075477609353545e-05,
      "loss": 0.0626,
      "step": 27750
    },
    {
      "epoch": 0.5551333839939208,
      "grad_norm": 0.12271988391876221,
      "learning_rate": 4.075144316015412e-05,
      "loss": 0.069,
      "step": 27760
    },
    {
      "epoch": 0.5553333599968003,
      "grad_norm": 0.1410616636276245,
      "learning_rate": 4.074811022677279e-05,
      "loss": 0.0821,
      "step": 27770
    },
    {
      "epoch": 0.55553333599968,
      "grad_norm": 0.1707715094089508,
      "learning_rate": 4.0744777293391464e-05,
      "loss": 0.1747,
      "step": 27780
    },
    {
      "epoch": 0.5557333120025597,
      "grad_norm": 0.16431234776973724,
      "learning_rate": 4.0741444360010134e-05,
      "loss": 0.0583,
      "step": 27790
    },
    {
      "epoch": 0.5559332880054394,
      "grad_norm": 0.14620336890220642,
      "learning_rate": 4.0738111426628804e-05,
      "loss": 0.0805,
      "step": 27800
    },
    {
      "epoch": 0.556133264008319,
      "grad_norm": 0.154121994972229,
      "learning_rate": 4.073477849324748e-05,
      "loss": 0.0865,
      "step": 27810
    },
    {
      "epoch": 0.5563332400111987,
      "grad_norm": 0.09525663405656815,
      "learning_rate": 4.073144555986615e-05,
      "loss": 0.0828,
      "step": 27820
    },
    {
      "epoch": 0.5565332160140783,
      "grad_norm": 0.06801880151033401,
      "learning_rate": 4.072811262648482e-05,
      "loss": 0.0829,
      "step": 27830
    },
    {
      "epoch": 0.5567331920169579,
      "grad_norm": 0.19069409370422363,
      "learning_rate": 4.0724779693103496e-05,
      "loss": 0.0807,
      "step": 27840
    },
    {
      "epoch": 0.5569331680198376,
      "grad_norm": 0.13113078474998474,
      "learning_rate": 4.072144675972217e-05,
      "loss": 0.1007,
      "step": 27850
    },
    {
      "epoch": 0.5571331440227173,
      "grad_norm": 0.13193821907043457,
      "learning_rate": 4.071811382634084e-05,
      "loss": 0.0543,
      "step": 27860
    },
    {
      "epoch": 0.5573331200255969,
      "grad_norm": 0.14772889018058777,
      "learning_rate": 4.071478089295951e-05,
      "loss": 0.0898,
      "step": 27870
    },
    {
      "epoch": 0.5575330960284766,
      "grad_norm": 0.12047849595546722,
      "learning_rate": 4.071144795957819e-05,
      "loss": 0.0824,
      "step": 27880
    },
    {
      "epoch": 0.5577330720313562,
      "grad_norm": 0.07378434389829636,
      "learning_rate": 4.070811502619686e-05,
      "loss": 0.0741,
      "step": 27890
    },
    {
      "epoch": 0.5579330480342359,
      "grad_norm": 0.1026536300778389,
      "learning_rate": 4.070478209281553e-05,
      "loss": 0.0893,
      "step": 27900
    },
    {
      "epoch": 0.5581330240371155,
      "grad_norm": 0.11487620323896408,
      "learning_rate": 4.07014491594342e-05,
      "loss": 0.1105,
      "step": 27910
    },
    {
      "epoch": 0.5583330000399952,
      "grad_norm": 0.09875496476888657,
      "learning_rate": 4.069811622605287e-05,
      "loss": 0.0588,
      "step": 27920
    },
    {
      "epoch": 0.5585329760428749,
      "grad_norm": 0.07931046187877655,
      "learning_rate": 4.069478329267154e-05,
      "loss": 0.0496,
      "step": 27930
    },
    {
      "epoch": 0.5587329520457545,
      "grad_norm": 0.1066548153758049,
      "learning_rate": 4.0691450359290226e-05,
      "loss": 0.0853,
      "step": 27940
    },
    {
      "epoch": 0.5589329280486341,
      "grad_norm": 0.1752071976661682,
      "learning_rate": 4.0688117425908895e-05,
      "loss": 0.0862,
      "step": 27950
    },
    {
      "epoch": 0.5591329040515138,
      "grad_norm": 0.14524438977241516,
      "learning_rate": 4.0684784492527565e-05,
      "loss": 0.0932,
      "step": 27960
    },
    {
      "epoch": 0.5593328800543935,
      "grad_norm": 0.1540733128786087,
      "learning_rate": 4.068145155914624e-05,
      "loss": 0.1379,
      "step": 27970
    },
    {
      "epoch": 0.5595328560572731,
      "grad_norm": 0.08476236462593079,
      "learning_rate": 4.067811862576491e-05,
      "loss": 0.0619,
      "step": 27980
    },
    {
      "epoch": 0.5597328320601528,
      "grad_norm": 0.11259261518716812,
      "learning_rate": 4.067478569238358e-05,
      "loss": 0.1304,
      "step": 27990
    },
    {
      "epoch": 0.5599328080630325,
      "grad_norm": 0.18078148365020752,
      "learning_rate": 4.067145275900226e-05,
      "loss": 0.1177,
      "step": 28000
    },
    {
      "epoch": 0.560132784065912,
      "grad_norm": 0.30253738164901733,
      "learning_rate": 4.0668119825620927e-05,
      "loss": 0.2736,
      "step": 28010
    },
    {
      "epoch": 0.5603327600687917,
      "grad_norm": 0.1661648154258728,
      "learning_rate": 4.0664786892239596e-05,
      "loss": 0.09,
      "step": 28020
    },
    {
      "epoch": 0.5605327360716714,
      "grad_norm": 0.09993140399456024,
      "learning_rate": 4.066145395885827e-05,
      "loss": 0.0831,
      "step": 28030
    },
    {
      "epoch": 0.560732712074551,
      "grad_norm": 0.16095738112926483,
      "learning_rate": 4.065812102547695e-05,
      "loss": 0.092,
      "step": 28040
    },
    {
      "epoch": 0.5609326880774307,
      "grad_norm": 0.096356600522995,
      "learning_rate": 4.065478809209562e-05,
      "loss": 0.1219,
      "step": 28050
    },
    {
      "epoch": 0.5611326640803104,
      "grad_norm": 0.21830637753009796,
      "learning_rate": 4.065145515871429e-05,
      "loss": 0.0735,
      "step": 28060
    },
    {
      "epoch": 0.5613326400831901,
      "grad_norm": 0.08647976070642471,
      "learning_rate": 4.0648122225332965e-05,
      "loss": 0.0559,
      "step": 28070
    },
    {
      "epoch": 0.5615326160860696,
      "grad_norm": 0.12369844317436218,
      "learning_rate": 4.0644789291951634e-05,
      "loss": 0.0875,
      "step": 28080
    },
    {
      "epoch": 0.5617325920889493,
      "grad_norm": 0.18121372163295746,
      "learning_rate": 4.0641456358570304e-05,
      "loss": 0.1044,
      "step": 28090
    },
    {
      "epoch": 0.561932568091829,
      "grad_norm": 0.1294689029455185,
      "learning_rate": 4.063812342518898e-05,
      "loss": 0.0939,
      "step": 28100
    },
    {
      "epoch": 0.5621325440947086,
      "grad_norm": 0.1256919801235199,
      "learning_rate": 4.063479049180765e-05,
      "loss": 0.0851,
      "step": 28110
    },
    {
      "epoch": 0.5623325200975883,
      "grad_norm": 0.11328737437725067,
      "learning_rate": 4.063145755842632e-05,
      "loss": 0.0577,
      "step": 28120
    },
    {
      "epoch": 0.562532496100468,
      "grad_norm": 0.07052257657051086,
      "learning_rate": 4.0628124625044996e-05,
      "loss": 0.07,
      "step": 28130
    },
    {
      "epoch": 0.5627324721033476,
      "grad_norm": 0.12852101027965546,
      "learning_rate": 4.062479169166367e-05,
      "loss": 0.082,
      "step": 28140
    },
    {
      "epoch": 0.5629324481062272,
      "grad_norm": 0.0942692831158638,
      "learning_rate": 4.062145875828234e-05,
      "loss": 0.0701,
      "step": 28150
    },
    {
      "epoch": 0.5631324241091069,
      "grad_norm": 0.11781509220600128,
      "learning_rate": 4.061812582490102e-05,
      "loss": 0.0967,
      "step": 28160
    },
    {
      "epoch": 0.5633324001119866,
      "grad_norm": 0.1360684186220169,
      "learning_rate": 4.061479289151969e-05,
      "loss": 0.0517,
      "step": 28170
    },
    {
      "epoch": 0.5635323761148662,
      "grad_norm": 0.19226953387260437,
      "learning_rate": 4.061145995813836e-05,
      "loss": 0.0749,
      "step": 28180
    },
    {
      "epoch": 0.5637323521177459,
      "grad_norm": 0.06779365241527557,
      "learning_rate": 4.0608127024757034e-05,
      "loss": 0.0634,
      "step": 28190
    },
    {
      "epoch": 0.5639323281206255,
      "grad_norm": 0.12844078242778778,
      "learning_rate": 4.0604794091375703e-05,
      "loss": 0.0823,
      "step": 28200
    },
    {
      "epoch": 0.5641323041235051,
      "grad_norm": 0.13297368586063385,
      "learning_rate": 4.060146115799437e-05,
      "loss": 0.0487,
      "step": 28210
    },
    {
      "epoch": 0.5643322801263848,
      "grad_norm": 0.21606886386871338,
      "learning_rate": 4.059812822461305e-05,
      "loss": 0.1145,
      "step": 28220
    },
    {
      "epoch": 0.5645322561292645,
      "grad_norm": 0.1759548783302307,
      "learning_rate": 4.059479529123172e-05,
      "loss": 0.0752,
      "step": 28230
    },
    {
      "epoch": 0.5647322321321442,
      "grad_norm": 0.05509456992149353,
      "learning_rate": 4.059146235785039e-05,
      "loss": 0.1143,
      "step": 28240
    },
    {
      "epoch": 0.5649322081350238,
      "grad_norm": 0.09677528589963913,
      "learning_rate": 4.0588129424469065e-05,
      "loss": 0.0676,
      "step": 28250
    },
    {
      "epoch": 0.5651321841379034,
      "grad_norm": 0.05188782885670662,
      "learning_rate": 4.058479649108774e-05,
      "loss": 0.1258,
      "step": 28260
    },
    {
      "epoch": 0.5653321601407831,
      "grad_norm": 0.061336152255535126,
      "learning_rate": 4.058146355770641e-05,
      "loss": 0.0764,
      "step": 28270
    },
    {
      "epoch": 0.5655321361436627,
      "grad_norm": 0.1145152747631073,
      "learning_rate": 4.057813062432508e-05,
      "loss": 0.0672,
      "step": 28280
    },
    {
      "epoch": 0.5657321121465424,
      "grad_norm": 0.11441771686077118,
      "learning_rate": 4.057479769094376e-05,
      "loss": 0.0717,
      "step": 28290
    },
    {
      "epoch": 0.5659320881494221,
      "grad_norm": 0.10266551375389099,
      "learning_rate": 4.057146475756243e-05,
      "loss": 0.0899,
      "step": 28300
    },
    {
      "epoch": 0.5661320641523018,
      "grad_norm": 0.12808440625667572,
      "learning_rate": 4.0568131824181096e-05,
      "loss": 0.0692,
      "step": 28310
    },
    {
      "epoch": 0.5663320401551813,
      "grad_norm": 0.06838856637477875,
      "learning_rate": 4.056479889079977e-05,
      "loss": 0.09,
      "step": 28320
    },
    {
      "epoch": 0.566532016158061,
      "grad_norm": 0.049675896763801575,
      "learning_rate": 4.056146595741844e-05,
      "loss": 0.0678,
      "step": 28330
    },
    {
      "epoch": 0.5667319921609407,
      "grad_norm": 0.11937066167593002,
      "learning_rate": 4.055813302403711e-05,
      "loss": 0.0698,
      "step": 28340
    },
    {
      "epoch": 0.5669319681638203,
      "grad_norm": 0.18442216515541077,
      "learning_rate": 4.0554800090655795e-05,
      "loss": 0.0765,
      "step": 28350
    },
    {
      "epoch": 0.5671319441667,
      "grad_norm": 0.14118251204490662,
      "learning_rate": 4.0551467157274465e-05,
      "loss": 0.0922,
      "step": 28360
    },
    {
      "epoch": 0.5673319201695797,
      "grad_norm": 0.09774421155452728,
      "learning_rate": 4.0548134223893134e-05,
      "loss": 0.0605,
      "step": 28370
    },
    {
      "epoch": 0.5675318961724594,
      "grad_norm": 0.07924723625183105,
      "learning_rate": 4.054480129051181e-05,
      "loss": 0.0688,
      "step": 28380
    },
    {
      "epoch": 0.5677318721753389,
      "grad_norm": 0.08964560180902481,
      "learning_rate": 4.054146835713048e-05,
      "loss": 0.0775,
      "step": 28390
    },
    {
      "epoch": 0.5679318481782186,
      "grad_norm": 0.11234554648399353,
      "learning_rate": 4.053813542374915e-05,
      "loss": 0.0719,
      "step": 28400
    },
    {
      "epoch": 0.5681318241810983,
      "grad_norm": 0.09259944409132004,
      "learning_rate": 4.0534802490367826e-05,
      "loss": 0.104,
      "step": 28410
    },
    {
      "epoch": 0.5683318001839779,
      "grad_norm": 0.22822970151901245,
      "learning_rate": 4.0531469556986496e-05,
      "loss": 0.0846,
      "step": 28420
    },
    {
      "epoch": 0.5685317761868576,
      "grad_norm": 0.13765737414360046,
      "learning_rate": 4.0528136623605166e-05,
      "loss": 0.1103,
      "step": 28430
    },
    {
      "epoch": 0.5687317521897373,
      "grad_norm": 0.0925033837556839,
      "learning_rate": 4.052480369022384e-05,
      "loss": 0.064,
      "step": 28440
    },
    {
      "epoch": 0.5689317281926168,
      "grad_norm": 0.11685119569301605,
      "learning_rate": 4.052147075684252e-05,
      "loss": 0.0841,
      "step": 28450
    },
    {
      "epoch": 0.5691317041954965,
      "grad_norm": 0.08846849203109741,
      "learning_rate": 4.051813782346119e-05,
      "loss": 0.0637,
      "step": 28460
    },
    {
      "epoch": 0.5693316801983762,
      "grad_norm": 0.1480197012424469,
      "learning_rate": 4.051480489007986e-05,
      "loss": 0.0944,
      "step": 28470
    },
    {
      "epoch": 0.5695316562012559,
      "grad_norm": 0.11346497386693954,
      "learning_rate": 4.0511471956698534e-05,
      "loss": 0.0754,
      "step": 28480
    },
    {
      "epoch": 0.5697316322041355,
      "grad_norm": 0.20534560084342957,
      "learning_rate": 4.0508139023317204e-05,
      "loss": 0.0577,
      "step": 28490
    },
    {
      "epoch": 0.5699316082070152,
      "grad_norm": 0.16740915179252625,
      "learning_rate": 4.050480608993587e-05,
      "loss": 0.1077,
      "step": 28500
    },
    {
      "epoch": 0.5701315842098948,
      "grad_norm": 0.05744354799389839,
      "learning_rate": 4.050147315655455e-05,
      "loss": 0.0643,
      "step": 28510
    },
    {
      "epoch": 0.5703315602127744,
      "grad_norm": 0.11563721299171448,
      "learning_rate": 4.049814022317322e-05,
      "loss": 0.0692,
      "step": 28520
    },
    {
      "epoch": 0.5705315362156541,
      "grad_norm": 0.10809232294559479,
      "learning_rate": 4.049480728979189e-05,
      "loss": 0.0837,
      "step": 28530
    },
    {
      "epoch": 0.5707315122185338,
      "grad_norm": 0.11169009655714035,
      "learning_rate": 4.0491474356410565e-05,
      "loss": 0.0602,
      "step": 28540
    },
    {
      "epoch": 0.5709314882214135,
      "grad_norm": 0.11259185522794724,
      "learning_rate": 4.048814142302924e-05,
      "loss": 0.0694,
      "step": 28550
    },
    {
      "epoch": 0.5711314642242931,
      "grad_norm": 0.07291460037231445,
      "learning_rate": 4.048480848964791e-05,
      "loss": 0.0775,
      "step": 28560
    },
    {
      "epoch": 0.5713314402271727,
      "grad_norm": 0.2052905410528183,
      "learning_rate": 4.048147555626659e-05,
      "loss": 0.083,
      "step": 28570
    },
    {
      "epoch": 0.5715314162300524,
      "grad_norm": 0.06319432705640793,
      "learning_rate": 4.047814262288526e-05,
      "loss": 0.1013,
      "step": 28580
    },
    {
      "epoch": 0.571731392232932,
      "grad_norm": 0.11809320002794266,
      "learning_rate": 4.047480968950393e-05,
      "loss": 0.0725,
      "step": 28590
    },
    {
      "epoch": 0.5719313682358117,
      "grad_norm": 0.1826222538948059,
      "learning_rate": 4.04714767561226e-05,
      "loss": 0.0836,
      "step": 28600
    },
    {
      "epoch": 0.5721313442386914,
      "grad_norm": 0.09573445469141006,
      "learning_rate": 4.046814382274127e-05,
      "loss": 0.0903,
      "step": 28610
    },
    {
      "epoch": 0.572331320241571,
      "grad_norm": 0.1467900425195694,
      "learning_rate": 4.046481088935994e-05,
      "loss": 0.0996,
      "step": 28620
    },
    {
      "epoch": 0.5725312962444506,
      "grad_norm": 0.07087395340204239,
      "learning_rate": 4.046147795597862e-05,
      "loss": 0.0964,
      "step": 28630
    },
    {
      "epoch": 0.5727312722473303,
      "grad_norm": 0.17370209097862244,
      "learning_rate": 4.045814502259729e-05,
      "loss": 0.0957,
      "step": 28640
    },
    {
      "epoch": 0.57293124825021,
      "grad_norm": 0.08270134031772614,
      "learning_rate": 4.0454812089215965e-05,
      "loss": 0.0917,
      "step": 28650
    },
    {
      "epoch": 0.5731312242530896,
      "grad_norm": 0.19618737697601318,
      "learning_rate": 4.0451479155834635e-05,
      "loss": 0.1032,
      "step": 28660
    },
    {
      "epoch": 0.5733312002559693,
      "grad_norm": 0.06933530420064926,
      "learning_rate": 4.044814622245331e-05,
      "loss": 0.1238,
      "step": 28670
    },
    {
      "epoch": 0.573531176258849,
      "grad_norm": 0.13825064897537231,
      "learning_rate": 4.044481328907198e-05,
      "loss": 0.0874,
      "step": 28680
    },
    {
      "epoch": 0.5737311522617285,
      "grad_norm": 0.19592049717903137,
      "learning_rate": 4.044148035569065e-05,
      "loss": 0.0724,
      "step": 28690
    },
    {
      "epoch": 0.5739311282646082,
      "grad_norm": 0.17116478085517883,
      "learning_rate": 4.0438147422309327e-05,
      "loss": 0.0808,
      "step": 28700
    },
    {
      "epoch": 0.5741311042674879,
      "grad_norm": 0.0740962103009224,
      "learning_rate": 4.0434814488927996e-05,
      "loss": 0.0648,
      "step": 28710
    },
    {
      "epoch": 0.5743310802703676,
      "grad_norm": 0.205074280500412,
      "learning_rate": 4.0431481555546666e-05,
      "loss": 0.1103,
      "step": 28720
    },
    {
      "epoch": 0.5745310562732472,
      "grad_norm": 0.10872714966535568,
      "learning_rate": 4.042814862216534e-05,
      "loss": 0.0613,
      "step": 28730
    },
    {
      "epoch": 0.5747310322761269,
      "grad_norm": 0.14535097777843475,
      "learning_rate": 4.042481568878401e-05,
      "loss": 0.1034,
      "step": 28740
    },
    {
      "epoch": 0.5749310082790066,
      "grad_norm": 0.04486938565969467,
      "learning_rate": 4.042148275540268e-05,
      "loss": 0.046,
      "step": 28750
    },
    {
      "epoch": 0.5751309842818861,
      "grad_norm": 0.08377150446176529,
      "learning_rate": 4.0418149822021365e-05,
      "loss": 0.0977,
      "step": 28760
    },
    {
      "epoch": 0.5753309602847658,
      "grad_norm": 0.17651093006134033,
      "learning_rate": 4.0414816888640034e-05,
      "loss": 0.0861,
      "step": 28770
    },
    {
      "epoch": 0.5755309362876455,
      "grad_norm": 0.09685376286506653,
      "learning_rate": 4.0411483955258704e-05,
      "loss": 0.0392,
      "step": 28780
    },
    {
      "epoch": 0.5757309122905251,
      "grad_norm": 0.10235293954610825,
      "learning_rate": 4.040815102187738e-05,
      "loss": 0.1529,
      "step": 28790
    },
    {
      "epoch": 0.5759308882934048,
      "grad_norm": 0.08063477277755737,
      "learning_rate": 4.040481808849605e-05,
      "loss": 0.0717,
      "step": 28800
    },
    {
      "epoch": 0.5761308642962845,
      "grad_norm": 0.07253048568964005,
      "learning_rate": 4.040148515511472e-05,
      "loss": 0.0496,
      "step": 28810
    },
    {
      "epoch": 0.5763308402991641,
      "grad_norm": 0.12552393972873688,
      "learning_rate": 4.0398152221733396e-05,
      "loss": 0.0503,
      "step": 28820
    },
    {
      "epoch": 0.5765308163020437,
      "grad_norm": 0.10486247390508652,
      "learning_rate": 4.0394819288352065e-05,
      "loss": 0.0694,
      "step": 28830
    },
    {
      "epoch": 0.5767307923049234,
      "grad_norm": 0.0801415741443634,
      "learning_rate": 4.0391486354970735e-05,
      "loss": 0.0679,
      "step": 28840
    },
    {
      "epoch": 0.5769307683078031,
      "grad_norm": 0.14146766066551208,
      "learning_rate": 4.038815342158941e-05,
      "loss": 0.0978,
      "step": 28850
    },
    {
      "epoch": 0.5771307443106827,
      "grad_norm": 0.16586945950984955,
      "learning_rate": 4.038482048820809e-05,
      "loss": 0.0768,
      "step": 28860
    },
    {
      "epoch": 0.5773307203135624,
      "grad_norm": 0.09634765982627869,
      "learning_rate": 4.038148755482676e-05,
      "loss": 0.065,
      "step": 28870
    },
    {
      "epoch": 0.577530696316442,
      "grad_norm": 0.14940208196640015,
      "learning_rate": 4.037815462144543e-05,
      "loss": 0.1071,
      "step": 28880
    },
    {
      "epoch": 0.5777306723193217,
      "grad_norm": 0.12440131604671478,
      "learning_rate": 4.0374821688064103e-05,
      "loss": 0.0539,
      "step": 28890
    },
    {
      "epoch": 0.5779306483222013,
      "grad_norm": 0.05968600884079933,
      "learning_rate": 4.037148875468277e-05,
      "loss": 0.0863,
      "step": 28900
    },
    {
      "epoch": 0.578130624325081,
      "grad_norm": 0.07088721543550491,
      "learning_rate": 4.036815582130144e-05,
      "loss": 0.072,
      "step": 28910
    },
    {
      "epoch": 0.5783306003279607,
      "grad_norm": 0.19864457845687866,
      "learning_rate": 4.036482288792012e-05,
      "loss": 0.0903,
      "step": 28920
    },
    {
      "epoch": 0.5785305763308403,
      "grad_norm": 0.1950225681066513,
      "learning_rate": 4.036148995453879e-05,
      "loss": 0.1004,
      "step": 28930
    },
    {
      "epoch": 0.57873055233372,
      "grad_norm": 0.0592522956430912,
      "learning_rate": 4.035815702115746e-05,
      "loss": 0.0773,
      "step": 28940
    },
    {
      "epoch": 0.5789305283365996,
      "grad_norm": 0.10967081040143967,
      "learning_rate": 4.0354824087776135e-05,
      "loss": 0.0684,
      "step": 28950
    },
    {
      "epoch": 0.5791305043394792,
      "grad_norm": 0.1273900419473648,
      "learning_rate": 4.035149115439481e-05,
      "loss": 0.1054,
      "step": 28960
    },
    {
      "epoch": 0.5793304803423589,
      "grad_norm": 0.14618045091629028,
      "learning_rate": 4.034815822101348e-05,
      "loss": 0.0861,
      "step": 28970
    },
    {
      "epoch": 0.5795304563452386,
      "grad_norm": 0.17534464597702026,
      "learning_rate": 4.034482528763216e-05,
      "loss": 0.086,
      "step": 28980
    },
    {
      "epoch": 0.5797304323481183,
      "grad_norm": 0.1164848655462265,
      "learning_rate": 4.034149235425083e-05,
      "loss": 0.0552,
      "step": 28990
    },
    {
      "epoch": 0.5799304083509979,
      "grad_norm": 0.17686103284358978,
      "learning_rate": 4.0338159420869496e-05,
      "loss": 0.0793,
      "step": 29000
    },
    {
      "epoch": 0.5801303843538775,
      "grad_norm": 0.08265330642461777,
      "learning_rate": 4.033482648748817e-05,
      "loss": 0.0803,
      "step": 29010
    },
    {
      "epoch": 0.5803303603567572,
      "grad_norm": 0.13301502168178558,
      "learning_rate": 4.033149355410684e-05,
      "loss": 0.0694,
      "step": 29020
    },
    {
      "epoch": 0.5805303363596368,
      "grad_norm": 0.12546151876449585,
      "learning_rate": 4.032816062072551e-05,
      "loss": 0.0644,
      "step": 29030
    },
    {
      "epoch": 0.5807303123625165,
      "grad_norm": 0.1119537353515625,
      "learning_rate": 4.032482768734419e-05,
      "loss": 0.079,
      "step": 29040
    },
    {
      "epoch": 0.5809302883653962,
      "grad_norm": 0.14394326508045197,
      "learning_rate": 4.032149475396286e-05,
      "loss": 0.0667,
      "step": 29050
    },
    {
      "epoch": 0.5811302643682759,
      "grad_norm": 0.1606961190700531,
      "learning_rate": 4.0318161820581534e-05,
      "loss": 0.0468,
      "step": 29060
    },
    {
      "epoch": 0.5813302403711554,
      "grad_norm": 0.07446974515914917,
      "learning_rate": 4.0314828887200204e-05,
      "loss": 0.0758,
      "step": 29070
    },
    {
      "epoch": 0.5815302163740351,
      "grad_norm": 0.06383838504552841,
      "learning_rate": 4.031149595381888e-05,
      "loss": 0.0954,
      "step": 29080
    },
    {
      "epoch": 0.5817301923769148,
      "grad_norm": 0.09205843508243561,
      "learning_rate": 4.030816302043755e-05,
      "loss": 0.081,
      "step": 29090
    },
    {
      "epoch": 0.5819301683797944,
      "grad_norm": 0.09797827899456024,
      "learning_rate": 4.030483008705622e-05,
      "loss": 0.0547,
      "step": 29100
    },
    {
      "epoch": 0.5821301443826741,
      "grad_norm": 0.06155597046017647,
      "learning_rate": 4.0301497153674896e-05,
      "loss": 0.0897,
      "step": 29110
    },
    {
      "epoch": 0.5823301203855538,
      "grad_norm": 0.0934007316827774,
      "learning_rate": 4.0298164220293566e-05,
      "loss": 0.1047,
      "step": 29120
    },
    {
      "epoch": 0.5825300963884333,
      "grad_norm": 0.0828523114323616,
      "learning_rate": 4.0294831286912235e-05,
      "loss": 0.062,
      "step": 29130
    },
    {
      "epoch": 0.582730072391313,
      "grad_norm": 0.13729900121688843,
      "learning_rate": 4.029149835353091e-05,
      "loss": 0.1164,
      "step": 29140
    },
    {
      "epoch": 0.5829300483941927,
      "grad_norm": 0.10134963691234589,
      "learning_rate": 4.028816542014958e-05,
      "loss": 0.0967,
      "step": 29150
    },
    {
      "epoch": 0.5831300243970724,
      "grad_norm": 0.17040778696537018,
      "learning_rate": 4.028483248676826e-05,
      "loss": 0.0961,
      "step": 29160
    },
    {
      "epoch": 0.583330000399952,
      "grad_norm": 0.16962429881095886,
      "learning_rate": 4.0281499553386934e-05,
      "loss": 0.0841,
      "step": 29170
    },
    {
      "epoch": 0.5835299764028317,
      "grad_norm": 0.1103740781545639,
      "learning_rate": 4.0278166620005604e-05,
      "loss": 0.1048,
      "step": 29180
    },
    {
      "epoch": 0.5837299524057113,
      "grad_norm": 0.05148836970329285,
      "learning_rate": 4.027483368662427e-05,
      "loss": 0.0664,
      "step": 29190
    },
    {
      "epoch": 0.5839299284085909,
      "grad_norm": 0.18594804406166077,
      "learning_rate": 4.027150075324295e-05,
      "loss": 0.0601,
      "step": 29200
    },
    {
      "epoch": 0.5841299044114706,
      "grad_norm": 0.0782521441578865,
      "learning_rate": 4.026816781986162e-05,
      "loss": 0.14,
      "step": 29210
    },
    {
      "epoch": 0.5843298804143503,
      "grad_norm": 0.22272367775440216,
      "learning_rate": 4.026483488648029e-05,
      "loss": 0.0974,
      "step": 29220
    },
    {
      "epoch": 0.58452985641723,
      "grad_norm": 0.3602350950241089,
      "learning_rate": 4.0261501953098965e-05,
      "loss": 0.5598,
      "step": 29230
    },
    {
      "epoch": 0.5847298324201096,
      "grad_norm": 0.13790789246559143,
      "learning_rate": 4.0258169019717635e-05,
      "loss": 0.0834,
      "step": 29240
    },
    {
      "epoch": 0.5849298084229893,
      "grad_norm": 0.10012798756361008,
      "learning_rate": 4.0254836086336304e-05,
      "loss": 0.0999,
      "step": 29250
    },
    {
      "epoch": 0.5851297844258689,
      "grad_norm": 0.0708453357219696,
      "learning_rate": 4.025150315295498e-05,
      "loss": 0.1378,
      "step": 29260
    },
    {
      "epoch": 0.5853297604287485,
      "grad_norm": 0.13977907598018646,
      "learning_rate": 4.024817021957366e-05,
      "loss": 0.1017,
      "step": 29270
    },
    {
      "epoch": 0.5855297364316282,
      "grad_norm": 0.09133852273225784,
      "learning_rate": 4.024483728619233e-05,
      "loss": 0.1101,
      "step": 29280
    },
    {
      "epoch": 0.5857297124345079,
      "grad_norm": 0.17370229959487915,
      "learning_rate": 4.0241504352810996e-05,
      "loss": 0.096,
      "step": 29290
    },
    {
      "epoch": 0.5859296884373875,
      "grad_norm": 0.1485019028186798,
      "learning_rate": 4.023817141942967e-05,
      "loss": 0.0638,
      "step": 29300
    },
    {
      "epoch": 0.5861296644402672,
      "grad_norm": 0.1966935396194458,
      "learning_rate": 4.023483848604834e-05,
      "loss": 0.1374,
      "step": 29310
    },
    {
      "epoch": 0.5863296404431468,
      "grad_norm": 0.06845057755708694,
      "learning_rate": 4.023150555266701e-05,
      "loss": 0.0787,
      "step": 29320
    },
    {
      "epoch": 0.5865296164460265,
      "grad_norm": 0.07559625059366226,
      "learning_rate": 4.022817261928569e-05,
      "loss": 0.0729,
      "step": 29330
    },
    {
      "epoch": 0.5867295924489061,
      "grad_norm": 0.07333320379257202,
      "learning_rate": 4.022483968590436e-05,
      "loss": 0.0644,
      "step": 29340
    },
    {
      "epoch": 0.5869295684517858,
      "grad_norm": 0.11514504253864288,
      "learning_rate": 4.022150675252303e-05,
      "loss": 0.0857,
      "step": 29350
    },
    {
      "epoch": 0.5871295444546655,
      "grad_norm": 0.1314876675605774,
      "learning_rate": 4.0218173819141704e-05,
      "loss": 0.0941,
      "step": 29360
    },
    {
      "epoch": 0.587329520457545,
      "grad_norm": 0.19366486370563507,
      "learning_rate": 4.021484088576038e-05,
      "loss": 0.0974,
      "step": 29370
    },
    {
      "epoch": 0.5875294964604247,
      "grad_norm": 0.09702371060848236,
      "learning_rate": 4.021150795237905e-05,
      "loss": 0.0843,
      "step": 29380
    },
    {
      "epoch": 0.5877294724633044,
      "grad_norm": 0.05131092295050621,
      "learning_rate": 4.0208175018997727e-05,
      "loss": 0.1054,
      "step": 29390
    },
    {
      "epoch": 0.5879294484661841,
      "grad_norm": 0.12949493527412415,
      "learning_rate": 4.0204842085616396e-05,
      "loss": 0.0982,
      "step": 29400
    },
    {
      "epoch": 0.5881294244690637,
      "grad_norm": 0.12020692974328995,
      "learning_rate": 4.0201509152235066e-05,
      "loss": 0.0748,
      "step": 29410
    },
    {
      "epoch": 0.5883294004719434,
      "grad_norm": 0.09012991935014725,
      "learning_rate": 4.019817621885374e-05,
      "loss": 0.0691,
      "step": 29420
    },
    {
      "epoch": 0.5885293764748231,
      "grad_norm": 0.10574467480182648,
      "learning_rate": 4.019484328547241e-05,
      "loss": 0.069,
      "step": 29430
    },
    {
      "epoch": 0.5887293524777026,
      "grad_norm": 0.06061876565217972,
      "learning_rate": 4.019151035209108e-05,
      "loss": 0.0649,
      "step": 29440
    },
    {
      "epoch": 0.5889293284805823,
      "grad_norm": 0.147800475358963,
      "learning_rate": 4.018817741870976e-05,
      "loss": 0.0767,
      "step": 29450
    },
    {
      "epoch": 0.589129304483462,
      "grad_norm": 0.10649338364601135,
      "learning_rate": 4.018484448532843e-05,
      "loss": 0.0468,
      "step": 29460
    },
    {
      "epoch": 0.5893292804863416,
      "grad_norm": 0.06451130658388138,
      "learning_rate": 4.0181511551947104e-05,
      "loss": 0.0777,
      "step": 29470
    },
    {
      "epoch": 0.5895292564892213,
      "grad_norm": 0.11254788935184479,
      "learning_rate": 4.0178178618565773e-05,
      "loss": 0.0499,
      "step": 29480
    },
    {
      "epoch": 0.589729232492101,
      "grad_norm": 0.25234076380729675,
      "learning_rate": 4.017484568518445e-05,
      "loss": 0.11,
      "step": 29490
    },
    {
      "epoch": 0.5899292084949807,
      "grad_norm": 0.1322840005159378,
      "learning_rate": 4.017151275180312e-05,
      "loss": 0.0737,
      "step": 29500
    },
    {
      "epoch": 0.5901291844978602,
      "grad_norm": 0.26835373044013977,
      "learning_rate": 4.016817981842179e-05,
      "loss": 0.096,
      "step": 29510
    },
    {
      "epoch": 0.5903291605007399,
      "grad_norm": 0.15073227882385254,
      "learning_rate": 4.0164846885040465e-05,
      "loss": 0.0893,
      "step": 29520
    },
    {
      "epoch": 0.5905291365036196,
      "grad_norm": 0.11774386465549469,
      "learning_rate": 4.016184724499727e-05,
      "loss": 0.1039,
      "step": 29530
    },
    {
      "epoch": 0.5907291125064992,
      "grad_norm": 0.10248807817697525,
      "learning_rate": 4.0158514311615944e-05,
      "loss": 0.0916,
      "step": 29540
    },
    {
      "epoch": 0.5909290885093789,
      "grad_norm": 0.13253116607666016,
      "learning_rate": 4.0155181378234613e-05,
      "loss": 0.0892,
      "step": 29550
    },
    {
      "epoch": 0.5911290645122586,
      "grad_norm": 0.10760590434074402,
      "learning_rate": 4.015184844485328e-05,
      "loss": 0.1066,
      "step": 29560
    },
    {
      "epoch": 0.5913290405151382,
      "grad_norm": 0.07095605880022049,
      "learning_rate": 4.014851551147196e-05,
      "loss": 0.0727,
      "step": 29570
    },
    {
      "epoch": 0.5915290165180178,
      "grad_norm": 0.06517378985881805,
      "learning_rate": 4.014518257809063e-05,
      "loss": 0.0729,
      "step": 29580
    },
    {
      "epoch": 0.5917289925208975,
      "grad_norm": 0.20475558936595917,
      "learning_rate": 4.0141849644709305e-05,
      "loss": 0.0644,
      "step": 29590
    },
    {
      "epoch": 0.5919289685237772,
      "grad_norm": 0.09126704931259155,
      "learning_rate": 4.0138516711327975e-05,
      "loss": 0.0446,
      "step": 29600
    },
    {
      "epoch": 0.5921289445266568,
      "grad_norm": 0.1884271651506424,
      "learning_rate": 4.013518377794665e-05,
      "loss": 0.08,
      "step": 29610
    },
    {
      "epoch": 0.5923289205295365,
      "grad_norm": 0.09694857150316238,
      "learning_rate": 4.013185084456532e-05,
      "loss": 0.0834,
      "step": 29620
    },
    {
      "epoch": 0.5925288965324161,
      "grad_norm": 0.12324736267328262,
      "learning_rate": 4.012851791118399e-05,
      "loss": 0.0688,
      "step": 29630
    },
    {
      "epoch": 0.5927288725352957,
      "grad_norm": 0.13346628844738007,
      "learning_rate": 4.012518497780267e-05,
      "loss": 0.116,
      "step": 29640
    },
    {
      "epoch": 0.5929288485381754,
      "grad_norm": 0.0962071567773819,
      "learning_rate": 4.012185204442134e-05,
      "loss": 0.0717,
      "step": 29650
    },
    {
      "epoch": 0.5931288245410551,
      "grad_norm": 0.15049459040164948,
      "learning_rate": 4.0118519111040006e-05,
      "loss": 0.1005,
      "step": 29660
    },
    {
      "epoch": 0.5933288005439348,
      "grad_norm": 0.2728683650493622,
      "learning_rate": 4.011518617765868e-05,
      "loss": 0.0942,
      "step": 29670
    },
    {
      "epoch": 0.5935287765468144,
      "grad_norm": 0.1773672252893448,
      "learning_rate": 4.011185324427735e-05,
      "loss": 0.1114,
      "step": 29680
    },
    {
      "epoch": 0.593728752549694,
      "grad_norm": 0.18323051929473877,
      "learning_rate": 4.010852031089602e-05,
      "loss": 0.0858,
      "step": 29690
    },
    {
      "epoch": 0.5939287285525737,
      "grad_norm": 0.1146511659026146,
      "learning_rate": 4.0105187377514705e-05,
      "loss": 0.0671,
      "step": 29700
    },
    {
      "epoch": 0.5941287045554533,
      "grad_norm": 0.06967989355325699,
      "learning_rate": 4.0101854444133375e-05,
      "loss": 0.0595,
      "step": 29710
    },
    {
      "epoch": 0.594328680558333,
      "grad_norm": 0.08923335373401642,
      "learning_rate": 4.0098521510752044e-05,
      "loss": 0.1154,
      "step": 29720
    },
    {
      "epoch": 0.5945286565612127,
      "grad_norm": 0.14562658965587616,
      "learning_rate": 4.009518857737072e-05,
      "loss": 0.0825,
      "step": 29730
    },
    {
      "epoch": 0.5947286325640924,
      "grad_norm": 0.12846532464027405,
      "learning_rate": 4.009185564398939e-05,
      "loss": 0.0571,
      "step": 29740
    },
    {
      "epoch": 0.5949286085669719,
      "grad_norm": 0.07068149000406265,
      "learning_rate": 4.008852271060806e-05,
      "loss": 0.0617,
      "step": 29750
    },
    {
      "epoch": 0.5951285845698516,
      "grad_norm": 0.10823456197977066,
      "learning_rate": 4.0085189777226736e-05,
      "loss": 0.0626,
      "step": 29760
    },
    {
      "epoch": 0.5953285605727313,
      "grad_norm": 0.17343199253082275,
      "learning_rate": 4.0081856843845406e-05,
      "loss": 0.107,
      "step": 29770
    },
    {
      "epoch": 0.5955285365756109,
      "grad_norm": 0.14043064415454865,
      "learning_rate": 4.0078523910464076e-05,
      "loss": 0.0831,
      "step": 29780
    },
    {
      "epoch": 0.5957285125784906,
      "grad_norm": 0.058695800602436066,
      "learning_rate": 4.007519097708275e-05,
      "loss": 0.0827,
      "step": 29790
    },
    {
      "epoch": 0.5959284885813703,
      "grad_norm": 0.07355321943759918,
      "learning_rate": 4.007185804370143e-05,
      "loss": 0.0827,
      "step": 29800
    },
    {
      "epoch": 0.5961284645842498,
      "grad_norm": 0.07379047572612762,
      "learning_rate": 4.00685251103201e-05,
      "loss": 0.0675,
      "step": 29810
    },
    {
      "epoch": 0.5963284405871295,
      "grad_norm": 0.11165263503789902,
      "learning_rate": 4.006519217693877e-05,
      "loss": 0.085,
      "step": 29820
    },
    {
      "epoch": 0.5965284165900092,
      "grad_norm": 0.11441997438669205,
      "learning_rate": 4.0061859243557444e-05,
      "loss": 0.0747,
      "step": 29830
    },
    {
      "epoch": 0.5967283925928889,
      "grad_norm": 0.12119800597429276,
      "learning_rate": 4.0058526310176114e-05,
      "loss": 0.0516,
      "step": 29840
    },
    {
      "epoch": 0.5969283685957685,
      "grad_norm": 0.18769636750221252,
      "learning_rate": 4.005519337679478e-05,
      "loss": 0.1218,
      "step": 29850
    },
    {
      "epoch": 0.5971283445986482,
      "grad_norm": 0.10365476459264755,
      "learning_rate": 4.005186044341346e-05,
      "loss": 0.0543,
      "step": 29860
    },
    {
      "epoch": 0.5973283206015279,
      "grad_norm": 0.12944260239601135,
      "learning_rate": 4.004852751003213e-05,
      "loss": 0.092,
      "step": 29870
    },
    {
      "epoch": 0.5975282966044074,
      "grad_norm": 0.07728345692157745,
      "learning_rate": 4.00451945766508e-05,
      "loss": 0.0967,
      "step": 29880
    },
    {
      "epoch": 0.5977282726072871,
      "grad_norm": 0.09966683387756348,
      "learning_rate": 4.0041861643269475e-05,
      "loss": 0.0827,
      "step": 29890
    },
    {
      "epoch": 0.5979282486101668,
      "grad_norm": 0.20288130640983582,
      "learning_rate": 4.003852870988815e-05,
      "loss": 0.104,
      "step": 29900
    },
    {
      "epoch": 0.5981282246130465,
      "grad_norm": 0.19451217353343964,
      "learning_rate": 4.003519577650682e-05,
      "loss": 0.1034,
      "step": 29910
    },
    {
      "epoch": 0.5983282006159261,
      "grad_norm": 0.08323010057210922,
      "learning_rate": 4.00318628431255e-05,
      "loss": 0.0779,
      "step": 29920
    },
    {
      "epoch": 0.5985281766188058,
      "grad_norm": 0.20758172869682312,
      "learning_rate": 4.002852990974417e-05,
      "loss": 0.1005,
      "step": 29930
    },
    {
      "epoch": 0.5987281526216854,
      "grad_norm": 0.07138406485319138,
      "learning_rate": 4.002519697636284e-05,
      "loss": 0.0487,
      "step": 29940
    },
    {
      "epoch": 0.598928128624565,
      "grad_norm": 0.13273735344409943,
      "learning_rate": 4.002186404298151e-05,
      "loss": 0.0749,
      "step": 29950
    },
    {
      "epoch": 0.5991281046274447,
      "grad_norm": 0.058972638100385666,
      "learning_rate": 4.001853110960018e-05,
      "loss": 0.0465,
      "step": 29960
    },
    {
      "epoch": 0.5993280806303244,
      "grad_norm": 0.1542067974805832,
      "learning_rate": 4.001519817621885e-05,
      "loss": 0.0868,
      "step": 29970
    },
    {
      "epoch": 0.599528056633204,
      "grad_norm": 0.10958654433488846,
      "learning_rate": 4.001186524283753e-05,
      "loss": 0.0379,
      "step": 29980
    },
    {
      "epoch": 0.5997280326360837,
      "grad_norm": 0.10795469582080841,
      "learning_rate": 4.00085323094562e-05,
      "loss": 0.0856,
      "step": 29990
    },
    {
      "epoch": 0.5999280086389633,
      "grad_norm": 0.13959810137748718,
      "learning_rate": 4.0005199376074875e-05,
      "loss": 0.0462,
      "step": 30000
    },
    {
      "epoch": 0.600127984641843,
      "grad_norm": 0.1446312665939331,
      "learning_rate": 4.0001866442693544e-05,
      "loss": 0.043,
      "step": 30010
    },
    {
      "epoch": 0.6003279606447226,
      "grad_norm": 0.12057461589574814,
      "learning_rate": 3.999853350931222e-05,
      "loss": 0.0513,
      "step": 30020
    },
    {
      "epoch": 0.6005279366476023,
      "grad_norm": 0.11567032337188721,
      "learning_rate": 3.999520057593089e-05,
      "loss": 0.0675,
      "step": 30030
    },
    {
      "epoch": 0.600727912650482,
      "grad_norm": 0.07798629254102707,
      "learning_rate": 3.999186764254956e-05,
      "loss": 0.0844,
      "step": 30040
    },
    {
      "epoch": 0.6009278886533616,
      "grad_norm": 0.1185707226395607,
      "learning_rate": 3.9988534709168237e-05,
      "loss": 0.0664,
      "step": 30050
    },
    {
      "epoch": 0.6011278646562412,
      "grad_norm": 0.1056496798992157,
      "learning_rate": 3.9985201775786906e-05,
      "loss": 0.0735,
      "step": 30060
    },
    {
      "epoch": 0.6013278406591209,
      "grad_norm": 0.11370112746953964,
      "learning_rate": 3.9981868842405576e-05,
      "loss": 0.0409,
      "step": 30070
    },
    {
      "epoch": 0.6015278166620006,
      "grad_norm": 0.1555081307888031,
      "learning_rate": 3.997853590902425e-05,
      "loss": 0.1279,
      "step": 30080
    },
    {
      "epoch": 0.6017277926648802,
      "grad_norm": 0.16562609374523163,
      "learning_rate": 3.997520297564292e-05,
      "loss": 0.0823,
      "step": 30090
    },
    {
      "epoch": 0.6019277686677599,
      "grad_norm": 0.17391930520534515,
      "learning_rate": 3.99718700422616e-05,
      "loss": 0.1635,
      "step": 30100
    },
    {
      "epoch": 0.6021277446706396,
      "grad_norm": 0.0798586830496788,
      "learning_rate": 3.9968537108880275e-05,
      "loss": 0.0678,
      "step": 30110
    },
    {
      "epoch": 0.6023277206735191,
      "grad_norm": 0.12250256538391113,
      "learning_rate": 3.9965204175498944e-05,
      "loss": 0.0703,
      "step": 30120
    },
    {
      "epoch": 0.6025276966763988,
      "grad_norm": 0.08338167518377304,
      "learning_rate": 3.9961871242117614e-05,
      "loss": 0.0658,
      "step": 30130
    },
    {
      "epoch": 0.6027276726792785,
      "grad_norm": 0.08381746709346771,
      "learning_rate": 3.995853830873629e-05,
      "loss": 0.0933,
      "step": 30140
    },
    {
      "epoch": 0.6029276486821581,
      "grad_norm": 0.16826528310775757,
      "learning_rate": 3.995520537535496e-05,
      "loss": 0.0997,
      "step": 30150
    },
    {
      "epoch": 0.6031276246850378,
      "grad_norm": 0.07315152883529663,
      "learning_rate": 3.995187244197363e-05,
      "loss": 0.0613,
      "step": 30160
    },
    {
      "epoch": 0.6033276006879175,
      "grad_norm": 0.08649969100952148,
      "learning_rate": 3.9948539508592306e-05,
      "loss": 0.0451,
      "step": 30170
    },
    {
      "epoch": 0.6035275766907972,
      "grad_norm": 0.17173081636428833,
      "learning_rate": 3.9945206575210975e-05,
      "loss": 0.0996,
      "step": 30180
    },
    {
      "epoch": 0.6037275526936767,
      "grad_norm": 0.11781042069196701,
      "learning_rate": 3.9941873641829645e-05,
      "loss": 0.0979,
      "step": 30190
    },
    {
      "epoch": 0.6039275286965564,
      "grad_norm": 0.19304609298706055,
      "learning_rate": 3.993854070844832e-05,
      "loss": 0.0915,
      "step": 30200
    },
    {
      "epoch": 0.6041275046994361,
      "grad_norm": 0.11168882250785828,
      "learning_rate": 3.9935207775067e-05,
      "loss": 0.0708,
      "step": 30210
    },
    {
      "epoch": 0.6043274807023157,
      "grad_norm": 0.09369337558746338,
      "learning_rate": 3.993187484168567e-05,
      "loss": 0.0675,
      "step": 30220
    },
    {
      "epoch": 0.6045274567051954,
      "grad_norm": 0.07253522425889969,
      "learning_rate": 3.992854190830434e-05,
      "loss": 0.0797,
      "step": 30230
    },
    {
      "epoch": 0.604727432708075,
      "grad_norm": 0.10830695182085037,
      "learning_rate": 3.9925208974923013e-05,
      "loss": 0.0704,
      "step": 30240
    },
    {
      "epoch": 0.6049274087109547,
      "grad_norm": 0.09763872623443604,
      "learning_rate": 3.992187604154168e-05,
      "loss": 0.0854,
      "step": 30250
    },
    {
      "epoch": 0.6051273847138343,
      "grad_norm": 0.23075316846370697,
      "learning_rate": 3.991854310816035e-05,
      "loss": 0.1,
      "step": 30260
    },
    {
      "epoch": 0.605327360716714,
      "grad_norm": 0.13204486668109894,
      "learning_rate": 3.991521017477903e-05,
      "loss": 0.085,
      "step": 30270
    },
    {
      "epoch": 0.6055273367195937,
      "grad_norm": 0.19562573730945587,
      "learning_rate": 3.99118772413977e-05,
      "loss": 0.0863,
      "step": 30280
    },
    {
      "epoch": 0.6057273127224733,
      "grad_norm": 0.17999541759490967,
      "learning_rate": 3.990854430801637e-05,
      "loss": 0.0659,
      "step": 30290
    },
    {
      "epoch": 0.605927288725353,
      "grad_norm": 0.13955450057983398,
      "learning_rate": 3.9905211374635045e-05,
      "loss": 0.0795,
      "step": 30300
    },
    {
      "epoch": 0.6061272647282326,
      "grad_norm": 0.05529147759079933,
      "learning_rate": 3.990187844125372e-05,
      "loss": 0.086,
      "step": 30310
    },
    {
      "epoch": 0.6063272407311122,
      "grad_norm": 0.11961255222558975,
      "learning_rate": 3.989854550787239e-05,
      "loss": 0.0731,
      "step": 30320
    },
    {
      "epoch": 0.6065272167339919,
      "grad_norm": 0.08561410009860992,
      "learning_rate": 3.989521257449107e-05,
      "loss": 0.0447,
      "step": 30330
    },
    {
      "epoch": 0.6067271927368716,
      "grad_norm": 0.06714820116758347,
      "learning_rate": 3.989187964110974e-05,
      "loss": 0.116,
      "step": 30340
    },
    {
      "epoch": 0.6069271687397513,
      "grad_norm": 0.1927565634250641,
      "learning_rate": 3.9888546707728406e-05,
      "loss": 0.0751,
      "step": 30350
    },
    {
      "epoch": 0.6071271447426309,
      "grad_norm": 0.09591305255889893,
      "learning_rate": 3.988521377434708e-05,
      "loss": 0.0508,
      "step": 30360
    },
    {
      "epoch": 0.6073271207455105,
      "grad_norm": 0.07751554995775223,
      "learning_rate": 3.988188084096575e-05,
      "loss": 0.0774,
      "step": 30370
    },
    {
      "epoch": 0.6075270967483902,
      "grad_norm": 0.15747830271720886,
      "learning_rate": 3.987854790758442e-05,
      "loss": 0.0879,
      "step": 30380
    },
    {
      "epoch": 0.6077270727512698,
      "grad_norm": 0.17895102500915527,
      "learning_rate": 3.98752149742031e-05,
      "loss": 0.0729,
      "step": 30390
    },
    {
      "epoch": 0.6079270487541495,
      "grad_norm": 0.10482162982225418,
      "learning_rate": 3.987188204082177e-05,
      "loss": 0.0808,
      "step": 30400
    },
    {
      "epoch": 0.6081270247570292,
      "grad_norm": 0.12041756510734558,
      "learning_rate": 3.9868549107440444e-05,
      "loss": 0.107,
      "step": 30410
    },
    {
      "epoch": 0.6083270007599089,
      "grad_norm": 0.1544680893421173,
      "learning_rate": 3.9865216174059114e-05,
      "loss": 0.0774,
      "step": 30420
    },
    {
      "epoch": 0.6085269767627884,
      "grad_norm": 0.09723155945539474,
      "learning_rate": 3.986188324067779e-05,
      "loss": 0.089,
      "step": 30430
    },
    {
      "epoch": 0.6087269527656681,
      "grad_norm": 0.13210591673851013,
      "learning_rate": 3.985855030729646e-05,
      "loss": 0.0743,
      "step": 30440
    },
    {
      "epoch": 0.6089269287685478,
      "grad_norm": 0.06586036831140518,
      "learning_rate": 3.985521737391513e-05,
      "loss": 0.0915,
      "step": 30450
    },
    {
      "epoch": 0.6091269047714274,
      "grad_norm": 0.15450674295425415,
      "learning_rate": 3.9851884440533806e-05,
      "loss": 0.0975,
      "step": 30460
    },
    {
      "epoch": 0.6093268807743071,
      "grad_norm": 0.14662538468837738,
      "learning_rate": 3.9848551507152476e-05,
      "loss": 0.0614,
      "step": 30470
    },
    {
      "epoch": 0.6095268567771868,
      "grad_norm": 0.16202305257320404,
      "learning_rate": 3.9845218573771145e-05,
      "loss": 0.0785,
      "step": 30480
    },
    {
      "epoch": 0.6097268327800663,
      "grad_norm": 0.08597243577241898,
      "learning_rate": 3.984188564038982e-05,
      "loss": 0.0772,
      "step": 30490
    },
    {
      "epoch": 0.609926808782946,
      "grad_norm": 0.13996419310569763,
      "learning_rate": 3.983855270700849e-05,
      "loss": 0.059,
      "step": 30500
    },
    {
      "epoch": 0.6101267847858257,
      "grad_norm": 0.0843501016497612,
      "learning_rate": 3.983521977362717e-05,
      "loss": 0.0563,
      "step": 30510
    },
    {
      "epoch": 0.6103267607887054,
      "grad_norm": 0.04083884879946709,
      "learning_rate": 3.9831886840245844e-05,
      "loss": 0.075,
      "step": 30520
    },
    {
      "epoch": 0.610526736791585,
      "grad_norm": 0.1532253921031952,
      "learning_rate": 3.9828553906864514e-05,
      "loss": 0.0804,
      "step": 30530
    },
    {
      "epoch": 0.6107267127944647,
      "grad_norm": 0.13517969846725464,
      "learning_rate": 3.982522097348318e-05,
      "loss": 0.1134,
      "step": 30540
    },
    {
      "epoch": 0.6109266887973444,
      "grad_norm": 0.07255387306213379,
      "learning_rate": 3.982188804010186e-05,
      "loss": 0.0859,
      "step": 30550
    },
    {
      "epoch": 0.6111266648002239,
      "grad_norm": 0.060618311166763306,
      "learning_rate": 3.981855510672053e-05,
      "loss": 0.0668,
      "step": 30560
    },
    {
      "epoch": 0.6113266408031036,
      "grad_norm": 0.2229527235031128,
      "learning_rate": 3.98152221733392e-05,
      "loss": 0.0916,
      "step": 30570
    },
    {
      "epoch": 0.6115266168059833,
      "grad_norm": 0.08646996319293976,
      "learning_rate": 3.9811889239957875e-05,
      "loss": 0.0819,
      "step": 30580
    },
    {
      "epoch": 0.611726592808863,
      "grad_norm": 0.05061308667063713,
      "learning_rate": 3.9808556306576545e-05,
      "loss": 0.0656,
      "step": 30590
    },
    {
      "epoch": 0.6119265688117426,
      "grad_norm": 0.12353268265724182,
      "learning_rate": 3.9805223373195214e-05,
      "loss": 0.061,
      "step": 30600
    },
    {
      "epoch": 0.6121265448146223,
      "grad_norm": 0.10171959549188614,
      "learning_rate": 3.980189043981389e-05,
      "loss": 0.0939,
      "step": 30610
    },
    {
      "epoch": 0.6123265208175019,
      "grad_norm": 0.16066354513168335,
      "learning_rate": 3.979855750643257e-05,
      "loss": 0.1047,
      "step": 30620
    },
    {
      "epoch": 0.6125264968203815,
      "grad_norm": 0.11229689419269562,
      "learning_rate": 3.979522457305124e-05,
      "loss": 0.0888,
      "step": 30630
    },
    {
      "epoch": 0.6127264728232612,
      "grad_norm": 0.06339426338672638,
      "learning_rate": 3.9791891639669906e-05,
      "loss": 0.0753,
      "step": 30640
    },
    {
      "epoch": 0.6129264488261409,
      "grad_norm": 0.16787859797477722,
      "learning_rate": 3.978855870628858e-05,
      "loss": 0.0791,
      "step": 30650
    },
    {
      "epoch": 0.6131264248290205,
      "grad_norm": 0.0669192522764206,
      "learning_rate": 3.978522577290725e-05,
      "loss": 0.0471,
      "step": 30660
    },
    {
      "epoch": 0.6133264008319002,
      "grad_norm": 0.2344464808702469,
      "learning_rate": 3.978189283952592e-05,
      "loss": 0.078,
      "step": 30670
    },
    {
      "epoch": 0.6135263768347798,
      "grad_norm": 0.11050969362258911,
      "learning_rate": 3.97785599061446e-05,
      "loss": 0.0554,
      "step": 30680
    },
    {
      "epoch": 0.6137263528376595,
      "grad_norm": 0.13585986196994781,
      "learning_rate": 3.977522697276327e-05,
      "loss": 0.0741,
      "step": 30690
    },
    {
      "epoch": 0.6139263288405391,
      "grad_norm": 0.10140360891819,
      "learning_rate": 3.977189403938194e-05,
      "loss": 0.0641,
      "step": 30700
    },
    {
      "epoch": 0.6141263048434188,
      "grad_norm": 0.06615805625915527,
      "learning_rate": 3.9768561106000614e-05,
      "loss": 0.1185,
      "step": 30710
    },
    {
      "epoch": 0.6143262808462985,
      "grad_norm": 0.15868978202342987,
      "learning_rate": 3.976522817261929e-05,
      "loss": 0.0732,
      "step": 30720
    },
    {
      "epoch": 0.614526256849178,
      "grad_norm": 0.08007704466581345,
      "learning_rate": 3.976189523923796e-05,
      "loss": 0.0676,
      "step": 30730
    },
    {
      "epoch": 0.6147262328520577,
      "grad_norm": 0.08188554644584656,
      "learning_rate": 3.9758562305856637e-05,
      "loss": 0.0698,
      "step": 30740
    },
    {
      "epoch": 0.6149262088549374,
      "grad_norm": 0.11970204859972,
      "learning_rate": 3.9755229372475306e-05,
      "loss": 0.0797,
      "step": 30750
    },
    {
      "epoch": 0.6151261848578171,
      "grad_norm": 0.1782906949520111,
      "learning_rate": 3.9751896439093976e-05,
      "loss": 0.1408,
      "step": 30760
    },
    {
      "epoch": 0.6153261608606967,
      "grad_norm": 0.1244799867272377,
      "learning_rate": 3.974856350571265e-05,
      "loss": 0.0919,
      "step": 30770
    },
    {
      "epoch": 0.6155261368635764,
      "grad_norm": 0.17716893553733826,
      "learning_rate": 3.974523057233132e-05,
      "loss": 0.1043,
      "step": 30780
    },
    {
      "epoch": 0.6157261128664561,
      "grad_norm": 0.11128336936235428,
      "learning_rate": 3.974189763894999e-05,
      "loss": 0.1024,
      "step": 30790
    },
    {
      "epoch": 0.6159260888693356,
      "grad_norm": 0.12732087075710297,
      "learning_rate": 3.973856470556867e-05,
      "loss": 0.0955,
      "step": 30800
    },
    {
      "epoch": 0.6161260648722153,
      "grad_norm": 0.11789527535438538,
      "learning_rate": 3.973523177218734e-05,
      "loss": 0.0614,
      "step": 30810
    },
    {
      "epoch": 0.616326040875095,
      "grad_norm": 0.21303074061870575,
      "learning_rate": 3.9731898838806014e-05,
      "loss": 0.1088,
      "step": 30820
    },
    {
      "epoch": 0.6165260168779746,
      "grad_norm": 0.07162318378686905,
      "learning_rate": 3.9728565905424683e-05,
      "loss": 0.0865,
      "step": 30830
    },
    {
      "epoch": 0.6167259928808543,
      "grad_norm": 0.0543832965195179,
      "learning_rate": 3.972523297204336e-05,
      "loss": 0.0375,
      "step": 30840
    },
    {
      "epoch": 0.616925968883734,
      "grad_norm": 0.10417148470878601,
      "learning_rate": 3.972190003866203e-05,
      "loss": 0.0807,
      "step": 30850
    },
    {
      "epoch": 0.6171259448866137,
      "grad_norm": 0.1499362587928772,
      "learning_rate": 3.97185671052807e-05,
      "loss": 0.0926,
      "step": 30860
    },
    {
      "epoch": 0.6173259208894932,
      "grad_norm": 0.08738981932401657,
      "learning_rate": 3.9715234171899375e-05,
      "loss": 0.0615,
      "step": 30870
    },
    {
      "epoch": 0.6175258968923729,
      "grad_norm": 0.13123421370983124,
      "learning_rate": 3.9711901238518045e-05,
      "loss": 0.0926,
      "step": 30880
    },
    {
      "epoch": 0.6177258728952526,
      "grad_norm": 0.07773693650960922,
      "learning_rate": 3.9708568305136715e-05,
      "loss": 0.0616,
      "step": 30890
    },
    {
      "epoch": 0.6179258488981322,
      "grad_norm": 0.11372024565935135,
      "learning_rate": 3.970523537175539e-05,
      "loss": 0.0574,
      "step": 30900
    },
    {
      "epoch": 0.6181258249010119,
      "grad_norm": 0.09615857899188995,
      "learning_rate": 3.970190243837406e-05,
      "loss": 0.0297,
      "step": 30910
    },
    {
      "epoch": 0.6183258009038916,
      "grad_norm": 0.1963970959186554,
      "learning_rate": 3.969856950499274e-05,
      "loss": 0.0787,
      "step": 30920
    },
    {
      "epoch": 0.6185257769067712,
      "grad_norm": 0.12680596113204956,
      "learning_rate": 3.9695236571611413e-05,
      "loss": 0.0955,
      "step": 30930
    },
    {
      "epoch": 0.6187257529096508,
      "grad_norm": 0.07355868816375732,
      "learning_rate": 3.969190363823008e-05,
      "loss": 0.1035,
      "step": 30940
    },
    {
      "epoch": 0.6189257289125305,
      "grad_norm": 0.10167371481657028,
      "learning_rate": 3.968857070484875e-05,
      "loss": 0.0647,
      "step": 30950
    },
    {
      "epoch": 0.6191257049154102,
      "grad_norm": 0.08428680896759033,
      "learning_rate": 3.968523777146743e-05,
      "loss": 0.072,
      "step": 30960
    },
    {
      "epoch": 0.6193256809182898,
      "grad_norm": 0.16216786205768585,
      "learning_rate": 3.96819048380861e-05,
      "loss": 0.1066,
      "step": 30970
    },
    {
      "epoch": 0.6195256569211695,
      "grad_norm": 0.06379274278879166,
      "learning_rate": 3.967857190470477e-05,
      "loss": 0.0874,
      "step": 30980
    },
    {
      "epoch": 0.6197256329240491,
      "grad_norm": 0.05935909226536751,
      "learning_rate": 3.9675238971323445e-05,
      "loss": 0.07,
      "step": 30990
    },
    {
      "epoch": 0.6199256089269287,
      "grad_norm": 0.05922446772456169,
      "learning_rate": 3.9671906037942114e-05,
      "loss": 0.0903,
      "step": 31000
    },
    {
      "epoch": 0.6201255849298084,
      "grad_norm": 0.14393222332000732,
      "learning_rate": 3.9668573104560784e-05,
      "loss": 0.0682,
      "step": 31010
    },
    {
      "epoch": 0.6203255609326881,
      "grad_norm": 0.09162719547748566,
      "learning_rate": 3.966524017117946e-05,
      "loss": 0.0795,
      "step": 31020
    },
    {
      "epoch": 0.6205255369355678,
      "grad_norm": 0.07016772031784058,
      "learning_rate": 3.966190723779814e-05,
      "loss": 0.1026,
      "step": 31030
    },
    {
      "epoch": 0.6207255129384474,
      "grad_norm": 0.23070257902145386,
      "learning_rate": 3.9658574304416806e-05,
      "loss": 0.1115,
      "step": 31040
    },
    {
      "epoch": 0.620925488941327,
      "grad_norm": 0.09806305170059204,
      "learning_rate": 3.9655241371035476e-05,
      "loss": 0.0541,
      "step": 31050
    },
    {
      "epoch": 0.6211254649442067,
      "grad_norm": 0.11600915342569351,
      "learning_rate": 3.965190843765415e-05,
      "loss": 0.0665,
      "step": 31060
    },
    {
      "epoch": 0.6213254409470863,
      "grad_norm": 0.1362379789352417,
      "learning_rate": 3.964857550427282e-05,
      "loss": 0.0993,
      "step": 31070
    },
    {
      "epoch": 0.621525416949966,
      "grad_norm": 0.15023085474967957,
      "learning_rate": 3.964524257089149e-05,
      "loss": 0.0654,
      "step": 31080
    },
    {
      "epoch": 0.6217253929528457,
      "grad_norm": 0.10870096832513809,
      "learning_rate": 3.964190963751017e-05,
      "loss": 0.0795,
      "step": 31090
    },
    {
      "epoch": 0.6219253689557254,
      "grad_norm": 0.04517776891589165,
      "learning_rate": 3.963857670412884e-05,
      "loss": 0.0612,
      "step": 31100
    },
    {
      "epoch": 0.6221253449586049,
      "grad_norm": 0.07892764359712601,
      "learning_rate": 3.963524377074751e-05,
      "loss": 0.0688,
      "step": 31110
    },
    {
      "epoch": 0.6223253209614846,
      "grad_norm": 0.08934232592582703,
      "learning_rate": 3.963191083736619e-05,
      "loss": 0.0945,
      "step": 31120
    },
    {
      "epoch": 0.6225252969643643,
      "grad_norm": 0.13782815635204315,
      "learning_rate": 3.962857790398486e-05,
      "loss": 0.0866,
      "step": 31130
    },
    {
      "epoch": 0.6227252729672439,
      "grad_norm": 0.18735608458518982,
      "learning_rate": 3.962524497060353e-05,
      "loss": 0.0949,
      "step": 31140
    },
    {
      "epoch": 0.6229252489701236,
      "grad_norm": 0.1576147973537445,
      "learning_rate": 3.9621912037222206e-05,
      "loss": 0.0948,
      "step": 31150
    },
    {
      "epoch": 0.6231252249730033,
      "grad_norm": 0.16917231678962708,
      "learning_rate": 3.9618579103840876e-05,
      "loss": 0.0515,
      "step": 31160
    },
    {
      "epoch": 0.6233252009758828,
      "grad_norm": 0.09589903801679611,
      "learning_rate": 3.9615246170459545e-05,
      "loss": 0.0651,
      "step": 31170
    },
    {
      "epoch": 0.6235251769787625,
      "grad_norm": 0.0874629095196724,
      "learning_rate": 3.961191323707822e-05,
      "loss": 0.1316,
      "step": 31180
    },
    {
      "epoch": 0.6237251529816422,
      "grad_norm": 0.1153855249285698,
      "learning_rate": 3.960858030369689e-05,
      "loss": 0.0511,
      "step": 31190
    },
    {
      "epoch": 0.6239251289845219,
      "grad_norm": 0.16612175107002258,
      "learning_rate": 3.960524737031556e-05,
      "loss": 0.1007,
      "step": 31200
    },
    {
      "epoch": 0.6241251049874015,
      "grad_norm": 0.11504806578159332,
      "learning_rate": 3.960191443693424e-05,
      "loss": 0.0577,
      "step": 31210
    },
    {
      "epoch": 0.6243250809902812,
      "grad_norm": 0.052362602204084396,
      "learning_rate": 3.959858150355291e-05,
      "loss": 0.0917,
      "step": 31220
    },
    {
      "epoch": 0.6245250569931609,
      "grad_norm": 0.1744661033153534,
      "learning_rate": 3.959524857017158e-05,
      "loss": 0.08,
      "step": 31230
    },
    {
      "epoch": 0.6247250329960404,
      "grad_norm": 0.09410031884908676,
      "learning_rate": 3.959191563679025e-05,
      "loss": 0.0421,
      "step": 31240
    },
    {
      "epoch": 0.6249250089989201,
      "grad_norm": 0.1039838194847107,
      "learning_rate": 3.958858270340893e-05,
      "loss": 0.0707,
      "step": 31250
    },
    {
      "epoch": 0.6251249850017998,
      "grad_norm": 0.12712310254573822,
      "learning_rate": 3.95852497700276e-05,
      "loss": 0.1149,
      "step": 31260
    },
    {
      "epoch": 0.6253249610046795,
      "grad_norm": 0.09549488127231598,
      "learning_rate": 3.958191683664627e-05,
      "loss": 0.0635,
      "step": 31270
    },
    {
      "epoch": 0.6255249370075591,
      "grad_norm": 0.1876976490020752,
      "learning_rate": 3.9578583903264945e-05,
      "loss": 0.1028,
      "step": 31280
    },
    {
      "epoch": 0.6257249130104388,
      "grad_norm": 0.16462357342243195,
      "learning_rate": 3.9575250969883614e-05,
      "loss": 0.1777,
      "step": 31290
    },
    {
      "epoch": 0.6259248890133184,
      "grad_norm": 0.17735622823238373,
      "learning_rate": 3.9571918036502284e-05,
      "loss": 0.0701,
      "step": 31300
    },
    {
      "epoch": 0.626124865016198,
      "grad_norm": 0.18155083060264587,
      "learning_rate": 3.956858510312096e-05,
      "loss": 0.0809,
      "step": 31310
    },
    {
      "epoch": 0.6263248410190777,
      "grad_norm": 0.11629237234592438,
      "learning_rate": 3.956525216973963e-05,
      "loss": 0.1988,
      "step": 31320
    },
    {
      "epoch": 0.6265248170219574,
      "grad_norm": 0.057571858167648315,
      "learning_rate": 3.9561919236358306e-05,
      "loss": 0.0628,
      "step": 31330
    },
    {
      "epoch": 0.626724793024837,
      "grad_norm": 0.09696011245250702,
      "learning_rate": 3.955858630297698e-05,
      "loss": 0.0906,
      "step": 31340
    },
    {
      "epoch": 0.6269247690277167,
      "grad_norm": 0.18213967978954315,
      "learning_rate": 3.955525336959565e-05,
      "loss": 0.0798,
      "step": 31350
    },
    {
      "epoch": 0.6271247450305963,
      "grad_norm": 0.07413069158792496,
      "learning_rate": 3.955192043621432e-05,
      "loss": 0.0974,
      "step": 31360
    },
    {
      "epoch": 0.627324721033476,
      "grad_norm": 0.10140424966812134,
      "learning_rate": 3.9548587502833e-05,
      "loss": 0.0763,
      "step": 31370
    },
    {
      "epoch": 0.6275246970363556,
      "grad_norm": 0.11005546152591705,
      "learning_rate": 3.954525456945167e-05,
      "loss": 0.0782,
      "step": 31380
    },
    {
      "epoch": 0.6277246730392353,
      "grad_norm": 0.11861880868673325,
      "learning_rate": 3.954192163607034e-05,
      "loss": 0.0762,
      "step": 31390
    },
    {
      "epoch": 0.627924649042115,
      "grad_norm": 0.0930105596780777,
      "learning_rate": 3.9538588702689014e-05,
      "loss": 0.0759,
      "step": 31400
    },
    {
      "epoch": 0.6281246250449946,
      "grad_norm": 0.0721970796585083,
      "learning_rate": 3.9535255769307684e-05,
      "loss": 0.0984,
      "step": 31410
    },
    {
      "epoch": 0.6283246010478742,
      "grad_norm": 0.0890735313296318,
      "learning_rate": 3.953192283592635e-05,
      "loss": 0.0518,
      "step": 31420
    },
    {
      "epoch": 0.6285245770507539,
      "grad_norm": 0.09300196915864944,
      "learning_rate": 3.952858990254503e-05,
      "loss": 0.076,
      "step": 31430
    },
    {
      "epoch": 0.6287245530536336,
      "grad_norm": 0.2051830142736435,
      "learning_rate": 3.9525256969163706e-05,
      "loss": 0.1172,
      "step": 31440
    },
    {
      "epoch": 0.6289245290565132,
      "grad_norm": 0.14668916165828705,
      "learning_rate": 3.9521924035782376e-05,
      "loss": 0.0804,
      "step": 31450
    },
    {
      "epoch": 0.6291245050593929,
      "grad_norm": 0.13061033189296722,
      "learning_rate": 3.9518591102401045e-05,
      "loss": 0.0883,
      "step": 31460
    },
    {
      "epoch": 0.6293244810622726,
      "grad_norm": 0.14668124914169312,
      "learning_rate": 3.951525816901972e-05,
      "loss": 0.083,
      "step": 31470
    },
    {
      "epoch": 0.6295244570651521,
      "grad_norm": 0.07181233167648315,
      "learning_rate": 3.951192523563839e-05,
      "loss": 0.0722,
      "step": 31480
    },
    {
      "epoch": 0.6297244330680318,
      "grad_norm": 0.19547487795352936,
      "learning_rate": 3.950859230225706e-05,
      "loss": 0.1143,
      "step": 31490
    },
    {
      "epoch": 0.6299244090709115,
      "grad_norm": 0.09767385572195053,
      "learning_rate": 3.950525936887574e-05,
      "loss": 0.0784,
      "step": 31500
    },
    {
      "epoch": 0.6301243850737911,
      "grad_norm": 0.1098007932305336,
      "learning_rate": 3.950192643549441e-05,
      "loss": 0.062,
      "step": 31510
    },
    {
      "epoch": 0.6303243610766708,
      "grad_norm": 0.18362341821193695,
      "learning_rate": 3.949859350211308e-05,
      "loss": 0.0445,
      "step": 31520
    },
    {
      "epoch": 0.6305243370795505,
      "grad_norm": 0.17449207603931427,
      "learning_rate": 3.949526056873176e-05,
      "loss": 0.1191,
      "step": 31530
    },
    {
      "epoch": 0.6307243130824302,
      "grad_norm": 0.15473029017448425,
      "learning_rate": 3.949192763535043e-05,
      "loss": 0.0567,
      "step": 31540
    },
    {
      "epoch": 0.6309242890853097,
      "grad_norm": 0.11671363562345505,
      "learning_rate": 3.94885947019691e-05,
      "loss": 0.0753,
      "step": 31550
    },
    {
      "epoch": 0.6311242650881894,
      "grad_norm": 0.18732179701328278,
      "learning_rate": 3.9485261768587775e-05,
      "loss": 0.0686,
      "step": 31560
    },
    {
      "epoch": 0.6313242410910691,
      "grad_norm": 0.10851506888866425,
      "learning_rate": 3.9481928835206445e-05,
      "loss": 0.0471,
      "step": 31570
    },
    {
      "epoch": 0.6315242170939487,
      "grad_norm": 0.13852708041667938,
      "learning_rate": 3.9478595901825115e-05,
      "loss": 0.0566,
      "step": 31580
    },
    {
      "epoch": 0.6317241930968284,
      "grad_norm": 0.12621749937534332,
      "learning_rate": 3.947526296844379e-05,
      "loss": 0.1314,
      "step": 31590
    },
    {
      "epoch": 0.631924169099708,
      "grad_norm": 0.13934828341007233,
      "learning_rate": 3.947193003506246e-05,
      "loss": 0.0801,
      "step": 31600
    },
    {
      "epoch": 0.6321241451025877,
      "grad_norm": 0.13872385025024414,
      "learning_rate": 3.946859710168113e-05,
      "loss": 0.0883,
      "step": 31610
    },
    {
      "epoch": 0.6323241211054673,
      "grad_norm": 0.09471475332975388,
      "learning_rate": 3.946526416829981e-05,
      "loss": 0.0513,
      "step": 31620
    },
    {
      "epoch": 0.632524097108347,
      "grad_norm": 0.12308327853679657,
      "learning_rate": 3.946193123491848e-05,
      "loss": 0.0702,
      "step": 31630
    },
    {
      "epoch": 0.6327240731112267,
      "grad_norm": 0.09395255148410797,
      "learning_rate": 3.945859830153715e-05,
      "loss": 0.069,
      "step": 31640
    },
    {
      "epoch": 0.6329240491141063,
      "grad_norm": 0.07886991649866104,
      "learning_rate": 3.945526536815582e-05,
      "loss": 0.1385,
      "step": 31650
    },
    {
      "epoch": 0.633124025116986,
      "grad_norm": 0.11628125607967377,
      "learning_rate": 3.94519324347745e-05,
      "loss": 0.0621,
      "step": 31660
    },
    {
      "epoch": 0.6333240011198656,
      "grad_norm": 0.13874366879463196,
      "learning_rate": 3.944859950139317e-05,
      "loss": 0.0986,
      "step": 31670
    },
    {
      "epoch": 0.6335239771227452,
      "grad_norm": 0.17711003124713898,
      "learning_rate": 3.944526656801184e-05,
      "loss": 0.0903,
      "step": 31680
    },
    {
      "epoch": 0.6337239531256249,
      "grad_norm": 0.1103011816740036,
      "learning_rate": 3.9441933634630514e-05,
      "loss": 0.1091,
      "step": 31690
    },
    {
      "epoch": 0.6339239291285046,
      "grad_norm": 0.1693296730518341,
      "learning_rate": 3.9438600701249184e-05,
      "loss": 0.0972,
      "step": 31700
    },
    {
      "epoch": 0.6341239051313843,
      "grad_norm": 0.08180665969848633,
      "learning_rate": 3.9435267767867854e-05,
      "loss": 0.0752,
      "step": 31710
    },
    {
      "epoch": 0.6343238811342639,
      "grad_norm": 0.12786711752414703,
      "learning_rate": 3.943193483448653e-05,
      "loss": 0.0652,
      "step": 31720
    },
    {
      "epoch": 0.6345238571371435,
      "grad_norm": 0.09339073300361633,
      "learning_rate": 3.94286019011052e-05,
      "loss": 0.0574,
      "step": 31730
    },
    {
      "epoch": 0.6347238331400232,
      "grad_norm": 0.0907071977853775,
      "learning_rate": 3.9425268967723876e-05,
      "loss": 0.1035,
      "step": 31740
    },
    {
      "epoch": 0.6349238091429028,
      "grad_norm": 0.05153004825115204,
      "learning_rate": 3.942193603434255e-05,
      "loss": 0.0822,
      "step": 31750
    },
    {
      "epoch": 0.6351237851457825,
      "grad_norm": 0.14081494510173798,
      "learning_rate": 3.941860310096122e-05,
      "loss": 0.0859,
      "step": 31760
    },
    {
      "epoch": 0.6353237611486622,
      "grad_norm": 0.1481330245733261,
      "learning_rate": 3.941527016757989e-05,
      "loss": 0.0588,
      "step": 31770
    },
    {
      "epoch": 0.6355237371515419,
      "grad_norm": 0.19050656259059906,
      "learning_rate": 3.941193723419857e-05,
      "loss": 0.0995,
      "step": 31780
    },
    {
      "epoch": 0.6357237131544214,
      "grad_norm": 0.18147632479667664,
      "learning_rate": 3.940860430081724e-05,
      "loss": 0.0639,
      "step": 31790
    },
    {
      "epoch": 0.6359236891573011,
      "grad_norm": 0.06261356174945831,
      "learning_rate": 3.940527136743591e-05,
      "loss": 0.074,
      "step": 31800
    },
    {
      "epoch": 0.6361236651601808,
      "grad_norm": 0.18432509899139404,
      "learning_rate": 3.9401938434054584e-05,
      "loss": 0.1325,
      "step": 31810
    },
    {
      "epoch": 0.6363236411630604,
      "grad_norm": 0.07097593694925308,
      "learning_rate": 3.939860550067325e-05,
      "loss": 0.0728,
      "step": 31820
    },
    {
      "epoch": 0.6365236171659401,
      "grad_norm": 0.07852647453546524,
      "learning_rate": 3.939527256729192e-05,
      "loss": 0.0729,
      "step": 31830
    },
    {
      "epoch": 0.6367235931688198,
      "grad_norm": 0.13648833334445953,
      "learning_rate": 3.93919396339106e-05,
      "loss": 0.0482,
      "step": 31840
    },
    {
      "epoch": 0.6369235691716993,
      "grad_norm": 0.13557492196559906,
      "learning_rate": 3.9388606700529276e-05,
      "loss": 0.0766,
      "step": 31850
    },
    {
      "epoch": 0.637123545174579,
      "grad_norm": 0.08020002394914627,
      "learning_rate": 3.9385273767147945e-05,
      "loss": 0.5557,
      "step": 31860
    },
    {
      "epoch": 0.6373235211774587,
      "grad_norm": 0.20417487621307373,
      "learning_rate": 3.9381940833766615e-05,
      "loss": 0.1179,
      "step": 31870
    },
    {
      "epoch": 0.6375234971803384,
      "grad_norm": 0.1683131754398346,
      "learning_rate": 3.937860790038529e-05,
      "loss": 0.0807,
      "step": 31880
    },
    {
      "epoch": 0.637723473183218,
      "grad_norm": 0.08341848105192184,
      "learning_rate": 3.937527496700396e-05,
      "loss": 0.0661,
      "step": 31890
    },
    {
      "epoch": 0.6379234491860977,
      "grad_norm": 0.05647066980600357,
      "learning_rate": 3.937194203362263e-05,
      "loss": 0.0622,
      "step": 31900
    },
    {
      "epoch": 0.6381234251889774,
      "grad_norm": 0.16300003230571747,
      "learning_rate": 3.936860910024131e-05,
      "loss": 0.1078,
      "step": 31910
    },
    {
      "epoch": 0.6383234011918569,
      "grad_norm": 0.07074347138404846,
      "learning_rate": 3.9365276166859976e-05,
      "loss": 0.0828,
      "step": 31920
    },
    {
      "epoch": 0.6385233771947366,
      "grad_norm": 0.17772342264652252,
      "learning_rate": 3.9361943233478646e-05,
      "loss": 0.075,
      "step": 31930
    },
    {
      "epoch": 0.6387233531976163,
      "grad_norm": 0.0532466359436512,
      "learning_rate": 3.935861030009733e-05,
      "loss": 0.0817,
      "step": 31940
    },
    {
      "epoch": 0.638923329200496,
      "grad_norm": 0.1015288233757019,
      "learning_rate": 3.9355277366716e-05,
      "loss": 0.0865,
      "step": 31950
    },
    {
      "epoch": 0.6391233052033756,
      "grad_norm": 0.16606947779655457,
      "learning_rate": 3.935194443333467e-05,
      "loss": 0.1003,
      "step": 31960
    },
    {
      "epoch": 0.6393232812062553,
      "grad_norm": 0.12003728002309799,
      "learning_rate": 3.9348611499953345e-05,
      "loss": 0.0616,
      "step": 31970
    },
    {
      "epoch": 0.6395232572091349,
      "grad_norm": 0.05506474897265434,
      "learning_rate": 3.9345278566572014e-05,
      "loss": 0.0764,
      "step": 31980
    },
    {
      "epoch": 0.6397232332120145,
      "grad_norm": 0.10809334367513657,
      "learning_rate": 3.9341945633190684e-05,
      "loss": 0.1021,
      "step": 31990
    },
    {
      "epoch": 0.6399232092148942,
      "grad_norm": 0.15639320015907288,
      "learning_rate": 3.933861269980936e-05,
      "loss": 0.0824,
      "step": 32000
    },
    {
      "epoch": 0.6401231852177739,
      "grad_norm": 0.19430889189243317,
      "learning_rate": 3.933527976642803e-05,
      "loss": 0.0898,
      "step": 32010
    },
    {
      "epoch": 0.6403231612206535,
      "grad_norm": 0.15605202317237854,
      "learning_rate": 3.93319468330467e-05,
      "loss": 0.0882,
      "step": 32020
    },
    {
      "epoch": 0.6405231372235332,
      "grad_norm": 0.16649296879768372,
      "learning_rate": 3.9328613899665376e-05,
      "loss": 0.0741,
      "step": 32030
    },
    {
      "epoch": 0.6407231132264128,
      "grad_norm": 0.08789306879043579,
      "learning_rate": 3.932528096628405e-05,
      "loss": 0.0651,
      "step": 32040
    },
    {
      "epoch": 0.6409230892292925,
      "grad_norm": 0.14006255567073822,
      "learning_rate": 3.932194803290272e-05,
      "loss": 0.1001,
      "step": 32050
    },
    {
      "epoch": 0.6411230652321721,
      "grad_norm": 0.17535683512687683,
      "learning_rate": 3.931861509952139e-05,
      "loss": 0.0927,
      "step": 32060
    },
    {
      "epoch": 0.6413230412350518,
      "grad_norm": 0.07771418243646622,
      "learning_rate": 3.931528216614007e-05,
      "loss": 0.0558,
      "step": 32070
    },
    {
      "epoch": 0.6415230172379315,
      "grad_norm": 0.11587502062320709,
      "learning_rate": 3.931194923275874e-05,
      "loss": 0.029,
      "step": 32080
    },
    {
      "epoch": 0.6417229932408111,
      "grad_norm": 0.0998367965221405,
      "learning_rate": 3.930861629937741e-05,
      "loss": 0.0707,
      "step": 32090
    },
    {
      "epoch": 0.6419229692436907,
      "grad_norm": 0.07137276977300644,
      "learning_rate": 3.9305283365996084e-05,
      "loss": 0.0694,
      "step": 32100
    },
    {
      "epoch": 0.6421229452465704,
      "grad_norm": 0.18716487288475037,
      "learning_rate": 3.930195043261475e-05,
      "loss": 0.0738,
      "step": 32110
    },
    {
      "epoch": 0.6423229212494501,
      "grad_norm": 0.19375424087047577,
      "learning_rate": 3.929861749923342e-05,
      "loss": 0.077,
      "step": 32120
    },
    {
      "epoch": 0.6425228972523297,
      "grad_norm": 0.06352880597114563,
      "learning_rate": 3.92952845658521e-05,
      "loss": 0.0743,
      "step": 32130
    },
    {
      "epoch": 0.6427228732552094,
      "grad_norm": 0.15412186086177826,
      "learning_rate": 3.9291951632470776e-05,
      "loss": 0.0799,
      "step": 32140
    },
    {
      "epoch": 0.6429228492580891,
      "grad_norm": 0.0965413898229599,
      "learning_rate": 3.9288618699089445e-05,
      "loss": 0.068,
      "step": 32150
    },
    {
      "epoch": 0.6431228252609686,
      "grad_norm": 0.20651410520076752,
      "learning_rate": 3.928528576570812e-05,
      "loss": 0.0644,
      "step": 32160
    },
    {
      "epoch": 0.6433228012638483,
      "grad_norm": 0.20039565861225128,
      "learning_rate": 3.928195283232679e-05,
      "loss": 0.1002,
      "step": 32170
    },
    {
      "epoch": 0.643522777266728,
      "grad_norm": 0.09810954332351685,
      "learning_rate": 3.927861989894546e-05,
      "loss": 0.0647,
      "step": 32180
    },
    {
      "epoch": 0.6437227532696076,
      "grad_norm": 0.14771407842636108,
      "learning_rate": 3.927528696556414e-05,
      "loss": 0.0828,
      "step": 32190
    },
    {
      "epoch": 0.6439227292724873,
      "grad_norm": 0.08584088832139969,
      "learning_rate": 3.927195403218281e-05,
      "loss": 0.058,
      "step": 32200
    },
    {
      "epoch": 0.644122705275367,
      "grad_norm": 0.0948195606470108,
      "learning_rate": 3.926862109880148e-05,
      "loss": 0.0683,
      "step": 32210
    },
    {
      "epoch": 0.6443226812782467,
      "grad_norm": 0.17858512699604034,
      "learning_rate": 3.926528816542015e-05,
      "loss": 0.1075,
      "step": 32220
    },
    {
      "epoch": 0.6445226572811262,
      "grad_norm": 0.17717351019382477,
      "learning_rate": 3.926195523203882e-05,
      "loss": 0.0673,
      "step": 32230
    },
    {
      "epoch": 0.6447226332840059,
      "grad_norm": 0.088337741792202,
      "learning_rate": 3.925862229865749e-05,
      "loss": 0.0969,
      "step": 32240
    },
    {
      "epoch": 0.6449226092868856,
      "grad_norm": 0.14407747983932495,
      "learning_rate": 3.925528936527617e-05,
      "loss": 0.0843,
      "step": 32250
    },
    {
      "epoch": 0.6451225852897652,
      "grad_norm": 0.11584509909152985,
      "learning_rate": 3.9251956431894845e-05,
      "loss": 0.07,
      "step": 32260
    },
    {
      "epoch": 0.6453225612926449,
      "grad_norm": 0.08102400600910187,
      "learning_rate": 3.9248623498513515e-05,
      "loss": 0.0799,
      "step": 32270
    },
    {
      "epoch": 0.6455225372955246,
      "grad_norm": 0.06417810171842575,
      "learning_rate": 3.9245290565132184e-05,
      "loss": 0.1069,
      "step": 32280
    },
    {
      "epoch": 0.6457225132984042,
      "grad_norm": 0.08444461226463318,
      "learning_rate": 3.924195763175086e-05,
      "loss": 0.0597,
      "step": 32290
    },
    {
      "epoch": 0.6459224893012838,
      "grad_norm": 0.1748191863298416,
      "learning_rate": 3.923862469836953e-05,
      "loss": 0.0799,
      "step": 32300
    },
    {
      "epoch": 0.6461224653041635,
      "grad_norm": 0.13142965734004974,
      "learning_rate": 3.92352917649882e-05,
      "loss": 0.0655,
      "step": 32310
    },
    {
      "epoch": 0.6463224413070432,
      "grad_norm": 0.1006617322564125,
      "learning_rate": 3.9231958831606876e-05,
      "loss": 0.0843,
      "step": 32320
    },
    {
      "epoch": 0.6465224173099228,
      "grad_norm": 0.16108538210391998,
      "learning_rate": 3.9228625898225546e-05,
      "loss": 0.0692,
      "step": 32330
    },
    {
      "epoch": 0.6467223933128025,
      "grad_norm": 0.11999744921922684,
      "learning_rate": 3.9225292964844216e-05,
      "loss": 0.0531,
      "step": 32340
    },
    {
      "epoch": 0.6469223693156821,
      "grad_norm": 0.14783602952957153,
      "learning_rate": 3.92219600314629e-05,
      "loss": 0.1023,
      "step": 32350
    },
    {
      "epoch": 0.6471223453185617,
      "grad_norm": 0.12524878978729248,
      "learning_rate": 3.921862709808157e-05,
      "loss": 0.0926,
      "step": 32360
    },
    {
      "epoch": 0.6473223213214414,
      "grad_norm": 0.061485789716243744,
      "learning_rate": 3.921529416470024e-05,
      "loss": 0.0964,
      "step": 32370
    },
    {
      "epoch": 0.6475222973243211,
      "grad_norm": 0.10449337959289551,
      "learning_rate": 3.9211961231318914e-05,
      "loss": 0.0566,
      "step": 32380
    },
    {
      "epoch": 0.6477222733272008,
      "grad_norm": 0.17682653665542603,
      "learning_rate": 3.9208628297937584e-05,
      "loss": 0.1123,
      "step": 32390
    },
    {
      "epoch": 0.6479222493300804,
      "grad_norm": 0.07117565721273422,
      "learning_rate": 3.9205295364556254e-05,
      "loss": 0.0495,
      "step": 32400
    },
    {
      "epoch": 0.64812222533296,
      "grad_norm": 0.19264823198318481,
      "learning_rate": 3.920196243117493e-05,
      "loss": 0.0898,
      "step": 32410
    },
    {
      "epoch": 0.6483222013358397,
      "grad_norm": 0.1831749677658081,
      "learning_rate": 3.91986294977936e-05,
      "loss": 0.0655,
      "step": 32420
    },
    {
      "epoch": 0.6485221773387193,
      "grad_norm": 0.10795891284942627,
      "learning_rate": 3.919529656441227e-05,
      "loss": 0.0864,
      "step": 32430
    },
    {
      "epoch": 0.648722153341599,
      "grad_norm": 0.16486895084381104,
      "learning_rate": 3.9191963631030946e-05,
      "loss": 0.0883,
      "step": 32440
    },
    {
      "epoch": 0.6489221293444787,
      "grad_norm": 0.08801336586475372,
      "learning_rate": 3.918863069764962e-05,
      "loss": 0.0649,
      "step": 32450
    },
    {
      "epoch": 0.6491221053473584,
      "grad_norm": 0.13930143415927887,
      "learning_rate": 3.918529776426829e-05,
      "loss": 0.0709,
      "step": 32460
    },
    {
      "epoch": 0.649322081350238,
      "grad_norm": 0.10971266776323318,
      "learning_rate": 3.918196483088696e-05,
      "loss": 0.0779,
      "step": 32470
    },
    {
      "epoch": 0.6495220573531176,
      "grad_norm": 0.08551733940839767,
      "learning_rate": 3.917863189750564e-05,
      "loss": 0.0984,
      "step": 32480
    },
    {
      "epoch": 0.6497220333559973,
      "grad_norm": 0.10570266842842102,
      "learning_rate": 3.917529896412431e-05,
      "loss": 0.0529,
      "step": 32490
    },
    {
      "epoch": 0.6499220093588769,
      "grad_norm": 0.1684621423482895,
      "learning_rate": 3.917196603074298e-05,
      "loss": 0.0627,
      "step": 32500
    },
    {
      "epoch": 0.6501219853617566,
      "grad_norm": 0.06243157386779785,
      "learning_rate": 3.916863309736165e-05,
      "loss": 0.0827,
      "step": 32510
    },
    {
      "epoch": 0.6503219613646363,
      "grad_norm": 0.08027391880750656,
      "learning_rate": 3.916530016398032e-05,
      "loss": 0.0807,
      "step": 32520
    },
    {
      "epoch": 0.6505219373675158,
      "grad_norm": 0.15508492290973663,
      "learning_rate": 3.916196723059899e-05,
      "loss": 0.0951,
      "step": 32530
    },
    {
      "epoch": 0.6507219133703955,
      "grad_norm": 0.1233825758099556,
      "learning_rate": 3.915863429721767e-05,
      "loss": 0.0826,
      "step": 32540
    },
    {
      "epoch": 0.6509218893732752,
      "grad_norm": 0.09000841528177261,
      "learning_rate": 3.9155301363836345e-05,
      "loss": 0.0672,
      "step": 32550
    },
    {
      "epoch": 0.6511218653761549,
      "grad_norm": 0.09834129363298416,
      "learning_rate": 3.9151968430455015e-05,
      "loss": 0.0881,
      "step": 32560
    },
    {
      "epoch": 0.6513218413790345,
      "grad_norm": 0.11546294391155243,
      "learning_rate": 3.914863549707369e-05,
      "loss": 0.0723,
      "step": 32570
    },
    {
      "epoch": 0.6515218173819142,
      "grad_norm": 0.08619368076324463,
      "learning_rate": 3.914530256369236e-05,
      "loss": 0.0836,
      "step": 32580
    },
    {
      "epoch": 0.6517217933847939,
      "grad_norm": 0.1355409473180771,
      "learning_rate": 3.914196963031103e-05,
      "loss": 0.0831,
      "step": 32590
    },
    {
      "epoch": 0.6519217693876734,
      "grad_norm": 0.169729545712471,
      "learning_rate": 3.913863669692971e-05,
      "loss": 0.0992,
      "step": 32600
    },
    {
      "epoch": 0.6521217453905531,
      "grad_norm": 0.1517000049352646,
      "learning_rate": 3.9135303763548376e-05,
      "loss": 0.062,
      "step": 32610
    },
    {
      "epoch": 0.6523217213934328,
      "grad_norm": 0.07709638774394989,
      "learning_rate": 3.9131970830167046e-05,
      "loss": 0.0805,
      "step": 32620
    },
    {
      "epoch": 0.6525216973963125,
      "grad_norm": 0.0771888941526413,
      "learning_rate": 3.912863789678572e-05,
      "loss": 0.1078,
      "step": 32630
    },
    {
      "epoch": 0.6527216733991921,
      "grad_norm": 0.20874929428100586,
      "learning_rate": 3.912530496340439e-05,
      "loss": 0.1064,
      "step": 32640
    },
    {
      "epoch": 0.6529216494020718,
      "grad_norm": 0.09042316675186157,
      "learning_rate": 3.912197203002307e-05,
      "loss": 0.0685,
      "step": 32650
    },
    {
      "epoch": 0.6531216254049514,
      "grad_norm": 0.1746053546667099,
      "learning_rate": 3.911863909664174e-05,
      "loss": 0.1036,
      "step": 32660
    },
    {
      "epoch": 0.653321601407831,
      "grad_norm": 0.10814530402421951,
      "learning_rate": 3.9115306163260414e-05,
      "loss": 0.1692,
      "step": 32670
    },
    {
      "epoch": 0.6535215774107107,
      "grad_norm": 0.12719833850860596,
      "learning_rate": 3.9111973229879084e-05,
      "loss": 0.0919,
      "step": 32680
    },
    {
      "epoch": 0.6537215534135904,
      "grad_norm": 0.16870824992656708,
      "learning_rate": 3.9108640296497754e-05,
      "loss": 0.0591,
      "step": 32690
    },
    {
      "epoch": 0.65392152941647,
      "grad_norm": 0.1879015564918518,
      "learning_rate": 3.910530736311643e-05,
      "loss": 0.1383,
      "step": 32700
    },
    {
      "epoch": 0.6541215054193497,
      "grad_norm": 0.08376310020685196,
      "learning_rate": 3.91019744297351e-05,
      "loss": 0.1055,
      "step": 32710
    },
    {
      "epoch": 0.6543214814222293,
      "grad_norm": 0.14156857132911682,
      "learning_rate": 3.909864149635377e-05,
      "loss": 0.0792,
      "step": 32720
    },
    {
      "epoch": 0.654521457425109,
      "grad_norm": 0.1896413117647171,
      "learning_rate": 3.9095308562972446e-05,
      "loss": 0.0708,
      "step": 32730
    },
    {
      "epoch": 0.6547214334279886,
      "grad_norm": 0.16300921142101288,
      "learning_rate": 3.9091975629591115e-05,
      "loss": 0.0966,
      "step": 32740
    },
    {
      "epoch": 0.6549214094308683,
      "grad_norm": 0.07315964996814728,
      "learning_rate": 3.9088642696209785e-05,
      "loss": 0.0577,
      "step": 32750
    },
    {
      "epoch": 0.655121385433748,
      "grad_norm": 0.1841319054365158,
      "learning_rate": 3.908530976282847e-05,
      "loss": 0.1024,
      "step": 32760
    },
    {
      "epoch": 0.6553213614366276,
      "grad_norm": 0.10106105357408524,
      "learning_rate": 3.908197682944714e-05,
      "loss": 0.0662,
      "step": 32770
    },
    {
      "epoch": 0.6555213374395072,
      "grad_norm": 0.12852473556995392,
      "learning_rate": 3.907864389606581e-05,
      "loss": 0.065,
      "step": 32780
    },
    {
      "epoch": 0.6557213134423869,
      "grad_norm": 0.13894914090633392,
      "learning_rate": 3.9075310962684484e-05,
      "loss": 0.0943,
      "step": 32790
    },
    {
      "epoch": 0.6559212894452666,
      "grad_norm": 0.14427180588245392,
      "learning_rate": 3.907197802930315e-05,
      "loss": 0.0952,
      "step": 32800
    },
    {
      "epoch": 0.6561212654481462,
      "grad_norm": 0.09805946052074432,
      "learning_rate": 3.906864509592182e-05,
      "loss": 0.0824,
      "step": 32810
    },
    {
      "epoch": 0.6563212414510259,
      "grad_norm": 0.1326431781053543,
      "learning_rate": 3.90653121625405e-05,
      "loss": 0.0911,
      "step": 32820
    },
    {
      "epoch": 0.6565212174539056,
      "grad_norm": 0.1394294649362564,
      "learning_rate": 3.906197922915917e-05,
      "loss": 0.0545,
      "step": 32830
    },
    {
      "epoch": 0.6567211934567851,
      "grad_norm": 0.07602877914905548,
      "learning_rate": 3.905864629577784e-05,
      "loss": 0.0797,
      "step": 32840
    },
    {
      "epoch": 0.6569211694596648,
      "grad_norm": 0.1213281899690628,
      "learning_rate": 3.9055313362396515e-05,
      "loss": 0.0872,
      "step": 32850
    },
    {
      "epoch": 0.6571211454625445,
      "grad_norm": 0.22733169794082642,
      "learning_rate": 3.905198042901519e-05,
      "loss": 0.0683,
      "step": 32860
    },
    {
      "epoch": 0.6573211214654241,
      "grad_norm": 0.07801477611064911,
      "learning_rate": 3.904864749563386e-05,
      "loss": 0.0756,
      "step": 32870
    },
    {
      "epoch": 0.6575210974683038,
      "grad_norm": 0.09605415910482407,
      "learning_rate": 3.904531456225253e-05,
      "loss": 0.0576,
      "step": 32880
    },
    {
      "epoch": 0.6577210734711835,
      "grad_norm": 0.14659081399440765,
      "learning_rate": 3.904198162887121e-05,
      "loss": 0.0859,
      "step": 32890
    },
    {
      "epoch": 0.6579210494740632,
      "grad_norm": 0.19494830071926117,
      "learning_rate": 3.903864869548988e-05,
      "loss": 0.0922,
      "step": 32900
    },
    {
      "epoch": 0.6581210254769427,
      "grad_norm": 0.17190302908420563,
      "learning_rate": 3.9035315762108546e-05,
      "loss": 0.0733,
      "step": 32910
    },
    {
      "epoch": 0.6583210014798224,
      "grad_norm": 0.08349712193012238,
      "learning_rate": 3.903198282872722e-05,
      "loss": 0.0344,
      "step": 32920
    },
    {
      "epoch": 0.6585209774827021,
      "grad_norm": 0.10237427800893784,
      "learning_rate": 3.902864989534589e-05,
      "loss": 0.0553,
      "step": 32930
    },
    {
      "epoch": 0.6587209534855817,
      "grad_norm": 0.11558371782302856,
      "learning_rate": 3.902531696196456e-05,
      "loss": 0.0738,
      "step": 32940
    },
    {
      "epoch": 0.6589209294884614,
      "grad_norm": 0.16176769137382507,
      "learning_rate": 3.902198402858324e-05,
      "loss": 0.1195,
      "step": 32950
    },
    {
      "epoch": 0.6591209054913411,
      "grad_norm": 0.09799093008041382,
      "learning_rate": 3.9018651095201915e-05,
      "loss": 0.0887,
      "step": 32960
    },
    {
      "epoch": 0.6593208814942207,
      "grad_norm": 0.1014624610543251,
      "learning_rate": 3.9015318161820584e-05,
      "loss": 0.116,
      "step": 32970
    },
    {
      "epoch": 0.6595208574971003,
      "grad_norm": 0.13100361824035645,
      "learning_rate": 3.901198522843926e-05,
      "loss": 0.074,
      "step": 32980
    },
    {
      "epoch": 0.65972083349998,
      "grad_norm": 0.12337171286344528,
      "learning_rate": 3.900865229505793e-05,
      "loss": 0.0537,
      "step": 32990
    },
    {
      "epoch": 0.6599208095028597,
      "grad_norm": 0.089015431702137,
      "learning_rate": 3.90053193616766e-05,
      "loss": 0.0711,
      "step": 33000
    },
    {
      "epoch": 0.6601207855057393,
      "grad_norm": 0.08260069787502289,
      "learning_rate": 3.9001986428295276e-05,
      "loss": 0.0619,
      "step": 33010
    },
    {
      "epoch": 0.660320761508619,
      "grad_norm": 0.17782147228717804,
      "learning_rate": 3.8998653494913946e-05,
      "loss": 0.0571,
      "step": 33020
    },
    {
      "epoch": 0.6605207375114986,
      "grad_norm": 0.0804714560508728,
      "learning_rate": 3.8995320561532616e-05,
      "loss": 0.0889,
      "step": 33030
    },
    {
      "epoch": 0.6607207135143782,
      "grad_norm": 0.04614666849374771,
      "learning_rate": 3.899198762815129e-05,
      "loss": 0.0749,
      "step": 33040
    },
    {
      "epoch": 0.6609206895172579,
      "grad_norm": 0.1746084988117218,
      "learning_rate": 3.898865469476996e-05,
      "loss": 0.0942,
      "step": 33050
    },
    {
      "epoch": 0.6611206655201376,
      "grad_norm": 0.16084226965904236,
      "learning_rate": 3.898532176138864e-05,
      "loss": 0.0742,
      "step": 33060
    },
    {
      "epoch": 0.6613206415230173,
      "grad_norm": 0.16031046211719513,
      "learning_rate": 3.898198882800731e-05,
      "loss": 0.0719,
      "step": 33070
    },
    {
      "epoch": 0.6615206175258969,
      "grad_norm": 0.14306437969207764,
      "learning_rate": 3.8978655894625984e-05,
      "loss": 0.0457,
      "step": 33080
    },
    {
      "epoch": 0.6617205935287765,
      "grad_norm": 0.1441912055015564,
      "learning_rate": 3.8975322961244654e-05,
      "loss": 0.0902,
      "step": 33090
    },
    {
      "epoch": 0.6619205695316562,
      "grad_norm": 0.186701238155365,
      "learning_rate": 3.897199002786332e-05,
      "loss": 0.0892,
      "step": 33100
    },
    {
      "epoch": 0.6621205455345358,
      "grad_norm": 0.11329113692045212,
      "learning_rate": 3.8968657094482e-05,
      "loss": 0.0644,
      "step": 33110
    },
    {
      "epoch": 0.6623205215374155,
      "grad_norm": 0.10052701830863953,
      "learning_rate": 3.896532416110067e-05,
      "loss": 0.0573,
      "step": 33120
    },
    {
      "epoch": 0.6625204975402952,
      "grad_norm": 0.0875769555568695,
      "learning_rate": 3.896199122771934e-05,
      "loss": 0.0961,
      "step": 33130
    },
    {
      "epoch": 0.6627204735431749,
      "grad_norm": 0.10789458453655243,
      "learning_rate": 3.8958658294338015e-05,
      "loss": 0.0981,
      "step": 33140
    },
    {
      "epoch": 0.6629204495460544,
      "grad_norm": 0.11057034134864807,
      "learning_rate": 3.8955325360956685e-05,
      "loss": 0.0594,
      "step": 33150
    },
    {
      "epoch": 0.6631204255489341,
      "grad_norm": 0.15879803895950317,
      "learning_rate": 3.8951992427575354e-05,
      "loss": 0.1141,
      "step": 33160
    },
    {
      "epoch": 0.6633204015518138,
      "grad_norm": 0.11014849692583084,
      "learning_rate": 3.894865949419403e-05,
      "loss": 0.0674,
      "step": 33170
    },
    {
      "epoch": 0.6635203775546934,
      "grad_norm": 0.12415362894535065,
      "learning_rate": 3.894532656081271e-05,
      "loss": 0.0749,
      "step": 33180
    },
    {
      "epoch": 0.6637203535575731,
      "grad_norm": 0.15655024349689484,
      "learning_rate": 3.894199362743138e-05,
      "loss": 0.0888,
      "step": 33190
    },
    {
      "epoch": 0.6639203295604528,
      "grad_norm": 0.06694170087575912,
      "learning_rate": 3.8938660694050046e-05,
      "loss": 0.0915,
      "step": 33200
    },
    {
      "epoch": 0.6641203055633323,
      "grad_norm": 0.10751647502183914,
      "learning_rate": 3.893532776066872e-05,
      "loss": 0.084,
      "step": 33210
    },
    {
      "epoch": 0.664320281566212,
      "grad_norm": 0.09070112556219101,
      "learning_rate": 3.893199482728739e-05,
      "loss": 0.0478,
      "step": 33220
    },
    {
      "epoch": 0.6645202575690917,
      "grad_norm": 0.16932515799999237,
      "learning_rate": 3.892866189390606e-05,
      "loss": 0.0979,
      "step": 33230
    },
    {
      "epoch": 0.6647202335719714,
      "grad_norm": 0.20230761170387268,
      "learning_rate": 3.892532896052474e-05,
      "loss": 0.1072,
      "step": 33240
    },
    {
      "epoch": 0.664920209574851,
      "grad_norm": 0.21144552528858185,
      "learning_rate": 3.892199602714341e-05,
      "loss": 0.0679,
      "step": 33250
    },
    {
      "epoch": 0.6651201855777307,
      "grad_norm": 0.1790788471698761,
      "learning_rate": 3.8918663093762084e-05,
      "loss": 0.088,
      "step": 33260
    },
    {
      "epoch": 0.6653201615806104,
      "grad_norm": 0.07016649842262268,
      "learning_rate": 3.891533016038076e-05,
      "loss": 0.0644,
      "step": 33270
    },
    {
      "epoch": 0.6655201375834899,
      "grad_norm": 0.16932412981987,
      "learning_rate": 3.891199722699943e-05,
      "loss": 0.0727,
      "step": 33280
    },
    {
      "epoch": 0.6657201135863696,
      "grad_norm": 0.06202666461467743,
      "learning_rate": 3.89086642936181e-05,
      "loss": 0.0597,
      "step": 33290
    },
    {
      "epoch": 0.6659200895892493,
      "grad_norm": 0.2037808895111084,
      "learning_rate": 3.8905331360236776e-05,
      "loss": 0.1938,
      "step": 33300
    },
    {
      "epoch": 0.666120065592129,
      "grad_norm": 0.14965219795703888,
      "learning_rate": 3.8901998426855446e-05,
      "loss": 0.074,
      "step": 33310
    },
    {
      "epoch": 0.6663200415950086,
      "grad_norm": 0.13598832488059998,
      "learning_rate": 3.8898665493474116e-05,
      "loss": 0.077,
      "step": 33320
    },
    {
      "epoch": 0.6665200175978883,
      "grad_norm": 0.052195534110069275,
      "learning_rate": 3.889533256009279e-05,
      "loss": 0.0409,
      "step": 33330
    },
    {
      "epoch": 0.666719993600768,
      "grad_norm": 0.15350863337516785,
      "learning_rate": 3.889199962671146e-05,
      "loss": 0.1141,
      "step": 33340
    },
    {
      "epoch": 0.6669199696036475,
      "grad_norm": 0.13092336058616638,
      "learning_rate": 3.888866669333013e-05,
      "loss": 0.0724,
      "step": 33350
    },
    {
      "epoch": 0.6671199456065272,
      "grad_norm": 0.13207516074180603,
      "learning_rate": 3.888533375994881e-05,
      "loss": 0.0949,
      "step": 33360
    },
    {
      "epoch": 0.6673199216094069,
      "grad_norm": 0.09902345389127731,
      "learning_rate": 3.8882000826567484e-05,
      "loss": 0.0993,
      "step": 33370
    },
    {
      "epoch": 0.6675198976122865,
      "grad_norm": 0.1533830314874649,
      "learning_rate": 3.8878667893186154e-05,
      "loss": 0.0866,
      "step": 33380
    },
    {
      "epoch": 0.6677198736151662,
      "grad_norm": 0.1732582449913025,
      "learning_rate": 3.887533495980482e-05,
      "loss": 0.0923,
      "step": 33390
    },
    {
      "epoch": 0.6679198496180458,
      "grad_norm": 0.10505568236112595,
      "learning_rate": 3.88720020264235e-05,
      "loss": 0.0959,
      "step": 33400
    },
    {
      "epoch": 0.6681198256209255,
      "grad_norm": 0.06997473537921906,
      "learning_rate": 3.886866909304217e-05,
      "loss": 0.0677,
      "step": 33410
    },
    {
      "epoch": 0.6683198016238051,
      "grad_norm": 0.11979850381612778,
      "learning_rate": 3.886533615966084e-05,
      "loss": 0.0786,
      "step": 33420
    },
    {
      "epoch": 0.6685197776266848,
      "grad_norm": 0.06975629180669785,
      "learning_rate": 3.8862003226279515e-05,
      "loss": 0.0515,
      "step": 33430
    },
    {
      "epoch": 0.6687197536295645,
      "grad_norm": 0.07559304684400558,
      "learning_rate": 3.8858670292898185e-05,
      "loss": 0.0609,
      "step": 33440
    },
    {
      "epoch": 0.6689197296324441,
      "grad_norm": 0.10401049256324768,
      "learning_rate": 3.8855337359516855e-05,
      "loss": 0.0541,
      "step": 33450
    },
    {
      "epoch": 0.6691197056353237,
      "grad_norm": 0.07980838418006897,
      "learning_rate": 3.885200442613553e-05,
      "loss": 0.0698,
      "step": 33460
    },
    {
      "epoch": 0.6693196816382034,
      "grad_norm": 0.14149264991283417,
      "learning_rate": 3.884867149275421e-05,
      "loss": 0.0953,
      "step": 33470
    },
    {
      "epoch": 0.6695196576410831,
      "grad_norm": 0.17803813517093658,
      "learning_rate": 3.884533855937288e-05,
      "loss": 0.0568,
      "step": 33480
    },
    {
      "epoch": 0.6697196336439627,
      "grad_norm": 0.09699950367212296,
      "learning_rate": 3.884200562599155e-05,
      "loss": 0.0861,
      "step": 33490
    },
    {
      "epoch": 0.6699196096468424,
      "grad_norm": 0.10020774602890015,
      "learning_rate": 3.883867269261022e-05,
      "loss": 0.0559,
      "step": 33500
    },
    {
      "epoch": 0.6701195856497221,
      "grad_norm": 0.07816280424594879,
      "learning_rate": 3.883533975922889e-05,
      "loss": 0.0995,
      "step": 33510
    },
    {
      "epoch": 0.6703195616526016,
      "grad_norm": 0.12287189066410065,
      "learning_rate": 3.883200682584757e-05,
      "loss": 0.0635,
      "step": 33520
    },
    {
      "epoch": 0.6705195376554813,
      "grad_norm": 0.12353210896253586,
      "learning_rate": 3.882867389246624e-05,
      "loss": 0.0798,
      "step": 33530
    },
    {
      "epoch": 0.670719513658361,
      "grad_norm": 0.15077924728393555,
      "learning_rate": 3.882534095908491e-05,
      "loss": 0.079,
      "step": 33540
    },
    {
      "epoch": 0.6709194896612406,
      "grad_norm": 0.16360943019390106,
      "learning_rate": 3.8822008025703585e-05,
      "loss": 0.0845,
      "step": 33550
    },
    {
      "epoch": 0.6711194656641203,
      "grad_norm": 0.09862282127141953,
      "learning_rate": 3.8818675092322254e-05,
      "loss": 0.0499,
      "step": 33560
    },
    {
      "epoch": 0.671319441667,
      "grad_norm": 0.1662529557943344,
      "learning_rate": 3.881534215894093e-05,
      "loss": 0.0644,
      "step": 33570
    },
    {
      "epoch": 0.6715194176698797,
      "grad_norm": 0.11309051513671875,
      "learning_rate": 3.88120092255596e-05,
      "loss": 0.0956,
      "step": 33580
    },
    {
      "epoch": 0.6717193936727592,
      "grad_norm": 0.14823603630065918,
      "learning_rate": 3.880867629217828e-05,
      "loss": 0.0716,
      "step": 33590
    },
    {
      "epoch": 0.6719193696756389,
      "grad_norm": 0.1826688051223755,
      "learning_rate": 3.8805343358796946e-05,
      "loss": 0.0861,
      "step": 33600
    },
    {
      "epoch": 0.6721193456785186,
      "grad_norm": 0.2194415181875229,
      "learning_rate": 3.8802010425415616e-05,
      "loss": 0.0831,
      "step": 33610
    },
    {
      "epoch": 0.6723193216813982,
      "grad_norm": 0.18617042899131775,
      "learning_rate": 3.879867749203429e-05,
      "loss": 0.084,
      "step": 33620
    },
    {
      "epoch": 0.6725192976842779,
      "grad_norm": 0.1776837259531021,
      "learning_rate": 3.879534455865296e-05,
      "loss": 0.0757,
      "step": 33630
    },
    {
      "epoch": 0.6727192736871576,
      "grad_norm": 0.1774158626794815,
      "learning_rate": 3.879201162527163e-05,
      "loss": 0.0845,
      "step": 33640
    },
    {
      "epoch": 0.6729192496900372,
      "grad_norm": 0.10690324753522873,
      "learning_rate": 3.878867869189031e-05,
      "loss": 0.0689,
      "step": 33650
    },
    {
      "epoch": 0.6731192256929168,
      "grad_norm": 0.2019072026014328,
      "learning_rate": 3.878534575850898e-05,
      "loss": 0.0694,
      "step": 33660
    },
    {
      "epoch": 0.6733192016957965,
      "grad_norm": 0.1386154294013977,
      "learning_rate": 3.878201282512765e-05,
      "loss": 0.046,
      "step": 33670
    },
    {
      "epoch": 0.6735191776986762,
      "grad_norm": 0.1837855875492096,
      "learning_rate": 3.877867989174633e-05,
      "loss": 0.0747,
      "step": 33680
    },
    {
      "epoch": 0.6737191537015558,
      "grad_norm": 0.23617808520793915,
      "learning_rate": 3.8775346958365e-05,
      "loss": 0.102,
      "step": 33690
    },
    {
      "epoch": 0.6739191297044355,
      "grad_norm": 0.061686255037784576,
      "learning_rate": 3.877201402498367e-05,
      "loss": 0.0627,
      "step": 33700
    },
    {
      "epoch": 0.6741191057073151,
      "grad_norm": 0.07308144122362137,
      "learning_rate": 3.8768681091602346e-05,
      "loss": 0.0473,
      "step": 33710
    },
    {
      "epoch": 0.6743190817101947,
      "grad_norm": 0.12391246855258942,
      "learning_rate": 3.8765348158221016e-05,
      "loss": 0.0906,
      "step": 33720
    },
    {
      "epoch": 0.6745190577130744,
      "grad_norm": 0.24112917482852936,
      "learning_rate": 3.8762015224839685e-05,
      "loss": 0.0579,
      "step": 33730
    },
    {
      "epoch": 0.6747190337159541,
      "grad_norm": 0.0782790258526802,
      "learning_rate": 3.875868229145836e-05,
      "loss": 0.0545,
      "step": 33740
    },
    {
      "epoch": 0.6749190097188338,
      "grad_norm": 0.1057388186454773,
      "learning_rate": 3.875534935807703e-05,
      "loss": 0.0683,
      "step": 33750
    },
    {
      "epoch": 0.6751189857217134,
      "grad_norm": 0.11863946914672852,
      "learning_rate": 3.87520164246957e-05,
      "loss": 0.0945,
      "step": 33760
    },
    {
      "epoch": 0.675318961724593,
      "grad_norm": 0.14041419327259064,
      "learning_rate": 3.874868349131438e-05,
      "loss": 0.0702,
      "step": 33770
    },
    {
      "epoch": 0.6755189377274727,
      "grad_norm": 0.09020359069108963,
      "learning_rate": 3.8745350557933054e-05,
      "loss": 0.0907,
      "step": 33780
    },
    {
      "epoch": 0.6757189137303523,
      "grad_norm": 0.08752957731485367,
      "learning_rate": 3.874201762455172e-05,
      "loss": 0.081,
      "step": 33790
    },
    {
      "epoch": 0.675918889733232,
      "grad_norm": 0.15786683559417725,
      "learning_rate": 3.873868469117039e-05,
      "loss": 0.0746,
      "step": 33800
    },
    {
      "epoch": 0.6761188657361117,
      "grad_norm": 0.20623373985290527,
      "learning_rate": 3.873535175778907e-05,
      "loss": 0.0872,
      "step": 33810
    },
    {
      "epoch": 0.6763188417389914,
      "grad_norm": 0.0937785878777504,
      "learning_rate": 3.873201882440774e-05,
      "loss": 0.0922,
      "step": 33820
    },
    {
      "epoch": 0.676518817741871,
      "grad_norm": 0.09057466685771942,
      "learning_rate": 3.872868589102641e-05,
      "loss": 0.0749,
      "step": 33830
    },
    {
      "epoch": 0.6767187937447506,
      "grad_norm": 0.15880145132541656,
      "learning_rate": 3.8725352957645085e-05,
      "loss": 0.0793,
      "step": 33840
    },
    {
      "epoch": 0.6769187697476303,
      "grad_norm": 0.12155847251415253,
      "learning_rate": 3.8722020024263754e-05,
      "loss": 0.1019,
      "step": 33850
    },
    {
      "epoch": 0.6771187457505099,
      "grad_norm": 0.05497701093554497,
      "learning_rate": 3.8718687090882424e-05,
      "loss": 0.0739,
      "step": 33860
    },
    {
      "epoch": 0.6773187217533896,
      "grad_norm": 0.16813863813877106,
      "learning_rate": 3.87153541575011e-05,
      "loss": 0.0788,
      "step": 33870
    },
    {
      "epoch": 0.6775186977562693,
      "grad_norm": 0.09218920767307281,
      "learning_rate": 3.871202122411978e-05,
      "loss": 0.0831,
      "step": 33880
    },
    {
      "epoch": 0.6777186737591488,
      "grad_norm": 0.18665757775306702,
      "learning_rate": 3.8708688290738446e-05,
      "loss": 0.0903,
      "step": 33890
    },
    {
      "epoch": 0.6779186497620285,
      "grad_norm": 0.10490240901708603,
      "learning_rate": 3.870535535735712e-05,
      "loss": 0.0919,
      "step": 33900
    },
    {
      "epoch": 0.6781186257649082,
      "grad_norm": 0.1303505152463913,
      "learning_rate": 3.870202242397579e-05,
      "loss": 0.0648,
      "step": 33910
    },
    {
      "epoch": 0.6783186017677879,
      "grad_norm": 0.07308860123157501,
      "learning_rate": 3.869868949059446e-05,
      "loss": 0.083,
      "step": 33920
    },
    {
      "epoch": 0.6785185777706675,
      "grad_norm": 0.18273288011550903,
      "learning_rate": 3.869535655721314e-05,
      "loss": 0.0967,
      "step": 33930
    },
    {
      "epoch": 0.6787185537735472,
      "grad_norm": 0.061236850917339325,
      "learning_rate": 3.869202362383181e-05,
      "loss": 0.0844,
      "step": 33940
    },
    {
      "epoch": 0.6789185297764269,
      "grad_norm": 0.08408598601818085,
      "learning_rate": 3.868869069045048e-05,
      "loss": 0.073,
      "step": 33950
    },
    {
      "epoch": 0.6791185057793064,
      "grad_norm": 0.12020287662744522,
      "learning_rate": 3.8685357757069154e-05,
      "loss": 0.1035,
      "step": 33960
    },
    {
      "epoch": 0.6793184817821861,
      "grad_norm": 0.0724305659532547,
      "learning_rate": 3.8682024823687824e-05,
      "loss": 0.1052,
      "step": 33970
    },
    {
      "epoch": 0.6795184577850658,
      "grad_norm": 0.09784093499183655,
      "learning_rate": 3.86786918903065e-05,
      "loss": 0.0801,
      "step": 33980
    },
    {
      "epoch": 0.6797184337879455,
      "grad_norm": 0.08641184866428375,
      "learning_rate": 3.867535895692517e-05,
      "loss": 0.2744,
      "step": 33990
    },
    {
      "epoch": 0.6799184097908251,
      "grad_norm": 0.051846615970134735,
      "learning_rate": 3.8672026023543846e-05,
      "loss": 0.0747,
      "step": 34000
    },
    {
      "epoch": 0.6801183857937048,
      "grad_norm": 0.1509425789117813,
      "learning_rate": 3.8668693090162516e-05,
      "loss": 0.0784,
      "step": 34010
    },
    {
      "epoch": 0.6803183617965844,
      "grad_norm": 0.18588833510875702,
      "learning_rate": 3.8665360156781185e-05,
      "loss": 0.0677,
      "step": 34020
    },
    {
      "epoch": 0.680518337799464,
      "grad_norm": 0.0880637913942337,
      "learning_rate": 3.866202722339986e-05,
      "loss": 0.0764,
      "step": 34030
    },
    {
      "epoch": 0.6807183138023437,
      "grad_norm": 0.17378810048103333,
      "learning_rate": 3.865869429001853e-05,
      "loss": 0.0565,
      "step": 34040
    },
    {
      "epoch": 0.6809182898052234,
      "grad_norm": 0.14621376991271973,
      "learning_rate": 3.86553613566372e-05,
      "loss": 0.0602,
      "step": 34050
    },
    {
      "epoch": 0.681118265808103,
      "grad_norm": 0.2013193517923355,
      "learning_rate": 3.865202842325588e-05,
      "loss": 0.1065,
      "step": 34060
    },
    {
      "epoch": 0.6813182418109827,
      "grad_norm": 0.08178123086690903,
      "learning_rate": 3.864869548987455e-05,
      "loss": 0.0648,
      "step": 34070
    },
    {
      "epoch": 0.6815182178138623,
      "grad_norm": 0.18230916559696198,
      "learning_rate": 3.864536255649322e-05,
      "loss": 0.0762,
      "step": 34080
    },
    {
      "epoch": 0.681718193816742,
      "grad_norm": 0.10152728110551834,
      "learning_rate": 3.86420296231119e-05,
      "loss": 0.0677,
      "step": 34090
    },
    {
      "epoch": 0.6819181698196216,
      "grad_norm": 0.06951575726270676,
      "learning_rate": 3.863869668973057e-05,
      "loss": 0.082,
      "step": 34100
    },
    {
      "epoch": 0.6821181458225013,
      "grad_norm": 0.18630944192409515,
      "learning_rate": 3.863569704968738e-05,
      "loss": 0.4468,
      "step": 34110
    },
    {
      "epoch": 0.682318121825381,
      "grad_norm": 0.1652783900499344,
      "learning_rate": 3.863236411630605e-05,
      "loss": 0.0687,
      "step": 34120
    },
    {
      "epoch": 0.6825180978282606,
      "grad_norm": 0.3223066031932831,
      "learning_rate": 3.862903118292472e-05,
      "loss": 0.1145,
      "step": 34130
    },
    {
      "epoch": 0.6827180738311402,
      "grad_norm": 0.10733456164598465,
      "learning_rate": 3.8625698249543394e-05,
      "loss": 0.0902,
      "step": 34140
    },
    {
      "epoch": 0.6829180498340199,
      "grad_norm": 0.18611761927604675,
      "learning_rate": 3.862236531616206e-05,
      "loss": 0.0835,
      "step": 34150
    },
    {
      "epoch": 0.6831180258368996,
      "grad_norm": 0.16792556643486023,
      "learning_rate": 3.861903238278073e-05,
      "loss": 0.0758,
      "step": 34160
    },
    {
      "epoch": 0.6833180018397792,
      "grad_norm": 0.16871359944343567,
      "learning_rate": 3.861569944939941e-05,
      "loss": 0.0787,
      "step": 34170
    },
    {
      "epoch": 0.6835179778426589,
      "grad_norm": 0.17486292123794556,
      "learning_rate": 3.861236651601808e-05,
      "loss": 0.0641,
      "step": 34180
    },
    {
      "epoch": 0.6837179538455386,
      "grad_norm": 0.2728741466999054,
      "learning_rate": 3.860903358263675e-05,
      "loss": 0.09,
      "step": 34190
    },
    {
      "epoch": 0.6839179298484181,
      "grad_norm": 0.12039080262184143,
      "learning_rate": 3.8605700649255425e-05,
      "loss": 0.0944,
      "step": 34200
    },
    {
      "epoch": 0.6841179058512978,
      "grad_norm": 0.06353897601366043,
      "learning_rate": 3.86023677158741e-05,
      "loss": 0.0887,
      "step": 34210
    },
    {
      "epoch": 0.6843178818541775,
      "grad_norm": 0.19072873890399933,
      "learning_rate": 3.859903478249277e-05,
      "loss": 0.0785,
      "step": 34220
    },
    {
      "epoch": 0.6845178578570571,
      "grad_norm": 0.123263418674469,
      "learning_rate": 3.859570184911144e-05,
      "loss": 0.0547,
      "step": 34230
    },
    {
      "epoch": 0.6847178338599368,
      "grad_norm": 0.08928335458040237,
      "learning_rate": 3.859236891573012e-05,
      "loss": 0.0647,
      "step": 34240
    },
    {
      "epoch": 0.6849178098628165,
      "grad_norm": 0.06633295863866806,
      "learning_rate": 3.858903598234879e-05,
      "loss": 0.0861,
      "step": 34250
    },
    {
      "epoch": 0.6851177858656962,
      "grad_norm": 0.12268700450658798,
      "learning_rate": 3.8585703048967456e-05,
      "loss": 0.0612,
      "step": 34260
    },
    {
      "epoch": 0.6853177618685757,
      "grad_norm": 0.16161295771598816,
      "learning_rate": 3.858237011558613e-05,
      "loss": 0.0497,
      "step": 34270
    },
    {
      "epoch": 0.6855177378714554,
      "grad_norm": 0.15267708897590637,
      "learning_rate": 3.85790371822048e-05,
      "loss": 0.119,
      "step": 34280
    },
    {
      "epoch": 0.6857177138743351,
      "grad_norm": 0.046859726309776306,
      "learning_rate": 3.857570424882347e-05,
      "loss": 0.0668,
      "step": 34290
    },
    {
      "epoch": 0.6859176898772147,
      "grad_norm": 0.12279308587312698,
      "learning_rate": 3.857237131544215e-05,
      "loss": 0.077,
      "step": 34300
    },
    {
      "epoch": 0.6861176658800944,
      "grad_norm": 0.2092912793159485,
      "learning_rate": 3.8569038382060825e-05,
      "loss": 0.0819,
      "step": 34310
    },
    {
      "epoch": 0.6863176418829741,
      "grad_norm": 0.09314538538455963,
      "learning_rate": 3.8565705448679494e-05,
      "loss": 0.0615,
      "step": 34320
    },
    {
      "epoch": 0.6865176178858537,
      "grad_norm": 0.1382761150598526,
      "learning_rate": 3.856237251529817e-05,
      "loss": 0.1018,
      "step": 34330
    },
    {
      "epoch": 0.6867175938887333,
      "grad_norm": 0.06812943518161774,
      "learning_rate": 3.855903958191684e-05,
      "loss": 0.0917,
      "step": 34340
    },
    {
      "epoch": 0.686917569891613,
      "grad_norm": 0.05194054916501045,
      "learning_rate": 3.855570664853551e-05,
      "loss": 0.0777,
      "step": 34350
    },
    {
      "epoch": 0.6871175458944927,
      "grad_norm": 0.12659019231796265,
      "learning_rate": 3.8552373715154186e-05,
      "loss": 0.0628,
      "step": 34360
    },
    {
      "epoch": 0.6873175218973723,
      "grad_norm": 0.20668652653694153,
      "learning_rate": 3.8549040781772856e-05,
      "loss": 0.1051,
      "step": 34370
    },
    {
      "epoch": 0.687517497900252,
      "grad_norm": 0.10914907604455948,
      "learning_rate": 3.8545707848391526e-05,
      "loss": 0.097,
      "step": 34380
    },
    {
      "epoch": 0.6877174739031316,
      "grad_norm": 0.1220160648226738,
      "learning_rate": 3.85423749150102e-05,
      "loss": 0.094,
      "step": 34390
    },
    {
      "epoch": 0.6879174499060112,
      "grad_norm": 0.09797505289316177,
      "learning_rate": 3.853904198162887e-05,
      "loss": 0.0781,
      "step": 34400
    },
    {
      "epoch": 0.6881174259088909,
      "grad_norm": 0.17413435876369476,
      "learning_rate": 3.853570904824755e-05,
      "loss": 0.0697,
      "step": 34410
    },
    {
      "epoch": 0.6883174019117706,
      "grad_norm": 0.18167082965373993,
      "learning_rate": 3.853237611486622e-05,
      "loss": 0.0987,
      "step": 34420
    },
    {
      "epoch": 0.6885173779146503,
      "grad_norm": 0.11272080987691879,
      "learning_rate": 3.8529043181484894e-05,
      "loss": 0.056,
      "step": 34430
    },
    {
      "epoch": 0.6887173539175299,
      "grad_norm": 0.1135832667350769,
      "learning_rate": 3.8525710248103564e-05,
      "loss": 0.075,
      "step": 34440
    },
    {
      "epoch": 0.6889173299204095,
      "grad_norm": 0.12993213534355164,
      "learning_rate": 3.852237731472223e-05,
      "loss": 0.0475,
      "step": 34450
    },
    {
      "epoch": 0.6891173059232892,
      "grad_norm": 0.08346294611692429,
      "learning_rate": 3.851904438134091e-05,
      "loss": 0.0796,
      "step": 34460
    },
    {
      "epoch": 0.6893172819261688,
      "grad_norm": 0.08524709194898605,
      "learning_rate": 3.851571144795958e-05,
      "loss": 0.0902,
      "step": 34470
    },
    {
      "epoch": 0.6895172579290485,
      "grad_norm": 0.14621257781982422,
      "learning_rate": 3.851237851457825e-05,
      "loss": 0.0949,
      "step": 34480
    },
    {
      "epoch": 0.6897172339319282,
      "grad_norm": 0.0930144414305687,
      "learning_rate": 3.8509045581196925e-05,
      "loss": 0.0548,
      "step": 34490
    },
    {
      "epoch": 0.6899172099348079,
      "grad_norm": 0.08107222616672516,
      "learning_rate": 3.8505712647815595e-05,
      "loss": 0.0891,
      "step": 34500
    },
    {
      "epoch": 0.6901171859376874,
      "grad_norm": 0.23379725217819214,
      "learning_rate": 3.850237971443427e-05,
      "loss": 0.089,
      "step": 34510
    },
    {
      "epoch": 0.6903171619405671,
      "grad_norm": 0.07296288013458252,
      "learning_rate": 3.849904678105295e-05,
      "loss": 0.0515,
      "step": 34520
    },
    {
      "epoch": 0.6905171379434468,
      "grad_norm": 0.14734147489070892,
      "learning_rate": 3.849571384767162e-05,
      "loss": 0.0838,
      "step": 34530
    },
    {
      "epoch": 0.6907171139463264,
      "grad_norm": 0.09821539372205734,
      "learning_rate": 3.849238091429029e-05,
      "loss": 0.0458,
      "step": 34540
    },
    {
      "epoch": 0.6909170899492061,
      "grad_norm": 0.226103737950325,
      "learning_rate": 3.848904798090896e-05,
      "loss": 0.125,
      "step": 34550
    },
    {
      "epoch": 0.6911170659520858,
      "grad_norm": 0.16134612262248993,
      "learning_rate": 3.848571504752763e-05,
      "loss": 0.0774,
      "step": 34560
    },
    {
      "epoch": 0.6913170419549654,
      "grad_norm": 0.09397764503955841,
      "learning_rate": 3.84823821141463e-05,
      "loss": 0.0893,
      "step": 34570
    },
    {
      "epoch": 0.691517017957845,
      "grad_norm": 0.1135292798280716,
      "learning_rate": 3.847904918076498e-05,
      "loss": 0.0863,
      "step": 34580
    },
    {
      "epoch": 0.6917169939607247,
      "grad_norm": 0.1918269842863083,
      "learning_rate": 3.847571624738365e-05,
      "loss": 0.0851,
      "step": 34590
    },
    {
      "epoch": 0.6919169699636044,
      "grad_norm": 0.15561802685260773,
      "learning_rate": 3.847238331400232e-05,
      "loss": 0.0869,
      "step": 34600
    },
    {
      "epoch": 0.692116945966484,
      "grad_norm": 0.09355035424232483,
      "learning_rate": 3.8469050380620994e-05,
      "loss": 0.0689,
      "step": 34610
    },
    {
      "epoch": 0.6923169219693637,
      "grad_norm": 0.1626022905111313,
      "learning_rate": 3.846571744723967e-05,
      "loss": 0.0515,
      "step": 34620
    },
    {
      "epoch": 0.6925168979722434,
      "grad_norm": 0.19263237714767456,
      "learning_rate": 3.846238451385834e-05,
      "loss": 0.1089,
      "step": 34630
    },
    {
      "epoch": 0.6927168739751229,
      "grad_norm": 0.12758468091487885,
      "learning_rate": 3.845905158047701e-05,
      "loss": 0.0619,
      "step": 34640
    },
    {
      "epoch": 0.6929168499780026,
      "grad_norm": 0.09617248922586441,
      "learning_rate": 3.8455718647095686e-05,
      "loss": 0.0785,
      "step": 34650
    },
    {
      "epoch": 0.6931168259808823,
      "grad_norm": 0.11423587799072266,
      "learning_rate": 3.8452385713714356e-05,
      "loss": 0.0564,
      "step": 34660
    },
    {
      "epoch": 0.693316801983762,
      "grad_norm": 0.11562807857990265,
      "learning_rate": 3.8449052780333026e-05,
      "loss": 0.0418,
      "step": 34670
    },
    {
      "epoch": 0.6935167779866416,
      "grad_norm": 0.16405172646045685,
      "learning_rate": 3.84457198469517e-05,
      "loss": 0.0907,
      "step": 34680
    },
    {
      "epoch": 0.6937167539895213,
      "grad_norm": 0.10400868952274323,
      "learning_rate": 3.844238691357037e-05,
      "loss": 0.084,
      "step": 34690
    },
    {
      "epoch": 0.693916729992401,
      "grad_norm": 0.08016187697649002,
      "learning_rate": 3.843905398018904e-05,
      "loss": 0.0531,
      "step": 34700
    },
    {
      "epoch": 0.6941167059952805,
      "grad_norm": 0.15155749022960663,
      "learning_rate": 3.843572104680772e-05,
      "loss": 0.0715,
      "step": 34710
    },
    {
      "epoch": 0.6943166819981602,
      "grad_norm": 0.09445207566022873,
      "learning_rate": 3.8432388113426394e-05,
      "loss": 0.0752,
      "step": 34720
    },
    {
      "epoch": 0.6945166580010399,
      "grad_norm": 0.11041687428951263,
      "learning_rate": 3.8429055180045064e-05,
      "loss": 0.0823,
      "step": 34730
    },
    {
      "epoch": 0.6947166340039195,
      "grad_norm": 0.09362880885601044,
      "learning_rate": 3.842572224666374e-05,
      "loss": 0.075,
      "step": 34740
    },
    {
      "epoch": 0.6949166100067992,
      "grad_norm": 0.0741991475224495,
      "learning_rate": 3.842238931328241e-05,
      "loss": 0.0909,
      "step": 34750
    },
    {
      "epoch": 0.6951165860096788,
      "grad_norm": 0.20485763251781464,
      "learning_rate": 3.841905637990108e-05,
      "loss": 0.0773,
      "step": 34760
    },
    {
      "epoch": 0.6953165620125585,
      "grad_norm": 0.15718351304531097,
      "learning_rate": 3.8415723446519756e-05,
      "loss": 0.0713,
      "step": 34770
    },
    {
      "epoch": 0.6955165380154381,
      "grad_norm": 0.15088216960430145,
      "learning_rate": 3.8412390513138425e-05,
      "loss": 0.0834,
      "step": 34780
    },
    {
      "epoch": 0.6957165140183178,
      "grad_norm": 0.18173149228096008,
      "learning_rate": 3.8409057579757095e-05,
      "loss": 0.083,
      "step": 34790
    },
    {
      "epoch": 0.6959164900211975,
      "grad_norm": 0.05622616037726402,
      "learning_rate": 3.840572464637577e-05,
      "loss": 0.043,
      "step": 34800
    },
    {
      "epoch": 0.6961164660240771,
      "grad_norm": 0.12666083872318268,
      "learning_rate": 3.840239171299444e-05,
      "loss": 0.0651,
      "step": 34810
    },
    {
      "epoch": 0.6963164420269568,
      "grad_norm": 0.13267557322978973,
      "learning_rate": 3.839905877961312e-05,
      "loss": 0.0984,
      "step": 34820
    },
    {
      "epoch": 0.6965164180298364,
      "grad_norm": 0.12384171783924103,
      "learning_rate": 3.839572584623179e-05,
      "loss": 0.1126,
      "step": 34830
    },
    {
      "epoch": 0.6967163940327161,
      "grad_norm": 0.11401523649692535,
      "learning_rate": 3.839239291285046e-05,
      "loss": 0.0724,
      "step": 34840
    },
    {
      "epoch": 0.6969163700355957,
      "grad_norm": 0.05751529708504677,
      "learning_rate": 3.838905997946913e-05,
      "loss": 0.0441,
      "step": 34850
    },
    {
      "epoch": 0.6971163460384754,
      "grad_norm": 0.17657651007175446,
      "learning_rate": 3.83857270460878e-05,
      "loss": 0.0932,
      "step": 34860
    },
    {
      "epoch": 0.6973163220413551,
      "grad_norm": 0.15117743611335754,
      "learning_rate": 3.838239411270648e-05,
      "loss": 0.0693,
      "step": 34870
    },
    {
      "epoch": 0.6975162980442347,
      "grad_norm": 0.07891558110713959,
      "learning_rate": 3.837906117932515e-05,
      "loss": 0.0723,
      "step": 34880
    },
    {
      "epoch": 0.6977162740471143,
      "grad_norm": 0.12861816585063934,
      "learning_rate": 3.837572824594382e-05,
      "loss": 0.0686,
      "step": 34890
    },
    {
      "epoch": 0.697916250049994,
      "grad_norm": 0.05008357763290405,
      "learning_rate": 3.8372395312562495e-05,
      "loss": 0.0771,
      "step": 34900
    },
    {
      "epoch": 0.6981162260528736,
      "grad_norm": 0.21444596350193024,
      "learning_rate": 3.8369062379181164e-05,
      "loss": 0.0891,
      "step": 34910
    },
    {
      "epoch": 0.6983162020557533,
      "grad_norm": 0.15414807200431824,
      "learning_rate": 3.836572944579984e-05,
      "loss": 0.0676,
      "step": 34920
    },
    {
      "epoch": 0.698516178058633,
      "grad_norm": 0.1394404172897339,
      "learning_rate": 3.836239651241852e-05,
      "loss": 0.0516,
      "step": 34930
    },
    {
      "epoch": 0.6987161540615127,
      "grad_norm": 0.14673703908920288,
      "learning_rate": 3.835906357903719e-05,
      "loss": 0.075,
      "step": 34940
    },
    {
      "epoch": 0.6989161300643922,
      "grad_norm": 0.09354604780673981,
      "learning_rate": 3.8355730645655856e-05,
      "loss": 0.0738,
      "step": 34950
    },
    {
      "epoch": 0.6991161060672719,
      "grad_norm": 0.19833873212337494,
      "learning_rate": 3.835239771227453e-05,
      "loss": 0.0754,
      "step": 34960
    },
    {
      "epoch": 0.6993160820701516,
      "grad_norm": 0.1543772965669632,
      "learning_rate": 3.83490647788932e-05,
      "loss": 0.0751,
      "step": 34970
    },
    {
      "epoch": 0.6995160580730312,
      "grad_norm": 0.0791720524430275,
      "learning_rate": 3.834573184551187e-05,
      "loss": 0.0823,
      "step": 34980
    },
    {
      "epoch": 0.6997160340759109,
      "grad_norm": 0.08310726284980774,
      "learning_rate": 3.834239891213055e-05,
      "loss": 0.0649,
      "step": 34990
    },
    {
      "epoch": 0.6999160100787906,
      "grad_norm": 0.1036507859826088,
      "learning_rate": 3.833906597874922e-05,
      "loss": 0.0927,
      "step": 35000
    },
    {
      "epoch": 0.7001159860816702,
      "grad_norm": 0.10005706548690796,
      "learning_rate": 3.833573304536789e-05,
      "loss": 0.0752,
      "step": 35010
    },
    {
      "epoch": 0.7003159620845498,
      "grad_norm": 0.09833268821239471,
      "learning_rate": 3.8332400111986564e-05,
      "loss": 0.0379,
      "step": 35020
    },
    {
      "epoch": 0.7005159380874295,
      "grad_norm": 0.2066526710987091,
      "learning_rate": 3.832906717860524e-05,
      "loss": 0.085,
      "step": 35030
    },
    {
      "epoch": 0.7007159140903092,
      "grad_norm": 0.11392796784639359,
      "learning_rate": 3.832573424522391e-05,
      "loss": 0.0898,
      "step": 35040
    },
    {
      "epoch": 0.7009158900931888,
      "grad_norm": 0.18329577147960663,
      "learning_rate": 3.832240131184258e-05,
      "loss": 0.0838,
      "step": 35050
    },
    {
      "epoch": 0.7011158660960685,
      "grad_norm": 0.09869863837957382,
      "learning_rate": 3.8319068378461256e-05,
      "loss": 0.092,
      "step": 35060
    },
    {
      "epoch": 0.7013158420989482,
      "grad_norm": 0.10032394528388977,
      "learning_rate": 3.8315735445079926e-05,
      "loss": 0.1153,
      "step": 35070
    },
    {
      "epoch": 0.7015158181018277,
      "grad_norm": 0.10543648153543472,
      "learning_rate": 3.8312402511698595e-05,
      "loss": 0.0808,
      "step": 35080
    },
    {
      "epoch": 0.7017157941047074,
      "grad_norm": 0.16643580794334412,
      "learning_rate": 3.830906957831727e-05,
      "loss": 0.0762,
      "step": 35090
    },
    {
      "epoch": 0.7019157701075871,
      "grad_norm": 0.11619707196950912,
      "learning_rate": 3.830573664493594e-05,
      "loss": 0.0608,
      "step": 35100
    },
    {
      "epoch": 0.7021157461104668,
      "grad_norm": 0.1181805431842804,
      "learning_rate": 3.830240371155461e-05,
      "loss": 0.1249,
      "step": 35110
    },
    {
      "epoch": 0.7023157221133464,
      "grad_norm": 0.0941389799118042,
      "learning_rate": 3.829907077817329e-05,
      "loss": 0.0671,
      "step": 35120
    },
    {
      "epoch": 0.702515698116226,
      "grad_norm": 0.11020157486200333,
      "learning_rate": 3.8295737844791964e-05,
      "loss": 0.1265,
      "step": 35130
    },
    {
      "epoch": 0.7027156741191057,
      "grad_norm": 0.1999482661485672,
      "learning_rate": 3.829240491141063e-05,
      "loss": 0.1043,
      "step": 35140
    },
    {
      "epoch": 0.7029156501219853,
      "grad_norm": 0.055771686136722565,
      "learning_rate": 3.82890719780293e-05,
      "loss": 0.0529,
      "step": 35150
    },
    {
      "epoch": 0.703115626124865,
      "grad_norm": 0.04712054505944252,
      "learning_rate": 3.828607233798611e-05,
      "loss": 0.1034,
      "step": 35160
    },
    {
      "epoch": 0.7033156021277447,
      "grad_norm": 0.0917975902557373,
      "learning_rate": 3.828273940460478e-05,
      "loss": 0.0405,
      "step": 35170
    },
    {
      "epoch": 0.7035155781306244,
      "grad_norm": 0.08062891662120819,
      "learning_rate": 3.827940647122346e-05,
      "loss": 0.0608,
      "step": 35180
    },
    {
      "epoch": 0.703715554133504,
      "grad_norm": 0.1344451755285263,
      "learning_rate": 3.827607353784213e-05,
      "loss": 0.0849,
      "step": 35190
    },
    {
      "epoch": 0.7039155301363836,
      "grad_norm": 0.1243397668004036,
      "learning_rate": 3.82727406044608e-05,
      "loss": 0.0469,
      "step": 35200
    },
    {
      "epoch": 0.7041155061392633,
      "grad_norm": 0.1236996278166771,
      "learning_rate": 3.826940767107947e-05,
      "loss": 0.0713,
      "step": 35210
    },
    {
      "epoch": 0.7043154821421429,
      "grad_norm": 0.12830661237239838,
      "learning_rate": 3.826607473769814e-05,
      "loss": 0.0871,
      "step": 35220
    },
    {
      "epoch": 0.7045154581450226,
      "grad_norm": 0.12515364587306976,
      "learning_rate": 3.826274180431681e-05,
      "loss": 0.0744,
      "step": 35230
    },
    {
      "epoch": 0.7047154341479023,
      "grad_norm": 0.08186163008213043,
      "learning_rate": 3.825940887093549e-05,
      "loss": 0.1033,
      "step": 35240
    },
    {
      "epoch": 0.7049154101507819,
      "grad_norm": 0.08935199677944183,
      "learning_rate": 3.8256075937554165e-05,
      "loss": 0.0639,
      "step": 35250
    },
    {
      "epoch": 0.7051153861536615,
      "grad_norm": 0.15368402004241943,
      "learning_rate": 3.8252743004172835e-05,
      "loss": 0.0502,
      "step": 35260
    },
    {
      "epoch": 0.7053153621565412,
      "grad_norm": 0.09505657851696014,
      "learning_rate": 3.824941007079151e-05,
      "loss": 0.0557,
      "step": 35270
    },
    {
      "epoch": 0.7055153381594209,
      "grad_norm": 0.10154470056295395,
      "learning_rate": 3.824607713741018e-05,
      "loss": 0.0831,
      "step": 35280
    },
    {
      "epoch": 0.7057153141623005,
      "grad_norm": 0.10502877831459045,
      "learning_rate": 3.824274420402885e-05,
      "loss": 0.079,
      "step": 35290
    },
    {
      "epoch": 0.7059152901651802,
      "grad_norm": 0.16341380774974823,
      "learning_rate": 3.823941127064753e-05,
      "loss": 0.0809,
      "step": 35300
    },
    {
      "epoch": 0.7061152661680599,
      "grad_norm": 0.1850571185350418,
      "learning_rate": 3.8236078337266196e-05,
      "loss": 0.0821,
      "step": 35310
    },
    {
      "epoch": 0.7063152421709394,
      "grad_norm": 0.13547752797603607,
      "learning_rate": 3.8232745403884866e-05,
      "loss": 0.0894,
      "step": 35320
    },
    {
      "epoch": 0.7065152181738191,
      "grad_norm": 0.07068446278572083,
      "learning_rate": 3.822941247050354e-05,
      "loss": 0.0524,
      "step": 35330
    },
    {
      "epoch": 0.7067151941766988,
      "grad_norm": 0.08960648626089096,
      "learning_rate": 3.822607953712221e-05,
      "loss": 0.0812,
      "step": 35340
    },
    {
      "epoch": 0.7069151701795785,
      "grad_norm": 0.19393230974674225,
      "learning_rate": 3.822274660374089e-05,
      "loss": 0.116,
      "step": 35350
    },
    {
      "epoch": 0.7071151461824581,
      "grad_norm": 0.0888134017586708,
      "learning_rate": 3.821941367035956e-05,
      "loss": 0.0834,
      "step": 35360
    },
    {
      "epoch": 0.7073151221853378,
      "grad_norm": 0.07583849132061005,
      "learning_rate": 3.8216080736978234e-05,
      "loss": 0.0691,
      "step": 35370
    },
    {
      "epoch": 0.7075150981882175,
      "grad_norm": 0.0780664011836052,
      "learning_rate": 3.8212747803596904e-05,
      "loss": 0.0735,
      "step": 35380
    },
    {
      "epoch": 0.707715074191097,
      "grad_norm": 0.1489614099264145,
      "learning_rate": 3.8209414870215574e-05,
      "loss": 0.093,
      "step": 35390
    },
    {
      "epoch": 0.7079150501939767,
      "grad_norm": 0.11440487205982208,
      "learning_rate": 3.820608193683425e-05,
      "loss": 0.0618,
      "step": 35400
    },
    {
      "epoch": 0.7081150261968564,
      "grad_norm": 0.0525403656065464,
      "learning_rate": 3.820274900345292e-05,
      "loss": 0.0953,
      "step": 35410
    },
    {
      "epoch": 0.708315002199736,
      "grad_norm": 0.227784663438797,
      "learning_rate": 3.819941607007159e-05,
      "loss": 0.091,
      "step": 35420
    },
    {
      "epoch": 0.7085149782026157,
      "grad_norm": 0.23313911259174347,
      "learning_rate": 3.8196083136690266e-05,
      "loss": 0.1103,
      "step": 35430
    },
    {
      "epoch": 0.7087149542054954,
      "grad_norm": 0.0938756912946701,
      "learning_rate": 3.8192750203308935e-05,
      "loss": 0.0856,
      "step": 35440
    },
    {
      "epoch": 0.708914930208375,
      "grad_norm": 0.1579536646604538,
      "learning_rate": 3.818941726992761e-05,
      "loss": 0.0722,
      "step": 35450
    },
    {
      "epoch": 0.7091149062112546,
      "grad_norm": 0.07028912752866745,
      "learning_rate": 3.818608433654629e-05,
      "loss": 0.0487,
      "step": 35460
    },
    {
      "epoch": 0.7093148822141343,
      "grad_norm": 0.18983682990074158,
      "learning_rate": 3.818275140316496e-05,
      "loss": 0.1071,
      "step": 35470
    },
    {
      "epoch": 0.709514858217014,
      "grad_norm": 0.1466849446296692,
      "learning_rate": 3.817941846978363e-05,
      "loss": 0.0999,
      "step": 35480
    },
    {
      "epoch": 0.7097148342198936,
      "grad_norm": 0.1276383101940155,
      "learning_rate": 3.8176085536402304e-05,
      "loss": 0.0947,
      "step": 35490
    },
    {
      "epoch": 0.7099148102227733,
      "grad_norm": 0.07254031300544739,
      "learning_rate": 3.817275260302097e-05,
      "loss": 0.0489,
      "step": 35500
    },
    {
      "epoch": 0.7101147862256529,
      "grad_norm": 0.10877407342195511,
      "learning_rate": 3.816941966963964e-05,
      "loss": 0.3751,
      "step": 35510
    },
    {
      "epoch": 0.7103147622285326,
      "grad_norm": 0.14660175144672394,
      "learning_rate": 3.816608673625832e-05,
      "loss": 0.092,
      "step": 35520
    },
    {
      "epoch": 0.7105147382314122,
      "grad_norm": 0.2190643846988678,
      "learning_rate": 3.816275380287699e-05,
      "loss": 0.0831,
      "step": 35530
    },
    {
      "epoch": 0.7107147142342919,
      "grad_norm": 0.19523409008979797,
      "learning_rate": 3.815942086949566e-05,
      "loss": 0.0804,
      "step": 35540
    },
    {
      "epoch": 0.7109146902371716,
      "grad_norm": 0.15195800364017487,
      "learning_rate": 3.8156087936114335e-05,
      "loss": 0.0698,
      "step": 35550
    },
    {
      "epoch": 0.7111146662400512,
      "grad_norm": 0.16590605676174164,
      "learning_rate": 3.815275500273301e-05,
      "loss": 0.0582,
      "step": 35560
    },
    {
      "epoch": 0.7113146422429308,
      "grad_norm": 0.12914857268333435,
      "learning_rate": 3.814942206935168e-05,
      "loss": 0.0709,
      "step": 35570
    },
    {
      "epoch": 0.7115146182458105,
      "grad_norm": 0.12303991615772247,
      "learning_rate": 3.814608913597035e-05,
      "loss": 0.0684,
      "step": 35580
    },
    {
      "epoch": 0.7117145942486901,
      "grad_norm": 0.0967375636100769,
      "learning_rate": 3.814275620258903e-05,
      "loss": 0.0724,
      "step": 35590
    },
    {
      "epoch": 0.7119145702515698,
      "grad_norm": 0.09935907274484634,
      "learning_rate": 3.8139423269207697e-05,
      "loss": 0.0556,
      "step": 35600
    },
    {
      "epoch": 0.7121145462544495,
      "grad_norm": 0.12250345945358276,
      "learning_rate": 3.8136090335826366e-05,
      "loss": 0.0738,
      "step": 35610
    },
    {
      "epoch": 0.7123145222573292,
      "grad_norm": 0.096736840903759,
      "learning_rate": 3.813275740244504e-05,
      "loss": 0.0689,
      "step": 35620
    },
    {
      "epoch": 0.7125144982602087,
      "grad_norm": 0.06712714582681656,
      "learning_rate": 3.812942446906371e-05,
      "loss": 0.1029,
      "step": 35630
    },
    {
      "epoch": 0.7127144742630884,
      "grad_norm": 0.06853986531496048,
      "learning_rate": 3.812609153568238e-05,
      "loss": 0.0547,
      "step": 35640
    },
    {
      "epoch": 0.7129144502659681,
      "grad_norm": 0.04730338230729103,
      "learning_rate": 3.812275860230106e-05,
      "loss": 0.0814,
      "step": 35650
    },
    {
      "epoch": 0.7131144262688477,
      "grad_norm": 0.15497714281082153,
      "learning_rate": 3.8119425668919735e-05,
      "loss": 0.0578,
      "step": 35660
    },
    {
      "epoch": 0.7133144022717274,
      "grad_norm": 0.0945468619465828,
      "learning_rate": 3.8116092735538404e-05,
      "loss": 0.0678,
      "step": 35670
    },
    {
      "epoch": 0.7135143782746071,
      "grad_norm": 0.055221445858478546,
      "learning_rate": 3.811275980215708e-05,
      "loss": 0.0501,
      "step": 35680
    },
    {
      "epoch": 0.7137143542774868,
      "grad_norm": 0.08423744887113571,
      "learning_rate": 3.810942686877575e-05,
      "loss": 0.081,
      "step": 35690
    },
    {
      "epoch": 0.7139143302803663,
      "grad_norm": 0.22772665321826935,
      "learning_rate": 3.810609393539442e-05,
      "loss": 0.0973,
      "step": 35700
    },
    {
      "epoch": 0.714114306283246,
      "grad_norm": 0.0777105912566185,
      "learning_rate": 3.8102761002013096e-05,
      "loss": 0.0702,
      "step": 35710
    },
    {
      "epoch": 0.7143142822861257,
      "grad_norm": 0.09694277495145798,
      "learning_rate": 3.8099428068631766e-05,
      "loss": 0.0646,
      "step": 35720
    },
    {
      "epoch": 0.7145142582890053,
      "grad_norm": 0.10379163920879364,
      "learning_rate": 3.8096095135250435e-05,
      "loss": 0.0735,
      "step": 35730
    },
    {
      "epoch": 0.714714234291885,
      "grad_norm": 0.07131145149469376,
      "learning_rate": 3.809276220186911e-05,
      "loss": 0.0669,
      "step": 35740
    },
    {
      "epoch": 0.7149142102947647,
      "grad_norm": 0.07800278812646866,
      "learning_rate": 3.808942926848778e-05,
      "loss": 0.0797,
      "step": 35750
    },
    {
      "epoch": 0.7151141862976442,
      "grad_norm": 0.08509081602096558,
      "learning_rate": 3.808609633510646e-05,
      "loss": 0.0736,
      "step": 35760
    },
    {
      "epoch": 0.7153141623005239,
      "grad_norm": 0.10112347453832626,
      "learning_rate": 3.808276340172513e-05,
      "loss": 0.0921,
      "step": 35770
    },
    {
      "epoch": 0.7155141383034036,
      "grad_norm": 0.061688199639320374,
      "learning_rate": 3.8079430468343804e-05,
      "loss": 0.0616,
      "step": 35780
    },
    {
      "epoch": 0.7157141143062833,
      "grad_norm": 0.11727534234523773,
      "learning_rate": 3.8076097534962474e-05,
      "loss": 0.0853,
      "step": 35790
    },
    {
      "epoch": 0.7159140903091629,
      "grad_norm": 0.1956687867641449,
      "learning_rate": 3.807276460158114e-05,
      "loss": 0.0806,
      "step": 35800
    },
    {
      "epoch": 0.7161140663120426,
      "grad_norm": 0.07218638062477112,
      "learning_rate": 3.806943166819982e-05,
      "loss": 0.089,
      "step": 35810
    },
    {
      "epoch": 0.7163140423149222,
      "grad_norm": 0.16027256846427917,
      "learning_rate": 3.806609873481849e-05,
      "loss": 0.0651,
      "step": 35820
    },
    {
      "epoch": 0.7165140183178018,
      "grad_norm": 0.09772792458534241,
      "learning_rate": 3.806276580143716e-05,
      "loss": 0.0791,
      "step": 35830
    },
    {
      "epoch": 0.7167139943206815,
      "grad_norm": 0.09549888223409653,
      "learning_rate": 3.8059432868055835e-05,
      "loss": 0.092,
      "step": 35840
    },
    {
      "epoch": 0.7169139703235612,
      "grad_norm": 0.16990318894386292,
      "learning_rate": 3.8056099934674505e-05,
      "loss": 0.0679,
      "step": 35850
    },
    {
      "epoch": 0.7171139463264409,
      "grad_norm": 0.08777827769517899,
      "learning_rate": 3.805276700129318e-05,
      "loss": 0.0411,
      "step": 35860
    },
    {
      "epoch": 0.7173139223293205,
      "grad_norm": 0.13451339304447174,
      "learning_rate": 3.804943406791186e-05,
      "loss": 0.0933,
      "step": 35870
    },
    {
      "epoch": 0.7175138983322001,
      "grad_norm": 0.11546838283538818,
      "learning_rate": 3.804610113453053e-05,
      "loss": 0.0761,
      "step": 35880
    },
    {
      "epoch": 0.7177138743350798,
      "grad_norm": 0.06523556262254715,
      "learning_rate": 3.80427682011492e-05,
      "loss": 0.0764,
      "step": 35890
    },
    {
      "epoch": 0.7179138503379594,
      "grad_norm": 0.09985063970088959,
      "learning_rate": 3.803943526776787e-05,
      "loss": 0.1148,
      "step": 35900
    },
    {
      "epoch": 0.7181138263408391,
      "grad_norm": 0.13860224187374115,
      "learning_rate": 3.803610233438654e-05,
      "loss": 0.0808,
      "step": 35910
    },
    {
      "epoch": 0.7183138023437188,
      "grad_norm": 0.11189279705286026,
      "learning_rate": 3.803276940100521e-05,
      "loss": 0.0474,
      "step": 35920
    },
    {
      "epoch": 0.7185137783465984,
      "grad_norm": 0.1985710710287094,
      "learning_rate": 3.802943646762389e-05,
      "loss": 0.0933,
      "step": 35930
    },
    {
      "epoch": 0.718713754349478,
      "grad_norm": 0.10645271837711334,
      "learning_rate": 3.802610353424256e-05,
      "loss": 0.0727,
      "step": 35940
    },
    {
      "epoch": 0.7189137303523577,
      "grad_norm": 0.07519284635782242,
      "learning_rate": 3.802277060086123e-05,
      "loss": 0.0484,
      "step": 35950
    },
    {
      "epoch": 0.7191137063552374,
      "grad_norm": 0.11895257234573364,
      "learning_rate": 3.8019437667479904e-05,
      "loss": 0.0632,
      "step": 35960
    },
    {
      "epoch": 0.719313682358117,
      "grad_norm": 0.102495938539505,
      "learning_rate": 3.801610473409858e-05,
      "loss": 0.0625,
      "step": 35970
    },
    {
      "epoch": 0.7195136583609967,
      "grad_norm": 0.0834050178527832,
      "learning_rate": 3.801277180071725e-05,
      "loss": 0.146,
      "step": 35980
    },
    {
      "epoch": 0.7197136343638764,
      "grad_norm": 0.10952658206224442,
      "learning_rate": 3.800943886733592e-05,
      "loss": 0.0794,
      "step": 35990
    },
    {
      "epoch": 0.7199136103667559,
      "grad_norm": 0.10324392467737198,
      "learning_rate": 3.8006105933954596e-05,
      "loss": 0.0837,
      "step": 36000
    },
    {
      "epoch": 0.7201135863696356,
      "grad_norm": 0.14500094950199127,
      "learning_rate": 3.8002773000573266e-05,
      "loss": 0.0821,
      "step": 36010
    },
    {
      "epoch": 0.7203135623725153,
      "grad_norm": 0.1945594996213913,
      "learning_rate": 3.7999440067191936e-05,
      "loss": 0.0893,
      "step": 36020
    },
    {
      "epoch": 0.720513538375395,
      "grad_norm": 0.15915712714195251,
      "learning_rate": 3.799610713381061e-05,
      "loss": 0.078,
      "step": 36030
    },
    {
      "epoch": 0.7207135143782746,
      "grad_norm": 0.09978037327528,
      "learning_rate": 3.799277420042928e-05,
      "loss": 0.1322,
      "step": 36040
    },
    {
      "epoch": 0.7209134903811543,
      "grad_norm": 0.08725660294294357,
      "learning_rate": 3.798944126704795e-05,
      "loss": 0.0538,
      "step": 36050
    },
    {
      "epoch": 0.721113466384034,
      "grad_norm": 0.15431107580661774,
      "learning_rate": 3.7986108333666634e-05,
      "loss": 0.1204,
      "step": 36060
    },
    {
      "epoch": 0.7213134423869135,
      "grad_norm": 0.1261751800775528,
      "learning_rate": 3.7982775400285304e-05,
      "loss": 0.0764,
      "step": 36070
    },
    {
      "epoch": 0.7215134183897932,
      "grad_norm": 0.15168549120426178,
      "learning_rate": 3.7979442466903974e-05,
      "loss": 0.0635,
      "step": 36080
    },
    {
      "epoch": 0.7217133943926729,
      "grad_norm": 0.08650711923837662,
      "learning_rate": 3.797610953352265e-05,
      "loss": 0.082,
      "step": 36090
    },
    {
      "epoch": 0.7219133703955525,
      "grad_norm": 0.20156630873680115,
      "learning_rate": 3.797277660014132e-05,
      "loss": 0.0935,
      "step": 36100
    },
    {
      "epoch": 0.7221133463984322,
      "grad_norm": 0.14044569432735443,
      "learning_rate": 3.796944366675999e-05,
      "loss": 0.0513,
      "step": 36110
    },
    {
      "epoch": 0.7223133224013119,
      "grad_norm": 0.07863978296518326,
      "learning_rate": 3.7966110733378666e-05,
      "loss": 0.0626,
      "step": 36120
    },
    {
      "epoch": 0.7225132984041915,
      "grad_norm": 0.1977686882019043,
      "learning_rate": 3.7962777799997335e-05,
      "loss": 0.0925,
      "step": 36130
    },
    {
      "epoch": 0.7227132744070711,
      "grad_norm": 0.07766889780759811,
      "learning_rate": 3.7959444866616005e-05,
      "loss": 0.0705,
      "step": 36140
    },
    {
      "epoch": 0.7229132504099508,
      "grad_norm": 0.15947921574115753,
      "learning_rate": 3.795611193323468e-05,
      "loss": 0.0869,
      "step": 36150
    },
    {
      "epoch": 0.7231132264128305,
      "grad_norm": 0.19195964932441711,
      "learning_rate": 3.795277899985335e-05,
      "loss": 0.0857,
      "step": 36160
    },
    {
      "epoch": 0.7233132024157101,
      "grad_norm": 0.11133521795272827,
      "learning_rate": 3.794944606647203e-05,
      "loss": 0.058,
      "step": 36170
    },
    {
      "epoch": 0.7235131784185898,
      "grad_norm": 0.19510860741138458,
      "learning_rate": 3.79461131330907e-05,
      "loss": 0.1012,
      "step": 36180
    },
    {
      "epoch": 0.7237131544214694,
      "grad_norm": 0.053982749581336975,
      "learning_rate": 3.794278019970937e-05,
      "loss": 0.0925,
      "step": 36190
    },
    {
      "epoch": 0.7239131304243491,
      "grad_norm": 0.10312177985906601,
      "learning_rate": 3.793944726632804e-05,
      "loss": 0.08,
      "step": 36200
    },
    {
      "epoch": 0.7241131064272287,
      "grad_norm": 0.15671761333942413,
      "learning_rate": 3.793611433294671e-05,
      "loss": 0.0925,
      "step": 36210
    },
    {
      "epoch": 0.7243130824301084,
      "grad_norm": 0.1742585301399231,
      "learning_rate": 3.793278139956539e-05,
      "loss": 0.0972,
      "step": 36220
    },
    {
      "epoch": 0.7245130584329881,
      "grad_norm": 0.13257846236228943,
      "learning_rate": 3.792944846618406e-05,
      "loss": 0.0928,
      "step": 36230
    },
    {
      "epoch": 0.7247130344358677,
      "grad_norm": 0.18180008232593536,
      "learning_rate": 3.792611553280273e-05,
      "loss": 0.0603,
      "step": 36240
    },
    {
      "epoch": 0.7249130104387473,
      "grad_norm": 0.1810891479253769,
      "learning_rate": 3.7922782599421405e-05,
      "loss": 0.0857,
      "step": 36250
    },
    {
      "epoch": 0.725112986441627,
      "grad_norm": 0.1988873928785324,
      "learning_rate": 3.7919449666040074e-05,
      "loss": 0.1331,
      "step": 36260
    },
    {
      "epoch": 0.7253129624445066,
      "grad_norm": 0.13103587925434113,
      "learning_rate": 3.791611673265875e-05,
      "loss": 0.0847,
      "step": 36270
    },
    {
      "epoch": 0.7255129384473863,
      "grad_norm": 0.07748318463563919,
      "learning_rate": 3.791278379927743e-05,
      "loss": 0.1003,
      "step": 36280
    },
    {
      "epoch": 0.725712914450266,
      "grad_norm": 0.1927562952041626,
      "learning_rate": 3.7909450865896097e-05,
      "loss": 0.0733,
      "step": 36290
    },
    {
      "epoch": 0.7259128904531457,
      "grad_norm": 0.07528222352266312,
      "learning_rate": 3.7906117932514766e-05,
      "loss": 0.0512,
      "step": 36300
    },
    {
      "epoch": 0.7261128664560252,
      "grad_norm": 0.08744107931852341,
      "learning_rate": 3.790278499913344e-05,
      "loss": 0.1425,
      "step": 36310
    },
    {
      "epoch": 0.7263128424589049,
      "grad_norm": 0.1401088833808899,
      "learning_rate": 3.789945206575211e-05,
      "loss": 0.114,
      "step": 36320
    },
    {
      "epoch": 0.7265128184617846,
      "grad_norm": 0.07215500622987747,
      "learning_rate": 3.789611913237078e-05,
      "loss": 0.067,
      "step": 36330
    },
    {
      "epoch": 0.7267127944646642,
      "grad_norm": 0.16377688944339752,
      "learning_rate": 3.789278619898946e-05,
      "loss": 0.0837,
      "step": 36340
    },
    {
      "epoch": 0.7269127704675439,
      "grad_norm": 0.1610044538974762,
      "learning_rate": 3.788945326560813e-05,
      "loss": 0.0893,
      "step": 36350
    },
    {
      "epoch": 0.7271127464704236,
      "grad_norm": 0.11873748153448105,
      "learning_rate": 3.78861203322268e-05,
      "loss": 0.0992,
      "step": 36360
    },
    {
      "epoch": 0.7273127224733033,
      "grad_norm": 0.185430645942688,
      "learning_rate": 3.7882787398845474e-05,
      "loss": 0.0961,
      "step": 36370
    },
    {
      "epoch": 0.7275126984761828,
      "grad_norm": 0.1731531172990799,
      "learning_rate": 3.787945446546415e-05,
      "loss": 0.0926,
      "step": 36380
    },
    {
      "epoch": 0.7277126744790625,
      "grad_norm": 0.1670072078704834,
      "learning_rate": 3.787612153208282e-05,
      "loss": 0.1191,
      "step": 36390
    },
    {
      "epoch": 0.7279126504819422,
      "grad_norm": 0.13718484342098236,
      "learning_rate": 3.787278859870149e-05,
      "loss": 0.081,
      "step": 36400
    },
    {
      "epoch": 0.7281126264848218,
      "grad_norm": 0.0991964042186737,
      "learning_rate": 3.7869455665320166e-05,
      "loss": 0.0774,
      "step": 36410
    },
    {
      "epoch": 0.7283126024877015,
      "grad_norm": 0.06740271300077438,
      "learning_rate": 3.7866122731938835e-05,
      "loss": 0.0849,
      "step": 36420
    },
    {
      "epoch": 0.7285125784905812,
      "grad_norm": 0.17426899075508118,
      "learning_rate": 3.7862789798557505e-05,
      "loss": 0.1146,
      "step": 36430
    },
    {
      "epoch": 0.7287125544934608,
      "grad_norm": 0.18251699209213257,
      "learning_rate": 3.785945686517618e-05,
      "loss": 0.1024,
      "step": 36440
    },
    {
      "epoch": 0.7289125304963404,
      "grad_norm": 0.15626369416713715,
      "learning_rate": 3.785612393179485e-05,
      "loss": 0.103,
      "step": 36450
    },
    {
      "epoch": 0.7291125064992201,
      "grad_norm": 0.08974451571702957,
      "learning_rate": 3.785279099841352e-05,
      "loss": 0.0835,
      "step": 36460
    },
    {
      "epoch": 0.7293124825020998,
      "grad_norm": 0.10731685161590576,
      "learning_rate": 3.7849458065032204e-05,
      "loss": 0.0912,
      "step": 36470
    },
    {
      "epoch": 0.7295124585049794,
      "grad_norm": 0.1712871938943863,
      "learning_rate": 3.7846125131650874e-05,
      "loss": 0.3411,
      "step": 36480
    },
    {
      "epoch": 0.729712434507859,
      "grad_norm": 0.11872919648885727,
      "learning_rate": 3.784279219826954e-05,
      "loss": 0.0988,
      "step": 36490
    },
    {
      "epoch": 0.7299124105107387,
      "grad_norm": 0.11779065430164337,
      "learning_rate": 3.783945926488822e-05,
      "loss": 0.0601,
      "step": 36500
    },
    {
      "epoch": 0.7301123865136183,
      "grad_norm": 0.22830583155155182,
      "learning_rate": 3.783612633150689e-05,
      "loss": 0.088,
      "step": 36510
    },
    {
      "epoch": 0.730312362516498,
      "grad_norm": 0.10861053317785263,
      "learning_rate": 3.783279339812556e-05,
      "loss": 0.0549,
      "step": 36520
    },
    {
      "epoch": 0.7305123385193777,
      "grad_norm": 0.10452895611524582,
      "learning_rate": 3.7829460464744235e-05,
      "loss": 0.0906,
      "step": 36530
    },
    {
      "epoch": 0.7307123145222574,
      "grad_norm": 0.1766279637813568,
      "learning_rate": 3.7826127531362905e-05,
      "loss": 0.0845,
      "step": 36540
    },
    {
      "epoch": 0.730912290525137,
      "grad_norm": 0.1037478968501091,
      "learning_rate": 3.7822794597981574e-05,
      "loss": 0.0638,
      "step": 36550
    },
    {
      "epoch": 0.7311122665280166,
      "grad_norm": 0.12499664723873138,
      "learning_rate": 3.781946166460025e-05,
      "loss": 0.0607,
      "step": 36560
    },
    {
      "epoch": 0.7313122425308963,
      "grad_norm": 0.0883687436580658,
      "learning_rate": 3.781612873121893e-05,
      "loss": 0.0526,
      "step": 36570
    },
    {
      "epoch": 0.7315122185337759,
      "grad_norm": 0.04269362613558769,
      "learning_rate": 3.78127957978376e-05,
      "loss": 0.0448,
      "step": 36580
    },
    {
      "epoch": 0.7317121945366556,
      "grad_norm": 0.10884179919958115,
      "learning_rate": 3.7809462864456266e-05,
      "loss": 0.0726,
      "step": 36590
    },
    {
      "epoch": 0.7319121705395353,
      "grad_norm": 0.0491846427321434,
      "learning_rate": 3.780612993107494e-05,
      "loss": 0.0581,
      "step": 36600
    },
    {
      "epoch": 0.732112146542415,
      "grad_norm": 0.06450824439525604,
      "learning_rate": 3.780279699769361e-05,
      "loss": 0.0879,
      "step": 36610
    },
    {
      "epoch": 0.7323121225452945,
      "grad_norm": 0.1919126808643341,
      "learning_rate": 3.779946406431228e-05,
      "loss": 0.075,
      "step": 36620
    },
    {
      "epoch": 0.7325120985481742,
      "grad_norm": 0.23686563968658447,
      "learning_rate": 3.779613113093096e-05,
      "loss": 0.0629,
      "step": 36630
    },
    {
      "epoch": 0.7327120745510539,
      "grad_norm": 0.14728809893131256,
      "learning_rate": 3.779279819754963e-05,
      "loss": 0.0512,
      "step": 36640
    },
    {
      "epoch": 0.7329120505539335,
      "grad_norm": 0.07039019465446472,
      "learning_rate": 3.77894652641683e-05,
      "loss": 0.0678,
      "step": 36650
    },
    {
      "epoch": 0.7331120265568132,
      "grad_norm": 0.17874674499034882,
      "learning_rate": 3.7786132330786974e-05,
      "loss": 0.1096,
      "step": 36660
    },
    {
      "epoch": 0.7333120025596929,
      "grad_norm": 0.07145623117685318,
      "learning_rate": 3.7782799397405644e-05,
      "loss": 0.1023,
      "step": 36670
    },
    {
      "epoch": 0.7335119785625724,
      "grad_norm": 0.12754328548908234,
      "learning_rate": 3.777946646402432e-05,
      "loss": 0.0818,
      "step": 36680
    },
    {
      "epoch": 0.7337119545654521,
      "grad_norm": 0.2139476090669632,
      "learning_rate": 3.7776133530642996e-05,
      "loss": 0.0672,
      "step": 36690
    },
    {
      "epoch": 0.7339119305683318,
      "grad_norm": 0.14607958495616913,
      "learning_rate": 3.7772800597261666e-05,
      "loss": 0.0928,
      "step": 36700
    },
    {
      "epoch": 0.7341119065712115,
      "grad_norm": 0.07169424742460251,
      "learning_rate": 3.7769467663880336e-05,
      "loss": 0.0623,
      "step": 36710
    },
    {
      "epoch": 0.7343118825740911,
      "grad_norm": 0.17106591165065765,
      "learning_rate": 3.776613473049901e-05,
      "loss": 0.1074,
      "step": 36720
    },
    {
      "epoch": 0.7345118585769708,
      "grad_norm": 0.19358329474925995,
      "learning_rate": 3.776280179711768e-05,
      "loss": 0.0798,
      "step": 36730
    },
    {
      "epoch": 0.7347118345798505,
      "grad_norm": 0.07550416886806488,
      "learning_rate": 3.775946886373635e-05,
      "loss": 0.0662,
      "step": 36740
    },
    {
      "epoch": 0.73491181058273,
      "grad_norm": 0.15262144804000854,
      "learning_rate": 3.775613593035503e-05,
      "loss": 0.0738,
      "step": 36750
    },
    {
      "epoch": 0.7351117865856097,
      "grad_norm": 0.09043017774820328,
      "learning_rate": 3.77528029969737e-05,
      "loss": 0.0701,
      "step": 36760
    },
    {
      "epoch": 0.7353117625884894,
      "grad_norm": 0.10157611966133118,
      "learning_rate": 3.774947006359237e-05,
      "loss": 0.0902,
      "step": 36770
    },
    {
      "epoch": 0.7355117385913691,
      "grad_norm": 0.06351304799318314,
      "learning_rate": 3.774613713021104e-05,
      "loss": 0.0386,
      "step": 36780
    },
    {
      "epoch": 0.7357117145942487,
      "grad_norm": 0.10544388741254807,
      "learning_rate": 3.774280419682972e-05,
      "loss": 0.0383,
      "step": 36790
    },
    {
      "epoch": 0.7359116905971284,
      "grad_norm": 0.08237030357122421,
      "learning_rate": 3.773947126344839e-05,
      "loss": 0.0561,
      "step": 36800
    },
    {
      "epoch": 0.736111666600008,
      "grad_norm": 0.08577647805213928,
      "learning_rate": 3.773613833006706e-05,
      "loss": 0.0699,
      "step": 36810
    },
    {
      "epoch": 0.7363116426028876,
      "grad_norm": 0.06993439793586731,
      "learning_rate": 3.7732805396685735e-05,
      "loss": 0.0566,
      "step": 36820
    },
    {
      "epoch": 0.7365116186057673,
      "grad_norm": 0.16513954102993011,
      "learning_rate": 3.7729472463304405e-05,
      "loss": 0.0629,
      "step": 36830
    },
    {
      "epoch": 0.736711594608647,
      "grad_norm": 0.10185440629720688,
      "learning_rate": 3.7726139529923075e-05,
      "loss": 0.0617,
      "step": 36840
    },
    {
      "epoch": 0.7369115706115266,
      "grad_norm": 0.08933417499065399,
      "learning_rate": 3.772280659654175e-05,
      "loss": 0.0775,
      "step": 36850
    },
    {
      "epoch": 0.7371115466144063,
      "grad_norm": 0.19106371700763702,
      "learning_rate": 3.771947366316042e-05,
      "loss": 0.0982,
      "step": 36860
    },
    {
      "epoch": 0.7373115226172859,
      "grad_norm": 0.0882648304104805,
      "learning_rate": 3.771614072977909e-05,
      "loss": 0.0997,
      "step": 36870
    },
    {
      "epoch": 0.7375114986201656,
      "grad_norm": 0.1735760122537613,
      "learning_rate": 3.7712807796397767e-05,
      "loss": 0.0849,
      "step": 36880
    },
    {
      "epoch": 0.7377114746230452,
      "grad_norm": 0.11861273646354675,
      "learning_rate": 3.770947486301644e-05,
      "loss": 0.1042,
      "step": 36890
    },
    {
      "epoch": 0.7379114506259249,
      "grad_norm": 0.1424475759267807,
      "learning_rate": 3.770614192963511e-05,
      "loss": 0.0597,
      "step": 36900
    },
    {
      "epoch": 0.7381114266288046,
      "grad_norm": 0.0994153767824173,
      "learning_rate": 3.770280899625379e-05,
      "loss": 0.0402,
      "step": 36910
    },
    {
      "epoch": 0.7383114026316842,
      "grad_norm": 0.1559031456708908,
      "learning_rate": 3.769947606287246e-05,
      "loss": 0.0718,
      "step": 36920
    },
    {
      "epoch": 0.7385113786345638,
      "grad_norm": 0.16472557187080383,
      "learning_rate": 3.769614312949113e-05,
      "loss": 0.0722,
      "step": 36930
    },
    {
      "epoch": 0.7387113546374435,
      "grad_norm": 0.08288463950157166,
      "learning_rate": 3.7692810196109805e-05,
      "loss": 0.0979,
      "step": 36940
    },
    {
      "epoch": 0.7389113306403232,
      "grad_norm": 0.08640068024396896,
      "learning_rate": 3.7689477262728474e-05,
      "loss": 0.0852,
      "step": 36950
    },
    {
      "epoch": 0.7391113066432028,
      "grad_norm": 0.13780921697616577,
      "learning_rate": 3.7686144329347144e-05,
      "loss": 0.0932,
      "step": 36960
    },
    {
      "epoch": 0.7393112826460825,
      "grad_norm": 0.11722457408905029,
      "learning_rate": 3.768281139596582e-05,
      "loss": 0.0775,
      "step": 36970
    },
    {
      "epoch": 0.7395112586489622,
      "grad_norm": 0.1869778335094452,
      "learning_rate": 3.76794784625845e-05,
      "loss": 0.1095,
      "step": 36980
    },
    {
      "epoch": 0.7397112346518417,
      "grad_norm": 0.21302857995033264,
      "learning_rate": 3.7676145529203166e-05,
      "loss": 0.1148,
      "step": 36990
    },
    {
      "epoch": 0.7399112106547214,
      "grad_norm": 0.11325346678495407,
      "learning_rate": 3.7672812595821836e-05,
      "loss": 0.0993,
      "step": 37000
    },
    {
      "epoch": 0.7401111866576011,
      "grad_norm": 0.08601580560207367,
      "learning_rate": 3.766947966244051e-05,
      "loss": 0.1135,
      "step": 37010
    },
    {
      "epoch": 0.7403111626604807,
      "grad_norm": 0.11196109652519226,
      "learning_rate": 3.766614672905918e-05,
      "loss": 0.0594,
      "step": 37020
    },
    {
      "epoch": 0.7405111386633604,
      "grad_norm": 0.13025960326194763,
      "learning_rate": 3.766281379567785e-05,
      "loss": 0.0713,
      "step": 37030
    },
    {
      "epoch": 0.7407111146662401,
      "grad_norm": 0.23033510148525238,
      "learning_rate": 3.765948086229653e-05,
      "loss": 0.2305,
      "step": 37040
    },
    {
      "epoch": 0.7409110906691198,
      "grad_norm": 0.04667437821626663,
      "learning_rate": 3.76561479289152e-05,
      "loss": 0.0813,
      "step": 37050
    },
    {
      "epoch": 0.7411110666719993,
      "grad_norm": 0.09997500479221344,
      "learning_rate": 3.765281499553387e-05,
      "loss": 0.0948,
      "step": 37060
    },
    {
      "epoch": 0.741311042674879,
      "grad_norm": 0.16978691518306732,
      "learning_rate": 3.7649482062152543e-05,
      "loss": 0.1158,
      "step": 37070
    },
    {
      "epoch": 0.7415110186777587,
      "grad_norm": 0.15333674848079681,
      "learning_rate": 3.764614912877122e-05,
      "loss": 0.0753,
      "step": 37080
    },
    {
      "epoch": 0.7417109946806383,
      "grad_norm": 0.1160014271736145,
      "learning_rate": 3.764281619538989e-05,
      "loss": 0.0898,
      "step": 37090
    },
    {
      "epoch": 0.741910970683518,
      "grad_norm": 0.1269233673810959,
      "learning_rate": 3.763948326200856e-05,
      "loss": 0.0945,
      "step": 37100
    },
    {
      "epoch": 0.7421109466863977,
      "grad_norm": 0.08691582083702087,
      "learning_rate": 3.7636150328627236e-05,
      "loss": 0.0953,
      "step": 37110
    },
    {
      "epoch": 0.7423109226892773,
      "grad_norm": 0.11695857346057892,
      "learning_rate": 3.7632817395245905e-05,
      "loss": 0.0646,
      "step": 37120
    },
    {
      "epoch": 0.7425108986921569,
      "grad_norm": 0.10516763478517532,
      "learning_rate": 3.7629484461864575e-05,
      "loss": 0.1076,
      "step": 37130
    },
    {
      "epoch": 0.7427108746950366,
      "grad_norm": 0.14291417598724365,
      "learning_rate": 3.762615152848325e-05,
      "loss": 0.5024,
      "step": 37140
    },
    {
      "epoch": 0.7429108506979163,
      "grad_norm": 0.08670609444379807,
      "learning_rate": 3.762281859510192e-05,
      "loss": 0.0813,
      "step": 37150
    },
    {
      "epoch": 0.7431108267007959,
      "grad_norm": 0.12156202644109726,
      "learning_rate": 3.761948566172059e-05,
      "loss": 0.0951,
      "step": 37160
    },
    {
      "epoch": 0.7433108027036756,
      "grad_norm": 0.0768771693110466,
      "learning_rate": 3.761615272833927e-05,
      "loss": 0.0756,
      "step": 37170
    },
    {
      "epoch": 0.7435107787065552,
      "grad_norm": 0.15859052538871765,
      "learning_rate": 3.7612819794957936e-05,
      "loss": 0.1194,
      "step": 37180
    },
    {
      "epoch": 0.7437107547094348,
      "grad_norm": 0.11223957687616348,
      "learning_rate": 3.760948686157661e-05,
      "loss": 0.0841,
      "step": 37190
    },
    {
      "epoch": 0.7439107307123145,
      "grad_norm": 0.14911909401416779,
      "learning_rate": 3.760615392819529e-05,
      "loss": 0.0454,
      "step": 37200
    },
    {
      "epoch": 0.7441107067151942,
      "grad_norm": 0.21200035512447357,
      "learning_rate": 3.760282099481396e-05,
      "loss": 0.0777,
      "step": 37210
    },
    {
      "epoch": 0.7443106827180739,
      "grad_norm": 0.17637208104133606,
      "learning_rate": 3.759948806143263e-05,
      "loss": 0.0679,
      "step": 37220
    },
    {
      "epoch": 0.7445106587209535,
      "grad_norm": 0.08566578477621078,
      "learning_rate": 3.7596155128051305e-05,
      "loss": 0.0498,
      "step": 37230
    },
    {
      "epoch": 0.7447106347238331,
      "grad_norm": 0.10086914896965027,
      "learning_rate": 3.7592822194669974e-05,
      "loss": 0.0971,
      "step": 37240
    },
    {
      "epoch": 0.7449106107267128,
      "grad_norm": 0.06214001402258873,
      "learning_rate": 3.7589489261288644e-05,
      "loss": 0.0482,
      "step": 37250
    },
    {
      "epoch": 0.7451105867295924,
      "grad_norm": 0.13748784363269806,
      "learning_rate": 3.758615632790732e-05,
      "loss": 0.0689,
      "step": 37260
    },
    {
      "epoch": 0.7453105627324721,
      "grad_norm": 0.05107855051755905,
      "learning_rate": 3.758282339452599e-05,
      "loss": 0.0845,
      "step": 37270
    },
    {
      "epoch": 0.7455105387353518,
      "grad_norm": 0.21002182364463806,
      "learning_rate": 3.757949046114466e-05,
      "loss": 0.0961,
      "step": 37280
    },
    {
      "epoch": 0.7457105147382315,
      "grad_norm": 0.12896253168582916,
      "learning_rate": 3.7576157527763336e-05,
      "loss": 0.075,
      "step": 37290
    },
    {
      "epoch": 0.745910490741111,
      "grad_norm": 0.07561946660280228,
      "learning_rate": 3.757282459438201e-05,
      "loss": 0.0775,
      "step": 37300
    },
    {
      "epoch": 0.7461104667439907,
      "grad_norm": 0.057946640998125076,
      "learning_rate": 3.756949166100068e-05,
      "loss": 0.0535,
      "step": 37310
    },
    {
      "epoch": 0.7463104427468704,
      "grad_norm": 0.06952746957540512,
      "learning_rate": 3.756615872761935e-05,
      "loss": 0.0819,
      "step": 37320
    },
    {
      "epoch": 0.74651041874975,
      "grad_norm": 0.149692103266716,
      "learning_rate": 3.756282579423803e-05,
      "loss": 0.057,
      "step": 37330
    },
    {
      "epoch": 0.7467103947526297,
      "grad_norm": 0.1232776865363121,
      "learning_rate": 3.75594928608567e-05,
      "loss": 0.0934,
      "step": 37340
    },
    {
      "epoch": 0.7469103707555094,
      "grad_norm": 0.05856937915086746,
      "learning_rate": 3.755615992747537e-05,
      "loss": 0.0419,
      "step": 37350
    },
    {
      "epoch": 0.7471103467583889,
      "grad_norm": 0.08620259165763855,
      "learning_rate": 3.7552826994094044e-05,
      "loss": 0.0925,
      "step": 37360
    },
    {
      "epoch": 0.7473103227612686,
      "grad_norm": 0.16388632357120514,
      "learning_rate": 3.754949406071271e-05,
      "loss": 0.0888,
      "step": 37370
    },
    {
      "epoch": 0.7475102987641483,
      "grad_norm": 0.14336064457893372,
      "learning_rate": 3.754616112733138e-05,
      "loss": 0.0955,
      "step": 37380
    },
    {
      "epoch": 0.747710274767028,
      "grad_norm": 0.18067899346351624,
      "learning_rate": 3.7542828193950066e-05,
      "loss": 0.075,
      "step": 37390
    },
    {
      "epoch": 0.7479102507699076,
      "grad_norm": 0.11768276989459991,
      "learning_rate": 3.7539495260568736e-05,
      "loss": 0.0872,
      "step": 37400
    },
    {
      "epoch": 0.7481102267727873,
      "grad_norm": 0.153279110789299,
      "learning_rate": 3.7536162327187405e-05,
      "loss": 0.0606,
      "step": 37410
    },
    {
      "epoch": 0.748310202775667,
      "grad_norm": 0.09179109334945679,
      "learning_rate": 3.753282939380608e-05,
      "loss": 0.0594,
      "step": 37420
    },
    {
      "epoch": 0.7485101787785465,
      "grad_norm": 0.07491518557071686,
      "learning_rate": 3.752949646042475e-05,
      "loss": 0.0389,
      "step": 37430
    },
    {
      "epoch": 0.7487101547814262,
      "grad_norm": 0.15511824190616608,
      "learning_rate": 3.752616352704342e-05,
      "loss": 0.1153,
      "step": 37440
    },
    {
      "epoch": 0.7489101307843059,
      "grad_norm": 0.15407539904117584,
      "learning_rate": 3.75228305936621e-05,
      "loss": 0.0635,
      "step": 37450
    },
    {
      "epoch": 0.7491101067871856,
      "grad_norm": 0.0946335569024086,
      "learning_rate": 3.751949766028077e-05,
      "loss": 0.0835,
      "step": 37460
    },
    {
      "epoch": 0.7493100827900652,
      "grad_norm": 0.11327538639307022,
      "learning_rate": 3.7516164726899437e-05,
      "loss": 0.0621,
      "step": 37470
    },
    {
      "epoch": 0.7495100587929449,
      "grad_norm": 0.07063522189855576,
      "learning_rate": 3.751283179351811e-05,
      "loss": 0.074,
      "step": 37480
    },
    {
      "epoch": 0.7497100347958245,
      "grad_norm": 0.05551547929644585,
      "learning_rate": 3.750949886013679e-05,
      "loss": 0.0575,
      "step": 37490
    },
    {
      "epoch": 0.7499100107987041,
      "grad_norm": 0.08472755551338196,
      "learning_rate": 3.750616592675546e-05,
      "loss": 0.0404,
      "step": 37500
    },
    {
      "epoch": 0.7501099868015838,
      "grad_norm": 0.2713082432746887,
      "learning_rate": 3.750283299337413e-05,
      "loss": 0.0927,
      "step": 37510
    },
    {
      "epoch": 0.7503099628044635,
      "grad_norm": 0.07350930571556091,
      "learning_rate": 3.7499500059992805e-05,
      "loss": 0.0853,
      "step": 37520
    },
    {
      "epoch": 0.7505099388073431,
      "grad_norm": 0.13749657571315765,
      "learning_rate": 3.7496167126611475e-05,
      "loss": 0.0747,
      "step": 37530
    },
    {
      "epoch": 0.7507099148102228,
      "grad_norm": 0.18740734457969666,
      "learning_rate": 3.7492834193230144e-05,
      "loss": 0.0812,
      "step": 37540
    },
    {
      "epoch": 0.7509098908131024,
      "grad_norm": 0.14904172718524933,
      "learning_rate": 3.748950125984882e-05,
      "loss": 0.0705,
      "step": 37550
    },
    {
      "epoch": 0.7511098668159821,
      "grad_norm": 0.20870353281497955,
      "learning_rate": 3.748616832646749e-05,
      "loss": 0.1173,
      "step": 37560
    },
    {
      "epoch": 0.7513098428188617,
      "grad_norm": 0.11093319952487946,
      "learning_rate": 3.748283539308616e-05,
      "loss": 0.0674,
      "step": 37570
    },
    {
      "epoch": 0.7515098188217414,
      "grad_norm": 0.062278591096401215,
      "learning_rate": 3.7479502459704836e-05,
      "loss": 0.0659,
      "step": 37580
    },
    {
      "epoch": 0.7517097948246211,
      "grad_norm": 0.10188355296850204,
      "learning_rate": 3.747616952632351e-05,
      "loss": 0.0645,
      "step": 37590
    },
    {
      "epoch": 0.7519097708275007,
      "grad_norm": 0.06288183480501175,
      "learning_rate": 3.747283659294218e-05,
      "loss": 0.0572,
      "step": 37600
    },
    {
      "epoch": 0.7521097468303803,
      "grad_norm": 0.08308145403862,
      "learning_rate": 3.746950365956086e-05,
      "loss": 0.0499,
      "step": 37610
    },
    {
      "epoch": 0.75230972283326,
      "grad_norm": 0.05185094475746155,
      "learning_rate": 3.746617072617953e-05,
      "loss": 0.0789,
      "step": 37620
    },
    {
      "epoch": 0.7525096988361397,
      "grad_norm": 0.2074512541294098,
      "learning_rate": 3.74628377927982e-05,
      "loss": 0.0899,
      "step": 37630
    },
    {
      "epoch": 0.7527096748390193,
      "grad_norm": 0.07283417880535126,
      "learning_rate": 3.7459504859416874e-05,
      "loss": 0.0662,
      "step": 37640
    },
    {
      "epoch": 0.752909650841899,
      "grad_norm": 0.1329069882631302,
      "learning_rate": 3.7456171926035544e-05,
      "loss": 0.0938,
      "step": 37650
    },
    {
      "epoch": 0.7531096268447787,
      "grad_norm": 0.22245793044567108,
      "learning_rate": 3.7452838992654213e-05,
      "loss": 0.1052,
      "step": 37660
    },
    {
      "epoch": 0.7533096028476582,
      "grad_norm": 0.08542407304048538,
      "learning_rate": 3.744950605927289e-05,
      "loss": 0.0641,
      "step": 37670
    },
    {
      "epoch": 0.7535095788505379,
      "grad_norm": 0.10688081383705139,
      "learning_rate": 3.744617312589156e-05,
      "loss": 0.1445,
      "step": 37680
    },
    {
      "epoch": 0.7537095548534176,
      "grad_norm": 0.09526214003562927,
      "learning_rate": 3.744284019251023e-05,
      "loss": 0.093,
      "step": 37690
    },
    {
      "epoch": 0.7539095308562972,
      "grad_norm": 0.08737082034349442,
      "learning_rate": 3.7439507259128905e-05,
      "loss": 0.1087,
      "step": 37700
    },
    {
      "epoch": 0.7541095068591769,
      "grad_norm": 0.07807689905166626,
      "learning_rate": 3.743617432574758e-05,
      "loss": 0.0402,
      "step": 37710
    },
    {
      "epoch": 0.7543094828620566,
      "grad_norm": 0.09653884917497635,
      "learning_rate": 3.743284139236625e-05,
      "loss": 0.0943,
      "step": 37720
    },
    {
      "epoch": 0.7545094588649363,
      "grad_norm": 0.11522374302148819,
      "learning_rate": 3.742950845898492e-05,
      "loss": 0.0717,
      "step": 37730
    },
    {
      "epoch": 0.7547094348678158,
      "grad_norm": 0.11345375329256058,
      "learning_rate": 3.74261755256036e-05,
      "loss": 0.0738,
      "step": 37740
    },
    {
      "epoch": 0.7549094108706955,
      "grad_norm": 0.06667501479387283,
      "learning_rate": 3.742284259222227e-05,
      "loss": 0.0708,
      "step": 37750
    },
    {
      "epoch": 0.7551093868735752,
      "grad_norm": 0.16127796471118927,
      "learning_rate": 3.741950965884094e-05,
      "loss": 0.0633,
      "step": 37760
    },
    {
      "epoch": 0.7553093628764548,
      "grad_norm": 0.08955922722816467,
      "learning_rate": 3.741617672545961e-05,
      "loss": 0.0676,
      "step": 37770
    },
    {
      "epoch": 0.7555093388793345,
      "grad_norm": 0.22751787304878235,
      "learning_rate": 3.741284379207828e-05,
      "loss": 0.0819,
      "step": 37780
    },
    {
      "epoch": 0.7557093148822142,
      "grad_norm": 0.18867748975753784,
      "learning_rate": 3.740951085869695e-05,
      "loss": 0.0744,
      "step": 37790
    },
    {
      "epoch": 0.7559092908850938,
      "grad_norm": 0.12073968350887299,
      "learning_rate": 3.7406177925315636e-05,
      "loss": 0.0869,
      "step": 37800
    },
    {
      "epoch": 0.7561092668879734,
      "grad_norm": 0.06757203489542007,
      "learning_rate": 3.7402844991934305e-05,
      "loss": 0.0445,
      "step": 37810
    },
    {
      "epoch": 0.7563092428908531,
      "grad_norm": 0.11022646725177765,
      "learning_rate": 3.7399512058552975e-05,
      "loss": 0.0422,
      "step": 37820
    },
    {
      "epoch": 0.7565092188937328,
      "grad_norm": 0.0634874701499939,
      "learning_rate": 3.739617912517165e-05,
      "loss": 0.0574,
      "step": 37830
    },
    {
      "epoch": 0.7567091948966124,
      "grad_norm": 0.07634424418210983,
      "learning_rate": 3.739284619179032e-05,
      "loss": 0.034,
      "step": 37840
    },
    {
      "epoch": 0.7569091708994921,
      "grad_norm": 0.13862614333629608,
      "learning_rate": 3.738951325840899e-05,
      "loss": 0.0831,
      "step": 37850
    },
    {
      "epoch": 0.7571091469023717,
      "grad_norm": 0.1693231463432312,
      "learning_rate": 3.738618032502767e-05,
      "loss": 0.0943,
      "step": 37860
    },
    {
      "epoch": 0.7573091229052513,
      "grad_norm": 0.08747440576553345,
      "learning_rate": 3.7382847391646336e-05,
      "loss": 0.0866,
      "step": 37870
    },
    {
      "epoch": 0.757509098908131,
      "grad_norm": 0.06814026832580566,
      "learning_rate": 3.7379514458265006e-05,
      "loss": 0.074,
      "step": 37880
    },
    {
      "epoch": 0.7577090749110107,
      "grad_norm": 0.11926205456256866,
      "learning_rate": 3.737618152488368e-05,
      "loss": 0.1047,
      "step": 37890
    },
    {
      "epoch": 0.7579090509138904,
      "grad_norm": 0.08077298104763031,
      "learning_rate": 3.737284859150236e-05,
      "loss": 0.0688,
      "step": 37900
    },
    {
      "epoch": 0.75810902691677,
      "grad_norm": 0.08852001279592514,
      "learning_rate": 3.736951565812103e-05,
      "loss": 0.0854,
      "step": 37910
    },
    {
      "epoch": 0.7583090029196496,
      "grad_norm": 0.10870317369699478,
      "learning_rate": 3.73661827247397e-05,
      "loss": 0.1088,
      "step": 37920
    },
    {
      "epoch": 0.7585089789225293,
      "grad_norm": 0.06633052229881287,
      "learning_rate": 3.7362849791358374e-05,
      "loss": 0.0597,
      "step": 37930
    },
    {
      "epoch": 0.7587089549254089,
      "grad_norm": 0.13832591474056244,
      "learning_rate": 3.7359516857977044e-05,
      "loss": 0.0572,
      "step": 37940
    },
    {
      "epoch": 0.7589089309282886,
      "grad_norm": 0.08296554535627365,
      "learning_rate": 3.7356183924595714e-05,
      "loss": 0.0429,
      "step": 37950
    },
    {
      "epoch": 0.7591089069311683,
      "grad_norm": 0.15187928080558777,
      "learning_rate": 3.735285099121439e-05,
      "loss": 0.0962,
      "step": 37960
    },
    {
      "epoch": 0.759308882934048,
      "grad_norm": 0.21155495941638947,
      "learning_rate": 3.734951805783306e-05,
      "loss": 0.1302,
      "step": 37970
    },
    {
      "epoch": 0.7595088589369275,
      "grad_norm": 0.14311006665229797,
      "learning_rate": 3.734618512445173e-05,
      "loss": 0.1159,
      "step": 37980
    },
    {
      "epoch": 0.7597088349398072,
      "grad_norm": 0.08856502175331116,
      "learning_rate": 3.7342852191070406e-05,
      "loss": 0.0625,
      "step": 37990
    },
    {
      "epoch": 0.7599088109426869,
      "grad_norm": 0.11205039918422699,
      "learning_rate": 3.733951925768908e-05,
      "loss": 0.098,
      "step": 38000
    },
    {
      "epoch": 0.7601087869455665,
      "grad_norm": 0.10569474846124649,
      "learning_rate": 3.733618632430775e-05,
      "loss": 0.0933,
      "step": 38010
    },
    {
      "epoch": 0.7603087629484462,
      "grad_norm": 0.1513650119304657,
      "learning_rate": 3.733285339092643e-05,
      "loss": 0.0669,
      "step": 38020
    },
    {
      "epoch": 0.7605087389513259,
      "grad_norm": 0.14120949804782867,
      "learning_rate": 3.73295204575451e-05,
      "loss": 0.0567,
      "step": 38030
    },
    {
      "epoch": 0.7607087149542054,
      "grad_norm": 0.22285830974578857,
      "learning_rate": 3.732618752416377e-05,
      "loss": 0.0984,
      "step": 38040
    },
    {
      "epoch": 0.7609086909570851,
      "grad_norm": 0.1347891092300415,
      "learning_rate": 3.7322854590782444e-05,
      "loss": 0.0635,
      "step": 38050
    },
    {
      "epoch": 0.7611086669599648,
      "grad_norm": 0.11266852915287018,
      "learning_rate": 3.731952165740111e-05,
      "loss": 0.0788,
      "step": 38060
    },
    {
      "epoch": 0.7613086429628445,
      "grad_norm": 0.18214856088161469,
      "learning_rate": 3.731618872401978e-05,
      "loss": 0.0647,
      "step": 38070
    },
    {
      "epoch": 0.7615086189657241,
      "grad_norm": 0.18510156869888306,
      "learning_rate": 3.731285579063846e-05,
      "loss": 0.0996,
      "step": 38080
    },
    {
      "epoch": 0.7617085949686038,
      "grad_norm": 0.12709492444992065,
      "learning_rate": 3.730952285725713e-05,
      "loss": 0.0766,
      "step": 38090
    },
    {
      "epoch": 0.7619085709714835,
      "grad_norm": 0.1750282645225525,
      "learning_rate": 3.73061899238758e-05,
      "loss": 0.0677,
      "step": 38100
    },
    {
      "epoch": 0.762108546974363,
      "grad_norm": 0.10521479696035385,
      "learning_rate": 3.7302856990494475e-05,
      "loss": 0.0583,
      "step": 38110
    },
    {
      "epoch": 0.7623085229772427,
      "grad_norm": 0.1846500039100647,
      "learning_rate": 3.729952405711315e-05,
      "loss": 0.0792,
      "step": 38120
    },
    {
      "epoch": 0.7625084989801224,
      "grad_norm": 0.12879061698913574,
      "learning_rate": 3.729619112373182e-05,
      "loss": 0.0564,
      "step": 38130
    },
    {
      "epoch": 0.7627084749830021,
      "grad_norm": 0.07555301487445831,
      "learning_rate": 3.729285819035049e-05,
      "loss": 0.0961,
      "step": 38140
    },
    {
      "epoch": 0.7629084509858817,
      "grad_norm": 0.11998147517442703,
      "learning_rate": 3.728952525696917e-05,
      "loss": 0.0688,
      "step": 38150
    },
    {
      "epoch": 0.7631084269887614,
      "grad_norm": 0.0946895107626915,
      "learning_rate": 3.7286192323587837e-05,
      "loss": 0.0683,
      "step": 38160
    },
    {
      "epoch": 0.763308402991641,
      "grad_norm": 0.12318424135446548,
      "learning_rate": 3.7282859390206506e-05,
      "loss": 0.0648,
      "step": 38170
    },
    {
      "epoch": 0.7635083789945206,
      "grad_norm": 0.12514334917068481,
      "learning_rate": 3.727952645682518e-05,
      "loss": 0.0921,
      "step": 38180
    },
    {
      "epoch": 0.7637083549974003,
      "grad_norm": 0.16405215859413147,
      "learning_rate": 3.727619352344385e-05,
      "loss": 0.0816,
      "step": 38190
    },
    {
      "epoch": 0.76390833100028,
      "grad_norm": 0.18958532810211182,
      "learning_rate": 3.727286059006252e-05,
      "loss": 0.0933,
      "step": 38200
    },
    {
      "epoch": 0.7641083070031596,
      "grad_norm": 0.1522568315267563,
      "learning_rate": 3.7269527656681205e-05,
      "loss": 0.0835,
      "step": 38210
    },
    {
      "epoch": 0.7643082830060393,
      "grad_norm": 0.1298510879278183,
      "learning_rate": 3.7266194723299875e-05,
      "loss": 0.1053,
      "step": 38220
    },
    {
      "epoch": 0.7645082590089189,
      "grad_norm": 0.11551111936569214,
      "learning_rate": 3.7262861789918544e-05,
      "loss": 0.0866,
      "step": 38230
    },
    {
      "epoch": 0.7647082350117986,
      "grad_norm": 0.07654647529125214,
      "learning_rate": 3.725952885653722e-05,
      "loss": 0.0723,
      "step": 38240
    },
    {
      "epoch": 0.7649082110146782,
      "grad_norm": 0.14292845129966736,
      "learning_rate": 3.725619592315589e-05,
      "loss": 0.0646,
      "step": 38250
    },
    {
      "epoch": 0.7651081870175579,
      "grad_norm": 0.06431024521589279,
      "learning_rate": 3.725286298977456e-05,
      "loss": 0.0747,
      "step": 38260
    },
    {
      "epoch": 0.7653081630204376,
      "grad_norm": 0.14562532305717468,
      "learning_rate": 3.7249530056393236e-05,
      "loss": 0.067,
      "step": 38270
    },
    {
      "epoch": 0.7655081390233172,
      "grad_norm": 0.1999298334121704,
      "learning_rate": 3.7246197123011906e-05,
      "loss": 0.0687,
      "step": 38280
    },
    {
      "epoch": 0.7657081150261968,
      "grad_norm": 0.13673613965511322,
      "learning_rate": 3.7242864189630575e-05,
      "loss": 0.0799,
      "step": 38290
    },
    {
      "epoch": 0.7659080910290765,
      "grad_norm": 0.11163750290870667,
      "learning_rate": 3.723953125624925e-05,
      "loss": 0.05,
      "step": 38300
    },
    {
      "epoch": 0.7661080670319562,
      "grad_norm": 0.11140459030866623,
      "learning_rate": 3.723619832286793e-05,
      "loss": 0.0703,
      "step": 38310
    },
    {
      "epoch": 0.7663080430348358,
      "grad_norm": 0.1903635710477829,
      "learning_rate": 3.72328653894866e-05,
      "loss": 0.0938,
      "step": 38320
    },
    {
      "epoch": 0.7665080190377155,
      "grad_norm": 0.0917445719242096,
      "learning_rate": 3.722953245610527e-05,
      "loss": 0.082,
      "step": 38330
    },
    {
      "epoch": 0.7667079950405952,
      "grad_norm": 0.2154606133699417,
      "learning_rate": 3.7226199522723944e-05,
      "loss": 0.0814,
      "step": 38340
    },
    {
      "epoch": 0.7669079710434747,
      "grad_norm": 0.16717703640460968,
      "learning_rate": 3.7222866589342613e-05,
      "loss": 0.0872,
      "step": 38350
    },
    {
      "epoch": 0.7671079470463544,
      "grad_norm": 0.07779578119516373,
      "learning_rate": 3.721953365596128e-05,
      "loss": 0.0639,
      "step": 38360
    },
    {
      "epoch": 0.7673079230492341,
      "grad_norm": 0.2084459662437439,
      "learning_rate": 3.721620072257996e-05,
      "loss": 0.1173,
      "step": 38370
    },
    {
      "epoch": 0.7675078990521137,
      "grad_norm": 0.12652018666267395,
      "learning_rate": 3.721286778919863e-05,
      "loss": 0.1063,
      "step": 38380
    },
    {
      "epoch": 0.7677078750549934,
      "grad_norm": 0.08888076990842819,
      "learning_rate": 3.72095348558173e-05,
      "loss": 0.0959,
      "step": 38390
    },
    {
      "epoch": 0.7679078510578731,
      "grad_norm": 0.059302110224962234,
      "learning_rate": 3.7206201922435975e-05,
      "loss": 0.0787,
      "step": 38400
    },
    {
      "epoch": 0.7681078270607528,
      "grad_norm": 0.092989981174469,
      "learning_rate": 3.720286898905465e-05,
      "loss": 0.0722,
      "step": 38410
    },
    {
      "epoch": 0.7683078030636323,
      "grad_norm": 0.16480714082717896,
      "learning_rate": 3.719953605567332e-05,
      "loss": 0.0815,
      "step": 38420
    },
    {
      "epoch": 0.768507779066512,
      "grad_norm": 0.09257467836141586,
      "learning_rate": 3.7196203122292e-05,
      "loss": 0.0878,
      "step": 38430
    },
    {
      "epoch": 0.7687077550693917,
      "grad_norm": 0.08965497463941574,
      "learning_rate": 3.719287018891067e-05,
      "loss": 0.0463,
      "step": 38440
    },
    {
      "epoch": 0.7689077310722713,
      "grad_norm": 0.11074797064065933,
      "learning_rate": 3.718953725552934e-05,
      "loss": 0.0872,
      "step": 38450
    },
    {
      "epoch": 0.769107707075151,
      "grad_norm": 0.16776490211486816,
      "learning_rate": 3.718620432214801e-05,
      "loss": 0.0737,
      "step": 38460
    },
    {
      "epoch": 0.7693076830780307,
      "grad_norm": 0.1316651701927185,
      "learning_rate": 3.718287138876668e-05,
      "loss": 0.0695,
      "step": 38470
    },
    {
      "epoch": 0.7695076590809103,
      "grad_norm": 0.11403899639844894,
      "learning_rate": 3.717953845538535e-05,
      "loss": 0.0679,
      "step": 38480
    },
    {
      "epoch": 0.7697076350837899,
      "grad_norm": 0.12082350999116898,
      "learning_rate": 3.717620552200403e-05,
      "loss": 0.0614,
      "step": 38490
    },
    {
      "epoch": 0.7699076110866696,
      "grad_norm": 0.19411008059978485,
      "learning_rate": 3.71728725886227e-05,
      "loss": 0.1261,
      "step": 38500
    },
    {
      "epoch": 0.7701075870895493,
      "grad_norm": 0.07347101718187332,
      "learning_rate": 3.7169539655241375e-05,
      "loss": 0.0655,
      "step": 38510
    },
    {
      "epoch": 0.7703075630924289,
      "grad_norm": 0.2050183266401291,
      "learning_rate": 3.7166206721860044e-05,
      "loss": 0.0914,
      "step": 38520
    },
    {
      "epoch": 0.7705075390953086,
      "grad_norm": 0.09682890772819519,
      "learning_rate": 3.716287378847872e-05,
      "loss": 0.0545,
      "step": 38530
    },
    {
      "epoch": 0.7707075150981882,
      "grad_norm": 0.2320210039615631,
      "learning_rate": 3.715954085509739e-05,
      "loss": 0.0849,
      "step": 38540
    },
    {
      "epoch": 0.7709074911010678,
      "grad_norm": 0.09765315055847168,
      "learning_rate": 3.715620792171606e-05,
      "loss": 0.0435,
      "step": 38550
    },
    {
      "epoch": 0.7711074671039475,
      "grad_norm": 0.16580253839492798,
      "learning_rate": 3.7152874988334736e-05,
      "loss": 0.0997,
      "step": 38560
    },
    {
      "epoch": 0.7713074431068272,
      "grad_norm": 0.13262967765331268,
      "learning_rate": 3.7149542054953406e-05,
      "loss": 0.0976,
      "step": 38570
    },
    {
      "epoch": 0.7715074191097069,
      "grad_norm": 0.1353248804807663,
      "learning_rate": 3.7146209121572076e-05,
      "loss": 0.0656,
      "step": 38580
    },
    {
      "epoch": 0.7717073951125865,
      "grad_norm": 0.13230594992637634,
      "learning_rate": 3.714287618819075e-05,
      "loss": 0.0963,
      "step": 38590
    },
    {
      "epoch": 0.7719073711154661,
      "grad_norm": 0.10191097110509872,
      "learning_rate": 3.713954325480942e-05,
      "loss": 0.0539,
      "step": 38600
    },
    {
      "epoch": 0.7721073471183458,
      "grad_norm": 0.20111387968063354,
      "learning_rate": 3.713621032142809e-05,
      "loss": 0.0893,
      "step": 38610
    },
    {
      "epoch": 0.7723073231212254,
      "grad_norm": 0.07210423797369003,
      "learning_rate": 3.7132877388046774e-05,
      "loss": 0.09,
      "step": 38620
    },
    {
      "epoch": 0.7725072991241051,
      "grad_norm": 0.07139916718006134,
      "learning_rate": 3.7129544454665444e-05,
      "loss": 0.0758,
      "step": 38630
    },
    {
      "epoch": 0.7727072751269848,
      "grad_norm": 0.07575096935033798,
      "learning_rate": 3.7126211521284114e-05,
      "loss": 0.0753,
      "step": 38640
    },
    {
      "epoch": 0.7729072511298645,
      "grad_norm": 0.1747751086950302,
      "learning_rate": 3.712287858790279e-05,
      "loss": 0.1325,
      "step": 38650
    },
    {
      "epoch": 0.773107227132744,
      "grad_norm": 0.12076417356729507,
      "learning_rate": 3.711954565452146e-05,
      "loss": 0.0898,
      "step": 38660
    },
    {
      "epoch": 0.7733072031356237,
      "grad_norm": 0.06581821292638779,
      "learning_rate": 3.711621272114013e-05,
      "loss": 0.0942,
      "step": 38670
    },
    {
      "epoch": 0.7735071791385034,
      "grad_norm": 0.18959404528141022,
      "learning_rate": 3.7112879787758806e-05,
      "loss": 0.0503,
      "step": 38680
    },
    {
      "epoch": 0.773707155141383,
      "grad_norm": 0.1795516312122345,
      "learning_rate": 3.7109546854377475e-05,
      "loss": 0.0707,
      "step": 38690
    },
    {
      "epoch": 0.7739071311442627,
      "grad_norm": 0.18240147829055786,
      "learning_rate": 3.7106213920996145e-05,
      "loss": 0.0812,
      "step": 38700
    },
    {
      "epoch": 0.7741071071471424,
      "grad_norm": 0.1517905592918396,
      "learning_rate": 3.710288098761482e-05,
      "loss": 0.0719,
      "step": 38710
    },
    {
      "epoch": 0.774307083150022,
      "grad_norm": 0.1520259827375412,
      "learning_rate": 3.70995480542335e-05,
      "loss": 0.0806,
      "step": 38720
    },
    {
      "epoch": 0.7745070591529016,
      "grad_norm": 0.17078545689582825,
      "learning_rate": 3.709621512085217e-05,
      "loss": 0.0827,
      "step": 38730
    },
    {
      "epoch": 0.7747070351557813,
      "grad_norm": 0.07753793895244598,
      "learning_rate": 3.709288218747084e-05,
      "loss": 0.0492,
      "step": 38740
    },
    {
      "epoch": 0.774907011158661,
      "grad_norm": 0.1562170684337616,
      "learning_rate": 3.708954925408951e-05,
      "loss": 0.0647,
      "step": 38750
    },
    {
      "epoch": 0.7751069871615406,
      "grad_norm": 0.14269453287124634,
      "learning_rate": 3.708621632070818e-05,
      "loss": 0.0658,
      "step": 38760
    },
    {
      "epoch": 0.7753069631644203,
      "grad_norm": 0.09784596413373947,
      "learning_rate": 3.708288338732685e-05,
      "loss": 0.0898,
      "step": 38770
    },
    {
      "epoch": 0.7755069391673,
      "grad_norm": 0.16374176740646362,
      "learning_rate": 3.707955045394553e-05,
      "loss": 0.1076,
      "step": 38780
    },
    {
      "epoch": 0.7757069151701795,
      "grad_norm": 0.1422143429517746,
      "learning_rate": 3.70762175205642e-05,
      "loss": 0.0767,
      "step": 38790
    },
    {
      "epoch": 0.7759068911730592,
      "grad_norm": 0.21139992773532867,
      "learning_rate": 3.707288458718287e-05,
      "loss": 0.0789,
      "step": 38800
    },
    {
      "epoch": 0.7761068671759389,
      "grad_norm": 0.13760648667812347,
      "learning_rate": 3.7069551653801545e-05,
      "loss": 0.0873,
      "step": 38810
    },
    {
      "epoch": 0.7763068431788186,
      "grad_norm": 0.21024100482463837,
      "learning_rate": 3.706621872042022e-05,
      "loss": 0.0837,
      "step": 38820
    },
    {
      "epoch": 0.7765068191816982,
      "grad_norm": 0.1067267656326294,
      "learning_rate": 3.706288578703889e-05,
      "loss": 0.0847,
      "step": 38830
    },
    {
      "epoch": 0.7767067951845779,
      "grad_norm": 0.10210797935724258,
      "learning_rate": 3.705955285365757e-05,
      "loss": 0.095,
      "step": 38840
    },
    {
      "epoch": 0.7769067711874575,
      "grad_norm": 0.0850636288523674,
      "learning_rate": 3.7056219920276237e-05,
      "loss": 0.0849,
      "step": 38850
    },
    {
      "epoch": 0.7771067471903371,
      "grad_norm": 0.0640544667840004,
      "learning_rate": 3.7052886986894906e-05,
      "loss": 0.0719,
      "step": 38860
    },
    {
      "epoch": 0.7773067231932168,
      "grad_norm": 0.09838010370731354,
      "learning_rate": 3.704955405351358e-05,
      "loss": 0.0601,
      "step": 38870
    },
    {
      "epoch": 0.7775066991960965,
      "grad_norm": 0.0865246057510376,
      "learning_rate": 3.704622112013225e-05,
      "loss": 0.0468,
      "step": 38880
    },
    {
      "epoch": 0.7777066751989761,
      "grad_norm": 0.189368337392807,
      "learning_rate": 3.704288818675092e-05,
      "loss": 0.0783,
      "step": 38890
    },
    {
      "epoch": 0.7779066512018558,
      "grad_norm": 0.09001608192920685,
      "learning_rate": 3.70395552533696e-05,
      "loss": 0.0399,
      "step": 38900
    },
    {
      "epoch": 0.7781066272047354,
      "grad_norm": 0.18172134459018707,
      "learning_rate": 3.703622231998827e-05,
      "loss": 0.0935,
      "step": 38910
    },
    {
      "epoch": 0.7783066032076151,
      "grad_norm": 0.2524765431880951,
      "learning_rate": 3.7032889386606944e-05,
      "loss": 0.091,
      "step": 38920
    },
    {
      "epoch": 0.7785065792104947,
      "grad_norm": 0.16222959756851196,
      "learning_rate": 3.7029556453225614e-05,
      "loss": 0.0795,
      "step": 38930
    },
    {
      "epoch": 0.7787065552133744,
      "grad_norm": 0.10993961989879608,
      "learning_rate": 3.702622351984429e-05,
      "loss": 0.0848,
      "step": 38940
    },
    {
      "epoch": 0.7789065312162541,
      "grad_norm": 0.15260152518749237,
      "learning_rate": 3.702289058646296e-05,
      "loss": 0.1039,
      "step": 38950
    },
    {
      "epoch": 0.7791065072191337,
      "grad_norm": 0.0983208417892456,
      "learning_rate": 3.701955765308163e-05,
      "loss": 0.1005,
      "step": 38960
    },
    {
      "epoch": 0.7793064832220133,
      "grad_norm": 0.09446536749601364,
      "learning_rate": 3.7016224719700306e-05,
      "loss": 0.0931,
      "step": 38970
    },
    {
      "epoch": 0.779506459224893,
      "grad_norm": 0.1056768000125885,
      "learning_rate": 3.7012891786318975e-05,
      "loss": 0.0921,
      "step": 38980
    },
    {
      "epoch": 0.7797064352277727,
      "grad_norm": 0.15528781712055206,
      "learning_rate": 3.7009558852937645e-05,
      "loss": 0.058,
      "step": 38990
    },
    {
      "epoch": 0.7799064112306523,
      "grad_norm": 0.15687914192676544,
      "learning_rate": 3.700622591955632e-05,
      "loss": 0.0684,
      "step": 39000
    },
    {
      "epoch": 0.780106387233532,
      "grad_norm": 0.12264678627252579,
      "learning_rate": 3.700289298617499e-05,
      "loss": 0.0742,
      "step": 39010
    },
    {
      "epoch": 0.7803063632364117,
      "grad_norm": 0.10813716799020767,
      "learning_rate": 3.699956005279367e-05,
      "loss": 0.0594,
      "step": 39020
    },
    {
      "epoch": 0.7805063392392912,
      "grad_norm": 0.0360494889318943,
      "learning_rate": 3.6996227119412344e-05,
      "loss": 0.0498,
      "step": 39030
    },
    {
      "epoch": 0.7807063152421709,
      "grad_norm": 0.06746125221252441,
      "learning_rate": 3.6992894186031013e-05,
      "loss": 0.0833,
      "step": 39040
    },
    {
      "epoch": 0.7809062912450506,
      "grad_norm": 0.13287347555160522,
      "learning_rate": 3.698956125264968e-05,
      "loss": 0.0746,
      "step": 39050
    },
    {
      "epoch": 0.7811062672479302,
      "grad_norm": 0.10958972573280334,
      "learning_rate": 3.698622831926836e-05,
      "loss": 0.0691,
      "step": 39060
    },
    {
      "epoch": 0.7813062432508099,
      "grad_norm": 0.08908797800540924,
      "learning_rate": 3.698289538588703e-05,
      "loss": 0.0961,
      "step": 39070
    },
    {
      "epoch": 0.7815062192536896,
      "grad_norm": 0.1500166356563568,
      "learning_rate": 3.69795624525057e-05,
      "loss": 0.0781,
      "step": 39080
    },
    {
      "epoch": 0.7817061952565693,
      "grad_norm": 0.12751801311969757,
      "learning_rate": 3.6976229519124375e-05,
      "loss": 0.069,
      "step": 39090
    },
    {
      "epoch": 0.7819061712594488,
      "grad_norm": 0.12683908641338348,
      "learning_rate": 3.6972896585743045e-05,
      "loss": 0.0917,
      "step": 39100
    },
    {
      "epoch": 0.7821061472623285,
      "grad_norm": 0.18709811568260193,
      "learning_rate": 3.6969563652361714e-05,
      "loss": 0.1145,
      "step": 39110
    },
    {
      "epoch": 0.7823061232652082,
      "grad_norm": 0.0987779051065445,
      "learning_rate": 3.696623071898039e-05,
      "loss": 0.1189,
      "step": 39120
    },
    {
      "epoch": 0.7825060992680878,
      "grad_norm": 0.12755927443504333,
      "learning_rate": 3.696289778559907e-05,
      "loss": 0.0536,
      "step": 39130
    },
    {
      "epoch": 0.7827060752709675,
      "grad_norm": 0.05628800764679909,
      "learning_rate": 3.695956485221774e-05,
      "loss": 0.0766,
      "step": 39140
    },
    {
      "epoch": 0.7829060512738472,
      "grad_norm": 0.0868234783411026,
      "learning_rate": 3.6956231918836406e-05,
      "loss": 0.0721,
      "step": 39150
    },
    {
      "epoch": 0.7831060272767268,
      "grad_norm": 0.16866864264011383,
      "learning_rate": 3.695289898545508e-05,
      "loss": 0.0842,
      "step": 39160
    },
    {
      "epoch": 0.7833060032796064,
      "grad_norm": 0.19660185277462006,
      "learning_rate": 3.694956605207375e-05,
      "loss": 0.0748,
      "step": 39170
    },
    {
      "epoch": 0.7835059792824861,
      "grad_norm": 0.1725674420595169,
      "learning_rate": 3.694623311869242e-05,
      "loss": 0.0686,
      "step": 39180
    },
    {
      "epoch": 0.7837059552853658,
      "grad_norm": 0.07501436769962311,
      "learning_rate": 3.69429001853111e-05,
      "loss": 0.0451,
      "step": 39190
    },
    {
      "epoch": 0.7839059312882454,
      "grad_norm": 0.16049505770206451,
      "learning_rate": 3.693956725192977e-05,
      "loss": 0.0557,
      "step": 39200
    },
    {
      "epoch": 0.7841059072911251,
      "grad_norm": 0.13031801581382751,
      "learning_rate": 3.693623431854844e-05,
      "loss": 0.086,
      "step": 39210
    },
    {
      "epoch": 0.7843058832940047,
      "grad_norm": 0.05493375286459923,
      "learning_rate": 3.6932901385167114e-05,
      "loss": 0.0926,
      "step": 39220
    },
    {
      "epoch": 0.7845058592968843,
      "grad_norm": 0.11573805660009384,
      "learning_rate": 3.692956845178579e-05,
      "loss": 0.0877,
      "step": 39230
    },
    {
      "epoch": 0.784705835299764,
      "grad_norm": 0.08035117387771606,
      "learning_rate": 3.692623551840446e-05,
      "loss": 0.0802,
      "step": 39240
    },
    {
      "epoch": 0.7849058113026437,
      "grad_norm": 0.16068734228610992,
      "learning_rate": 3.6922902585023136e-05,
      "loss": 0.0767,
      "step": 39250
    },
    {
      "epoch": 0.7851057873055234,
      "grad_norm": 0.05422317609190941,
      "learning_rate": 3.6919569651641806e-05,
      "loss": 0.0719,
      "step": 39260
    },
    {
      "epoch": 0.785305763308403,
      "grad_norm": 0.1961430311203003,
      "learning_rate": 3.6916236718260476e-05,
      "loss": 0.0899,
      "step": 39270
    },
    {
      "epoch": 0.7855057393112826,
      "grad_norm": 0.1962168663740158,
      "learning_rate": 3.691290378487915e-05,
      "loss": 0.0565,
      "step": 39280
    },
    {
      "epoch": 0.7857057153141623,
      "grad_norm": 0.05855802819132805,
      "learning_rate": 3.690957085149782e-05,
      "loss": 0.0911,
      "step": 39290
    },
    {
      "epoch": 0.7859056913170419,
      "grad_norm": 0.18060535192489624,
      "learning_rate": 3.690623791811649e-05,
      "loss": 0.071,
      "step": 39300
    },
    {
      "epoch": 0.7861056673199216,
      "grad_norm": 0.10552243888378143,
      "learning_rate": 3.690290498473517e-05,
      "loss": 0.0704,
      "step": 39310
    },
    {
      "epoch": 0.7863056433228013,
      "grad_norm": 0.14053688943386078,
      "learning_rate": 3.689957205135384e-05,
      "loss": 0.096,
      "step": 39320
    },
    {
      "epoch": 0.786505619325681,
      "grad_norm": 0.1379546821117401,
      "learning_rate": 3.6896239117972514e-05,
      "loss": 0.0545,
      "step": 39330
    },
    {
      "epoch": 0.7867055953285605,
      "grad_norm": 0.13994945585727692,
      "learning_rate": 3.689290618459118e-05,
      "loss": 0.0512,
      "step": 39340
    },
    {
      "epoch": 0.7869055713314402,
      "grad_norm": 0.1159147098660469,
      "learning_rate": 3.688957325120986e-05,
      "loss": 0.055,
      "step": 39350
    },
    {
      "epoch": 0.7871055473343199,
      "grad_norm": 0.13781513273715973,
      "learning_rate": 3.688624031782853e-05,
      "loss": 0.0888,
      "step": 39360
    },
    {
      "epoch": 0.7873055233371995,
      "grad_norm": 0.17396922409534454,
      "learning_rate": 3.68829073844472e-05,
      "loss": 0.086,
      "step": 39370
    },
    {
      "epoch": 0.7875054993400792,
      "grad_norm": 0.08998075872659683,
      "learning_rate": 3.6879574451065875e-05,
      "loss": 0.0717,
      "step": 39380
    },
    {
      "epoch": 0.7877054753429589,
      "grad_norm": 0.09502264857292175,
      "learning_rate": 3.6876241517684545e-05,
      "loss": 0.0481,
      "step": 39390
    },
    {
      "epoch": 0.7879054513458384,
      "grad_norm": 0.20331814885139465,
      "learning_rate": 3.6872908584303215e-05,
      "loss": 0.0714,
      "step": 39400
    },
    {
      "epoch": 0.7881054273487181,
      "grad_norm": 0.21514980494976044,
      "learning_rate": 3.686957565092189e-05,
      "loss": 0.1013,
      "step": 39410
    },
    {
      "epoch": 0.7883054033515978,
      "grad_norm": 0.11648425459861755,
      "learning_rate": 3.686624271754056e-05,
      "loss": 0.089,
      "step": 39420
    },
    {
      "epoch": 0.7885053793544775,
      "grad_norm": 0.09609560668468475,
      "learning_rate": 3.686290978415924e-05,
      "loss": 0.1951,
      "step": 39430
    },
    {
      "epoch": 0.7887053553573571,
      "grad_norm": 0.05832909047603607,
      "learning_rate": 3.685957685077791e-05,
      "loss": 0.0852,
      "step": 39440
    },
    {
      "epoch": 0.7889053313602368,
      "grad_norm": 0.18652702867984772,
      "learning_rate": 3.685624391739658e-05,
      "loss": 0.0475,
      "step": 39450
    },
    {
      "epoch": 0.7891053073631165,
      "grad_norm": 0.17310237884521484,
      "learning_rate": 3.685291098401525e-05,
      "loss": 0.0899,
      "step": 39460
    },
    {
      "epoch": 0.789305283365996,
      "grad_norm": 0.1452900469303131,
      "learning_rate": 3.684957805063393e-05,
      "loss": 0.0751,
      "step": 39470
    },
    {
      "epoch": 0.7895052593688757,
      "grad_norm": 0.1306689828634262,
      "learning_rate": 3.68462451172526e-05,
      "loss": 0.0662,
      "step": 39480
    },
    {
      "epoch": 0.7897052353717554,
      "grad_norm": 0.15762262046337128,
      "learning_rate": 3.684291218387127e-05,
      "loss": 0.0758,
      "step": 39490
    },
    {
      "epoch": 0.7899052113746351,
      "grad_norm": 0.18632738292217255,
      "learning_rate": 3.6839579250489945e-05,
      "loss": 0.1073,
      "step": 39500
    },
    {
      "epoch": 0.7901051873775147,
      "grad_norm": 0.1017441526055336,
      "learning_rate": 3.6836246317108614e-05,
      "loss": 0.0809,
      "step": 39510
    },
    {
      "epoch": 0.7903051633803944,
      "grad_norm": 0.2598973214626312,
      "learning_rate": 3.6832913383727284e-05,
      "loss": 0.1193,
      "step": 39520
    },
    {
      "epoch": 0.790505139383274,
      "grad_norm": 0.18532153964042664,
      "learning_rate": 3.682958045034596e-05,
      "loss": 0.122,
      "step": 39530
    },
    {
      "epoch": 0.7907051153861536,
      "grad_norm": 0.08471472561359406,
      "learning_rate": 3.6826247516964637e-05,
      "loss": 0.0677,
      "step": 39540
    },
    {
      "epoch": 0.7909050913890333,
      "grad_norm": 0.20239809155464172,
      "learning_rate": 3.6822914583583306e-05,
      "loss": 0.0692,
      "step": 39550
    },
    {
      "epoch": 0.791105067391913,
      "grad_norm": 0.10043762624263763,
      "learning_rate": 3.6819581650201976e-05,
      "loss": 0.0589,
      "step": 39560
    },
    {
      "epoch": 0.7913050433947926,
      "grad_norm": 0.07700010389089584,
      "learning_rate": 3.681624871682065e-05,
      "loss": 0.0687,
      "step": 39570
    },
    {
      "epoch": 0.7915050193976723,
      "grad_norm": 0.11835841089487076,
      "learning_rate": 3.681291578343932e-05,
      "loss": 0.0793,
      "step": 39580
    },
    {
      "epoch": 0.791704995400552,
      "grad_norm": 0.08654120564460754,
      "learning_rate": 3.680958285005799e-05,
      "loss": 0.0863,
      "step": 39590
    },
    {
      "epoch": 0.7919049714034316,
      "grad_norm": 0.10844207555055618,
      "learning_rate": 3.680624991667667e-05,
      "loss": 0.0545,
      "step": 39600
    },
    {
      "epoch": 0.7921049474063112,
      "grad_norm": 0.11895200610160828,
      "learning_rate": 3.680291698329534e-05,
      "loss": 0.1214,
      "step": 39610
    },
    {
      "epoch": 0.7923049234091909,
      "grad_norm": 0.16627074778079987,
      "learning_rate": 3.679958404991401e-05,
      "loss": 0.1113,
      "step": 39620
    },
    {
      "epoch": 0.7925048994120706,
      "grad_norm": 0.12521371245384216,
      "learning_rate": 3.6796251116532683e-05,
      "loss": 0.0727,
      "step": 39630
    },
    {
      "epoch": 0.7927048754149502,
      "grad_norm": 0.16817666590213776,
      "learning_rate": 3.679291818315136e-05,
      "loss": 0.0879,
      "step": 39640
    },
    {
      "epoch": 0.7929048514178298,
      "grad_norm": 0.0731082335114479,
      "learning_rate": 3.678958524977003e-05,
      "loss": 0.0566,
      "step": 39650
    },
    {
      "epoch": 0.7931048274207095,
      "grad_norm": 0.144487664103508,
      "learning_rate": 3.6786252316388706e-05,
      "loss": 0.0766,
      "step": 39660
    },
    {
      "epoch": 0.7933048034235892,
      "grad_norm": 0.15349391102790833,
      "learning_rate": 3.6782919383007375e-05,
      "loss": 0.0806,
      "step": 39670
    },
    {
      "epoch": 0.7935047794264688,
      "grad_norm": 0.10569868981838226,
      "learning_rate": 3.6779586449626045e-05,
      "loss": 0.0772,
      "step": 39680
    },
    {
      "epoch": 0.7937047554293485,
      "grad_norm": 0.13457846641540527,
      "learning_rate": 3.677625351624472e-05,
      "loss": 0.0678,
      "step": 39690
    },
    {
      "epoch": 0.7939047314322282,
      "grad_norm": 0.1286364197731018,
      "learning_rate": 3.677292058286339e-05,
      "loss": 0.0905,
      "step": 39700
    },
    {
      "epoch": 0.7941047074351077,
      "grad_norm": 0.12638787925243378,
      "learning_rate": 3.676958764948206e-05,
      "loss": 0.0623,
      "step": 39710
    },
    {
      "epoch": 0.7943046834379874,
      "grad_norm": 0.12273534387350082,
      "learning_rate": 3.676625471610074e-05,
      "loss": 0.0581,
      "step": 39720
    },
    {
      "epoch": 0.7945046594408671,
      "grad_norm": 0.0720033049583435,
      "learning_rate": 3.676292178271941e-05,
      "loss": 0.0611,
      "step": 39730
    },
    {
      "epoch": 0.7947046354437467,
      "grad_norm": 0.1503513902425766,
      "learning_rate": 3.675958884933808e-05,
      "loss": 0.0841,
      "step": 39740
    },
    {
      "epoch": 0.7949046114466264,
      "grad_norm": 0.10945814102888107,
      "learning_rate": 3.675625591595675e-05,
      "loss": 0.0791,
      "step": 39750
    },
    {
      "epoch": 0.7951045874495061,
      "grad_norm": 0.07995820790529251,
      "learning_rate": 3.675292298257543e-05,
      "loss": 0.0827,
      "step": 39760
    },
    {
      "epoch": 0.7953045634523858,
      "grad_norm": 0.10121661424636841,
      "learning_rate": 3.67495900491941e-05,
      "loss": 0.0704,
      "step": 39770
    },
    {
      "epoch": 0.7955045394552653,
      "grad_norm": 0.08854684978723526,
      "learning_rate": 3.674625711581277e-05,
      "loss": 0.0712,
      "step": 39780
    },
    {
      "epoch": 0.795704515458145,
      "grad_norm": 0.10127957910299301,
      "learning_rate": 3.6742924182431445e-05,
      "loss": 0.1507,
      "step": 39790
    },
    {
      "epoch": 0.7959044914610247,
      "grad_norm": 0.1569841206073761,
      "learning_rate": 3.6739591249050114e-05,
      "loss": 0.082,
      "step": 39800
    },
    {
      "epoch": 0.7961044674639043,
      "grad_norm": 0.06866666674613953,
      "learning_rate": 3.6736258315668784e-05,
      "loss": 0.0781,
      "step": 39810
    },
    {
      "epoch": 0.796304443466784,
      "grad_norm": 0.0682055801153183,
      "learning_rate": 3.673292538228746e-05,
      "loss": 0.0942,
      "step": 39820
    },
    {
      "epoch": 0.7965044194696637,
      "grad_norm": 0.11113078147172928,
      "learning_rate": 3.672959244890613e-05,
      "loss": 0.0592,
      "step": 39830
    },
    {
      "epoch": 0.7967043954725433,
      "grad_norm": 0.10832097381353378,
      "learning_rate": 3.6726259515524806e-05,
      "loss": 0.0892,
      "step": 39840
    },
    {
      "epoch": 0.7969043714754229,
      "grad_norm": 0.10232841968536377,
      "learning_rate": 3.672292658214348e-05,
      "loss": 0.062,
      "step": 39850
    },
    {
      "epoch": 0.7971043474783026,
      "grad_norm": 0.05885724723339081,
      "learning_rate": 3.671959364876215e-05,
      "loss": 0.1063,
      "step": 39860
    },
    {
      "epoch": 0.7973043234811823,
      "grad_norm": 0.16935192048549652,
      "learning_rate": 3.671626071538082e-05,
      "loss": 0.0986,
      "step": 39870
    },
    {
      "epoch": 0.7975042994840619,
      "grad_norm": 0.16191615164279938,
      "learning_rate": 3.67129277819995e-05,
      "loss": 0.0927,
      "step": 39880
    },
    {
      "epoch": 0.7977042754869416,
      "grad_norm": 0.09784464538097382,
      "learning_rate": 3.670959484861817e-05,
      "loss": 0.111,
      "step": 39890
    },
    {
      "epoch": 0.7979042514898212,
      "grad_norm": 0.07984709739685059,
      "learning_rate": 3.670626191523684e-05,
      "loss": 0.1039,
      "step": 39900
    },
    {
      "epoch": 0.7981042274927008,
      "grad_norm": 0.05163051560521126,
      "learning_rate": 3.6702928981855514e-05,
      "loss": 0.0881,
      "step": 39910
    },
    {
      "epoch": 0.7983042034955805,
      "grad_norm": 0.1744171679019928,
      "learning_rate": 3.6699596048474184e-05,
      "loss": 0.1692,
      "step": 39920
    },
    {
      "epoch": 0.7985041794984602,
      "grad_norm": 0.15275780856609344,
      "learning_rate": 3.669626311509285e-05,
      "loss": 0.0688,
      "step": 39930
    },
    {
      "epoch": 0.7987041555013399,
      "grad_norm": 0.08449643105268478,
      "learning_rate": 3.669293018171153e-05,
      "loss": 0.0696,
      "step": 39940
    },
    {
      "epoch": 0.7989041315042195,
      "grad_norm": 0.11508164554834366,
      "learning_rate": 3.6689597248330206e-05,
      "loss": 0.0928,
      "step": 39950
    },
    {
      "epoch": 0.7991041075070991,
      "grad_norm": 0.08252423256635666,
      "learning_rate": 3.6686264314948876e-05,
      "loss": 0.0393,
      "step": 39960
    },
    {
      "epoch": 0.7993040835099788,
      "grad_norm": 0.14581353962421417,
      "learning_rate": 3.6682931381567545e-05,
      "loss": 0.0608,
      "step": 39970
    },
    {
      "epoch": 0.7995040595128584,
      "grad_norm": 0.1059558242559433,
      "learning_rate": 3.667959844818622e-05,
      "loss": 0.0782,
      "step": 39980
    },
    {
      "epoch": 0.7997040355157381,
      "grad_norm": 0.13464848697185516,
      "learning_rate": 3.667626551480489e-05,
      "loss": 0.0826,
      "step": 39990
    },
    {
      "epoch": 0.7999040115186178,
      "grad_norm": 0.12479150295257568,
      "learning_rate": 3.667293258142356e-05,
      "loss": 0.0818,
      "step": 40000
    },
    {
      "epoch": 0.8001039875214975,
      "grad_norm": 0.06996886432170868,
      "learning_rate": 3.666959964804224e-05,
      "loss": 0.0847,
      "step": 40010
    },
    {
      "epoch": 0.800303963524377,
      "grad_norm": 0.07371078431606293,
      "learning_rate": 3.666626671466091e-05,
      "loss": 0.1102,
      "step": 40020
    },
    {
      "epoch": 0.8005039395272567,
      "grad_norm": 0.057766735553741455,
      "learning_rate": 3.6662933781279576e-05,
      "loss": 0.0355,
      "step": 40030
    },
    {
      "epoch": 0.8007039155301364,
      "grad_norm": 0.13533149659633636,
      "learning_rate": 3.6659934141236385e-05,
      "loss": 0.0805,
      "step": 40040
    },
    {
      "epoch": 0.800903891533016,
      "grad_norm": 0.129581481218338,
      "learning_rate": 3.6656601207855055e-05,
      "loss": 0.0418,
      "step": 40050
    },
    {
      "epoch": 0.8011038675358957,
      "grad_norm": 0.18682362139225006,
      "learning_rate": 3.665326827447373e-05,
      "loss": 0.0783,
      "step": 40060
    },
    {
      "epoch": 0.8013038435387754,
      "grad_norm": 0.14925630390644073,
      "learning_rate": 3.664993534109241e-05,
      "loss": 0.0807,
      "step": 40070
    },
    {
      "epoch": 0.801503819541655,
      "grad_norm": 0.08310266584157944,
      "learning_rate": 3.664660240771108e-05,
      "loss": 0.054,
      "step": 40080
    },
    {
      "epoch": 0.8017037955445346,
      "grad_norm": 0.13625121116638184,
      "learning_rate": 3.664326947432975e-05,
      "loss": 0.5145,
      "step": 40090
    },
    {
      "epoch": 0.8019037715474143,
      "grad_norm": 0.18237553536891937,
      "learning_rate": 3.663993654094842e-05,
      "loss": 0.1241,
      "step": 40100
    },
    {
      "epoch": 0.802103747550294,
      "grad_norm": 0.16548119485378265,
      "learning_rate": 3.663660360756709e-05,
      "loss": 0.1488,
      "step": 40110
    },
    {
      "epoch": 0.8023037235531736,
      "grad_norm": 0.2163536250591278,
      "learning_rate": 3.663327067418576e-05,
      "loss": 0.1099,
      "step": 40120
    },
    {
      "epoch": 0.8025036995560533,
      "grad_norm": 0.18592862784862518,
      "learning_rate": 3.662993774080444e-05,
      "loss": 0.1167,
      "step": 40130
    },
    {
      "epoch": 0.802703675558933,
      "grad_norm": 0.08195087313652039,
      "learning_rate": 3.662660480742311e-05,
      "loss": 0.0825,
      "step": 40140
    },
    {
      "epoch": 0.8029036515618125,
      "grad_norm": 0.08876142650842667,
      "learning_rate": 3.662327187404178e-05,
      "loss": 0.0633,
      "step": 40150
    },
    {
      "epoch": 0.8031036275646922,
      "grad_norm": 0.0786859318614006,
      "learning_rate": 3.6619938940660455e-05,
      "loss": 0.0493,
      "step": 40160
    },
    {
      "epoch": 0.8033036035675719,
      "grad_norm": 0.09361305832862854,
      "learning_rate": 3.661660600727913e-05,
      "loss": 0.0775,
      "step": 40170
    },
    {
      "epoch": 0.8035035795704516,
      "grad_norm": 0.19696448743343353,
      "learning_rate": 3.66132730738978e-05,
      "loss": 0.0585,
      "step": 40180
    },
    {
      "epoch": 0.8037035555733312,
      "grad_norm": 0.08640395104885101,
      "learning_rate": 3.660994014051648e-05,
      "loss": 0.0651,
      "step": 40190
    },
    {
      "epoch": 0.8039035315762109,
      "grad_norm": 0.13978561758995056,
      "learning_rate": 3.6606607207135147e-05,
      "loss": 0.0749,
      "step": 40200
    },
    {
      "epoch": 0.8041035075790905,
      "grad_norm": 0.18252913653850555,
      "learning_rate": 3.6603274273753816e-05,
      "loss": 0.088,
      "step": 40210
    },
    {
      "epoch": 0.8043034835819701,
      "grad_norm": 0.12260133773088455,
      "learning_rate": 3.659994134037249e-05,
      "loss": 0.0704,
      "step": 40220
    },
    {
      "epoch": 0.8045034595848498,
      "grad_norm": 0.12279927730560303,
      "learning_rate": 3.659660840699116e-05,
      "loss": 0.0899,
      "step": 40230
    },
    {
      "epoch": 0.8047034355877295,
      "grad_norm": 0.10531028360128403,
      "learning_rate": 3.659327547360983e-05,
      "loss": 0.0906,
      "step": 40240
    },
    {
      "epoch": 0.8049034115906091,
      "grad_norm": 0.11867168545722961,
      "learning_rate": 3.658994254022851e-05,
      "loss": 0.0801,
      "step": 40250
    },
    {
      "epoch": 0.8051033875934888,
      "grad_norm": 0.06315216422080994,
      "learning_rate": 3.658660960684718e-05,
      "loss": 0.0864,
      "step": 40260
    },
    {
      "epoch": 0.8053033635963684,
      "grad_norm": 0.22123675048351288,
      "learning_rate": 3.6583276673465854e-05,
      "loss": 0.0745,
      "step": 40270
    },
    {
      "epoch": 0.8055033395992481,
      "grad_norm": 0.17335191369056702,
      "learning_rate": 3.6579943740084524e-05,
      "loss": 0.0946,
      "step": 40280
    },
    {
      "epoch": 0.8057033156021277,
      "grad_norm": 0.20711401104927063,
      "learning_rate": 3.65766108067032e-05,
      "loss": 0.1001,
      "step": 40290
    },
    {
      "epoch": 0.8059032916050074,
      "grad_norm": 0.17788894474506378,
      "learning_rate": 3.657327787332187e-05,
      "loss": 0.0935,
      "step": 40300
    },
    {
      "epoch": 0.8061032676078871,
      "grad_norm": 0.1284942775964737,
      "learning_rate": 3.656994493994054e-05,
      "loss": 0.068,
      "step": 40310
    },
    {
      "epoch": 0.8063032436107667,
      "grad_norm": 0.1693524271249771,
      "learning_rate": 3.6566612006559216e-05,
      "loss": 0.0676,
      "step": 40320
    },
    {
      "epoch": 0.8065032196136463,
      "grad_norm": 0.07849682867527008,
      "learning_rate": 3.6563279073177885e-05,
      "loss": 0.0589,
      "step": 40330
    },
    {
      "epoch": 0.806703195616526,
      "grad_norm": 0.14679919183254242,
      "learning_rate": 3.6559946139796555e-05,
      "loss": 0.0808,
      "step": 40340
    },
    {
      "epoch": 0.8069031716194057,
      "grad_norm": 0.20557145774364471,
      "learning_rate": 3.655661320641523e-05,
      "loss": 0.0643,
      "step": 40350
    },
    {
      "epoch": 0.8071031476222853,
      "grad_norm": 0.19294245541095734,
      "learning_rate": 3.65532802730339e-05,
      "loss": 0.0886,
      "step": 40360
    },
    {
      "epoch": 0.807303123625165,
      "grad_norm": 0.17547956109046936,
      "learning_rate": 3.654994733965258e-05,
      "loss": 0.0955,
      "step": 40370
    },
    {
      "epoch": 0.8075030996280447,
      "grad_norm": 0.19151097536087036,
      "learning_rate": 3.6546614406271254e-05,
      "loss": 0.1232,
      "step": 40380
    },
    {
      "epoch": 0.8077030756309242,
      "grad_norm": 0.2104491889476776,
      "learning_rate": 3.6543281472889923e-05,
      "loss": 0.0963,
      "step": 40390
    },
    {
      "epoch": 0.8079030516338039,
      "grad_norm": 0.11081257462501526,
      "learning_rate": 3.653994853950859e-05,
      "loss": 0.076,
      "step": 40400
    },
    {
      "epoch": 0.8081030276366836,
      "grad_norm": 0.052224013954401016,
      "learning_rate": 3.653661560612727e-05,
      "loss": 0.0898,
      "step": 40410
    },
    {
      "epoch": 0.8083030036395632,
      "grad_norm": 0.08061855286359787,
      "learning_rate": 3.653328267274594e-05,
      "loss": 0.0981,
      "step": 40420
    },
    {
      "epoch": 0.8085029796424429,
      "grad_norm": 0.14986306428909302,
      "learning_rate": 3.652994973936461e-05,
      "loss": 0.0762,
      "step": 40430
    },
    {
      "epoch": 0.8087029556453226,
      "grad_norm": 0.1367061883211136,
      "learning_rate": 3.6526616805983285e-05,
      "loss": 0.08,
      "step": 40440
    },
    {
      "epoch": 0.8089029316482023,
      "grad_norm": 0.15348780155181885,
      "learning_rate": 3.6523283872601955e-05,
      "loss": 0.0783,
      "step": 40450
    },
    {
      "epoch": 0.8091029076510818,
      "grad_norm": 0.1704331338405609,
      "learning_rate": 3.6519950939220624e-05,
      "loss": 0.0841,
      "step": 40460
    },
    {
      "epoch": 0.8093028836539615,
      "grad_norm": 0.14347970485687256,
      "learning_rate": 3.65166180058393e-05,
      "loss": 0.0684,
      "step": 40470
    },
    {
      "epoch": 0.8095028596568412,
      "grad_norm": 0.19479236006736755,
      "learning_rate": 3.651328507245798e-05,
      "loss": 0.0552,
      "step": 40480
    },
    {
      "epoch": 0.8097028356597208,
      "grad_norm": 0.1777007281780243,
      "learning_rate": 3.650995213907665e-05,
      "loss": 0.0531,
      "step": 40490
    },
    {
      "epoch": 0.8099028116626005,
      "grad_norm": 0.16086316108703613,
      "learning_rate": 3.6506619205695316e-05,
      "loss": 0.0812,
      "step": 40500
    },
    {
      "epoch": 0.8101027876654802,
      "grad_norm": 0.07653586566448212,
      "learning_rate": 3.650328627231399e-05,
      "loss": 0.0498,
      "step": 40510
    },
    {
      "epoch": 0.8103027636683598,
      "grad_norm": 0.1688651591539383,
      "learning_rate": 3.649995333893266e-05,
      "loss": 0.0829,
      "step": 40520
    },
    {
      "epoch": 0.8105027396712394,
      "grad_norm": 0.08984781801700592,
      "learning_rate": 3.649662040555133e-05,
      "loss": 0.0925,
      "step": 40530
    },
    {
      "epoch": 0.8107027156741191,
      "grad_norm": 0.17827929556369781,
      "learning_rate": 3.649328747217001e-05,
      "loss": 0.1097,
      "step": 40540
    },
    {
      "epoch": 0.8109026916769988,
      "grad_norm": 0.1560792624950409,
      "learning_rate": 3.648995453878868e-05,
      "loss": 0.0666,
      "step": 40550
    },
    {
      "epoch": 0.8111026676798784,
      "grad_norm": 0.07278875261545181,
      "learning_rate": 3.648662160540735e-05,
      "loss": 0.0544,
      "step": 40560
    },
    {
      "epoch": 0.8113026436827581,
      "grad_norm": 0.055900201201438904,
      "learning_rate": 3.6483288672026024e-05,
      "loss": 0.0381,
      "step": 40570
    },
    {
      "epoch": 0.8115026196856377,
      "grad_norm": 0.22641758620738983,
      "learning_rate": 3.64799557386447e-05,
      "loss": 0.0709,
      "step": 40580
    },
    {
      "epoch": 0.8117025956885173,
      "grad_norm": 0.08405255526304245,
      "learning_rate": 3.647662280526337e-05,
      "loss": 0.0598,
      "step": 40590
    },
    {
      "epoch": 0.811902571691397,
      "grad_norm": 0.12973999977111816,
      "learning_rate": 3.6473289871882046e-05,
      "loss": 0.081,
      "step": 40600
    },
    {
      "epoch": 0.8121025476942767,
      "grad_norm": 0.07599562406539917,
      "learning_rate": 3.6469956938500716e-05,
      "loss": 0.0564,
      "step": 40610
    },
    {
      "epoch": 0.8123025236971564,
      "grad_norm": 0.10666350275278091,
      "learning_rate": 3.6466624005119386e-05,
      "loss": 0.0739,
      "step": 40620
    },
    {
      "epoch": 0.812502499700036,
      "grad_norm": 0.1196720153093338,
      "learning_rate": 3.646329107173806e-05,
      "loss": 0.0638,
      "step": 40630
    },
    {
      "epoch": 0.8127024757029156,
      "grad_norm": 0.16893503069877625,
      "learning_rate": 3.645995813835673e-05,
      "loss": 0.1159,
      "step": 40640
    },
    {
      "epoch": 0.8129024517057953,
      "grad_norm": 0.21564455330371857,
      "learning_rate": 3.64566252049754e-05,
      "loss": 0.1329,
      "step": 40650
    },
    {
      "epoch": 0.8131024277086749,
      "grad_norm": 0.1324983537197113,
      "learning_rate": 3.645329227159408e-05,
      "loss": 0.0694,
      "step": 40660
    },
    {
      "epoch": 0.8133024037115546,
      "grad_norm": 0.1249210312962532,
      "learning_rate": 3.644995933821275e-05,
      "loss": 0.0831,
      "step": 40670
    },
    {
      "epoch": 0.8135023797144343,
      "grad_norm": 0.0895727276802063,
      "learning_rate": 3.6446626404831424e-05,
      "loss": 0.0715,
      "step": 40680
    },
    {
      "epoch": 0.813702355717314,
      "grad_norm": 0.100185826420784,
      "learning_rate": 3.644329347145009e-05,
      "loss": 0.0478,
      "step": 40690
    },
    {
      "epoch": 0.8139023317201936,
      "grad_norm": 0.08215682953596115,
      "learning_rate": 3.643996053806877e-05,
      "loss": 0.0855,
      "step": 40700
    },
    {
      "epoch": 0.8141023077230732,
      "grad_norm": 0.14990349113941193,
      "learning_rate": 3.643662760468744e-05,
      "loss": 0.1001,
      "step": 40710
    },
    {
      "epoch": 0.8143022837259529,
      "grad_norm": 0.15233877301216125,
      "learning_rate": 3.643329467130611e-05,
      "loss": 0.062,
      "step": 40720
    },
    {
      "epoch": 0.8145022597288325,
      "grad_norm": 0.14200712740421295,
      "learning_rate": 3.6429961737924785e-05,
      "loss": 0.0806,
      "step": 40730
    },
    {
      "epoch": 0.8147022357317122,
      "grad_norm": 0.06952955573797226,
      "learning_rate": 3.6426628804543455e-05,
      "loss": 0.0988,
      "step": 40740
    },
    {
      "epoch": 0.8149022117345919,
      "grad_norm": 0.16343358159065247,
      "learning_rate": 3.6423295871162124e-05,
      "loss": 0.0668,
      "step": 40750
    },
    {
      "epoch": 0.8151021877374715,
      "grad_norm": 0.18691352009773254,
      "learning_rate": 3.64199629377808e-05,
      "loss": 0.0884,
      "step": 40760
    },
    {
      "epoch": 0.8153021637403511,
      "grad_norm": 0.09047108143568039,
      "learning_rate": 3.641663000439947e-05,
      "loss": 0.0726,
      "step": 40770
    },
    {
      "epoch": 0.8155021397432308,
      "grad_norm": 0.1624084860086441,
      "learning_rate": 3.641329707101815e-05,
      "loss": 0.0766,
      "step": 40780
    },
    {
      "epoch": 0.8157021157461105,
      "grad_norm": 0.09678172320127487,
      "learning_rate": 3.640996413763682e-05,
      "loss": 0.0676,
      "step": 40790
    },
    {
      "epoch": 0.8159020917489901,
      "grad_norm": 0.042794566601514816,
      "learning_rate": 3.640663120425549e-05,
      "loss": 0.0935,
      "step": 40800
    },
    {
      "epoch": 0.8161020677518698,
      "grad_norm": 0.14623688161373138,
      "learning_rate": 3.640329827087416e-05,
      "loss": 0.0758,
      "step": 40810
    },
    {
      "epoch": 0.8163020437547495,
      "grad_norm": 0.1598084568977356,
      "learning_rate": 3.639996533749284e-05,
      "loss": 0.086,
      "step": 40820
    },
    {
      "epoch": 0.816502019757629,
      "grad_norm": 0.054926011711359024,
      "learning_rate": 3.639663240411151e-05,
      "loss": 0.0737,
      "step": 40830
    },
    {
      "epoch": 0.8167019957605087,
      "grad_norm": 0.05365930497646332,
      "learning_rate": 3.639329947073018e-05,
      "loss": 0.0744,
      "step": 40840
    },
    {
      "epoch": 0.8169019717633884,
      "grad_norm": 0.10282337665557861,
      "learning_rate": 3.6389966537348855e-05,
      "loss": 0.057,
      "step": 40850
    },
    {
      "epoch": 0.8171019477662681,
      "grad_norm": 0.24735689163208008,
      "learning_rate": 3.6386633603967524e-05,
      "loss": 0.1144,
      "step": 40860
    },
    {
      "epoch": 0.8173019237691477,
      "grad_norm": 0.1188785582780838,
      "learning_rate": 3.6383300670586194e-05,
      "loss": 0.061,
      "step": 40870
    },
    {
      "epoch": 0.8175018997720274,
      "grad_norm": 0.12126714736223221,
      "learning_rate": 3.637996773720487e-05,
      "loss": 0.0972,
      "step": 40880
    },
    {
      "epoch": 0.817701875774907,
      "grad_norm": 0.17983637750148773,
      "learning_rate": 3.6376634803823547e-05,
      "loss": 0.1123,
      "step": 40890
    },
    {
      "epoch": 0.8179018517777866,
      "grad_norm": 0.11710474640130997,
      "learning_rate": 3.6373301870442216e-05,
      "loss": 0.0729,
      "step": 40900
    },
    {
      "epoch": 0.8181018277806663,
      "grad_norm": 0.24398639798164368,
      "learning_rate": 3.6369968937060886e-05,
      "loss": 0.1087,
      "step": 40910
    },
    {
      "epoch": 0.818301803783546,
      "grad_norm": 0.059280578047037125,
      "learning_rate": 3.636663600367956e-05,
      "loss": 0.043,
      "step": 40920
    },
    {
      "epoch": 0.8185017797864256,
      "grad_norm": 0.11450737714767456,
      "learning_rate": 3.636330307029823e-05,
      "loss": 0.0623,
      "step": 40930
    },
    {
      "epoch": 0.8187017557893053,
      "grad_norm": 0.1581278145313263,
      "learning_rate": 3.63599701369169e-05,
      "loss": 0.0857,
      "step": 40940
    },
    {
      "epoch": 0.818901731792185,
      "grad_norm": 0.12106185406446457,
      "learning_rate": 3.635663720353558e-05,
      "loss": 0.0752,
      "step": 40950
    },
    {
      "epoch": 0.8191017077950646,
      "grad_norm": 0.1998155415058136,
      "learning_rate": 3.635330427015425e-05,
      "loss": 0.0908,
      "step": 40960
    },
    {
      "epoch": 0.8193016837979442,
      "grad_norm": 0.0895431786775589,
      "learning_rate": 3.634997133677292e-05,
      "loss": 0.1157,
      "step": 40970
    },
    {
      "epoch": 0.8195016598008239,
      "grad_norm": 0.0752011239528656,
      "learning_rate": 3.63466384033916e-05,
      "loss": 0.0581,
      "step": 40980
    },
    {
      "epoch": 0.8197016358037036,
      "grad_norm": 0.13346879184246063,
      "learning_rate": 3.634330547001027e-05,
      "loss": 0.074,
      "step": 40990
    },
    {
      "epoch": 0.8199016118065832,
      "grad_norm": 0.14091117680072784,
      "learning_rate": 3.633997253662894e-05,
      "loss": 0.0684,
      "step": 41000
    },
    {
      "epoch": 0.8201015878094629,
      "grad_norm": 0.08399516344070435,
      "learning_rate": 3.6336639603247616e-05,
      "loss": 0.0884,
      "step": 41010
    },
    {
      "epoch": 0.8203015638123425,
      "grad_norm": 0.18230634927749634,
      "learning_rate": 3.6333306669866285e-05,
      "loss": 0.067,
      "step": 41020
    },
    {
      "epoch": 0.8205015398152222,
      "grad_norm": 0.08174236863851547,
      "learning_rate": 3.6329973736484955e-05,
      "loss": 0.124,
      "step": 41030
    },
    {
      "epoch": 0.8207015158181018,
      "grad_norm": 0.08536270260810852,
      "learning_rate": 3.632664080310363e-05,
      "loss": 0.1027,
      "step": 41040
    },
    {
      "epoch": 0.8209014918209815,
      "grad_norm": 0.08725865185260773,
      "learning_rate": 3.63233078697223e-05,
      "loss": 0.0531,
      "step": 41050
    },
    {
      "epoch": 0.8211014678238612,
      "grad_norm": 0.23596015572547913,
      "learning_rate": 3.631997493634097e-05,
      "loss": 0.0865,
      "step": 41060
    },
    {
      "epoch": 0.8213014438267408,
      "grad_norm": 0.08314104378223419,
      "learning_rate": 3.631664200295965e-05,
      "loss": 0.0829,
      "step": 41070
    },
    {
      "epoch": 0.8215014198296204,
      "grad_norm": 0.13168111443519592,
      "learning_rate": 3.631330906957832e-05,
      "loss": 0.0837,
      "step": 41080
    },
    {
      "epoch": 0.8217013958325001,
      "grad_norm": 0.09626614302396774,
      "learning_rate": 3.630997613619699e-05,
      "loss": 0.0691,
      "step": 41090
    },
    {
      "epoch": 0.8219013718353797,
      "grad_norm": 0.14657534658908844,
      "learning_rate": 3.630664320281566e-05,
      "loss": 0.0727,
      "step": 41100
    },
    {
      "epoch": 0.8221013478382594,
      "grad_norm": 0.06961293518543243,
      "learning_rate": 3.630331026943434e-05,
      "loss": 0.0628,
      "step": 41110
    },
    {
      "epoch": 0.8223013238411391,
      "grad_norm": 0.16632646322250366,
      "learning_rate": 3.629997733605301e-05,
      "loss": 0.0805,
      "step": 41120
    },
    {
      "epoch": 0.8225012998440188,
      "grad_norm": 0.18762733042240143,
      "learning_rate": 3.629664440267168e-05,
      "loss": 0.082,
      "step": 41130
    },
    {
      "epoch": 0.8227012758468983,
      "grad_norm": 0.1225963607430458,
      "learning_rate": 3.6293311469290355e-05,
      "loss": 0.0772,
      "step": 41140
    },
    {
      "epoch": 0.822901251849778,
      "grad_norm": 0.058267876505851746,
      "learning_rate": 3.6289978535909024e-05,
      "loss": 0.0839,
      "step": 41150
    },
    {
      "epoch": 0.8231012278526577,
      "grad_norm": 0.06852113455533981,
      "learning_rate": 3.6286645602527694e-05,
      "loss": 0.0498,
      "step": 41160
    },
    {
      "epoch": 0.8233012038555373,
      "grad_norm": 0.11154724657535553,
      "learning_rate": 3.628331266914637e-05,
      "loss": 0.121,
      "step": 41170
    },
    {
      "epoch": 0.823501179858417,
      "grad_norm": 0.06262233108282089,
      "learning_rate": 3.627997973576504e-05,
      "loss": 0.0974,
      "step": 41180
    },
    {
      "epoch": 0.8237011558612967,
      "grad_norm": 0.06415633857250214,
      "learning_rate": 3.6276646802383716e-05,
      "loss": 0.2649,
      "step": 41190
    },
    {
      "epoch": 0.8239011318641764,
      "grad_norm": 0.13941991329193115,
      "learning_rate": 3.627331386900239e-05,
      "loss": 0.1,
      "step": 41200
    },
    {
      "epoch": 0.8241011078670559,
      "grad_norm": 0.09481693059206009,
      "learning_rate": 3.626998093562106e-05,
      "loss": 0.0955,
      "step": 41210
    },
    {
      "epoch": 0.8243010838699356,
      "grad_norm": 0.11778610199689865,
      "learning_rate": 3.626664800223973e-05,
      "loss": 0.0725,
      "step": 41220
    },
    {
      "epoch": 0.8245010598728153,
      "grad_norm": 0.1558942198753357,
      "learning_rate": 3.626331506885841e-05,
      "loss": 0.0969,
      "step": 41230
    },
    {
      "epoch": 0.8247010358756949,
      "grad_norm": 0.05915185436606407,
      "learning_rate": 3.625998213547708e-05,
      "loss": 0.0702,
      "step": 41240
    },
    {
      "epoch": 0.8249010118785746,
      "grad_norm": 0.10258623957633972,
      "learning_rate": 3.625664920209575e-05,
      "loss": 0.0969,
      "step": 41250
    },
    {
      "epoch": 0.8251009878814543,
      "grad_norm": 0.09646249562501907,
      "learning_rate": 3.6253316268714424e-05,
      "loss": 0.0677,
      "step": 41260
    },
    {
      "epoch": 0.8253009638843338,
      "grad_norm": 0.09192559123039246,
      "learning_rate": 3.6249983335333094e-05,
      "loss": 0.0914,
      "step": 41270
    },
    {
      "epoch": 0.8255009398872135,
      "grad_norm": 0.16502037644386292,
      "learning_rate": 3.624665040195176e-05,
      "loss": 0.0561,
      "step": 41280
    },
    {
      "epoch": 0.8257009158900932,
      "grad_norm": 0.10838820040225983,
      "learning_rate": 3.624331746857044e-05,
      "loss": 0.0583,
      "step": 41290
    },
    {
      "epoch": 0.8259008918929729,
      "grad_norm": 0.15688598155975342,
      "learning_rate": 3.6239984535189116e-05,
      "loss": 0.075,
      "step": 41300
    },
    {
      "epoch": 0.8261008678958525,
      "grad_norm": 0.15827545523643494,
      "learning_rate": 3.6236651601807786e-05,
      "loss": 0.0994,
      "step": 41310
    },
    {
      "epoch": 0.8263008438987322,
      "grad_norm": 0.18462039530277252,
      "learning_rate": 3.6233318668426455e-05,
      "loss": 0.0864,
      "step": 41320
    },
    {
      "epoch": 0.8265008199016118,
      "grad_norm": 0.18197587132453918,
      "learning_rate": 3.622998573504513e-05,
      "loss": 0.0696,
      "step": 41330
    },
    {
      "epoch": 0.8267007959044914,
      "grad_norm": 0.19564099609851837,
      "learning_rate": 3.62266528016638e-05,
      "loss": 0.1142,
      "step": 41340
    },
    {
      "epoch": 0.8269007719073711,
      "grad_norm": 0.20470008254051208,
      "learning_rate": 3.622331986828247e-05,
      "loss": 0.1999,
      "step": 41350
    },
    {
      "epoch": 0.8271007479102508,
      "grad_norm": 0.10192601382732391,
      "learning_rate": 3.621998693490115e-05,
      "loss": 0.0543,
      "step": 41360
    },
    {
      "epoch": 0.8273007239131305,
      "grad_norm": 0.2677158713340759,
      "learning_rate": 3.621665400151982e-05,
      "loss": 0.1059,
      "step": 41370
    },
    {
      "epoch": 0.82750069991601,
      "grad_norm": 0.1254071444272995,
      "learning_rate": 3.6213321068138486e-05,
      "loss": 0.056,
      "step": 41380
    },
    {
      "epoch": 0.8277006759188897,
      "grad_norm": 0.2341621220111847,
      "learning_rate": 3.620998813475717e-05,
      "loss": 0.0756,
      "step": 41390
    },
    {
      "epoch": 0.8279006519217694,
      "grad_norm": 0.05037061870098114,
      "learning_rate": 3.620665520137584e-05,
      "loss": 0.0763,
      "step": 41400
    },
    {
      "epoch": 0.828100627924649,
      "grad_norm": 0.19925083220005035,
      "learning_rate": 3.620332226799451e-05,
      "loss": 0.1067,
      "step": 41410
    },
    {
      "epoch": 0.8283006039275287,
      "grad_norm": 0.04649508371949196,
      "learning_rate": 3.6199989334613185e-05,
      "loss": 0.058,
      "step": 41420
    },
    {
      "epoch": 0.8285005799304084,
      "grad_norm": 0.0621357299387455,
      "learning_rate": 3.6196656401231855e-05,
      "loss": 0.0458,
      "step": 41430
    },
    {
      "epoch": 0.828700555933288,
      "grad_norm": 0.08198603987693787,
      "learning_rate": 3.6193323467850524e-05,
      "loss": 0.0735,
      "step": 41440
    },
    {
      "epoch": 0.8289005319361676,
      "grad_norm": 0.06942751258611679,
      "learning_rate": 3.61899905344692e-05,
      "loss": 0.0731,
      "step": 41450
    },
    {
      "epoch": 0.8291005079390473,
      "grad_norm": 0.15366233885288239,
      "learning_rate": 3.618665760108787e-05,
      "loss": 0.0867,
      "step": 41460
    },
    {
      "epoch": 0.829300483941927,
      "grad_norm": 0.19564872980117798,
      "learning_rate": 3.618332466770654e-05,
      "loss": 0.1001,
      "step": 41470
    },
    {
      "epoch": 0.8295004599448066,
      "grad_norm": 0.12953650951385498,
      "learning_rate": 3.6179991734325217e-05,
      "loss": 0.0564,
      "step": 41480
    },
    {
      "epoch": 0.8297004359476863,
      "grad_norm": 0.18528085947036743,
      "learning_rate": 3.617665880094389e-05,
      "loss": 0.0868,
      "step": 41490
    },
    {
      "epoch": 0.829900411950566,
      "grad_norm": 0.11197135597467422,
      "learning_rate": 3.617332586756256e-05,
      "loss": 0.0759,
      "step": 41500
    },
    {
      "epoch": 0.8301003879534455,
      "grad_norm": 0.1296503245830536,
      "learning_rate": 3.616999293418123e-05,
      "loss": 0.0733,
      "step": 41510
    },
    {
      "epoch": 0.8303003639563252,
      "grad_norm": 0.09971852600574493,
      "learning_rate": 3.616666000079991e-05,
      "loss": 0.095,
      "step": 41520
    },
    {
      "epoch": 0.8305003399592049,
      "grad_norm": 0.1778201162815094,
      "learning_rate": 3.616332706741858e-05,
      "loss": 0.0924,
      "step": 41530
    },
    {
      "epoch": 0.8307003159620846,
      "grad_norm": 0.05828071013092995,
      "learning_rate": 3.615999413403725e-05,
      "loss": 0.0632,
      "step": 41540
    },
    {
      "epoch": 0.8309002919649642,
      "grad_norm": 0.1595756560564041,
      "learning_rate": 3.6156661200655924e-05,
      "loss": 0.0654,
      "step": 41550
    },
    {
      "epoch": 0.8311002679678439,
      "grad_norm": 0.10184245556592941,
      "learning_rate": 3.6153328267274594e-05,
      "loss": 0.0781,
      "step": 41560
    },
    {
      "epoch": 0.8313002439707236,
      "grad_norm": 0.15090663731098175,
      "learning_rate": 3.614999533389326e-05,
      "loss": 0.0771,
      "step": 41570
    },
    {
      "epoch": 0.8315002199736031,
      "grad_norm": 0.10926233977079391,
      "learning_rate": 3.614666240051194e-05,
      "loss": 0.0624,
      "step": 41580
    },
    {
      "epoch": 0.8317001959764828,
      "grad_norm": 0.13907530903816223,
      "learning_rate": 3.614332946713061e-05,
      "loss": 0.0852,
      "step": 41590
    },
    {
      "epoch": 0.8319001719793625,
      "grad_norm": 0.13790710270404816,
      "learning_rate": 3.6139996533749286e-05,
      "loss": 0.0942,
      "step": 41600
    },
    {
      "epoch": 0.8321001479822421,
      "grad_norm": 0.23356786370277405,
      "learning_rate": 3.613666360036796e-05,
      "loss": 0.1375,
      "step": 41610
    },
    {
      "epoch": 0.8323001239851218,
      "grad_norm": 0.0980834886431694,
      "learning_rate": 3.613333066698663e-05,
      "loss": 0.1187,
      "step": 41620
    },
    {
      "epoch": 0.8325000999880015,
      "grad_norm": 0.057826656848192215,
      "learning_rate": 3.61299977336053e-05,
      "loss": 0.061,
      "step": 41630
    },
    {
      "epoch": 0.8327000759908811,
      "grad_norm": 0.06713562458753586,
      "learning_rate": 3.612666480022398e-05,
      "loss": 0.0929,
      "step": 41640
    },
    {
      "epoch": 0.8329000519937607,
      "grad_norm": 0.06660440564155579,
      "learning_rate": 3.612333186684265e-05,
      "loss": 0.0548,
      "step": 41650
    },
    {
      "epoch": 0.8331000279966404,
      "grad_norm": 0.048269547522068024,
      "learning_rate": 3.611999893346132e-05,
      "loss": 0.0853,
      "step": 41660
    },
    {
      "epoch": 0.8333000039995201,
      "grad_norm": 0.14465190470218658,
      "learning_rate": 3.6116666000079993e-05,
      "loss": 0.0491,
      "step": 41670
    },
    {
      "epoch": 0.8334999800023997,
      "grad_norm": 0.11829505860805511,
      "learning_rate": 3.611333306669866e-05,
      "loss": 0.0589,
      "step": 41680
    },
    {
      "epoch": 0.8336999560052794,
      "grad_norm": 0.07064056396484375,
      "learning_rate": 3.611000013331733e-05,
      "loss": 0.0874,
      "step": 41690
    },
    {
      "epoch": 0.833899932008159,
      "grad_norm": 0.13677719235420227,
      "learning_rate": 3.610666719993601e-05,
      "loss": 0.1007,
      "step": 41700
    },
    {
      "epoch": 0.8340999080110387,
      "grad_norm": 0.17123818397521973,
      "learning_rate": 3.6103334266554685e-05,
      "loss": 0.1428,
      "step": 41710
    },
    {
      "epoch": 0.8342998840139183,
      "grad_norm": 0.19015908241271973,
      "learning_rate": 3.6100001333173355e-05,
      "loss": 0.0615,
      "step": 41720
    },
    {
      "epoch": 0.834499860016798,
      "grad_norm": 0.09957225620746613,
      "learning_rate": 3.6096668399792025e-05,
      "loss": 0.0936,
      "step": 41730
    },
    {
      "epoch": 0.8346998360196777,
      "grad_norm": 0.06620711833238602,
      "learning_rate": 3.60933354664107e-05,
      "loss": 0.1061,
      "step": 41740
    },
    {
      "epoch": 0.8348998120225573,
      "grad_norm": 0.098757304251194,
      "learning_rate": 3.609000253302937e-05,
      "loss": 0.1,
      "step": 41750
    },
    {
      "epoch": 0.8350997880254369,
      "grad_norm": 0.15176226198673248,
      "learning_rate": 3.608666959964804e-05,
      "loss": 0.0999,
      "step": 41760
    },
    {
      "epoch": 0.8352997640283166,
      "grad_norm": 0.1330280900001526,
      "learning_rate": 3.608333666626672e-05,
      "loss": 0.1121,
      "step": 41770
    },
    {
      "epoch": 0.8354997400311962,
      "grad_norm": 0.12653914093971252,
      "learning_rate": 3.6080003732885386e-05,
      "loss": 0.0768,
      "step": 41780
    },
    {
      "epoch": 0.8356997160340759,
      "grad_norm": 0.11957496404647827,
      "learning_rate": 3.6076670799504056e-05,
      "loss": 0.0932,
      "step": 41790
    },
    {
      "epoch": 0.8358996920369556,
      "grad_norm": 0.14766967296600342,
      "learning_rate": 3.607333786612274e-05,
      "loss": 0.0768,
      "step": 41800
    },
    {
      "epoch": 0.8360996680398353,
      "grad_norm": 0.10287146270275116,
      "learning_rate": 3.607000493274141e-05,
      "loss": 0.0652,
      "step": 41810
    },
    {
      "epoch": 0.8362996440427148,
      "grad_norm": 0.12931811809539795,
      "learning_rate": 3.606667199936008e-05,
      "loss": 0.0744,
      "step": 41820
    },
    {
      "epoch": 0.8364996200455945,
      "grad_norm": 0.20942147076129913,
      "learning_rate": 3.6063339065978755e-05,
      "loss": 0.0873,
      "step": 41830
    },
    {
      "epoch": 0.8366995960484742,
      "grad_norm": 0.12276919931173325,
      "learning_rate": 3.6060006132597424e-05,
      "loss": 0.1177,
      "step": 41840
    },
    {
      "epoch": 0.8368995720513538,
      "grad_norm": 0.15870417654514313,
      "learning_rate": 3.6056673199216094e-05,
      "loss": 0.0899,
      "step": 41850
    },
    {
      "epoch": 0.8370995480542335,
      "grad_norm": 0.11229347437620163,
      "learning_rate": 3.605334026583477e-05,
      "loss": 0.0597,
      "step": 41860
    },
    {
      "epoch": 0.8372995240571132,
      "grad_norm": 0.11873067170381546,
      "learning_rate": 3.605000733245344e-05,
      "loss": 0.0608,
      "step": 41870
    },
    {
      "epoch": 0.8374995000599929,
      "grad_norm": 0.0834643766283989,
      "learning_rate": 3.604667439907211e-05,
      "loss": 0.0775,
      "step": 41880
    },
    {
      "epoch": 0.8376994760628724,
      "grad_norm": 0.17816892266273499,
      "learning_rate": 3.6043341465690786e-05,
      "loss": 0.0967,
      "step": 41890
    },
    {
      "epoch": 0.8378994520657521,
      "grad_norm": 0.18639907240867615,
      "learning_rate": 3.604000853230946e-05,
      "loss": 0.0693,
      "step": 41900
    },
    {
      "epoch": 0.8380994280686318,
      "grad_norm": 0.1211031973361969,
      "learning_rate": 3.603667559892813e-05,
      "loss": 0.1394,
      "step": 41910
    },
    {
      "epoch": 0.8382994040715114,
      "grad_norm": 0.05229632556438446,
      "learning_rate": 3.60333426655468e-05,
      "loss": 0.0761,
      "step": 41920
    },
    {
      "epoch": 0.8384993800743911,
      "grad_norm": 0.11518802493810654,
      "learning_rate": 3.603000973216548e-05,
      "loss": 0.0764,
      "step": 41930
    },
    {
      "epoch": 0.8386993560772708,
      "grad_norm": 0.08305381238460541,
      "learning_rate": 3.602667679878415e-05,
      "loss": 0.061,
      "step": 41940
    },
    {
      "epoch": 0.8388993320801503,
      "grad_norm": 0.13915613293647766,
      "learning_rate": 3.602334386540282e-05,
      "loss": 0.0522,
      "step": 41950
    },
    {
      "epoch": 0.83909930808303,
      "grad_norm": 0.058036092668771744,
      "learning_rate": 3.6020010932021494e-05,
      "loss": 0.0941,
      "step": 41960
    },
    {
      "epoch": 0.8392992840859097,
      "grad_norm": 0.04790184646844864,
      "learning_rate": 3.601667799864016e-05,
      "loss": 0.0787,
      "step": 41970
    },
    {
      "epoch": 0.8394992600887894,
      "grad_norm": 0.13977643847465515,
      "learning_rate": 3.601334506525883e-05,
      "loss": 0.059,
      "step": 41980
    },
    {
      "epoch": 0.839699236091669,
      "grad_norm": 0.10202261060476303,
      "learning_rate": 3.601001213187751e-05,
      "loss": 0.0459,
      "step": 41990
    },
    {
      "epoch": 0.8398992120945487,
      "grad_norm": 0.0640052780508995,
      "learning_rate": 3.6006679198496186e-05,
      "loss": 0.0709,
      "step": 42000
    },
    {
      "epoch": 0.8400991880974283,
      "grad_norm": 0.15625979006290436,
      "learning_rate": 3.6003346265114855e-05,
      "loss": 0.0968,
      "step": 42010
    },
    {
      "epoch": 0.8402991641003079,
      "grad_norm": 0.13245271146297455,
      "learning_rate": 3.600001333173353e-05,
      "loss": 0.1129,
      "step": 42020
    },
    {
      "epoch": 0.8404991401031876,
      "grad_norm": 0.06857485324144363,
      "learning_rate": 3.59966803983522e-05,
      "loss": 0.0638,
      "step": 42030
    },
    {
      "epoch": 0.8406991161060673,
      "grad_norm": 0.17111769318580627,
      "learning_rate": 3.599334746497087e-05,
      "loss": 0.0643,
      "step": 42040
    },
    {
      "epoch": 0.840899092108947,
      "grad_norm": 0.11740528047084808,
      "learning_rate": 3.599001453158955e-05,
      "loss": 0.0467,
      "step": 42050
    },
    {
      "epoch": 0.8410990681118266,
      "grad_norm": 0.08056890219449997,
      "learning_rate": 3.598668159820822e-05,
      "loss": 0.0593,
      "step": 42060
    },
    {
      "epoch": 0.8412990441147062,
      "grad_norm": 0.1060427576303482,
      "learning_rate": 3.5983348664826886e-05,
      "loss": 0.0972,
      "step": 42070
    },
    {
      "epoch": 0.8414990201175859,
      "grad_norm": 0.06470829993486404,
      "learning_rate": 3.598001573144556e-05,
      "loss": 0.0794,
      "step": 42080
    },
    {
      "epoch": 0.8416989961204655,
      "grad_norm": 0.12382043153047562,
      "learning_rate": 3.597668279806423e-05,
      "loss": 0.0614,
      "step": 42090
    },
    {
      "epoch": 0.8418989721233452,
      "grad_norm": 0.06892494112253189,
      "learning_rate": 3.59733498646829e-05,
      "loss": 0.1618,
      "step": 42100
    },
    {
      "epoch": 0.8420989481262249,
      "grad_norm": 0.10879587382078171,
      "learning_rate": 3.597001693130158e-05,
      "loss": 0.0863,
      "step": 42110
    },
    {
      "epoch": 0.8422989241291045,
      "grad_norm": 0.05381261929869652,
      "learning_rate": 3.5966683997920255e-05,
      "loss": 0.0768,
      "step": 42120
    },
    {
      "epoch": 0.8424989001319841,
      "grad_norm": 0.13864369690418243,
      "learning_rate": 3.5963351064538925e-05,
      "loss": 0.0866,
      "step": 42130
    },
    {
      "epoch": 0.8426988761348638,
      "grad_norm": 0.12010537087917328,
      "learning_rate": 3.5960018131157594e-05,
      "loss": 0.0618,
      "step": 42140
    },
    {
      "epoch": 0.8428988521377435,
      "grad_norm": 0.08170279860496521,
      "learning_rate": 3.595668519777627e-05,
      "loss": 0.0778,
      "step": 42150
    },
    {
      "epoch": 0.8430988281406231,
      "grad_norm": 0.10692828893661499,
      "learning_rate": 3.595335226439494e-05,
      "loss": 0.0424,
      "step": 42160
    },
    {
      "epoch": 0.8432988041435028,
      "grad_norm": 0.1425912082195282,
      "learning_rate": 3.595001933101361e-05,
      "loss": 0.1102,
      "step": 42170
    },
    {
      "epoch": 0.8434987801463825,
      "grad_norm": 0.07734545320272446,
      "learning_rate": 3.5946686397632286e-05,
      "loss": 0.0418,
      "step": 42180
    },
    {
      "epoch": 0.843698756149262,
      "grad_norm": 0.17491744458675385,
      "learning_rate": 3.5943353464250956e-05,
      "loss": 0.0492,
      "step": 42190
    },
    {
      "epoch": 0.8438987321521417,
      "grad_norm": 0.04228778928518295,
      "learning_rate": 3.5940020530869625e-05,
      "loss": 0.0579,
      "step": 42200
    },
    {
      "epoch": 0.8440987081550214,
      "grad_norm": 0.1553450971841812,
      "learning_rate": 3.593668759748831e-05,
      "loss": 0.0644,
      "step": 42210
    },
    {
      "epoch": 0.8442986841579011,
      "grad_norm": 0.20956799387931824,
      "learning_rate": 3.593335466410698e-05,
      "loss": 0.109,
      "step": 42220
    },
    {
      "epoch": 0.8444986601607807,
      "grad_norm": 0.09865155816078186,
      "learning_rate": 3.593002173072565e-05,
      "loss": 0.0756,
      "step": 42230
    },
    {
      "epoch": 0.8446986361636604,
      "grad_norm": 0.1328592151403427,
      "learning_rate": 3.5926688797344324e-05,
      "loss": 0.0892,
      "step": 42240
    },
    {
      "epoch": 0.84489861216654,
      "grad_norm": 0.10094721615314484,
      "learning_rate": 3.5923355863962994e-05,
      "loss": 0.1189,
      "step": 42250
    },
    {
      "epoch": 0.8450985881694196,
      "grad_norm": 0.16863802075386047,
      "learning_rate": 3.5920022930581663e-05,
      "loss": 0.0997,
      "step": 42260
    },
    {
      "epoch": 0.8452985641722993,
      "grad_norm": 0.16010327637195587,
      "learning_rate": 3.591668999720034e-05,
      "loss": 0.0425,
      "step": 42270
    },
    {
      "epoch": 0.845498540175179,
      "grad_norm": 0.069075807929039,
      "learning_rate": 3.591335706381901e-05,
      "loss": 0.042,
      "step": 42280
    },
    {
      "epoch": 0.8456985161780586,
      "grad_norm": 0.14234456419944763,
      "learning_rate": 3.591002413043768e-05,
      "loss": 0.098,
      "step": 42290
    },
    {
      "epoch": 0.8458984921809383,
      "grad_norm": 0.1676342934370041,
      "learning_rate": 3.5906691197056355e-05,
      "loss": 0.1164,
      "step": 42300
    },
    {
      "epoch": 0.846098468183818,
      "grad_norm": 0.09121567010879517,
      "learning_rate": 3.590335826367503e-05,
      "loss": 0.0629,
      "step": 42310
    },
    {
      "epoch": 0.8462984441866976,
      "grad_norm": 0.1894477903842926,
      "learning_rate": 3.59000253302937e-05,
      "loss": 0.0766,
      "step": 42320
    },
    {
      "epoch": 0.8464984201895772,
      "grad_norm": 0.06135524809360504,
      "learning_rate": 3.589669239691237e-05,
      "loss": 0.0631,
      "step": 42330
    },
    {
      "epoch": 0.8466983961924569,
      "grad_norm": 0.08069152384996414,
      "learning_rate": 3.589335946353105e-05,
      "loss": 0.063,
      "step": 42340
    },
    {
      "epoch": 0.8468983721953366,
      "grad_norm": 0.054945044219493866,
      "learning_rate": 3.589002653014972e-05,
      "loss": 0.1134,
      "step": 42350
    },
    {
      "epoch": 0.8470983481982162,
      "grad_norm": 0.16015268862247467,
      "learning_rate": 3.588669359676839e-05,
      "loss": 0.1457,
      "step": 42360
    },
    {
      "epoch": 0.8472983242010959,
      "grad_norm": 0.18952883780002594,
      "learning_rate": 3.588336066338706e-05,
      "loss": 0.0953,
      "step": 42370
    },
    {
      "epoch": 0.8474983002039755,
      "grad_norm": 0.21105945110321045,
      "learning_rate": 3.588002773000573e-05,
      "loss": 0.1024,
      "step": 42380
    },
    {
      "epoch": 0.8476982762068552,
      "grad_norm": 0.13150665163993835,
      "learning_rate": 3.58766947966244e-05,
      "loss": 0.0531,
      "step": 42390
    },
    {
      "epoch": 0.8478982522097348,
      "grad_norm": 0.09619513154029846,
      "learning_rate": 3.587336186324308e-05,
      "loss": 0.0641,
      "step": 42400
    },
    {
      "epoch": 0.8480982282126145,
      "grad_norm": 0.1398324817419052,
      "learning_rate": 3.5870028929861755e-05,
      "loss": 0.0618,
      "step": 42410
    },
    {
      "epoch": 0.8482982042154942,
      "grad_norm": 0.18764519691467285,
      "learning_rate": 3.5866695996480425e-05,
      "loss": 0.0966,
      "step": 42420
    },
    {
      "epoch": 0.8484981802183738,
      "grad_norm": 0.1487444043159485,
      "learning_rate": 3.58633630630991e-05,
      "loss": 0.0714,
      "step": 42430
    },
    {
      "epoch": 0.8486981562212534,
      "grad_norm": 0.1970914900302887,
      "learning_rate": 3.586003012971777e-05,
      "loss": 0.0868,
      "step": 42440
    },
    {
      "epoch": 0.8488981322241331,
      "grad_norm": 0.12384926527738571,
      "learning_rate": 3.585669719633644e-05,
      "loss": 0.0828,
      "step": 42450
    },
    {
      "epoch": 0.8490981082270127,
      "grad_norm": 0.06498979777097702,
      "learning_rate": 3.585336426295512e-05,
      "loss": 0.0579,
      "step": 42460
    },
    {
      "epoch": 0.8492980842298924,
      "grad_norm": 0.10535958409309387,
      "learning_rate": 3.5850031329573786e-05,
      "loss": 0.0914,
      "step": 42470
    },
    {
      "epoch": 0.8494980602327721,
      "grad_norm": 0.2541247606277466,
      "learning_rate": 3.5846698396192456e-05,
      "loss": 0.1133,
      "step": 42480
    },
    {
      "epoch": 0.8496980362356518,
      "grad_norm": 0.09286734461784363,
      "learning_rate": 3.584336546281113e-05,
      "loss": 0.0457,
      "step": 42490
    },
    {
      "epoch": 0.8498980122385313,
      "grad_norm": 0.16513358056545258,
      "learning_rate": 3.58400325294298e-05,
      "loss": 0.0664,
      "step": 42500
    },
    {
      "epoch": 0.850097988241411,
      "grad_norm": 0.1618073284626007,
      "learning_rate": 3.583669959604848e-05,
      "loss": 0.0768,
      "step": 42510
    },
    {
      "epoch": 0.8502979642442907,
      "grad_norm": 0.09977135062217712,
      "learning_rate": 3.583336666266715e-05,
      "loss": 0.0391,
      "step": 42520
    },
    {
      "epoch": 0.8504979402471703,
      "grad_norm": 0.09709443897008896,
      "learning_rate": 3.5830033729285824e-05,
      "loss": 0.0642,
      "step": 42530
    },
    {
      "epoch": 0.85069791625005,
      "grad_norm": 0.0933757871389389,
      "learning_rate": 3.5826700795904494e-05,
      "loss": 0.0983,
      "step": 42540
    },
    {
      "epoch": 0.8508978922529297,
      "grad_norm": 0.139839768409729,
      "learning_rate": 3.5823367862523164e-05,
      "loss": 0.0929,
      "step": 42550
    },
    {
      "epoch": 0.8510978682558094,
      "grad_norm": 0.08199460059404373,
      "learning_rate": 3.582003492914184e-05,
      "loss": 0.0805,
      "step": 42560
    },
    {
      "epoch": 0.8512978442586889,
      "grad_norm": 0.252551794052124,
      "learning_rate": 3.581670199576051e-05,
      "loss": 0.1014,
      "step": 42570
    },
    {
      "epoch": 0.8514978202615686,
      "grad_norm": 0.06842219084501266,
      "learning_rate": 3.581336906237918e-05,
      "loss": 0.0783,
      "step": 42580
    },
    {
      "epoch": 0.8516977962644483,
      "grad_norm": 0.1182616576552391,
      "learning_rate": 3.5810036128997856e-05,
      "loss": 0.0953,
      "step": 42590
    },
    {
      "epoch": 0.8518977722673279,
      "grad_norm": 0.11306078732013702,
      "learning_rate": 3.5806703195616525e-05,
      "loss": 0.0664,
      "step": 42600
    },
    {
      "epoch": 0.8520977482702076,
      "grad_norm": 0.1211342141032219,
      "learning_rate": 3.5803370262235195e-05,
      "loss": 0.0849,
      "step": 42610
    },
    {
      "epoch": 0.8522977242730873,
      "grad_norm": 0.14737235009670258,
      "learning_rate": 3.580003732885388e-05,
      "loss": 0.0735,
      "step": 42620
    },
    {
      "epoch": 0.8524977002759668,
      "grad_norm": 0.07783626019954681,
      "learning_rate": 3.579670439547255e-05,
      "loss": 0.0982,
      "step": 42630
    },
    {
      "epoch": 0.8526976762788465,
      "grad_norm": 0.15755146741867065,
      "learning_rate": 3.579337146209122e-05,
      "loss": 0.0796,
      "step": 42640
    },
    {
      "epoch": 0.8528976522817262,
      "grad_norm": 0.08179258555173874,
      "learning_rate": 3.5790038528709894e-05,
      "loss": 0.0941,
      "step": 42650
    },
    {
      "epoch": 0.8530976282846059,
      "grad_norm": 0.11449678987264633,
      "learning_rate": 3.578670559532856e-05,
      "loss": 0.1043,
      "step": 42660
    },
    {
      "epoch": 0.8532976042874855,
      "grad_norm": 0.1812402904033661,
      "learning_rate": 3.578337266194723e-05,
      "loss": 0.0772,
      "step": 42670
    },
    {
      "epoch": 0.8534975802903652,
      "grad_norm": 0.08867346495389938,
      "learning_rate": 3.578003972856591e-05,
      "loss": 0.0532,
      "step": 42680
    },
    {
      "epoch": 0.8536975562932448,
      "grad_norm": 0.1513521522283554,
      "learning_rate": 3.577670679518458e-05,
      "loss": 0.0546,
      "step": 42690
    },
    {
      "epoch": 0.8538975322961244,
      "grad_norm": 0.06428985297679901,
      "learning_rate": 3.577337386180325e-05,
      "loss": 0.0695,
      "step": 42700
    },
    {
      "epoch": 0.8540975082990041,
      "grad_norm": 0.17793413996696472,
      "learning_rate": 3.5770040928421925e-05,
      "loss": 0.0687,
      "step": 42710
    },
    {
      "epoch": 0.8542974843018838,
      "grad_norm": 0.07075965404510498,
      "learning_rate": 3.57667079950406e-05,
      "loss": 0.0733,
      "step": 42720
    },
    {
      "epoch": 0.8544974603047635,
      "grad_norm": 0.05791589245200157,
      "learning_rate": 3.576337506165927e-05,
      "loss": 0.0559,
      "step": 42730
    },
    {
      "epoch": 0.854697436307643,
      "grad_norm": 0.12976914644241333,
      "learning_rate": 3.576004212827794e-05,
      "loss": 0.0782,
      "step": 42740
    },
    {
      "epoch": 0.8548974123105227,
      "grad_norm": 0.2149970680475235,
      "learning_rate": 3.575670919489662e-05,
      "loss": 0.0605,
      "step": 42750
    },
    {
      "epoch": 0.8550973883134024,
      "grad_norm": 0.10827481746673584,
      "learning_rate": 3.5753376261515286e-05,
      "loss": 0.0463,
      "step": 42760
    },
    {
      "epoch": 0.855297364316282,
      "grad_norm": 0.11612682789564133,
      "learning_rate": 3.5750043328133956e-05,
      "loss": 0.0617,
      "step": 42770
    },
    {
      "epoch": 0.8554973403191617,
      "grad_norm": 0.12939414381980896,
      "learning_rate": 3.574671039475263e-05,
      "loss": 0.0923,
      "step": 42780
    },
    {
      "epoch": 0.8556973163220414,
      "grad_norm": 0.15235117077827454,
      "learning_rate": 3.57433774613713e-05,
      "loss": 0.0568,
      "step": 42790
    },
    {
      "epoch": 0.855897292324921,
      "grad_norm": 0.13961082696914673,
      "learning_rate": 3.574004452798997e-05,
      "loss": 0.1093,
      "step": 42800
    },
    {
      "epoch": 0.8560972683278006,
      "grad_norm": 0.2183447629213333,
      "learning_rate": 3.573671159460865e-05,
      "loss": 0.0888,
      "step": 42810
    },
    {
      "epoch": 0.8562972443306803,
      "grad_norm": 0.1742357611656189,
      "learning_rate": 3.5733378661227325e-05,
      "loss": 0.0616,
      "step": 42820
    },
    {
      "epoch": 0.85649722033356,
      "grad_norm": 0.15345612168312073,
      "learning_rate": 3.5730045727845994e-05,
      "loss": 0.0812,
      "step": 42830
    },
    {
      "epoch": 0.8566971963364396,
      "grad_norm": 0.16108395159244537,
      "learning_rate": 3.572671279446467e-05,
      "loss": 0.0628,
      "step": 42840
    },
    {
      "epoch": 0.8568971723393193,
      "grad_norm": 0.1604979783296585,
      "learning_rate": 3.572337986108334e-05,
      "loss": 0.0746,
      "step": 42850
    },
    {
      "epoch": 0.857097148342199,
      "grad_norm": 0.18111911416053772,
      "learning_rate": 3.572004692770201e-05,
      "loss": 0.0973,
      "step": 42860
    },
    {
      "epoch": 0.8572971243450785,
      "grad_norm": 0.08748546242713928,
      "learning_rate": 3.5716713994320686e-05,
      "loss": 0.1024,
      "step": 42870
    },
    {
      "epoch": 0.8574971003479582,
      "grad_norm": 0.1375676691532135,
      "learning_rate": 3.5713381060939356e-05,
      "loss": 0.0796,
      "step": 42880
    },
    {
      "epoch": 0.8576970763508379,
      "grad_norm": 0.15719886124134064,
      "learning_rate": 3.5710048127558025e-05,
      "loss": 0.0826,
      "step": 42890
    },
    {
      "epoch": 0.8578970523537176,
      "grad_norm": 0.10505280643701553,
      "learning_rate": 3.57067151941767e-05,
      "loss": 0.0765,
      "step": 42900
    },
    {
      "epoch": 0.8580970283565972,
      "grad_norm": 0.1530027687549591,
      "learning_rate": 3.570338226079537e-05,
      "loss": 0.0513,
      "step": 42910
    },
    {
      "epoch": 0.8582970043594769,
      "grad_norm": 0.07498028874397278,
      "learning_rate": 3.570004932741405e-05,
      "loss": 0.0547,
      "step": 42920
    },
    {
      "epoch": 0.8584969803623566,
      "grad_norm": 0.13972002267837524,
      "learning_rate": 3.569671639403272e-05,
      "loss": 0.0594,
      "step": 42930
    },
    {
      "epoch": 0.8586969563652361,
      "grad_norm": 0.13946639001369476,
      "learning_rate": 3.5693383460651394e-05,
      "loss": 0.0799,
      "step": 42940
    },
    {
      "epoch": 0.8588969323681158,
      "grad_norm": 0.20777468383312225,
      "learning_rate": 3.5690050527270063e-05,
      "loss": 0.0671,
      "step": 42950
    },
    {
      "epoch": 0.8590969083709955,
      "grad_norm": 0.1843465268611908,
      "learning_rate": 3.568671759388873e-05,
      "loss": 0.1155,
      "step": 42960
    },
    {
      "epoch": 0.8592968843738751,
      "grad_norm": 0.08334183692932129,
      "learning_rate": 3.568338466050741e-05,
      "loss": 0.1287,
      "step": 42970
    },
    {
      "epoch": 0.8594968603767548,
      "grad_norm": 0.06524833291769028,
      "learning_rate": 3.568005172712608e-05,
      "loss": 0.0927,
      "step": 42980
    },
    {
      "epoch": 0.8596968363796345,
      "grad_norm": 0.1278477907180786,
      "learning_rate": 3.567671879374475e-05,
      "loss": 0.0985,
      "step": 42990
    },
    {
      "epoch": 0.8598968123825141,
      "grad_norm": 0.12176951766014099,
      "learning_rate": 3.5673385860363425e-05,
      "loss": 0.0505,
      "step": 43000
    },
    {
      "epoch": 0.8600967883853937,
      "grad_norm": 0.14780829846858978,
      "learning_rate": 3.5670052926982095e-05,
      "loss": 0.0673,
      "step": 43010
    },
    {
      "epoch": 0.8602967643882734,
      "grad_norm": 0.10598458349704742,
      "learning_rate": 3.566671999360077e-05,
      "loss": 0.1075,
      "step": 43020
    },
    {
      "epoch": 0.8604967403911531,
      "grad_norm": 0.11249451339244843,
      "learning_rate": 3.566338706021945e-05,
      "loss": 0.0668,
      "step": 43030
    },
    {
      "epoch": 0.8606967163940327,
      "grad_norm": 0.17933103442192078,
      "learning_rate": 3.566005412683812e-05,
      "loss": 0.0711,
      "step": 43040
    },
    {
      "epoch": 0.8608966923969124,
      "grad_norm": 0.06258749961853027,
      "learning_rate": 3.565672119345679e-05,
      "loss": 0.0466,
      "step": 43050
    },
    {
      "epoch": 0.861096668399792,
      "grad_norm": 0.059861984103918076,
      "learning_rate": 3.565338826007546e-05,
      "loss": 0.0615,
      "step": 43060
    },
    {
      "epoch": 0.8612966444026717,
      "grad_norm": 0.14977702498435974,
      "learning_rate": 3.565005532669413e-05,
      "loss": 0.0786,
      "step": 43070
    },
    {
      "epoch": 0.8614966204055513,
      "grad_norm": 0.1827305257320404,
      "learning_rate": 3.56467223933128e-05,
      "loss": 0.1027,
      "step": 43080
    },
    {
      "epoch": 0.861696596408431,
      "grad_norm": 0.06777599453926086,
      "learning_rate": 3.564338945993148e-05,
      "loss": 0.0705,
      "step": 43090
    },
    {
      "epoch": 0.8618965724113107,
      "grad_norm": 0.08934076130390167,
      "learning_rate": 3.564005652655015e-05,
      "loss": 0.0654,
      "step": 43100
    },
    {
      "epoch": 0.8620965484141903,
      "grad_norm": 0.11230798810720444,
      "learning_rate": 3.563672359316882e-05,
      "loss": 0.053,
      "step": 43110
    },
    {
      "epoch": 0.8622965244170699,
      "grad_norm": 0.21095773577690125,
      "learning_rate": 3.5633390659787494e-05,
      "loss": 0.1012,
      "step": 43120
    },
    {
      "epoch": 0.8624965004199496,
      "grad_norm": 0.12108802795410156,
      "learning_rate": 3.563005772640617e-05,
      "loss": 0.0585,
      "step": 43130
    },
    {
      "epoch": 0.8626964764228292,
      "grad_norm": 0.12683343887329102,
      "learning_rate": 3.562672479302484e-05,
      "loss": 0.066,
      "step": 43140
    },
    {
      "epoch": 0.8628964524257089,
      "grad_norm": 0.14670635759830475,
      "learning_rate": 3.562339185964351e-05,
      "loss": 0.0853,
      "step": 43150
    },
    {
      "epoch": 0.8630964284285886,
      "grad_norm": 0.1863691806793213,
      "learning_rate": 3.5620058926262186e-05,
      "loss": 0.0759,
      "step": 43160
    },
    {
      "epoch": 0.8632964044314683,
      "grad_norm": 0.08974476903676987,
      "learning_rate": 3.5616725992880856e-05,
      "loss": 0.0769,
      "step": 43170
    },
    {
      "epoch": 0.8634963804343478,
      "grad_norm": 0.059124696999788284,
      "learning_rate": 3.5613393059499526e-05,
      "loss": 0.0376,
      "step": 43180
    },
    {
      "epoch": 0.8636963564372275,
      "grad_norm": 0.05259339511394501,
      "learning_rate": 3.56100601261182e-05,
      "loss": 0.0493,
      "step": 43190
    },
    {
      "epoch": 0.8638963324401072,
      "grad_norm": 0.1367226094007492,
      "learning_rate": 3.560672719273687e-05,
      "loss": 0.0595,
      "step": 43200
    },
    {
      "epoch": 0.8640963084429868,
      "grad_norm": 0.07518138736486435,
      "learning_rate": 3.560339425935554e-05,
      "loss": 0.0688,
      "step": 43210
    },
    {
      "epoch": 0.8642962844458665,
      "grad_norm": 0.151474729180336,
      "learning_rate": 3.560006132597422e-05,
      "loss": 0.0706,
      "step": 43220
    },
    {
      "epoch": 0.8644962604487462,
      "grad_norm": 0.1787017434835434,
      "learning_rate": 3.5596728392592894e-05,
      "loss": 0.1306,
      "step": 43230
    },
    {
      "epoch": 0.8646962364516259,
      "grad_norm": 0.15458856523036957,
      "learning_rate": 3.5593395459211564e-05,
      "loss": 0.1181,
      "step": 43240
    },
    {
      "epoch": 0.8648962124545054,
      "grad_norm": 0.05921933054924011,
      "learning_rate": 3.559006252583024e-05,
      "loss": 0.0593,
      "step": 43250
    },
    {
      "epoch": 0.8650961884573851,
      "grad_norm": 0.21888022124767303,
      "learning_rate": 3.558672959244891e-05,
      "loss": 0.0708,
      "step": 43260
    },
    {
      "epoch": 0.8652961644602648,
      "grad_norm": 0.14979948103427887,
      "learning_rate": 3.558339665906758e-05,
      "loss": 0.0889,
      "step": 43270
    },
    {
      "epoch": 0.8654961404631444,
      "grad_norm": 0.1014300286769867,
      "learning_rate": 3.5580063725686256e-05,
      "loss": 0.0554,
      "step": 43280
    },
    {
      "epoch": 0.8656961164660241,
      "grad_norm": 0.05416984483599663,
      "learning_rate": 3.5576730792304925e-05,
      "loss": 0.0624,
      "step": 43290
    },
    {
      "epoch": 0.8658960924689038,
      "grad_norm": 0.16111455857753754,
      "learning_rate": 3.5573397858923595e-05,
      "loss": 0.0744,
      "step": 43300
    },
    {
      "epoch": 0.8660960684717833,
      "grad_norm": 0.06723717600107193,
      "learning_rate": 3.557006492554227e-05,
      "loss": 0.0497,
      "step": 43310
    },
    {
      "epoch": 0.866296044474663,
      "grad_norm": 0.09059308469295502,
      "learning_rate": 3.556673199216094e-05,
      "loss": 0.0754,
      "step": 43320
    },
    {
      "epoch": 0.8664960204775427,
      "grad_norm": 0.15092046558856964,
      "learning_rate": 3.556339905877962e-05,
      "loss": 0.0735,
      "step": 43330
    },
    {
      "epoch": 0.8666959964804224,
      "grad_norm": 0.06951556354761124,
      "learning_rate": 3.556006612539829e-05,
      "loss": 0.0793,
      "step": 43340
    },
    {
      "epoch": 0.866895972483302,
      "grad_norm": 0.05874685198068619,
      "learning_rate": 3.555673319201696e-05,
      "loss": 0.0419,
      "step": 43350
    },
    {
      "epoch": 0.8670959484861817,
      "grad_norm": 0.10626015067100525,
      "learning_rate": 3.555340025863563e-05,
      "loss": 0.0968,
      "step": 43360
    },
    {
      "epoch": 0.8672959244890613,
      "grad_norm": 0.08902996778488159,
      "learning_rate": 3.55500673252543e-05,
      "loss": 0.0461,
      "step": 43370
    },
    {
      "epoch": 0.8674959004919409,
      "grad_norm": 0.08948373049497604,
      "learning_rate": 3.554673439187298e-05,
      "loss": 0.0744,
      "step": 43380
    },
    {
      "epoch": 0.8676958764948206,
      "grad_norm": 0.11837522685527802,
      "learning_rate": 3.554340145849165e-05,
      "loss": 0.0574,
      "step": 43390
    },
    {
      "epoch": 0.8678958524977003,
      "grad_norm": 0.11771222203969955,
      "learning_rate": 3.554006852511032e-05,
      "loss": 0.1041,
      "step": 43400
    },
    {
      "epoch": 0.86809582850058,
      "grad_norm": 0.08557245880365372,
      "learning_rate": 3.5536735591728994e-05,
      "loss": 0.0864,
      "step": 43410
    },
    {
      "epoch": 0.8682958045034596,
      "grad_norm": 0.12164364010095596,
      "learning_rate": 3.5533402658347664e-05,
      "loss": 0.0698,
      "step": 43420
    },
    {
      "epoch": 0.8684957805063392,
      "grad_norm": 0.07916171848773956,
      "learning_rate": 3.553006972496634e-05,
      "loss": 0.0681,
      "step": 43430
    },
    {
      "epoch": 0.8686957565092189,
      "grad_norm": 0.08187101036310196,
      "learning_rate": 3.552673679158502e-05,
      "loss": 0.1241,
      "step": 43440
    },
    {
      "epoch": 0.8688957325120985,
      "grad_norm": 0.09339668601751328,
      "learning_rate": 3.5523403858203687e-05,
      "loss": 0.088,
      "step": 43450
    },
    {
      "epoch": 0.8690957085149782,
      "grad_norm": 0.09637458622455597,
      "learning_rate": 3.5520070924822356e-05,
      "loss": 0.0768,
      "step": 43460
    },
    {
      "epoch": 0.8692956845178579,
      "grad_norm": 0.15322095155715942,
      "learning_rate": 3.551673799144103e-05,
      "loss": 0.0964,
      "step": 43470
    },
    {
      "epoch": 0.8694956605207375,
      "grad_norm": 0.109324149787426,
      "learning_rate": 3.55134050580597e-05,
      "loss": 0.0545,
      "step": 43480
    },
    {
      "epoch": 0.8696956365236171,
      "grad_norm": 0.0781727135181427,
      "learning_rate": 3.551007212467837e-05,
      "loss": 0.0933,
      "step": 43490
    },
    {
      "epoch": 0.8698956125264968,
      "grad_norm": 0.22362148761749268,
      "learning_rate": 3.550673919129705e-05,
      "loss": 0.0971,
      "step": 43500
    },
    {
      "epoch": 0.8700955885293765,
      "grad_norm": 0.19073820114135742,
      "learning_rate": 3.550340625791572e-05,
      "loss": 0.1089,
      "step": 43510
    },
    {
      "epoch": 0.8702955645322561,
      "grad_norm": 0.05245450139045715,
      "learning_rate": 3.550007332453439e-05,
      "loss": 0.0941,
      "step": 43520
    },
    {
      "epoch": 0.8704955405351358,
      "grad_norm": 0.1363154947757721,
      "learning_rate": 3.5496740391153064e-05,
      "loss": 0.0751,
      "step": 43530
    },
    {
      "epoch": 0.8706955165380155,
      "grad_norm": 0.05579223483800888,
      "learning_rate": 3.549340745777174e-05,
      "loss": 0.0701,
      "step": 43540
    },
    {
      "epoch": 0.870895492540895,
      "grad_norm": 0.1209486797451973,
      "learning_rate": 3.549007452439041e-05,
      "loss": 0.0695,
      "step": 43550
    },
    {
      "epoch": 0.8710954685437747,
      "grad_norm": 0.11034675687551498,
      "learning_rate": 3.548674159100908e-05,
      "loss": 0.0754,
      "step": 43560
    },
    {
      "epoch": 0.8712954445466544,
      "grad_norm": 0.047833316028118134,
      "learning_rate": 3.5483408657627756e-05,
      "loss": 0.0716,
      "step": 43570
    },
    {
      "epoch": 0.8714954205495341,
      "grad_norm": 0.04752064496278763,
      "learning_rate": 3.5480075724246425e-05,
      "loss": 0.0583,
      "step": 43580
    },
    {
      "epoch": 0.8716953965524137,
      "grad_norm": 0.070332370698452,
      "learning_rate": 3.5476742790865095e-05,
      "loss": 0.0577,
      "step": 43590
    },
    {
      "epoch": 0.8718953725552934,
      "grad_norm": 0.1606721729040146,
      "learning_rate": 3.547340985748377e-05,
      "loss": 0.0702,
      "step": 43600
    },
    {
      "epoch": 0.8720953485581731,
      "grad_norm": 0.140768900513649,
      "learning_rate": 3.547007692410244e-05,
      "loss": 0.0688,
      "step": 43610
    },
    {
      "epoch": 0.8722953245610526,
      "grad_norm": 0.05691269785165787,
      "learning_rate": 3.546674399072111e-05,
      "loss": 0.1074,
      "step": 43620
    },
    {
      "epoch": 0.8724953005639323,
      "grad_norm": 0.19890978932380676,
      "learning_rate": 3.546341105733979e-05,
      "loss": 0.0709,
      "step": 43630
    },
    {
      "epoch": 0.872695276566812,
      "grad_norm": 0.10671094059944153,
      "learning_rate": 3.5460078123958463e-05,
      "loss": 0.1164,
      "step": 43640
    },
    {
      "epoch": 0.8728952525696916,
      "grad_norm": 0.04186195880174637,
      "learning_rate": 3.545674519057713e-05,
      "loss": 0.0661,
      "step": 43650
    },
    {
      "epoch": 0.8730952285725713,
      "grad_norm": 0.17833349108695984,
      "learning_rate": 3.545341225719581e-05,
      "loss": 0.0891,
      "step": 43660
    },
    {
      "epoch": 0.873295204575451,
      "grad_norm": 0.06650078296661377,
      "learning_rate": 3.545007932381448e-05,
      "loss": 0.0563,
      "step": 43670
    },
    {
      "epoch": 0.8734951805783306,
      "grad_norm": 0.10664261132478714,
      "learning_rate": 3.544674639043315e-05,
      "loss": 0.0787,
      "step": 43680
    },
    {
      "epoch": 0.8736951565812102,
      "grad_norm": 0.042756397277116776,
      "learning_rate": 3.5443413457051825e-05,
      "loss": 0.0967,
      "step": 43690
    },
    {
      "epoch": 0.8738951325840899,
      "grad_norm": 0.10514184832572937,
      "learning_rate": 3.5440080523670495e-05,
      "loss": 0.0667,
      "step": 43700
    },
    {
      "epoch": 0.8740951085869696,
      "grad_norm": 0.11003812402486801,
      "learning_rate": 3.5436747590289164e-05,
      "loss": 0.0835,
      "step": 43710
    },
    {
      "epoch": 0.8742950845898492,
      "grad_norm": 0.21531842648983002,
      "learning_rate": 3.543341465690784e-05,
      "loss": 0.0747,
      "step": 43720
    },
    {
      "epoch": 0.8744950605927289,
      "grad_norm": 0.1874348670244217,
      "learning_rate": 3.543008172352651e-05,
      "loss": 0.063,
      "step": 43730
    },
    {
      "epoch": 0.8746950365956085,
      "grad_norm": 0.14729054272174835,
      "learning_rate": 3.542674879014519e-05,
      "loss": 0.0874,
      "step": 43740
    },
    {
      "epoch": 0.8748950125984882,
      "grad_norm": 0.07615426182746887,
      "learning_rate": 3.5423415856763856e-05,
      "loss": 0.0374,
      "step": 43750
    },
    {
      "epoch": 0.8750949886013678,
      "grad_norm": 0.11897910386323929,
      "learning_rate": 3.542008292338253e-05,
      "loss": 0.0439,
      "step": 43760
    },
    {
      "epoch": 0.8752949646042475,
      "grad_norm": 0.124649278819561,
      "learning_rate": 3.54167499900012e-05,
      "loss": 0.119,
      "step": 43770
    },
    {
      "epoch": 0.8754949406071272,
      "grad_norm": 0.19465899467468262,
      "learning_rate": 3.541341705661987e-05,
      "loss": 0.1126,
      "step": 43780
    },
    {
      "epoch": 0.8756949166100068,
      "grad_norm": 0.0994253009557724,
      "learning_rate": 3.541008412323855e-05,
      "loss": 0.0509,
      "step": 43790
    },
    {
      "epoch": 0.8758948926128864,
      "grad_norm": 0.15186017751693726,
      "learning_rate": 3.540675118985722e-05,
      "loss": 0.0915,
      "step": 43800
    },
    {
      "epoch": 0.8760948686157661,
      "grad_norm": 0.16163663566112518,
      "learning_rate": 3.540341825647589e-05,
      "loss": 0.0772,
      "step": 43810
    },
    {
      "epoch": 0.8762948446186457,
      "grad_norm": 0.040737755596637726,
      "learning_rate": 3.5400085323094564e-05,
      "loss": 0.0862,
      "step": 43820
    },
    {
      "epoch": 0.8764948206215254,
      "grad_norm": 0.07042235136032104,
      "learning_rate": 3.5396752389713234e-05,
      "loss": 0.0858,
      "step": 43830
    },
    {
      "epoch": 0.8766947966244051,
      "grad_norm": 0.10419756174087524,
      "learning_rate": 3.539341945633191e-05,
      "loss": 0.081,
      "step": 43840
    },
    {
      "epoch": 0.8768947726272848,
      "grad_norm": 0.11232538521289825,
      "learning_rate": 3.539008652295058e-05,
      "loss": 0.095,
      "step": 43850
    },
    {
      "epoch": 0.8770947486301643,
      "grad_norm": 0.1810276359319687,
      "learning_rate": 3.5386753589569256e-05,
      "loss": 0.0879,
      "step": 43860
    },
    {
      "epoch": 0.877294724633044,
      "grad_norm": 0.1550282984972,
      "learning_rate": 3.5383420656187926e-05,
      "loss": 0.1054,
      "step": 43870
    },
    {
      "epoch": 0.8774947006359237,
      "grad_norm": 0.10810587555170059,
      "learning_rate": 3.5380087722806595e-05,
      "loss": 0.0725,
      "step": 43880
    },
    {
      "epoch": 0.8776946766388033,
      "grad_norm": 0.07379943877458572,
      "learning_rate": 3.537675478942527e-05,
      "loss": 0.0664,
      "step": 43890
    },
    {
      "epoch": 0.877894652641683,
      "grad_norm": 0.15836118161678314,
      "learning_rate": 3.537342185604394e-05,
      "loss": 0.1202,
      "step": 43900
    },
    {
      "epoch": 0.8780946286445627,
      "grad_norm": 0.19021274149417877,
      "learning_rate": 3.537008892266262e-05,
      "loss": 0.0774,
      "step": 43910
    },
    {
      "epoch": 0.8782946046474424,
      "grad_norm": 0.07945159077644348,
      "learning_rate": 3.536675598928129e-05,
      "loss": 0.0348,
      "step": 43920
    },
    {
      "epoch": 0.8784945806503219,
      "grad_norm": 0.08434129506349564,
      "learning_rate": 3.536342305589996e-05,
      "loss": 0.0945,
      "step": 43930
    },
    {
      "epoch": 0.8786945566532016,
      "grad_norm": 0.18659567832946777,
      "learning_rate": 3.536009012251863e-05,
      "loss": 0.0712,
      "step": 43940
    },
    {
      "epoch": 0.8788945326560813,
      "grad_norm": 0.11456415802240372,
      "learning_rate": 3.535675718913731e-05,
      "loss": 0.0609,
      "step": 43950
    },
    {
      "epoch": 0.8790945086589609,
      "grad_norm": 0.07460596412420273,
      "learning_rate": 3.535342425575598e-05,
      "loss": 0.0999,
      "step": 43960
    },
    {
      "epoch": 0.8792944846618406,
      "grad_norm": 0.07709109038114548,
      "learning_rate": 3.535009132237465e-05,
      "loss": 0.0886,
      "step": 43970
    },
    {
      "epoch": 0.8794944606647203,
      "grad_norm": 0.18011574447155,
      "learning_rate": 3.5346758388993325e-05,
      "loss": 0.0918,
      "step": 43980
    },
    {
      "epoch": 0.8796944366675998,
      "grad_norm": 0.14474278688430786,
      "learning_rate": 3.5343425455611995e-05,
      "loss": 0.1065,
      "step": 43990
    },
    {
      "epoch": 0.8798944126704795,
      "grad_norm": 0.10018672049045563,
      "learning_rate": 3.5340092522230664e-05,
      "loss": 0.086,
      "step": 44000
    },
    {
      "epoch": 0.8800943886733592,
      "grad_norm": 0.16230082511901855,
      "learning_rate": 3.533675958884934e-05,
      "loss": 0.112,
      "step": 44010
    },
    {
      "epoch": 0.8802943646762389,
      "grad_norm": 0.07512570172548294,
      "learning_rate": 3.533342665546801e-05,
      "loss": 0.1205,
      "step": 44020
    },
    {
      "epoch": 0.8804943406791185,
      "grad_norm": 0.07743694633245468,
      "learning_rate": 3.533009372208668e-05,
      "loss": 0.0648,
      "step": 44030
    },
    {
      "epoch": 0.8806943166819982,
      "grad_norm": 0.09965478628873825,
      "learning_rate": 3.5326760788705356e-05,
      "loss": 0.0786,
      "step": 44040
    },
    {
      "epoch": 0.8808942926848778,
      "grad_norm": 0.12203425914049149,
      "learning_rate": 3.532342785532403e-05,
      "loss": 0.1102,
      "step": 44050
    },
    {
      "epoch": 0.8810942686877574,
      "grad_norm": 0.19561588764190674,
      "learning_rate": 3.53200949219427e-05,
      "loss": 0.0813,
      "step": 44060
    },
    {
      "epoch": 0.8812942446906371,
      "grad_norm": 0.12924446165561676,
      "learning_rate": 3.531676198856137e-05,
      "loss": 0.0506,
      "step": 44070
    },
    {
      "epoch": 0.8814942206935168,
      "grad_norm": 0.06313527375459671,
      "learning_rate": 3.531342905518005e-05,
      "loss": 0.0567,
      "step": 44080
    },
    {
      "epoch": 0.8816941966963965,
      "grad_norm": 0.20227135717868805,
      "learning_rate": 3.531009612179872e-05,
      "loss": 0.0953,
      "step": 44090
    },
    {
      "epoch": 0.8818941726992761,
      "grad_norm": 0.08000006526708603,
      "learning_rate": 3.530676318841739e-05,
      "loss": 0.0509,
      "step": 44100
    },
    {
      "epoch": 0.8820941487021557,
      "grad_norm": 0.17775402963161469,
      "learning_rate": 3.5303763548374196e-05,
      "loss": 0.4276,
      "step": 44110
    },
    {
      "epoch": 0.8822941247050354,
      "grad_norm": 0.08616506308317184,
      "learning_rate": 3.5300430614992866e-05,
      "loss": 0.128,
      "step": 44120
    },
    {
      "epoch": 0.882494100707915,
      "grad_norm": 0.10906605422496796,
      "learning_rate": 3.529709768161154e-05,
      "loss": 0.1073,
      "step": 44130
    },
    {
      "epoch": 0.8826940767107947,
      "grad_norm": 0.2053353488445282,
      "learning_rate": 3.529376474823021e-05,
      "loss": 0.0955,
      "step": 44140
    },
    {
      "epoch": 0.8828940527136744,
      "grad_norm": 0.05784787982702255,
      "learning_rate": 3.529043181484888e-05,
      "loss": 0.0879,
      "step": 44150
    },
    {
      "epoch": 0.883094028716554,
      "grad_norm": 0.15159077942371368,
      "learning_rate": 3.528709888146756e-05,
      "loss": 0.083,
      "step": 44160
    },
    {
      "epoch": 0.8832940047194336,
      "grad_norm": 0.10910148918628693,
      "learning_rate": 3.5283765948086234e-05,
      "loss": 0.0472,
      "step": 44170
    },
    {
      "epoch": 0.8834939807223133,
      "grad_norm": 0.16748853027820587,
      "learning_rate": 3.5280433014704904e-05,
      "loss": 0.0782,
      "step": 44180
    },
    {
      "epoch": 0.883693956725193,
      "grad_norm": 0.07300076633691788,
      "learning_rate": 3.527710008132358e-05,
      "loss": 0.0803,
      "step": 44190
    },
    {
      "epoch": 0.8838939327280726,
      "grad_norm": 0.16256831586360931,
      "learning_rate": 3.527376714794225e-05,
      "loss": 0.0556,
      "step": 44200
    },
    {
      "epoch": 0.8840939087309523,
      "grad_norm": 0.1496218740940094,
      "learning_rate": 3.527043421456092e-05,
      "loss": 0.0995,
      "step": 44210
    },
    {
      "epoch": 0.884293884733832,
      "grad_norm": 0.11336590349674225,
      "learning_rate": 3.5267101281179596e-05,
      "loss": 0.1026,
      "step": 44220
    },
    {
      "epoch": 0.8844938607367115,
      "grad_norm": 0.1201062873005867,
      "learning_rate": 3.5263768347798266e-05,
      "loss": 0.0921,
      "step": 44230
    },
    {
      "epoch": 0.8846938367395912,
      "grad_norm": 0.1354900598526001,
      "learning_rate": 3.5260435414416935e-05,
      "loss": 0.0795,
      "step": 44240
    },
    {
      "epoch": 0.8848938127424709,
      "grad_norm": 0.18149973452091217,
      "learning_rate": 3.525710248103561e-05,
      "loss": 0.0895,
      "step": 44250
    },
    {
      "epoch": 0.8850937887453506,
      "grad_norm": 0.11978974938392639,
      "learning_rate": 3.525376954765428e-05,
      "loss": 0.0444,
      "step": 44260
    },
    {
      "epoch": 0.8852937647482302,
      "grad_norm": 0.1152530163526535,
      "learning_rate": 3.525043661427296e-05,
      "loss": 0.0736,
      "step": 44270
    },
    {
      "epoch": 0.8854937407511099,
      "grad_norm": 0.06724758446216583,
      "learning_rate": 3.524710368089163e-05,
      "loss": 0.0744,
      "step": 44280
    },
    {
      "epoch": 0.8856937167539896,
      "grad_norm": 0.11586835235357285,
      "learning_rate": 3.5243770747510304e-05,
      "loss": 0.0681,
      "step": 44290
    },
    {
      "epoch": 0.8858936927568691,
      "grad_norm": 0.12029239535331726,
      "learning_rate": 3.524043781412897e-05,
      "loss": 0.0646,
      "step": 44300
    },
    {
      "epoch": 0.8860936687597488,
      "grad_norm": 0.07655614614486694,
      "learning_rate": 3.523710488074764e-05,
      "loss": 0.0883,
      "step": 44310
    },
    {
      "epoch": 0.8862936447626285,
      "grad_norm": 0.07960766553878784,
      "learning_rate": 3.523377194736632e-05,
      "loss": 0.0652,
      "step": 44320
    },
    {
      "epoch": 0.8864936207655081,
      "grad_norm": 0.04735269397497177,
      "learning_rate": 3.523043901398499e-05,
      "loss": 0.081,
      "step": 44330
    },
    {
      "epoch": 0.8866935967683878,
      "grad_norm": 0.21640922129154205,
      "learning_rate": 3.522710608060366e-05,
      "loss": 0.0824,
      "step": 44340
    },
    {
      "epoch": 0.8868935727712675,
      "grad_norm": 0.1460198163986206,
      "learning_rate": 3.5223773147222335e-05,
      "loss": 0.316,
      "step": 44350
    },
    {
      "epoch": 0.8870935487741471,
      "grad_norm": 0.12785601615905762,
      "learning_rate": 3.5220440213841005e-05,
      "loss": 0.086,
      "step": 44360
    },
    {
      "epoch": 0.8872935247770267,
      "grad_norm": 0.07599924504756927,
      "learning_rate": 3.521710728045968e-05,
      "loss": 0.0924,
      "step": 44370
    },
    {
      "epoch": 0.8874935007799064,
      "grad_norm": 0.1389634609222412,
      "learning_rate": 3.521377434707836e-05,
      "loss": 0.0717,
      "step": 44380
    },
    {
      "epoch": 0.8876934767827861,
      "grad_norm": 0.15272235870361328,
      "learning_rate": 3.521044141369703e-05,
      "loss": 0.1058,
      "step": 44390
    },
    {
      "epoch": 0.8878934527856657,
      "grad_norm": 0.21106570959091187,
      "learning_rate": 3.52071084803157e-05,
      "loss": 0.0841,
      "step": 44400
    },
    {
      "epoch": 0.8880934287885454,
      "grad_norm": 0.04443713650107384,
      "learning_rate": 3.520377554693437e-05,
      "loss": 0.0823,
      "step": 44410
    },
    {
      "epoch": 0.888293404791425,
      "grad_norm": 0.11425859481096268,
      "learning_rate": 3.520044261355304e-05,
      "loss": 0.103,
      "step": 44420
    },
    {
      "epoch": 0.8884933807943047,
      "grad_norm": 0.16008833050727844,
      "learning_rate": 3.519710968017171e-05,
      "loss": 0.0822,
      "step": 44430
    },
    {
      "epoch": 0.8886933567971843,
      "grad_norm": 0.20874656736850739,
      "learning_rate": 3.519377674679039e-05,
      "loss": 0.1,
      "step": 44440
    },
    {
      "epoch": 0.888893332800064,
      "grad_norm": 0.11480394750833511,
      "learning_rate": 3.519044381340906e-05,
      "loss": 0.0664,
      "step": 44450
    },
    {
      "epoch": 0.8890933088029437,
      "grad_norm": 0.10863394290208817,
      "learning_rate": 3.518711088002773e-05,
      "loss": 0.0989,
      "step": 44460
    },
    {
      "epoch": 0.8892932848058233,
      "grad_norm": 0.07124920189380646,
      "learning_rate": 3.5183777946646404e-05,
      "loss": 0.0497,
      "step": 44470
    },
    {
      "epoch": 0.889493260808703,
      "grad_norm": 0.11152854561805725,
      "learning_rate": 3.518044501326508e-05,
      "loss": 0.0767,
      "step": 44480
    },
    {
      "epoch": 0.8896932368115826,
      "grad_norm": 0.08254743367433548,
      "learning_rate": 3.517711207988375e-05,
      "loss": 0.0819,
      "step": 44490
    },
    {
      "epoch": 0.8898932128144623,
      "grad_norm": 0.12433198094367981,
      "learning_rate": 3.517377914650242e-05,
      "loss": 0.1037,
      "step": 44500
    },
    {
      "epoch": 0.8900931888173419,
      "grad_norm": 0.17190101742744446,
      "learning_rate": 3.5170446213121096e-05,
      "loss": 0.0849,
      "step": 44510
    },
    {
      "epoch": 0.8902931648202216,
      "grad_norm": 0.05855429545044899,
      "learning_rate": 3.5167113279739766e-05,
      "loss": 0.0575,
      "step": 44520
    },
    {
      "epoch": 0.8904931408231013,
      "grad_norm": 0.12589162588119507,
      "learning_rate": 3.5163780346358436e-05,
      "loss": 0.083,
      "step": 44530
    },
    {
      "epoch": 0.8906931168259808,
      "grad_norm": 0.09437832981348038,
      "learning_rate": 3.516044741297711e-05,
      "loss": 0.0736,
      "step": 44540
    },
    {
      "epoch": 0.8908930928288605,
      "grad_norm": 0.12923817336559296,
      "learning_rate": 3.515711447959578e-05,
      "loss": 0.0854,
      "step": 44550
    },
    {
      "epoch": 0.8910930688317402,
      "grad_norm": 0.123359315097332,
      "learning_rate": 3.515378154621445e-05,
      "loss": 0.0583,
      "step": 44560
    },
    {
      "epoch": 0.8912930448346198,
      "grad_norm": 0.11855148524045944,
      "learning_rate": 3.515044861283313e-05,
      "loss": 0.104,
      "step": 44570
    },
    {
      "epoch": 0.8914930208374995,
      "grad_norm": 0.05770569667220116,
      "learning_rate": 3.5147115679451804e-05,
      "loss": 0.0804,
      "step": 44580
    },
    {
      "epoch": 0.8916929968403792,
      "grad_norm": 0.29368123412132263,
      "learning_rate": 3.5143782746070474e-05,
      "loss": 0.3005,
      "step": 44590
    },
    {
      "epoch": 0.8918929728432589,
      "grad_norm": 0.11998888105154037,
      "learning_rate": 3.514044981268915e-05,
      "loss": 0.0833,
      "step": 44600
    },
    {
      "epoch": 0.8920929488461384,
      "grad_norm": 0.12604764103889465,
      "learning_rate": 3.513711687930782e-05,
      "loss": 0.0603,
      "step": 44610
    },
    {
      "epoch": 0.8922929248490181,
      "grad_norm": 0.190863698720932,
      "learning_rate": 3.513378394592649e-05,
      "loss": 0.0767,
      "step": 44620
    },
    {
      "epoch": 0.8924929008518978,
      "grad_norm": 0.16669677197933197,
      "learning_rate": 3.5130451012545166e-05,
      "loss": 0.061,
      "step": 44630
    },
    {
      "epoch": 0.8926928768547774,
      "grad_norm": 0.11124156415462494,
      "learning_rate": 3.5127118079163835e-05,
      "loss": 0.0729,
      "step": 44640
    },
    {
      "epoch": 0.8928928528576571,
      "grad_norm": 0.23997320234775543,
      "learning_rate": 3.5123785145782505e-05,
      "loss": 0.0849,
      "step": 44650
    },
    {
      "epoch": 0.8930928288605368,
      "grad_norm": 0.09253697842359543,
      "learning_rate": 3.512045221240118e-05,
      "loss": 0.1008,
      "step": 44660
    },
    {
      "epoch": 0.8932928048634164,
      "grad_norm": 0.09326782822608948,
      "learning_rate": 3.511711927901985e-05,
      "loss": 0.1092,
      "step": 44670
    },
    {
      "epoch": 0.893492780866296,
      "grad_norm": 0.10083327442407608,
      "learning_rate": 3.511378634563853e-05,
      "loss": 0.0715,
      "step": 44680
    },
    {
      "epoch": 0.8936927568691757,
      "grad_norm": 0.11705300211906433,
      "learning_rate": 3.51104534122572e-05,
      "loss": 0.0711,
      "step": 44690
    },
    {
      "epoch": 0.8938927328720554,
      "grad_norm": 0.15799584984779358,
      "learning_rate": 3.510712047887587e-05,
      "loss": 0.0932,
      "step": 44700
    },
    {
      "epoch": 0.894092708874935,
      "grad_norm": 0.06103067472577095,
      "learning_rate": 3.510378754549454e-05,
      "loss": 0.0692,
      "step": 44710
    },
    {
      "epoch": 0.8942926848778147,
      "grad_norm": 0.19828349351882935,
      "learning_rate": 3.510045461211321e-05,
      "loss": 0.0704,
      "step": 44720
    },
    {
      "epoch": 0.8944926608806943,
      "grad_norm": 0.08818810433149338,
      "learning_rate": 3.509712167873189e-05,
      "loss": 0.0792,
      "step": 44730
    },
    {
      "epoch": 0.8946926368835739,
      "grad_norm": 0.07467209547758102,
      "learning_rate": 3.509378874535056e-05,
      "loss": 0.0717,
      "step": 44740
    },
    {
      "epoch": 0.8948926128864536,
      "grad_norm": 0.08410428464412689,
      "learning_rate": 3.509045581196923e-05,
      "loss": 0.08,
      "step": 44750
    },
    {
      "epoch": 0.8950925888893333,
      "grad_norm": 0.20161665976047516,
      "learning_rate": 3.5087122878587904e-05,
      "loss": 0.0945,
      "step": 44760
    },
    {
      "epoch": 0.895292564892213,
      "grad_norm": 0.07031567394733429,
      "learning_rate": 3.5083789945206574e-05,
      "loss": 0.093,
      "step": 44770
    },
    {
      "epoch": 0.8954925408950926,
      "grad_norm": 0.11091096699237823,
      "learning_rate": 3.508045701182525e-05,
      "loss": 0.0506,
      "step": 44780
    },
    {
      "epoch": 0.8956925168979722,
      "grad_norm": 0.17095208168029785,
      "learning_rate": 3.507712407844393e-05,
      "loss": 0.0992,
      "step": 44790
    },
    {
      "epoch": 0.8958924929008519,
      "grad_norm": 0.07728102058172226,
      "learning_rate": 3.5073791145062596e-05,
      "loss": 0.0543,
      "step": 44800
    },
    {
      "epoch": 0.8960924689037315,
      "grad_norm": 0.14450687170028687,
      "learning_rate": 3.5070458211681266e-05,
      "loss": 0.0738,
      "step": 44810
    },
    {
      "epoch": 0.8962924449066112,
      "grad_norm": 0.08251331746578217,
      "learning_rate": 3.5067458571638075e-05,
      "loss": 0.072,
      "step": 44820
    },
    {
      "epoch": 0.8964924209094909,
      "grad_norm": 0.06796009838581085,
      "learning_rate": 3.5064125638256744e-05,
      "loss": 0.0726,
      "step": 44830
    },
    {
      "epoch": 0.8966923969123706,
      "grad_norm": 0.19418153166770935,
      "learning_rate": 3.5060792704875414e-05,
      "loss": 0.0786,
      "step": 44840
    },
    {
      "epoch": 0.8968923729152501,
      "grad_norm": 0.11970409750938416,
      "learning_rate": 3.505745977149409e-05,
      "loss": 0.0694,
      "step": 44850
    },
    {
      "epoch": 0.8970923489181298,
      "grad_norm": 0.09578050673007965,
      "learning_rate": 3.505412683811276e-05,
      "loss": 0.097,
      "step": 44860
    },
    {
      "epoch": 0.8972923249210095,
      "grad_norm": 0.09986966848373413,
      "learning_rate": 3.505079390473143e-05,
      "loss": 0.0822,
      "step": 44870
    },
    {
      "epoch": 0.8974923009238891,
      "grad_norm": 0.0719207227230072,
      "learning_rate": 3.5047460971350106e-05,
      "loss": 0.1119,
      "step": 44880
    },
    {
      "epoch": 0.8976922769267688,
      "grad_norm": 0.10400678962469101,
      "learning_rate": 3.5044128037968776e-05,
      "loss": 0.0584,
      "step": 44890
    },
    {
      "epoch": 0.8978922529296485,
      "grad_norm": 0.08380882441997528,
      "learning_rate": 3.504079510458745e-05,
      "loss": 0.0466,
      "step": 44900
    },
    {
      "epoch": 0.898092228932528,
      "grad_norm": 0.08945906907320023,
      "learning_rate": 3.503746217120613e-05,
      "loss": 0.0607,
      "step": 44910
    },
    {
      "epoch": 0.8982922049354077,
      "grad_norm": 0.06165678799152374,
      "learning_rate": 3.50341292378248e-05,
      "loss": 0.0852,
      "step": 44920
    },
    {
      "epoch": 0.8984921809382874,
      "grad_norm": 0.12860342860221863,
      "learning_rate": 3.503079630444347e-05,
      "loss": 0.1248,
      "step": 44930
    },
    {
      "epoch": 0.8986921569411671,
      "grad_norm": 0.14510206878185272,
      "learning_rate": 3.5027463371062144e-05,
      "loss": 0.109,
      "step": 44940
    },
    {
      "epoch": 0.8988921329440467,
      "grad_norm": 0.09137637168169022,
      "learning_rate": 3.5024130437680814e-05,
      "loss": 0.0969,
      "step": 44950
    },
    {
      "epoch": 0.8990921089469264,
      "grad_norm": 0.1881984919309616,
      "learning_rate": 3.502079750429948e-05,
      "loss": 0.0774,
      "step": 44960
    },
    {
      "epoch": 0.8992920849498061,
      "grad_norm": 0.19411900639533997,
      "learning_rate": 3.501746457091816e-05,
      "loss": 0.0748,
      "step": 44970
    },
    {
      "epoch": 0.8994920609526856,
      "grad_norm": 0.186798557639122,
      "learning_rate": 3.501413163753683e-05,
      "loss": 0.1025,
      "step": 44980
    },
    {
      "epoch": 0.8996920369555653,
      "grad_norm": 0.09862945973873138,
      "learning_rate": 3.50107987041555e-05,
      "loss": 0.0671,
      "step": 44990
    },
    {
      "epoch": 0.899892012958445,
      "grad_norm": 0.11550985276699066,
      "learning_rate": 3.5007465770774175e-05,
      "loss": 0.0702,
      "step": 45000
    },
    {
      "epoch": 0.9000919889613247,
      "grad_norm": 0.14815492928028107,
      "learning_rate": 3.500413283739285e-05,
      "loss": 0.1119,
      "step": 45010
    },
    {
      "epoch": 0.9002919649642043,
      "grad_norm": 0.12888139486312866,
      "learning_rate": 3.500079990401152e-05,
      "loss": 0.0527,
      "step": 45020
    },
    {
      "epoch": 0.900491940967084,
      "grad_norm": 0.15293407440185547,
      "learning_rate": 3.499746697063019e-05,
      "loss": 0.0744,
      "step": 45030
    },
    {
      "epoch": 0.9006919169699636,
      "grad_norm": 0.0949268788099289,
      "learning_rate": 3.499413403724887e-05,
      "loss": 0.0763,
      "step": 45040
    },
    {
      "epoch": 0.9008918929728432,
      "grad_norm": 0.06939173489809036,
      "learning_rate": 3.499080110386754e-05,
      "loss": 0.0723,
      "step": 45050
    },
    {
      "epoch": 0.9010918689757229,
      "grad_norm": 0.16822993755340576,
      "learning_rate": 3.498746817048621e-05,
      "loss": 0.0717,
      "step": 45060
    },
    {
      "epoch": 0.9012918449786026,
      "grad_norm": 0.10588717460632324,
      "learning_rate": 3.498413523710488e-05,
      "loss": 0.0425,
      "step": 45070
    },
    {
      "epoch": 0.9014918209814822,
      "grad_norm": 0.08679848164319992,
      "learning_rate": 3.498080230372355e-05,
      "loss": 0.0811,
      "step": 45080
    },
    {
      "epoch": 0.9016917969843619,
      "grad_norm": 0.06137999892234802,
      "learning_rate": 3.497746937034222e-05,
      "loss": 0.0922,
      "step": 45090
    },
    {
      "epoch": 0.9018917729872415,
      "grad_norm": 0.16028980910778046,
      "learning_rate": 3.49741364369609e-05,
      "loss": 0.07,
      "step": 45100
    },
    {
      "epoch": 0.9020917489901212,
      "grad_norm": 0.07290123403072357,
      "learning_rate": 3.4970803503579575e-05,
      "loss": 0.0788,
      "step": 45110
    },
    {
      "epoch": 0.9022917249930008,
      "grad_norm": 0.17631012201309204,
      "learning_rate": 3.4967470570198245e-05,
      "loss": 0.0534,
      "step": 45120
    },
    {
      "epoch": 0.9024917009958805,
      "grad_norm": 0.1735515147447586,
      "learning_rate": 3.496413763681692e-05,
      "loss": 0.0966,
      "step": 45130
    },
    {
      "epoch": 0.9026916769987602,
      "grad_norm": 0.1772850602865219,
      "learning_rate": 3.496080470343559e-05,
      "loss": 0.1114,
      "step": 45140
    },
    {
      "epoch": 0.9028916530016398,
      "grad_norm": 0.06829903274774551,
      "learning_rate": 3.495747177005426e-05,
      "loss": 0.047,
      "step": 45150
    },
    {
      "epoch": 0.9030916290045194,
      "grad_norm": 0.08923233300447464,
      "learning_rate": 3.495413883667294e-05,
      "loss": 0.0526,
      "step": 45160
    },
    {
      "epoch": 0.9032916050073991,
      "grad_norm": 0.15880383551120758,
      "learning_rate": 3.4950805903291606e-05,
      "loss": 0.0902,
      "step": 45170
    },
    {
      "epoch": 0.9034915810102788,
      "grad_norm": 0.07805154472589493,
      "learning_rate": 3.4947472969910276e-05,
      "loss": 0.1374,
      "step": 45180
    },
    {
      "epoch": 0.9036915570131584,
      "grad_norm": 0.06296844035387039,
      "learning_rate": 3.494414003652895e-05,
      "loss": 0.0458,
      "step": 45190
    },
    {
      "epoch": 0.9038915330160381,
      "grad_norm": 0.2238704115152359,
      "learning_rate": 3.494080710314762e-05,
      "loss": 0.0914,
      "step": 45200
    },
    {
      "epoch": 0.9040915090189178,
      "grad_norm": 0.15298213064670563,
      "learning_rate": 3.49374741697663e-05,
      "loss": 0.0881,
      "step": 45210
    },
    {
      "epoch": 0.9042914850217973,
      "grad_norm": 0.09029128402471542,
      "learning_rate": 3.493414123638497e-05,
      "loss": 0.1004,
      "step": 45220
    },
    {
      "epoch": 0.904491461024677,
      "grad_norm": 0.14816738665103912,
      "learning_rate": 3.4930808303003644e-05,
      "loss": 0.0908,
      "step": 45230
    },
    {
      "epoch": 0.9046914370275567,
      "grad_norm": 0.20266979932785034,
      "learning_rate": 3.4927475369622314e-05,
      "loss": 0.0941,
      "step": 45240
    },
    {
      "epoch": 0.9048914130304363,
      "grad_norm": 0.1618097424507141,
      "learning_rate": 3.4924142436240984e-05,
      "loss": 0.0577,
      "step": 45250
    },
    {
      "epoch": 0.905091389033316,
      "grad_norm": 0.09100768715143204,
      "learning_rate": 3.492080950285966e-05,
      "loss": 0.0633,
      "step": 45260
    },
    {
      "epoch": 0.9052913650361957,
      "grad_norm": 0.10106667131185532,
      "learning_rate": 3.491747656947833e-05,
      "loss": 0.0761,
      "step": 45270
    },
    {
      "epoch": 0.9054913410390754,
      "grad_norm": 0.15885761380195618,
      "learning_rate": 3.4914143636097e-05,
      "loss": 0.0659,
      "step": 45280
    },
    {
      "epoch": 0.9056913170419549,
      "grad_norm": 0.15932059288024902,
      "learning_rate": 3.4910810702715676e-05,
      "loss": 0.0697,
      "step": 45290
    },
    {
      "epoch": 0.9058912930448346,
      "grad_norm": 0.2738966643810272,
      "learning_rate": 3.4907477769334345e-05,
      "loss": 0.1656,
      "step": 45300
    },
    {
      "epoch": 0.9060912690477143,
      "grad_norm": 0.0951169952750206,
      "learning_rate": 3.490414483595302e-05,
      "loss": 0.063,
      "step": 45310
    },
    {
      "epoch": 0.9062912450505939,
      "grad_norm": 0.09098968654870987,
      "learning_rate": 3.49008119025717e-05,
      "loss": 0.0491,
      "step": 45320
    },
    {
      "epoch": 0.9064912210534736,
      "grad_norm": 0.1449389010667801,
      "learning_rate": 3.489747896919037e-05,
      "loss": 0.0633,
      "step": 45330
    },
    {
      "epoch": 0.9066911970563533,
      "grad_norm": 0.08988228440284729,
      "learning_rate": 3.489414603580904e-05,
      "loss": 0.044,
      "step": 45340
    },
    {
      "epoch": 0.906891173059233,
      "grad_norm": 0.16066336631774902,
      "learning_rate": 3.4890813102427714e-05,
      "loss": 0.0628,
      "step": 45350
    },
    {
      "epoch": 0.9070911490621125,
      "grad_norm": 0.21856972575187683,
      "learning_rate": 3.488748016904638e-05,
      "loss": 0.0815,
      "step": 45360
    },
    {
      "epoch": 0.9072911250649922,
      "grad_norm": 0.09007398784160614,
      "learning_rate": 3.488414723566505e-05,
      "loss": 0.0496,
      "step": 45370
    },
    {
      "epoch": 0.9074911010678719,
      "grad_norm": 0.05494414269924164,
      "learning_rate": 3.488081430228373e-05,
      "loss": 0.0821,
      "step": 45380
    },
    {
      "epoch": 0.9076910770707515,
      "grad_norm": 0.038022954016923904,
      "learning_rate": 3.48774813689024e-05,
      "loss": 0.0513,
      "step": 45390
    },
    {
      "epoch": 0.9078910530736312,
      "grad_norm": 0.11979518830776215,
      "learning_rate": 3.487414843552107e-05,
      "loss": 0.0808,
      "step": 45400
    },
    {
      "epoch": 0.9080910290765108,
      "grad_norm": 0.20217378437519073,
      "learning_rate": 3.4870815502139745e-05,
      "loss": 0.1118,
      "step": 45410
    },
    {
      "epoch": 0.9082910050793904,
      "grad_norm": 0.17047035694122314,
      "learning_rate": 3.486748256875842e-05,
      "loss": 0.081,
      "step": 45420
    },
    {
      "epoch": 0.9084909810822701,
      "grad_norm": 0.11418610066175461,
      "learning_rate": 3.486414963537709e-05,
      "loss": 0.0584,
      "step": 45430
    },
    {
      "epoch": 0.9086909570851498,
      "grad_norm": 0.14562585949897766,
      "learning_rate": 3.486081670199576e-05,
      "loss": 0.0797,
      "step": 45440
    },
    {
      "epoch": 0.9088909330880295,
      "grad_norm": 0.11667679250240326,
      "learning_rate": 3.485748376861444e-05,
      "loss": 0.0611,
      "step": 45450
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.12605391442775726,
      "learning_rate": 3.4854150835233106e-05,
      "loss": 0.0497,
      "step": 45460
    },
    {
      "epoch": 0.9092908850937887,
      "grad_norm": 0.1287171095609665,
      "learning_rate": 3.4850817901851776e-05,
      "loss": 0.0713,
      "step": 45470
    },
    {
      "epoch": 0.9094908610966684,
      "grad_norm": 0.05543605610728264,
      "learning_rate": 3.484748496847045e-05,
      "loss": 0.0795,
      "step": 45480
    },
    {
      "epoch": 0.909690837099548,
      "grad_norm": 0.19981823861598969,
      "learning_rate": 3.484415203508912e-05,
      "loss": 0.1003,
      "step": 45490
    },
    {
      "epoch": 0.9098908131024277,
      "grad_norm": 0.23835262656211853,
      "learning_rate": 3.484081910170779e-05,
      "loss": 0.1533,
      "step": 45500
    },
    {
      "epoch": 0.9100907891053074,
      "grad_norm": 0.14039774239063263,
      "learning_rate": 3.483748616832647e-05,
      "loss": 0.0855,
      "step": 45510
    },
    {
      "epoch": 0.9102907651081871,
      "grad_norm": 0.17580218613147736,
      "learning_rate": 3.4834153234945144e-05,
      "loss": 0.0606,
      "step": 45520
    },
    {
      "epoch": 0.9104907411110666,
      "grad_norm": 0.07744531333446503,
      "learning_rate": 3.4830820301563814e-05,
      "loss": 0.1096,
      "step": 45530
    },
    {
      "epoch": 0.9106907171139463,
      "grad_norm": 0.05302029475569725,
      "learning_rate": 3.482748736818249e-05,
      "loss": 0.1019,
      "step": 45540
    },
    {
      "epoch": 0.910890693116826,
      "grad_norm": 0.18668808043003082,
      "learning_rate": 3.482415443480116e-05,
      "loss": 0.0922,
      "step": 45550
    },
    {
      "epoch": 0.9110906691197056,
      "grad_norm": 0.06791271269321442,
      "learning_rate": 3.482082150141983e-05,
      "loss": 0.0507,
      "step": 45560
    },
    {
      "epoch": 0.9112906451225853,
      "grad_norm": 0.18770891427993774,
      "learning_rate": 3.4817488568038506e-05,
      "loss": 0.0894,
      "step": 45570
    },
    {
      "epoch": 0.911490621125465,
      "grad_norm": 0.1914033442735672,
      "learning_rate": 3.4814155634657176e-05,
      "loss": 0.0931,
      "step": 45580
    },
    {
      "epoch": 0.9116905971283445,
      "grad_norm": 0.21268045902252197,
      "learning_rate": 3.4810822701275845e-05,
      "loss": 0.0567,
      "step": 45590
    },
    {
      "epoch": 0.9118905731312242,
      "grad_norm": 0.15730085968971252,
      "learning_rate": 3.480748976789452e-05,
      "loss": 0.0558,
      "step": 45600
    },
    {
      "epoch": 0.9120905491341039,
      "grad_norm": 0.19064196944236755,
      "learning_rate": 3.480415683451319e-05,
      "loss": 0.1166,
      "step": 45610
    },
    {
      "epoch": 0.9122905251369836,
      "grad_norm": 0.12620806694030762,
      "learning_rate": 3.480082390113187e-05,
      "loss": 0.0845,
      "step": 45620
    },
    {
      "epoch": 0.9124905011398632,
      "grad_norm": 0.0936194509267807,
      "learning_rate": 3.479749096775054e-05,
      "loss": 0.09,
      "step": 45630
    },
    {
      "epoch": 0.9126904771427429,
      "grad_norm": 0.11224271357059479,
      "learning_rate": 3.4794158034369214e-05,
      "loss": 0.0872,
      "step": 45640
    },
    {
      "epoch": 0.9128904531456226,
      "grad_norm": 0.091692253947258,
      "learning_rate": 3.479082510098788e-05,
      "loss": 0.0696,
      "step": 45650
    },
    {
      "epoch": 0.9130904291485021,
      "grad_norm": 0.1325557678937912,
      "learning_rate": 3.478749216760655e-05,
      "loss": 0.0959,
      "step": 45660
    },
    {
      "epoch": 0.9132904051513818,
      "grad_norm": 0.11036928743124008,
      "learning_rate": 3.478415923422523e-05,
      "loss": 0.0655,
      "step": 45670
    },
    {
      "epoch": 0.9134903811542615,
      "grad_norm": 0.07113586366176605,
      "learning_rate": 3.47808263008439e-05,
      "loss": 0.0816,
      "step": 45680
    },
    {
      "epoch": 0.9136903571571412,
      "grad_norm": 0.18477866053581238,
      "learning_rate": 3.477749336746257e-05,
      "loss": 0.083,
      "step": 45690
    },
    {
      "epoch": 0.9138903331600208,
      "grad_norm": 0.07116606086492538,
      "learning_rate": 3.4774160434081245e-05,
      "loss": 0.0969,
      "step": 45700
    },
    {
      "epoch": 0.9140903091629005,
      "grad_norm": 0.06530407816171646,
      "learning_rate": 3.4770827500699915e-05,
      "loss": 0.0758,
      "step": 45710
    },
    {
      "epoch": 0.9142902851657801,
      "grad_norm": 0.08133421838283539,
      "learning_rate": 3.476749456731859e-05,
      "loss": 0.0686,
      "step": 45720
    },
    {
      "epoch": 0.9144902611686597,
      "grad_norm": 0.09192164987325668,
      "learning_rate": 3.476416163393727e-05,
      "loss": 0.088,
      "step": 45730
    },
    {
      "epoch": 0.9146902371715394,
      "grad_norm": 0.15618731081485748,
      "learning_rate": 3.476082870055594e-05,
      "loss": 0.0912,
      "step": 45740
    },
    {
      "epoch": 0.9148902131744191,
      "grad_norm": 0.12449132651090622,
      "learning_rate": 3.475749576717461e-05,
      "loss": 0.0649,
      "step": 45750
    },
    {
      "epoch": 0.9150901891772987,
      "grad_norm": 0.07820948958396912,
      "learning_rate": 3.475416283379328e-05,
      "loss": 0.0804,
      "step": 45760
    },
    {
      "epoch": 0.9152901651801784,
      "grad_norm": 0.12400330603122711,
      "learning_rate": 3.475082990041195e-05,
      "loss": 0.0587,
      "step": 45770
    },
    {
      "epoch": 0.915490141183058,
      "grad_norm": 0.09230291843414307,
      "learning_rate": 3.474749696703062e-05,
      "loss": 0.0457,
      "step": 45780
    },
    {
      "epoch": 0.9156901171859377,
      "grad_norm": 0.09648769348859787,
      "learning_rate": 3.47441640336493e-05,
      "loss": 0.0983,
      "step": 45790
    },
    {
      "epoch": 0.9158900931888173,
      "grad_norm": 0.07951615005731583,
      "learning_rate": 3.474083110026797e-05,
      "loss": 0.0942,
      "step": 45800
    },
    {
      "epoch": 0.916090069191697,
      "grad_norm": 0.1258051097393036,
      "learning_rate": 3.473749816688664e-05,
      "loss": 0.0738,
      "step": 45810
    },
    {
      "epoch": 0.9162900451945767,
      "grad_norm": 0.19380322098731995,
      "learning_rate": 3.4734165233505314e-05,
      "loss": 0.0933,
      "step": 45820
    },
    {
      "epoch": 0.9164900211974563,
      "grad_norm": 0.07714394479990005,
      "learning_rate": 3.473083230012399e-05,
      "loss": 0.072,
      "step": 45830
    },
    {
      "epoch": 0.916689997200336,
      "grad_norm": 0.10222089290618896,
      "learning_rate": 3.472749936674266e-05,
      "loss": 0.0998,
      "step": 45840
    },
    {
      "epoch": 0.9168899732032156,
      "grad_norm": 0.18818579614162445,
      "learning_rate": 3.472416643336133e-05,
      "loss": 0.0895,
      "step": 45850
    },
    {
      "epoch": 0.9170899492060953,
      "grad_norm": 0.16701768338680267,
      "learning_rate": 3.4720833499980006e-05,
      "loss": 0.0749,
      "step": 45860
    },
    {
      "epoch": 0.9172899252089749,
      "grad_norm": 0.06705313175916672,
      "learning_rate": 3.4717500566598676e-05,
      "loss": 0.0564,
      "step": 45870
    },
    {
      "epoch": 0.9174899012118546,
      "grad_norm": 0.14976778626441956,
      "learning_rate": 3.4714167633217346e-05,
      "loss": 0.0839,
      "step": 45880
    },
    {
      "epoch": 0.9176898772147343,
      "grad_norm": 0.11284816265106201,
      "learning_rate": 3.471083469983602e-05,
      "loss": 0.0994,
      "step": 45890
    },
    {
      "epoch": 0.9178898532176138,
      "grad_norm": 0.07063658535480499,
      "learning_rate": 3.470750176645469e-05,
      "loss": 0.0558,
      "step": 45900
    },
    {
      "epoch": 0.9180898292204935,
      "grad_norm": 0.1655094176530838,
      "learning_rate": 3.470416883307336e-05,
      "loss": 0.0556,
      "step": 45910
    },
    {
      "epoch": 0.9182898052233732,
      "grad_norm": 0.07101494818925858,
      "learning_rate": 3.4700835899692044e-05,
      "loss": 0.0507,
      "step": 45920
    },
    {
      "epoch": 0.9184897812262528,
      "grad_norm": 0.06051009148359299,
      "learning_rate": 3.4697502966310714e-05,
      "loss": 0.0881,
      "step": 45930
    },
    {
      "epoch": 0.9186897572291325,
      "grad_norm": 0.07880187779664993,
      "learning_rate": 3.4694170032929384e-05,
      "loss": 0.0916,
      "step": 45940
    },
    {
      "epoch": 0.9188897332320122,
      "grad_norm": 0.17336872220039368,
      "learning_rate": 3.469083709954806e-05,
      "loss": 0.0541,
      "step": 45950
    },
    {
      "epoch": 0.9190897092348919,
      "grad_norm": 0.14686144888401031,
      "learning_rate": 3.468750416616673e-05,
      "loss": 0.0703,
      "step": 45960
    },
    {
      "epoch": 0.9192896852377714,
      "grad_norm": 0.11756283789873123,
      "learning_rate": 3.46841712327854e-05,
      "loss": 0.0926,
      "step": 45970
    },
    {
      "epoch": 0.9194896612406511,
      "grad_norm": 0.15101833641529083,
      "learning_rate": 3.4680838299404076e-05,
      "loss": 0.0798,
      "step": 45980
    },
    {
      "epoch": 0.9196896372435308,
      "grad_norm": 0.08382046967744827,
      "learning_rate": 3.4677505366022745e-05,
      "loss": 0.0728,
      "step": 45990
    },
    {
      "epoch": 0.9198896132464104,
      "grad_norm": 0.13225245475769043,
      "learning_rate": 3.4674172432641415e-05,
      "loss": 0.1066,
      "step": 46000
    },
    {
      "epoch": 0.9200895892492901,
      "grad_norm": 0.21339277923107147,
      "learning_rate": 3.467083949926009e-05,
      "loss": 0.0821,
      "step": 46010
    },
    {
      "epoch": 0.9202895652521698,
      "grad_norm": 0.0877416655421257,
      "learning_rate": 3.466750656587876e-05,
      "loss": 0.0689,
      "step": 46020
    },
    {
      "epoch": 0.9204895412550494,
      "grad_norm": 0.15399624407291412,
      "learning_rate": 3.466417363249744e-05,
      "loss": 0.2692,
      "step": 46030
    },
    {
      "epoch": 0.920689517257929,
      "grad_norm": 0.0728304535150528,
      "learning_rate": 3.466084069911611e-05,
      "loss": 0.0999,
      "step": 46040
    },
    {
      "epoch": 0.9208894932608087,
      "grad_norm": 0.07091424614191055,
      "learning_rate": 3.465750776573478e-05,
      "loss": 0.1263,
      "step": 46050
    },
    {
      "epoch": 0.9210894692636884,
      "grad_norm": 0.09131938964128494,
      "learning_rate": 3.465417483235345e-05,
      "loss": 0.0658,
      "step": 46060
    },
    {
      "epoch": 0.921289445266568,
      "grad_norm": 0.13929539918899536,
      "learning_rate": 3.465084189897212e-05,
      "loss": 0.0663,
      "step": 46070
    },
    {
      "epoch": 0.9214894212694477,
      "grad_norm": 0.1418086141347885,
      "learning_rate": 3.46475089655908e-05,
      "loss": 0.0906,
      "step": 46080
    },
    {
      "epoch": 0.9216893972723273,
      "grad_norm": 0.15116824209690094,
      "learning_rate": 3.464417603220947e-05,
      "loss": 0.1009,
      "step": 46090
    },
    {
      "epoch": 0.9218893732752069,
      "grad_norm": 0.14832478761672974,
      "learning_rate": 3.464084309882814e-05,
      "loss": 0.0651,
      "step": 46100
    },
    {
      "epoch": 0.9220893492780866,
      "grad_norm": 0.1762489527463913,
      "learning_rate": 3.4637510165446814e-05,
      "loss": 0.0837,
      "step": 46110
    },
    {
      "epoch": 0.9222893252809663,
      "grad_norm": 0.10804419964551926,
      "learning_rate": 3.4634177232065484e-05,
      "loss": 0.1041,
      "step": 46120
    },
    {
      "epoch": 0.922489301283846,
      "grad_norm": 0.14752399921417236,
      "learning_rate": 3.463084429868416e-05,
      "loss": 0.0817,
      "step": 46130
    },
    {
      "epoch": 0.9226892772867256,
      "grad_norm": 0.17569057643413544,
      "learning_rate": 3.462751136530284e-05,
      "loss": 0.1185,
      "step": 46140
    },
    {
      "epoch": 0.9228892532896052,
      "grad_norm": 0.14293883740901947,
      "learning_rate": 3.4624178431921506e-05,
      "loss": 0.0811,
      "step": 46150
    },
    {
      "epoch": 0.9230892292924849,
      "grad_norm": 0.09582694619894028,
      "learning_rate": 3.4620845498540176e-05,
      "loss": 0.0785,
      "step": 46160
    },
    {
      "epoch": 0.9232892052953645,
      "grad_norm": 0.11493083834648132,
      "learning_rate": 3.461751256515885e-05,
      "loss": 0.0667,
      "step": 46170
    },
    {
      "epoch": 0.9234891812982442,
      "grad_norm": 0.21940600872039795,
      "learning_rate": 3.461417963177752e-05,
      "loss": 0.0886,
      "step": 46180
    },
    {
      "epoch": 0.9236891573011239,
      "grad_norm": 0.18660499155521393,
      "learning_rate": 3.461084669839619e-05,
      "loss": 0.1139,
      "step": 46190
    },
    {
      "epoch": 0.9238891333040036,
      "grad_norm": 0.0919499471783638,
      "learning_rate": 3.460751376501487e-05,
      "loss": 0.0921,
      "step": 46200
    },
    {
      "epoch": 0.9240891093068831,
      "grad_norm": 0.11598192900419235,
      "learning_rate": 3.460418083163354e-05,
      "loss": 0.1016,
      "step": 46210
    },
    {
      "epoch": 0.9242890853097628,
      "grad_norm": 0.04198789969086647,
      "learning_rate": 3.460084789825221e-05,
      "loss": 0.0749,
      "step": 46220
    },
    {
      "epoch": 0.9244890613126425,
      "grad_norm": 0.11520141363143921,
      "learning_rate": 3.4597514964870884e-05,
      "loss": 0.0662,
      "step": 46230
    },
    {
      "epoch": 0.9246890373155221,
      "grad_norm": 0.09977855533361435,
      "learning_rate": 3.459418203148956e-05,
      "loss": 0.07,
      "step": 46240
    },
    {
      "epoch": 0.9248890133184018,
      "grad_norm": 0.0790594071149826,
      "learning_rate": 3.459084909810823e-05,
      "loss": 0.1112,
      "step": 46250
    },
    {
      "epoch": 0.9250889893212815,
      "grad_norm": 0.1413888782262802,
      "learning_rate": 3.45875161647269e-05,
      "loss": 0.0699,
      "step": 46260
    },
    {
      "epoch": 0.925288965324161,
      "grad_norm": 0.07633374631404877,
      "learning_rate": 3.4584183231345576e-05,
      "loss": 0.0828,
      "step": 46270
    },
    {
      "epoch": 0.9254889413270407,
      "grad_norm": 0.15364892780780792,
      "learning_rate": 3.4580850297964245e-05,
      "loss": 0.0872,
      "step": 46280
    },
    {
      "epoch": 0.9256889173299204,
      "grad_norm": 0.09394239634275436,
      "learning_rate": 3.4577517364582915e-05,
      "loss": 0.1648,
      "step": 46290
    },
    {
      "epoch": 0.9258888933328001,
      "grad_norm": 0.21023467183113098,
      "learning_rate": 3.457418443120159e-05,
      "loss": 0.0896,
      "step": 46300
    },
    {
      "epoch": 0.9260888693356797,
      "grad_norm": 0.1709432601928711,
      "learning_rate": 3.457085149782026e-05,
      "loss": 0.0984,
      "step": 46310
    },
    {
      "epoch": 0.9262888453385594,
      "grad_norm": 0.07663188129663467,
      "learning_rate": 3.456751856443893e-05,
      "loss": 0.0577,
      "step": 46320
    },
    {
      "epoch": 0.9264888213414391,
      "grad_norm": 0.09896253794431686,
      "learning_rate": 3.4564185631057614e-05,
      "loss": 0.0733,
      "step": 46330
    },
    {
      "epoch": 0.9266887973443186,
      "grad_norm": 0.17760448157787323,
      "learning_rate": 3.456085269767628e-05,
      "loss": 0.0446,
      "step": 46340
    },
    {
      "epoch": 0.9268887733471983,
      "grad_norm": 0.07071640342473984,
      "learning_rate": 3.455751976429495e-05,
      "loss": 0.0818,
      "step": 46350
    },
    {
      "epoch": 0.927088749350078,
      "grad_norm": 0.07758157700300217,
      "learning_rate": 3.455418683091363e-05,
      "loss": 0.0623,
      "step": 46360
    },
    {
      "epoch": 0.9272887253529577,
      "grad_norm": 0.04996555671095848,
      "learning_rate": 3.45508538975323e-05,
      "loss": 0.1067,
      "step": 46370
    },
    {
      "epoch": 0.9274887013558373,
      "grad_norm": 0.10034347325563431,
      "learning_rate": 3.454752096415097e-05,
      "loss": 0.0663,
      "step": 46380
    },
    {
      "epoch": 0.927688677358717,
      "grad_norm": 0.15877582132816315,
      "learning_rate": 3.4544188030769645e-05,
      "loss": 0.1099,
      "step": 46390
    },
    {
      "epoch": 0.9278886533615966,
      "grad_norm": 0.15064753592014313,
      "learning_rate": 3.4540855097388315e-05,
      "loss": 0.0685,
      "step": 46400
    },
    {
      "epoch": 0.9280886293644762,
      "grad_norm": 0.15657752752304077,
      "learning_rate": 3.4537522164006984e-05,
      "loss": 0.0881,
      "step": 46410
    },
    {
      "epoch": 0.9282886053673559,
      "grad_norm": 0.07076980918645859,
      "learning_rate": 3.453418923062566e-05,
      "loss": 0.0499,
      "step": 46420
    },
    {
      "epoch": 0.9284885813702356,
      "grad_norm": 0.12537804245948792,
      "learning_rate": 3.453085629724434e-05,
      "loss": 0.0737,
      "step": 46430
    },
    {
      "epoch": 0.9286885573731152,
      "grad_norm": 0.08083977550268173,
      "learning_rate": 3.452752336386301e-05,
      "loss": 0.0784,
      "step": 46440
    },
    {
      "epoch": 0.9288885333759949,
      "grad_norm": 0.10648935288190842,
      "learning_rate": 3.4524190430481676e-05,
      "loss": 0.0837,
      "step": 46450
    },
    {
      "epoch": 0.9290885093788745,
      "grad_norm": 0.07655118405818939,
      "learning_rate": 3.452085749710035e-05,
      "loss": 0.1034,
      "step": 46460
    },
    {
      "epoch": 0.9292884853817542,
      "grad_norm": 0.06060256436467171,
      "learning_rate": 3.451752456371902e-05,
      "loss": 0.0944,
      "step": 46470
    },
    {
      "epoch": 0.9294884613846338,
      "grad_norm": 0.11096970736980438,
      "learning_rate": 3.451419163033769e-05,
      "loss": 0.0799,
      "step": 46480
    },
    {
      "epoch": 0.9296884373875135,
      "grad_norm": 0.1070699542760849,
      "learning_rate": 3.451085869695637e-05,
      "loss": 0.0481,
      "step": 46490
    },
    {
      "epoch": 0.9298884133903932,
      "grad_norm": 0.16991497576236725,
      "learning_rate": 3.450752576357504e-05,
      "loss": 0.0973,
      "step": 46500
    },
    {
      "epoch": 0.9300883893932728,
      "grad_norm": 0.1525362730026245,
      "learning_rate": 3.450419283019371e-05,
      "loss": 0.0751,
      "step": 46510
    },
    {
      "epoch": 0.9302883653961525,
      "grad_norm": 0.21529258787631989,
      "learning_rate": 3.4500859896812384e-05,
      "loss": 0.1119,
      "step": 46520
    },
    {
      "epoch": 0.9304883413990321,
      "grad_norm": 0.11470794677734375,
      "learning_rate": 3.4497526963431054e-05,
      "loss": 0.0861,
      "step": 46530
    },
    {
      "epoch": 0.9306883174019118,
      "grad_norm": 0.17155905067920685,
      "learning_rate": 3.449419403004973e-05,
      "loss": 0.0734,
      "step": 46540
    },
    {
      "epoch": 0.9308882934047914,
      "grad_norm": 0.04545886069536209,
      "learning_rate": 3.4490861096668406e-05,
      "loss": 0.0672,
      "step": 46550
    },
    {
      "epoch": 0.9310882694076711,
      "grad_norm": 0.13320091366767883,
      "learning_rate": 3.4487528163287076e-05,
      "loss": 0.09,
      "step": 46560
    },
    {
      "epoch": 0.9312882454105508,
      "grad_norm": 0.13067439198493958,
      "learning_rate": 3.4484195229905746e-05,
      "loss": 0.0458,
      "step": 46570
    },
    {
      "epoch": 0.9314882214134304,
      "grad_norm": 0.05544788017868996,
      "learning_rate": 3.448086229652442e-05,
      "loss": 0.0769,
      "step": 46580
    },
    {
      "epoch": 0.93168819741631,
      "grad_norm": 0.19615617394447327,
      "learning_rate": 3.447752936314309e-05,
      "loss": 0.0661,
      "step": 46590
    },
    {
      "epoch": 0.9318881734191897,
      "grad_norm": 0.1990603804588318,
      "learning_rate": 3.447419642976176e-05,
      "loss": 0.0765,
      "step": 46600
    },
    {
      "epoch": 0.9320881494220693,
      "grad_norm": 0.14859721064567566,
      "learning_rate": 3.447086349638044e-05,
      "loss": 0.09,
      "step": 46610
    },
    {
      "epoch": 0.932288125424949,
      "grad_norm": 0.09464453160762787,
      "learning_rate": 3.446753056299911e-05,
      "loss": 0.0806,
      "step": 46620
    },
    {
      "epoch": 0.9324881014278287,
      "grad_norm": 0.10296287387609482,
      "learning_rate": 3.446419762961778e-05,
      "loss": 0.087,
      "step": 46630
    },
    {
      "epoch": 0.9326880774307084,
      "grad_norm": 0.17564202845096588,
      "learning_rate": 3.446086469623645e-05,
      "loss": 0.1295,
      "step": 46640
    },
    {
      "epoch": 0.9328880534335879,
      "grad_norm": 0.12085041403770447,
      "learning_rate": 3.445753176285513e-05,
      "loss": 0.051,
      "step": 46650
    },
    {
      "epoch": 0.9330880294364676,
      "grad_norm": 0.1628618985414505,
      "learning_rate": 3.44541988294738e-05,
      "loss": 0.0538,
      "step": 46660
    },
    {
      "epoch": 0.9332880054393473,
      "grad_norm": 0.10757597535848618,
      "learning_rate": 3.445086589609247e-05,
      "loss": 0.0605,
      "step": 46670
    },
    {
      "epoch": 0.9334879814422269,
      "grad_norm": 0.1313009113073349,
      "learning_rate": 3.4447532962711145e-05,
      "loss": 0.0613,
      "step": 46680
    },
    {
      "epoch": 0.9336879574451066,
      "grad_norm": 0.10337425768375397,
      "learning_rate": 3.4444200029329815e-05,
      "loss": 0.089,
      "step": 46690
    },
    {
      "epoch": 0.9338879334479863,
      "grad_norm": 0.18443936109542847,
      "learning_rate": 3.4440867095948484e-05,
      "loss": 0.0928,
      "step": 46700
    },
    {
      "epoch": 0.934087909450866,
      "grad_norm": 0.1473698765039444,
      "learning_rate": 3.443753416256716e-05,
      "loss": 0.0994,
      "step": 46710
    },
    {
      "epoch": 0.9342878854537455,
      "grad_norm": 0.08416321128606796,
      "learning_rate": 3.443420122918583e-05,
      "loss": 0.0749,
      "step": 46720
    },
    {
      "epoch": 0.9344878614566252,
      "grad_norm": 0.20580920577049255,
      "learning_rate": 3.44308682958045e-05,
      "loss": 0.0665,
      "step": 46730
    },
    {
      "epoch": 0.9346878374595049,
      "grad_norm": 0.10421104729175568,
      "learning_rate": 3.442753536242318e-05,
      "loss": 0.0708,
      "step": 46740
    },
    {
      "epoch": 0.9348878134623845,
      "grad_norm": 0.09997133910655975,
      "learning_rate": 3.442420242904185e-05,
      "loss": 0.0857,
      "step": 46750
    },
    {
      "epoch": 0.9350877894652642,
      "grad_norm": 0.11021042615175247,
      "learning_rate": 3.442086949566052e-05,
      "loss": 0.0858,
      "step": 46760
    },
    {
      "epoch": 0.9352877654681439,
      "grad_norm": 0.16991683840751648,
      "learning_rate": 3.44175365622792e-05,
      "loss": 0.0685,
      "step": 46770
    },
    {
      "epoch": 0.9354877414710234,
      "grad_norm": 0.20385389029979706,
      "learning_rate": 3.441420362889787e-05,
      "loss": 0.1019,
      "step": 46780
    },
    {
      "epoch": 0.9356877174739031,
      "grad_norm": 0.1403859555721283,
      "learning_rate": 3.441087069551654e-05,
      "loss": 0.0859,
      "step": 46790
    },
    {
      "epoch": 0.9358876934767828,
      "grad_norm": 0.13759586215019226,
      "learning_rate": 3.4407537762135214e-05,
      "loss": 0.0906,
      "step": 46800
    },
    {
      "epoch": 0.9360876694796625,
      "grad_norm": 0.1228121891617775,
      "learning_rate": 3.4404204828753884e-05,
      "loss": 0.0569,
      "step": 46810
    },
    {
      "epoch": 0.9362876454825421,
      "grad_norm": 0.11293905973434448,
      "learning_rate": 3.4400871895372554e-05,
      "loss": 0.056,
      "step": 46820
    },
    {
      "epoch": 0.9364876214854218,
      "grad_norm": 0.10967553406953812,
      "learning_rate": 3.439753896199123e-05,
      "loss": 0.2961,
      "step": 46830
    },
    {
      "epoch": 0.9366875974883014,
      "grad_norm": 0.07179907709360123,
      "learning_rate": 3.4394206028609906e-05,
      "loss": 0.0773,
      "step": 46840
    },
    {
      "epoch": 0.936887573491181,
      "grad_norm": 0.10371238738298416,
      "learning_rate": 3.4390873095228576e-05,
      "loss": 0.0693,
      "step": 46850
    },
    {
      "epoch": 0.9370875494940607,
      "grad_norm": 0.19719094038009644,
      "learning_rate": 3.4387540161847246e-05,
      "loss": 0.0769,
      "step": 46860
    },
    {
      "epoch": 0.9372875254969404,
      "grad_norm": 0.16059055924415588,
      "learning_rate": 3.438420722846592e-05,
      "loss": 0.0974,
      "step": 46870
    },
    {
      "epoch": 0.9374875014998201,
      "grad_norm": 0.17150288820266724,
      "learning_rate": 3.438087429508459e-05,
      "loss": 0.0926,
      "step": 46880
    },
    {
      "epoch": 0.9376874775026997,
      "grad_norm": 0.09758494049310684,
      "learning_rate": 3.437754136170326e-05,
      "loss": 0.0704,
      "step": 46890
    },
    {
      "epoch": 0.9378874535055793,
      "grad_norm": 0.14643031358718872,
      "learning_rate": 3.437420842832194e-05,
      "loss": 0.0712,
      "step": 46900
    },
    {
      "epoch": 0.938087429508459,
      "grad_norm": 0.19525651633739471,
      "learning_rate": 3.437087549494061e-05,
      "loss": 0.082,
      "step": 46910
    },
    {
      "epoch": 0.9382874055113386,
      "grad_norm": 0.19169779121875763,
      "learning_rate": 3.436754256155928e-05,
      "loss": 0.0863,
      "step": 46920
    },
    {
      "epoch": 0.9384873815142183,
      "grad_norm": 0.21759763360023499,
      "learning_rate": 3.436420962817795e-05,
      "loss": 0.0739,
      "step": 46930
    },
    {
      "epoch": 0.938687357517098,
      "grad_norm": 0.20965440571308136,
      "learning_rate": 3.436087669479663e-05,
      "loss": 0.0884,
      "step": 46940
    },
    {
      "epoch": 0.9388873335199776,
      "grad_norm": 0.17517848312854767,
      "learning_rate": 3.43575437614153e-05,
      "loss": 0.1128,
      "step": 46950
    },
    {
      "epoch": 0.9390873095228572,
      "grad_norm": 0.09433462470769882,
      "learning_rate": 3.4354210828033976e-05,
      "loss": 0.0697,
      "step": 46960
    },
    {
      "epoch": 0.9392872855257369,
      "grad_norm": 0.137929767370224,
      "learning_rate": 3.4350877894652645e-05,
      "loss": 0.0817,
      "step": 46970
    },
    {
      "epoch": 0.9394872615286166,
      "grad_norm": 0.07232896983623505,
      "learning_rate": 3.4347544961271315e-05,
      "loss": 0.0534,
      "step": 46980
    },
    {
      "epoch": 0.9396872375314962,
      "grad_norm": 0.06437771767377853,
      "learning_rate": 3.434421202788999e-05,
      "loss": 0.0934,
      "step": 46990
    },
    {
      "epoch": 0.9398872135343759,
      "grad_norm": 0.09264442324638367,
      "learning_rate": 3.434087909450866e-05,
      "loss": 0.0517,
      "step": 47000
    },
    {
      "epoch": 0.9400871895372556,
      "grad_norm": 0.08182136714458466,
      "learning_rate": 3.433754616112733e-05,
      "loss": 0.0597,
      "step": 47010
    },
    {
      "epoch": 0.9402871655401351,
      "grad_norm": 0.1446969211101532,
      "learning_rate": 3.433421322774601e-05,
      "loss": 0.0651,
      "step": 47020
    },
    {
      "epoch": 0.9404871415430148,
      "grad_norm": 0.11771336942911148,
      "learning_rate": 3.4330880294364677e-05,
      "loss": 0.0661,
      "step": 47030
    },
    {
      "epoch": 0.9406871175458945,
      "grad_norm": 0.09503738582134247,
      "learning_rate": 3.4327547360983346e-05,
      "loss": 0.0756,
      "step": 47040
    },
    {
      "epoch": 0.9408870935487742,
      "grad_norm": 0.1700514853000641,
      "learning_rate": 3.432421442760202e-05,
      "loss": 0.0569,
      "step": 47050
    },
    {
      "epoch": 0.9410870695516538,
      "grad_norm": 0.11332843452692032,
      "learning_rate": 3.43208814942207e-05,
      "loss": 0.0844,
      "step": 47060
    },
    {
      "epoch": 0.9412870455545335,
      "grad_norm": 0.16222797334194183,
      "learning_rate": 3.431754856083937e-05,
      "loss": 0.0799,
      "step": 47070
    },
    {
      "epoch": 0.9414870215574132,
      "grad_norm": 0.14255912601947784,
      "learning_rate": 3.431421562745804e-05,
      "loss": 0.0632,
      "step": 47080
    },
    {
      "epoch": 0.9416869975602927,
      "grad_norm": 0.0883907750248909,
      "learning_rate": 3.4310882694076715e-05,
      "loss": 0.0605,
      "step": 47090
    },
    {
      "epoch": 0.9418869735631724,
      "grad_norm": 0.12098776549100876,
      "learning_rate": 3.4307549760695384e-05,
      "loss": 0.082,
      "step": 47100
    },
    {
      "epoch": 0.9420869495660521,
      "grad_norm": 0.09798243641853333,
      "learning_rate": 3.4304216827314054e-05,
      "loss": 0.0848,
      "step": 47110
    },
    {
      "epoch": 0.9422869255689317,
      "grad_norm": 0.16051261126995087,
      "learning_rate": 3.430088389393273e-05,
      "loss": 0.0826,
      "step": 47120
    },
    {
      "epoch": 0.9424869015718114,
      "grad_norm": 0.13757286965847015,
      "learning_rate": 3.42975509605514e-05,
      "loss": 0.0636,
      "step": 47130
    },
    {
      "epoch": 0.942686877574691,
      "grad_norm": 0.06176932156085968,
      "learning_rate": 3.429421802717007e-05,
      "loss": 0.0578,
      "step": 47140
    },
    {
      "epoch": 0.9428868535775707,
      "grad_norm": 0.18970508873462677,
      "learning_rate": 3.429088509378875e-05,
      "loss": 0.0853,
      "step": 47150
    },
    {
      "epoch": 0.9430868295804503,
      "grad_norm": 0.26660043001174927,
      "learning_rate": 3.428755216040742e-05,
      "loss": 0.0947,
      "step": 47160
    },
    {
      "epoch": 0.94328680558333,
      "grad_norm": 0.19219264388084412,
      "learning_rate": 3.428421922702609e-05,
      "loss": 0.0989,
      "step": 47170
    },
    {
      "epoch": 0.9434867815862097,
      "grad_norm": 0.05225653946399689,
      "learning_rate": 3.428088629364477e-05,
      "loss": 0.0653,
      "step": 47180
    },
    {
      "epoch": 0.9436867575890893,
      "grad_norm": NaN,
      "learning_rate": 3.427755336026344e-05,
      "loss": 0.1136,
      "step": 47190
    },
    {
      "epoch": 0.943886733591969,
      "grad_norm": 0.09226610511541367,
      "learning_rate": 3.427455372022024e-05,
      "loss": 0.0676,
      "step": 47200
    },
    {
      "epoch": 0.9440867095948486,
      "grad_norm": 0.209129199385643,
      "learning_rate": 3.4271220786838916e-05,
      "loss": 0.0808,
      "step": 47210
    },
    {
      "epoch": 0.9442866855977283,
      "grad_norm": 0.14904160797595978,
      "learning_rate": 3.4267887853457586e-05,
      "loss": 0.0712,
      "step": 47220
    },
    {
      "epoch": 0.9444866616006079,
      "grad_norm": 0.17430126667022705,
      "learning_rate": 3.4264554920076255e-05,
      "loss": 0.07,
      "step": 47230
    },
    {
      "epoch": 0.9446866376034876,
      "grad_norm": 0.05975399166345596,
      "learning_rate": 3.426122198669493e-05,
      "loss": 0.0463,
      "step": 47240
    },
    {
      "epoch": 0.9448866136063673,
      "grad_norm": 0.09562848508358002,
      "learning_rate": 3.42578890533136e-05,
      "loss": 0.0914,
      "step": 47250
    },
    {
      "epoch": 0.9450865896092469,
      "grad_norm": 0.10653083771467209,
      "learning_rate": 3.425455611993227e-05,
      "loss": 0.047,
      "step": 47260
    },
    {
      "epoch": 0.9452865656121265,
      "grad_norm": 0.07622572779655457,
      "learning_rate": 3.4251223186550954e-05,
      "loss": 0.0587,
      "step": 47270
    },
    {
      "epoch": 0.9454865416150062,
      "grad_norm": 0.14455187320709229,
      "learning_rate": 3.4247890253169624e-05,
      "loss": 0.0704,
      "step": 47280
    },
    {
      "epoch": 0.9456865176178858,
      "grad_norm": 0.14799371361732483,
      "learning_rate": 3.4244557319788294e-05,
      "loss": 0.1074,
      "step": 47290
    },
    {
      "epoch": 0.9458864936207655,
      "grad_norm": 0.08508078753948212,
      "learning_rate": 3.424122438640697e-05,
      "loss": 0.0924,
      "step": 47300
    },
    {
      "epoch": 0.9460864696236452,
      "grad_norm": 0.1755995750427246,
      "learning_rate": 3.423789145302564e-05,
      "loss": 0.0725,
      "step": 47310
    },
    {
      "epoch": 0.9462864456265249,
      "grad_norm": 0.1305173933506012,
      "learning_rate": 3.423455851964431e-05,
      "loss": 0.0579,
      "step": 47320
    },
    {
      "epoch": 0.9464864216294044,
      "grad_norm": 0.08735273033380508,
      "learning_rate": 3.4231225586262986e-05,
      "loss": 0.1103,
      "step": 47330
    },
    {
      "epoch": 0.9466863976322841,
      "grad_norm": 0.19984085857868195,
      "learning_rate": 3.4227892652881655e-05,
      "loss": 0.0834,
      "step": 47340
    },
    {
      "epoch": 0.9468863736351638,
      "grad_norm": 0.16083604097366333,
      "learning_rate": 3.4224559719500325e-05,
      "loss": 0.4773,
      "step": 47350
    },
    {
      "epoch": 0.9470863496380434,
      "grad_norm": 0.1972678303718567,
      "learning_rate": 3.4221226786119e-05,
      "loss": 0.101,
      "step": 47360
    },
    {
      "epoch": 0.9472863256409231,
      "grad_norm": 0.13518144190311432,
      "learning_rate": 3.421789385273768e-05,
      "loss": 0.1251,
      "step": 47370
    },
    {
      "epoch": 0.9474863016438028,
      "grad_norm": 0.09373043477535248,
      "learning_rate": 3.421456091935635e-05,
      "loss": 0.09,
      "step": 47380
    },
    {
      "epoch": 0.9476862776466825,
      "grad_norm": 0.13122379779815674,
      "learning_rate": 3.421122798597502e-05,
      "loss": 0.0746,
      "step": 47390
    },
    {
      "epoch": 0.947886253649562,
      "grad_norm": 0.07382386177778244,
      "learning_rate": 3.420789505259369e-05,
      "loss": 0.0767,
      "step": 47400
    },
    {
      "epoch": 0.9480862296524417,
      "grad_norm": 0.10269074887037277,
      "learning_rate": 3.420456211921236e-05,
      "loss": 0.0641,
      "step": 47410
    },
    {
      "epoch": 0.9482862056553214,
      "grad_norm": 0.054234135895967484,
      "learning_rate": 3.420122918583103e-05,
      "loss": 0.062,
      "step": 47420
    },
    {
      "epoch": 0.948486181658201,
      "grad_norm": 0.15144434571266174,
      "learning_rate": 3.419789625244971e-05,
      "loss": 0.0647,
      "step": 47430
    },
    {
      "epoch": 0.9486861576610807,
      "grad_norm": 0.17859400808811188,
      "learning_rate": 3.419456331906838e-05,
      "loss": 0.0548,
      "step": 47440
    },
    {
      "epoch": 0.9488861336639604,
      "grad_norm": 0.19877909123897552,
      "learning_rate": 3.419123038568705e-05,
      "loss": 0.1218,
      "step": 47450
    },
    {
      "epoch": 0.9490861096668399,
      "grad_norm": 0.13784076273441315,
      "learning_rate": 3.4187897452305724e-05,
      "loss": 0.0667,
      "step": 47460
    },
    {
      "epoch": 0.9492860856697196,
      "grad_norm": 0.1532755196094513,
      "learning_rate": 3.41845645189244e-05,
      "loss": 0.1079,
      "step": 47470
    },
    {
      "epoch": 0.9494860616725993,
      "grad_norm": 0.1270875334739685,
      "learning_rate": 3.418123158554307e-05,
      "loss": 0.0951,
      "step": 47480
    },
    {
      "epoch": 0.949686037675479,
      "grad_norm": 0.09830094128847122,
      "learning_rate": 3.417789865216175e-05,
      "loss": 0.1683,
      "step": 47490
    },
    {
      "epoch": 0.9498860136783586,
      "grad_norm": 0.16887983679771423,
      "learning_rate": 3.4174565718780416e-05,
      "loss": 0.0704,
      "step": 47500
    },
    {
      "epoch": 0.9500859896812383,
      "grad_norm": 0.18244333565235138,
      "learning_rate": 3.4171232785399086e-05,
      "loss": 0.0884,
      "step": 47510
    },
    {
      "epoch": 0.9502859656841179,
      "grad_norm": 0.11593251675367355,
      "learning_rate": 3.416789985201776e-05,
      "loss": 0.0721,
      "step": 47520
    },
    {
      "epoch": 0.9504859416869975,
      "grad_norm": 0.13439123332500458,
      "learning_rate": 3.416456691863643e-05,
      "loss": 0.3157,
      "step": 47530
    },
    {
      "epoch": 0.9506859176898772,
      "grad_norm": 0.06327460706233978,
      "learning_rate": 3.41612339852551e-05,
      "loss": 0.0952,
      "step": 47540
    },
    {
      "epoch": 0.9508858936927569,
      "grad_norm": 0.11895344406366348,
      "learning_rate": 3.415790105187378e-05,
      "loss": 0.1041,
      "step": 47550
    },
    {
      "epoch": 0.9510858696956366,
      "grad_norm": 0.15775981545448303,
      "learning_rate": 3.415456811849245e-05,
      "loss": 0.0863,
      "step": 47560
    },
    {
      "epoch": 0.9512858456985162,
      "grad_norm": 0.13314077258110046,
      "learning_rate": 3.415123518511112e-05,
      "loss": 0.0483,
      "step": 47570
    },
    {
      "epoch": 0.9514858217013958,
      "grad_norm": 0.19368262588977814,
      "learning_rate": 3.4147902251729794e-05,
      "loss": 0.0759,
      "step": 47580
    },
    {
      "epoch": 0.9516857977042755,
      "grad_norm": 0.08452688157558441,
      "learning_rate": 3.414456931834847e-05,
      "loss": 0.0727,
      "step": 47590
    },
    {
      "epoch": 0.9518857737071551,
      "grad_norm": 0.07770061492919922,
      "learning_rate": 3.414123638496714e-05,
      "loss": 0.0774,
      "step": 47600
    },
    {
      "epoch": 0.9520857497100348,
      "grad_norm": 0.12410901486873627,
      "learning_rate": 3.413790345158581e-05,
      "loss": 0.1185,
      "step": 47610
    },
    {
      "epoch": 0.9522857257129145,
      "grad_norm": 0.1272163689136505,
      "learning_rate": 3.4134570518204486e-05,
      "loss": 0.0826,
      "step": 47620
    },
    {
      "epoch": 0.952485701715794,
      "grad_norm": 0.06745609641075134,
      "learning_rate": 3.4131237584823155e-05,
      "loss": 0.0785,
      "step": 47630
    },
    {
      "epoch": 0.9526856777186737,
      "grad_norm": 0.16179358959197998,
      "learning_rate": 3.4127904651441825e-05,
      "loss": 0.0866,
      "step": 47640
    },
    {
      "epoch": 0.9528856537215534,
      "grad_norm": 0.0703030452132225,
      "learning_rate": 3.41245717180605e-05,
      "loss": 0.0588,
      "step": 47650
    },
    {
      "epoch": 0.9530856297244331,
      "grad_norm": 0.07013051956892014,
      "learning_rate": 3.412123878467917e-05,
      "loss": 0.0659,
      "step": 47660
    },
    {
      "epoch": 0.9532856057273127,
      "grad_norm": 0.1579739898443222,
      "learning_rate": 3.411790585129784e-05,
      "loss": 0.0727,
      "step": 47670
    },
    {
      "epoch": 0.9534855817301924,
      "grad_norm": 0.22125586867332458,
      "learning_rate": 3.4114572917916524e-05,
      "loss": 0.1088,
      "step": 47680
    },
    {
      "epoch": 0.9536855577330721,
      "grad_norm": 0.06339743733406067,
      "learning_rate": 3.411123998453519e-05,
      "loss": 0.0895,
      "step": 47690
    },
    {
      "epoch": 0.9538855337359516,
      "grad_norm": 0.11240168660879135,
      "learning_rate": 3.410790705115386e-05,
      "loss": 0.0937,
      "step": 47700
    },
    {
      "epoch": 0.9540855097388313,
      "grad_norm": 0.093356192111969,
      "learning_rate": 3.410457411777254e-05,
      "loss": 0.0873,
      "step": 47710
    },
    {
      "epoch": 0.954285485741711,
      "grad_norm": 0.15593156218528748,
      "learning_rate": 3.410124118439121e-05,
      "loss": 0.098,
      "step": 47720
    },
    {
      "epoch": 0.9544854617445907,
      "grad_norm": 0.14904087781906128,
      "learning_rate": 3.409790825100988e-05,
      "loss": 0.0826,
      "step": 47730
    },
    {
      "epoch": 0.9546854377474703,
      "grad_norm": 0.07679382711648941,
      "learning_rate": 3.4094575317628555e-05,
      "loss": 0.0624,
      "step": 47740
    },
    {
      "epoch": 0.95488541375035,
      "grad_norm": 0.08653489500284195,
      "learning_rate": 3.4091242384247225e-05,
      "loss": 0.0604,
      "step": 47750
    },
    {
      "epoch": 0.9550853897532297,
      "grad_norm": 0.07345987856388092,
      "learning_rate": 3.4087909450865894e-05,
      "loss": 0.0549,
      "step": 47760
    },
    {
      "epoch": 0.9552853657561092,
      "grad_norm": 0.08717431873083115,
      "learning_rate": 3.408457651748457e-05,
      "loss": 0.0653,
      "step": 47770
    },
    {
      "epoch": 0.9554853417589889,
      "grad_norm": 0.07399594038724899,
      "learning_rate": 3.408124358410325e-05,
      "loss": 0.0822,
      "step": 47780
    },
    {
      "epoch": 0.9556853177618686,
      "grad_norm": 0.13267187774181366,
      "learning_rate": 3.4077910650721917e-05,
      "loss": 0.0882,
      "step": 47790
    },
    {
      "epoch": 0.9558852937647482,
      "grad_norm": 0.06941388547420502,
      "learning_rate": 3.4074577717340586e-05,
      "loss": 0.0707,
      "step": 47800
    },
    {
      "epoch": 0.9560852697676279,
      "grad_norm": 0.0947006493806839,
      "learning_rate": 3.407124478395926e-05,
      "loss": 0.1486,
      "step": 47810
    },
    {
      "epoch": 0.9562852457705076,
      "grad_norm": 0.07305184006690979,
      "learning_rate": 3.406791185057793e-05,
      "loss": 0.0859,
      "step": 47820
    },
    {
      "epoch": 0.9564852217733872,
      "grad_norm": 0.11321109533309937,
      "learning_rate": 3.40645789171966e-05,
      "loss": 0.2095,
      "step": 47830
    },
    {
      "epoch": 0.9566851977762668,
      "grad_norm": 0.09232491254806519,
      "learning_rate": 3.406124598381528e-05,
      "loss": 0.0864,
      "step": 47840
    },
    {
      "epoch": 0.9568851737791465,
      "grad_norm": 0.19234086573123932,
      "learning_rate": 3.405791305043395e-05,
      "loss": 0.0951,
      "step": 47850
    },
    {
      "epoch": 0.9570851497820262,
      "grad_norm": 0.18613293766975403,
      "learning_rate": 3.405458011705262e-05,
      "loss": 0.1204,
      "step": 47860
    },
    {
      "epoch": 0.9572851257849058,
      "grad_norm": 0.10969017446041107,
      "learning_rate": 3.4051247183671294e-05,
      "loss": 0.0731,
      "step": 47870
    },
    {
      "epoch": 0.9574851017877855,
      "grad_norm": 0.20492850244045258,
      "learning_rate": 3.404791425028997e-05,
      "loss": 0.0836,
      "step": 47880
    },
    {
      "epoch": 0.9576850777906651,
      "grad_norm": 0.15924131870269775,
      "learning_rate": 3.404458131690864e-05,
      "loss": 0.1108,
      "step": 47890
    },
    {
      "epoch": 0.9578850537935448,
      "grad_norm": 0.0696040689945221,
      "learning_rate": 3.4041248383527316e-05,
      "loss": 0.0625,
      "step": 47900
    },
    {
      "epoch": 0.9580850297964244,
      "grad_norm": 0.10223051905632019,
      "learning_rate": 3.4037915450145986e-05,
      "loss": 0.0892,
      "step": 47910
    },
    {
      "epoch": 0.9582850057993041,
      "grad_norm": 0.11381743103265762,
      "learning_rate": 3.4034582516764655e-05,
      "loss": 0.0673,
      "step": 47920
    },
    {
      "epoch": 0.9584849818021838,
      "grad_norm": 0.16295823454856873,
      "learning_rate": 3.403124958338333e-05,
      "loss": 0.0852,
      "step": 47930
    },
    {
      "epoch": 0.9586849578050634,
      "grad_norm": 0.07697903364896774,
      "learning_rate": 3.4027916650002e-05,
      "loss": 0.0825,
      "step": 47940
    },
    {
      "epoch": 0.958884933807943,
      "grad_norm": 0.1796860545873642,
      "learning_rate": 3.402458371662067e-05,
      "loss": 0.0856,
      "step": 47950
    },
    {
      "epoch": 0.9590849098108227,
      "grad_norm": 0.173879012465477,
      "learning_rate": 3.402125078323935e-05,
      "loss": 0.0992,
      "step": 47960
    },
    {
      "epoch": 0.9592848858137023,
      "grad_norm": 0.1305534690618515,
      "learning_rate": 3.401791784985802e-05,
      "loss": 0.0613,
      "step": 47970
    },
    {
      "epoch": 0.959484861816582,
      "grad_norm": 0.07711683958768845,
      "learning_rate": 3.401458491647669e-05,
      "loss": 0.132,
      "step": 47980
    },
    {
      "epoch": 0.9596848378194617,
      "grad_norm": 0.19453933835029602,
      "learning_rate": 3.401125198309536e-05,
      "loss": 0.0837,
      "step": 47990
    },
    {
      "epoch": 0.9598848138223414,
      "grad_norm": 0.12385307997465134,
      "learning_rate": 3.400791904971404e-05,
      "loss": 0.0638,
      "step": 48000
    },
    {
      "epoch": 0.9600847898252209,
      "grad_norm": 0.08982027322053909,
      "learning_rate": 3.400458611633271e-05,
      "loss": 0.0564,
      "step": 48010
    },
    {
      "epoch": 0.9602847658281006,
      "grad_norm": 0.054303720593452454,
      "learning_rate": 3.400125318295138e-05,
      "loss": 0.0665,
      "step": 48020
    },
    {
      "epoch": 0.9604847418309803,
      "grad_norm": 0.16191993653774261,
      "learning_rate": 3.3997920249570055e-05,
      "loss": 0.0871,
      "step": 48030
    },
    {
      "epoch": 0.9606847178338599,
      "grad_norm": 0.17865002155303955,
      "learning_rate": 3.3994587316188725e-05,
      "loss": 0.0892,
      "step": 48040
    },
    {
      "epoch": 0.9608846938367396,
      "grad_norm": 0.20242449641227722,
      "learning_rate": 3.3991254382807394e-05,
      "loss": 0.1001,
      "step": 48050
    },
    {
      "epoch": 0.9610846698396193,
      "grad_norm": 0.1162736564874649,
      "learning_rate": 3.398792144942607e-05,
      "loss": 0.06,
      "step": 48060
    },
    {
      "epoch": 0.961284645842499,
      "grad_norm": 0.17823177576065063,
      "learning_rate": 3.398458851604474e-05,
      "loss": 0.0932,
      "step": 48070
    },
    {
      "epoch": 0.9614846218453785,
      "grad_norm": 0.06421779841184616,
      "learning_rate": 3.398125558266341e-05,
      "loss": 0.0626,
      "step": 48080
    },
    {
      "epoch": 0.9616845978482582,
      "grad_norm": 0.06467930972576141,
      "learning_rate": 3.397792264928209e-05,
      "loss": 0.0498,
      "step": 48090
    },
    {
      "epoch": 0.9618845738511379,
      "grad_norm": 0.04920282959938049,
      "learning_rate": 3.397458971590076e-05,
      "loss": 0.0881,
      "step": 48100
    },
    {
      "epoch": 0.9620845498540175,
      "grad_norm": 0.10993270576000214,
      "learning_rate": 3.397125678251943e-05,
      "loss": 0.0646,
      "step": 48110
    },
    {
      "epoch": 0.9622845258568972,
      "grad_norm": 0.08520006388425827,
      "learning_rate": 3.396792384913811e-05,
      "loss": 0.069,
      "step": 48120
    },
    {
      "epoch": 0.9624845018597769,
      "grad_norm": 0.17715011537075043,
      "learning_rate": 3.396459091575678e-05,
      "loss": 0.071,
      "step": 48130
    },
    {
      "epoch": 0.9626844778626564,
      "grad_norm": 0.09890824556350708,
      "learning_rate": 3.396125798237545e-05,
      "loss": 0.0821,
      "step": 48140
    },
    {
      "epoch": 0.9628844538655361,
      "grad_norm": 0.06427587568759918,
      "learning_rate": 3.3957925048994124e-05,
      "loss": 0.0931,
      "step": 48150
    },
    {
      "epoch": 0.9630844298684158,
      "grad_norm": 0.14363978803157806,
      "learning_rate": 3.3954592115612794e-05,
      "loss": 0.0565,
      "step": 48160
    },
    {
      "epoch": 0.9632844058712955,
      "grad_norm": 0.0759182795882225,
      "learning_rate": 3.3951259182231464e-05,
      "loss": 0.0397,
      "step": 48170
    },
    {
      "epoch": 0.9634843818741751,
      "grad_norm": 0.18772809207439423,
      "learning_rate": 3.394792624885014e-05,
      "loss": 0.0763,
      "step": 48180
    },
    {
      "epoch": 0.9636843578770548,
      "grad_norm": 0.11624079197645187,
      "learning_rate": 3.3944593315468816e-05,
      "loss": 0.0492,
      "step": 48190
    },
    {
      "epoch": 0.9638843338799344,
      "grad_norm": 0.2259995937347412,
      "learning_rate": 3.3941260382087486e-05,
      "loss": 0.0926,
      "step": 48200
    },
    {
      "epoch": 0.964084309882814,
      "grad_norm": 0.2858729958534241,
      "learning_rate": 3.3937927448706156e-05,
      "loss": 0.0883,
      "step": 48210
    },
    {
      "epoch": 0.9642842858856937,
      "grad_norm": 0.08333833515644073,
      "learning_rate": 3.393459451532483e-05,
      "loss": 0.0871,
      "step": 48220
    },
    {
      "epoch": 0.9644842618885734,
      "grad_norm": 0.17735697329044342,
      "learning_rate": 3.39312615819435e-05,
      "loss": 0.0931,
      "step": 48230
    },
    {
      "epoch": 0.9646842378914531,
      "grad_norm": 0.1589004099369049,
      "learning_rate": 3.392792864856217e-05,
      "loss": 0.0592,
      "step": 48240
    },
    {
      "epoch": 0.9648842138943327,
      "grad_norm": 0.09013460576534271,
      "learning_rate": 3.392459571518085e-05,
      "loss": 0.0509,
      "step": 48250
    },
    {
      "epoch": 0.9650841898972123,
      "grad_norm": 0.0856122374534607,
      "learning_rate": 3.392126278179952e-05,
      "loss": 0.0681,
      "step": 48260
    },
    {
      "epoch": 0.965284165900092,
      "grad_norm": 0.17512555420398712,
      "learning_rate": 3.391792984841819e-05,
      "loss": 0.0656,
      "step": 48270
    },
    {
      "epoch": 0.9654841419029716,
      "grad_norm": 0.09088452160358429,
      "learning_rate": 3.391459691503686e-05,
      "loss": 0.1149,
      "step": 48280
    },
    {
      "epoch": 0.9656841179058513,
      "grad_norm": 0.12692378461360931,
      "learning_rate": 3.391126398165554e-05,
      "loss": 0.1025,
      "step": 48290
    },
    {
      "epoch": 0.965884093908731,
      "grad_norm": 0.08415637165307999,
      "learning_rate": 3.390793104827421e-05,
      "loss": 0.0599,
      "step": 48300
    },
    {
      "epoch": 0.9660840699116106,
      "grad_norm": 0.16865316033363342,
      "learning_rate": 3.3904598114892886e-05,
      "loss": 0.0913,
      "step": 48310
    },
    {
      "epoch": 0.9662840459144902,
      "grad_norm": 0.18143610656261444,
      "learning_rate": 3.3901265181511555e-05,
      "loss": 0.0758,
      "step": 48320
    },
    {
      "epoch": 0.9664840219173699,
      "grad_norm": 0.20221038162708282,
      "learning_rate": 3.3897932248130225e-05,
      "loss": 0.1127,
      "step": 48330
    },
    {
      "epoch": 0.9666839979202496,
      "grad_norm": 0.2108195424079895,
      "learning_rate": 3.38945993147489e-05,
      "loss": 0.1314,
      "step": 48340
    },
    {
      "epoch": 0.9668839739231292,
      "grad_norm": 0.07532958686351776,
      "learning_rate": 3.389126638136757e-05,
      "loss": 0.0634,
      "step": 48350
    },
    {
      "epoch": 0.9670839499260089,
      "grad_norm": 0.15837697684764862,
      "learning_rate": 3.388793344798624e-05,
      "loss": 0.0766,
      "step": 48360
    },
    {
      "epoch": 0.9672839259288886,
      "grad_norm": 0.19119401276111603,
      "learning_rate": 3.388460051460492e-05,
      "loss": 0.0864,
      "step": 48370
    },
    {
      "epoch": 0.9674839019317681,
      "grad_norm": 0.1835213601589203,
      "learning_rate": 3.3881267581223587e-05,
      "loss": 0.0909,
      "step": 48380
    },
    {
      "epoch": 0.9676838779346478,
      "grad_norm": 0.09970840811729431,
      "learning_rate": 3.387793464784226e-05,
      "loss": 0.0651,
      "step": 48390
    },
    {
      "epoch": 0.9678838539375275,
      "grad_norm": 0.07046288251876831,
      "learning_rate": 3.387460171446093e-05,
      "loss": 0.0522,
      "step": 48400
    },
    {
      "epoch": 0.9680838299404072,
      "grad_norm": 0.2137610912322998,
      "learning_rate": 3.387126878107961e-05,
      "loss": 0.0622,
      "step": 48410
    },
    {
      "epoch": 0.9682838059432868,
      "grad_norm": 0.07544286549091339,
      "learning_rate": 3.386793584769828e-05,
      "loss": 0.065,
      "step": 48420
    },
    {
      "epoch": 0.9684837819461665,
      "grad_norm": 0.14965800940990448,
      "learning_rate": 3.386460291431695e-05,
      "loss": 0.0832,
      "step": 48430
    },
    {
      "epoch": 0.9686837579490462,
      "grad_norm": 0.17452366650104523,
      "learning_rate": 3.3861269980935625e-05,
      "loss": 0.0943,
      "step": 48440
    },
    {
      "epoch": 0.9688837339519257,
      "grad_norm": 0.1676265299320221,
      "learning_rate": 3.3857937047554294e-05,
      "loss": 0.0764,
      "step": 48450
    },
    {
      "epoch": 0.9690837099548054,
      "grad_norm": 0.05844580754637718,
      "learning_rate": 3.3854604114172964e-05,
      "loss": 0.0707,
      "step": 48460
    },
    {
      "epoch": 0.9692836859576851,
      "grad_norm": 0.13244511187076569,
      "learning_rate": 3.385127118079164e-05,
      "loss": 0.0482,
      "step": 48470
    },
    {
      "epoch": 0.9694836619605647,
      "grad_norm": 0.041353289037942886,
      "learning_rate": 3.384793824741031e-05,
      "loss": 0.074,
      "step": 48480
    },
    {
      "epoch": 0.9696836379634444,
      "grad_norm": 0.054694220423698425,
      "learning_rate": 3.384460531402898e-05,
      "loss": 0.0659,
      "step": 48490
    },
    {
      "epoch": 0.969883613966324,
      "grad_norm": 0.19224177300930023,
      "learning_rate": 3.384127238064766e-05,
      "loss": 0.2321,
      "step": 48500
    },
    {
      "epoch": 0.9700835899692037,
      "grad_norm": 0.10115090012550354,
      "learning_rate": 3.383793944726633e-05,
      "loss": 0.0871,
      "step": 48510
    },
    {
      "epoch": 0.9702835659720833,
      "grad_norm": 0.07129162549972534,
      "learning_rate": 3.3834606513885e-05,
      "loss": 0.0926,
      "step": 48520
    },
    {
      "epoch": 0.970483541974963,
      "grad_norm": 0.07840511947870255,
      "learning_rate": 3.383127358050368e-05,
      "loss": 0.0441,
      "step": 48530
    },
    {
      "epoch": 0.9706835179778427,
      "grad_norm": 0.20960146188735962,
      "learning_rate": 3.382794064712235e-05,
      "loss": 0.102,
      "step": 48540
    },
    {
      "epoch": 0.9708834939807223,
      "grad_norm": 0.20220130681991577,
      "learning_rate": 3.382460771374102e-05,
      "loss": 0.1028,
      "step": 48550
    },
    {
      "epoch": 0.971083469983602,
      "grad_norm": 0.0753219872713089,
      "learning_rate": 3.3821274780359694e-05,
      "loss": 0.0613,
      "step": 48560
    },
    {
      "epoch": 0.9712834459864816,
      "grad_norm": 0.0805027112364769,
      "learning_rate": 3.3817941846978363e-05,
      "loss": 0.0669,
      "step": 48570
    },
    {
      "epoch": 0.9714834219893613,
      "grad_norm": 0.19544295966625214,
      "learning_rate": 3.381460891359703e-05,
      "loss": 0.0816,
      "step": 48580
    },
    {
      "epoch": 0.9716833979922409,
      "grad_norm": 0.1410561054944992,
      "learning_rate": 3.381127598021571e-05,
      "loss": 0.0772,
      "step": 48590
    },
    {
      "epoch": 0.9718833739951206,
      "grad_norm": 0.15573404729366302,
      "learning_rate": 3.3807943046834386e-05,
      "loss": 0.1029,
      "step": 48600
    },
    {
      "epoch": 0.9720833499980003,
      "grad_norm": 0.14411817491054535,
      "learning_rate": 3.3804610113453056e-05,
      "loss": 0.1103,
      "step": 48610
    },
    {
      "epoch": 0.9722833260008799,
      "grad_norm": 0.18123210966587067,
      "learning_rate": 3.3801277180071725e-05,
      "loss": 0.0713,
      "step": 48620
    },
    {
      "epoch": 0.9724833020037595,
      "grad_norm": 0.16953957080841064,
      "learning_rate": 3.37979442466904e-05,
      "loss": 0.0904,
      "step": 48630
    },
    {
      "epoch": 0.9726832780066392,
      "grad_norm": 0.24365845322608948,
      "learning_rate": 3.379461131330907e-05,
      "loss": 0.089,
      "step": 48640
    },
    {
      "epoch": 0.9728832540095188,
      "grad_norm": 0.12243101745843887,
      "learning_rate": 3.379127837992774e-05,
      "loss": 0.0854,
      "step": 48650
    },
    {
      "epoch": 0.9730832300123985,
      "grad_norm": 0.14899611473083496,
      "learning_rate": 3.378794544654642e-05,
      "loss": 0.0977,
      "step": 48660
    },
    {
      "epoch": 0.9732832060152782,
      "grad_norm": 0.10937732458114624,
      "learning_rate": 3.378461251316509e-05,
      "loss": 0.0606,
      "step": 48670
    },
    {
      "epoch": 0.9734831820181579,
      "grad_norm": 0.10051671415567398,
      "learning_rate": 3.3781279579783756e-05,
      "loss": 0.0798,
      "step": 48680
    },
    {
      "epoch": 0.9736831580210374,
      "grad_norm": 0.18487872183322906,
      "learning_rate": 3.377794664640243e-05,
      "loss": 0.0882,
      "step": 48690
    },
    {
      "epoch": 0.9738831340239171,
      "grad_norm": 0.2138996124267578,
      "learning_rate": 3.377461371302111e-05,
      "loss": 0.0694,
      "step": 48700
    },
    {
      "epoch": 0.9740831100267968,
      "grad_norm": 0.13044202327728271,
      "learning_rate": 3.377128077963978e-05,
      "loss": 0.0703,
      "step": 48710
    },
    {
      "epoch": 0.9742830860296764,
      "grad_norm": 0.08222033083438873,
      "learning_rate": 3.3767947846258455e-05,
      "loss": 0.0749,
      "step": 48720
    },
    {
      "epoch": 0.9744830620325561,
      "grad_norm": 0.10081510245800018,
      "learning_rate": 3.3764614912877125e-05,
      "loss": 0.0816,
      "step": 48730
    },
    {
      "epoch": 0.9746830380354358,
      "grad_norm": 0.1720055490732193,
      "learning_rate": 3.3761281979495794e-05,
      "loss": 0.0842,
      "step": 48740
    },
    {
      "epoch": 0.9748830140383155,
      "grad_norm": 0.16851410269737244,
      "learning_rate": 3.375794904611447e-05,
      "loss": 0.0707,
      "step": 48750
    },
    {
      "epoch": 0.975082990041195,
      "grad_norm": 0.16249971091747284,
      "learning_rate": 3.375461611273314e-05,
      "loss": 0.0677,
      "step": 48760
    },
    {
      "epoch": 0.9752829660440747,
      "grad_norm": 0.10884346812963486,
      "learning_rate": 3.375128317935181e-05,
      "loss": 0.0556,
      "step": 48770
    },
    {
      "epoch": 0.9754829420469544,
      "grad_norm": 0.12814059853553772,
      "learning_rate": 3.3747950245970486e-05,
      "loss": 0.0787,
      "step": 48780
    },
    {
      "epoch": 0.975682918049834,
      "grad_norm": 0.09591236710548401,
      "learning_rate": 3.3744617312589156e-05,
      "loss": 0.0754,
      "step": 48790
    },
    {
      "epoch": 0.9758828940527137,
      "grad_norm": 0.14911450445652008,
      "learning_rate": 3.374128437920783e-05,
      "loss": 0.0719,
      "step": 48800
    },
    {
      "epoch": 0.9760828700555934,
      "grad_norm": 0.1510946899652481,
      "learning_rate": 3.37379514458265e-05,
      "loss": 0.0864,
      "step": 48810
    },
    {
      "epoch": 0.9762828460584729,
      "grad_norm": 0.12594571709632874,
      "learning_rate": 3.373461851244518e-05,
      "loss": 0.102,
      "step": 48820
    },
    {
      "epoch": 0.9764828220613526,
      "grad_norm": 0.06657001376152039,
      "learning_rate": 3.373128557906385e-05,
      "loss": 0.0738,
      "step": 48830
    },
    {
      "epoch": 0.9766827980642323,
      "grad_norm": 0.08796746283769608,
      "learning_rate": 3.372795264568252e-05,
      "loss": 0.0822,
      "step": 48840
    },
    {
      "epoch": 0.976882774067112,
      "grad_norm": 0.176019087433815,
      "learning_rate": 3.3724619712301194e-05,
      "loss": 0.0636,
      "step": 48850
    },
    {
      "epoch": 0.9770827500699916,
      "grad_norm": 0.153669074177742,
      "learning_rate": 3.3721286778919864e-05,
      "loss": 0.0825,
      "step": 48860
    },
    {
      "epoch": 0.9772827260728713,
      "grad_norm": 0.08770550042390823,
      "learning_rate": 3.371795384553853e-05,
      "loss": 0.076,
      "step": 48870
    },
    {
      "epoch": 0.9774827020757509,
      "grad_norm": 0.13204790651798248,
      "learning_rate": 3.371462091215721e-05,
      "loss": 0.0751,
      "step": 48880
    },
    {
      "epoch": 0.9776826780786305,
      "grad_norm": 0.0873103141784668,
      "learning_rate": 3.371128797877588e-05,
      "loss": 0.061,
      "step": 48890
    },
    {
      "epoch": 0.9778826540815102,
      "grad_norm": 0.2425214946269989,
      "learning_rate": 3.3707955045394556e-05,
      "loss": 0.1183,
      "step": 48900
    },
    {
      "epoch": 0.9780826300843899,
      "grad_norm": 0.06673914194107056,
      "learning_rate": 3.370462211201323e-05,
      "loss": 0.0688,
      "step": 48910
    },
    {
      "epoch": 0.9782826060872696,
      "grad_norm": 0.15433776378631592,
      "learning_rate": 3.37012891786319e-05,
      "loss": 0.0684,
      "step": 48920
    },
    {
      "epoch": 0.9784825820901492,
      "grad_norm": 0.06728235632181168,
      "learning_rate": 3.369795624525057e-05,
      "loss": 0.0459,
      "step": 48930
    },
    {
      "epoch": 0.9786825580930288,
      "grad_norm": 0.13531117141246796,
      "learning_rate": 3.369462331186925e-05,
      "loss": 0.0969,
      "step": 48940
    },
    {
      "epoch": 0.9788825340959085,
      "grad_norm": 0.14425846934318542,
      "learning_rate": 3.369129037848792e-05,
      "loss": 0.0477,
      "step": 48950
    },
    {
      "epoch": 0.9790825100987881,
      "grad_norm": 0.1288420408964157,
      "learning_rate": 3.368795744510659e-05,
      "loss": 0.1581,
      "step": 48960
    },
    {
      "epoch": 0.9792824861016678,
      "grad_norm": 0.1804012805223465,
      "learning_rate": 3.368462451172526e-05,
      "loss": 0.0642,
      "step": 48970
    },
    {
      "epoch": 0.9794824621045475,
      "grad_norm": 0.05978420004248619,
      "learning_rate": 3.368129157834393e-05,
      "loss": 0.0588,
      "step": 48980
    },
    {
      "epoch": 0.9796824381074271,
      "grad_norm": 0.07403872162103653,
      "learning_rate": 3.36779586449626e-05,
      "loss": 0.0858,
      "step": 48990
    },
    {
      "epoch": 0.9798824141103067,
      "grad_norm": 0.12497975677251816,
      "learning_rate": 3.367462571158128e-05,
      "loss": 0.0911,
      "step": 49000
    },
    {
      "epoch": 0.9800823901131864,
      "grad_norm": 0.09320150315761566,
      "learning_rate": 3.3671292778199955e-05,
      "loss": 0.0594,
      "step": 49010
    },
    {
      "epoch": 0.9802823661160661,
      "grad_norm": 0.10716328024864197,
      "learning_rate": 3.3667959844818625e-05,
      "loss": 0.1082,
      "step": 49020
    },
    {
      "epoch": 0.9804823421189457,
      "grad_norm": 0.23617441952228546,
      "learning_rate": 3.3664626911437295e-05,
      "loss": 0.0709,
      "step": 49030
    },
    {
      "epoch": 0.9806823181218254,
      "grad_norm": 0.20427563786506653,
      "learning_rate": 3.366129397805597e-05,
      "loss": 0.0525,
      "step": 49040
    },
    {
      "epoch": 0.9808822941247051,
      "grad_norm": 0.14593230187892914,
      "learning_rate": 3.365796104467464e-05,
      "loss": 0.079,
      "step": 49050
    },
    {
      "epoch": 0.9810822701275846,
      "grad_norm": 0.10735847055912018,
      "learning_rate": 3.365462811129331e-05,
      "loss": 0.0777,
      "step": 49060
    },
    {
      "epoch": 0.9812822461304643,
      "grad_norm": 0.12338476628065109,
      "learning_rate": 3.3651295177911987e-05,
      "loss": 0.0959,
      "step": 49070
    },
    {
      "epoch": 0.981482222133344,
      "grad_norm": 0.11664462089538574,
      "learning_rate": 3.3647962244530656e-05,
      "loss": 0.0437,
      "step": 49080
    },
    {
      "epoch": 0.9816821981362237,
      "grad_norm": 0.06325583904981613,
      "learning_rate": 3.3644629311149326e-05,
      "loss": 0.0444,
      "step": 49090
    },
    {
      "epoch": 0.9818821741391033,
      "grad_norm": 0.09200823307037354,
      "learning_rate": 3.3641296377768e-05,
      "loss": 0.0671,
      "step": 49100
    },
    {
      "epoch": 0.982082150141983,
      "grad_norm": 0.1339455097913742,
      "learning_rate": 3.363796344438668e-05,
      "loss": 0.077,
      "step": 49110
    },
    {
      "epoch": 0.9822821261448627,
      "grad_norm": 0.05068355053663254,
      "learning_rate": 3.363463051100535e-05,
      "loss": 0.0876,
      "step": 49120
    },
    {
      "epoch": 0.9824821021477422,
      "grad_norm": 0.12666760385036469,
      "learning_rate": 3.3631297577624025e-05,
      "loss": 0.0729,
      "step": 49130
    },
    {
      "epoch": 0.9826820781506219,
      "grad_norm": 0.20926061272621155,
      "learning_rate": 3.3627964644242694e-05,
      "loss": 0.077,
      "step": 49140
    },
    {
      "epoch": 0.9828820541535016,
      "grad_norm": 0.17227116227149963,
      "learning_rate": 3.3624631710861364e-05,
      "loss": 0.099,
      "step": 49150
    },
    {
      "epoch": 0.9830820301563812,
      "grad_norm": 0.09821979701519012,
      "learning_rate": 3.362129877748004e-05,
      "loss": 0.0807,
      "step": 49160
    },
    {
      "epoch": 0.9832820061592609,
      "grad_norm": 0.10997471213340759,
      "learning_rate": 3.361796584409871e-05,
      "loss": 0.0951,
      "step": 49170
    },
    {
      "epoch": 0.9834819821621406,
      "grad_norm": 0.13752661645412445,
      "learning_rate": 3.361463291071738e-05,
      "loss": 0.1108,
      "step": 49180
    },
    {
      "epoch": 0.9836819581650202,
      "grad_norm": 0.08704788237810135,
      "learning_rate": 3.3611299977336056e-05,
      "loss": 0.0822,
      "step": 49190
    },
    {
      "epoch": 0.9838819341678998,
      "grad_norm": 0.1698305606842041,
      "learning_rate": 3.3607967043954725e-05,
      "loss": 0.0661,
      "step": 49200
    },
    {
      "epoch": 0.9840819101707795,
      "grad_norm": 0.06091798096895218,
      "learning_rate": 3.36046341105734e-05,
      "loss": 0.0392,
      "step": 49210
    },
    {
      "epoch": 0.9842818861736592,
      "grad_norm": 0.08661244809627533,
      "learning_rate": 3.360130117719207e-05,
      "loss": 0.1205,
      "step": 49220
    },
    {
      "epoch": 0.9844818621765388,
      "grad_norm": 0.20366542041301727,
      "learning_rate": 3.359796824381075e-05,
      "loss": 0.0943,
      "step": 49230
    },
    {
      "epoch": 0.9846818381794185,
      "grad_norm": 0.19750307500362396,
      "learning_rate": 3.359463531042942e-05,
      "loss": 0.0827,
      "step": 49240
    },
    {
      "epoch": 0.9848818141822981,
      "grad_norm": 0.1566522866487503,
      "learning_rate": 3.359130237704809e-05,
      "loss": 0.069,
      "step": 49250
    },
    {
      "epoch": 0.9850817901851778,
      "grad_norm": 0.11752500385046005,
      "learning_rate": 3.3587969443666764e-05,
      "loss": 0.0558,
      "step": 49260
    },
    {
      "epoch": 0.9852817661880574,
      "grad_norm": 0.14390289783477783,
      "learning_rate": 3.358463651028543e-05,
      "loss": 0.0917,
      "step": 49270
    },
    {
      "epoch": 0.9854817421909371,
      "grad_norm": 0.05874793976545334,
      "learning_rate": 3.35813035769041e-05,
      "loss": 0.0686,
      "step": 49280
    },
    {
      "epoch": 0.9856817181938168,
      "grad_norm": 0.1108211874961853,
      "learning_rate": 3.357797064352278e-05,
      "loss": 0.0625,
      "step": 49290
    },
    {
      "epoch": 0.9858816941966964,
      "grad_norm": 0.14256225526332855,
      "learning_rate": 3.357463771014145e-05,
      "loss": 0.0709,
      "step": 49300
    },
    {
      "epoch": 0.986081670199576,
      "grad_norm": 0.16856159269809723,
      "learning_rate": 3.3571304776760125e-05,
      "loss": 0.2181,
      "step": 49310
    },
    {
      "epoch": 0.9862816462024557,
      "grad_norm": 0.09359527379274368,
      "learning_rate": 3.35679718433788e-05,
      "loss": 0.0839,
      "step": 49320
    },
    {
      "epoch": 0.9864816222053353,
      "grad_norm": 0.15935151278972626,
      "learning_rate": 3.356463890999747e-05,
      "loss": 0.0712,
      "step": 49330
    },
    {
      "epoch": 0.986681598208215,
      "grad_norm": 0.216702401638031,
      "learning_rate": 3.356130597661614e-05,
      "loss": 0.0827,
      "step": 49340
    },
    {
      "epoch": 0.9868815742110947,
      "grad_norm": 0.17345547676086426,
      "learning_rate": 3.355797304323482e-05,
      "loss": 0.0729,
      "step": 49350
    },
    {
      "epoch": 0.9870815502139744,
      "grad_norm": 0.0976158007979393,
      "learning_rate": 3.355464010985349e-05,
      "loss": 0.0531,
      "step": 49360
    },
    {
      "epoch": 0.9872815262168539,
      "grad_norm": 0.09369496256113052,
      "learning_rate": 3.3551307176472156e-05,
      "loss": 0.0803,
      "step": 49370
    },
    {
      "epoch": 0.9874815022197336,
      "grad_norm": 0.1223793625831604,
      "learning_rate": 3.354797424309083e-05,
      "loss": 0.0686,
      "step": 49380
    },
    {
      "epoch": 0.9876814782226133,
      "grad_norm": 0.06860081106424332,
      "learning_rate": 3.35446413097095e-05,
      "loss": 0.0571,
      "step": 49390
    },
    {
      "epoch": 0.9878814542254929,
      "grad_norm": 0.0951351523399353,
      "learning_rate": 3.354130837632817e-05,
      "loss": 0.07,
      "step": 49400
    },
    {
      "epoch": 0.9880814302283726,
      "grad_norm": 0.15272590517997742,
      "learning_rate": 3.353797544294685e-05,
      "loss": 0.0796,
      "step": 49410
    },
    {
      "epoch": 0.9882814062312523,
      "grad_norm": 0.10289189219474792,
      "learning_rate": 3.3534642509565525e-05,
      "loss": 0.0903,
      "step": 49420
    },
    {
      "epoch": 0.988481382234132,
      "grad_norm": 0.1002715453505516,
      "learning_rate": 3.3531309576184194e-05,
      "loss": 0.0724,
      "step": 49430
    },
    {
      "epoch": 0.9886813582370115,
      "grad_norm": 0.08222860097885132,
      "learning_rate": 3.3527976642802864e-05,
      "loss": 0.0652,
      "step": 49440
    },
    {
      "epoch": 0.9888813342398912,
      "grad_norm": 0.11238531768321991,
      "learning_rate": 3.352464370942154e-05,
      "loss": 0.0531,
      "step": 49450
    },
    {
      "epoch": 0.9890813102427709,
      "grad_norm": 0.17705951631069183,
      "learning_rate": 3.352131077604021e-05,
      "loss": 0.0972,
      "step": 49460
    },
    {
      "epoch": 0.9892812862456505,
      "grad_norm": 0.049633245915174484,
      "learning_rate": 3.351797784265888e-05,
      "loss": 0.0873,
      "step": 49470
    },
    {
      "epoch": 0.9894812622485302,
      "grad_norm": 0.11925343424081802,
      "learning_rate": 3.3514644909277556e-05,
      "loss": 0.0573,
      "step": 49480
    },
    {
      "epoch": 0.9896812382514099,
      "grad_norm": 0.08409462124109268,
      "learning_rate": 3.3511311975896226e-05,
      "loss": 0.0592,
      "step": 49490
    },
    {
      "epoch": 0.9898812142542894,
      "grad_norm": 0.1543162316083908,
      "learning_rate": 3.3507979042514895e-05,
      "loss": 0.1001,
      "step": 49500
    },
    {
      "epoch": 0.9900811902571691,
      "grad_norm": 0.15162032842636108,
      "learning_rate": 3.350464610913357e-05,
      "loss": 0.0885,
      "step": 49510
    },
    {
      "epoch": 0.9902811662600488,
      "grad_norm": 0.1585088074207306,
      "learning_rate": 3.350131317575225e-05,
      "loss": 0.0655,
      "step": 49520
    },
    {
      "epoch": 0.9904811422629285,
      "grad_norm": 0.07502002269029617,
      "learning_rate": 3.349798024237092e-05,
      "loss": 0.0654,
      "step": 49530
    },
    {
      "epoch": 0.9906811182658081,
      "grad_norm": 0.09266656637191772,
      "learning_rate": 3.3494647308989594e-05,
      "loss": 0.0971,
      "step": 49540
    },
    {
      "epoch": 0.9908810942686878,
      "grad_norm": 0.13295283913612366,
      "learning_rate": 3.3491314375608264e-05,
      "loss": 0.0617,
      "step": 49550
    },
    {
      "epoch": 0.9910810702715674,
      "grad_norm": 0.08417270332574844,
      "learning_rate": 3.348798144222693e-05,
      "loss": 0.0602,
      "step": 49560
    },
    {
      "epoch": 0.991281046274447,
      "grad_norm": 0.13092510402202606,
      "learning_rate": 3.348464850884561e-05,
      "loss": 0.0683,
      "step": 49570
    },
    {
      "epoch": 0.9914810222773267,
      "grad_norm": 0.14491738379001617,
      "learning_rate": 3.348131557546428e-05,
      "loss": 0.1194,
      "step": 49580
    },
    {
      "epoch": 0.9916809982802064,
      "grad_norm": 0.1993827372789383,
      "learning_rate": 3.347798264208295e-05,
      "loss": 0.0931,
      "step": 49590
    },
    {
      "epoch": 0.9918809742830861,
      "grad_norm": 0.124518021941185,
      "learning_rate": 3.3474649708701625e-05,
      "loss": 0.0659,
      "step": 49600
    },
    {
      "epoch": 0.9920809502859657,
      "grad_norm": 0.1171405240893364,
      "learning_rate": 3.3471316775320295e-05,
      "loss": 0.05,
      "step": 49610
    },
    {
      "epoch": 0.9922809262888453,
      "grad_norm": 0.10589172691106796,
      "learning_rate": 3.346798384193897e-05,
      "loss": 0.0715,
      "step": 49620
    },
    {
      "epoch": 0.992480902291725,
      "grad_norm": 0.19937847554683685,
      "learning_rate": 3.346465090855764e-05,
      "loss": 0.0945,
      "step": 49630
    },
    {
      "epoch": 0.9926808782946046,
      "grad_norm": 0.05552053824067116,
      "learning_rate": 3.346131797517632e-05,
      "loss": 0.0427,
      "step": 49640
    },
    {
      "epoch": 0.9928808542974843,
      "grad_norm": 0.15691927075386047,
      "learning_rate": 3.345798504179499e-05,
      "loss": 0.097,
      "step": 49650
    },
    {
      "epoch": 0.993080830300364,
      "grad_norm": 0.18178535997867584,
      "learning_rate": 3.3454652108413657e-05,
      "loss": 0.0969,
      "step": 49660
    },
    {
      "epoch": 0.9932808063032436,
      "grad_norm": 0.14726558327674866,
      "learning_rate": 3.345131917503233e-05,
      "loss": 0.0524,
      "step": 49670
    },
    {
      "epoch": 0.9934807823061232,
      "grad_norm": 0.09574966877698898,
      "learning_rate": 3.3447986241651e-05,
      "loss": 0.1112,
      "step": 49680
    },
    {
      "epoch": 0.9936807583090029,
      "grad_norm": 0.1663087010383606,
      "learning_rate": 3.344465330826967e-05,
      "loss": 0.104,
      "step": 49690
    },
    {
      "epoch": 0.9938807343118826,
      "grad_norm": 0.09411872178316116,
      "learning_rate": 3.344132037488835e-05,
      "loss": 0.0882,
      "step": 49700
    },
    {
      "epoch": 0.9940807103147622,
      "grad_norm": 0.050364185124635696,
      "learning_rate": 3.343798744150702e-05,
      "loss": 0.0573,
      "step": 49710
    },
    {
      "epoch": 0.9942806863176419,
      "grad_norm": 0.16667531430721283,
      "learning_rate": 3.3434654508125695e-05,
      "loss": 0.0536,
      "step": 49720
    },
    {
      "epoch": 0.9944806623205216,
      "grad_norm": 0.12648847699165344,
      "learning_rate": 3.3431321574744364e-05,
      "loss": 0.0695,
      "step": 49730
    },
    {
      "epoch": 0.9946806383234011,
      "grad_norm": 0.0956813171505928,
      "learning_rate": 3.342798864136304e-05,
      "loss": 0.0642,
      "step": 49740
    },
    {
      "epoch": 0.9948806143262808,
      "grad_norm": 0.13908617198467255,
      "learning_rate": 3.342465570798171e-05,
      "loss": 0.0836,
      "step": 49750
    },
    {
      "epoch": 0.9950805903291605,
      "grad_norm": 0.09300252795219421,
      "learning_rate": 3.342132277460038e-05,
      "loss": 0.0905,
      "step": 49760
    },
    {
      "epoch": 0.9952805663320402,
      "grad_norm": 0.06259264051914215,
      "learning_rate": 3.3417989841219056e-05,
      "loss": 0.0688,
      "step": 49770
    },
    {
      "epoch": 0.9954805423349198,
      "grad_norm": 0.09554523229598999,
      "learning_rate": 3.3414656907837726e-05,
      "loss": 0.0538,
      "step": 49780
    },
    {
      "epoch": 0.9956805183377995,
      "grad_norm": 0.15899181365966797,
      "learning_rate": 3.34113239744564e-05,
      "loss": 0.0761,
      "step": 49790
    },
    {
      "epoch": 0.9958804943406792,
      "grad_norm": 0.06585235148668289,
      "learning_rate": 3.340799104107507e-05,
      "loss": 0.0817,
      "step": 49800
    },
    {
      "epoch": 0.9960804703435587,
      "grad_norm": 0.190037801861763,
      "learning_rate": 3.340465810769374e-05,
      "loss": 0.1056,
      "step": 49810
    },
    {
      "epoch": 0.9962804463464384,
      "grad_norm": 0.18936103582382202,
      "learning_rate": 3.340132517431242e-05,
      "loss": 0.0765,
      "step": 49820
    },
    {
      "epoch": 0.9964804223493181,
      "grad_norm": 0.20151256024837494,
      "learning_rate": 3.3397992240931094e-05,
      "loss": 0.0745,
      "step": 49830
    },
    {
      "epoch": 0.9966803983521977,
      "grad_norm": 0.2061983048915863,
      "learning_rate": 3.3394659307549764e-05,
      "loss": 0.0885,
      "step": 49840
    },
    {
      "epoch": 0.9968803743550774,
      "grad_norm": 0.08628123998641968,
      "learning_rate": 3.3391326374168433e-05,
      "loss": 0.0937,
      "step": 49850
    },
    {
      "epoch": 0.9970803503579571,
      "grad_norm": 0.21686775982379913,
      "learning_rate": 3.338799344078711e-05,
      "loss": 0.0868,
      "step": 49860
    },
    {
      "epoch": 0.9972803263608367,
      "grad_norm": 0.06539914757013321,
      "learning_rate": 3.338466050740578e-05,
      "loss": 0.0704,
      "step": 49870
    },
    {
      "epoch": 0.9974803023637163,
      "grad_norm": 0.22801947593688965,
      "learning_rate": 3.338132757402445e-05,
      "loss": 0.087,
      "step": 49880
    },
    {
      "epoch": 0.997680278366596,
      "grad_norm": 0.12129829078912735,
      "learning_rate": 3.3377994640643125e-05,
      "loss": 0.0673,
      "step": 49890
    },
    {
      "epoch": 0.9978802543694757,
      "grad_norm": 0.15583959221839905,
      "learning_rate": 3.3374661707261795e-05,
      "loss": 0.084,
      "step": 49900
    },
    {
      "epoch": 0.9980802303723553,
      "grad_norm": 0.1741981953382492,
      "learning_rate": 3.3371328773880465e-05,
      "loss": 0.0861,
      "step": 49910
    },
    {
      "epoch": 0.998280206375235,
      "grad_norm": 0.17323285341262817,
      "learning_rate": 3.336799584049914e-05,
      "loss": 0.0969,
      "step": 49920
    },
    {
      "epoch": 0.9984801823781146,
      "grad_norm": 0.07348926365375519,
      "learning_rate": 3.336466290711782e-05,
      "loss": 0.0686,
      "step": 49930
    },
    {
      "epoch": 0.9986801583809943,
      "grad_norm": 0.07263706624507904,
      "learning_rate": 3.336132997373649e-05,
      "loss": 0.0672,
      "step": 49940
    },
    {
      "epoch": 0.9988801343838739,
      "grad_norm": 0.1751040816307068,
      "learning_rate": 3.335799704035516e-05,
      "loss": 0.0682,
      "step": 49950
    },
    {
      "epoch": 0.9990801103867536,
      "grad_norm": 0.09130815416574478,
      "learning_rate": 3.335466410697383e-05,
      "loss": 0.0759,
      "step": 49960
    },
    {
      "epoch": 0.9992800863896333,
      "grad_norm": 0.10485462844371796,
      "learning_rate": 3.33513311735925e-05,
      "loss": 0.0793,
      "step": 49970
    },
    {
      "epoch": 0.9994800623925129,
      "grad_norm": 0.13992010056972504,
      "learning_rate": 3.334799824021117e-05,
      "loss": 0.0669,
      "step": 49980
    },
    {
      "epoch": 0.9996800383953925,
      "grad_norm": 0.17612862586975098,
      "learning_rate": 3.334466530682985e-05,
      "loss": 0.1063,
      "step": 49990
    },
    {
      "epoch": 0.9998800143982722,
      "grad_norm": 0.08796925842761993,
      "learning_rate": 3.334133237344852e-05,
      "loss": 0.0658,
      "step": 50000
    },
    {
      "epoch": 1.000079990401152,
      "grad_norm": 0.2039162963628769,
      "learning_rate": 3.333799944006719e-05,
      "loss": 0.1096,
      "step": 50010
    },
    {
      "epoch": 1.0002799664040316,
      "grad_norm": 0.14013580977916718,
      "learning_rate": 3.3334666506685864e-05,
      "loss": 0.0597,
      "step": 50020
    },
    {
      "epoch": 1.000479942406911,
      "grad_norm": 0.07091949880123138,
      "learning_rate": 3.333133357330454e-05,
      "loss": 0.0686,
      "step": 50030
    },
    {
      "epoch": 1.0006799184097908,
      "grad_norm": 0.1268874704837799,
      "learning_rate": 3.332800063992321e-05,
      "loss": 0.0717,
      "step": 50040
    },
    {
      "epoch": 1.0008798944126704,
      "grad_norm": 0.20561884343624115,
      "learning_rate": 3.332466770654189e-05,
      "loss": 0.0699,
      "step": 50050
    },
    {
      "epoch": 1.0010798704155501,
      "grad_norm": 0.14273610711097717,
      "learning_rate": 3.3321334773160556e-05,
      "loss": 0.0962,
      "step": 50060
    },
    {
      "epoch": 1.0012798464184298,
      "grad_norm": 0.19230009615421295,
      "learning_rate": 3.3318001839779226e-05,
      "loss": 0.0727,
      "step": 50070
    },
    {
      "epoch": 1.0014798224213095,
      "grad_norm": 0.13379217684268951,
      "learning_rate": 3.33146689063979e-05,
      "loss": 0.0586,
      "step": 50080
    },
    {
      "epoch": 1.0016797984241892,
      "grad_norm": 0.11248871684074402,
      "learning_rate": 3.331133597301657e-05,
      "loss": 0.1061,
      "step": 50090
    },
    {
      "epoch": 1.0018797744270687,
      "grad_norm": 0.05621878430247307,
      "learning_rate": 3.330800303963524e-05,
      "loss": 0.0415,
      "step": 50100
    },
    {
      "epoch": 1.0020797504299483,
      "grad_norm": 0.1845494508743286,
      "learning_rate": 3.330467010625392e-05,
      "loss": 0.0694,
      "step": 50110
    },
    {
      "epoch": 1.002279726432828,
      "grad_norm": 0.1403975635766983,
      "learning_rate": 3.330133717287259e-05,
      "loss": 0.1045,
      "step": 50120
    },
    {
      "epoch": 1.0024797024357077,
      "grad_norm": 0.17126241326332092,
      "learning_rate": 3.3298004239491264e-05,
      "loss": 0.0962,
      "step": 50130
    },
    {
      "epoch": 1.0026796784385874,
      "grad_norm": 0.11225803941488266,
      "learning_rate": 3.3294671306109934e-05,
      "loss": 0.0552,
      "step": 50140
    },
    {
      "epoch": 1.002879654441467,
      "grad_norm": 0.20266738533973694,
      "learning_rate": 3.329133837272861e-05,
      "loss": 0.0676,
      "step": 50150
    },
    {
      "epoch": 1.0030796304443468,
      "grad_norm": 0.11432304233312607,
      "learning_rate": 3.328800543934728e-05,
      "loss": 0.0729,
      "step": 50160
    },
    {
      "epoch": 1.0032796064472262,
      "grad_norm": 0.09550023823976517,
      "learning_rate": 3.328467250596595e-05,
      "loss": 0.0894,
      "step": 50170
    },
    {
      "epoch": 1.003479582450106,
      "grad_norm": 0.1289370208978653,
      "learning_rate": 3.3281339572584626e-05,
      "loss": 0.0774,
      "step": 50180
    },
    {
      "epoch": 1.0036795584529856,
      "grad_norm": 0.08485633879899979,
      "learning_rate": 3.3278006639203295e-05,
      "loss": 0.0715,
      "step": 50190
    },
    {
      "epoch": 1.0038795344558653,
      "grad_norm": 0.2010609358549118,
      "learning_rate": 3.3274673705821965e-05,
      "loss": 0.0627,
      "step": 50200
    },
    {
      "epoch": 1.004079510458745,
      "grad_norm": 0.13897982239723206,
      "learning_rate": 3.327134077244064e-05,
      "loss": 0.1019,
      "step": 50210
    },
    {
      "epoch": 1.0042794864616247,
      "grad_norm": 0.11187561601400375,
      "learning_rate": 3.326800783905931e-05,
      "loss": 0.0653,
      "step": 50220
    },
    {
      "epoch": 1.0044794624645044,
      "grad_norm": 0.16458304226398468,
      "learning_rate": 3.326467490567799e-05,
      "loss": 0.1015,
      "step": 50230
    },
    {
      "epoch": 1.0046794384673838,
      "grad_norm": 0.11572025716304779,
      "learning_rate": 3.326167526563479e-05,
      "loss": 0.0575,
      "step": 50240
    },
    {
      "epoch": 1.0048794144702635,
      "grad_norm": 0.07242651283740997,
      "learning_rate": 3.3258342332253466e-05,
      "loss": 0.0658,
      "step": 50250
    },
    {
      "epoch": 1.0050793904731432,
      "grad_norm": 0.1801532655954361,
      "learning_rate": 3.325500939887214e-05,
      "loss": 0.0447,
      "step": 50260
    },
    {
      "epoch": 1.005279366476023,
      "grad_norm": 0.173649400472641,
      "learning_rate": 3.325167646549081e-05,
      "loss": 0.0861,
      "step": 50270
    },
    {
      "epoch": 1.0054793424789026,
      "grad_norm": 0.08078236132860184,
      "learning_rate": 3.324834353210948e-05,
      "loss": 0.0674,
      "step": 50280
    },
    {
      "epoch": 1.0056793184817823,
      "grad_norm": 0.22570492327213287,
      "learning_rate": 3.324501059872816e-05,
      "loss": 0.0738,
      "step": 50290
    },
    {
      "epoch": 1.0058792944846617,
      "grad_norm": 0.11451406031847,
      "learning_rate": 3.324167766534683e-05,
      "loss": 0.0502,
      "step": 50300
    },
    {
      "epoch": 1.0060792704875414,
      "grad_norm": 0.16243615746498108,
      "learning_rate": 3.32383447319655e-05,
      "loss": 0.0627,
      "step": 50310
    },
    {
      "epoch": 1.006279246490421,
      "grad_norm": 0.14162079989910126,
      "learning_rate": 3.323501179858417e-05,
      "loss": 0.0502,
      "step": 50320
    },
    {
      "epoch": 1.0064792224933008,
      "grad_norm": 0.16989952325820923,
      "learning_rate": 3.323167886520284e-05,
      "loss": 0.0884,
      "step": 50330
    },
    {
      "epoch": 1.0066791984961805,
      "grad_norm": 0.10263276845216751,
      "learning_rate": 3.322834593182151e-05,
      "loss": 0.117,
      "step": 50340
    },
    {
      "epoch": 1.0068791744990602,
      "grad_norm": 0.22136658430099487,
      "learning_rate": 3.322501299844019e-05,
      "loss": 0.0843,
      "step": 50350
    },
    {
      "epoch": 1.0070791505019399,
      "grad_norm": 0.13105720281600952,
      "learning_rate": 3.3221680065058865e-05,
      "loss": 0.0885,
      "step": 50360
    },
    {
      "epoch": 1.0072791265048193,
      "grad_norm": 0.08463428914546967,
      "learning_rate": 3.3218347131677535e-05,
      "loss": 0.0321,
      "step": 50370
    },
    {
      "epoch": 1.007479102507699,
      "grad_norm": 0.2014216035604477,
      "learning_rate": 3.3215014198296205e-05,
      "loss": 0.1134,
      "step": 50380
    },
    {
      "epoch": 1.0076790785105787,
      "grad_norm": 0.08982211351394653,
      "learning_rate": 3.321168126491488e-05,
      "loss": 0.0873,
      "step": 50390
    },
    {
      "epoch": 1.0078790545134584,
      "grad_norm": 0.09384816884994507,
      "learning_rate": 3.320834833153355e-05,
      "loss": 0.0936,
      "step": 50400
    },
    {
      "epoch": 1.008079030516338,
      "grad_norm": 0.1526620090007782,
      "learning_rate": 3.320501539815222e-05,
      "loss": 0.047,
      "step": 50410
    },
    {
      "epoch": 1.0082790065192178,
      "grad_norm": 0.2070884108543396,
      "learning_rate": 3.3201682464770897e-05,
      "loss": 0.1677,
      "step": 50420
    },
    {
      "epoch": 1.0084789825220974,
      "grad_norm": 0.13879892230033875,
      "learning_rate": 3.3198349531389566e-05,
      "loss": 0.1027,
      "step": 50430
    },
    {
      "epoch": 1.008678958524977,
      "grad_norm": 0.12503115832805634,
      "learning_rate": 3.3195016598008236e-05,
      "loss": 0.0905,
      "step": 50440
    },
    {
      "epoch": 1.0088789345278566,
      "grad_norm": 0.06916957348585129,
      "learning_rate": 3.319168366462691e-05,
      "loss": 0.0643,
      "step": 50450
    },
    {
      "epoch": 1.0090789105307363,
      "grad_norm": 0.13779643177986145,
      "learning_rate": 3.318835073124559e-05,
      "loss": 0.0871,
      "step": 50460
    },
    {
      "epoch": 1.009278886533616,
      "grad_norm": 0.28715160489082336,
      "learning_rate": 3.318501779786426e-05,
      "loss": 0.1143,
      "step": 50470
    },
    {
      "epoch": 1.0094788625364957,
      "grad_norm": 0.06801671534776688,
      "learning_rate": 3.3181684864482935e-05,
      "loss": 0.0633,
      "step": 50480
    },
    {
      "epoch": 1.0096788385393753,
      "grad_norm": 0.1885381042957306,
      "learning_rate": 3.3178351931101604e-05,
      "loss": 0.0956,
      "step": 50490
    },
    {
      "epoch": 1.009878814542255,
      "grad_norm": 0.14903214573860168,
      "learning_rate": 3.3175018997720274e-05,
      "loss": 0.0659,
      "step": 50500
    },
    {
      "epoch": 1.0100787905451345,
      "grad_norm": 0.14553433656692505,
      "learning_rate": 3.317168606433895e-05,
      "loss": 0.0416,
      "step": 50510
    },
    {
      "epoch": 1.0102787665480142,
      "grad_norm": 0.16268011927604675,
      "learning_rate": 3.316835313095762e-05,
      "loss": 0.0697,
      "step": 50520
    },
    {
      "epoch": 1.0104787425508939,
      "grad_norm": 0.12224000692367554,
      "learning_rate": 3.316502019757629e-05,
      "loss": 0.0853,
      "step": 50530
    },
    {
      "epoch": 1.0106787185537736,
      "grad_norm": 0.13519719243049622,
      "learning_rate": 3.3161687264194966e-05,
      "loss": 0.0318,
      "step": 50540
    },
    {
      "epoch": 1.0108786945566532,
      "grad_norm": 0.09502483159303665,
      "learning_rate": 3.3158354330813635e-05,
      "loss": 0.0985,
      "step": 50550
    },
    {
      "epoch": 1.011078670559533,
      "grad_norm": 0.24150486290454865,
      "learning_rate": 3.315502139743231e-05,
      "loss": 0.0663,
      "step": 50560
    },
    {
      "epoch": 1.0112786465624126,
      "grad_norm": 0.21193180978298187,
      "learning_rate": 3.315168846405098e-05,
      "loss": 0.0692,
      "step": 50570
    },
    {
      "epoch": 1.011478622565292,
      "grad_norm": 0.13192157447338104,
      "learning_rate": 3.314835553066966e-05,
      "loss": 0.0881,
      "step": 50580
    },
    {
      "epoch": 1.0116785985681718,
      "grad_norm": 0.06717150658369064,
      "learning_rate": 3.314502259728833e-05,
      "loss": 0.0758,
      "step": 50590
    },
    {
      "epoch": 1.0118785745710515,
      "grad_norm": 0.22481997311115265,
      "learning_rate": 3.3141689663907e-05,
      "loss": 0.0851,
      "step": 50600
    },
    {
      "epoch": 1.0120785505739311,
      "grad_norm": 0.08350306004285812,
      "learning_rate": 3.3138356730525673e-05,
      "loss": 0.0706,
      "step": 50610
    },
    {
      "epoch": 1.0122785265768108,
      "grad_norm": 0.13938555121421814,
      "learning_rate": 3.313502379714434e-05,
      "loss": 0.0668,
      "step": 50620
    },
    {
      "epoch": 1.0124785025796905,
      "grad_norm": 0.10161188989877701,
      "learning_rate": 3.313169086376301e-05,
      "loss": 0.0354,
      "step": 50630
    },
    {
      "epoch": 1.01267847858257,
      "grad_norm": 0.22862695157527924,
      "learning_rate": 3.312835793038169e-05,
      "loss": 0.0667,
      "step": 50640
    },
    {
      "epoch": 1.0128784545854497,
      "grad_norm": 0.20994660258293152,
      "learning_rate": 3.312502499700036e-05,
      "loss": 0.0629,
      "step": 50650
    },
    {
      "epoch": 1.0130784305883294,
      "grad_norm": 0.18371587991714478,
      "learning_rate": 3.3121692063619035e-05,
      "loss": 0.0844,
      "step": 50660
    },
    {
      "epoch": 1.013278406591209,
      "grad_norm": 0.1854221671819687,
      "learning_rate": 3.311835913023771e-05,
      "loss": 0.086,
      "step": 50670
    },
    {
      "epoch": 1.0134783825940887,
      "grad_norm": 0.14662940800189972,
      "learning_rate": 3.311502619685638e-05,
      "loss": 0.0756,
      "step": 50680
    },
    {
      "epoch": 1.0136783585969684,
      "grad_norm": 0.08137588948011398,
      "learning_rate": 3.311169326347505e-05,
      "loss": 0.0731,
      "step": 50690
    },
    {
      "epoch": 1.013878334599848,
      "grad_norm": 0.0748649463057518,
      "learning_rate": 3.310836033009373e-05,
      "loss": 0.099,
      "step": 50700
    },
    {
      "epoch": 1.0140783106027276,
      "grad_norm": 0.12388996034860611,
      "learning_rate": 3.31050273967124e-05,
      "loss": 0.0634,
      "step": 50710
    },
    {
      "epoch": 1.0142782866056073,
      "grad_norm": 0.06517083197832108,
      "learning_rate": 3.3101694463331066e-05,
      "loss": 0.0595,
      "step": 50720
    },
    {
      "epoch": 1.014478262608487,
      "grad_norm": 0.1456320881843567,
      "learning_rate": 3.309836152994974e-05,
      "loss": 0.0808,
      "step": 50730
    },
    {
      "epoch": 1.0146782386113666,
      "grad_norm": 0.09355480968952179,
      "learning_rate": 3.309502859656841e-05,
      "loss": 0.0651,
      "step": 50740
    },
    {
      "epoch": 1.0148782146142463,
      "grad_norm": 0.0809541717171669,
      "learning_rate": 3.309169566318708e-05,
      "loss": 0.0922,
      "step": 50750
    },
    {
      "epoch": 1.015078190617126,
      "grad_norm": 0.08127894997596741,
      "learning_rate": 3.308836272980576e-05,
      "loss": 0.0517,
      "step": 50760
    },
    {
      "epoch": 1.0152781666200057,
      "grad_norm": 0.2017524391412735,
      "learning_rate": 3.3085029796424435e-05,
      "loss": 0.0801,
      "step": 50770
    },
    {
      "epoch": 1.0154781426228852,
      "grad_norm": 0.14728650450706482,
      "learning_rate": 3.3081696863043104e-05,
      "loss": 0.0681,
      "step": 50780
    },
    {
      "epoch": 1.0156781186257648,
      "grad_norm": 0.1827564239501953,
      "learning_rate": 3.3078363929661774e-05,
      "loss": 0.0706,
      "step": 50790
    },
    {
      "epoch": 1.0158780946286445,
      "grad_norm": 0.15958747267723083,
      "learning_rate": 3.307503099628045e-05,
      "loss": 0.0995,
      "step": 50800
    },
    {
      "epoch": 1.0160780706315242,
      "grad_norm": 0.19504567980766296,
      "learning_rate": 3.307169806289912e-05,
      "loss": 0.0945,
      "step": 50810
    },
    {
      "epoch": 1.016278046634404,
      "grad_norm": 0.2311004251241684,
      "learning_rate": 3.306836512951779e-05,
      "loss": 0.0765,
      "step": 50820
    },
    {
      "epoch": 1.0164780226372836,
      "grad_norm": 0.12835825979709625,
      "learning_rate": 3.3065032196136466e-05,
      "loss": 0.0538,
      "step": 50830
    },
    {
      "epoch": 1.0166779986401633,
      "grad_norm": 0.10555588454008102,
      "learning_rate": 3.3061699262755136e-05,
      "loss": 0.0568,
      "step": 50840
    },
    {
      "epoch": 1.0168779746430427,
      "grad_norm": 0.0752045139670372,
      "learning_rate": 3.3058366329373805e-05,
      "loss": 0.0977,
      "step": 50850
    },
    {
      "epoch": 1.0170779506459224,
      "grad_norm": 0.06456926465034485,
      "learning_rate": 3.305503339599249e-05,
      "loss": 0.0677,
      "step": 50860
    },
    {
      "epoch": 1.0172779266488021,
      "grad_norm": 0.06495600193738937,
      "learning_rate": 3.305170046261116e-05,
      "loss": 0.1179,
      "step": 50870
    },
    {
      "epoch": 1.0174779026516818,
      "grad_norm": 0.10250794887542725,
      "learning_rate": 3.304836752922983e-05,
      "loss": 0.0841,
      "step": 50880
    },
    {
      "epoch": 1.0176778786545615,
      "grad_norm": 0.0890820175409317,
      "learning_rate": 3.3045034595848504e-05,
      "loss": 0.0647,
      "step": 50890
    },
    {
      "epoch": 1.0178778546574412,
      "grad_norm": 0.09928300231695175,
      "learning_rate": 3.3041701662467174e-05,
      "loss": 0.0495,
      "step": 50900
    },
    {
      "epoch": 1.0180778306603209,
      "grad_norm": 0.21949075162410736,
      "learning_rate": 3.303836872908584e-05,
      "loss": 0.1185,
      "step": 50910
    },
    {
      "epoch": 1.0182778066632003,
      "grad_norm": 0.13632254302501678,
      "learning_rate": 3.303503579570452e-05,
      "loss": 0.1161,
      "step": 50920
    },
    {
      "epoch": 1.01847778266608,
      "grad_norm": 0.1692645400762558,
      "learning_rate": 3.303170286232319e-05,
      "loss": 0.093,
      "step": 50930
    },
    {
      "epoch": 1.0186777586689597,
      "grad_norm": 0.12503884732723236,
      "learning_rate": 3.302836992894186e-05,
      "loss": 0.1599,
      "step": 50940
    },
    {
      "epoch": 1.0188777346718394,
      "grad_norm": 0.15315544605255127,
      "learning_rate": 3.3025036995560535e-05,
      "loss": 0.0684,
      "step": 50950
    },
    {
      "epoch": 1.019077710674719,
      "grad_norm": 0.10094312578439713,
      "learning_rate": 3.3021704062179205e-05,
      "loss": 0.0566,
      "step": 50960
    },
    {
      "epoch": 1.0192776866775988,
      "grad_norm": 0.11556022614240646,
      "learning_rate": 3.301837112879788e-05,
      "loss": 0.0683,
      "step": 50970
    },
    {
      "epoch": 1.0194776626804782,
      "grad_norm": 0.08965540677309036,
      "learning_rate": 3.301503819541655e-05,
      "loss": 0.0683,
      "step": 50980
    },
    {
      "epoch": 1.019677638683358,
      "grad_norm": 0.09145870059728622,
      "learning_rate": 3.301170526203523e-05,
      "loss": 0.0664,
      "step": 50990
    },
    {
      "epoch": 1.0198776146862376,
      "grad_norm": 0.15719307959079742,
      "learning_rate": 3.30083723286539e-05,
      "loss": 0.0785,
      "step": 51000
    },
    {
      "epoch": 1.0200775906891173,
      "grad_norm": 0.06412610411643982,
      "learning_rate": 3.3005039395272567e-05,
      "loss": 0.0428,
      "step": 51010
    },
    {
      "epoch": 1.020277566691997,
      "grad_norm": 0.0647292360663414,
      "learning_rate": 3.300170646189124e-05,
      "loss": 0.2276,
      "step": 51020
    },
    {
      "epoch": 1.0204775426948767,
      "grad_norm": 0.2156507819890976,
      "learning_rate": 3.299837352850991e-05,
      "loss": 0.0901,
      "step": 51030
    },
    {
      "epoch": 1.0206775186977564,
      "grad_norm": 0.07700005918741226,
      "learning_rate": 3.299504059512858e-05,
      "loss": 0.1033,
      "step": 51040
    },
    {
      "epoch": 1.0208774947006358,
      "grad_norm": 0.12927000224590302,
      "learning_rate": 3.299170766174726e-05,
      "loss": 0.0763,
      "step": 51050
    },
    {
      "epoch": 1.0210774707035155,
      "grad_norm": 0.1083681583404541,
      "learning_rate": 3.298837472836593e-05,
      "loss": 0.0602,
      "step": 51060
    },
    {
      "epoch": 1.0212774467063952,
      "grad_norm": 0.2281169891357422,
      "learning_rate": 3.2985041794984605e-05,
      "loss": 0.0739,
      "step": 51070
    },
    {
      "epoch": 1.0214774227092749,
      "grad_norm": 0.13596104085445404,
      "learning_rate": 3.298170886160328e-05,
      "loss": 0.0608,
      "step": 51080
    },
    {
      "epoch": 1.0216773987121546,
      "grad_norm": 0.21734130382537842,
      "learning_rate": 3.297837592822195e-05,
      "loss": 0.0902,
      "step": 51090
    },
    {
      "epoch": 1.0218773747150343,
      "grad_norm": 0.18645335733890533,
      "learning_rate": 3.297504299484062e-05,
      "loss": 0.1312,
      "step": 51100
    },
    {
      "epoch": 1.022077350717914,
      "grad_norm": 0.05213426798582077,
      "learning_rate": 3.2971710061459297e-05,
      "loss": 0.0738,
      "step": 51110
    },
    {
      "epoch": 1.0222773267207934,
      "grad_norm": 0.18305324018001556,
      "learning_rate": 3.2968377128077966e-05,
      "loss": 0.0908,
      "step": 51120
    },
    {
      "epoch": 1.022477302723673,
      "grad_norm": 0.10687516629695892,
      "learning_rate": 3.2965044194696636e-05,
      "loss": 0.0723,
      "step": 51130
    },
    {
      "epoch": 1.0226772787265528,
      "grad_norm": 0.12602832913398743,
      "learning_rate": 3.296171126131531e-05,
      "loss": 0.0517,
      "step": 51140
    },
    {
      "epoch": 1.0228772547294325,
      "grad_norm": 0.11888112127780914,
      "learning_rate": 3.295837832793398e-05,
      "loss": 0.0637,
      "step": 51150
    },
    {
      "epoch": 1.0230772307323122,
      "grad_norm": 0.07034648954868317,
      "learning_rate": 3.295504539455265e-05,
      "loss": 0.0577,
      "step": 51160
    },
    {
      "epoch": 1.0232772067351918,
      "grad_norm": 0.13849011063575745,
      "learning_rate": 3.295171246117133e-05,
      "loss": 0.0748,
      "step": 51170
    },
    {
      "epoch": 1.0234771827380715,
      "grad_norm": 0.07023216038942337,
      "learning_rate": 3.2948379527790004e-05,
      "loss": 0.0861,
      "step": 51180
    },
    {
      "epoch": 1.023677158740951,
      "grad_norm": 0.10357236862182617,
      "learning_rate": 3.2945046594408674e-05,
      "loss": 0.0643,
      "step": 51190
    },
    {
      "epoch": 1.0238771347438307,
      "grad_norm": 0.12402401119470596,
      "learning_rate": 3.2941713661027343e-05,
      "loss": 0.1197,
      "step": 51200
    },
    {
      "epoch": 1.0240771107467104,
      "grad_norm": 0.1305437833070755,
      "learning_rate": 3.293838072764602e-05,
      "loss": 0.0633,
      "step": 51210
    },
    {
      "epoch": 1.02427708674959,
      "grad_norm": 0.13333380222320557,
      "learning_rate": 3.293504779426469e-05,
      "loss": 0.0742,
      "step": 51220
    },
    {
      "epoch": 1.0244770627524697,
      "grad_norm": 0.17340342700481415,
      "learning_rate": 3.293171486088336e-05,
      "loss": 0.054,
      "step": 51230
    },
    {
      "epoch": 1.0246770387553494,
      "grad_norm": 0.121824711561203,
      "learning_rate": 3.2928381927502035e-05,
      "loss": 0.0831,
      "step": 51240
    },
    {
      "epoch": 1.0248770147582291,
      "grad_norm": 0.12441728264093399,
      "learning_rate": 3.2925048994120705e-05,
      "loss": 0.0693,
      "step": 51250
    },
    {
      "epoch": 1.0250769907611086,
      "grad_norm": 0.1788308471441269,
      "learning_rate": 3.2921716060739375e-05,
      "loss": 0.0955,
      "step": 51260
    },
    {
      "epoch": 1.0252769667639883,
      "grad_norm": 0.13310584425926208,
      "learning_rate": 3.291838312735806e-05,
      "loss": 0.0885,
      "step": 51270
    },
    {
      "epoch": 1.025476942766868,
      "grad_norm": 0.09184256941080093,
      "learning_rate": 3.291505019397673e-05,
      "loss": 0.0745,
      "step": 51280
    },
    {
      "epoch": 1.0256769187697476,
      "grad_norm": 0.0820104256272316,
      "learning_rate": 3.29117172605954e-05,
      "loss": 0.0837,
      "step": 51290
    },
    {
      "epoch": 1.0258768947726273,
      "grad_norm": 0.08572972565889359,
      "learning_rate": 3.2908384327214073e-05,
      "loss": 0.0715,
      "step": 51300
    },
    {
      "epoch": 1.026076870775507,
      "grad_norm": 0.19428354501724243,
      "learning_rate": 3.290505139383274e-05,
      "loss": 0.1355,
      "step": 51310
    },
    {
      "epoch": 1.0262768467783865,
      "grad_norm": 0.1361512690782547,
      "learning_rate": 3.290171846045141e-05,
      "loss": 0.0748,
      "step": 51320
    },
    {
      "epoch": 1.0264768227812662,
      "grad_norm": 0.06999307870864868,
      "learning_rate": 3.289838552707009e-05,
      "loss": 0.0591,
      "step": 51330
    },
    {
      "epoch": 1.0266767987841459,
      "grad_norm": 0.09832669794559479,
      "learning_rate": 3.289505259368876e-05,
      "loss": 0.0898,
      "step": 51340
    },
    {
      "epoch": 1.0268767747870255,
      "grad_norm": 0.07223759591579437,
      "learning_rate": 3.289171966030743e-05,
      "loss": 0.0615,
      "step": 51350
    },
    {
      "epoch": 1.0270767507899052,
      "grad_norm": 0.20051926374435425,
      "learning_rate": 3.2888386726926105e-05,
      "loss": 0.1173,
      "step": 51360
    },
    {
      "epoch": 1.027276726792785,
      "grad_norm": 0.11482493579387665,
      "learning_rate": 3.288505379354478e-05,
      "loss": 0.0628,
      "step": 51370
    },
    {
      "epoch": 1.0274767027956646,
      "grad_norm": 0.1099904403090477,
      "learning_rate": 3.288172086016345e-05,
      "loss": 0.0652,
      "step": 51380
    },
    {
      "epoch": 1.027676678798544,
      "grad_norm": 0.15489782392978668,
      "learning_rate": 3.287838792678212e-05,
      "loss": 0.0876,
      "step": 51390
    },
    {
      "epoch": 1.0278766548014238,
      "grad_norm": 0.11084659397602081,
      "learning_rate": 3.28750549934008e-05,
      "loss": 0.1087,
      "step": 51400
    },
    {
      "epoch": 1.0280766308043034,
      "grad_norm": 0.10573187470436096,
      "learning_rate": 3.2871722060019466e-05,
      "loss": 0.0723,
      "step": 51410
    },
    {
      "epoch": 1.0282766068071831,
      "grad_norm": 0.10030484944581985,
      "learning_rate": 3.2868389126638136e-05,
      "loss": 0.0813,
      "step": 51420
    },
    {
      "epoch": 1.0284765828100628,
      "grad_norm": 0.11642803251743317,
      "learning_rate": 3.286505619325681e-05,
      "loss": 0.0514,
      "step": 51430
    },
    {
      "epoch": 1.0286765588129425,
      "grad_norm": 0.20053912699222565,
      "learning_rate": 3.286172325987548e-05,
      "loss": 0.0906,
      "step": 51440
    },
    {
      "epoch": 1.0288765348158222,
      "grad_norm": 0.12089604884386063,
      "learning_rate": 3.285839032649415e-05,
      "loss": 0.0385,
      "step": 51450
    },
    {
      "epoch": 1.0290765108187017,
      "grad_norm": 0.1738317310810089,
      "learning_rate": 3.285505739311283e-05,
      "loss": 0.0392,
      "step": 51460
    },
    {
      "epoch": 1.0292764868215813,
      "grad_norm": 0.07759656012058258,
      "learning_rate": 3.28517244597315e-05,
      "loss": 0.1159,
      "step": 51470
    },
    {
      "epoch": 1.029476462824461,
      "grad_norm": 0.10383494198322296,
      "learning_rate": 3.2848391526350174e-05,
      "loss": 0.0872,
      "step": 51480
    },
    {
      "epoch": 1.0296764388273407,
      "grad_norm": 0.1589221954345703,
      "learning_rate": 3.284505859296885e-05,
      "loss": 0.079,
      "step": 51490
    },
    {
      "epoch": 1.0298764148302204,
      "grad_norm": 0.11269444972276688,
      "learning_rate": 3.284172565958752e-05,
      "loss": 0.0905,
      "step": 51500
    },
    {
      "epoch": 1.0300763908331,
      "grad_norm": 0.13555265963077545,
      "learning_rate": 3.283839272620619e-05,
      "loss": 0.0487,
      "step": 51510
    },
    {
      "epoch": 1.0302763668359798,
      "grad_norm": 0.12458567321300507,
      "learning_rate": 3.2835059792824866e-05,
      "loss": 0.065,
      "step": 51520
    },
    {
      "epoch": 1.0304763428388592,
      "grad_norm": 0.09052921086549759,
      "learning_rate": 3.2831726859443536e-05,
      "loss": 0.0637,
      "step": 51530
    },
    {
      "epoch": 1.030676318841739,
      "grad_norm": 0.1495131552219391,
      "learning_rate": 3.2828393926062205e-05,
      "loss": 0.0725,
      "step": 51540
    },
    {
      "epoch": 1.0308762948446186,
      "grad_norm": 0.16234172880649567,
      "learning_rate": 3.282506099268088e-05,
      "loss": 0.1001,
      "step": 51550
    },
    {
      "epoch": 1.0310762708474983,
      "grad_norm": 0.1484927088022232,
      "learning_rate": 3.282172805929955e-05,
      "loss": 0.0967,
      "step": 51560
    },
    {
      "epoch": 1.031276246850378,
      "grad_norm": 0.1909220814704895,
      "learning_rate": 3.281839512591822e-05,
      "loss": 0.0805,
      "step": 51570
    },
    {
      "epoch": 1.0314762228532577,
      "grad_norm": 0.06166815757751465,
      "learning_rate": 3.28150621925369e-05,
      "loss": 0.0802,
      "step": 51580
    },
    {
      "epoch": 1.0316761988561374,
      "grad_norm": 0.15357883274555206,
      "learning_rate": 3.2811729259155574e-05,
      "loss": 0.0724,
      "step": 51590
    },
    {
      "epoch": 1.0318761748590168,
      "grad_norm": 0.17842936515808105,
      "learning_rate": 3.280839632577424e-05,
      "loss": 0.0976,
      "step": 51600
    },
    {
      "epoch": 1.0320761508618965,
      "grad_norm": 0.22512319684028625,
      "learning_rate": 3.280506339239291e-05,
      "loss": 0.0749,
      "step": 51610
    },
    {
      "epoch": 1.0322761268647762,
      "grad_norm": 0.16185158491134644,
      "learning_rate": 3.280173045901159e-05,
      "loss": 0.0889,
      "step": 51620
    },
    {
      "epoch": 1.032476102867656,
      "grad_norm": 0.17335689067840576,
      "learning_rate": 3.279839752563026e-05,
      "loss": 0.0796,
      "step": 51630
    },
    {
      "epoch": 1.0326760788705356,
      "grad_norm": 0.07159892469644547,
      "learning_rate": 3.279506459224893e-05,
      "loss": 0.0863,
      "step": 51640
    },
    {
      "epoch": 1.0328760548734153,
      "grad_norm": 0.1274537444114685,
      "learning_rate": 3.2791731658867605e-05,
      "loss": 0.0927,
      "step": 51650
    },
    {
      "epoch": 1.0330760308762947,
      "grad_norm": 0.08416715264320374,
      "learning_rate": 3.2788398725486275e-05,
      "loss": 0.0573,
      "step": 51660
    },
    {
      "epoch": 1.0332760068791744,
      "grad_norm": 0.0752323567867279,
      "learning_rate": 3.2785065792104944e-05,
      "loss": 0.0552,
      "step": 51670
    },
    {
      "epoch": 1.0334759828820541,
      "grad_norm": 0.13282333314418793,
      "learning_rate": 3.278173285872362e-05,
      "loss": 0.0607,
      "step": 51680
    },
    {
      "epoch": 1.0336759588849338,
      "grad_norm": 0.19660015404224396,
      "learning_rate": 3.27783999253423e-05,
      "loss": 0.0785,
      "step": 51690
    },
    {
      "epoch": 1.0338759348878135,
      "grad_norm": 0.11743098497390747,
      "learning_rate": 3.2775066991960967e-05,
      "loss": 0.06,
      "step": 51700
    },
    {
      "epoch": 1.0340759108906932,
      "grad_norm": 0.18412798643112183,
      "learning_rate": 3.2771734058579636e-05,
      "loss": 0.0806,
      "step": 51710
    },
    {
      "epoch": 1.0342758868935729,
      "grad_norm": 0.1732477992773056,
      "learning_rate": 3.276840112519831e-05,
      "loss": 0.061,
      "step": 51720
    },
    {
      "epoch": 1.0344758628964523,
      "grad_norm": 0.12673789262771606,
      "learning_rate": 3.276506819181698e-05,
      "loss": 0.0539,
      "step": 51730
    },
    {
      "epoch": 1.034675838899332,
      "grad_norm": 0.19684168696403503,
      "learning_rate": 3.276173525843565e-05,
      "loss": 0.0886,
      "step": 51740
    },
    {
      "epoch": 1.0348758149022117,
      "grad_norm": 0.10365261882543564,
      "learning_rate": 3.275840232505433e-05,
      "loss": 0.0782,
      "step": 51750
    },
    {
      "epoch": 1.0350757909050914,
      "grad_norm": 0.06434579193592072,
      "learning_rate": 3.2755069391673e-05,
      "loss": 0.1287,
      "step": 51760
    },
    {
      "epoch": 1.035275766907971,
      "grad_norm": 0.13959364593029022,
      "learning_rate": 3.2751736458291674e-05,
      "loss": 0.0565,
      "step": 51770
    },
    {
      "epoch": 1.0354757429108508,
      "grad_norm": 0.16285383701324463,
      "learning_rate": 3.274840352491035e-05,
      "loss": 0.0655,
      "step": 51780
    },
    {
      "epoch": 1.0356757189137304,
      "grad_norm": 0.06337787210941315,
      "learning_rate": 3.274507059152902e-05,
      "loss": 0.0705,
      "step": 51790
    },
    {
      "epoch": 1.03587569491661,
      "grad_norm": 0.05302434414625168,
      "learning_rate": 3.274173765814769e-05,
      "loss": 0.0555,
      "step": 51800
    },
    {
      "epoch": 1.0360756709194896,
      "grad_norm": 0.22201219201087952,
      "learning_rate": 3.2738404724766366e-05,
      "loss": 0.0932,
      "step": 51810
    },
    {
      "epoch": 1.0362756469223693,
      "grad_norm": 0.30859801173210144,
      "learning_rate": 3.2735071791385036e-05,
      "loss": 0.0781,
      "step": 51820
    },
    {
      "epoch": 1.036475622925249,
      "grad_norm": 0.1457267850637436,
      "learning_rate": 3.2731738858003705e-05,
      "loss": 0.0684,
      "step": 51830
    },
    {
      "epoch": 1.0366755989281287,
      "grad_norm": 0.08970783650875092,
      "learning_rate": 3.272840592462238e-05,
      "loss": 0.1011,
      "step": 51840
    },
    {
      "epoch": 1.0368755749310083,
      "grad_norm": 0.13394418358802795,
      "learning_rate": 3.272507299124105e-05,
      "loss": 0.0626,
      "step": 51850
    },
    {
      "epoch": 1.037075550933888,
      "grad_norm": 0.09430064260959625,
      "learning_rate": 3.272174005785972e-05,
      "loss": 0.0585,
      "step": 51860
    },
    {
      "epoch": 1.0372755269367675,
      "grad_norm": 0.09289862960577011,
      "learning_rate": 3.27184071244784e-05,
      "loss": 0.0771,
      "step": 51870
    },
    {
      "epoch": 1.0374755029396472,
      "grad_norm": 0.09352073073387146,
      "learning_rate": 3.2715074191097074e-05,
      "loss": 0.0939,
      "step": 51880
    },
    {
      "epoch": 1.0376754789425269,
      "grad_norm": 0.12354675680398941,
      "learning_rate": 3.2711741257715743e-05,
      "loss": 0.0434,
      "step": 51890
    },
    {
      "epoch": 1.0378754549454066,
      "grad_norm": 0.19878840446472168,
      "learning_rate": 3.270840832433441e-05,
      "loss": 0.0787,
      "step": 51900
    },
    {
      "epoch": 1.0380754309482862,
      "grad_norm": 0.21014012396335602,
      "learning_rate": 3.270507539095309e-05,
      "loss": 0.1127,
      "step": 51910
    },
    {
      "epoch": 1.038275406951166,
      "grad_norm": 0.15141133964061737,
      "learning_rate": 3.270174245757176e-05,
      "loss": 0.0804,
      "step": 51920
    },
    {
      "epoch": 1.0384753829540454,
      "grad_norm": 0.13880357146263123,
      "learning_rate": 3.269840952419043e-05,
      "loss": 0.0556,
      "step": 51930
    },
    {
      "epoch": 1.038675358956925,
      "grad_norm": 0.07505160570144653,
      "learning_rate": 3.2695076590809105e-05,
      "loss": 0.0529,
      "step": 51940
    },
    {
      "epoch": 1.0388753349598048,
      "grad_norm": 0.07579385489225388,
      "learning_rate": 3.2691743657427775e-05,
      "loss": 0.0632,
      "step": 51950
    },
    {
      "epoch": 1.0390753109626845,
      "grad_norm": 0.18766550719738007,
      "learning_rate": 3.2688410724046444e-05,
      "loss": 0.0777,
      "step": 51960
    },
    {
      "epoch": 1.0392752869655641,
      "grad_norm": 0.13295334577560425,
      "learning_rate": 3.268507779066512e-05,
      "loss": 0.0717,
      "step": 51970
    },
    {
      "epoch": 1.0394752629684438,
      "grad_norm": 0.24997450411319733,
      "learning_rate": 3.268174485728379e-05,
      "loss": 0.1052,
      "step": 51980
    },
    {
      "epoch": 1.0396752389713235,
      "grad_norm": 0.1808970719575882,
      "learning_rate": 3.267841192390247e-05,
      "loss": 0.0876,
      "step": 51990
    },
    {
      "epoch": 1.039875214974203,
      "grad_norm": 0.2140025943517685,
      "learning_rate": 3.267507899052114e-05,
      "loss": 0.0837,
      "step": 52000
    },
    {
      "epoch": 1.0400751909770827,
      "grad_norm": 0.16107305884361267,
      "learning_rate": 3.267174605713981e-05,
      "loss": 0.1017,
      "step": 52010
    },
    {
      "epoch": 1.0402751669799624,
      "grad_norm": 0.06750091165304184,
      "learning_rate": 3.266841312375848e-05,
      "loss": 0.1273,
      "step": 52020
    },
    {
      "epoch": 1.040475142982842,
      "grad_norm": 0.1081506684422493,
      "learning_rate": 3.266508019037716e-05,
      "loss": 0.064,
      "step": 52030
    },
    {
      "epoch": 1.0406751189857217,
      "grad_norm": 0.16659829020500183,
      "learning_rate": 3.266174725699583e-05,
      "loss": 0.098,
      "step": 52040
    },
    {
      "epoch": 1.0408750949886014,
      "grad_norm": 0.1348123848438263,
      "learning_rate": 3.26584143236145e-05,
      "loss": 0.0562,
      "step": 52050
    },
    {
      "epoch": 1.041075070991481,
      "grad_norm": 0.15680523216724396,
      "learning_rate": 3.2655081390233174e-05,
      "loss": 0.0967,
      "step": 52060
    },
    {
      "epoch": 1.0412750469943606,
      "grad_norm": 0.08707749098539352,
      "learning_rate": 3.2651748456851844e-05,
      "loss": 0.0599,
      "step": 52070
    },
    {
      "epoch": 1.0414750229972403,
      "grad_norm": 0.07681291550397873,
      "learning_rate": 3.2648415523470514e-05,
      "loss": 0.0927,
      "step": 52080
    },
    {
      "epoch": 1.04167499900012,
      "grad_norm": 0.04301132261753082,
      "learning_rate": 3.264508259008919e-05,
      "loss": 0.0753,
      "step": 52090
    },
    {
      "epoch": 1.0418749750029996,
      "grad_norm": 0.16095387935638428,
      "learning_rate": 3.2641749656707866e-05,
      "loss": 0.0638,
      "step": 52100
    },
    {
      "epoch": 1.0420749510058793,
      "grad_norm": 0.10953865200281143,
      "learning_rate": 3.2638416723326536e-05,
      "loss": 0.0856,
      "step": 52110
    },
    {
      "epoch": 1.042274927008759,
      "grad_norm": 0.18463674187660217,
      "learning_rate": 3.2635083789945206e-05,
      "loss": 0.0494,
      "step": 52120
    },
    {
      "epoch": 1.0424749030116387,
      "grad_norm": 0.0699918121099472,
      "learning_rate": 3.263175085656388e-05,
      "loss": 0.0562,
      "step": 52130
    },
    {
      "epoch": 1.0426748790145182,
      "grad_norm": 0.20538094639778137,
      "learning_rate": 3.262841792318255e-05,
      "loss": 0.0927,
      "step": 52140
    },
    {
      "epoch": 1.0428748550173979,
      "grad_norm": 0.13674581050872803,
      "learning_rate": 3.262508498980122e-05,
      "loss": 0.0699,
      "step": 52150
    },
    {
      "epoch": 1.0430748310202775,
      "grad_norm": 0.08149058371782303,
      "learning_rate": 3.26217520564199e-05,
      "loss": 0.0697,
      "step": 52160
    },
    {
      "epoch": 1.0432748070231572,
      "grad_norm": 0.04843999445438385,
      "learning_rate": 3.261841912303857e-05,
      "loss": 0.0428,
      "step": 52170
    },
    {
      "epoch": 1.043474783026037,
      "grad_norm": 0.12439658492803574,
      "learning_rate": 3.261508618965724e-05,
      "loss": 0.0572,
      "step": 52180
    },
    {
      "epoch": 1.0436747590289166,
      "grad_norm": 0.1781567931175232,
      "learning_rate": 3.261175325627592e-05,
      "loss": 0.0809,
      "step": 52190
    },
    {
      "epoch": 1.0438747350317963,
      "grad_norm": 0.06377417594194412,
      "learning_rate": 3.260842032289459e-05,
      "loss": 0.0417,
      "step": 52200
    },
    {
      "epoch": 1.0440747110346758,
      "grad_norm": 0.20546972751617432,
      "learning_rate": 3.260508738951326e-05,
      "loss": 0.1064,
      "step": 52210
    },
    {
      "epoch": 1.0442746870375554,
      "grad_norm": 0.20370566844940186,
      "learning_rate": 3.2601754456131936e-05,
      "loss": 0.0562,
      "step": 52220
    },
    {
      "epoch": 1.0444746630404351,
      "grad_norm": 0.11785690486431122,
      "learning_rate": 3.2598421522750605e-05,
      "loss": 0.0434,
      "step": 52230
    },
    {
      "epoch": 1.0446746390433148,
      "grad_norm": 0.10766009241342545,
      "learning_rate": 3.2595088589369275e-05,
      "loss": 0.0757,
      "step": 52240
    },
    {
      "epoch": 1.0448746150461945,
      "grad_norm": 0.1617121547460556,
      "learning_rate": 3.259175565598795e-05,
      "loss": 0.0618,
      "step": 52250
    },
    {
      "epoch": 1.0450745910490742,
      "grad_norm": 0.20049068331718445,
      "learning_rate": 3.258842272260662e-05,
      "loss": 0.0568,
      "step": 52260
    },
    {
      "epoch": 1.0452745670519539,
      "grad_norm": 0.12703460454940796,
      "learning_rate": 3.258508978922529e-05,
      "loss": 0.0526,
      "step": 52270
    },
    {
      "epoch": 1.0454745430548333,
      "grad_norm": 0.12171554565429688,
      "learning_rate": 3.258175685584397e-05,
      "loss": 0.1008,
      "step": 52280
    },
    {
      "epoch": 1.045674519057713,
      "grad_norm": 0.0972956195473671,
      "learning_rate": 3.257842392246264e-05,
      "loss": 0.0596,
      "step": 52290
    },
    {
      "epoch": 1.0458744950605927,
      "grad_norm": 0.0814640000462532,
      "learning_rate": 3.257509098908131e-05,
      "loss": 0.0448,
      "step": 52300
    },
    {
      "epoch": 1.0460744710634724,
      "grad_norm": 0.18490639328956604,
      "learning_rate": 3.257175805569998e-05,
      "loss": 0.0856,
      "step": 52310
    },
    {
      "epoch": 1.046274447066352,
      "grad_norm": 0.07015746831893921,
      "learning_rate": 3.256842512231866e-05,
      "loss": 0.0429,
      "step": 52320
    },
    {
      "epoch": 1.0464744230692318,
      "grad_norm": 0.07577686756849289,
      "learning_rate": 3.256509218893733e-05,
      "loss": 0.081,
      "step": 52330
    },
    {
      "epoch": 1.0466743990721112,
      "grad_norm": 0.22540614008903503,
      "learning_rate": 3.2561759255556e-05,
      "loss": 0.1101,
      "step": 52340
    },
    {
      "epoch": 1.046874375074991,
      "grad_norm": 0.19285322725772858,
      "learning_rate": 3.2558426322174675e-05,
      "loss": 0.0514,
      "step": 52350
    },
    {
      "epoch": 1.0470743510778706,
      "grad_norm": 0.11794165521860123,
      "learning_rate": 3.2555093388793344e-05,
      "loss": 0.0904,
      "step": 52360
    },
    {
      "epoch": 1.0472743270807503,
      "grad_norm": 0.1059829592704773,
      "learning_rate": 3.2551760455412014e-05,
      "loss": 0.0709,
      "step": 52370
    },
    {
      "epoch": 1.04747430308363,
      "grad_norm": 0.13689906895160675,
      "learning_rate": 3.254842752203069e-05,
      "loss": 0.0877,
      "step": 52380
    },
    {
      "epoch": 1.0476742790865097,
      "grad_norm": 0.07515094429254532,
      "learning_rate": 3.2545094588649367e-05,
      "loss": 0.0595,
      "step": 52390
    },
    {
      "epoch": 1.0478742550893894,
      "grad_norm": 0.09606023132801056,
      "learning_rate": 3.2541761655268036e-05,
      "loss": 0.0756,
      "step": 52400
    },
    {
      "epoch": 1.0480742310922688,
      "grad_norm": 0.1886993795633316,
      "learning_rate": 3.253842872188671e-05,
      "loss": 0.0737,
      "step": 52410
    },
    {
      "epoch": 1.0482742070951485,
      "grad_norm": 0.2100156992673874,
      "learning_rate": 3.253509578850538e-05,
      "loss": 0.0854,
      "step": 52420
    },
    {
      "epoch": 1.0484741830980282,
      "grad_norm": 0.10576360672712326,
      "learning_rate": 3.253176285512405e-05,
      "loss": 0.0703,
      "step": 52430
    },
    {
      "epoch": 1.0486741591009079,
      "grad_norm": 0.22100503742694855,
      "learning_rate": 3.252842992174273e-05,
      "loss": 0.096,
      "step": 52440
    },
    {
      "epoch": 1.0488741351037876,
      "grad_norm": 0.09067259728908539,
      "learning_rate": 3.25250969883614e-05,
      "loss": 0.0548,
      "step": 52450
    },
    {
      "epoch": 1.0490741111066673,
      "grad_norm": 0.1122257336974144,
      "learning_rate": 3.252176405498007e-05,
      "loss": 0.0946,
      "step": 52460
    },
    {
      "epoch": 1.049274087109547,
      "grad_norm": 0.07626920938491821,
      "learning_rate": 3.2518431121598744e-05,
      "loss": 0.0709,
      "step": 52470
    },
    {
      "epoch": 1.0494740631124264,
      "grad_norm": 0.12050729244947433,
      "learning_rate": 3.2515098188217413e-05,
      "loss": 0.0991,
      "step": 52480
    },
    {
      "epoch": 1.049674039115306,
      "grad_norm": 0.1842026263475418,
      "learning_rate": 3.251209854817422e-05,
      "loss": 0.0531,
      "step": 52490
    },
    {
      "epoch": 1.0498740151181858,
      "grad_norm": 0.14108411967754364,
      "learning_rate": 3.250876561479289e-05,
      "loss": 0.0947,
      "step": 52500
    },
    {
      "epoch": 1.0500739911210655,
      "grad_norm": 0.11205483973026276,
      "learning_rate": 3.250543268141156e-05,
      "loss": 0.0757,
      "step": 52510
    },
    {
      "epoch": 1.0502739671239452,
      "grad_norm": 0.19954782724380493,
      "learning_rate": 3.250209974803024e-05,
      "loss": 0.1228,
      "step": 52520
    },
    {
      "epoch": 1.0504739431268248,
      "grad_norm": 0.10030565410852432,
      "learning_rate": 3.2498766814648914e-05,
      "loss": 0.0828,
      "step": 52530
    },
    {
      "epoch": 1.0506739191297045,
      "grad_norm": 0.14824263751506805,
      "learning_rate": 3.2495433881267584e-05,
      "loss": 0.0865,
      "step": 52540
    },
    {
      "epoch": 1.050873895132584,
      "grad_norm": 0.1276189535856247,
      "learning_rate": 3.2492100947886253e-05,
      "loss": 0.0579,
      "step": 52550
    },
    {
      "epoch": 1.0510738711354637,
      "grad_norm": 0.10797303169965744,
      "learning_rate": 3.248876801450493e-05,
      "loss": 0.0532,
      "step": 52560
    },
    {
      "epoch": 1.0512738471383434,
      "grad_norm": 0.1401153951883316,
      "learning_rate": 3.24854350811236e-05,
      "loss": 0.054,
      "step": 52570
    },
    {
      "epoch": 1.051473823141223,
      "grad_norm": 0.1762738823890686,
      "learning_rate": 3.248210214774227e-05,
      "loss": 0.0626,
      "step": 52580
    },
    {
      "epoch": 1.0516737991441027,
      "grad_norm": 0.09109904617071152,
      "learning_rate": 3.2478769214360945e-05,
      "loss": 0.0782,
      "step": 52590
    },
    {
      "epoch": 1.0518737751469824,
      "grad_norm": 0.15075378119945526,
      "learning_rate": 3.2475436280979615e-05,
      "loss": 0.091,
      "step": 52600
    },
    {
      "epoch": 1.052073751149862,
      "grad_norm": 0.10190273076295853,
      "learning_rate": 3.2472103347598285e-05,
      "loss": 0.0527,
      "step": 52610
    },
    {
      "epoch": 1.0522737271527416,
      "grad_norm": 0.10059604793787003,
      "learning_rate": 3.246877041421697e-05,
      "loss": 0.0873,
      "step": 52620
    },
    {
      "epoch": 1.0524737031556213,
      "grad_norm": 0.113111712038517,
      "learning_rate": 3.246543748083564e-05,
      "loss": 0.0857,
      "step": 52630
    },
    {
      "epoch": 1.052673679158501,
      "grad_norm": 0.09277801215648651,
      "learning_rate": 3.246210454745431e-05,
      "loss": 0.08,
      "step": 52640
    },
    {
      "epoch": 1.0528736551613807,
      "grad_norm": 0.231214702129364,
      "learning_rate": 3.2458771614072983e-05,
      "loss": 0.11,
      "step": 52650
    },
    {
      "epoch": 1.0530736311642603,
      "grad_norm": 0.11350881308317184,
      "learning_rate": 3.245543868069165e-05,
      "loss": 0.0863,
      "step": 52660
    },
    {
      "epoch": 1.05327360716714,
      "grad_norm": 0.20599617063999176,
      "learning_rate": 3.245210574731032e-05,
      "loss": 0.1068,
      "step": 52670
    },
    {
      "epoch": 1.0534735831700197,
      "grad_norm": 0.06591792404651642,
      "learning_rate": 3.2448772813929e-05,
      "loss": 0.0487,
      "step": 52680
    },
    {
      "epoch": 1.0536735591728992,
      "grad_norm": 0.19196268916130066,
      "learning_rate": 3.244543988054767e-05,
      "loss": 0.0686,
      "step": 52690
    },
    {
      "epoch": 1.0538735351757789,
      "grad_norm": 0.17985551059246063,
      "learning_rate": 3.244210694716634e-05,
      "loss": 0.065,
      "step": 52700
    },
    {
      "epoch": 1.0540735111786586,
      "grad_norm": 0.12185576558113098,
      "learning_rate": 3.2438774013785015e-05,
      "loss": 0.0958,
      "step": 52710
    },
    {
      "epoch": 1.0542734871815382,
      "grad_norm": 0.12506438791751862,
      "learning_rate": 3.243544108040369e-05,
      "loss": 0.0916,
      "step": 52720
    },
    {
      "epoch": 1.054473463184418,
      "grad_norm": 0.18450827896595,
      "learning_rate": 3.243210814702236e-05,
      "loss": 0.0724,
      "step": 52730
    },
    {
      "epoch": 1.0546734391872976,
      "grad_norm": 0.08452096581459045,
      "learning_rate": 3.242877521364103e-05,
      "loss": 0.073,
      "step": 52740
    },
    {
      "epoch": 1.054873415190177,
      "grad_norm": 0.11450472474098206,
      "learning_rate": 3.242544228025971e-05,
      "loss": 0.0591,
      "step": 52750
    },
    {
      "epoch": 1.0550733911930568,
      "grad_norm": 0.13077110052108765,
      "learning_rate": 3.2422109346878376e-05,
      "loss": 0.0714,
      "step": 52760
    },
    {
      "epoch": 1.0552733671959365,
      "grad_norm": 0.08010588586330414,
      "learning_rate": 3.2418776413497046e-05,
      "loss": 0.0531,
      "step": 52770
    },
    {
      "epoch": 1.0554733431988161,
      "grad_norm": 0.18279671669006348,
      "learning_rate": 3.241544348011572e-05,
      "loss": 0.0829,
      "step": 52780
    },
    {
      "epoch": 1.0556733192016958,
      "grad_norm": 0.09494063258171082,
      "learning_rate": 3.241211054673439e-05,
      "loss": 0.0849,
      "step": 52790
    },
    {
      "epoch": 1.0558732952045755,
      "grad_norm": 0.17154543101787567,
      "learning_rate": 3.240877761335306e-05,
      "loss": 0.0805,
      "step": 52800
    },
    {
      "epoch": 1.0560732712074552,
      "grad_norm": 0.20099885761737823,
      "learning_rate": 3.240544467997174e-05,
      "loss": 0.062,
      "step": 52810
    },
    {
      "epoch": 1.0562732472103347,
      "grad_norm": 0.2546795606613159,
      "learning_rate": 3.2402111746590414e-05,
      "loss": 0.0843,
      "step": 52820
    },
    {
      "epoch": 1.0564732232132144,
      "grad_norm": 0.19846294820308685,
      "learning_rate": 3.2398778813209084e-05,
      "loss": 0.4717,
      "step": 52830
    },
    {
      "epoch": 1.056673199216094,
      "grad_norm": 0.20932015776634216,
      "learning_rate": 3.239544587982776e-05,
      "loss": 0.0958,
      "step": 52840
    },
    {
      "epoch": 1.0568731752189737,
      "grad_norm": 0.09390635788440704,
      "learning_rate": 3.239211294644643e-05,
      "loss": 0.0997,
      "step": 52850
    },
    {
      "epoch": 1.0570731512218534,
      "grad_norm": 0.07747476547956467,
      "learning_rate": 3.23887800130651e-05,
      "loss": 0.0797,
      "step": 52860
    },
    {
      "epoch": 1.057273127224733,
      "grad_norm": 0.1844170093536377,
      "learning_rate": 3.2385447079683776e-05,
      "loss": 0.0912,
      "step": 52870
    },
    {
      "epoch": 1.0574731032276128,
      "grad_norm": 0.11131702363491058,
      "learning_rate": 3.2382114146302446e-05,
      "loss": 0.0681,
      "step": 52880
    },
    {
      "epoch": 1.0576730792304923,
      "grad_norm": 0.11236543953418732,
      "learning_rate": 3.2378781212921115e-05,
      "loss": 0.0948,
      "step": 52890
    },
    {
      "epoch": 1.057873055233372,
      "grad_norm": 0.058786772191524506,
      "learning_rate": 3.237544827953979e-05,
      "loss": 0.0708,
      "step": 52900
    },
    {
      "epoch": 1.0580730312362516,
      "grad_norm": 0.22660204768180847,
      "learning_rate": 3.237211534615846e-05,
      "loss": 0.0906,
      "step": 52910
    },
    {
      "epoch": 1.0582730072391313,
      "grad_norm": 0.07251029461622238,
      "learning_rate": 3.236878241277713e-05,
      "loss": 0.0559,
      "step": 52920
    },
    {
      "epoch": 1.058472983242011,
      "grad_norm": 0.17976608872413635,
      "learning_rate": 3.236544947939581e-05,
      "loss": 0.0838,
      "step": 52930
    },
    {
      "epoch": 1.0586729592448907,
      "grad_norm": 0.08607790619134903,
      "learning_rate": 3.2362116546014484e-05,
      "loss": 0.0626,
      "step": 52940
    },
    {
      "epoch": 1.0588729352477704,
      "grad_norm": 0.19014260172843933,
      "learning_rate": 3.235878361263315e-05,
      "loss": 0.0565,
      "step": 52950
    },
    {
      "epoch": 1.0590729112506498,
      "grad_norm": 0.06640666723251343,
      "learning_rate": 3.235545067925182e-05,
      "loss": 0.0558,
      "step": 52960
    },
    {
      "epoch": 1.0592728872535295,
      "grad_norm": 0.16141924262046814,
      "learning_rate": 3.23521177458705e-05,
      "loss": 0.0921,
      "step": 52970
    },
    {
      "epoch": 1.0594728632564092,
      "grad_norm": 0.15544508397579193,
      "learning_rate": 3.234878481248917e-05,
      "loss": 0.0931,
      "step": 52980
    },
    {
      "epoch": 1.059672839259289,
      "grad_norm": 0.16360042989253998,
      "learning_rate": 3.234545187910784e-05,
      "loss": 0.0824,
      "step": 52990
    },
    {
      "epoch": 1.0598728152621686,
      "grad_norm": 0.13228942453861237,
      "learning_rate": 3.2342118945726515e-05,
      "loss": 0.081,
      "step": 53000
    },
    {
      "epoch": 1.0600727912650483,
      "grad_norm": 0.09297341108322144,
      "learning_rate": 3.2338786012345185e-05,
      "loss": 0.1129,
      "step": 53010
    },
    {
      "epoch": 1.0602727672679277,
      "grad_norm": 0.17475305497646332,
      "learning_rate": 3.2335453078963854e-05,
      "loss": 0.0846,
      "step": 53020
    },
    {
      "epoch": 1.0604727432708074,
      "grad_norm": 0.11850526928901672,
      "learning_rate": 3.233212014558254e-05,
      "loss": 0.0831,
      "step": 53030
    },
    {
      "epoch": 1.0606727192736871,
      "grad_norm": 0.1385916769504547,
      "learning_rate": 3.232878721220121e-05,
      "loss": 0.0773,
      "step": 53040
    },
    {
      "epoch": 1.0608726952765668,
      "grad_norm": 0.21337749063968658,
      "learning_rate": 3.2325454278819877e-05,
      "loss": 0.0848,
      "step": 53050
    },
    {
      "epoch": 1.0610726712794465,
      "grad_norm": 0.14129142463207245,
      "learning_rate": 3.232212134543855e-05,
      "loss": 0.0673,
      "step": 53060
    },
    {
      "epoch": 1.0612726472823262,
      "grad_norm": 0.17719274759292603,
      "learning_rate": 3.231878841205722e-05,
      "loss": 0.1348,
      "step": 53070
    },
    {
      "epoch": 1.0614726232852059,
      "grad_norm": 0.11762794107198715,
      "learning_rate": 3.231545547867589e-05,
      "loss": 0.0615,
      "step": 53080
    },
    {
      "epoch": 1.0616725992880853,
      "grad_norm": 0.16610871255397797,
      "learning_rate": 3.231212254529457e-05,
      "loss": 0.1025,
      "step": 53090
    },
    {
      "epoch": 1.061872575290965,
      "grad_norm": 0.16012625396251678,
      "learning_rate": 3.230878961191324e-05,
      "loss": 0.0547,
      "step": 53100
    },
    {
      "epoch": 1.0620725512938447,
      "grad_norm": 0.11043767631053925,
      "learning_rate": 3.230545667853191e-05,
      "loss": 0.0606,
      "step": 53110
    },
    {
      "epoch": 1.0622725272967244,
      "grad_norm": 0.16252416372299194,
      "learning_rate": 3.2302123745150584e-05,
      "loss": 0.0772,
      "step": 53120
    },
    {
      "epoch": 1.062472503299604,
      "grad_norm": 0.09126286953687668,
      "learning_rate": 3.229879081176926e-05,
      "loss": 0.1097,
      "step": 53130
    },
    {
      "epoch": 1.0626724793024838,
      "grad_norm": 0.19413909316062927,
      "learning_rate": 3.229545787838793e-05,
      "loss": 0.1025,
      "step": 53140
    },
    {
      "epoch": 1.0628724553053635,
      "grad_norm": 0.07061184197664261,
      "learning_rate": 3.22921249450066e-05,
      "loss": 0.0721,
      "step": 53150
    },
    {
      "epoch": 1.063072431308243,
      "grad_norm": 0.11900880187749863,
      "learning_rate": 3.2288792011625276e-05,
      "loss": 0.0744,
      "step": 53160
    },
    {
      "epoch": 1.0632724073111226,
      "grad_norm": 0.08567163348197937,
      "learning_rate": 3.2285459078243946e-05,
      "loss": 0.0593,
      "step": 53170
    },
    {
      "epoch": 1.0634723833140023,
      "grad_norm": 0.16413164138793945,
      "learning_rate": 3.2282126144862615e-05,
      "loss": 0.098,
      "step": 53180
    },
    {
      "epoch": 1.063672359316882,
      "grad_norm": 0.08973865956068039,
      "learning_rate": 3.227879321148129e-05,
      "loss": 0.0536,
      "step": 53190
    },
    {
      "epoch": 1.0638723353197617,
      "grad_norm": 0.10239887237548828,
      "learning_rate": 3.227546027809996e-05,
      "loss": 0.0666,
      "step": 53200
    },
    {
      "epoch": 1.0640723113226414,
      "grad_norm": 0.1361672729253769,
      "learning_rate": 3.227212734471863e-05,
      "loss": 0.0648,
      "step": 53210
    },
    {
      "epoch": 1.064272287325521,
      "grad_norm": 0.19090667366981506,
      "learning_rate": 3.226879441133731e-05,
      "loss": 0.0739,
      "step": 53220
    },
    {
      "epoch": 1.0644722633284005,
      "grad_norm": 0.05020484700798988,
      "learning_rate": 3.2265461477955984e-05,
      "loss": 0.0491,
      "step": 53230
    },
    {
      "epoch": 1.0646722393312802,
      "grad_norm": 0.13159026205539703,
      "learning_rate": 3.2262128544574653e-05,
      "loss": 0.0893,
      "step": 53240
    },
    {
      "epoch": 1.0648722153341599,
      "grad_norm": 0.07861300557851791,
      "learning_rate": 3.225879561119333e-05,
      "loss": 0.0422,
      "step": 53250
    },
    {
      "epoch": 1.0650721913370396,
      "grad_norm": 0.09029187262058258,
      "learning_rate": 3.2255462677812e-05,
      "loss": 0.0628,
      "step": 53260
    },
    {
      "epoch": 1.0652721673399193,
      "grad_norm": 0.08229084312915802,
      "learning_rate": 3.225212974443067e-05,
      "loss": 0.0726,
      "step": 53270
    },
    {
      "epoch": 1.065472143342799,
      "grad_norm": 0.12457016855478287,
      "learning_rate": 3.2248796811049345e-05,
      "loss": 0.0741,
      "step": 53280
    },
    {
      "epoch": 1.0656721193456784,
      "grad_norm": 0.1524491310119629,
      "learning_rate": 3.2245463877668015e-05,
      "loss": 0.0665,
      "step": 53290
    },
    {
      "epoch": 1.065872095348558,
      "grad_norm": 0.12040846049785614,
      "learning_rate": 3.2242130944286685e-05,
      "loss": 0.071,
      "step": 53300
    },
    {
      "epoch": 1.0660720713514378,
      "grad_norm": 0.14807848632335663,
      "learning_rate": 3.223879801090536e-05,
      "loss": 0.077,
      "step": 53310
    },
    {
      "epoch": 1.0662720473543175,
      "grad_norm": 0.18812833726406097,
      "learning_rate": 3.223546507752403e-05,
      "loss": 0.0881,
      "step": 53320
    },
    {
      "epoch": 1.0664720233571972,
      "grad_norm": 0.10709366202354431,
      "learning_rate": 3.223213214414271e-05,
      "loss": 0.0341,
      "step": 53330
    },
    {
      "epoch": 1.0666719993600768,
      "grad_norm": 0.10445334762334824,
      "learning_rate": 3.222879921076138e-05,
      "loss": 0.072,
      "step": 53340
    },
    {
      "epoch": 1.0668719753629565,
      "grad_norm": 0.18991439044475555,
      "learning_rate": 3.222546627738005e-05,
      "loss": 0.0897,
      "step": 53350
    },
    {
      "epoch": 1.0670719513658362,
      "grad_norm": 0.06604395061731339,
      "learning_rate": 3.222213334399872e-05,
      "loss": 0.0995,
      "step": 53360
    },
    {
      "epoch": 1.0672719273687157,
      "grad_norm": 0.06453058123588562,
      "learning_rate": 3.221880041061739e-05,
      "loss": 0.0608,
      "step": 53370
    },
    {
      "epoch": 1.0674719033715954,
      "grad_norm": 0.21845459938049316,
      "learning_rate": 3.221546747723607e-05,
      "loss": 0.0694,
      "step": 53380
    },
    {
      "epoch": 1.067671879374475,
      "grad_norm": 0.06845187395811081,
      "learning_rate": 3.221213454385474e-05,
      "loss": 0.0637,
      "step": 53390
    },
    {
      "epoch": 1.0678718553773547,
      "grad_norm": 0.12807013094425201,
      "learning_rate": 3.220880161047341e-05,
      "loss": 0.0615,
      "step": 53400
    },
    {
      "epoch": 1.0680718313802344,
      "grad_norm": 0.20216915011405945,
      "learning_rate": 3.2205468677092084e-05,
      "loss": 0.0785,
      "step": 53410
    },
    {
      "epoch": 1.0682718073831141,
      "grad_norm": 0.14116168022155762,
      "learning_rate": 3.2202135743710754e-05,
      "loss": 0.0892,
      "step": 53420
    },
    {
      "epoch": 1.0684717833859936,
      "grad_norm": 0.06587067246437073,
      "learning_rate": 3.2198802810329424e-05,
      "loss": 0.058,
      "step": 53430
    },
    {
      "epoch": 1.0686717593888733,
      "grad_norm": 0.0638093575835228,
      "learning_rate": 3.21954698769481e-05,
      "loss": 0.0585,
      "step": 53440
    },
    {
      "epoch": 1.068871735391753,
      "grad_norm": 0.145636186003685,
      "learning_rate": 3.2192136943566776e-05,
      "loss": 0.0787,
      "step": 53450
    },
    {
      "epoch": 1.0690717113946326,
      "grad_norm": 0.06849568337202072,
      "learning_rate": 3.2188804010185446e-05,
      "loss": 0.0635,
      "step": 53460
    },
    {
      "epoch": 1.0692716873975123,
      "grad_norm": 0.1597200483083725,
      "learning_rate": 3.218547107680412e-05,
      "loss": 0.0587,
      "step": 53470
    },
    {
      "epoch": 1.069471663400392,
      "grad_norm": 0.16253702342510223,
      "learning_rate": 3.218213814342279e-05,
      "loss": 0.1031,
      "step": 53480
    },
    {
      "epoch": 1.0696716394032717,
      "grad_norm": 0.2106403261423111,
      "learning_rate": 3.217880521004146e-05,
      "loss": 0.0862,
      "step": 53490
    },
    {
      "epoch": 1.0698716154061512,
      "grad_norm": 0.20806923508644104,
      "learning_rate": 3.217547227666014e-05,
      "loss": 0.0871,
      "step": 53500
    },
    {
      "epoch": 1.0700715914090309,
      "grad_norm": 0.19172954559326172,
      "learning_rate": 3.217213934327881e-05,
      "loss": 0.0868,
      "step": 53510
    },
    {
      "epoch": 1.0702715674119105,
      "grad_norm": 0.1560223251581192,
      "learning_rate": 3.216880640989748e-05,
      "loss": 0.0743,
      "step": 53520
    },
    {
      "epoch": 1.0704715434147902,
      "grad_norm": 0.08970226347446442,
      "learning_rate": 3.2165473476516154e-05,
      "loss": 0.084,
      "step": 53530
    },
    {
      "epoch": 1.07067151941767,
      "grad_norm": 0.16499114036560059,
      "learning_rate": 3.216214054313483e-05,
      "loss": 0.059,
      "step": 53540
    },
    {
      "epoch": 1.0708714954205496,
      "grad_norm": 0.10704096406698227,
      "learning_rate": 3.21588076097535e-05,
      "loss": 0.0527,
      "step": 53550
    },
    {
      "epoch": 1.0710714714234293,
      "grad_norm": 0.05750194564461708,
      "learning_rate": 3.215547467637217e-05,
      "loss": 0.0826,
      "step": 53560
    },
    {
      "epoch": 1.0712714474263088,
      "grad_norm": 0.1505240648984909,
      "learning_rate": 3.2152141742990846e-05,
      "loss": 0.0795,
      "step": 53570
    },
    {
      "epoch": 1.0714714234291884,
      "grad_norm": 0.16183800995349884,
      "learning_rate": 3.2148808809609515e-05,
      "loss": 0.0935,
      "step": 53580
    },
    {
      "epoch": 1.0716713994320681,
      "grad_norm": 0.16846531629562378,
      "learning_rate": 3.2145475876228185e-05,
      "loss": 0.0541,
      "step": 53590
    },
    {
      "epoch": 1.0718713754349478,
      "grad_norm": 0.14118070900440216,
      "learning_rate": 3.214214294284686e-05,
      "loss": 0.0844,
      "step": 53600
    },
    {
      "epoch": 1.0720713514378275,
      "grad_norm": 0.12561237812042236,
      "learning_rate": 3.213881000946553e-05,
      "loss": 0.0911,
      "step": 53610
    },
    {
      "epoch": 1.0722713274407072,
      "grad_norm": 0.10656417906284332,
      "learning_rate": 3.21354770760842e-05,
      "loss": 0.0909,
      "step": 53620
    },
    {
      "epoch": 1.0724713034435869,
      "grad_norm": 0.10857173055410385,
      "learning_rate": 3.213214414270288e-05,
      "loss": 0.0737,
      "step": 53630
    },
    {
      "epoch": 1.0726712794464663,
      "grad_norm": 0.14878961443901062,
      "learning_rate": 3.212881120932155e-05,
      "loss": 0.0816,
      "step": 53640
    },
    {
      "epoch": 1.072871255449346,
      "grad_norm": 0.08320644497871399,
      "learning_rate": 3.212547827594022e-05,
      "loss": 0.0388,
      "step": 53650
    },
    {
      "epoch": 1.0730712314522257,
      "grad_norm": 0.06466897577047348,
      "learning_rate": 3.212214534255889e-05,
      "loss": 0.0795,
      "step": 53660
    },
    {
      "epoch": 1.0732712074551054,
      "grad_norm": 0.20952662825584412,
      "learning_rate": 3.211881240917757e-05,
      "loss": 0.0663,
      "step": 53670
    },
    {
      "epoch": 1.073471183457985,
      "grad_norm": 0.12254465371370316,
      "learning_rate": 3.211547947579624e-05,
      "loss": 0.0877,
      "step": 53680
    },
    {
      "epoch": 1.0736711594608648,
      "grad_norm": 0.13065017759799957,
      "learning_rate": 3.211214654241491e-05,
      "loss": 0.0779,
      "step": 53690
    },
    {
      "epoch": 1.0738711354637442,
      "grad_norm": 0.07761520147323608,
      "learning_rate": 3.2108813609033585e-05,
      "loss": 0.0797,
      "step": 53700
    },
    {
      "epoch": 1.074071111466624,
      "grad_norm": 0.06974032521247864,
      "learning_rate": 3.2105480675652254e-05,
      "loss": 0.0612,
      "step": 53710
    },
    {
      "epoch": 1.0742710874695036,
      "grad_norm": 0.3089946210384369,
      "learning_rate": 3.210214774227093e-05,
      "loss": 0.1248,
      "step": 53720
    },
    {
      "epoch": 1.0744710634723833,
      "grad_norm": 0.09215149283409119,
      "learning_rate": 3.20988148088896e-05,
      "loss": 0.0612,
      "step": 53730
    },
    {
      "epoch": 1.074671039475263,
      "grad_norm": 0.05447498708963394,
      "learning_rate": 3.2095481875508277e-05,
      "loss": 0.0539,
      "step": 53740
    },
    {
      "epoch": 1.0748710154781427,
      "grad_norm": 0.14906547963619232,
      "learning_rate": 3.2092148942126946e-05,
      "loss": 0.0764,
      "step": 53750
    },
    {
      "epoch": 1.0750709914810224,
      "grad_norm": 0.15951891243457794,
      "learning_rate": 3.208881600874562e-05,
      "loss": 0.0721,
      "step": 53760
    },
    {
      "epoch": 1.0752709674839018,
      "grad_norm": 0.051972582936286926,
      "learning_rate": 3.208548307536429e-05,
      "loss": 0.0992,
      "step": 53770
    },
    {
      "epoch": 1.0754709434867815,
      "grad_norm": 0.05469328165054321,
      "learning_rate": 3.208215014198296e-05,
      "loss": 0.0613,
      "step": 53780
    },
    {
      "epoch": 1.0756709194896612,
      "grad_norm": 0.13947434723377228,
      "learning_rate": 3.207881720860164e-05,
      "loss": 0.069,
      "step": 53790
    },
    {
      "epoch": 1.075870895492541,
      "grad_norm": 0.0636751800775528,
      "learning_rate": 3.207548427522031e-05,
      "loss": 0.0894,
      "step": 53800
    },
    {
      "epoch": 1.0760708714954206,
      "grad_norm": 0.11761946231126785,
      "learning_rate": 3.207215134183898e-05,
      "loss": 0.0626,
      "step": 53810
    },
    {
      "epoch": 1.0762708474983003,
      "grad_norm": 0.09076099097728729,
      "learning_rate": 3.2068818408457654e-05,
      "loss": 0.1021,
      "step": 53820
    },
    {
      "epoch": 1.07647082350118,
      "grad_norm": 0.1779361218214035,
      "learning_rate": 3.2065485475076323e-05,
      "loss": 0.0818,
      "step": 53830
    },
    {
      "epoch": 1.0766707995040594,
      "grad_norm": 0.07119186222553253,
      "learning_rate": 3.2062152541695e-05,
      "loss": 0.0527,
      "step": 53840
    },
    {
      "epoch": 1.076870775506939,
      "grad_norm": 0.17065787315368652,
      "learning_rate": 3.205881960831367e-05,
      "loss": 0.1045,
      "step": 53850
    },
    {
      "epoch": 1.0770707515098188,
      "grad_norm": 0.13193689286708832,
      "learning_rate": 3.2055486674932346e-05,
      "loss": 0.0677,
      "step": 53860
    },
    {
      "epoch": 1.0772707275126985,
      "grad_norm": 0.07585933059453964,
      "learning_rate": 3.2052153741551015e-05,
      "loss": 0.0506,
      "step": 53870
    },
    {
      "epoch": 1.0774707035155782,
      "grad_norm": 0.12564218044281006,
      "learning_rate": 3.2048820808169685e-05,
      "loss": 0.0726,
      "step": 53880
    },
    {
      "epoch": 1.0776706795184579,
      "grad_norm": 0.2001614272594452,
      "learning_rate": 3.204548787478836e-05,
      "loss": 0.11,
      "step": 53890
    },
    {
      "epoch": 1.0778706555213375,
      "grad_norm": 0.13038598001003265,
      "learning_rate": 3.204215494140703e-05,
      "loss": 0.0796,
      "step": 53900
    },
    {
      "epoch": 1.078070631524217,
      "grad_norm": 0.19647514820098877,
      "learning_rate": 3.20388220080257e-05,
      "loss": 0.0579,
      "step": 53910
    },
    {
      "epoch": 1.0782706075270967,
      "grad_norm": 0.13658931851387024,
      "learning_rate": 3.203548907464438e-05,
      "loss": 0.2026,
      "step": 53920
    },
    {
      "epoch": 1.0784705835299764,
      "grad_norm": 0.0634387731552124,
      "learning_rate": 3.203215614126305e-05,
      "loss": 0.0874,
      "step": 53930
    },
    {
      "epoch": 1.078670559532856,
      "grad_norm": 0.2034030556678772,
      "learning_rate": 3.2028823207881716e-05,
      "loss": 0.0528,
      "step": 53940
    },
    {
      "epoch": 1.0788705355357358,
      "grad_norm": 0.1126052737236023,
      "learning_rate": 3.20254902745004e-05,
      "loss": 0.0441,
      "step": 53950
    },
    {
      "epoch": 1.0790705115386154,
      "grad_norm": 0.11184245347976685,
      "learning_rate": 3.202215734111907e-05,
      "loss": 0.064,
      "step": 53960
    },
    {
      "epoch": 1.079270487541495,
      "grad_norm": 0.11028437316417694,
      "learning_rate": 3.201882440773774e-05,
      "loss": 0.0748,
      "step": 53970
    },
    {
      "epoch": 1.0794704635443746,
      "grad_norm": 0.18208952248096466,
      "learning_rate": 3.2015491474356415e-05,
      "loss": 0.1153,
      "step": 53980
    },
    {
      "epoch": 1.0796704395472543,
      "grad_norm": 0.13688750565052032,
      "learning_rate": 3.2012158540975085e-05,
      "loss": 0.0747,
      "step": 53990
    },
    {
      "epoch": 1.079870415550134,
      "grad_norm": 0.16494153439998627,
      "learning_rate": 3.2008825607593754e-05,
      "loss": 0.0628,
      "step": 54000
    },
    {
      "epoch": 1.0800703915530137,
      "grad_norm": 0.11072662472724915,
      "learning_rate": 3.200549267421243e-05,
      "loss": 0.0754,
      "step": 54010
    },
    {
      "epoch": 1.0802703675558933,
      "grad_norm": 0.21345049142837524,
      "learning_rate": 3.20021597408311e-05,
      "loss": 0.0945,
      "step": 54020
    },
    {
      "epoch": 1.080470343558773,
      "grad_norm": 0.18792220950126648,
      "learning_rate": 3.199882680744977e-05,
      "loss": 0.083,
      "step": 54030
    },
    {
      "epoch": 1.0806703195616527,
      "grad_norm": 0.09759646654129028,
      "learning_rate": 3.1995493874068446e-05,
      "loss": 0.0972,
      "step": 54040
    },
    {
      "epoch": 1.0808702955645322,
      "grad_norm": 0.17607450485229492,
      "learning_rate": 3.199216094068712e-05,
      "loss": 0.0763,
      "step": 54050
    },
    {
      "epoch": 1.0810702715674119,
      "grad_norm": 0.07452520728111267,
      "learning_rate": 3.198882800730579e-05,
      "loss": 0.0316,
      "step": 54060
    },
    {
      "epoch": 1.0812702475702916,
      "grad_norm": 0.10261669009923935,
      "learning_rate": 3.198549507392446e-05,
      "loss": 0.0826,
      "step": 54070
    },
    {
      "epoch": 1.0814702235731712,
      "grad_norm": 0.12711568176746368,
      "learning_rate": 3.198216214054314e-05,
      "loss": 0.0637,
      "step": 54080
    },
    {
      "epoch": 1.081670199576051,
      "grad_norm": 0.19109424948692322,
      "learning_rate": 3.197882920716181e-05,
      "loss": 0.0903,
      "step": 54090
    },
    {
      "epoch": 1.0818701755789306,
      "grad_norm": 0.08339022099971771,
      "learning_rate": 3.197549627378048e-05,
      "loss": 0.0946,
      "step": 54100
    },
    {
      "epoch": 1.08207015158181,
      "grad_norm": 0.10160181671380997,
      "learning_rate": 3.1972163340399154e-05,
      "loss": 0.0542,
      "step": 54110
    },
    {
      "epoch": 1.0822701275846898,
      "grad_norm": 0.08029511570930481,
      "learning_rate": 3.1968830407017824e-05,
      "loss": 0.064,
      "step": 54120
    },
    {
      "epoch": 1.0824701035875695,
      "grad_norm": 0.15048351883888245,
      "learning_rate": 3.196549747363649e-05,
      "loss": 0.063,
      "step": 54130
    },
    {
      "epoch": 1.0826700795904491,
      "grad_norm": 0.05083061382174492,
      "learning_rate": 3.196216454025517e-05,
      "loss": 0.0669,
      "step": 54140
    },
    {
      "epoch": 1.0828700555933288,
      "grad_norm": 0.2776014506816864,
      "learning_rate": 3.1958831606873846e-05,
      "loss": 0.124,
      "step": 54150
    },
    {
      "epoch": 1.0830700315962085,
      "grad_norm": 0.0539444237947464,
      "learning_rate": 3.1955498673492516e-05,
      "loss": 0.0814,
      "step": 54160
    },
    {
      "epoch": 1.0832700075990882,
      "grad_norm": 0.19517602026462555,
      "learning_rate": 3.195216574011119e-05,
      "loss": 0.115,
      "step": 54170
    },
    {
      "epoch": 1.0834699836019677,
      "grad_norm": 0.10841374099254608,
      "learning_rate": 3.194883280672986e-05,
      "loss": 0.068,
      "step": 54180
    },
    {
      "epoch": 1.0836699596048474,
      "grad_norm": 0.08221937716007233,
      "learning_rate": 3.194549987334853e-05,
      "loss": 0.0714,
      "step": 54190
    },
    {
      "epoch": 1.083869935607727,
      "grad_norm": 0.13053646683692932,
      "learning_rate": 3.194216693996721e-05,
      "loss": 0.0843,
      "step": 54200
    },
    {
      "epoch": 1.0840699116106067,
      "grad_norm": 0.12924261391162872,
      "learning_rate": 3.193883400658588e-05,
      "loss": 0.0745,
      "step": 54210
    },
    {
      "epoch": 1.0842698876134864,
      "grad_norm": 0.1625155508518219,
      "learning_rate": 3.193550107320455e-05,
      "loss": 0.066,
      "step": 54220
    },
    {
      "epoch": 1.084469863616366,
      "grad_norm": 0.11832503229379654,
      "learning_rate": 3.193216813982322e-05,
      "loss": 0.072,
      "step": 54230
    },
    {
      "epoch": 1.0846698396192458,
      "grad_norm": 0.09023363888263702,
      "learning_rate": 3.192883520644189e-05,
      "loss": 0.0807,
      "step": 54240
    },
    {
      "epoch": 1.0848698156221253,
      "grad_norm": 0.2780570983886719,
      "learning_rate": 3.192550227306057e-05,
      "loss": 0.0993,
      "step": 54250
    },
    {
      "epoch": 1.085069791625005,
      "grad_norm": 0.08429165184497833,
      "learning_rate": 3.192216933967924e-05,
      "loss": 0.0778,
      "step": 54260
    },
    {
      "epoch": 1.0852697676278846,
      "grad_norm": 0.1789531260728836,
      "learning_rate": 3.1918836406297915e-05,
      "loss": 0.1027,
      "step": 54270
    },
    {
      "epoch": 1.0854697436307643,
      "grad_norm": 0.1439245343208313,
      "learning_rate": 3.1915503472916585e-05,
      "loss": 0.077,
      "step": 54280
    },
    {
      "epoch": 1.085669719633644,
      "grad_norm": 0.11624525487422943,
      "learning_rate": 3.1912170539535254e-05,
      "loss": 0.0758,
      "step": 54290
    },
    {
      "epoch": 1.0858696956365237,
      "grad_norm": 0.14604106545448303,
      "learning_rate": 3.190883760615393e-05,
      "loss": 0.0576,
      "step": 54300
    },
    {
      "epoch": 1.0860696716394034,
      "grad_norm": 0.17309653759002686,
      "learning_rate": 3.19055046727726e-05,
      "loss": 0.1197,
      "step": 54310
    },
    {
      "epoch": 1.0862696476422828,
      "grad_norm": 0.1769455224275589,
      "learning_rate": 3.190217173939127e-05,
      "loss": 0.1119,
      "step": 54320
    },
    {
      "epoch": 1.0864696236451625,
      "grad_norm": 0.08283880352973938,
      "learning_rate": 3.1898838806009946e-05,
      "loss": 0.1038,
      "step": 54330
    },
    {
      "epoch": 1.0866695996480422,
      "grad_norm": 0.18337291479110718,
      "learning_rate": 3.1895505872628616e-05,
      "loss": 0.0683,
      "step": 54340
    },
    {
      "epoch": 1.086869575650922,
      "grad_norm": 0.18401673436164856,
      "learning_rate": 3.189217293924729e-05,
      "loss": 0.0962,
      "step": 54350
    },
    {
      "epoch": 1.0870695516538016,
      "grad_norm": 0.17351534962654114,
      "learning_rate": 3.188884000586597e-05,
      "loss": 0.1048,
      "step": 54360
    },
    {
      "epoch": 1.0872695276566813,
      "grad_norm": 0.18994556367397308,
      "learning_rate": 3.188550707248464e-05,
      "loss": 0.0756,
      "step": 54370
    },
    {
      "epoch": 1.0874695036595607,
      "grad_norm": 0.16855844855308533,
      "learning_rate": 3.188217413910331e-05,
      "loss": 0.4737,
      "step": 54380
    },
    {
      "epoch": 1.0876694796624404,
      "grad_norm": 0.23437248170375824,
      "learning_rate": 3.1878841205721985e-05,
      "loss": 0.0713,
      "step": 54390
    },
    {
      "epoch": 1.0878694556653201,
      "grad_norm": 0.16935746371746063,
      "learning_rate": 3.1875508272340654e-05,
      "loss": 0.0936,
      "step": 54400
    },
    {
      "epoch": 1.0880694316681998,
      "grad_norm": 0.14746223390102386,
      "learning_rate": 3.1872175338959324e-05,
      "loss": 0.0889,
      "step": 54410
    },
    {
      "epoch": 1.0882694076710795,
      "grad_norm": 0.2014106661081314,
      "learning_rate": 3.1868842405578e-05,
      "loss": 0.0778,
      "step": 54420
    },
    {
      "epoch": 1.0884693836739592,
      "grad_norm": 0.08401656895875931,
      "learning_rate": 3.186550947219667e-05,
      "loss": 0.052,
      "step": 54430
    },
    {
      "epoch": 1.0886693596768389,
      "grad_norm": 0.11026536673307419,
      "learning_rate": 3.186217653881534e-05,
      "loss": 0.0476,
      "step": 54440
    },
    {
      "epoch": 1.0888693356797183,
      "grad_norm": 0.22547303140163422,
      "learning_rate": 3.1858843605434016e-05,
      "loss": 0.0929,
      "step": 54450
    },
    {
      "epoch": 1.089069311682598,
      "grad_norm": 0.09178591519594193,
      "learning_rate": 3.185551067205269e-05,
      "loss": 0.1019,
      "step": 54460
    },
    {
      "epoch": 1.0892692876854777,
      "grad_norm": 0.20888687670230865,
      "learning_rate": 3.185217773867136e-05,
      "loss": 0.1045,
      "step": 54470
    },
    {
      "epoch": 1.0894692636883574,
      "grad_norm": 0.07057124376296997,
      "learning_rate": 3.184884480529003e-05,
      "loss": 0.067,
      "step": 54480
    },
    {
      "epoch": 1.089669239691237,
      "grad_norm": 0.10748741775751114,
      "learning_rate": 3.184551187190871e-05,
      "loss": 0.0463,
      "step": 54490
    },
    {
      "epoch": 1.0898692156941168,
      "grad_norm": 0.12493991106748581,
      "learning_rate": 3.184217893852738e-05,
      "loss": 0.0588,
      "step": 54500
    },
    {
      "epoch": 1.0900691916969965,
      "grad_norm": 0.21437600255012512,
      "learning_rate": 3.183884600514605e-05,
      "loss": 0.088,
      "step": 54510
    },
    {
      "epoch": 1.090269167699876,
      "grad_norm": 0.14280694723129272,
      "learning_rate": 3.1835513071764723e-05,
      "loss": 0.0914,
      "step": 54520
    },
    {
      "epoch": 1.0904691437027556,
      "grad_norm": 0.21054422855377197,
      "learning_rate": 3.183218013838339e-05,
      "loss": 0.0781,
      "step": 54530
    },
    {
      "epoch": 1.0906691197056353,
      "grad_norm": 0.14872623980045319,
      "learning_rate": 3.182884720500206e-05,
      "loss": 0.0625,
      "step": 54540
    },
    {
      "epoch": 1.090869095708515,
      "grad_norm": 0.16625960171222687,
      "learning_rate": 3.182551427162074e-05,
      "loss": 0.0717,
      "step": 54550
    },
    {
      "epoch": 1.0910690717113947,
      "grad_norm": 0.19113771617412567,
      "learning_rate": 3.1822181338239415e-05,
      "loss": 0.0736,
      "step": 54560
    },
    {
      "epoch": 1.0912690477142744,
      "grad_norm": 0.12850254774093628,
      "learning_rate": 3.1818848404858085e-05,
      "loss": 0.0868,
      "step": 54570
    },
    {
      "epoch": 1.091469023717154,
      "grad_norm": 0.19221831858158112,
      "learning_rate": 3.181551547147676e-05,
      "loss": 0.0778,
      "step": 54580
    },
    {
      "epoch": 1.0916689997200335,
      "grad_norm": 0.1494840830564499,
      "learning_rate": 3.181218253809543e-05,
      "loss": 0.0717,
      "step": 54590
    },
    {
      "epoch": 1.0918689757229132,
      "grad_norm": 0.10059799998998642,
      "learning_rate": 3.18088496047141e-05,
      "loss": 0.0776,
      "step": 54600
    },
    {
      "epoch": 1.0920689517257929,
      "grad_norm": 0.08357682824134827,
      "learning_rate": 3.180551667133278e-05,
      "loss": 0.0629,
      "step": 54610
    },
    {
      "epoch": 1.0922689277286726,
      "grad_norm": 0.0872940868139267,
      "learning_rate": 3.180218373795145e-05,
      "loss": 0.0717,
      "step": 54620
    },
    {
      "epoch": 1.0924689037315523,
      "grad_norm": 0.2100585550069809,
      "learning_rate": 3.1798850804570116e-05,
      "loss": 0.0591,
      "step": 54630
    },
    {
      "epoch": 1.092668879734432,
      "grad_norm": 0.11232303828001022,
      "learning_rate": 3.179551787118879e-05,
      "loss": 0.0644,
      "step": 54640
    },
    {
      "epoch": 1.0928688557373114,
      "grad_norm": 0.10229422897100449,
      "learning_rate": 3.179218493780746e-05,
      "loss": 0.0648,
      "step": 54650
    },
    {
      "epoch": 1.093068831740191,
      "grad_norm": 0.1526440680027008,
      "learning_rate": 3.178885200442614e-05,
      "loss": 0.0685,
      "step": 54660
    },
    {
      "epoch": 1.0932688077430708,
      "grad_norm": 0.14652574062347412,
      "learning_rate": 3.178551907104481e-05,
      "loss": 0.0744,
      "step": 54670
    },
    {
      "epoch": 1.0934687837459505,
      "grad_norm": 0.16062740981578827,
      "learning_rate": 3.1782186137663485e-05,
      "loss": 0.0696,
      "step": 54680
    },
    {
      "epoch": 1.0936687597488302,
      "grad_norm": 0.08786719292402267,
      "learning_rate": 3.1778853204282154e-05,
      "loss": 0.0862,
      "step": 54690
    },
    {
      "epoch": 1.0938687357517098,
      "grad_norm": 0.06902164965867996,
      "learning_rate": 3.1775520270900824e-05,
      "loss": 0.076,
      "step": 54700
    },
    {
      "epoch": 1.0940687117545895,
      "grad_norm": 0.13072232902050018,
      "learning_rate": 3.17721873375195e-05,
      "loss": 0.094,
      "step": 54710
    },
    {
      "epoch": 1.0942686877574692,
      "grad_norm": 0.10922913998365402,
      "learning_rate": 3.176885440413817e-05,
      "loss": 0.1099,
      "step": 54720
    },
    {
      "epoch": 1.0944686637603487,
      "grad_norm": 0.15344227850437164,
      "learning_rate": 3.176552147075684e-05,
      "loss": 0.0906,
      "step": 54730
    },
    {
      "epoch": 1.0946686397632284,
      "grad_norm": 0.07876672595739365,
      "learning_rate": 3.1762188537375516e-05,
      "loss": 0.0891,
      "step": 54740
    },
    {
      "epoch": 1.094868615766108,
      "grad_norm": 0.054908718913793564,
      "learning_rate": 3.1758855603994186e-05,
      "loss": 0.0625,
      "step": 54750
    },
    {
      "epoch": 1.0950685917689877,
      "grad_norm": 0.12923066318035126,
      "learning_rate": 3.175552267061286e-05,
      "loss": 0.0602,
      "step": 54760
    },
    {
      "epoch": 1.0952685677718674,
      "grad_norm": 0.14071115851402283,
      "learning_rate": 3.175218973723154e-05,
      "loss": 0.0944,
      "step": 54770
    },
    {
      "epoch": 1.0954685437747471,
      "grad_norm": 0.1514071226119995,
      "learning_rate": 3.174885680385021e-05,
      "loss": 0.2595,
      "step": 54780
    },
    {
      "epoch": 1.0956685197776266,
      "grad_norm": 0.14813123643398285,
      "learning_rate": 3.174552387046888e-05,
      "loss": 0.0784,
      "step": 54790
    },
    {
      "epoch": 1.0958684957805063,
      "grad_norm": 0.07080449908971786,
      "learning_rate": 3.1742190937087554e-05,
      "loss": 0.0808,
      "step": 54800
    },
    {
      "epoch": 1.096068471783386,
      "grad_norm": 0.18373429775238037,
      "learning_rate": 3.1738858003706224e-05,
      "loss": 0.0767,
      "step": 54810
    },
    {
      "epoch": 1.0962684477862656,
      "grad_norm": 0.05906548723578453,
      "learning_rate": 3.173552507032489e-05,
      "loss": 0.0818,
      "step": 54820
    },
    {
      "epoch": 1.0964684237891453,
      "grad_norm": 0.08572366088628769,
      "learning_rate": 3.173219213694357e-05,
      "loss": 0.0736,
      "step": 54830
    },
    {
      "epoch": 1.096668399792025,
      "grad_norm": 0.06624271720647812,
      "learning_rate": 3.172885920356224e-05,
      "loss": 0.0643,
      "step": 54840
    },
    {
      "epoch": 1.0968683757949047,
      "grad_norm": 0.12578745186328888,
      "learning_rate": 3.172552627018091e-05,
      "loss": 0.0485,
      "step": 54850
    },
    {
      "epoch": 1.0970683517977842,
      "grad_norm": 0.06849747151136398,
      "learning_rate": 3.1722193336799585e-05,
      "loss": 0.0686,
      "step": 54860
    },
    {
      "epoch": 1.0972683278006639,
      "grad_norm": 0.11560732126235962,
      "learning_rate": 3.171886040341826e-05,
      "loss": 0.0996,
      "step": 54870
    },
    {
      "epoch": 1.0974683038035435,
      "grad_norm": 0.20947980880737305,
      "learning_rate": 3.171552747003693e-05,
      "loss": 0.0707,
      "step": 54880
    },
    {
      "epoch": 1.0976682798064232,
      "grad_norm": 0.09123773872852325,
      "learning_rate": 3.17121945366556e-05,
      "loss": 0.0651,
      "step": 54890
    },
    {
      "epoch": 1.097868255809303,
      "grad_norm": 0.22761014103889465,
      "learning_rate": 3.170886160327428e-05,
      "loss": 0.0936,
      "step": 54900
    },
    {
      "epoch": 1.0980682318121826,
      "grad_norm": 0.20685343444347382,
      "learning_rate": 3.170552866989295e-05,
      "loss": 0.0772,
      "step": 54910
    },
    {
      "epoch": 1.0982682078150623,
      "grad_norm": 0.13607299327850342,
      "learning_rate": 3.1702195736511616e-05,
      "loss": 0.0831,
      "step": 54920
    },
    {
      "epoch": 1.0984681838179418,
      "grad_norm": 0.09268857538700104,
      "learning_rate": 3.169886280313029e-05,
      "loss": 0.0582,
      "step": 54930
    },
    {
      "epoch": 1.0986681598208214,
      "grad_norm": 0.14963743090629578,
      "learning_rate": 3.169552986974896e-05,
      "loss": 0.0652,
      "step": 54940
    },
    {
      "epoch": 1.0988681358237011,
      "grad_norm": 0.13847492635250092,
      "learning_rate": 3.169219693636763e-05,
      "loss": 0.0829,
      "step": 54950
    },
    {
      "epoch": 1.0990681118265808,
      "grad_norm": 0.1163073480129242,
      "learning_rate": 3.168886400298631e-05,
      "loss": 0.0688,
      "step": 54960
    },
    {
      "epoch": 1.0992680878294605,
      "grad_norm": 0.1258089542388916,
      "learning_rate": 3.1685531069604985e-05,
      "loss": 0.0734,
      "step": 54970
    },
    {
      "epoch": 1.0994680638323402,
      "grad_norm": 0.07886069267988205,
      "learning_rate": 3.1682198136223654e-05,
      "loss": 0.0669,
      "step": 54980
    },
    {
      "epoch": 1.0996680398352199,
      "grad_norm": 0.15269437432289124,
      "learning_rate": 3.167886520284233e-05,
      "loss": 0.0825,
      "step": 54990
    },
    {
      "epoch": 1.0998680158380993,
      "grad_norm": 0.129420205950737,
      "learning_rate": 3.1675532269461e-05,
      "loss": 0.0805,
      "step": 55000
    },
    {
      "epoch": 1.100067991840979,
      "grad_norm": 0.10422049462795258,
      "learning_rate": 3.167219933607967e-05,
      "loss": 0.0771,
      "step": 55010
    },
    {
      "epoch": 1.1002679678438587,
      "grad_norm": 0.1966528445482254,
      "learning_rate": 3.1668866402698347e-05,
      "loss": 0.0837,
      "step": 55020
    },
    {
      "epoch": 1.1004679438467384,
      "grad_norm": 0.14196202158927917,
      "learning_rate": 3.1665533469317016e-05,
      "loss": 0.1123,
      "step": 55030
    },
    {
      "epoch": 1.100667919849618,
      "grad_norm": 0.16350872814655304,
      "learning_rate": 3.1662200535935686e-05,
      "loss": 0.093,
      "step": 55040
    },
    {
      "epoch": 1.1008678958524978,
      "grad_norm": 0.1010027751326561,
      "learning_rate": 3.165886760255436e-05,
      "loss": 0.0515,
      "step": 55050
    },
    {
      "epoch": 1.1010678718553772,
      "grad_norm": 0.20915241539478302,
      "learning_rate": 3.165553466917303e-05,
      "loss": 0.0552,
      "step": 55060
    },
    {
      "epoch": 1.101267847858257,
      "grad_norm": 0.19400838017463684,
      "learning_rate": 3.165220173579171e-05,
      "loss": 0.0957,
      "step": 55070
    },
    {
      "epoch": 1.1014678238611366,
      "grad_norm": 0.1371614784002304,
      "learning_rate": 3.164886880241038e-05,
      "loss": 0.1023,
      "step": 55080
    },
    {
      "epoch": 1.1016677998640163,
      "grad_norm": 0.18014517426490784,
      "learning_rate": 3.1645535869029054e-05,
      "loss": 0.0766,
      "step": 55090
    },
    {
      "epoch": 1.101867775866896,
      "grad_norm": 0.1302844136953354,
      "learning_rate": 3.1642202935647724e-05,
      "loss": 0.073,
      "step": 55100
    },
    {
      "epoch": 1.1020677518697757,
      "grad_norm": 0.09992795437574387,
      "learning_rate": 3.163887000226639e-05,
      "loss": 0.0362,
      "step": 55110
    },
    {
      "epoch": 1.1022677278726554,
      "grad_norm": 0.11129862070083618,
      "learning_rate": 3.163553706888507e-05,
      "loss": 0.0498,
      "step": 55120
    },
    {
      "epoch": 1.1024677038755348,
      "grad_norm": 0.05991688743233681,
      "learning_rate": 3.163220413550374e-05,
      "loss": 0.054,
      "step": 55130
    },
    {
      "epoch": 1.1026676798784145,
      "grad_norm": 0.15524922311306,
      "learning_rate": 3.162887120212241e-05,
      "loss": 0.1181,
      "step": 55140
    },
    {
      "epoch": 1.1028676558812942,
      "grad_norm": 0.07551531493663788,
      "learning_rate": 3.1625538268741085e-05,
      "loss": 0.0986,
      "step": 55150
    },
    {
      "epoch": 1.103067631884174,
      "grad_norm": 0.07915569096803665,
      "learning_rate": 3.1622205335359755e-05,
      "loss": 0.0638,
      "step": 55160
    },
    {
      "epoch": 1.1032676078870536,
      "grad_norm": 0.15400929749011993,
      "learning_rate": 3.161887240197843e-05,
      "loss": 0.0691,
      "step": 55170
    },
    {
      "epoch": 1.1034675838899333,
      "grad_norm": 0.207919180393219,
      "learning_rate": 3.161553946859711e-05,
      "loss": 0.0689,
      "step": 55180
    },
    {
      "epoch": 1.103667559892813,
      "grad_norm": 0.1668563187122345,
      "learning_rate": 3.161220653521578e-05,
      "loss": 0.074,
      "step": 55190
    },
    {
      "epoch": 1.1038675358956924,
      "grad_norm": 0.10453830659389496,
      "learning_rate": 3.160887360183445e-05,
      "loss": 0.0593,
      "step": 55200
    },
    {
      "epoch": 1.104067511898572,
      "grad_norm": 0.12951095402240753,
      "learning_rate": 3.1605540668453123e-05,
      "loss": 0.0564,
      "step": 55210
    },
    {
      "epoch": 1.1042674879014518,
      "grad_norm": 0.10235051810741425,
      "learning_rate": 3.160220773507179e-05,
      "loss": 0.0772,
      "step": 55220
    },
    {
      "epoch": 1.1044674639043315,
      "grad_norm": 0.09773743152618408,
      "learning_rate": 3.159887480169046e-05,
      "loss": 0.0644,
      "step": 55230
    },
    {
      "epoch": 1.1046674399072112,
      "grad_norm": 0.14838659763336182,
      "learning_rate": 3.159554186830914e-05,
      "loss": 0.0836,
      "step": 55240
    },
    {
      "epoch": 1.1048674159100909,
      "grad_norm": 0.21976520121097565,
      "learning_rate": 3.159220893492781e-05,
      "loss": 0.0891,
      "step": 55250
    },
    {
      "epoch": 1.1050673919129705,
      "grad_norm": 0.08297992497682571,
      "learning_rate": 3.158887600154648e-05,
      "loss": 0.0421,
      "step": 55260
    },
    {
      "epoch": 1.10526736791585,
      "grad_norm": 0.14400911331176758,
      "learning_rate": 3.1585543068165155e-05,
      "loss": 0.0704,
      "step": 55270
    },
    {
      "epoch": 1.1054673439187297,
      "grad_norm": 0.1350008249282837,
      "learning_rate": 3.158221013478383e-05,
      "loss": 0.0754,
      "step": 55280
    },
    {
      "epoch": 1.1056673199216094,
      "grad_norm": 0.22050218284130096,
      "learning_rate": 3.15788772014025e-05,
      "loss": 0.0946,
      "step": 55290
    },
    {
      "epoch": 1.105867295924489,
      "grad_norm": 0.1957608461380005,
      "learning_rate": 3.157554426802117e-05,
      "loss": 0.0956,
      "step": 55300
    },
    {
      "epoch": 1.1060672719273688,
      "grad_norm": 0.03678944334387779,
      "learning_rate": 3.157221133463985e-05,
      "loss": 0.0652,
      "step": 55310
    },
    {
      "epoch": 1.1062672479302484,
      "grad_norm": 0.1530638039112091,
      "learning_rate": 3.1568878401258516e-05,
      "loss": 0.0541,
      "step": 55320
    },
    {
      "epoch": 1.106467223933128,
      "grad_norm": 0.24107052385807037,
      "learning_rate": 3.1565545467877186e-05,
      "loss": 0.0896,
      "step": 55330
    },
    {
      "epoch": 1.1066671999360076,
      "grad_norm": 0.14803753793239594,
      "learning_rate": 3.156221253449586e-05,
      "loss": 0.0981,
      "step": 55340
    },
    {
      "epoch": 1.1068671759388873,
      "grad_norm": 0.05728146806359291,
      "learning_rate": 3.155887960111453e-05,
      "loss": 0.0477,
      "step": 55350
    },
    {
      "epoch": 1.107067151941767,
      "grad_norm": 0.11998527497053146,
      "learning_rate": 3.15555466677332e-05,
      "loss": 0.0549,
      "step": 55360
    },
    {
      "epoch": 1.1072671279446467,
      "grad_norm": 0.1389169692993164,
      "learning_rate": 3.1552213734351885e-05,
      "loss": 0.0655,
      "step": 55370
    },
    {
      "epoch": 1.1074671039475263,
      "grad_norm": 0.061662930995225906,
      "learning_rate": 3.1548880800970554e-05,
      "loss": 0.0557,
      "step": 55380
    },
    {
      "epoch": 1.107667079950406,
      "grad_norm": 0.13918757438659668,
      "learning_rate": 3.1545547867589224e-05,
      "loss": 0.039,
      "step": 55390
    },
    {
      "epoch": 1.1078670559532857,
      "grad_norm": 0.08497423678636551,
      "learning_rate": 3.15422149342079e-05,
      "loss": 0.0566,
      "step": 55400
    },
    {
      "epoch": 1.1080670319561652,
      "grad_norm": 0.19248250126838684,
      "learning_rate": 3.153888200082657e-05,
      "loss": 0.0846,
      "step": 55410
    },
    {
      "epoch": 1.1082670079590449,
      "grad_norm": 0.1679060161113739,
      "learning_rate": 3.153554906744524e-05,
      "loss": 0.0601,
      "step": 55420
    },
    {
      "epoch": 1.1084669839619246,
      "grad_norm": 0.19442327320575714,
      "learning_rate": 3.1532216134063916e-05,
      "loss": 0.0762,
      "step": 55430
    },
    {
      "epoch": 1.1086669599648042,
      "grad_norm": 0.15499085187911987,
      "learning_rate": 3.1528883200682586e-05,
      "loss": 0.0755,
      "step": 55440
    },
    {
      "epoch": 1.108866935967684,
      "grad_norm": 0.06588034331798553,
      "learning_rate": 3.1525550267301255e-05,
      "loss": 0.049,
      "step": 55450
    },
    {
      "epoch": 1.1090669119705636,
      "grad_norm": 0.09363621473312378,
      "learning_rate": 3.152221733391993e-05,
      "loss": 0.0619,
      "step": 55460
    },
    {
      "epoch": 1.109266887973443,
      "grad_norm": NaN,
      "learning_rate": 3.15188844005386e-05,
      "loss": 0.1365,
      "step": 55470
    },
    {
      "epoch": 1.1094668639763228,
      "grad_norm": 0.07606390118598938,
      "learning_rate": 3.151588476049541e-05,
      "loss": 0.0626,
      "step": 55480
    },
    {
      "epoch": 1.1096668399792025,
      "grad_norm": 0.11434033513069153,
      "learning_rate": 3.151255182711408e-05,
      "loss": 0.0831,
      "step": 55490
    },
    {
      "epoch": 1.1098668159820821,
      "grad_norm": 0.12350872904062271,
      "learning_rate": 3.1509218893732756e-05,
      "loss": 0.0741,
      "step": 55500
    },
    {
      "epoch": 1.1100667919849618,
      "grad_norm": 0.08638734370470047,
      "learning_rate": 3.1505885960351426e-05,
      "loss": 0.0697,
      "step": 55510
    },
    {
      "epoch": 1.1102667679878415,
      "grad_norm": 0.11518397927284241,
      "learning_rate": 3.15025530269701e-05,
      "loss": 0.0682,
      "step": 55520
    },
    {
      "epoch": 1.1104667439907212,
      "grad_norm": 0.22261711955070496,
      "learning_rate": 3.149922009358877e-05,
      "loss": 0.0656,
      "step": 55530
    },
    {
      "epoch": 1.1106667199936007,
      "grad_norm": 0.11526172608137131,
      "learning_rate": 3.149588716020744e-05,
      "loss": 0.0987,
      "step": 55540
    },
    {
      "epoch": 1.1108666959964804,
      "grad_norm": 0.07485003769397736,
      "learning_rate": 3.149255422682612e-05,
      "loss": 0.0941,
      "step": 55550
    },
    {
      "epoch": 1.11106667199936,
      "grad_norm": 0.16863268613815308,
      "learning_rate": 3.148922129344479e-05,
      "loss": 0.0845,
      "step": 55560
    },
    {
      "epoch": 1.1112666480022397,
      "grad_norm": 0.21312256157398224,
      "learning_rate": 3.148588836006346e-05,
      "loss": 0.0728,
      "step": 55570
    },
    {
      "epoch": 1.1114666240051194,
      "grad_norm": 0.23248623311519623,
      "learning_rate": 3.148255542668213e-05,
      "loss": 0.0674,
      "step": 55580
    },
    {
      "epoch": 1.111666600007999,
      "grad_norm": 0.08302537351846695,
      "learning_rate": 3.14792224933008e-05,
      "loss": 0.0891,
      "step": 55590
    },
    {
      "epoch": 1.1118665760108788,
      "grad_norm": 0.09099145233631134,
      "learning_rate": 3.147588955991948e-05,
      "loss": 0.0609,
      "step": 55600
    },
    {
      "epoch": 1.1120665520137583,
      "grad_norm": 0.1323997527360916,
      "learning_rate": 3.147255662653815e-05,
      "loss": 0.0621,
      "step": 55610
    },
    {
      "epoch": 1.112266528016638,
      "grad_norm": 0.12084309756755829,
      "learning_rate": 3.1469223693156825e-05,
      "loss": 0.0568,
      "step": 55620
    },
    {
      "epoch": 1.1124665040195176,
      "grad_norm": 0.15489228069782257,
      "learning_rate": 3.1465890759775495e-05,
      "loss": 0.1065,
      "step": 55630
    },
    {
      "epoch": 1.1126664800223973,
      "grad_norm": 0.1606098711490631,
      "learning_rate": 3.1462557826394164e-05,
      "loss": 0.0777,
      "step": 55640
    },
    {
      "epoch": 1.112866456025277,
      "grad_norm": 0.08691156655550003,
      "learning_rate": 3.145922489301284e-05,
      "loss": 0.1028,
      "step": 55650
    },
    {
      "epoch": 1.1130664320281567,
      "grad_norm": 0.2036668062210083,
      "learning_rate": 3.145589195963151e-05,
      "loss": 0.1102,
      "step": 55660
    },
    {
      "epoch": 1.1132664080310364,
      "grad_norm": 0.21713222563266754,
      "learning_rate": 3.145255902625018e-05,
      "loss": 0.1241,
      "step": 55670
    },
    {
      "epoch": 1.1134663840339158,
      "grad_norm": 0.07715102285146713,
      "learning_rate": 3.1449226092868856e-05,
      "loss": 0.0681,
      "step": 55680
    },
    {
      "epoch": 1.1136663600367955,
      "grad_norm": 0.09391983598470688,
      "learning_rate": 3.1445893159487526e-05,
      "loss": 0.062,
      "step": 55690
    },
    {
      "epoch": 1.1138663360396752,
      "grad_norm": 0.1740325689315796,
      "learning_rate": 3.14425602261062e-05,
      "loss": 0.0501,
      "step": 55700
    },
    {
      "epoch": 1.114066312042555,
      "grad_norm": 0.09800562262535095,
      "learning_rate": 3.143922729272488e-05,
      "loss": 0.0595,
      "step": 55710
    },
    {
      "epoch": 1.1142662880454346,
      "grad_norm": 0.16377998888492584,
      "learning_rate": 3.143589435934355e-05,
      "loss": 0.084,
      "step": 55720
    },
    {
      "epoch": 1.1144662640483143,
      "grad_norm": 0.23401696979999542,
      "learning_rate": 3.143256142596222e-05,
      "loss": 0.0673,
      "step": 55730
    },
    {
      "epoch": 1.1146662400511937,
      "grad_norm": 0.16416944563388824,
      "learning_rate": 3.1429228492580895e-05,
      "loss": 0.0828,
      "step": 55740
    },
    {
      "epoch": 1.1148662160540734,
      "grad_norm": 0.11215086281299591,
      "learning_rate": 3.1425895559199564e-05,
      "loss": 0.0777,
      "step": 55750
    },
    {
      "epoch": 1.1150661920569531,
      "grad_norm": 0.07323528826236725,
      "learning_rate": 3.1422562625818234e-05,
      "loss": 0.0519,
      "step": 55760
    },
    {
      "epoch": 1.1152661680598328,
      "grad_norm": 0.07063211500644684,
      "learning_rate": 3.141922969243691e-05,
      "loss": 0.0534,
      "step": 55770
    },
    {
      "epoch": 1.1154661440627125,
      "grad_norm": 0.12952134013175964,
      "learning_rate": 3.141589675905558e-05,
      "loss": 0.1054,
      "step": 55780
    },
    {
      "epoch": 1.1156661200655922,
      "grad_norm": 0.1441645622253418,
      "learning_rate": 3.141256382567425e-05,
      "loss": 0.0655,
      "step": 55790
    },
    {
      "epoch": 1.1158660960684719,
      "grad_norm": 0.2072204053401947,
      "learning_rate": 3.1409230892292926e-05,
      "loss": 0.1037,
      "step": 55800
    },
    {
      "epoch": 1.1160660720713513,
      "grad_norm": 0.08251145482063293,
      "learning_rate": 3.14058979589116e-05,
      "loss": 0.1061,
      "step": 55810
    },
    {
      "epoch": 1.116266048074231,
      "grad_norm": 0.12524765729904175,
      "learning_rate": 3.140256502553027e-05,
      "loss": 0.0665,
      "step": 55820
    },
    {
      "epoch": 1.1164660240771107,
      "grad_norm": 0.1254778504371643,
      "learning_rate": 3.139923209214894e-05,
      "loss": 0.0569,
      "step": 55830
    },
    {
      "epoch": 1.1166660000799904,
      "grad_norm": 0.08455735445022583,
      "learning_rate": 3.139589915876762e-05,
      "loss": 0.0668,
      "step": 55840
    },
    {
      "epoch": 1.11686597608287,
      "grad_norm": 0.16231998801231384,
      "learning_rate": 3.139256622538629e-05,
      "loss": 0.055,
      "step": 55850
    },
    {
      "epoch": 1.1170659520857498,
      "grad_norm": 0.2161417454481125,
      "learning_rate": 3.138923329200496e-05,
      "loss": 0.0871,
      "step": 55860
    },
    {
      "epoch": 1.1172659280886295,
      "grad_norm": 0.12273410707712173,
      "learning_rate": 3.1385900358623633e-05,
      "loss": 0.1233,
      "step": 55870
    },
    {
      "epoch": 1.117465904091509,
      "grad_norm": 0.12292952835559845,
      "learning_rate": 3.13825674252423e-05,
      "loss": 0.0827,
      "step": 55880
    },
    {
      "epoch": 1.1176658800943886,
      "grad_norm": 0.09687159210443497,
      "learning_rate": 3.137923449186097e-05,
      "loss": 0.0581,
      "step": 55890
    },
    {
      "epoch": 1.1178658560972683,
      "grad_norm": 0.1676754355430603,
      "learning_rate": 3.137590155847965e-05,
      "loss": 0.0769,
      "step": 55900
    },
    {
      "epoch": 1.118065832100148,
      "grad_norm": 0.23259805142879486,
      "learning_rate": 3.1372568625098325e-05,
      "loss": 0.0876,
      "step": 55910
    },
    {
      "epoch": 1.1182658081030277,
      "grad_norm": 0.1620924323797226,
      "learning_rate": 3.1369235691716995e-05,
      "loss": 0.0837,
      "step": 55920
    },
    {
      "epoch": 1.1184657841059074,
      "grad_norm": 0.2397059202194214,
      "learning_rate": 3.136590275833567e-05,
      "loss": 0.11,
      "step": 55930
    },
    {
      "epoch": 1.118665760108787,
      "grad_norm": 0.0918910801410675,
      "learning_rate": 3.136256982495434e-05,
      "loss": 0.05,
      "step": 55940
    },
    {
      "epoch": 1.1188657361116665,
      "grad_norm": 0.15692101418972015,
      "learning_rate": 3.135923689157301e-05,
      "loss": 0.095,
      "step": 55950
    },
    {
      "epoch": 1.1190657121145462,
      "grad_norm": 0.10291635245084763,
      "learning_rate": 3.135590395819169e-05,
      "loss": 0.0477,
      "step": 55960
    },
    {
      "epoch": 1.1192656881174259,
      "grad_norm": 0.0877145305275917,
      "learning_rate": 3.135257102481036e-05,
      "loss": 0.0781,
      "step": 55970
    },
    {
      "epoch": 1.1194656641203056,
      "grad_norm": 0.15852583944797516,
      "learning_rate": 3.1349238091429026e-05,
      "loss": 0.077,
      "step": 55980
    },
    {
      "epoch": 1.1196656401231853,
      "grad_norm": 0.07975386828184128,
      "learning_rate": 3.13459051580477e-05,
      "loss": 0.0883,
      "step": 55990
    },
    {
      "epoch": 1.119865616126065,
      "grad_norm": 0.13948772847652435,
      "learning_rate": 3.134257222466637e-05,
      "loss": 0.1277,
      "step": 56000
    },
    {
      "epoch": 1.1200655921289444,
      "grad_norm": 0.10291888564825058,
      "learning_rate": 3.133923929128505e-05,
      "loss": 0.076,
      "step": 56010
    },
    {
      "epoch": 1.120265568131824,
      "grad_norm": 0.12599778175354004,
      "learning_rate": 3.133590635790372e-05,
      "loss": 0.0429,
      "step": 56020
    },
    {
      "epoch": 1.1204655441347038,
      "grad_norm": 0.14164260029792786,
      "learning_rate": 3.1332573424522395e-05,
      "loss": 0.1253,
      "step": 56030
    },
    {
      "epoch": 1.1206655201375835,
      "grad_norm": 0.07350661605596542,
      "learning_rate": 3.1329240491141064e-05,
      "loss": 0.0495,
      "step": 56040
    },
    {
      "epoch": 1.1208654961404632,
      "grad_norm": 0.21875864267349243,
      "learning_rate": 3.1325907557759734e-05,
      "loss": 0.1377,
      "step": 56050
    },
    {
      "epoch": 1.1210654721433428,
      "grad_norm": 0.2107401341199875,
      "learning_rate": 3.132257462437841e-05,
      "loss": 0.1246,
      "step": 56060
    },
    {
      "epoch": 1.1212654481462225,
      "grad_norm": 0.05737525224685669,
      "learning_rate": 3.131924169099708e-05,
      "loss": 0.0451,
      "step": 56070
    },
    {
      "epoch": 1.1214654241491022,
      "grad_norm": 0.12868022918701172,
      "learning_rate": 3.131590875761575e-05,
      "loss": 0.0731,
      "step": 56080
    },
    {
      "epoch": 1.1216654001519817,
      "grad_norm": 0.07545517385005951,
      "learning_rate": 3.1312575824234426e-05,
      "loss": 0.0705,
      "step": 56090
    },
    {
      "epoch": 1.1218653761548614,
      "grad_norm": 0.13934510946273804,
      "learning_rate": 3.1309242890853096e-05,
      "loss": 0.0837,
      "step": 56100
    },
    {
      "epoch": 1.122065352157741,
      "grad_norm": 0.09463024884462357,
      "learning_rate": 3.130590995747177e-05,
      "loss": 0.0705,
      "step": 56110
    },
    {
      "epoch": 1.1222653281606207,
      "grad_norm": 0.24967284500598907,
      "learning_rate": 3.130257702409045e-05,
      "loss": 0.0784,
      "step": 56120
    },
    {
      "epoch": 1.1224653041635004,
      "grad_norm": 0.1191326230764389,
      "learning_rate": 3.129924409070912e-05,
      "loss": 0.0674,
      "step": 56130
    },
    {
      "epoch": 1.1226652801663801,
      "grad_norm": 0.12247665226459503,
      "learning_rate": 3.129591115732779e-05,
      "loss": 0.0501,
      "step": 56140
    },
    {
      "epoch": 1.1228652561692596,
      "grad_norm": 0.0583723708987236,
      "learning_rate": 3.1292578223946464e-05,
      "loss": 0.0492,
      "step": 56150
    },
    {
      "epoch": 1.1230652321721393,
      "grad_norm": 0.074318528175354,
      "learning_rate": 3.1289245290565134e-05,
      "loss": 0.0614,
      "step": 56160
    },
    {
      "epoch": 1.123265208175019,
      "grad_norm": 0.08355049043893814,
      "learning_rate": 3.12859123571838e-05,
      "loss": 0.0841,
      "step": 56170
    },
    {
      "epoch": 1.1234651841778986,
      "grad_norm": 0.10902933776378632,
      "learning_rate": 3.128257942380248e-05,
      "loss": 0.0771,
      "step": 56180
    },
    {
      "epoch": 1.1236651601807783,
      "grad_norm": 0.1255287081003189,
      "learning_rate": 3.127924649042115e-05,
      "loss": 0.0635,
      "step": 56190
    },
    {
      "epoch": 1.123865136183658,
      "grad_norm": 0.12022749334573746,
      "learning_rate": 3.127591355703982e-05,
      "loss": 0.0708,
      "step": 56200
    },
    {
      "epoch": 1.1240651121865377,
      "grad_norm": 0.1113559752702713,
      "learning_rate": 3.1272580623658495e-05,
      "loss": 0.0706,
      "step": 56210
    },
    {
      "epoch": 1.1242650881894172,
      "grad_norm": 0.18025515973567963,
      "learning_rate": 3.126924769027717e-05,
      "loss": 0.0596,
      "step": 56220
    },
    {
      "epoch": 1.1244650641922969,
      "grad_norm": 0.15777777135372162,
      "learning_rate": 3.126591475689584e-05,
      "loss": 0.0813,
      "step": 56230
    },
    {
      "epoch": 1.1246650401951765,
      "grad_norm": 0.059402890503406525,
      "learning_rate": 3.126258182351451e-05,
      "loss": 0.0767,
      "step": 56240
    },
    {
      "epoch": 1.1248650161980562,
      "grad_norm": 0.08518051356077194,
      "learning_rate": 3.125924889013319e-05,
      "loss": 0.0707,
      "step": 56250
    },
    {
      "epoch": 1.125064992200936,
      "grad_norm": 0.13241985440254211,
      "learning_rate": 3.125591595675186e-05,
      "loss": 0.0548,
      "step": 56260
    },
    {
      "epoch": 1.1252649682038156,
      "grad_norm": 0.2399180680513382,
      "learning_rate": 3.1252583023370526e-05,
      "loss": 0.0836,
      "step": 56270
    },
    {
      "epoch": 1.125464944206695,
      "grad_norm": 0.10907844454050064,
      "learning_rate": 3.12492500899892e-05,
      "loss": 0.0794,
      "step": 56280
    },
    {
      "epoch": 1.1256649202095748,
      "grad_norm": 0.1172080859541893,
      "learning_rate": 3.124591715660787e-05,
      "loss": 0.1273,
      "step": 56290
    },
    {
      "epoch": 1.1258648962124544,
      "grad_norm": 0.15864165127277374,
      "learning_rate": 3.124258422322654e-05,
      "loss": 0.082,
      "step": 56300
    },
    {
      "epoch": 1.1260648722153341,
      "grad_norm": 0.13053278625011444,
      "learning_rate": 3.1239251289845225e-05,
      "loss": 0.102,
      "step": 56310
    },
    {
      "epoch": 1.1262648482182138,
      "grad_norm": 0.09422290325164795,
      "learning_rate": 3.1235918356463895e-05,
      "loss": 0.0469,
      "step": 56320
    },
    {
      "epoch": 1.1264648242210935,
      "grad_norm": 0.08604787290096283,
      "learning_rate": 3.1232585423082564e-05,
      "loss": 0.053,
      "step": 56330
    },
    {
      "epoch": 1.1266648002239732,
      "grad_norm": 0.11636017262935638,
      "learning_rate": 3.122925248970124e-05,
      "loss": 0.0613,
      "step": 56340
    },
    {
      "epoch": 1.1268647762268529,
      "grad_norm": 0.11216451227664948,
      "learning_rate": 3.122591955631991e-05,
      "loss": 0.0713,
      "step": 56350
    },
    {
      "epoch": 1.1270647522297323,
      "grad_norm": 0.12709708511829376,
      "learning_rate": 3.122258662293858e-05,
      "loss": 0.0656,
      "step": 56360
    },
    {
      "epoch": 1.127264728232612,
      "grad_norm": 0.10399331897497177,
      "learning_rate": 3.1219253689557256e-05,
      "loss": 0.0649,
      "step": 56370
    },
    {
      "epoch": 1.1274647042354917,
      "grad_norm": 0.13669544458389282,
      "learning_rate": 3.1215920756175926e-05,
      "loss": 0.0866,
      "step": 56380
    },
    {
      "epoch": 1.1276646802383714,
      "grad_norm": 0.14847750961780548,
      "learning_rate": 3.1212587822794596e-05,
      "loss": 0.0688,
      "step": 56390
    },
    {
      "epoch": 1.127864656241251,
      "grad_norm": 0.11656583100557327,
      "learning_rate": 3.120925488941327e-05,
      "loss": 0.0567,
      "step": 56400
    },
    {
      "epoch": 1.1280646322441308,
      "grad_norm": 0.11196751147508621,
      "learning_rate": 3.120592195603194e-05,
      "loss": 0.0728,
      "step": 56410
    },
    {
      "epoch": 1.1282646082470102,
      "grad_norm": 0.14676116406917572,
      "learning_rate": 3.120258902265062e-05,
      "loss": 0.07,
      "step": 56420
    },
    {
      "epoch": 1.12846458424989,
      "grad_norm": 0.06429486721754074,
      "learning_rate": 3.119925608926929e-05,
      "loss": 0.0804,
      "step": 56430
    },
    {
      "epoch": 1.1286645602527696,
      "grad_norm": 0.06329130381345749,
      "learning_rate": 3.1195923155887964e-05,
      "loss": 0.0537,
      "step": 56440
    },
    {
      "epoch": 1.1288645362556493,
      "grad_norm": 0.07543837279081345,
      "learning_rate": 3.1192590222506634e-05,
      "loss": 0.0637,
      "step": 56450
    },
    {
      "epoch": 1.129064512258529,
      "grad_norm": 0.14831222593784332,
      "learning_rate": 3.11892572891253e-05,
      "loss": 0.0351,
      "step": 56460
    },
    {
      "epoch": 1.1292644882614087,
      "grad_norm": 0.06525620818138123,
      "learning_rate": 3.118592435574398e-05,
      "loss": 0.0459,
      "step": 56470
    },
    {
      "epoch": 1.1294644642642884,
      "grad_norm": 0.19590617716312408,
      "learning_rate": 3.118259142236265e-05,
      "loss": 0.0485,
      "step": 56480
    },
    {
      "epoch": 1.129664440267168,
      "grad_norm": 0.12525109946727753,
      "learning_rate": 3.117925848898132e-05,
      "loss": 0.0818,
      "step": 56490
    },
    {
      "epoch": 1.1298644162700475,
      "grad_norm": 0.10218029469251633,
      "learning_rate": 3.1175925555599995e-05,
      "loss": 0.0526,
      "step": 56500
    },
    {
      "epoch": 1.1300643922729272,
      "grad_norm": 0.07976140826940536,
      "learning_rate": 3.1172592622218665e-05,
      "loss": 0.1062,
      "step": 56510
    },
    {
      "epoch": 1.130264368275807,
      "grad_norm": 0.16211842000484467,
      "learning_rate": 3.116925968883734e-05,
      "loss": 0.0544,
      "step": 56520
    },
    {
      "epoch": 1.1304643442786866,
      "grad_norm": 0.1616433709859848,
      "learning_rate": 3.116592675545602e-05,
      "loss": 0.0842,
      "step": 56530
    },
    {
      "epoch": 1.1306643202815663,
      "grad_norm": 0.23113217949867249,
      "learning_rate": 3.116259382207469e-05,
      "loss": 0.0535,
      "step": 56540
    },
    {
      "epoch": 1.130864296284446,
      "grad_norm": 0.10161641985177994,
      "learning_rate": 3.115926088869336e-05,
      "loss": 0.0864,
      "step": 56550
    },
    {
      "epoch": 1.1310642722873254,
      "grad_norm": 0.22469213604927063,
      "learning_rate": 3.1155927955312033e-05,
      "loss": 0.1039,
      "step": 56560
    },
    {
      "epoch": 1.131264248290205,
      "grad_norm": 0.06518422812223434,
      "learning_rate": 3.11525950219307e-05,
      "loss": 0.0571,
      "step": 56570
    },
    {
      "epoch": 1.1314642242930848,
      "grad_norm": 0.10259907692670822,
      "learning_rate": 3.114926208854937e-05,
      "loss": 0.0547,
      "step": 56580
    },
    {
      "epoch": 1.1316642002959645,
      "grad_norm": 0.1281689703464508,
      "learning_rate": 3.114592915516805e-05,
      "loss": 0.214,
      "step": 56590
    },
    {
      "epoch": 1.1318641762988442,
      "grad_norm": 0.17376220226287842,
      "learning_rate": 3.114259622178672e-05,
      "loss": 0.0762,
      "step": 56600
    },
    {
      "epoch": 1.1320641523017239,
      "grad_norm": 0.0844036117196083,
      "learning_rate": 3.113926328840539e-05,
      "loss": 0.062,
      "step": 56610
    },
    {
      "epoch": 1.1322641283046035,
      "grad_norm": 0.1285250186920166,
      "learning_rate": 3.1135930355024065e-05,
      "loss": 0.0935,
      "step": 56620
    },
    {
      "epoch": 1.132464104307483,
      "grad_norm": 0.20866571366786957,
      "learning_rate": 3.113259742164274e-05,
      "loss": 0.0958,
      "step": 56630
    },
    {
      "epoch": 1.1326640803103627,
      "grad_norm": 0.1991213709115982,
      "learning_rate": 3.112926448826141e-05,
      "loss": 0.0698,
      "step": 56640
    },
    {
      "epoch": 1.1328640563132424,
      "grad_norm": 0.1651252657175064,
      "learning_rate": 3.112593155488008e-05,
      "loss": 0.1326,
      "step": 56650
    },
    {
      "epoch": 1.133064032316122,
      "grad_norm": 0.09588395059108734,
      "learning_rate": 3.112259862149876e-05,
      "loss": 0.1129,
      "step": 56660
    },
    {
      "epoch": 1.1332640083190018,
      "grad_norm": 0.11305868625640869,
      "learning_rate": 3.1119265688117426e-05,
      "loss": 0.0613,
      "step": 56670
    },
    {
      "epoch": 1.1334639843218814,
      "grad_norm": 0.17202921211719513,
      "learning_rate": 3.1115932754736096e-05,
      "loss": 0.0929,
      "step": 56680
    },
    {
      "epoch": 1.133663960324761,
      "grad_norm": 0.10292288661003113,
      "learning_rate": 3.111259982135477e-05,
      "loss": 0.0535,
      "step": 56690
    },
    {
      "epoch": 1.1338639363276406,
      "grad_norm": 0.16753743588924408,
      "learning_rate": 3.110926688797344e-05,
      "loss": 0.0626,
      "step": 56700
    },
    {
      "epoch": 1.1340639123305203,
      "grad_norm": 0.09876382350921631,
      "learning_rate": 3.110593395459211e-05,
      "loss": 0.0641,
      "step": 56710
    },
    {
      "epoch": 1.1342638883334,
      "grad_norm": 0.1426132172346115,
      "learning_rate": 3.1102601021210795e-05,
      "loss": 0.0753,
      "step": 56720
    },
    {
      "epoch": 1.1344638643362797,
      "grad_norm": 0.13180828094482422,
      "learning_rate": 3.1099268087829464e-05,
      "loss": 0.0635,
      "step": 56730
    },
    {
      "epoch": 1.1346638403391593,
      "grad_norm": 0.17115212976932526,
      "learning_rate": 3.1095935154448134e-05,
      "loss": 0.061,
      "step": 56740
    },
    {
      "epoch": 1.134863816342039,
      "grad_norm": 0.23056408762931824,
      "learning_rate": 3.109260222106681e-05,
      "loss": 0.069,
      "step": 56750
    },
    {
      "epoch": 1.1350637923449187,
      "grad_norm": 0.06279418617486954,
      "learning_rate": 3.108926928768548e-05,
      "loss": 0.052,
      "step": 56760
    },
    {
      "epoch": 1.1352637683477982,
      "grad_norm": 0.12971332669258118,
      "learning_rate": 3.108593635430415e-05,
      "loss": 0.0748,
      "step": 56770
    },
    {
      "epoch": 1.1354637443506779,
      "grad_norm": 0.14237001538276672,
      "learning_rate": 3.1082603420922826e-05,
      "loss": 0.1084,
      "step": 56780
    },
    {
      "epoch": 1.1356637203535576,
      "grad_norm": 0.16885323822498322,
      "learning_rate": 3.1079270487541496e-05,
      "loss": 0.083,
      "step": 56790
    },
    {
      "epoch": 1.1358636963564372,
      "grad_norm": 0.15897135436534882,
      "learning_rate": 3.1075937554160165e-05,
      "loss": 0.0495,
      "step": 56800
    },
    {
      "epoch": 1.136063672359317,
      "grad_norm": 0.1988818347454071,
      "learning_rate": 3.107260462077884e-05,
      "loss": 0.0754,
      "step": 56810
    },
    {
      "epoch": 1.1362636483621966,
      "grad_norm": 0.07352371513843536,
      "learning_rate": 3.106927168739752e-05,
      "loss": 0.0462,
      "step": 56820
    },
    {
      "epoch": 1.136463624365076,
      "grad_norm": 0.0800081416964531,
      "learning_rate": 3.106593875401619e-05,
      "loss": 0.0819,
      "step": 56830
    },
    {
      "epoch": 1.1366636003679558,
      "grad_norm": 0.06805244088172913,
      "learning_rate": 3.106260582063486e-05,
      "loss": 0.0612,
      "step": 56840
    },
    {
      "epoch": 1.1368635763708355,
      "grad_norm": 0.2336873710155487,
      "learning_rate": 3.1059272887253534e-05,
      "loss": 0.0446,
      "step": 56850
    },
    {
      "epoch": 1.1370635523737151,
      "grad_norm": 0.1468358337879181,
      "learning_rate": 3.10559399538722e-05,
      "loss": 0.0816,
      "step": 56860
    },
    {
      "epoch": 1.1372635283765948,
      "grad_norm": 0.17349621653556824,
      "learning_rate": 3.105260702049087e-05,
      "loss": 0.1087,
      "step": 56870
    },
    {
      "epoch": 1.1374635043794745,
      "grad_norm": 0.1770211011171341,
      "learning_rate": 3.104927408710955e-05,
      "loss": 0.1144,
      "step": 56880
    },
    {
      "epoch": 1.1376634803823542,
      "grad_norm": 0.16091111302375793,
      "learning_rate": 3.104594115372822e-05,
      "loss": 0.0694,
      "step": 56890
    },
    {
      "epoch": 1.137863456385234,
      "grad_norm": 0.19150424003601074,
      "learning_rate": 3.104260822034689e-05,
      "loss": 0.0684,
      "step": 56900
    },
    {
      "epoch": 1.1380634323881134,
      "grad_norm": 0.06979961693286896,
      "learning_rate": 3.1039275286965565e-05,
      "loss": 0.0538,
      "step": 56910
    },
    {
      "epoch": 1.138263408390993,
      "grad_norm": 0.16005899012088776,
      "learning_rate": 3.1035942353584234e-05,
      "loss": 0.0822,
      "step": 56920
    },
    {
      "epoch": 1.1384633843938727,
      "grad_norm": 0.04303792491555214,
      "learning_rate": 3.103260942020291e-05,
      "loss": 0.0903,
      "step": 56930
    },
    {
      "epoch": 1.1386633603967524,
      "grad_norm": 0.1903822273015976,
      "learning_rate": 3.102927648682159e-05,
      "loss": 0.099,
      "step": 56940
    },
    {
      "epoch": 1.138863336399632,
      "grad_norm": 0.24536457657814026,
      "learning_rate": 3.102594355344026e-05,
      "loss": 0.1016,
      "step": 56950
    },
    {
      "epoch": 1.1390633124025116,
      "grad_norm": 0.08809811621904373,
      "learning_rate": 3.1022610620058926e-05,
      "loss": 0.0727,
      "step": 56960
    },
    {
      "epoch": 1.1392632884053913,
      "grad_norm": 0.11121971905231476,
      "learning_rate": 3.10192776866776e-05,
      "loss": 0.1016,
      "step": 56970
    },
    {
      "epoch": 1.139463264408271,
      "grad_norm": 0.15221671760082245,
      "learning_rate": 3.101594475329627e-05,
      "loss": 0.0756,
      "step": 56980
    },
    {
      "epoch": 1.1396632404111506,
      "grad_norm": 0.06892839074134827,
      "learning_rate": 3.101261181991494e-05,
      "loss": 0.0821,
      "step": 56990
    },
    {
      "epoch": 1.1398632164140303,
      "grad_norm": 0.11910451203584671,
      "learning_rate": 3.100927888653362e-05,
      "loss": 0.0772,
      "step": 57000
    },
    {
      "epoch": 1.14006319241691,
      "grad_norm": 0.08744332194328308,
      "learning_rate": 3.100594595315229e-05,
      "loss": 0.0878,
      "step": 57010
    },
    {
      "epoch": 1.1402631684197897,
      "grad_norm": 0.1276780217885971,
      "learning_rate": 3.100261301977096e-05,
      "loss": 0.1057,
      "step": 57020
    },
    {
      "epoch": 1.1404631444226694,
      "grad_norm": 0.08961786329746246,
      "learning_rate": 3.0999280086389634e-05,
      "loss": 0.064,
      "step": 57030
    },
    {
      "epoch": 1.1406631204255488,
      "grad_norm": 0.13367049396038055,
      "learning_rate": 3.099594715300831e-05,
      "loss": 0.036,
      "step": 57040
    },
    {
      "epoch": 1.1408630964284285,
      "grad_norm": 0.19213749468326569,
      "learning_rate": 3.099261421962698e-05,
      "loss": 0.0789,
      "step": 57050
    },
    {
      "epoch": 1.1410630724313082,
      "grad_norm": 0.3044908344745636,
      "learning_rate": 3.098928128624565e-05,
      "loss": 0.057,
      "step": 57060
    },
    {
      "epoch": 1.141263048434188,
      "grad_norm": 0.07128629088401794,
      "learning_rate": 3.0985948352864326e-05,
      "loss": 0.0877,
      "step": 57070
    },
    {
      "epoch": 1.1414630244370676,
      "grad_norm": 0.12290576100349426,
      "learning_rate": 3.0982615419482996e-05,
      "loss": 0.1894,
      "step": 57080
    },
    {
      "epoch": 1.1416630004399473,
      "grad_norm": 0.12439005821943283,
      "learning_rate": 3.0979282486101665e-05,
      "loss": 0.0484,
      "step": 57090
    },
    {
      "epoch": 1.1418629764428267,
      "grad_norm": 0.10445210337638855,
      "learning_rate": 3.097594955272034e-05,
      "loss": 0.0565,
      "step": 57100
    },
    {
      "epoch": 1.1420629524457064,
      "grad_norm": 0.13737761974334717,
      "learning_rate": 3.097261661933901e-05,
      "loss": 0.0713,
      "step": 57110
    },
    {
      "epoch": 1.1422629284485861,
      "grad_norm": 0.20478440821170807,
      "learning_rate": 3.096928368595768e-05,
      "loss": 0.0962,
      "step": 57120
    },
    {
      "epoch": 1.1424629044514658,
      "grad_norm": 0.13284248113632202,
      "learning_rate": 3.0965950752576364e-05,
      "loss": 0.1049,
      "step": 57130
    },
    {
      "epoch": 1.1426628804543455,
      "grad_norm": 0.11370629817247391,
      "learning_rate": 3.0962617819195034e-05,
      "loss": 0.0661,
      "step": 57140
    },
    {
      "epoch": 1.1428628564572252,
      "grad_norm": 0.2043144702911377,
      "learning_rate": 3.09592848858137e-05,
      "loss": 0.085,
      "step": 57150
    },
    {
      "epoch": 1.1430628324601049,
      "grad_norm": 0.10233946144580841,
      "learning_rate": 3.095595195243238e-05,
      "loss": 0.0577,
      "step": 57160
    },
    {
      "epoch": 1.1432628084629846,
      "grad_norm": 0.09279768168926239,
      "learning_rate": 3.095261901905105e-05,
      "loss": 0.0708,
      "step": 57170
    },
    {
      "epoch": 1.143462784465864,
      "grad_norm": 0.11820858716964722,
      "learning_rate": 3.094928608566972e-05,
      "loss": 0.0658,
      "step": 57180
    },
    {
      "epoch": 1.1436627604687437,
      "grad_norm": 0.17761410772800446,
      "learning_rate": 3.0945953152288395e-05,
      "loss": 0.0664,
      "step": 57190
    },
    {
      "epoch": 1.1438627364716234,
      "grad_norm": 0.200748011469841,
      "learning_rate": 3.0942620218907065e-05,
      "loss": 0.1296,
      "step": 57200
    },
    {
      "epoch": 1.144062712474503,
      "grad_norm": 0.1358664184808731,
      "learning_rate": 3.0939287285525735e-05,
      "loss": 0.0598,
      "step": 57210
    },
    {
      "epoch": 1.1442626884773828,
      "grad_norm": 0.15191750228405,
      "learning_rate": 3.093595435214441e-05,
      "loss": 0.0544,
      "step": 57220
    },
    {
      "epoch": 1.1444626644802625,
      "grad_norm": 0.21051716804504395,
      "learning_rate": 3.093262141876309e-05,
      "loss": 0.0732,
      "step": 57230
    },
    {
      "epoch": 1.144662640483142,
      "grad_norm": 0.12674105167388916,
      "learning_rate": 3.092928848538176e-05,
      "loss": 0.0659,
      "step": 57240
    },
    {
      "epoch": 1.1448626164860216,
      "grad_norm": 0.1345292031764984,
      "learning_rate": 3.092595555200043e-05,
      "loss": 0.1014,
      "step": 57250
    },
    {
      "epoch": 1.1450625924889013,
      "grad_norm": 0.07878131419420242,
      "learning_rate": 3.09226226186191e-05,
      "loss": 0.073,
      "step": 57260
    },
    {
      "epoch": 1.145262568491781,
      "grad_norm": 0.2293267548084259,
      "learning_rate": 3.091928968523777e-05,
      "loss": 0.0846,
      "step": 57270
    },
    {
      "epoch": 1.1454625444946607,
      "grad_norm": 0.07273755222558975,
      "learning_rate": 3.091595675185644e-05,
      "loss": 0.0773,
      "step": 57280
    },
    {
      "epoch": 1.1456625204975404,
      "grad_norm": 0.15619266033172607,
      "learning_rate": 3.091262381847512e-05,
      "loss": 0.0618,
      "step": 57290
    },
    {
      "epoch": 1.14586249650042,
      "grad_norm": 0.15939107537269592,
      "learning_rate": 3.090929088509379e-05,
      "loss": 0.0939,
      "step": 57300
    },
    {
      "epoch": 1.1460624725032995,
      "grad_norm": 0.15372994542121887,
      "learning_rate": 3.090595795171246e-05,
      "loss": 0.095,
      "step": 57310
    },
    {
      "epoch": 1.1462624485061792,
      "grad_norm": 0.10151307284832001,
      "learning_rate": 3.0902625018331134e-05,
      "loss": 0.0772,
      "step": 57320
    },
    {
      "epoch": 1.1464624245090589,
      "grad_norm": 0.11226993054151535,
      "learning_rate": 3.089929208494981e-05,
      "loss": 0.0539,
      "step": 57330
    },
    {
      "epoch": 1.1466624005119386,
      "grad_norm": 0.08744275569915771,
      "learning_rate": 3.089595915156848e-05,
      "loss": 0.0768,
      "step": 57340
    },
    {
      "epoch": 1.1468623765148183,
      "grad_norm": 0.1461147964000702,
      "learning_rate": 3.089262621818716e-05,
      "loss": 0.0847,
      "step": 57350
    },
    {
      "epoch": 1.147062352517698,
      "grad_norm": 0.23735080659389496,
      "learning_rate": 3.0889293284805826e-05,
      "loss": 0.0786,
      "step": 57360
    },
    {
      "epoch": 1.1472623285205774,
      "grad_norm": 0.13960164785385132,
      "learning_rate": 3.0885960351424496e-05,
      "loss": 0.0875,
      "step": 57370
    },
    {
      "epoch": 1.147462304523457,
      "grad_norm": 0.19977542757987976,
      "learning_rate": 3.088262741804317e-05,
      "loss": 0.0528,
      "step": 57380
    },
    {
      "epoch": 1.1476622805263368,
      "grad_norm": 0.1529562622308731,
      "learning_rate": 3.087929448466184e-05,
      "loss": 0.0815,
      "step": 57390
    },
    {
      "epoch": 1.1478622565292165,
      "grad_norm": 0.09697897732257843,
      "learning_rate": 3.087596155128051e-05,
      "loss": 0.0827,
      "step": 57400
    },
    {
      "epoch": 1.1480622325320962,
      "grad_norm": 0.23900160193443298,
      "learning_rate": 3.087262861789919e-05,
      "loss": 0.0854,
      "step": 57410
    },
    {
      "epoch": 1.1482622085349758,
      "grad_norm": 0.13811728358268738,
      "learning_rate": 3.086929568451786e-05,
      "loss": 0.0614,
      "step": 57420
    },
    {
      "epoch": 1.1484621845378555,
      "grad_norm": 0.1732911914587021,
      "learning_rate": 3.086596275113653e-05,
      "loss": 0.0876,
      "step": 57430
    },
    {
      "epoch": 1.1486621605407352,
      "grad_norm": 0.20772694051265717,
      "learning_rate": 3.0862629817755204e-05,
      "loss": 0.0797,
      "step": 57440
    },
    {
      "epoch": 1.1488621365436147,
      "grad_norm": 0.15755093097686768,
      "learning_rate": 3.085929688437388e-05,
      "loss": 0.0895,
      "step": 57450
    },
    {
      "epoch": 1.1490621125464944,
      "grad_norm": 0.10094156116247177,
      "learning_rate": 3.085596395099255e-05,
      "loss": 0.0769,
      "step": 57460
    },
    {
      "epoch": 1.149262088549374,
      "grad_norm": 0.06521359086036682,
      "learning_rate": 3.085263101761122e-05,
      "loss": 0.0689,
      "step": 57470
    },
    {
      "epoch": 1.1494620645522537,
      "grad_norm": 0.17033430933952332,
      "learning_rate": 3.0849298084229896e-05,
      "loss": 0.0641,
      "step": 57480
    },
    {
      "epoch": 1.1496620405551334,
      "grad_norm": 0.14528903365135193,
      "learning_rate": 3.0845965150848565e-05,
      "loss": 0.0744,
      "step": 57490
    },
    {
      "epoch": 1.1498620165580131,
      "grad_norm": 0.08729524910449982,
      "learning_rate": 3.0842632217467235e-05,
      "loss": 0.1089,
      "step": 57500
    },
    {
      "epoch": 1.1500619925608926,
      "grad_norm": 0.18615840375423431,
      "learning_rate": 3.083929928408591e-05,
      "loss": 0.1088,
      "step": 57510
    },
    {
      "epoch": 1.1502619685637723,
      "grad_norm": 0.13060249388217926,
      "learning_rate": 3.083596635070458e-05,
      "loss": 0.0656,
      "step": 57520
    },
    {
      "epoch": 1.150461944566652,
      "grad_norm": 0.1391729861497879,
      "learning_rate": 3.083263341732325e-05,
      "loss": 0.0495,
      "step": 57530
    },
    {
      "epoch": 1.1506619205695316,
      "grad_norm": 0.15414178371429443,
      "learning_rate": 3.0829300483941934e-05,
      "loss": 0.0513,
      "step": 57540
    },
    {
      "epoch": 1.1508618965724113,
      "grad_norm": 0.10366059094667435,
      "learning_rate": 3.08259675505606e-05,
      "loss": 0.0414,
      "step": 57550
    },
    {
      "epoch": 1.151061872575291,
      "grad_norm": 0.09310006350278854,
      "learning_rate": 3.082263461717927e-05,
      "loss": 0.0498,
      "step": 57560
    },
    {
      "epoch": 1.1512618485781707,
      "grad_norm": 0.12975624203681946,
      "learning_rate": 3.081930168379795e-05,
      "loss": 0.0748,
      "step": 57570
    },
    {
      "epoch": 1.1514618245810504,
      "grad_norm": 0.13736896216869354,
      "learning_rate": 3.081596875041662e-05,
      "loss": 0.0875,
      "step": 57580
    },
    {
      "epoch": 1.1516618005839299,
      "grad_norm": 0.0835808664560318,
      "learning_rate": 3.081263581703529e-05,
      "loss": 0.0723,
      "step": 57590
    },
    {
      "epoch": 1.1518617765868095,
      "grad_norm": 0.07371419668197632,
      "learning_rate": 3.0809302883653965e-05,
      "loss": 0.1023,
      "step": 57600
    },
    {
      "epoch": 1.1520617525896892,
      "grad_norm": 0.12904055416584015,
      "learning_rate": 3.0805969950272634e-05,
      "loss": 0.249,
      "step": 57610
    },
    {
      "epoch": 1.152261728592569,
      "grad_norm": 0.13521809875965118,
      "learning_rate": 3.0802637016891304e-05,
      "loss": 0.0413,
      "step": 57620
    },
    {
      "epoch": 1.1524617045954486,
      "grad_norm": 0.09834428131580353,
      "learning_rate": 3.079930408350998e-05,
      "loss": 0.0998,
      "step": 57630
    },
    {
      "epoch": 1.1526616805983283,
      "grad_norm": 0.07472818344831467,
      "learning_rate": 3.079597115012866e-05,
      "loss": 0.0638,
      "step": 57640
    },
    {
      "epoch": 1.1528616566012078,
      "grad_norm": 0.21259330213069916,
      "learning_rate": 3.0792638216747326e-05,
      "loss": 0.0895,
      "step": 57650
    },
    {
      "epoch": 1.1530616326040874,
      "grad_norm": 0.1827213317155838,
      "learning_rate": 3.0789305283365996e-05,
      "loss": 0.0554,
      "step": 57660
    },
    {
      "epoch": 1.1532616086069671,
      "grad_norm": 0.22643060982227325,
      "learning_rate": 3.078597234998467e-05,
      "loss": 0.0926,
      "step": 57670
    },
    {
      "epoch": 1.1534615846098468,
      "grad_norm": 0.1624986231327057,
      "learning_rate": 3.078263941660334e-05,
      "loss": 0.1135,
      "step": 57680
    },
    {
      "epoch": 1.1536615606127265,
      "grad_norm": 0.06506084650754929,
      "learning_rate": 3.077930648322201e-05,
      "loss": 0.0729,
      "step": 57690
    },
    {
      "epoch": 1.1538615366156062,
      "grad_norm": 0.09025970846414566,
      "learning_rate": 3.077597354984069e-05,
      "loss": 0.0496,
      "step": 57700
    },
    {
      "epoch": 1.1540615126184859,
      "grad_norm": 0.13241438567638397,
      "learning_rate": 3.077264061645936e-05,
      "loss": 0.0723,
      "step": 57710
    },
    {
      "epoch": 1.1542614886213654,
      "grad_norm": 0.1186806932091713,
      "learning_rate": 3.076930768307803e-05,
      "loss": 0.0523,
      "step": 57720
    },
    {
      "epoch": 1.154461464624245,
      "grad_norm": 0.163605734705925,
      "learning_rate": 3.0765974749696704e-05,
      "loss": 0.0709,
      "step": 57730
    },
    {
      "epoch": 1.1546614406271247,
      "grad_norm": 0.07945175468921661,
      "learning_rate": 3.076264181631538e-05,
      "loss": 0.0813,
      "step": 57740
    },
    {
      "epoch": 1.1548614166300044,
      "grad_norm": 0.10897520184516907,
      "learning_rate": 3.075930888293405e-05,
      "loss": 0.0473,
      "step": 57750
    },
    {
      "epoch": 1.155061392632884,
      "grad_norm": 0.13239936530590057,
      "learning_rate": 3.0755975949552726e-05,
      "loss": 0.0485,
      "step": 57760
    },
    {
      "epoch": 1.1552613686357638,
      "grad_norm": 0.10324442386627197,
      "learning_rate": 3.0752643016171396e-05,
      "loss": 0.0673,
      "step": 57770
    },
    {
      "epoch": 1.1554613446386433,
      "grad_norm": 0.11521030962467194,
      "learning_rate": 3.0749310082790065e-05,
      "loss": 0.0871,
      "step": 57780
    },
    {
      "epoch": 1.155661320641523,
      "grad_norm": 0.2431306391954422,
      "learning_rate": 3.074597714940874e-05,
      "loss": 0.0877,
      "step": 57790
    },
    {
      "epoch": 1.1558612966444026,
      "grad_norm": 0.1274130791425705,
      "learning_rate": 3.074264421602741e-05,
      "loss": 0.0477,
      "step": 57800
    },
    {
      "epoch": 1.1560612726472823,
      "grad_norm": 0.09887992590665817,
      "learning_rate": 3.073931128264608e-05,
      "loss": 0.0808,
      "step": 57810
    },
    {
      "epoch": 1.156261248650162,
      "grad_norm": 0.10774660110473633,
      "learning_rate": 3.073597834926476e-05,
      "loss": 0.0982,
      "step": 57820
    },
    {
      "epoch": 1.1564612246530417,
      "grad_norm": 0.21154998242855072,
      "learning_rate": 3.073264541588343e-05,
      "loss": 0.0847,
      "step": 57830
    },
    {
      "epoch": 1.1566612006559214,
      "grad_norm": 0.10610873252153397,
      "learning_rate": 3.07293124825021e-05,
      "loss": 0.0963,
      "step": 57840
    },
    {
      "epoch": 1.156861176658801,
      "grad_norm": 0.1770026534795761,
      "learning_rate": 3.072597954912077e-05,
      "loss": 0.0921,
      "step": 57850
    },
    {
      "epoch": 1.1570611526616805,
      "grad_norm": 0.2587619721889496,
      "learning_rate": 3.072264661573945e-05,
      "loss": 0.0617,
      "step": 57860
    },
    {
      "epoch": 1.1572611286645602,
      "grad_norm": 0.10186874121427536,
      "learning_rate": 3.071931368235812e-05,
      "loss": 0.0497,
      "step": 57870
    },
    {
      "epoch": 1.15746110466744,
      "grad_norm": 0.17652882635593414,
      "learning_rate": 3.071598074897679e-05,
      "loss": 0.0489,
      "step": 57880
    },
    {
      "epoch": 1.1576610806703196,
      "grad_norm": 0.19182592630386353,
      "learning_rate": 3.0712647815595465e-05,
      "loss": 0.0804,
      "step": 57890
    },
    {
      "epoch": 1.1578610566731993,
      "grad_norm": 0.082705557346344,
      "learning_rate": 3.0709314882214135e-05,
      "loss": 0.051,
      "step": 57900
    },
    {
      "epoch": 1.158061032676079,
      "grad_norm": 0.08577919751405716,
      "learning_rate": 3.0705981948832804e-05,
      "loss": 0.0719,
      "step": 57910
    },
    {
      "epoch": 1.1582610086789584,
      "grad_norm": 0.10861258953809738,
      "learning_rate": 3.070264901545148e-05,
      "loss": 0.0722,
      "step": 57920
    },
    {
      "epoch": 1.1584609846818381,
      "grad_norm": 0.19227942824363708,
      "learning_rate": 3.069931608207015e-05,
      "loss": 0.0698,
      "step": 57930
    },
    {
      "epoch": 1.1586609606847178,
      "grad_norm": 0.1317928284406662,
      "learning_rate": 3.069598314868882e-05,
      "loss": 0.1023,
      "step": 57940
    },
    {
      "epoch": 1.1588609366875975,
      "grad_norm": 0.0951455757021904,
      "learning_rate": 3.06926502153075e-05,
      "loss": 0.0932,
      "step": 57950
    },
    {
      "epoch": 1.1590609126904772,
      "grad_norm": 0.1407690793275833,
      "learning_rate": 3.068931728192617e-05,
      "loss": 0.0644,
      "step": 57960
    },
    {
      "epoch": 1.1592608886933569,
      "grad_norm": 0.129963681101799,
      "learning_rate": 3.068598434854484e-05,
      "loss": 0.0637,
      "step": 57970
    },
    {
      "epoch": 1.1594608646962365,
      "grad_norm": 0.16736629605293274,
      "learning_rate": 3.068265141516352e-05,
      "loss": 0.1103,
      "step": 57980
    },
    {
      "epoch": 1.159660840699116,
      "grad_norm": 0.21828767657279968,
      "learning_rate": 3.067931848178219e-05,
      "loss": 0.0785,
      "step": 57990
    },
    {
      "epoch": 1.1598608167019957,
      "grad_norm": 0.1708182841539383,
      "learning_rate": 3.067598554840086e-05,
      "loss": 0.0435,
      "step": 58000
    },
    {
      "epoch": 1.1600607927048754,
      "grad_norm": 0.1281501203775406,
      "learning_rate": 3.0672652615019534e-05,
      "loss": 0.0629,
      "step": 58010
    },
    {
      "epoch": 1.160260768707755,
      "grad_norm": 0.26540690660476685,
      "learning_rate": 3.0669319681638204e-05,
      "loss": 0.1086,
      "step": 58020
    },
    {
      "epoch": 1.1604607447106348,
      "grad_norm": 0.08330971747636795,
      "learning_rate": 3.0665986748256874e-05,
      "loss": 0.0696,
      "step": 58030
    },
    {
      "epoch": 1.1606607207135144,
      "grad_norm": 0.21302366256713867,
      "learning_rate": 3.066265381487555e-05,
      "loss": 0.0769,
      "step": 58040
    },
    {
      "epoch": 1.160860696716394,
      "grad_norm": 0.07500583678483963,
      "learning_rate": 3.0659320881494226e-05,
      "loss": 0.0561,
      "step": 58050
    },
    {
      "epoch": 1.1610606727192736,
      "grad_norm": 0.1413833051919937,
      "learning_rate": 3.0655987948112896e-05,
      "loss": 0.0766,
      "step": 58060
    },
    {
      "epoch": 1.1612606487221533,
      "grad_norm": 0.10555198043584824,
      "learning_rate": 3.0652655014731566e-05,
      "loss": 0.1106,
      "step": 58070
    },
    {
      "epoch": 1.161460624725033,
      "grad_norm": 0.19537338614463806,
      "learning_rate": 3.064932208135024e-05,
      "loss": 0.1065,
      "step": 58080
    },
    {
      "epoch": 1.1616606007279127,
      "grad_norm": 0.07260340452194214,
      "learning_rate": 3.064598914796891e-05,
      "loss": 0.3083,
      "step": 58090
    },
    {
      "epoch": 1.1618605767307923,
      "grad_norm": 0.14957919716835022,
      "learning_rate": 3.064265621458758e-05,
      "loss": 0.0843,
      "step": 58100
    },
    {
      "epoch": 1.162060552733672,
      "grad_norm": 0.11300293356180191,
      "learning_rate": 3.063932328120626e-05,
      "loss": 0.0769,
      "step": 58110
    },
    {
      "epoch": 1.1622605287365517,
      "grad_norm": 0.08635455369949341,
      "learning_rate": 3.063599034782493e-05,
      "loss": 0.0753,
      "step": 58120
    },
    {
      "epoch": 1.1624605047394312,
      "grad_norm": 0.1566377878189087,
      "learning_rate": 3.06326574144436e-05,
      "loss": 0.0703,
      "step": 58130
    },
    {
      "epoch": 1.1626604807423109,
      "grad_norm": 0.05828087404370308,
      "learning_rate": 3.062932448106227e-05,
      "loss": 0.0701,
      "step": 58140
    },
    {
      "epoch": 1.1628604567451906,
      "grad_norm": 0.14749211072921753,
      "learning_rate": 3.062599154768095e-05,
      "loss": 0.4439,
      "step": 58150
    },
    {
      "epoch": 1.1630604327480702,
      "grad_norm": 0.07226470112800598,
      "learning_rate": 3.062265861429962e-05,
      "loss": 0.0666,
      "step": 58160
    },
    {
      "epoch": 1.16326040875095,
      "grad_norm": 0.04863971844315529,
      "learning_rate": 3.0619325680918296e-05,
      "loss": 0.0591,
      "step": 58170
    },
    {
      "epoch": 1.1634603847538296,
      "grad_norm": 0.09557589143514633,
      "learning_rate": 3.0615992747536965e-05,
      "loss": 0.1176,
      "step": 58180
    },
    {
      "epoch": 1.163660360756709,
      "grad_norm": 0.1989162415266037,
      "learning_rate": 3.0612659814155635e-05,
      "loss": 0.0897,
      "step": 58190
    },
    {
      "epoch": 1.1638603367595888,
      "grad_norm": 0.06340621411800385,
      "learning_rate": 3.060932688077431e-05,
      "loss": 0.0673,
      "step": 58200
    },
    {
      "epoch": 1.1640603127624685,
      "grad_norm": 0.17871539294719696,
      "learning_rate": 3.060599394739298e-05,
      "loss": 0.0955,
      "step": 58210
    },
    {
      "epoch": 1.1642602887653482,
      "grad_norm": 0.07072219997644424,
      "learning_rate": 3.060266101401165e-05,
      "loss": 0.0675,
      "step": 58220
    },
    {
      "epoch": 1.1644602647682278,
      "grad_norm": 0.08524708449840546,
      "learning_rate": 3.059932808063033e-05,
      "loss": 0.1046,
      "step": 58230
    },
    {
      "epoch": 1.1646602407711075,
      "grad_norm": 0.15721441805362701,
      "learning_rate": 3.0595995147248996e-05,
      "loss": 0.0689,
      "step": 58240
    },
    {
      "epoch": 1.1648602167739872,
      "grad_norm": 0.19195929169654846,
      "learning_rate": 3.059266221386767e-05,
      "loss": 0.1049,
      "step": 58250
    },
    {
      "epoch": 1.165060192776867,
      "grad_norm": 0.1619180589914322,
      "learning_rate": 3.058932928048634e-05,
      "loss": 0.1093,
      "step": 58260
    },
    {
      "epoch": 1.1652601687797464,
      "grad_norm": 0.14760613441467285,
      "learning_rate": 3.058599634710502e-05,
      "loss": 0.0549,
      "step": 58270
    },
    {
      "epoch": 1.165460144782626,
      "grad_norm": 0.10410530120134354,
      "learning_rate": 3.058266341372369e-05,
      "loss": 0.0797,
      "step": 58280
    },
    {
      "epoch": 1.1656601207855057,
      "grad_norm": 0.17023295164108276,
      "learning_rate": 3.057933048034236e-05,
      "loss": 0.0702,
      "step": 58290
    },
    {
      "epoch": 1.1658600967883854,
      "grad_norm": 0.13868963718414307,
      "learning_rate": 3.0575997546961034e-05,
      "loss": 0.0636,
      "step": 58300
    },
    {
      "epoch": 1.1660600727912651,
      "grad_norm": 0.08274893462657928,
      "learning_rate": 3.0572664613579704e-05,
      "loss": 0.0501,
      "step": 58310
    },
    {
      "epoch": 1.1662600487941448,
      "grad_norm": 0.12990190088748932,
      "learning_rate": 3.0569331680198374e-05,
      "loss": 0.0685,
      "step": 58320
    },
    {
      "epoch": 1.1664600247970243,
      "grad_norm": 0.09627669304609299,
      "learning_rate": 3.056599874681705e-05,
      "loss": 0.08,
      "step": 58330
    },
    {
      "epoch": 1.166660000799904,
      "grad_norm": 0.14926569163799286,
      "learning_rate": 3.056266581343572e-05,
      "loss": 0.08,
      "step": 58340
    },
    {
      "epoch": 1.1668599768027836,
      "grad_norm": 0.18247702717781067,
      "learning_rate": 3.0559332880054396e-05,
      "loss": 0.1153,
      "step": 58350
    },
    {
      "epoch": 1.1670599528056633,
      "grad_norm": 0.14354044198989868,
      "learning_rate": 3.055599994667307e-05,
      "loss": 0.0953,
      "step": 58360
    },
    {
      "epoch": 1.167259928808543,
      "grad_norm": 0.0684913620352745,
      "learning_rate": 3.055266701329174e-05,
      "loss": 0.056,
      "step": 58370
    },
    {
      "epoch": 1.1674599048114227,
      "grad_norm": 0.10422687977552414,
      "learning_rate": 3.054933407991041e-05,
      "loss": 0.063,
      "step": 58380
    },
    {
      "epoch": 1.1676598808143024,
      "grad_norm": 0.059301454573869705,
      "learning_rate": 3.054600114652909e-05,
      "loss": 0.0683,
      "step": 58390
    },
    {
      "epoch": 1.1678598568171819,
      "grad_norm": 0.11118564754724503,
      "learning_rate": 3.054266821314776e-05,
      "loss": 0.0858,
      "step": 58400
    },
    {
      "epoch": 1.1680598328200615,
      "grad_norm": 0.17289723455905914,
      "learning_rate": 3.053933527976643e-05,
      "loss": 0.0559,
      "step": 58410
    },
    {
      "epoch": 1.1682598088229412,
      "grad_norm": 0.14103984832763672,
      "learning_rate": 3.0536002346385104e-05,
      "loss": 0.0758,
      "step": 58420
    },
    {
      "epoch": 1.168459784825821,
      "grad_norm": 0.10426086187362671,
      "learning_rate": 3.053266941300377e-05,
      "loss": 0.076,
      "step": 58430
    },
    {
      "epoch": 1.1686597608287006,
      "grad_norm": 0.05910126492381096,
      "learning_rate": 3.052933647962244e-05,
      "loss": 0.0596,
      "step": 58440
    },
    {
      "epoch": 1.1688597368315803,
      "grad_norm": 0.09037870168685913,
      "learning_rate": 3.052600354624112e-05,
      "loss": 0.0793,
      "step": 58450
    },
    {
      "epoch": 1.1690597128344598,
      "grad_norm": 0.06975603103637695,
      "learning_rate": 3.0522670612859796e-05,
      "loss": 0.0853,
      "step": 58460
    },
    {
      "epoch": 1.1692596888373394,
      "grad_norm": 0.1716299206018448,
      "learning_rate": 3.0519337679478465e-05,
      "loss": 0.0432,
      "step": 58470
    },
    {
      "epoch": 1.1694596648402191,
      "grad_norm": 0.17716141045093536,
      "learning_rate": 3.051600474609714e-05,
      "loss": 0.0971,
      "step": 58480
    },
    {
      "epoch": 1.1696596408430988,
      "grad_norm": 0.10213024169206619,
      "learning_rate": 3.0512671812715808e-05,
      "loss": 0.0734,
      "step": 58490
    },
    {
      "epoch": 1.1698596168459785,
      "grad_norm": 0.1812068223953247,
      "learning_rate": 3.050933887933448e-05,
      "loss": 0.0664,
      "step": 58500
    },
    {
      "epoch": 1.1700595928488582,
      "grad_norm": 0.10853362828493118,
      "learning_rate": 3.0506005945953154e-05,
      "loss": 0.0866,
      "step": 58510
    },
    {
      "epoch": 1.1702595688517379,
      "grad_norm": 0.08940040320158005,
      "learning_rate": 3.0502673012571824e-05,
      "loss": 0.0675,
      "step": 58520
    },
    {
      "epoch": 1.1704595448546176,
      "grad_norm": 0.10870906710624695,
      "learning_rate": 3.0499340079190497e-05,
      "loss": 0.0798,
      "step": 58530
    },
    {
      "epoch": 1.170659520857497,
      "grad_norm": 0.15275971591472626,
      "learning_rate": 3.049600714580917e-05,
      "loss": 0.0716,
      "step": 58540
    },
    {
      "epoch": 1.1708594968603767,
      "grad_norm": 0.09262768179178238,
      "learning_rate": 3.049267421242784e-05,
      "loss": 0.0661,
      "step": 58550
    },
    {
      "epoch": 1.1710594728632564,
      "grad_norm": 0.1006811335682869,
      "learning_rate": 3.048934127904652e-05,
      "loss": 0.0673,
      "step": 58560
    },
    {
      "epoch": 1.171259448866136,
      "grad_norm": 0.13994045555591583,
      "learning_rate": 3.048600834566519e-05,
      "loss": 0.0723,
      "step": 58570
    },
    {
      "epoch": 1.1714594248690158,
      "grad_norm": 0.14876821637153625,
      "learning_rate": 3.048267541228386e-05,
      "loss": 0.0695,
      "step": 58580
    },
    {
      "epoch": 1.1716594008718955,
      "grad_norm": 0.0589381568133831,
      "learning_rate": 3.0479342478902535e-05,
      "loss": 0.0686,
      "step": 58590
    },
    {
      "epoch": 1.171859376874775,
      "grad_norm": 0.0912264883518219,
      "learning_rate": 3.0476009545521204e-05,
      "loss": 0.0838,
      "step": 58600
    },
    {
      "epoch": 1.1720593528776546,
      "grad_norm": 0.06719395518302917,
      "learning_rate": 3.0472676612139877e-05,
      "loss": 0.0604,
      "step": 58610
    },
    {
      "epoch": 1.1722593288805343,
      "grad_norm": 0.08271651715040207,
      "learning_rate": 3.046934367875855e-05,
      "loss": 0.0491,
      "step": 58620
    },
    {
      "epoch": 1.172459304883414,
      "grad_norm": 0.059184327721595764,
      "learning_rate": 3.046601074537722e-05,
      "loss": 0.0797,
      "step": 58630
    },
    {
      "epoch": 1.1726592808862937,
      "grad_norm": 0.11920410394668579,
      "learning_rate": 3.0462677811995893e-05,
      "loss": 0.0521,
      "step": 58640
    },
    {
      "epoch": 1.1728592568891734,
      "grad_norm": 0.08803417533636093,
      "learning_rate": 3.0459344878614566e-05,
      "loss": 0.076,
      "step": 58650
    },
    {
      "epoch": 1.173059232892053,
      "grad_norm": 0.06513682007789612,
      "learning_rate": 3.0456011945233242e-05,
      "loss": 0.0726,
      "step": 58660
    },
    {
      "epoch": 1.1732592088949325,
      "grad_norm": 0.1325298398733139,
      "learning_rate": 3.0452679011851915e-05,
      "loss": 0.0756,
      "step": 58670
    },
    {
      "epoch": 1.1734591848978122,
      "grad_norm": 0.0647997334599495,
      "learning_rate": 3.0449346078470585e-05,
      "loss": 0.0562,
      "step": 58680
    },
    {
      "epoch": 1.173659160900692,
      "grad_norm": 0.1795356571674347,
      "learning_rate": 3.0446013145089258e-05,
      "loss": 0.0914,
      "step": 58690
    },
    {
      "epoch": 1.1738591369035716,
      "grad_norm": 0.18045103549957275,
      "learning_rate": 3.044268021170793e-05,
      "loss": 0.0726,
      "step": 58700
    },
    {
      "epoch": 1.1740591129064513,
      "grad_norm": 0.10481972992420197,
      "learning_rate": 3.04393472783266e-05,
      "loss": 0.0756,
      "step": 58710
    },
    {
      "epoch": 1.174259088909331,
      "grad_norm": 0.09049339592456818,
      "learning_rate": 3.0436014344945274e-05,
      "loss": 0.0695,
      "step": 58720
    },
    {
      "epoch": 1.1744590649122104,
      "grad_norm": 0.07279861718416214,
      "learning_rate": 3.0432681411563947e-05,
      "loss": 0.0366,
      "step": 58730
    },
    {
      "epoch": 1.17465904091509,
      "grad_norm": 0.23296526074409485,
      "learning_rate": 3.0429348478182616e-05,
      "loss": 0.0947,
      "step": 58740
    },
    {
      "epoch": 1.1748590169179698,
      "grad_norm": 0.08692790567874908,
      "learning_rate": 3.042601554480129e-05,
      "loss": 0.0642,
      "step": 58750
    },
    {
      "epoch": 1.1750589929208495,
      "grad_norm": 0.05421151965856552,
      "learning_rate": 3.0422682611419966e-05,
      "loss": 0.0423,
      "step": 58760
    },
    {
      "epoch": 1.1752589689237292,
      "grad_norm": 0.1967145800590515,
      "learning_rate": 3.041934967803864e-05,
      "loss": 0.1065,
      "step": 58770
    },
    {
      "epoch": 1.1754589449266089,
      "grad_norm": 0.061590198427438736,
      "learning_rate": 3.041601674465731e-05,
      "loss": 0.1005,
      "step": 58780
    },
    {
      "epoch": 1.1756589209294885,
      "grad_norm": 0.05046652629971504,
      "learning_rate": 3.041268381127598e-05,
      "loss": 0.0773,
      "step": 58790
    },
    {
      "epoch": 1.1758588969323682,
      "grad_norm": 0.11851011961698532,
      "learning_rate": 3.0409350877894654e-05,
      "loss": 0.0447,
      "step": 58800
    },
    {
      "epoch": 1.1760588729352477,
      "grad_norm": 0.08398512005805969,
      "learning_rate": 3.0406017944513327e-05,
      "loss": 0.0813,
      "step": 58810
    },
    {
      "epoch": 1.1762588489381274,
      "grad_norm": 0.1069316640496254,
      "learning_rate": 3.0402685011131997e-05,
      "loss": 0.0681,
      "step": 58820
    },
    {
      "epoch": 1.176458824941007,
      "grad_norm": 0.07247427850961685,
      "learning_rate": 3.039935207775067e-05,
      "loss": 0.0701,
      "step": 58830
    },
    {
      "epoch": 1.1766588009438868,
      "grad_norm": 0.1356075555086136,
      "learning_rate": 3.0396019144369343e-05,
      "loss": 0.0834,
      "step": 58840
    },
    {
      "epoch": 1.1768587769467664,
      "grad_norm": 0.11024211347103119,
      "learning_rate": 3.0392686210988012e-05,
      "loss": 0.0578,
      "step": 58850
    },
    {
      "epoch": 1.1770587529496461,
      "grad_norm": 0.1325771063566208,
      "learning_rate": 3.0389353277606692e-05,
      "loss": 0.0646,
      "step": 58860
    },
    {
      "epoch": 1.1772587289525256,
      "grad_norm": 0.15397576987743378,
      "learning_rate": 3.0386020344225362e-05,
      "loss": 0.056,
      "step": 58870
    },
    {
      "epoch": 1.1774587049554053,
      "grad_norm": 0.14499908685684204,
      "learning_rate": 3.0382687410844035e-05,
      "loss": 0.0693,
      "step": 58880
    },
    {
      "epoch": 1.177658680958285,
      "grad_norm": 0.049066197127103806,
      "learning_rate": 3.0379354477462708e-05,
      "loss": 0.0633,
      "step": 58890
    },
    {
      "epoch": 1.1778586569611647,
      "grad_norm": 0.07851813733577728,
      "learning_rate": 3.0376021544081377e-05,
      "loss": 0.0441,
      "step": 58900
    },
    {
      "epoch": 1.1780586329640443,
      "grad_norm": 0.20236791670322418,
      "learning_rate": 3.037268861070005e-05,
      "loss": 0.0815,
      "step": 58910
    },
    {
      "epoch": 1.178258608966924,
      "grad_norm": 0.11964152008295059,
      "learning_rate": 3.0369355677318723e-05,
      "loss": 0.0608,
      "step": 58920
    },
    {
      "epoch": 1.1784585849698037,
      "grad_norm": 0.17364844679832458,
      "learning_rate": 3.0366022743937393e-05,
      "loss": 0.0657,
      "step": 58930
    },
    {
      "epoch": 1.1786585609726834,
      "grad_norm": 0.14699631929397583,
      "learning_rate": 3.0362689810556066e-05,
      "loss": 0.0669,
      "step": 58940
    },
    {
      "epoch": 1.1788585369755629,
      "grad_norm": 0.0826852023601532,
      "learning_rate": 3.035935687717474e-05,
      "loss": 0.107,
      "step": 58950
    },
    {
      "epoch": 1.1790585129784426,
      "grad_norm": 0.07627083361148834,
      "learning_rate": 3.035602394379341e-05,
      "loss": 0.1034,
      "step": 58960
    },
    {
      "epoch": 1.1792584889813222,
      "grad_norm": 0.10085754841566086,
      "learning_rate": 3.035269101041209e-05,
      "loss": 0.068,
      "step": 58970
    },
    {
      "epoch": 1.179458464984202,
      "grad_norm": 0.225926011800766,
      "learning_rate": 3.0349358077030758e-05,
      "loss": 0.0814,
      "step": 58980
    },
    {
      "epoch": 1.1796584409870816,
      "grad_norm": 0.16190384328365326,
      "learning_rate": 3.034602514364943e-05,
      "loss": 0.1003,
      "step": 58990
    },
    {
      "epoch": 1.1798584169899613,
      "grad_norm": 0.11263889074325562,
      "learning_rate": 3.0342692210268104e-05,
      "loss": 0.0971,
      "step": 59000
    },
    {
      "epoch": 1.1800583929928408,
      "grad_norm": 0.07127760350704193,
      "learning_rate": 3.0339359276886774e-05,
      "loss": 0.0668,
      "step": 59010
    },
    {
      "epoch": 1.1802583689957205,
      "grad_norm": 0.1436453014612198,
      "learning_rate": 3.0336026343505447e-05,
      "loss": 0.0672,
      "step": 59020
    },
    {
      "epoch": 1.1804583449986001,
      "grad_norm": 0.18673895299434662,
      "learning_rate": 3.033269341012412e-05,
      "loss": 0.0833,
      "step": 59030
    },
    {
      "epoch": 1.1806583210014798,
      "grad_norm": 0.10618152469396591,
      "learning_rate": 3.032936047674279e-05,
      "loss": 0.0569,
      "step": 59040
    },
    {
      "epoch": 1.1808582970043595,
      "grad_norm": 0.19723956286907196,
      "learning_rate": 3.0326027543361462e-05,
      "loss": 0.0969,
      "step": 59050
    },
    {
      "epoch": 1.1810582730072392,
      "grad_norm": 0.18355697393417358,
      "learning_rate": 3.0322694609980135e-05,
      "loss": 0.0859,
      "step": 59060
    },
    {
      "epoch": 1.1812582490101189,
      "grad_norm": 0.06561797112226486,
      "learning_rate": 3.0319361676598812e-05,
      "loss": 0.0348,
      "step": 59070
    },
    {
      "epoch": 1.1814582250129984,
      "grad_norm": 0.11771950125694275,
      "learning_rate": 3.0316028743217485e-05,
      "loss": 0.0523,
      "step": 59080
    },
    {
      "epoch": 1.181658201015878,
      "grad_norm": 0.20169973373413086,
      "learning_rate": 3.0312695809836154e-05,
      "loss": 0.0661,
      "step": 59090
    },
    {
      "epoch": 1.1818581770187577,
      "grad_norm": 0.1370536983013153,
      "learning_rate": 3.0309362876454827e-05,
      "loss": 0.0676,
      "step": 59100
    },
    {
      "epoch": 1.1820581530216374,
      "grad_norm": 0.09682803601026535,
      "learning_rate": 3.03060299430735e-05,
      "loss": 0.065,
      "step": 59110
    },
    {
      "epoch": 1.182258129024517,
      "grad_norm": 0.11201619356870651,
      "learning_rate": 3.030269700969217e-05,
      "loss": 0.0834,
      "step": 59120
    },
    {
      "epoch": 1.1824581050273968,
      "grad_norm": 0.09309045225381851,
      "learning_rate": 3.0299364076310843e-05,
      "loss": 0.2262,
      "step": 59130
    },
    {
      "epoch": 1.1826580810302763,
      "grad_norm": 0.24525733292102814,
      "learning_rate": 3.0296031142929516e-05,
      "loss": 0.0817,
      "step": 59140
    },
    {
      "epoch": 1.182858057033156,
      "grad_norm": 0.07283705472946167,
      "learning_rate": 3.0292698209548186e-05,
      "loss": 0.0927,
      "step": 59150
    },
    {
      "epoch": 1.1830580330360356,
      "grad_norm": 0.0969761535525322,
      "learning_rate": 3.028936527616686e-05,
      "loss": 0.0489,
      "step": 59160
    },
    {
      "epoch": 1.1832580090389153,
      "grad_norm": 0.15706054866313934,
      "learning_rate": 3.0286032342785535e-05,
      "loss": 0.0549,
      "step": 59170
    },
    {
      "epoch": 1.183457985041795,
      "grad_norm": 0.05410474166274071,
      "learning_rate": 3.0282699409404208e-05,
      "loss": 0.079,
      "step": 59180
    },
    {
      "epoch": 1.1836579610446747,
      "grad_norm": 0.06970575451850891,
      "learning_rate": 3.027936647602288e-05,
      "loss": 0.0763,
      "step": 59190
    },
    {
      "epoch": 1.1838579370475544,
      "grad_norm": 0.16976438462734222,
      "learning_rate": 3.027603354264155e-05,
      "loss": 0.0604,
      "step": 59200
    },
    {
      "epoch": 1.184057913050434,
      "grad_norm": 0.1837085783481598,
      "learning_rate": 3.0272700609260224e-05,
      "loss": 0.0732,
      "step": 59210
    },
    {
      "epoch": 1.1842578890533135,
      "grad_norm": 0.10547782480716705,
      "learning_rate": 3.0269367675878897e-05,
      "loss": 0.0551,
      "step": 59220
    },
    {
      "epoch": 1.1844578650561932,
      "grad_norm": 0.19391629099845886,
      "learning_rate": 3.0266034742497566e-05,
      "loss": 0.0721,
      "step": 59230
    },
    {
      "epoch": 1.184657841059073,
      "grad_norm": 0.24051807820796967,
      "learning_rate": 3.026270180911624e-05,
      "loss": 0.0723,
      "step": 59240
    },
    {
      "epoch": 1.1848578170619526,
      "grad_norm": 0.136116623878479,
      "learning_rate": 3.0259368875734912e-05,
      "loss": 0.0558,
      "step": 59250
    },
    {
      "epoch": 1.1850577930648323,
      "grad_norm": 0.20486287772655487,
      "learning_rate": 3.0256035942353582e-05,
      "loss": 0.0879,
      "step": 59260
    },
    {
      "epoch": 1.185257769067712,
      "grad_norm": 0.18892264366149902,
      "learning_rate": 3.025270300897226e-05,
      "loss": 0.0885,
      "step": 59270
    },
    {
      "epoch": 1.1854577450705914,
      "grad_norm": 0.1714828759431839,
      "learning_rate": 3.024937007559093e-05,
      "loss": 0.0963,
      "step": 59280
    },
    {
      "epoch": 1.1856577210734711,
      "grad_norm": 0.22200174629688263,
      "learning_rate": 3.0246037142209604e-05,
      "loss": 0.1099,
      "step": 59290
    },
    {
      "epoch": 1.1858576970763508,
      "grad_norm": 0.12205325067043304,
      "learning_rate": 3.0242704208828277e-05,
      "loss": 0.0842,
      "step": 59300
    },
    {
      "epoch": 1.1860576730792305,
      "grad_norm": 0.19838091731071472,
      "learning_rate": 3.0239371275446947e-05,
      "loss": 0.3082,
      "step": 59310
    },
    {
      "epoch": 1.1862576490821102,
      "grad_norm": 0.20430311560630798,
      "learning_rate": 3.023603834206562e-05,
      "loss": 0.0669,
      "step": 59320
    },
    {
      "epoch": 1.1864576250849899,
      "grad_norm": 0.18132999539375305,
      "learning_rate": 3.0232705408684293e-05,
      "loss": 0.0837,
      "step": 59330
    },
    {
      "epoch": 1.1866576010878696,
      "grad_norm": 0.10007977485656738,
      "learning_rate": 3.0229372475302963e-05,
      "loss": 0.0637,
      "step": 59340
    },
    {
      "epoch": 1.186857577090749,
      "grad_norm": 0.1890629678964615,
      "learning_rate": 3.0226039541921636e-05,
      "loss": 0.092,
      "step": 59350
    },
    {
      "epoch": 1.1870575530936287,
      "grad_norm": 0.18220192193984985,
      "learning_rate": 3.022270660854031e-05,
      "loss": 0.0913,
      "step": 59360
    },
    {
      "epoch": 1.1872575290965084,
      "grad_norm": 0.10602723807096481,
      "learning_rate": 3.0219373675158985e-05,
      "loss": 0.1194,
      "step": 59370
    },
    {
      "epoch": 1.187457505099388,
      "grad_norm": 0.10378443449735641,
      "learning_rate": 3.0216040741777658e-05,
      "loss": 0.0543,
      "step": 59380
    },
    {
      "epoch": 1.1876574811022678,
      "grad_norm": 0.20482107996940613,
      "learning_rate": 3.0212707808396328e-05,
      "loss": 0.0847,
      "step": 59390
    },
    {
      "epoch": 1.1878574571051475,
      "grad_norm": 0.19464842975139618,
      "learning_rate": 3.0209374875015e-05,
      "loss": 0.0862,
      "step": 59400
    },
    {
      "epoch": 1.188057433108027,
      "grad_norm": 0.10016614198684692,
      "learning_rate": 3.0206041941633674e-05,
      "loss": 0.0651,
      "step": 59410
    },
    {
      "epoch": 1.1882574091109066,
      "grad_norm": 0.25942379236221313,
      "learning_rate": 3.0202709008252343e-05,
      "loss": 0.1167,
      "step": 59420
    },
    {
      "epoch": 1.1884573851137863,
      "grad_norm": 0.1658567190170288,
      "learning_rate": 3.0199376074871016e-05,
      "loss": 0.0562,
      "step": 59430
    },
    {
      "epoch": 1.188657361116666,
      "grad_norm": 0.19478334486484528,
      "learning_rate": 3.019604314148969e-05,
      "loss": 0.0999,
      "step": 59440
    },
    {
      "epoch": 1.1888573371195457,
      "grad_norm": 0.09173320233821869,
      "learning_rate": 3.019271020810836e-05,
      "loss": 0.0823,
      "step": 59450
    },
    {
      "epoch": 1.1890573131224254,
      "grad_norm": 0.09595008194446564,
      "learning_rate": 3.0189377274727032e-05,
      "loss": 0.0737,
      "step": 59460
    },
    {
      "epoch": 1.189257289125305,
      "grad_norm": 0.057705312967300415,
      "learning_rate": 3.0186044341345705e-05,
      "loss": 0.05,
      "step": 59470
    },
    {
      "epoch": 1.1894572651281847,
      "grad_norm": 0.13571912050247192,
      "learning_rate": 3.018304470130251e-05,
      "loss": 0.1107,
      "step": 59480
    },
    {
      "epoch": 1.1896572411310642,
      "grad_norm": 0.11672297865152359,
      "learning_rate": 3.0179711767921183e-05,
      "loss": 0.0876,
      "step": 59490
    },
    {
      "epoch": 1.1898572171339439,
      "grad_norm": 0.06160669028759003,
      "learning_rate": 3.017637883453986e-05,
      "loss": 0.0633,
      "step": 59500
    },
    {
      "epoch": 1.1900571931368236,
      "grad_norm": 0.1132827177643776,
      "learning_rate": 3.0173045901158533e-05,
      "loss": 0.0588,
      "step": 59510
    },
    {
      "epoch": 1.1902571691397033,
      "grad_norm": 0.11072134226560593,
      "learning_rate": 3.0169712967777202e-05,
      "loss": 0.0907,
      "step": 59520
    },
    {
      "epoch": 1.190457145142583,
      "grad_norm": 0.07141280174255371,
      "learning_rate": 3.0166380034395875e-05,
      "loss": 0.0936,
      "step": 59530
    },
    {
      "epoch": 1.1906571211454626,
      "grad_norm": 0.11500934511423111,
      "learning_rate": 3.0163047101014548e-05,
      "loss": 0.0694,
      "step": 59540
    },
    {
      "epoch": 1.190857097148342,
      "grad_norm": 0.07251319289207458,
      "learning_rate": 3.0159714167633218e-05,
      "loss": 0.0425,
      "step": 59550
    },
    {
      "epoch": 1.1910570731512218,
      "grad_norm": 0.09805770963430405,
      "learning_rate": 3.015638123425189e-05,
      "loss": 0.0665,
      "step": 59560
    },
    {
      "epoch": 1.1912570491541015,
      "grad_norm": 0.10274956375360489,
      "learning_rate": 3.0153048300870564e-05,
      "loss": 0.1428,
      "step": 59570
    },
    {
      "epoch": 1.1914570251569812,
      "grad_norm": 0.06370871514081955,
      "learning_rate": 3.0149715367489233e-05,
      "loss": 0.046,
      "step": 59580
    },
    {
      "epoch": 1.1916570011598608,
      "grad_norm": 0.09440591186285019,
      "learning_rate": 3.0146382434107906e-05,
      "loss": 0.0693,
      "step": 59590
    },
    {
      "epoch": 1.1918569771627405,
      "grad_norm": 0.09236402064561844,
      "learning_rate": 3.0143049500726583e-05,
      "loss": 0.0565,
      "step": 59600
    },
    {
      "epoch": 1.1920569531656202,
      "grad_norm": 0.17321287095546722,
      "learning_rate": 3.0139716567345256e-05,
      "loss": 0.0842,
      "step": 59610
    },
    {
      "epoch": 1.1922569291685,
      "grad_norm": 0.2367120236158371,
      "learning_rate": 3.013638363396393e-05,
      "loss": 0.0734,
      "step": 59620
    },
    {
      "epoch": 1.1924569051713794,
      "grad_norm": 0.05844663083553314,
      "learning_rate": 3.01330507005826e-05,
      "loss": 0.064,
      "step": 59630
    },
    {
      "epoch": 1.192656881174259,
      "grad_norm": 0.207573801279068,
      "learning_rate": 3.012971776720127e-05,
      "loss": 0.0899,
      "step": 59640
    },
    {
      "epoch": 1.1928568571771387,
      "grad_norm": 0.0925249457359314,
      "learning_rate": 3.0126384833819944e-05,
      "loss": 0.09,
      "step": 59650
    },
    {
      "epoch": 1.1930568331800184,
      "grad_norm": 0.17206521332263947,
      "learning_rate": 3.0123051900438614e-05,
      "loss": 0.0751,
      "step": 59660
    },
    {
      "epoch": 1.1932568091828981,
      "grad_norm": 0.07384853810071945,
      "learning_rate": 3.0119718967057287e-05,
      "loss": 0.086,
      "step": 59670
    },
    {
      "epoch": 1.1934567851857778,
      "grad_norm": 0.10430185496807098,
      "learning_rate": 3.011638603367596e-05,
      "loss": 0.0542,
      "step": 59680
    },
    {
      "epoch": 1.1936567611886573,
      "grad_norm": 0.1070503294467926,
      "learning_rate": 3.011305310029463e-05,
      "loss": 0.0859,
      "step": 59690
    },
    {
      "epoch": 1.193856737191537,
      "grad_norm": 0.10082320868968964,
      "learning_rate": 3.010972016691331e-05,
      "loss": 0.0716,
      "step": 59700
    },
    {
      "epoch": 1.1940567131944166,
      "grad_norm": 0.1306154727935791,
      "learning_rate": 3.010638723353198e-05,
      "loss": 0.0793,
      "step": 59710
    },
    {
      "epoch": 1.1942566891972963,
      "grad_norm": 0.12869031727313995,
      "learning_rate": 3.0103054300150652e-05,
      "loss": 0.0632,
      "step": 59720
    },
    {
      "epoch": 1.194456665200176,
      "grad_norm": 0.10511620342731476,
      "learning_rate": 3.0099721366769325e-05,
      "loss": 0.0793,
      "step": 59730
    },
    {
      "epoch": 1.1946566412030557,
      "grad_norm": 0.19568049907684326,
      "learning_rate": 3.0096388433387995e-05,
      "loss": 0.097,
      "step": 59740
    },
    {
      "epoch": 1.1948566172059354,
      "grad_norm": 0.20990170538425446,
      "learning_rate": 3.0093055500006668e-05,
      "loss": 0.123,
      "step": 59750
    },
    {
      "epoch": 1.1950565932088149,
      "grad_norm": 0.17991888523101807,
      "learning_rate": 3.008972256662534e-05,
      "loss": 0.076,
      "step": 59760
    },
    {
      "epoch": 1.1952565692116945,
      "grad_norm": 0.12577782571315765,
      "learning_rate": 3.008638963324401e-05,
      "loss": 0.0843,
      "step": 59770
    },
    {
      "epoch": 1.1954565452145742,
      "grad_norm": 0.10607964545488358,
      "learning_rate": 3.0083056699862683e-05,
      "loss": 0.0576,
      "step": 59780
    },
    {
      "epoch": 1.195656521217454,
      "grad_norm": 0.1574469357728958,
      "learning_rate": 3.0079723766481356e-05,
      "loss": 0.081,
      "step": 59790
    },
    {
      "epoch": 1.1958564972203336,
      "grad_norm": 0.14586199820041656,
      "learning_rate": 3.0076390833100033e-05,
      "loss": 0.0959,
      "step": 59800
    },
    {
      "epoch": 1.1960564732232133,
      "grad_norm": 0.10622546076774597,
      "learning_rate": 3.0073057899718702e-05,
      "loss": 0.0589,
      "step": 59810
    },
    {
      "epoch": 1.1962564492260928,
      "grad_norm": 0.08449758589267731,
      "learning_rate": 3.0069724966337375e-05,
      "loss": 0.082,
      "step": 59820
    },
    {
      "epoch": 1.1964564252289724,
      "grad_norm": 0.06250903010368347,
      "learning_rate": 3.006639203295605e-05,
      "loss": 0.0478,
      "step": 59830
    },
    {
      "epoch": 1.1966564012318521,
      "grad_norm": 0.2322138100862503,
      "learning_rate": 3.0063392392912854e-05,
      "loss": 0.0851,
      "step": 59840
    },
    {
      "epoch": 1.1968563772347318,
      "grad_norm": 0.17846202850341797,
      "learning_rate": 3.0060059459531527e-05,
      "loss": 0.065,
      "step": 59850
    },
    {
      "epoch": 1.1970563532376115,
      "grad_norm": 0.27280449867248535,
      "learning_rate": 3.0056726526150196e-05,
      "loss": 0.0703,
      "step": 59860
    },
    {
      "epoch": 1.1972563292404912,
      "grad_norm": 0.1037294864654541,
      "learning_rate": 3.005339359276887e-05,
      "loss": 0.0656,
      "step": 59870
    },
    {
      "epoch": 1.1974563052433709,
      "grad_norm": 0.16986083984375,
      "learning_rate": 3.0050060659387542e-05,
      "loss": 0.0725,
      "step": 59880
    },
    {
      "epoch": 1.1976562812462506,
      "grad_norm": 0.050983015447854996,
      "learning_rate": 3.0046727726006212e-05,
      "loss": 0.0807,
      "step": 59890
    },
    {
      "epoch": 1.19785625724913,
      "grad_norm": 0.2127949744462967,
      "learning_rate": 3.0043394792624885e-05,
      "loss": 0.0783,
      "step": 59900
    },
    {
      "epoch": 1.1980562332520097,
      "grad_norm": 0.1728208214044571,
      "learning_rate": 3.0040061859243558e-05,
      "loss": 0.0686,
      "step": 59910
    },
    {
      "epoch": 1.1982562092548894,
      "grad_norm": 0.15643727779388428,
      "learning_rate": 3.0036728925862228e-05,
      "loss": 0.0572,
      "step": 59920
    },
    {
      "epoch": 1.198456185257769,
      "grad_norm": 0.07451003044843674,
      "learning_rate": 3.0033395992480907e-05,
      "loss": 0.0651,
      "step": 59930
    },
    {
      "epoch": 1.1986561612606488,
      "grad_norm": 0.11290325969457626,
      "learning_rate": 3.0030063059099577e-05,
      "loss": 0.0671,
      "step": 59940
    },
    {
      "epoch": 1.1988561372635285,
      "grad_norm": 0.09183816611766815,
      "learning_rate": 3.002673012571825e-05,
      "loss": 0.0609,
      "step": 59950
    },
    {
      "epoch": 1.199056113266408,
      "grad_norm": 0.13018454611301422,
      "learning_rate": 3.0023397192336923e-05,
      "loss": 0.0923,
      "step": 59960
    },
    {
      "epoch": 1.1992560892692876,
      "grad_norm": 0.09361360222101212,
      "learning_rate": 3.0020064258955593e-05,
      "loss": 0.0689,
      "step": 59970
    },
    {
      "epoch": 1.1994560652721673,
      "grad_norm": 0.1964719444513321,
      "learning_rate": 3.0016731325574266e-05,
      "loss": 0.0988,
      "step": 59980
    },
    {
      "epoch": 1.199656041275047,
      "grad_norm": 0.17106139659881592,
      "learning_rate": 3.001339839219294e-05,
      "loss": 0.1087,
      "step": 59990
    },
    {
      "epoch": 1.1998560172779267,
      "grad_norm": 0.0871913880109787,
      "learning_rate": 3.0010065458811608e-05,
      "loss": 0.0443,
      "step": 60000
    },
    {
      "epoch": 1.2000559932808064,
      "grad_norm": 0.06194320693612099,
      "learning_rate": 3.000673252543028e-05,
      "loss": 0.0759,
      "step": 60010
    },
    {
      "epoch": 1.200255969283686,
      "grad_norm": 0.0892428606748581,
      "learning_rate": 3.0003399592048954e-05,
      "loss": 0.0682,
      "step": 60020
    },
    {
      "epoch": 1.2004559452865655,
      "grad_norm": 0.09161239117383957,
      "learning_rate": 3.000006665866763e-05,
      "loss": 0.0782,
      "step": 60030
    },
    {
      "epoch": 1.2006559212894452,
      "grad_norm": 0.08739300072193146,
      "learning_rate": 2.9996733725286304e-05,
      "loss": 0.0957,
      "step": 60040
    },
    {
      "epoch": 1.200855897292325,
      "grad_norm": 0.1445847898721695,
      "learning_rate": 2.9993400791904973e-05,
      "loss": 0.0957,
      "step": 60050
    },
    {
      "epoch": 1.2010558732952046,
      "grad_norm": 0.0512063205242157,
      "learning_rate": 2.9990067858523646e-05,
      "loss": 0.0632,
      "step": 60060
    },
    {
      "epoch": 1.2012558492980843,
      "grad_norm": 0.20402038097381592,
      "learning_rate": 2.998673492514232e-05,
      "loss": 0.1092,
      "step": 60070
    },
    {
      "epoch": 1.201455825300964,
      "grad_norm": 0.20746761560440063,
      "learning_rate": 2.998340199176099e-05,
      "loss": 0.0805,
      "step": 60080
    },
    {
      "epoch": 1.2016558013038434,
      "grad_norm": 0.1988789141178131,
      "learning_rate": 2.9980069058379662e-05,
      "loss": 0.0774,
      "step": 60090
    },
    {
      "epoch": 1.201855777306723,
      "grad_norm": 0.08357808738946915,
      "learning_rate": 2.9976736124998335e-05,
      "loss": 0.0658,
      "step": 60100
    },
    {
      "epoch": 1.2020557533096028,
      "grad_norm": 0.08813878148794174,
      "learning_rate": 2.9973403191617004e-05,
      "loss": 0.0863,
      "step": 60110
    },
    {
      "epoch": 1.2022557293124825,
      "grad_norm": 0.06255562603473663,
      "learning_rate": 2.9970070258235677e-05,
      "loss": 0.0676,
      "step": 60120
    },
    {
      "epoch": 1.2024557053153622,
      "grad_norm": 0.19543471932411194,
      "learning_rate": 2.9966737324854354e-05,
      "loss": 0.0741,
      "step": 60130
    },
    {
      "epoch": 1.2026556813182419,
      "grad_norm": 0.06505858898162842,
      "learning_rate": 2.9963404391473027e-05,
      "loss": 0.0778,
      "step": 60140
    },
    {
      "epoch": 1.2028556573211215,
      "grad_norm": 0.11055450886487961,
      "learning_rate": 2.99600714580917e-05,
      "loss": 0.0695,
      "step": 60150
    },
    {
      "epoch": 1.2030556333240012,
      "grad_norm": 0.20096470415592194,
      "learning_rate": 2.995673852471037e-05,
      "loss": 0.0706,
      "step": 60160
    },
    {
      "epoch": 1.2032556093268807,
      "grad_norm": 0.18549133837223053,
      "learning_rate": 2.9953405591329043e-05,
      "loss": 0.0856,
      "step": 60170
    },
    {
      "epoch": 1.2034555853297604,
      "grad_norm": 0.09164062142372131,
      "learning_rate": 2.9950072657947716e-05,
      "loss": 0.0672,
      "step": 60180
    },
    {
      "epoch": 1.20365556133264,
      "grad_norm": 0.1566040813922882,
      "learning_rate": 2.9946739724566385e-05,
      "loss": 0.061,
      "step": 60190
    },
    {
      "epoch": 1.2038555373355198,
      "grad_norm": 0.0759214237332344,
      "learning_rate": 2.9943406791185058e-05,
      "loss": 0.0342,
      "step": 60200
    },
    {
      "epoch": 1.2040555133383994,
      "grad_norm": 0.13237209618091583,
      "learning_rate": 2.994007385780373e-05,
      "loss": 0.0709,
      "step": 60210
    },
    {
      "epoch": 1.2042554893412791,
      "grad_norm": 0.16866612434387207,
      "learning_rate": 2.99367409244224e-05,
      "loss": 0.0872,
      "step": 60220
    },
    {
      "epoch": 1.2044554653441586,
      "grad_norm": 0.10102348029613495,
      "learning_rate": 2.993340799104108e-05,
      "loss": 0.0499,
      "step": 60230
    },
    {
      "epoch": 1.2046554413470383,
      "grad_norm": 0.16418449580669403,
      "learning_rate": 2.993007505765975e-05,
      "loss": 0.0683,
      "step": 60240
    },
    {
      "epoch": 1.204855417349918,
      "grad_norm": 0.14481249451637268,
      "learning_rate": 2.9926742124278423e-05,
      "loss": 0.0778,
      "step": 60250
    },
    {
      "epoch": 1.2050553933527977,
      "grad_norm": 0.16472238302230835,
      "learning_rate": 2.9923409190897096e-05,
      "loss": 0.0827,
      "step": 60260
    },
    {
      "epoch": 1.2052553693556773,
      "grad_norm": 0.07077691704034805,
      "learning_rate": 2.9920076257515766e-05,
      "loss": 0.0663,
      "step": 60270
    },
    {
      "epoch": 1.205455345358557,
      "grad_norm": 0.2010238617658615,
      "learning_rate": 2.991674332413444e-05,
      "loss": 0.0925,
      "step": 60280
    },
    {
      "epoch": 1.2056553213614367,
      "grad_norm": 0.08016148954629898,
      "learning_rate": 2.9913410390753112e-05,
      "loss": 0.0863,
      "step": 60290
    },
    {
      "epoch": 1.2058552973643164,
      "grad_norm": 0.13319151103496552,
      "learning_rate": 2.991007745737178e-05,
      "loss": 0.0651,
      "step": 60300
    },
    {
      "epoch": 1.2060552733671959,
      "grad_norm": 0.13049329817295074,
      "learning_rate": 2.9906744523990454e-05,
      "loss": 0.0786,
      "step": 60310
    },
    {
      "epoch": 1.2062552493700756,
      "grad_norm": 0.14492465555667877,
      "learning_rate": 2.9903411590609127e-05,
      "loss": 0.0836,
      "step": 60320
    },
    {
      "epoch": 1.2064552253729552,
      "grad_norm": 0.09051855653524399,
      "learning_rate": 2.9900078657227797e-05,
      "loss": 0.1013,
      "step": 60330
    },
    {
      "epoch": 1.206655201375835,
      "grad_norm": 0.11143850535154343,
      "learning_rate": 2.9896745723846477e-05,
      "loss": 0.0614,
      "step": 60340
    },
    {
      "epoch": 1.2068551773787146,
      "grad_norm": 0.10084585845470428,
      "learning_rate": 2.9893412790465146e-05,
      "loss": 0.0651,
      "step": 60350
    },
    {
      "epoch": 1.2070551533815943,
      "grad_norm": 0.06306701898574829,
      "learning_rate": 2.989007985708382e-05,
      "loss": 0.046,
      "step": 60360
    },
    {
      "epoch": 1.2072551293844738,
      "grad_norm": 0.13496622443199158,
      "learning_rate": 2.9886746923702492e-05,
      "loss": 0.0827,
      "step": 60370
    },
    {
      "epoch": 1.2074551053873535,
      "grad_norm": 0.190540611743927,
      "learning_rate": 2.9883413990321162e-05,
      "loss": 0.0864,
      "step": 60380
    },
    {
      "epoch": 1.2076550813902331,
      "grad_norm": 0.13498592376708984,
      "learning_rate": 2.9880081056939835e-05,
      "loss": 0.0908,
      "step": 60390
    },
    {
      "epoch": 1.2078550573931128,
      "grad_norm": 0.24334506690502167,
      "learning_rate": 2.9876748123558508e-05,
      "loss": 0.0718,
      "step": 60400
    },
    {
      "epoch": 1.2080550333959925,
      "grad_norm": 0.18187867105007172,
      "learning_rate": 2.9873415190177178e-05,
      "loss": 0.0732,
      "step": 60410
    },
    {
      "epoch": 1.2082550093988722,
      "grad_norm": 0.25110775232315063,
      "learning_rate": 2.987008225679585e-05,
      "loss": 0.0943,
      "step": 60420
    },
    {
      "epoch": 1.208454985401752,
      "grad_norm": 0.09313120692968369,
      "learning_rate": 2.9866749323414524e-05,
      "loss": 0.0262,
      "step": 60430
    },
    {
      "epoch": 1.2086549614046314,
      "grad_norm": 0.1967543065547943,
      "learning_rate": 2.98634163900332e-05,
      "loss": 0.104,
      "step": 60440
    },
    {
      "epoch": 1.208854937407511,
      "grad_norm": 0.07372090220451355,
      "learning_rate": 2.9860083456651873e-05,
      "loss": 0.0773,
      "step": 60450
    },
    {
      "epoch": 1.2090549134103907,
      "grad_norm": 0.09893133491277695,
      "learning_rate": 2.9856750523270543e-05,
      "loss": 0.0835,
      "step": 60460
    },
    {
      "epoch": 1.2092548894132704,
      "grad_norm": 0.23237551748752594,
      "learning_rate": 2.9853417589889216e-05,
      "loss": 0.0722,
      "step": 60470
    },
    {
      "epoch": 1.20945486541615,
      "grad_norm": 0.16159504652023315,
      "learning_rate": 2.985008465650789e-05,
      "loss": 0.0804,
      "step": 60480
    },
    {
      "epoch": 1.2096548414190298,
      "grad_norm": 0.12409791350364685,
      "learning_rate": 2.984675172312656e-05,
      "loss": 0.0589,
      "step": 60490
    },
    {
      "epoch": 1.2098548174219093,
      "grad_norm": 0.13123758137226105,
      "learning_rate": 2.984341878974523e-05,
      "loss": 0.1226,
      "step": 60500
    },
    {
      "epoch": 1.210054793424789,
      "grad_norm": 0.200391486287117,
      "learning_rate": 2.9840085856363904e-05,
      "loss": 0.1003,
      "step": 60510
    },
    {
      "epoch": 1.2102547694276686,
      "grad_norm": 0.1301301270723343,
      "learning_rate": 2.9836752922982574e-05,
      "loss": 0.0994,
      "step": 60520
    },
    {
      "epoch": 1.2104547454305483,
      "grad_norm": 0.07367820292711258,
      "learning_rate": 2.9833419989601247e-05,
      "loss": 0.0471,
      "step": 60530
    },
    {
      "epoch": 1.210654721433428,
      "grad_norm": 0.1793697327375412,
      "learning_rate": 2.9830087056219923e-05,
      "loss": 0.0883,
      "step": 60540
    },
    {
      "epoch": 1.2108546974363077,
      "grad_norm": 0.09766994416713715,
      "learning_rate": 2.9826754122838596e-05,
      "loss": 0.1191,
      "step": 60550
    },
    {
      "epoch": 1.2110546734391874,
      "grad_norm": 0.07308856397867203,
      "learning_rate": 2.982342118945727e-05,
      "loss": 0.0941,
      "step": 60560
    },
    {
      "epoch": 1.211254649442067,
      "grad_norm": 0.08745446056127548,
      "learning_rate": 2.982008825607594e-05,
      "loss": 0.0702,
      "step": 60570
    },
    {
      "epoch": 1.2114546254449465,
      "grad_norm": 0.10455460101366043,
      "learning_rate": 2.9816755322694612e-05,
      "loss": 0.076,
      "step": 60580
    },
    {
      "epoch": 1.2116546014478262,
      "grad_norm": 0.10674456506967545,
      "learning_rate": 2.9813422389313285e-05,
      "loss": 0.0789,
      "step": 60590
    },
    {
      "epoch": 1.211854577450706,
      "grad_norm": 0.08233395218849182,
      "learning_rate": 2.9810089455931955e-05,
      "loss": 0.0916,
      "step": 60600
    },
    {
      "epoch": 1.2120545534535856,
      "grad_norm": 0.09689538925886154,
      "learning_rate": 2.9806756522550628e-05,
      "loss": 0.1024,
      "step": 60610
    },
    {
      "epoch": 1.2122545294564653,
      "grad_norm": 0.09142555296421051,
      "learning_rate": 2.98034235891693e-05,
      "loss": 0.0717,
      "step": 60620
    },
    {
      "epoch": 1.212454505459345,
      "grad_norm": 0.09294910728931427,
      "learning_rate": 2.980009065578797e-05,
      "loss": 0.0597,
      "step": 60630
    },
    {
      "epoch": 1.2126544814622244,
      "grad_norm": 0.05370228737592697,
      "learning_rate": 2.979675772240665e-05,
      "loss": 0.069,
      "step": 60640
    },
    {
      "epoch": 1.2128544574651041,
      "grad_norm": 0.10371112078428268,
      "learning_rate": 2.979342478902532e-05,
      "loss": 0.0596,
      "step": 60650
    },
    {
      "epoch": 1.2130544334679838,
      "grad_norm": 0.23392796516418457,
      "learning_rate": 2.9790091855643993e-05,
      "loss": 0.0918,
      "step": 60660
    },
    {
      "epoch": 1.2132544094708635,
      "grad_norm": 0.13620656728744507,
      "learning_rate": 2.9786758922262666e-05,
      "loss": 0.0625,
      "step": 60670
    },
    {
      "epoch": 1.2134543854737432,
      "grad_norm": 0.1362026035785675,
      "learning_rate": 2.9783425988881335e-05,
      "loss": 0.0891,
      "step": 60680
    },
    {
      "epoch": 1.2136543614766229,
      "grad_norm": 0.07237108796834946,
      "learning_rate": 2.9780093055500008e-05,
      "loss": 0.0428,
      "step": 60690
    },
    {
      "epoch": 1.2138543374795026,
      "grad_norm": 0.08548641204833984,
      "learning_rate": 2.977676012211868e-05,
      "loss": 0.0589,
      "step": 60700
    },
    {
      "epoch": 1.214054313482382,
      "grad_norm": 0.10778746753931046,
      "learning_rate": 2.977342718873735e-05,
      "loss": 0.0421,
      "step": 60710
    },
    {
      "epoch": 1.2142542894852617,
      "grad_norm": 0.06204258278012276,
      "learning_rate": 2.9770094255356024e-05,
      "loss": 0.0474,
      "step": 60720
    },
    {
      "epoch": 1.2144542654881414,
      "grad_norm": 0.12319528311491013,
      "learning_rate": 2.9766761321974697e-05,
      "loss": 0.0767,
      "step": 60730
    },
    {
      "epoch": 1.214654241491021,
      "grad_norm": 0.09767422825098038,
      "learning_rate": 2.9763428388593373e-05,
      "loss": 0.0846,
      "step": 60740
    },
    {
      "epoch": 1.2148542174939008,
      "grad_norm": 0.1045074537396431,
      "learning_rate": 2.9760095455212046e-05,
      "loss": 0.0635,
      "step": 60750
    },
    {
      "epoch": 1.2150541934967805,
      "grad_norm": 0.11001794040203094,
      "learning_rate": 2.9756762521830716e-05,
      "loss": 0.0722,
      "step": 60760
    },
    {
      "epoch": 1.21525416949966,
      "grad_norm": 0.12615269422531128,
      "learning_rate": 2.975342958844939e-05,
      "loss": 0.0625,
      "step": 60770
    },
    {
      "epoch": 1.2154541455025396,
      "grad_norm": 0.13955488801002502,
      "learning_rate": 2.9750096655068062e-05,
      "loss": 0.0994,
      "step": 60780
    },
    {
      "epoch": 1.2156541215054193,
      "grad_norm": 0.11424876749515533,
      "learning_rate": 2.974676372168673e-05,
      "loss": 0.09,
      "step": 60790
    },
    {
      "epoch": 1.215854097508299,
      "grad_norm": 0.20961813628673553,
      "learning_rate": 2.9743430788305404e-05,
      "loss": 0.0919,
      "step": 60800
    },
    {
      "epoch": 1.2160540735111787,
      "grad_norm": 0.08481192588806152,
      "learning_rate": 2.9740097854924078e-05,
      "loss": 0.0713,
      "step": 60810
    },
    {
      "epoch": 1.2162540495140584,
      "grad_norm": 0.12831982970237732,
      "learning_rate": 2.9736764921542747e-05,
      "loss": 0.0658,
      "step": 60820
    },
    {
      "epoch": 1.216454025516938,
      "grad_norm": 0.13640975952148438,
      "learning_rate": 2.973343198816142e-05,
      "loss": 0.084,
      "step": 60830
    },
    {
      "epoch": 1.2166540015198177,
      "grad_norm": 0.11066429316997528,
      "learning_rate": 2.9730099054780093e-05,
      "loss": 0.1263,
      "step": 60840
    },
    {
      "epoch": 1.2168539775226972,
      "grad_norm": 0.2313389778137207,
      "learning_rate": 2.972676612139877e-05,
      "loss": 0.1245,
      "step": 60850
    },
    {
      "epoch": 1.2170539535255769,
      "grad_norm": 0.08585549145936966,
      "learning_rate": 2.9723433188017443e-05,
      "loss": 0.0526,
      "step": 60860
    },
    {
      "epoch": 1.2172539295284566,
      "grad_norm": 0.10358253121376038,
      "learning_rate": 2.9720100254636112e-05,
      "loss": 0.0297,
      "step": 60870
    },
    {
      "epoch": 1.2174539055313363,
      "grad_norm": 0.1061079353094101,
      "learning_rate": 2.9716767321254785e-05,
      "loss": 0.0857,
      "step": 60880
    },
    {
      "epoch": 1.217653881534216,
      "grad_norm": 0.08219024538993835,
      "learning_rate": 2.9713434387873458e-05,
      "loss": 0.0965,
      "step": 60890
    },
    {
      "epoch": 1.2178538575370956,
      "grad_norm": 0.12905099987983704,
      "learning_rate": 2.9710101454492128e-05,
      "loss": 0.0817,
      "step": 60900
    },
    {
      "epoch": 1.218053833539975,
      "grad_norm": 0.12054212391376495,
      "learning_rate": 2.97067685211108e-05,
      "loss": 0.0788,
      "step": 60910
    },
    {
      "epoch": 1.2182538095428548,
      "grad_norm": 0.22527045011520386,
      "learning_rate": 2.9703435587729474e-05,
      "loss": 0.1064,
      "step": 60920
    },
    {
      "epoch": 1.2184537855457345,
      "grad_norm": 0.15143351256847382,
      "learning_rate": 2.9700102654348143e-05,
      "loss": 0.078,
      "step": 60930
    },
    {
      "epoch": 1.2186537615486142,
      "grad_norm": 0.0716501846909523,
      "learning_rate": 2.9696769720966816e-05,
      "loss": 0.0797,
      "step": 60940
    },
    {
      "epoch": 1.2188537375514938,
      "grad_norm": 0.08527600765228271,
      "learning_rate": 2.9693436787585493e-05,
      "loss": 0.0667,
      "step": 60950
    },
    {
      "epoch": 1.2190537135543735,
      "grad_norm": 0.13330931961536407,
      "learning_rate": 2.9690103854204166e-05,
      "loss": 0.1081,
      "step": 60960
    },
    {
      "epoch": 1.2192536895572532,
      "grad_norm": 0.10965024679899216,
      "learning_rate": 2.968677092082284e-05,
      "loss": 0.0689,
      "step": 60970
    },
    {
      "epoch": 1.219453665560133,
      "grad_norm": 0.19356700778007507,
      "learning_rate": 2.968343798744151e-05,
      "loss": 0.0873,
      "step": 60980
    },
    {
      "epoch": 1.2196536415630124,
      "grad_norm": 0.10636138916015625,
      "learning_rate": 2.968010505406018e-05,
      "loss": 0.0771,
      "step": 60990
    },
    {
      "epoch": 1.219853617565892,
      "grad_norm": 0.09070675075054169,
      "learning_rate": 2.9676772120678854e-05,
      "loss": 0.0755,
      "step": 61000
    },
    {
      "epoch": 1.2200535935687717,
      "grad_norm": 0.20562110841274261,
      "learning_rate": 2.9673439187297524e-05,
      "loss": 0.0747,
      "step": 61010
    },
    {
      "epoch": 1.2202535695716514,
      "grad_norm": 0.15049980580806732,
      "learning_rate": 2.9670106253916197e-05,
      "loss": 0.0652,
      "step": 61020
    },
    {
      "epoch": 1.2204535455745311,
      "grad_norm": 0.17607101798057556,
      "learning_rate": 2.966677332053487e-05,
      "loss": 0.0524,
      "step": 61030
    },
    {
      "epoch": 1.2206535215774108,
      "grad_norm": 0.1808343231678009,
      "learning_rate": 2.966344038715354e-05,
      "loss": 0.0645,
      "step": 61040
    },
    {
      "epoch": 1.2208534975802903,
      "grad_norm": 0.12296227365732193,
      "learning_rate": 2.966010745377222e-05,
      "loss": 0.091,
      "step": 61050
    },
    {
      "epoch": 1.22105347358317,
      "grad_norm": 0.19709821045398712,
      "learning_rate": 2.965677452039089e-05,
      "loss": 0.0816,
      "step": 61060
    },
    {
      "epoch": 1.2212534495860496,
      "grad_norm": 0.06343784183263779,
      "learning_rate": 2.9653441587009562e-05,
      "loss": 0.0546,
      "step": 61070
    },
    {
      "epoch": 1.2214534255889293,
      "grad_norm": 0.2165219932794571,
      "learning_rate": 2.9650108653628235e-05,
      "loss": 0.0793,
      "step": 61080
    },
    {
      "epoch": 1.221653401591809,
      "grad_norm": 0.09583918005228043,
      "learning_rate": 2.9646775720246905e-05,
      "loss": 0.084,
      "step": 61090
    },
    {
      "epoch": 1.2218533775946887,
      "grad_norm": 0.05551552027463913,
      "learning_rate": 2.9643442786865578e-05,
      "loss": 0.0873,
      "step": 61100
    },
    {
      "epoch": 1.2220533535975684,
      "grad_norm": 0.060149889439344406,
      "learning_rate": 2.964010985348425e-05,
      "loss": 0.078,
      "step": 61110
    },
    {
      "epoch": 1.2222533296004479,
      "grad_norm": 0.05666084960103035,
      "learning_rate": 2.963677692010292e-05,
      "loss": 0.1086,
      "step": 61120
    },
    {
      "epoch": 1.2224533056033275,
      "grad_norm": 0.11023703962564468,
      "learning_rate": 2.9633443986721593e-05,
      "loss": 0.1132,
      "step": 61130
    },
    {
      "epoch": 1.2226532816062072,
      "grad_norm": 0.18968144059181213,
      "learning_rate": 2.9630111053340266e-05,
      "loss": 0.1429,
      "step": 61140
    },
    {
      "epoch": 1.222853257609087,
      "grad_norm": 0.18660546839237213,
      "learning_rate": 2.9626778119958943e-05,
      "loss": 0.0715,
      "step": 61150
    },
    {
      "epoch": 1.2230532336119666,
      "grad_norm": 0.12642517685890198,
      "learning_rate": 2.9623445186577616e-05,
      "loss": 0.0676,
      "step": 61160
    },
    {
      "epoch": 1.2232532096148463,
      "grad_norm": 0.09985747933387756,
      "learning_rate": 2.9620112253196285e-05,
      "loss": 0.061,
      "step": 61170
    },
    {
      "epoch": 1.2234531856177258,
      "grad_norm": 0.07625012844800949,
      "learning_rate": 2.961677931981496e-05,
      "loss": 0.0704,
      "step": 61180
    },
    {
      "epoch": 1.2236531616206054,
      "grad_norm": 0.0717628076672554,
      "learning_rate": 2.961344638643363e-05,
      "loss": 0.1018,
      "step": 61190
    },
    {
      "epoch": 1.2238531376234851,
      "grad_norm": 0.09268356114625931,
      "learning_rate": 2.96101134530523e-05,
      "loss": 0.065,
      "step": 61200
    },
    {
      "epoch": 1.2240531136263648,
      "grad_norm": 0.12087574601173401,
      "learning_rate": 2.9606780519670974e-05,
      "loss": 0.0836,
      "step": 61210
    },
    {
      "epoch": 1.2242530896292445,
      "grad_norm": 0.1987054944038391,
      "learning_rate": 2.9603447586289647e-05,
      "loss": 0.0908,
      "step": 61220
    },
    {
      "epoch": 1.2244530656321242,
      "grad_norm": 0.12200288474559784,
      "learning_rate": 2.9600114652908317e-05,
      "loss": 0.0685,
      "step": 61230
    },
    {
      "epoch": 1.2246530416350039,
      "grad_norm": 0.06209807097911835,
      "learning_rate": 2.959678171952699e-05,
      "loss": 0.0898,
      "step": 61240
    },
    {
      "epoch": 1.2248530176378836,
      "grad_norm": 0.1368909627199173,
      "learning_rate": 2.9593448786145666e-05,
      "loss": 0.0905,
      "step": 61250
    },
    {
      "epoch": 1.225052993640763,
      "grad_norm": 0.09850489348173141,
      "learning_rate": 2.959011585276434e-05,
      "loss": 0.0813,
      "step": 61260
    },
    {
      "epoch": 1.2252529696436427,
      "grad_norm": 0.2520689368247986,
      "learning_rate": 2.9586782919383012e-05,
      "loss": 0.115,
      "step": 61270
    },
    {
      "epoch": 1.2254529456465224,
      "grad_norm": 0.21697060763835907,
      "learning_rate": 2.958344998600168e-05,
      "loss": 0.0632,
      "step": 61280
    },
    {
      "epoch": 1.225652921649402,
      "grad_norm": 0.15809926390647888,
      "learning_rate": 2.9580117052620355e-05,
      "loss": 0.1252,
      "step": 61290
    },
    {
      "epoch": 1.2258528976522818,
      "grad_norm": 0.12686510384082794,
      "learning_rate": 2.9576784119239028e-05,
      "loss": 0.0471,
      "step": 61300
    },
    {
      "epoch": 1.2260528736551615,
      "grad_norm": 0.19788870215415955,
      "learning_rate": 2.9573451185857697e-05,
      "loss": 0.08,
      "step": 61310
    },
    {
      "epoch": 1.226252849658041,
      "grad_norm": 0.20975279808044434,
      "learning_rate": 2.957011825247637e-05,
      "loss": 0.0953,
      "step": 61320
    },
    {
      "epoch": 1.2264528256609206,
      "grad_norm": 0.16943396627902985,
      "learning_rate": 2.9566785319095043e-05,
      "loss": 0.0726,
      "step": 61330
    },
    {
      "epoch": 1.2266528016638003,
      "grad_norm": 0.08824002742767334,
      "learning_rate": 2.9563452385713713e-05,
      "loss": 0.0598,
      "step": 61340
    },
    {
      "epoch": 1.22685277766668,
      "grad_norm": 0.14522093534469604,
      "learning_rate": 2.9560119452332386e-05,
      "loss": 0.0508,
      "step": 61350
    },
    {
      "epoch": 1.2270527536695597,
      "grad_norm": 0.14112704992294312,
      "learning_rate": 2.9556786518951062e-05,
      "loss": 0.0799,
      "step": 61360
    },
    {
      "epoch": 1.2272527296724394,
      "grad_norm": 0.12695999443531036,
      "learning_rate": 2.9553453585569735e-05,
      "loss": 0.0634,
      "step": 61370
    },
    {
      "epoch": 1.227452705675319,
      "grad_norm": 0.06143840029835701,
      "learning_rate": 2.9550120652188408e-05,
      "loss": 0.0573,
      "step": 61380
    },
    {
      "epoch": 1.2276526816781985,
      "grad_norm": 0.18552011251449585,
      "learning_rate": 2.9546787718807078e-05,
      "loss": 0.0895,
      "step": 61390
    },
    {
      "epoch": 1.2278526576810782,
      "grad_norm": 0.12326577305793762,
      "learning_rate": 2.954345478542575e-05,
      "loss": 0.083,
      "step": 61400
    },
    {
      "epoch": 1.228052633683958,
      "grad_norm": 0.14823995530605316,
      "learning_rate": 2.9540121852044424e-05,
      "loss": 0.0779,
      "step": 61410
    },
    {
      "epoch": 1.2282526096868376,
      "grad_norm": 0.15547426044940948,
      "learning_rate": 2.9536788918663093e-05,
      "loss": 0.0788,
      "step": 61420
    },
    {
      "epoch": 1.2284525856897173,
      "grad_norm": 0.19869954884052277,
      "learning_rate": 2.9533455985281766e-05,
      "loss": 0.0942,
      "step": 61430
    },
    {
      "epoch": 1.228652561692597,
      "grad_norm": 0.20268136262893677,
      "learning_rate": 2.953012305190044e-05,
      "loss": 0.0956,
      "step": 61440
    },
    {
      "epoch": 1.2288525376954764,
      "grad_norm": 0.11336260288953781,
      "learning_rate": 2.952679011851911e-05,
      "loss": 0.0511,
      "step": 61450
    },
    {
      "epoch": 1.229052513698356,
      "grad_norm": 0.11700396984815598,
      "learning_rate": 2.952345718513779e-05,
      "loss": 0.0587,
      "step": 61460
    },
    {
      "epoch": 1.2292524897012358,
      "grad_norm": 0.18570229411125183,
      "learning_rate": 2.952012425175646e-05,
      "loss": 0.0766,
      "step": 61470
    },
    {
      "epoch": 1.2294524657041155,
      "grad_norm": 0.10676398873329163,
      "learning_rate": 2.951679131837513e-05,
      "loss": 0.0629,
      "step": 61480
    },
    {
      "epoch": 1.2296524417069952,
      "grad_norm": 0.12465862184762955,
      "learning_rate": 2.9513458384993805e-05,
      "loss": 0.0624,
      "step": 61490
    },
    {
      "epoch": 1.2298524177098749,
      "grad_norm": 0.15009267628192902,
      "learning_rate": 2.9510125451612474e-05,
      "loss": 0.0951,
      "step": 61500
    },
    {
      "epoch": 1.2300523937127545,
      "grad_norm": 0.1860019862651825,
      "learning_rate": 2.9506792518231147e-05,
      "loss": 0.0959,
      "step": 61510
    },
    {
      "epoch": 1.2302523697156342,
      "grad_norm": 0.11636209487915039,
      "learning_rate": 2.950345958484982e-05,
      "loss": 0.0609,
      "step": 61520
    },
    {
      "epoch": 1.2304523457185137,
      "grad_norm": 0.06934807449579239,
      "learning_rate": 2.950012665146849e-05,
      "loss": 0.0494,
      "step": 61530
    },
    {
      "epoch": 1.2306523217213934,
      "grad_norm": 0.2305968552827835,
      "learning_rate": 2.9496793718087163e-05,
      "loss": 0.074,
      "step": 61540
    },
    {
      "epoch": 1.230852297724273,
      "grad_norm": 0.15936583280563354,
      "learning_rate": 2.9493460784705836e-05,
      "loss": 0.245,
      "step": 61550
    },
    {
      "epoch": 1.2310522737271528,
      "grad_norm": 0.15498992800712585,
      "learning_rate": 2.9490127851324512e-05,
      "loss": 0.0593,
      "step": 61560
    },
    {
      "epoch": 1.2312522497300324,
      "grad_norm": 0.10918160527944565,
      "learning_rate": 2.9486794917943185e-05,
      "loss": 0.1108,
      "step": 61570
    },
    {
      "epoch": 1.2314522257329121,
      "grad_norm": 0.07852053642272949,
      "learning_rate": 2.9483461984561855e-05,
      "loss": 0.066,
      "step": 61580
    },
    {
      "epoch": 1.2316522017357916,
      "grad_norm": 0.12924465537071228,
      "learning_rate": 2.9480129051180528e-05,
      "loss": 0.0603,
      "step": 61590
    },
    {
      "epoch": 1.2318521777386713,
      "grad_norm": 0.0901246890425682,
      "learning_rate": 2.94767961177992e-05,
      "loss": 0.0854,
      "step": 61600
    },
    {
      "epoch": 1.232052153741551,
      "grad_norm": 0.21975557506084442,
      "learning_rate": 2.947346318441787e-05,
      "loss": 0.1103,
      "step": 61610
    },
    {
      "epoch": 1.2322521297444307,
      "grad_norm": 0.07243245095014572,
      "learning_rate": 2.9470130251036543e-05,
      "loss": 0.0542,
      "step": 61620
    },
    {
      "epoch": 1.2324521057473103,
      "grad_norm": 0.1172022819519043,
      "learning_rate": 2.9466797317655216e-05,
      "loss": 0.0584,
      "step": 61630
    },
    {
      "epoch": 1.23265208175019,
      "grad_norm": 0.08297614753246307,
      "learning_rate": 2.9463464384273886e-05,
      "loss": 0.1775,
      "step": 61640
    },
    {
      "epoch": 1.2328520577530697,
      "grad_norm": 0.13815657794475555,
      "learning_rate": 2.946013145089256e-05,
      "loss": 0.1013,
      "step": 61650
    },
    {
      "epoch": 1.2330520337559494,
      "grad_norm": 0.07295693457126617,
      "learning_rate": 2.9456798517511235e-05,
      "loss": 0.2929,
      "step": 61660
    },
    {
      "epoch": 1.2332520097588289,
      "grad_norm": 0.1577381193637848,
      "learning_rate": 2.945346558412991e-05,
      "loss": 0.05,
      "step": 61670
    },
    {
      "epoch": 1.2334519857617086,
      "grad_norm": 0.08767304569482803,
      "learning_rate": 2.945013265074858e-05,
      "loss": 0.0709,
      "step": 61680
    },
    {
      "epoch": 1.2336519617645882,
      "grad_norm": 0.17703485488891602,
      "learning_rate": 2.944679971736725e-05,
      "loss": 0.0724,
      "step": 61690
    },
    {
      "epoch": 1.233851937767468,
      "grad_norm": 0.15745216608047485,
      "learning_rate": 2.9443466783985924e-05,
      "loss": 0.0835,
      "step": 61700
    },
    {
      "epoch": 1.2340519137703476,
      "grad_norm": 0.19670523703098297,
      "learning_rate": 2.9440133850604597e-05,
      "loss": 0.0765,
      "step": 61710
    },
    {
      "epoch": 1.2342518897732273,
      "grad_norm": 0.13838167488574982,
      "learning_rate": 2.9436800917223267e-05,
      "loss": 0.0858,
      "step": 61720
    },
    {
      "epoch": 1.2344518657761068,
      "grad_norm": 0.17602971196174622,
      "learning_rate": 2.943346798384194e-05,
      "loss": 0.2595,
      "step": 61730
    },
    {
      "epoch": 1.2346518417789865,
      "grad_norm": 0.0846451073884964,
      "learning_rate": 2.9430135050460613e-05,
      "loss": 0.0543,
      "step": 61740
    },
    {
      "epoch": 1.2348518177818661,
      "grad_norm": 0.0772114247083664,
      "learning_rate": 2.9426802117079282e-05,
      "loss": 0.0464,
      "step": 61750
    },
    {
      "epoch": 1.2350517937847458,
      "grad_norm": 0.05789561569690704,
      "learning_rate": 2.942346918369796e-05,
      "loss": 0.0713,
      "step": 61760
    },
    {
      "epoch": 1.2352517697876255,
      "grad_norm": 0.16046760976314545,
      "learning_rate": 2.942013625031663e-05,
      "loss": 0.0885,
      "step": 61770
    },
    {
      "epoch": 1.2354517457905052,
      "grad_norm": 0.24665948748588562,
      "learning_rate": 2.9416803316935305e-05,
      "loss": 0.1076,
      "step": 61780
    },
    {
      "epoch": 1.235651721793385,
      "grad_norm": 0.05807340517640114,
      "learning_rate": 2.9413470383553978e-05,
      "loss": 0.0545,
      "step": 61790
    },
    {
      "epoch": 1.2358516977962644,
      "grad_norm": 0.07559938728809357,
      "learning_rate": 2.9410137450172647e-05,
      "loss": 0.0406,
      "step": 61800
    },
    {
      "epoch": 1.236051673799144,
      "grad_norm": 0.059152282774448395,
      "learning_rate": 2.940680451679132e-05,
      "loss": 0.0778,
      "step": 61810
    },
    {
      "epoch": 1.2362516498020237,
      "grad_norm": 0.04955857992172241,
      "learning_rate": 2.9403471583409993e-05,
      "loss": 0.1098,
      "step": 61820
    },
    {
      "epoch": 1.2364516258049034,
      "grad_norm": 0.17118899524211884,
      "learning_rate": 2.9400138650028663e-05,
      "loss": 0.0846,
      "step": 61830
    },
    {
      "epoch": 1.236651601807783,
      "grad_norm": 0.23093271255493164,
      "learning_rate": 2.9396805716647336e-05,
      "loss": 0.0734,
      "step": 61840
    },
    {
      "epoch": 1.2368515778106628,
      "grad_norm": 0.17798753082752228,
      "learning_rate": 2.939347278326601e-05,
      "loss": 0.0901,
      "step": 61850
    },
    {
      "epoch": 1.2370515538135423,
      "grad_norm": 0.08867224305868149,
      "learning_rate": 2.939013984988468e-05,
      "loss": 0.0716,
      "step": 61860
    },
    {
      "epoch": 1.237251529816422,
      "grad_norm": 0.09749990701675415,
      "learning_rate": 2.9386806916503355e-05,
      "loss": 0.0823,
      "step": 61870
    },
    {
      "epoch": 1.2374515058193016,
      "grad_norm": 0.12249408662319183,
      "learning_rate": 2.9383473983122028e-05,
      "loss": 0.0795,
      "step": 61880
    },
    {
      "epoch": 1.2376514818221813,
      "grad_norm": 0.18465732038021088,
      "learning_rate": 2.93801410497407e-05,
      "loss": 0.087,
      "step": 61890
    },
    {
      "epoch": 1.237851457825061,
      "grad_norm": 0.18690802156925201,
      "learning_rate": 2.937680811635937e-05,
      "loss": 0.0708,
      "step": 61900
    },
    {
      "epoch": 1.2380514338279407,
      "grad_norm": 0.13045178353786469,
      "learning_rate": 2.9373475182978044e-05,
      "loss": 0.0825,
      "step": 61910
    },
    {
      "epoch": 1.2382514098308204,
      "grad_norm": 0.18389354646205902,
      "learning_rate": 2.9370142249596717e-05,
      "loss": 0.0997,
      "step": 61920
    },
    {
      "epoch": 1.2384513858337,
      "grad_norm": 0.16186054050922394,
      "learning_rate": 2.936680931621539e-05,
      "loss": 0.0875,
      "step": 61930
    },
    {
      "epoch": 1.2386513618365795,
      "grad_norm": 0.07769646495580673,
      "learning_rate": 2.936347638283406e-05,
      "loss": 0.046,
      "step": 61940
    },
    {
      "epoch": 1.2388513378394592,
      "grad_norm": 0.08556294441223145,
      "learning_rate": 2.9360143449452732e-05,
      "loss": 0.0471,
      "step": 61950
    },
    {
      "epoch": 1.239051313842339,
      "grad_norm": 0.2355475276708603,
      "learning_rate": 2.9356810516071405e-05,
      "loss": 0.0713,
      "step": 61960
    },
    {
      "epoch": 1.2392512898452186,
      "grad_norm": 0.15122313797473907,
      "learning_rate": 2.935347758269008e-05,
      "loss": 0.0938,
      "step": 61970
    },
    {
      "epoch": 1.2394512658480983,
      "grad_norm": 0.2025163471698761,
      "learning_rate": 2.935014464930875e-05,
      "loss": 0.0898,
      "step": 61980
    },
    {
      "epoch": 1.239651241850978,
      "grad_norm": 0.06542212516069412,
      "learning_rate": 2.9346811715927424e-05,
      "loss": 0.0933,
      "step": 61990
    },
    {
      "epoch": 1.2398512178538574,
      "grad_norm": 0.18956899642944336,
      "learning_rate": 2.9343478782546097e-05,
      "loss": 0.0868,
      "step": 62000
    },
    {
      "epoch": 1.2400511938567371,
      "grad_norm": 0.06890891492366791,
      "learning_rate": 2.9340145849164767e-05,
      "loss": 0.1132,
      "step": 62010
    },
    {
      "epoch": 1.2402511698596168,
      "grad_norm": 0.07782991975545883,
      "learning_rate": 2.933681291578344e-05,
      "loss": 0.0627,
      "step": 62020
    },
    {
      "epoch": 1.2404511458624965,
      "grad_norm": 0.12032065540552139,
      "learning_rate": 2.9333479982402113e-05,
      "loss": 0.1143,
      "step": 62030
    },
    {
      "epoch": 1.2406511218653762,
      "grad_norm": 0.15971314907073975,
      "learning_rate": 2.9330147049020782e-05,
      "loss": 0.0955,
      "step": 62040
    },
    {
      "epoch": 1.2408510978682559,
      "grad_norm": 0.06771446764469147,
      "learning_rate": 2.9326814115639455e-05,
      "loss": 0.0547,
      "step": 62050
    },
    {
      "epoch": 1.2410510738711356,
      "grad_norm": 0.1715248078107834,
      "learning_rate": 2.932348118225813e-05,
      "loss": 0.0709,
      "step": 62060
    },
    {
      "epoch": 1.241251049874015,
      "grad_norm": 0.16563661396503448,
      "learning_rate": 2.9320148248876805e-05,
      "loss": 0.0821,
      "step": 62070
    },
    {
      "epoch": 1.2414510258768947,
      "grad_norm": 0.09563752263784409,
      "learning_rate": 2.9316815315495478e-05,
      "loss": 0.0605,
      "step": 62080
    },
    {
      "epoch": 1.2416510018797744,
      "grad_norm": 0.08382752537727356,
      "learning_rate": 2.9313482382114147e-05,
      "loss": 0.0474,
      "step": 62090
    },
    {
      "epoch": 1.241850977882654,
      "grad_norm": 0.07097787410020828,
      "learning_rate": 2.931014944873282e-05,
      "loss": 0.0598,
      "step": 62100
    },
    {
      "epoch": 1.2420509538855338,
      "grad_norm": 0.18414834141731262,
      "learning_rate": 2.9306816515351493e-05,
      "loss": 0.0794,
      "step": 62110
    },
    {
      "epoch": 1.2422509298884135,
      "grad_norm": 0.057302724570035934,
      "learning_rate": 2.9303483581970163e-05,
      "loss": 0.0639,
      "step": 62120
    },
    {
      "epoch": 1.242450905891293,
      "grad_norm": 0.13843850791454315,
      "learning_rate": 2.9300150648588836e-05,
      "loss": 0.0671,
      "step": 62130
    },
    {
      "epoch": 1.2426508818941726,
      "grad_norm": 0.06906356662511826,
      "learning_rate": 2.929681771520751e-05,
      "loss": 0.077,
      "step": 62140
    },
    {
      "epoch": 1.2428508578970523,
      "grad_norm": 0.10270919650793076,
      "learning_rate": 2.929348478182618e-05,
      "loss": 0.0488,
      "step": 62150
    },
    {
      "epoch": 1.243050833899932,
      "grad_norm": 0.0801437720656395,
      "learning_rate": 2.9290151848444852e-05,
      "loss": 0.0687,
      "step": 62160
    },
    {
      "epoch": 1.2432508099028117,
      "grad_norm": 0.1078905239701271,
      "learning_rate": 2.9286818915063528e-05,
      "loss": 0.08,
      "step": 62170
    },
    {
      "epoch": 1.2434507859056914,
      "grad_norm": 0.1979171335697174,
      "learning_rate": 2.92834859816822e-05,
      "loss": 0.0603,
      "step": 62180
    },
    {
      "epoch": 1.243650761908571,
      "grad_norm": 0.1460099071264267,
      "learning_rate": 2.9280153048300874e-05,
      "loss": 0.0592,
      "step": 62190
    },
    {
      "epoch": 1.2438507379114507,
      "grad_norm": 0.10026343166828156,
      "learning_rate": 2.9276820114919544e-05,
      "loss": 0.0532,
      "step": 62200
    },
    {
      "epoch": 1.2440507139143302,
      "grad_norm": 0.14862056076526642,
      "learning_rate": 2.9273487181538217e-05,
      "loss": 0.0524,
      "step": 62210
    },
    {
      "epoch": 1.2442506899172099,
      "grad_norm": 0.16702742874622345,
      "learning_rate": 2.927015424815689e-05,
      "loss": 0.0806,
      "step": 62220
    },
    {
      "epoch": 1.2444506659200896,
      "grad_norm": 0.1947125792503357,
      "learning_rate": 2.926682131477556e-05,
      "loss": 0.0949,
      "step": 62230
    },
    {
      "epoch": 1.2446506419229693,
      "grad_norm": 0.07019636034965515,
      "learning_rate": 2.9263488381394232e-05,
      "loss": 0.0593,
      "step": 62240
    },
    {
      "epoch": 1.244850617925849,
      "grad_norm": 0.08880336582660675,
      "learning_rate": 2.9260155448012905e-05,
      "loss": 0.0804,
      "step": 62250
    },
    {
      "epoch": 1.2450505939287286,
      "grad_norm": 0.12084509432315826,
      "learning_rate": 2.9256822514631575e-05,
      "loss": 0.0567,
      "step": 62260
    },
    {
      "epoch": 1.245250569931608,
      "grad_norm": 0.1136941984295845,
      "learning_rate": 2.9253489581250255e-05,
      "loss": 0.0729,
      "step": 62270
    },
    {
      "epoch": 1.2454505459344878,
      "grad_norm": 0.0629836693406105,
      "learning_rate": 2.9250156647868924e-05,
      "loss": 0.0749,
      "step": 62280
    },
    {
      "epoch": 1.2456505219373675,
      "grad_norm": 0.14024406671524048,
      "learning_rate": 2.9246823714487597e-05,
      "loss": 0.0945,
      "step": 62290
    },
    {
      "epoch": 1.2458504979402472,
      "grad_norm": 0.1427234262228012,
      "learning_rate": 2.924349078110627e-05,
      "loss": 0.0661,
      "step": 62300
    },
    {
      "epoch": 1.2460504739431268,
      "grad_norm": 0.06251472234725952,
      "learning_rate": 2.924015784772494e-05,
      "loss": 0.0586,
      "step": 62310
    },
    {
      "epoch": 1.2462504499460065,
      "grad_norm": 0.14620867371559143,
      "learning_rate": 2.9236824914343613e-05,
      "loss": 0.0617,
      "step": 62320
    },
    {
      "epoch": 1.2464504259488862,
      "grad_norm": 0.1200176328420639,
      "learning_rate": 2.9233491980962286e-05,
      "loss": 0.0889,
      "step": 62330
    },
    {
      "epoch": 1.246650401951766,
      "grad_norm": 0.2202182561159134,
      "learning_rate": 2.9230159047580956e-05,
      "loss": 0.0695,
      "step": 62340
    },
    {
      "epoch": 1.2468503779546454,
      "grad_norm": 0.08052682131528854,
      "learning_rate": 2.922682611419963e-05,
      "loss": 0.0535,
      "step": 62350
    },
    {
      "epoch": 1.247050353957525,
      "grad_norm": 0.2221512645483017,
      "learning_rate": 2.92234931808183e-05,
      "loss": 0.0705,
      "step": 62360
    },
    {
      "epoch": 1.2472503299604047,
      "grad_norm": 0.20066951215267181,
      "learning_rate": 2.9220493540775107e-05,
      "loss": 0.0643,
      "step": 62370
    },
    {
      "epoch": 1.2474503059632844,
      "grad_norm": 0.11239398270845413,
      "learning_rate": 2.921716060739378e-05,
      "loss": 0.0506,
      "step": 62380
    },
    {
      "epoch": 1.2476502819661641,
      "grad_norm": 0.2314538061618805,
      "learning_rate": 2.921382767401245e-05,
      "loss": 0.073,
      "step": 62390
    },
    {
      "epoch": 1.2478502579690438,
      "grad_norm": 0.20360170304775238,
      "learning_rate": 2.921049474063113e-05,
      "loss": 0.0733,
      "step": 62400
    },
    {
      "epoch": 1.2480502339719233,
      "grad_norm": 0.12085695564746857,
      "learning_rate": 2.92071618072498e-05,
      "loss": 0.0473,
      "step": 62410
    },
    {
      "epoch": 1.248250209974803,
      "grad_norm": 0.07694884389638901,
      "learning_rate": 2.9203828873868472e-05,
      "loss": 0.093,
      "step": 62420
    },
    {
      "epoch": 1.2484501859776826,
      "grad_norm": 0.17005875706672668,
      "learning_rate": 2.9200495940487145e-05,
      "loss": 0.084,
      "step": 62430
    },
    {
      "epoch": 1.2486501619805623,
      "grad_norm": 0.16318437457084656,
      "learning_rate": 2.9197163007105815e-05,
      "loss": 0.0749,
      "step": 62440
    },
    {
      "epoch": 1.248850137983442,
      "grad_norm": 0.15544474124908447,
      "learning_rate": 2.9193830073724488e-05,
      "loss": 0.0751,
      "step": 62450
    },
    {
      "epoch": 1.2490501139863217,
      "grad_norm": 0.10973222553730011,
      "learning_rate": 2.919049714034316e-05,
      "loss": 0.0667,
      "step": 62460
    },
    {
      "epoch": 1.2492500899892014,
      "grad_norm": 0.12576046586036682,
      "learning_rate": 2.918716420696183e-05,
      "loss": 0.0848,
      "step": 62470
    },
    {
      "epoch": 1.2494500659920809,
      "grad_norm": 0.1292191743850708,
      "learning_rate": 2.9183831273580503e-05,
      "loss": 0.0826,
      "step": 62480
    },
    {
      "epoch": 1.2496500419949605,
      "grad_norm": 0.1861126571893692,
      "learning_rate": 2.9180498340199176e-05,
      "loss": 0.0983,
      "step": 62490
    },
    {
      "epoch": 1.2498500179978402,
      "grad_norm": 0.08813074976205826,
      "learning_rate": 2.9177165406817853e-05,
      "loss": 0.1004,
      "step": 62500
    },
    {
      "epoch": 1.25004999400072,
      "grad_norm": 0.12946276366710663,
      "learning_rate": 2.9173832473436526e-05,
      "loss": 0.0485,
      "step": 62510
    },
    {
      "epoch": 1.2502499700035996,
      "grad_norm": 0.19916734099388123,
      "learning_rate": 2.9170499540055195e-05,
      "loss": 0.0636,
      "step": 62520
    },
    {
      "epoch": 1.2504499460064793,
      "grad_norm": 0.07472114264965057,
      "learning_rate": 2.9167166606673868e-05,
      "loss": 0.0767,
      "step": 62530
    },
    {
      "epoch": 1.2506499220093588,
      "grad_norm": 0.12972909212112427,
      "learning_rate": 2.916383367329254e-05,
      "loss": 0.0734,
      "step": 62540
    },
    {
      "epoch": 1.2508498980122384,
      "grad_norm": 0.160628080368042,
      "learning_rate": 2.916050073991121e-05,
      "loss": 0.0861,
      "step": 62550
    },
    {
      "epoch": 1.2510498740151181,
      "grad_norm": 0.06669064611196518,
      "learning_rate": 2.9157167806529884e-05,
      "loss": 0.0562,
      "step": 62560
    },
    {
      "epoch": 1.2512498500179978,
      "grad_norm": 0.11167257279157639,
      "learning_rate": 2.9153834873148557e-05,
      "loss": 0.0588,
      "step": 62570
    },
    {
      "epoch": 1.2514498260208775,
      "grad_norm": 0.13573342561721802,
      "learning_rate": 2.9150501939767227e-05,
      "loss": 0.0663,
      "step": 62580
    },
    {
      "epoch": 1.2516498020237572,
      "grad_norm": 0.05675646290183067,
      "learning_rate": 2.91471690063859e-05,
      "loss": 0.0399,
      "step": 62590
    },
    {
      "epoch": 1.2518497780266369,
      "grad_norm": 0.1660958230495453,
      "learning_rate": 2.9143836073004576e-05,
      "loss": 0.0563,
      "step": 62600
    },
    {
      "epoch": 1.2520497540295166,
      "grad_norm": 0.07985945791006088,
      "learning_rate": 2.914050313962325e-05,
      "loss": 0.0932,
      "step": 62610
    },
    {
      "epoch": 1.252249730032396,
      "grad_norm": 0.16120406985282898,
      "learning_rate": 2.9137170206241922e-05,
      "loss": 0.0605,
      "step": 62620
    },
    {
      "epoch": 1.2524497060352757,
      "grad_norm": 0.12702663242816925,
      "learning_rate": 2.913383727286059e-05,
      "loss": 0.0721,
      "step": 62630
    },
    {
      "epoch": 1.2526496820381554,
      "grad_norm": 0.12626418471336365,
      "learning_rate": 2.9130504339479265e-05,
      "loss": 0.0696,
      "step": 62640
    },
    {
      "epoch": 1.252849658041035,
      "grad_norm": 0.17475418746471405,
      "learning_rate": 2.9127171406097938e-05,
      "loss": 0.0693,
      "step": 62650
    },
    {
      "epoch": 1.2530496340439148,
      "grad_norm": 0.1086965948343277,
      "learning_rate": 2.9123838472716607e-05,
      "loss": 0.0538,
      "step": 62660
    },
    {
      "epoch": 1.2532496100467942,
      "grad_norm": 0.08035928755998611,
      "learning_rate": 2.912050553933528e-05,
      "loss": 0.0423,
      "step": 62670
    },
    {
      "epoch": 1.253449586049674,
      "grad_norm": 0.23447903990745544,
      "learning_rate": 2.9117172605953953e-05,
      "loss": 0.0757,
      "step": 62680
    },
    {
      "epoch": 1.2536495620525536,
      "grad_norm": 0.0685533806681633,
      "learning_rate": 2.9113839672572623e-05,
      "loss": 0.0782,
      "step": 62690
    },
    {
      "epoch": 1.2538495380554333,
      "grad_norm": 0.211921826004982,
      "learning_rate": 2.9110506739191303e-05,
      "loss": 0.1604,
      "step": 62700
    },
    {
      "epoch": 1.254049514058313,
      "grad_norm": 0.11342009902000427,
      "learning_rate": 2.9107173805809972e-05,
      "loss": 0.0494,
      "step": 62710
    },
    {
      "epoch": 1.2542494900611927,
      "grad_norm": 0.10429349541664124,
      "learning_rate": 2.9103840872428645e-05,
      "loss": 0.08,
      "step": 62720
    },
    {
      "epoch": 1.2544494660640724,
      "grad_norm": 0.13022549450397491,
      "learning_rate": 2.9100507939047318e-05,
      "loss": 0.0772,
      "step": 62730
    },
    {
      "epoch": 1.254649442066952,
      "grad_norm": 0.101626917719841,
      "learning_rate": 2.9097175005665988e-05,
      "loss": 0.0689,
      "step": 62740
    },
    {
      "epoch": 1.2548494180698317,
      "grad_norm": 0.11016697436571121,
      "learning_rate": 2.909384207228466e-05,
      "loss": 0.087,
      "step": 62750
    },
    {
      "epoch": 1.2550493940727112,
      "grad_norm": 0.1815064549446106,
      "learning_rate": 2.9090509138903334e-05,
      "loss": 0.1137,
      "step": 62760
    },
    {
      "epoch": 1.255249370075591,
      "grad_norm": 0.24451392889022827,
      "learning_rate": 2.9087176205522003e-05,
      "loss": 0.0865,
      "step": 62770
    },
    {
      "epoch": 1.2554493460784706,
      "grad_norm": 0.18956229090690613,
      "learning_rate": 2.9083843272140676e-05,
      "loss": 0.0619,
      "step": 62780
    },
    {
      "epoch": 1.2556493220813503,
      "grad_norm": 0.07108964771032333,
      "learning_rate": 2.908051033875935e-05,
      "loss": 0.3192,
      "step": 62790
    },
    {
      "epoch": 1.25584929808423,
      "grad_norm": 0.21465107798576355,
      "learning_rate": 2.907717740537802e-05,
      "loss": 0.0956,
      "step": 62800
    },
    {
      "epoch": 1.2560492740871094,
      "grad_norm": 0.1919585019350052,
      "learning_rate": 2.90738444719967e-05,
      "loss": 0.0703,
      "step": 62810
    },
    {
      "epoch": 1.2562492500899891,
      "grad_norm": 0.12565286457538605,
      "learning_rate": 2.907051153861537e-05,
      "loss": 0.1467,
      "step": 62820
    },
    {
      "epoch": 1.2564492260928688,
      "grad_norm": 0.2409532368183136,
      "learning_rate": 2.906717860523404e-05,
      "loss": 0.0822,
      "step": 62830
    },
    {
      "epoch": 1.2566492020957485,
      "grad_norm": 0.12945550680160522,
      "learning_rate": 2.9063845671852714e-05,
      "loss": 0.0624,
      "step": 62840
    },
    {
      "epoch": 1.2568491780986282,
      "grad_norm": 0.19878654181957245,
      "learning_rate": 2.9060512738471384e-05,
      "loss": 0.0594,
      "step": 62850
    },
    {
      "epoch": 1.2570491541015079,
      "grad_norm": 0.08146847784519196,
      "learning_rate": 2.9057179805090057e-05,
      "loss": 0.0842,
      "step": 62860
    },
    {
      "epoch": 1.2572491301043875,
      "grad_norm": 0.09805682301521301,
      "learning_rate": 2.905384687170873e-05,
      "loss": 0.0681,
      "step": 62870
    },
    {
      "epoch": 1.2574491061072672,
      "grad_norm": 0.07379411906003952,
      "learning_rate": 2.90505139383274e-05,
      "loss": 0.0763,
      "step": 62880
    },
    {
      "epoch": 1.257649082110147,
      "grad_norm": 0.11261578649282455,
      "learning_rate": 2.9047181004946073e-05,
      "loss": 0.0667,
      "step": 62890
    },
    {
      "epoch": 1.2578490581130264,
      "grad_norm": 0.06275644898414612,
      "learning_rate": 2.9043848071564746e-05,
      "loss": 0.044,
      "step": 62900
    },
    {
      "epoch": 1.258049034115906,
      "grad_norm": 0.05432424694299698,
      "learning_rate": 2.9040515138183422e-05,
      "loss": 0.0465,
      "step": 62910
    },
    {
      "epoch": 1.2582490101187858,
      "grad_norm": 0.16805830597877502,
      "learning_rate": 2.9037182204802095e-05,
      "loss": 0.0706,
      "step": 62920
    },
    {
      "epoch": 1.2584489861216654,
      "grad_norm": 0.2471744269132614,
      "learning_rate": 2.9033849271420765e-05,
      "loss": 0.0932,
      "step": 62930
    },
    {
      "epoch": 1.2586489621245451,
      "grad_norm": 0.07114966213703156,
      "learning_rate": 2.9030516338039438e-05,
      "loss": 0.063,
      "step": 62940
    },
    {
      "epoch": 1.2588489381274246,
      "grad_norm": 0.10762451589107513,
      "learning_rate": 2.902718340465811e-05,
      "loss": 0.0796,
      "step": 62950
    },
    {
      "epoch": 1.2590489141303043,
      "grad_norm": 0.09756375849246979,
      "learning_rate": 2.902385047127678e-05,
      "loss": 0.084,
      "step": 62960
    },
    {
      "epoch": 1.259248890133184,
      "grad_norm": 0.07901188731193542,
      "learning_rate": 2.9020517537895453e-05,
      "loss": 0.098,
      "step": 62970
    },
    {
      "epoch": 1.2594488661360637,
      "grad_norm": 0.09709153324365616,
      "learning_rate": 2.9017184604514126e-05,
      "loss": 0.0709,
      "step": 62980
    },
    {
      "epoch": 1.2596488421389433,
      "grad_norm": 0.12030241638422012,
      "learning_rate": 2.9013851671132796e-05,
      "loss": 0.0621,
      "step": 62990
    },
    {
      "epoch": 1.259848818141823,
      "grad_norm": 0.11105646193027496,
      "learning_rate": 2.901051873775147e-05,
      "loss": 0.0497,
      "step": 63000
    },
    {
      "epoch": 1.2600487941447027,
      "grad_norm": 0.05405102297663689,
      "learning_rate": 2.9007185804370145e-05,
      "loss": 0.0394,
      "step": 63010
    },
    {
      "epoch": 1.2602487701475824,
      "grad_norm": 0.1420477330684662,
      "learning_rate": 2.900385287098882e-05,
      "loss": 0.0814,
      "step": 63020
    },
    {
      "epoch": 1.2604487461504619,
      "grad_norm": 0.18554535508155823,
      "learning_rate": 2.900051993760749e-05,
      "loss": 0.0733,
      "step": 63030
    },
    {
      "epoch": 1.2606487221533416,
      "grad_norm": 0.10206632316112518,
      "learning_rate": 2.899718700422616e-05,
      "loss": 0.0926,
      "step": 63040
    },
    {
      "epoch": 1.2608486981562212,
      "grad_norm": 0.17626111209392548,
      "learning_rate": 2.8993854070844834e-05,
      "loss": 0.0912,
      "step": 63050
    },
    {
      "epoch": 1.261048674159101,
      "grad_norm": 0.17999403178691864,
      "learning_rate": 2.8990521137463507e-05,
      "loss": 0.0725,
      "step": 63060
    },
    {
      "epoch": 1.2612486501619806,
      "grad_norm": 0.13281576335430145,
      "learning_rate": 2.8987188204082177e-05,
      "loss": 0.0994,
      "step": 63070
    },
    {
      "epoch": 1.26144862616486,
      "grad_norm": 0.204721137881279,
      "learning_rate": 2.898385527070085e-05,
      "loss": 0.0723,
      "step": 63080
    },
    {
      "epoch": 1.2616486021677398,
      "grad_norm": 0.22610951960086823,
      "learning_rate": 2.8980522337319523e-05,
      "loss": 0.1022,
      "step": 63090
    },
    {
      "epoch": 1.2618485781706195,
      "grad_norm": 0.07291901111602783,
      "learning_rate": 2.8977189403938192e-05,
      "loss": 0.0783,
      "step": 63100
    },
    {
      "epoch": 1.2620485541734991,
      "grad_norm": 0.21087750792503357,
      "learning_rate": 2.8973856470556872e-05,
      "loss": 0.0909,
      "step": 63110
    },
    {
      "epoch": 1.2622485301763788,
      "grad_norm": 0.08080544322729111,
      "learning_rate": 2.897052353717554e-05,
      "loss": 0.1068,
      "step": 63120
    },
    {
      "epoch": 1.2624485061792585,
      "grad_norm": 0.16218437254428864,
      "learning_rate": 2.8967190603794215e-05,
      "loss": 0.1354,
      "step": 63130
    },
    {
      "epoch": 1.2626484821821382,
      "grad_norm": 0.12248831987380981,
      "learning_rate": 2.8963857670412888e-05,
      "loss": 0.0759,
      "step": 63140
    },
    {
      "epoch": 1.262848458185018,
      "grad_norm": 0.1562872976064682,
      "learning_rate": 2.8960524737031557e-05,
      "loss": 0.0741,
      "step": 63150
    },
    {
      "epoch": 1.2630484341878976,
      "grad_norm": 0.16752400994300842,
      "learning_rate": 2.895719180365023e-05,
      "loss": 0.0701,
      "step": 63160
    },
    {
      "epoch": 1.263248410190777,
      "grad_norm": 0.09791968762874603,
      "learning_rate": 2.8953858870268903e-05,
      "loss": 0.0477,
      "step": 63170
    },
    {
      "epoch": 1.2634483861936567,
      "grad_norm": 0.11446622759103775,
      "learning_rate": 2.8950525936887573e-05,
      "loss": 0.0629,
      "step": 63180
    },
    {
      "epoch": 1.2636483621965364,
      "grad_norm": 0.06376577168703079,
      "learning_rate": 2.8947193003506246e-05,
      "loss": 0.0524,
      "step": 63190
    },
    {
      "epoch": 1.263848338199416,
      "grad_norm": 0.09292225539684296,
      "learning_rate": 2.894386007012492e-05,
      "loss": 0.0743,
      "step": 63200
    },
    {
      "epoch": 1.2640483142022958,
      "grad_norm": 0.12185598164796829,
      "learning_rate": 2.8940527136743595e-05,
      "loss": 0.0722,
      "step": 63210
    },
    {
      "epoch": 1.2642482902051753,
      "grad_norm": 0.1233828142285347,
      "learning_rate": 2.893719420336227e-05,
      "loss": 0.0855,
      "step": 63220
    },
    {
      "epoch": 1.264448266208055,
      "grad_norm": 0.11866099387407303,
      "learning_rate": 2.8933861269980938e-05,
      "loss": 0.0485,
      "step": 63230
    },
    {
      "epoch": 1.2646482422109346,
      "grad_norm": 0.05853734537959099,
      "learning_rate": 2.893052833659961e-05,
      "loss": 0.0632,
      "step": 63240
    },
    {
      "epoch": 1.2648482182138143,
      "grad_norm": 0.10134381800889969,
      "learning_rate": 2.8927195403218284e-05,
      "loss": 0.0778,
      "step": 63250
    },
    {
      "epoch": 1.265048194216694,
      "grad_norm": 0.13901713490486145,
      "learning_rate": 2.8923862469836954e-05,
      "loss": 0.0524,
      "step": 63260
    },
    {
      "epoch": 1.2652481702195737,
      "grad_norm": 0.13998405635356903,
      "learning_rate": 2.8920529536455627e-05,
      "loss": 0.094,
      "step": 63270
    },
    {
      "epoch": 1.2654481462224534,
      "grad_norm": 0.10910727083683014,
      "learning_rate": 2.89171966030743e-05,
      "loss": 0.0562,
      "step": 63280
    },
    {
      "epoch": 1.265648122225333,
      "grad_norm": 0.1334381252527237,
      "learning_rate": 2.891386366969297e-05,
      "loss": 0.1122,
      "step": 63290
    },
    {
      "epoch": 1.2658480982282125,
      "grad_norm": 0.1637338250875473,
      "learning_rate": 2.8910530736311642e-05,
      "loss": 0.063,
      "step": 63300
    },
    {
      "epoch": 1.2660480742310922,
      "grad_norm": 0.059255026280879974,
      "learning_rate": 2.8907197802930315e-05,
      "loss": 0.0406,
      "step": 63310
    },
    {
      "epoch": 1.266248050233972,
      "grad_norm": 0.09172829985618591,
      "learning_rate": 2.890386486954899e-05,
      "loss": 0.067,
      "step": 63320
    },
    {
      "epoch": 1.2664480262368516,
      "grad_norm": 0.16957461833953857,
      "learning_rate": 2.8900531936167665e-05,
      "loss": 0.0911,
      "step": 63330
    },
    {
      "epoch": 1.2666480022397313,
      "grad_norm": 0.14999938011169434,
      "learning_rate": 2.8897199002786334e-05,
      "loss": 0.0785,
      "step": 63340
    },
    {
      "epoch": 1.2668479782426108,
      "grad_norm": 0.17704930901527405,
      "learning_rate": 2.8893866069405007e-05,
      "loss": 0.1135,
      "step": 63350
    },
    {
      "epoch": 1.2670479542454904,
      "grad_norm": 0.20559321343898773,
      "learning_rate": 2.889053313602368e-05,
      "loss": 0.0573,
      "step": 63360
    },
    {
      "epoch": 1.2672479302483701,
      "grad_norm": 0.08198796212673187,
      "learning_rate": 2.888720020264235e-05,
      "loss": 0.1013,
      "step": 63370
    },
    {
      "epoch": 1.2674479062512498,
      "grad_norm": 0.13796956837177277,
      "learning_rate": 2.8883867269261023e-05,
      "loss": 0.0669,
      "step": 63380
    },
    {
      "epoch": 1.2676478822541295,
      "grad_norm": 0.13776010274887085,
      "learning_rate": 2.8880534335879696e-05,
      "loss": 0.0732,
      "step": 63390
    },
    {
      "epoch": 1.2678478582570092,
      "grad_norm": 0.19666074216365814,
      "learning_rate": 2.8877201402498365e-05,
      "loss": 0.1108,
      "step": 63400
    },
    {
      "epoch": 1.2680478342598889,
      "grad_norm": 0.11520381271839142,
      "learning_rate": 2.887386846911704e-05,
      "loss": 0.0638,
      "step": 63410
    },
    {
      "epoch": 1.2682478102627686,
      "grad_norm": 0.08118194341659546,
      "learning_rate": 2.8870535535735715e-05,
      "loss": 0.0452,
      "step": 63420
    },
    {
      "epoch": 1.2684477862656482,
      "grad_norm": 0.18393418192863464,
      "learning_rate": 2.8867202602354388e-05,
      "loss": 0.0805,
      "step": 63430
    },
    {
      "epoch": 1.2686477622685277,
      "grad_norm": 0.0881606861948967,
      "learning_rate": 2.886386966897306e-05,
      "loss": 0.0847,
      "step": 63440
    },
    {
      "epoch": 1.2688477382714074,
      "grad_norm": 0.16751880943775177,
      "learning_rate": 2.886053673559173e-05,
      "loss": 0.0466,
      "step": 63450
    },
    {
      "epoch": 1.269047714274287,
      "grad_norm": 0.07267556339502335,
      "learning_rate": 2.8857203802210403e-05,
      "loss": 0.0337,
      "step": 63460
    },
    {
      "epoch": 1.2692476902771668,
      "grad_norm": 0.14616608619689941,
      "learning_rate": 2.8853870868829076e-05,
      "loss": 0.0543,
      "step": 63470
    },
    {
      "epoch": 1.2694476662800465,
      "grad_norm": 0.1975017637014389,
      "learning_rate": 2.8850537935447746e-05,
      "loss": 0.0856,
      "step": 63480
    },
    {
      "epoch": 1.269647642282926,
      "grad_norm": 0.1343061923980713,
      "learning_rate": 2.884720500206642e-05,
      "loss": 0.0961,
      "step": 63490
    },
    {
      "epoch": 1.2698476182858056,
      "grad_norm": 0.17308761179447174,
      "learning_rate": 2.8843872068685092e-05,
      "loss": 0.065,
      "step": 63500
    },
    {
      "epoch": 1.2700475942886853,
      "grad_norm": 0.05261235311627388,
      "learning_rate": 2.8840539135303762e-05,
      "loss": 0.074,
      "step": 63510
    },
    {
      "epoch": 1.270247570291565,
      "grad_norm": 0.06173861026763916,
      "learning_rate": 2.883720620192244e-05,
      "loss": 0.0432,
      "step": 63520
    },
    {
      "epoch": 1.2704475462944447,
      "grad_norm": 0.07448922842741013,
      "learning_rate": 2.883387326854111e-05,
      "loss": 0.1125,
      "step": 63530
    },
    {
      "epoch": 1.2706475222973244,
      "grad_norm": 0.07821159064769745,
      "learning_rate": 2.8830540335159784e-05,
      "loss": 0.0771,
      "step": 63540
    },
    {
      "epoch": 1.270847498300204,
      "grad_norm": 0.12563446164131165,
      "learning_rate": 2.8827207401778457e-05,
      "loss": 0.0723,
      "step": 63550
    },
    {
      "epoch": 1.2710474743030837,
      "grad_norm": 0.08872003108263016,
      "learning_rate": 2.8823874468397127e-05,
      "loss": 0.0856,
      "step": 63560
    },
    {
      "epoch": 1.2712474503059634,
      "grad_norm": 0.09256760030984879,
      "learning_rate": 2.88205415350158e-05,
      "loss": 0.077,
      "step": 63570
    },
    {
      "epoch": 1.2714474263088429,
      "grad_norm": 0.07461299002170563,
      "learning_rate": 2.8817208601634473e-05,
      "loss": 0.0909,
      "step": 63580
    },
    {
      "epoch": 1.2716474023117226,
      "grad_norm": 0.1477021425962448,
      "learning_rate": 2.8813875668253142e-05,
      "loss": 0.0619,
      "step": 63590
    },
    {
      "epoch": 1.2718473783146023,
      "grad_norm": 0.13211308419704437,
      "learning_rate": 2.8810542734871815e-05,
      "loss": 0.0613,
      "step": 63600
    },
    {
      "epoch": 1.272047354317482,
      "grad_norm": 0.05885181576013565,
      "learning_rate": 2.880720980149049e-05,
      "loss": 0.2443,
      "step": 63610
    },
    {
      "epoch": 1.2722473303203616,
      "grad_norm": 0.20273591578006744,
      "learning_rate": 2.8803876868109165e-05,
      "loss": 0.0823,
      "step": 63620
    },
    {
      "epoch": 1.272447306323241,
      "grad_norm": 0.15988747775554657,
      "learning_rate": 2.8800543934727838e-05,
      "loss": 0.1209,
      "step": 63630
    },
    {
      "epoch": 1.2726472823261208,
      "grad_norm": 0.20858348906040192,
      "learning_rate": 2.8797211001346507e-05,
      "loss": 0.1022,
      "step": 63640
    },
    {
      "epoch": 1.2728472583290005,
      "grad_norm": 0.09808867424726486,
      "learning_rate": 2.879387806796518e-05,
      "loss": 0.0852,
      "step": 63650
    },
    {
      "epoch": 1.2730472343318802,
      "grad_norm": 0.22957567870616913,
      "learning_rate": 2.8790545134583853e-05,
      "loss": 0.0957,
      "step": 63660
    },
    {
      "epoch": 1.2732472103347598,
      "grad_norm": 0.0950501412153244,
      "learning_rate": 2.8787212201202523e-05,
      "loss": 0.0454,
      "step": 63670
    },
    {
      "epoch": 1.2734471863376395,
      "grad_norm": 0.09681973606348038,
      "learning_rate": 2.8783879267821196e-05,
      "loss": 0.0653,
      "step": 63680
    },
    {
      "epoch": 1.2736471623405192,
      "grad_norm": 0.15851151943206787,
      "learning_rate": 2.878054633443987e-05,
      "loss": 0.0869,
      "step": 63690
    },
    {
      "epoch": 1.273847138343399,
      "grad_norm": 0.20725208520889282,
      "learning_rate": 2.877721340105854e-05,
      "loss": 0.0726,
      "step": 63700
    },
    {
      "epoch": 1.2740471143462784,
      "grad_norm": 0.22483842074871063,
      "learning_rate": 2.877388046767721e-05,
      "loss": 0.0836,
      "step": 63710
    },
    {
      "epoch": 1.274247090349158,
      "grad_norm": 0.08832518756389618,
      "learning_rate": 2.8770547534295888e-05,
      "loss": 0.0737,
      "step": 63720
    },
    {
      "epoch": 1.2744470663520377,
      "grad_norm": 0.13382241129875183,
      "learning_rate": 2.876721460091456e-05,
      "loss": 0.0753,
      "step": 63730
    },
    {
      "epoch": 1.2746470423549174,
      "grad_norm": 0.1383359730243683,
      "learning_rate": 2.876388166753323e-05,
      "loss": 0.0588,
      "step": 63740
    },
    {
      "epoch": 1.2748470183577971,
      "grad_norm": 0.1888575702905655,
      "learning_rate": 2.8760548734151904e-05,
      "loss": 0.0976,
      "step": 63750
    },
    {
      "epoch": 1.2750469943606766,
      "grad_norm": 0.16746269166469574,
      "learning_rate": 2.8757215800770577e-05,
      "loss": 0.087,
      "step": 63760
    },
    {
      "epoch": 1.2752469703635563,
      "grad_norm": 0.11643067002296448,
      "learning_rate": 2.875388286738925e-05,
      "loss": 0.0701,
      "step": 63770
    },
    {
      "epoch": 1.275446946366436,
      "grad_norm": 0.11287416517734528,
      "learning_rate": 2.875054993400792e-05,
      "loss": 0.0586,
      "step": 63780
    },
    {
      "epoch": 1.2756469223693157,
      "grad_norm": 0.1806211620569229,
      "learning_rate": 2.8747217000626592e-05,
      "loss": 0.1008,
      "step": 63790
    },
    {
      "epoch": 1.2758468983721953,
      "grad_norm": 0.09869081526994705,
      "learning_rate": 2.8743884067245265e-05,
      "loss": 0.0669,
      "step": 63800
    },
    {
      "epoch": 1.276046874375075,
      "grad_norm": 0.09112314134836197,
      "learning_rate": 2.8740551133863935e-05,
      "loss": 0.0574,
      "step": 63810
    },
    {
      "epoch": 1.2762468503779547,
      "grad_norm": 0.16224531829357147,
      "learning_rate": 2.8737218200482608e-05,
      "loss": 0.0726,
      "step": 63820
    },
    {
      "epoch": 1.2764468263808344,
      "grad_norm": 0.15354998409748077,
      "learning_rate": 2.8733885267101284e-05,
      "loss": 0.1266,
      "step": 63830
    },
    {
      "epoch": 1.276646802383714,
      "grad_norm": 0.08606859296560287,
      "learning_rate": 2.8730552333719957e-05,
      "loss": 0.0607,
      "step": 63840
    },
    {
      "epoch": 1.2768467783865936,
      "grad_norm": 0.19925625622272491,
      "learning_rate": 2.8727219400338627e-05,
      "loss": 0.0911,
      "step": 63850
    },
    {
      "epoch": 1.2770467543894732,
      "grad_norm": 0.15207357704639435,
      "learning_rate": 2.87238864669573e-05,
      "loss": 0.0838,
      "step": 63860
    },
    {
      "epoch": 1.277246730392353,
      "grad_norm": 0.13586953282356262,
      "learning_rate": 2.8720553533575973e-05,
      "loss": 0.0949,
      "step": 63870
    },
    {
      "epoch": 1.2774467063952326,
      "grad_norm": 0.06058664992451668,
      "learning_rate": 2.8717220600194643e-05,
      "loss": 0.0558,
      "step": 63880
    },
    {
      "epoch": 1.2776466823981123,
      "grad_norm": 0.10427795350551605,
      "learning_rate": 2.8713887666813316e-05,
      "loss": 0.0551,
      "step": 63890
    },
    {
      "epoch": 1.2778466584009918,
      "grad_norm": 0.20700672268867493,
      "learning_rate": 2.871055473343199e-05,
      "loss": 0.0957,
      "step": 63900
    },
    {
      "epoch": 1.2780466344038715,
      "grad_norm": 0.11700129508972168,
      "learning_rate": 2.870722180005066e-05,
      "loss": 0.0381,
      "step": 63910
    },
    {
      "epoch": 1.2782466104067511,
      "grad_norm": 0.12710854411125183,
      "learning_rate": 2.870388886666933e-05,
      "loss": 0.0545,
      "step": 63920
    },
    {
      "epoch": 1.2784465864096308,
      "grad_norm": 0.13139976561069489,
      "learning_rate": 2.8700555933288008e-05,
      "loss": 0.0654,
      "step": 63930
    },
    {
      "epoch": 1.2786465624125105,
      "grad_norm": 0.09381701052188873,
      "learning_rate": 2.869722299990668e-05,
      "loss": 0.0874,
      "step": 63940
    },
    {
      "epoch": 1.2788465384153902,
      "grad_norm": 0.14106324315071106,
      "learning_rate": 2.8693890066525354e-05,
      "loss": 0.0727,
      "step": 63950
    },
    {
      "epoch": 1.2790465144182699,
      "grad_norm": 0.12195057421922684,
      "learning_rate": 2.8690557133144023e-05,
      "loss": 0.077,
      "step": 63960
    },
    {
      "epoch": 1.2792464904211496,
      "grad_norm": 0.08452177792787552,
      "learning_rate": 2.8687224199762696e-05,
      "loss": 0.0996,
      "step": 63970
    },
    {
      "epoch": 1.279446466424029,
      "grad_norm": 0.1566038429737091,
      "learning_rate": 2.868389126638137e-05,
      "loss": 0.0611,
      "step": 63980
    },
    {
      "epoch": 1.2796464424269087,
      "grad_norm": 0.16539862751960754,
      "learning_rate": 2.868055833300004e-05,
      "loss": 0.0693,
      "step": 63990
    },
    {
      "epoch": 1.2798464184297884,
      "grad_norm": 0.08652739226818085,
      "learning_rate": 2.8677225399618712e-05,
      "loss": 0.0505,
      "step": 64000
    },
    {
      "epoch": 1.280046394432668,
      "grad_norm": 0.14899437129497528,
      "learning_rate": 2.8673892466237385e-05,
      "loss": 0.1201,
      "step": 64010
    },
    {
      "epoch": 1.2802463704355478,
      "grad_norm": 0.22175273299217224,
      "learning_rate": 2.8670559532856054e-05,
      "loss": 0.0883,
      "step": 64020
    },
    {
      "epoch": 1.2804463464384273,
      "grad_norm": 0.1819739192724228,
      "learning_rate": 2.8667226599474734e-05,
      "loss": 0.127,
      "step": 64030
    },
    {
      "epoch": 1.280646322441307,
      "grad_norm": 0.09316748380661011,
      "learning_rate": 2.8663893666093404e-05,
      "loss": 0.0712,
      "step": 64040
    },
    {
      "epoch": 1.2808462984441866,
      "grad_norm": 0.18952298164367676,
      "learning_rate": 2.8660560732712077e-05,
      "loss": 0.0678,
      "step": 64050
    },
    {
      "epoch": 1.2810462744470663,
      "grad_norm": 0.08840561658143997,
      "learning_rate": 2.865722779933075e-05,
      "loss": 0.0965,
      "step": 64060
    },
    {
      "epoch": 1.281246250449946,
      "grad_norm": 0.12030593305826187,
      "learning_rate": 2.865389486594942e-05,
      "loss": 0.0613,
      "step": 64070
    },
    {
      "epoch": 1.2814462264528257,
      "grad_norm": 0.24259595572948456,
      "learning_rate": 2.8650561932568092e-05,
      "loss": 0.1596,
      "step": 64080
    },
    {
      "epoch": 1.2816462024557054,
      "grad_norm": 0.2869550883769989,
      "learning_rate": 2.8647228999186765e-05,
      "loss": 0.1648,
      "step": 64090
    },
    {
      "epoch": 1.281846178458585,
      "grad_norm": 0.11396995186805725,
      "learning_rate": 2.8643896065805435e-05,
      "loss": 0.0936,
      "step": 64100
    },
    {
      "epoch": 1.2820461544614647,
      "grad_norm": 0.12230446934700012,
      "learning_rate": 2.8640563132424108e-05,
      "loss": 0.0615,
      "step": 64110
    },
    {
      "epoch": 1.2822461304643442,
      "grad_norm": 0.04691319540143013,
      "learning_rate": 2.863723019904278e-05,
      "loss": 0.0482,
      "step": 64120
    },
    {
      "epoch": 1.282446106467224,
      "grad_norm": 0.19489501416683197,
      "learning_rate": 2.8633897265661457e-05,
      "loss": 0.113,
      "step": 64130
    },
    {
      "epoch": 1.2826460824701036,
      "grad_norm": 0.22445738315582275,
      "learning_rate": 2.863056433228013e-05,
      "loss": 0.0679,
      "step": 64140
    },
    {
      "epoch": 1.2828460584729833,
      "grad_norm": 0.07760391384363174,
      "learning_rate": 2.86272313988988e-05,
      "loss": 0.0584,
      "step": 64150
    },
    {
      "epoch": 1.283046034475863,
      "grad_norm": 0.12403731048107147,
      "learning_rate": 2.8623898465517473e-05,
      "loss": 0.0565,
      "step": 64160
    },
    {
      "epoch": 1.2832460104787424,
      "grad_norm": 0.12343506515026093,
      "learning_rate": 2.8620565532136146e-05,
      "loss": 0.0911,
      "step": 64170
    },
    {
      "epoch": 1.2834459864816221,
      "grad_norm": 0.2148645967245102,
      "learning_rate": 2.8617232598754816e-05,
      "loss": 0.0642,
      "step": 64180
    },
    {
      "epoch": 1.2836459624845018,
      "grad_norm": 0.12649255990982056,
      "learning_rate": 2.861389966537349e-05,
      "loss": 0.087,
      "step": 64190
    },
    {
      "epoch": 1.2838459384873815,
      "grad_norm": 0.08896846324205399,
      "learning_rate": 2.8610566731992162e-05,
      "loss": 0.0542,
      "step": 64200
    },
    {
      "epoch": 1.2840459144902612,
      "grad_norm": 0.09384487569332123,
      "learning_rate": 2.860723379861083e-05,
      "loss": 0.079,
      "step": 64210
    },
    {
      "epoch": 1.2842458904931409,
      "grad_norm": 0.10191302001476288,
      "learning_rate": 2.8603900865229504e-05,
      "loss": 0.0688,
      "step": 64220
    },
    {
      "epoch": 1.2844458664960205,
      "grad_norm": 0.0651867687702179,
      "learning_rate": 2.860056793184818e-05,
      "loss": 0.0866,
      "step": 64230
    },
    {
      "epoch": 1.2846458424989002,
      "grad_norm": 0.10780937969684601,
      "learning_rate": 2.8597234998466854e-05,
      "loss": 0.0462,
      "step": 64240
    },
    {
      "epoch": 1.28484581850178,
      "grad_norm": 0.5244099497795105,
      "learning_rate": 2.8593902065085527e-05,
      "loss": 0.2591,
      "step": 64250
    },
    {
      "epoch": 1.2850457945046594,
      "grad_norm": 0.120231494307518,
      "learning_rate": 2.8590569131704196e-05,
      "loss": 0.0904,
      "step": 64260
    },
    {
      "epoch": 1.285245770507539,
      "grad_norm": 0.06035216897726059,
      "learning_rate": 2.858723619832287e-05,
      "loss": 0.0667,
      "step": 64270
    },
    {
      "epoch": 1.2854457465104188,
      "grad_norm": 0.166189044713974,
      "learning_rate": 2.8583903264941542e-05,
      "loss": 0.0766,
      "step": 64280
    },
    {
      "epoch": 1.2856457225132985,
      "grad_norm": 0.1070363000035286,
      "learning_rate": 2.8580570331560212e-05,
      "loss": 0.0702,
      "step": 64290
    },
    {
      "epoch": 1.2858456985161781,
      "grad_norm": 0.15692156553268433,
      "learning_rate": 2.8577237398178885e-05,
      "loss": 0.1196,
      "step": 64300
    },
    {
      "epoch": 1.2860456745190576,
      "grad_norm": 0.20495153963565826,
      "learning_rate": 2.8573904464797558e-05,
      "loss": 0.0887,
      "step": 64310
    },
    {
      "epoch": 1.2862456505219373,
      "grad_norm": 0.07022488862276077,
      "learning_rate": 2.8570571531416228e-05,
      "loss": 0.0544,
      "step": 64320
    },
    {
      "epoch": 1.286445626524817,
      "grad_norm": 0.18038791418075562,
      "learning_rate": 2.85672385980349e-05,
      "loss": 0.0908,
      "step": 64330
    },
    {
      "epoch": 1.2866456025276967,
      "grad_norm": 0.2028847485780716,
      "learning_rate": 2.8563905664653577e-05,
      "loss": 0.0622,
      "step": 64340
    },
    {
      "epoch": 1.2868455785305764,
      "grad_norm": 0.07743567228317261,
      "learning_rate": 2.856057273127225e-05,
      "loss": 0.0524,
      "step": 64350
    },
    {
      "epoch": 1.287045554533456,
      "grad_norm": 0.10543974488973618,
      "learning_rate": 2.8557239797890923e-05,
      "loss": 0.0824,
      "step": 64360
    },
    {
      "epoch": 1.2872455305363357,
      "grad_norm": 0.07964668422937393,
      "learning_rate": 2.8553906864509593e-05,
      "loss": 0.079,
      "step": 64370
    },
    {
      "epoch": 1.2874455065392154,
      "grad_norm": 0.10485050082206726,
      "learning_rate": 2.8550573931128266e-05,
      "loss": 0.0716,
      "step": 64380
    },
    {
      "epoch": 1.2876454825420949,
      "grad_norm": 0.0960613489151001,
      "learning_rate": 2.854724099774694e-05,
      "loss": 0.0863,
      "step": 64390
    },
    {
      "epoch": 1.2878454585449746,
      "grad_norm": 0.07005523890256882,
      "learning_rate": 2.8543908064365608e-05,
      "loss": 0.0815,
      "step": 64400
    },
    {
      "epoch": 1.2880454345478543,
      "grad_norm": 0.0781937837600708,
      "learning_rate": 2.854057513098428e-05,
      "loss": 0.0464,
      "step": 64410
    },
    {
      "epoch": 1.288245410550734,
      "grad_norm": 0.13267168402671814,
      "learning_rate": 2.8537242197602954e-05,
      "loss": 0.0557,
      "step": 64420
    },
    {
      "epoch": 1.2884453865536136,
      "grad_norm": 0.08291471749544144,
      "learning_rate": 2.8533909264221624e-05,
      "loss": 0.0652,
      "step": 64430
    },
    {
      "epoch": 1.288645362556493,
      "grad_norm": 0.06970246881246567,
      "learning_rate": 2.8530576330840304e-05,
      "loss": 0.0667,
      "step": 64440
    },
    {
      "epoch": 1.2888453385593728,
      "grad_norm": 0.079070083796978,
      "learning_rate": 2.8527243397458973e-05,
      "loss": 0.0624,
      "step": 64450
    },
    {
      "epoch": 1.2890453145622525,
      "grad_norm": 0.14956413209438324,
      "learning_rate": 2.8523910464077646e-05,
      "loss": 0.0878,
      "step": 64460
    },
    {
      "epoch": 1.2892452905651322,
      "grad_norm": 0.0857231393456459,
      "learning_rate": 2.852057753069632e-05,
      "loss": 0.0607,
      "step": 64470
    },
    {
      "epoch": 1.2894452665680118,
      "grad_norm": 0.07155650109052658,
      "learning_rate": 2.851724459731499e-05,
      "loss": 0.0977,
      "step": 64480
    },
    {
      "epoch": 1.2896452425708915,
      "grad_norm": 0.08867672830820084,
      "learning_rate": 2.8513911663933662e-05,
      "loss": 0.094,
      "step": 64490
    },
    {
      "epoch": 1.2898452185737712,
      "grad_norm": 0.10056236386299133,
      "learning_rate": 2.8510578730552335e-05,
      "loss": 0.0446,
      "step": 64500
    },
    {
      "epoch": 1.290045194576651,
      "grad_norm": 0.05603676661849022,
      "learning_rate": 2.8507245797171005e-05,
      "loss": 0.0608,
      "step": 64510
    },
    {
      "epoch": 1.2902451705795306,
      "grad_norm": 0.10784091800451279,
      "learning_rate": 2.8503912863789678e-05,
      "loss": 0.0543,
      "step": 64520
    },
    {
      "epoch": 1.29044514658241,
      "grad_norm": 0.11820878833532333,
      "learning_rate": 2.850057993040835e-05,
      "loss": 0.0798,
      "step": 64530
    },
    {
      "epoch": 1.2906451225852897,
      "grad_norm": 0.10901208221912384,
      "learning_rate": 2.8497246997027027e-05,
      "loss": 0.0606,
      "step": 64540
    },
    {
      "epoch": 1.2908450985881694,
      "grad_norm": 0.12758001685142517,
      "learning_rate": 2.84939140636457e-05,
      "loss": 0.0813,
      "step": 64550
    },
    {
      "epoch": 1.2910450745910491,
      "grad_norm": 0.12925812602043152,
      "learning_rate": 2.849058113026437e-05,
      "loss": 0.0689,
      "step": 64560
    },
    {
      "epoch": 1.2912450505939288,
      "grad_norm": 0.10194467753171921,
      "learning_rate": 2.8487248196883043e-05,
      "loss": 0.0404,
      "step": 64570
    },
    {
      "epoch": 1.2914450265968083,
      "grad_norm": 0.10577018558979034,
      "learning_rate": 2.8483915263501716e-05,
      "loss": 0.0709,
      "step": 64580
    },
    {
      "epoch": 1.291645002599688,
      "grad_norm": 0.0872592031955719,
      "learning_rate": 2.8480582330120385e-05,
      "loss": 0.0683,
      "step": 64590
    },
    {
      "epoch": 1.2918449786025676,
      "grad_norm": 0.07955195754766464,
      "learning_rate": 2.8477249396739058e-05,
      "loss": 0.0504,
      "step": 64600
    },
    {
      "epoch": 1.2920449546054473,
      "grad_norm": 0.07556670904159546,
      "learning_rate": 2.847391646335773e-05,
      "loss": 0.0729,
      "step": 64610
    },
    {
      "epoch": 1.292244930608327,
      "grad_norm": 0.11960398405790329,
      "learning_rate": 2.84705835299764e-05,
      "loss": 0.1154,
      "step": 64620
    },
    {
      "epoch": 1.2924449066112067,
      "grad_norm": 0.12683264911174774,
      "learning_rate": 2.8467250596595074e-05,
      "loss": 0.0831,
      "step": 64630
    },
    {
      "epoch": 1.2926448826140864,
      "grad_norm": 0.15464244782924652,
      "learning_rate": 2.846391766321375e-05,
      "loss": 0.0529,
      "step": 64640
    },
    {
      "epoch": 1.292844858616966,
      "grad_norm": 0.09868580102920532,
      "learning_rate": 2.8460584729832423e-05,
      "loss": 0.0847,
      "step": 64650
    },
    {
      "epoch": 1.2930448346198455,
      "grad_norm": 0.2777859568595886,
      "learning_rate": 2.8457251796451096e-05,
      "loss": 0.2391,
      "step": 64660
    },
    {
      "epoch": 1.2932448106227252,
      "grad_norm": 0.1868349313735962,
      "learning_rate": 2.8453918863069766e-05,
      "loss": 0.1054,
      "step": 64670
    },
    {
      "epoch": 1.293444786625605,
      "grad_norm": 0.06047447770833969,
      "learning_rate": 2.845058592968844e-05,
      "loss": 0.0903,
      "step": 64680
    },
    {
      "epoch": 1.2936447626284846,
      "grad_norm": 0.09169565141201019,
      "learning_rate": 2.8447252996307112e-05,
      "loss": 0.073,
      "step": 64690
    },
    {
      "epoch": 1.2938447386313643,
      "grad_norm": 0.17406652867794037,
      "learning_rate": 2.844392006292578e-05,
      "loss": 0.0652,
      "step": 64700
    },
    {
      "epoch": 1.2940447146342438,
      "grad_norm": 0.20141646265983582,
      "learning_rate": 2.8440587129544454e-05,
      "loss": 0.0764,
      "step": 64710
    },
    {
      "epoch": 1.2942446906371234,
      "grad_norm": 0.07552287727594376,
      "learning_rate": 2.8437254196163127e-05,
      "loss": 0.0656,
      "step": 64720
    },
    {
      "epoch": 1.2944446666400031,
      "grad_norm": 0.0837065726518631,
      "learning_rate": 2.8433921262781797e-05,
      "loss": 0.1077,
      "step": 64730
    },
    {
      "epoch": 1.2946446426428828,
      "grad_norm": 0.22740410268306732,
      "learning_rate": 2.8430588329400477e-05,
      "loss": 0.052,
      "step": 64740
    },
    {
      "epoch": 1.2948446186457625,
      "grad_norm": 0.0986379012465477,
      "learning_rate": 2.8427255396019146e-05,
      "loss": 0.0759,
      "step": 64750
    },
    {
      "epoch": 1.2950445946486422,
      "grad_norm": 0.08474016934633255,
      "learning_rate": 2.842425575597595e-05,
      "loss": 0.1351,
      "step": 64760
    },
    {
      "epoch": 1.2952445706515219,
      "grad_norm": 0.11999136209487915,
      "learning_rate": 2.8420922822594625e-05,
      "loss": 0.0819,
      "step": 64770
    },
    {
      "epoch": 1.2954445466544016,
      "grad_norm": 0.11473587900400162,
      "learning_rate": 2.8417589889213298e-05,
      "loss": 0.0558,
      "step": 64780
    },
    {
      "epoch": 1.2956445226572813,
      "grad_norm": 0.20197011530399323,
      "learning_rate": 2.841425695583197e-05,
      "loss": 0.0661,
      "step": 64790
    },
    {
      "epoch": 1.2958444986601607,
      "grad_norm": 0.13209335505962372,
      "learning_rate": 2.841092402245064e-05,
      "loss": 0.0914,
      "step": 64800
    },
    {
      "epoch": 1.2960444746630404,
      "grad_norm": 0.11030875891447067,
      "learning_rate": 2.8407591089069313e-05,
      "loss": 0.0807,
      "step": 64810
    },
    {
      "epoch": 1.29624445066592,
      "grad_norm": 0.1468094438314438,
      "learning_rate": 2.8404258155687986e-05,
      "loss": 0.0851,
      "step": 64820
    },
    {
      "epoch": 1.2964444266687998,
      "grad_norm": 0.19737645983695984,
      "learning_rate": 2.8400925222306656e-05,
      "loss": 0.0737,
      "step": 64830
    },
    {
      "epoch": 1.2966444026716795,
      "grad_norm": 0.10832473635673523,
      "learning_rate": 2.839759228892533e-05,
      "loss": 0.0643,
      "step": 64840
    },
    {
      "epoch": 1.296844378674559,
      "grad_norm": 0.19982236623764038,
      "learning_rate": 2.8394259355544002e-05,
      "loss": 0.0375,
      "step": 64850
    },
    {
      "epoch": 1.2970443546774386,
      "grad_norm": 0.07847220450639725,
      "learning_rate": 2.839092642216267e-05,
      "loss": 0.0993,
      "step": 64860
    },
    {
      "epoch": 1.2972443306803183,
      "grad_norm": 0.08473260700702667,
      "learning_rate": 2.838759348878135e-05,
      "loss": 0.0667,
      "step": 64870
    },
    {
      "epoch": 1.297444306683198,
      "grad_norm": 0.09082808345556259,
      "learning_rate": 2.838426055540002e-05,
      "loss": 0.3948,
      "step": 64880
    },
    {
      "epoch": 1.2976442826860777,
      "grad_norm": 0.10699260979890823,
      "learning_rate": 2.8380927622018694e-05,
      "loss": 0.0473,
      "step": 64890
    },
    {
      "epoch": 1.2978442586889574,
      "grad_norm": 0.0691867545247078,
      "learning_rate": 2.8377594688637367e-05,
      "loss": 0.0735,
      "step": 64900
    },
    {
      "epoch": 1.298044234691837,
      "grad_norm": 0.08780840039253235,
      "learning_rate": 2.8374261755256037e-05,
      "loss": 0.0775,
      "step": 64910
    },
    {
      "epoch": 1.2982442106947167,
      "grad_norm": 0.12091198563575745,
      "learning_rate": 2.837092882187471e-05,
      "loss": 0.0824,
      "step": 64920
    },
    {
      "epoch": 1.2984441866975964,
      "grad_norm": 0.15272071957588196,
      "learning_rate": 2.8367595888493383e-05,
      "loss": 0.0515,
      "step": 64930
    },
    {
      "epoch": 1.298644162700476,
      "grad_norm": 0.2590932846069336,
      "learning_rate": 2.8364262955112052e-05,
      "loss": 0.1023,
      "step": 64940
    },
    {
      "epoch": 1.2988441387033556,
      "grad_norm": 0.1845393180847168,
      "learning_rate": 2.8360930021730725e-05,
      "loss": 0.0807,
      "step": 64950
    },
    {
      "epoch": 1.2990441147062353,
      "grad_norm": 0.17350523173809052,
      "learning_rate": 2.83575970883494e-05,
      "loss": 0.0689,
      "step": 64960
    },
    {
      "epoch": 1.299244090709115,
      "grad_norm": 0.22105388343334198,
      "learning_rate": 2.8354264154968075e-05,
      "loss": 0.0909,
      "step": 64970
    },
    {
      "epoch": 1.2994440667119946,
      "grad_norm": 0.12817220389842987,
      "learning_rate": 2.8350931221586748e-05,
      "loss": 0.0545,
      "step": 64980
    },
    {
      "epoch": 1.299644042714874,
      "grad_norm": 0.12677232921123505,
      "learning_rate": 2.8347598288205417e-05,
      "loss": 0.0718,
      "step": 64990
    },
    {
      "epoch": 1.2998440187177538,
      "grad_norm": 0.07537126541137695,
      "learning_rate": 2.834426535482409e-05,
      "loss": 0.064,
      "step": 65000
    },
    {
      "epoch": 1.3000439947206335,
      "grad_norm": 0.21476414799690247,
      "learning_rate": 2.8340932421442763e-05,
      "loss": 0.0868,
      "step": 65010
    },
    {
      "epoch": 1.3002439707235132,
      "grad_norm": 0.11467957496643066,
      "learning_rate": 2.8337599488061433e-05,
      "loss": 0.0777,
      "step": 65020
    },
    {
      "epoch": 1.3004439467263929,
      "grad_norm": 0.07053323090076447,
      "learning_rate": 2.8334266554680106e-05,
      "loss": 0.0857,
      "step": 65030
    },
    {
      "epoch": 1.3006439227292725,
      "grad_norm": 0.1498630940914154,
      "learning_rate": 2.833093362129878e-05,
      "loss": 0.096,
      "step": 65040
    },
    {
      "epoch": 1.3008438987321522,
      "grad_norm": 0.0689745843410492,
      "learning_rate": 2.832760068791745e-05,
      "loss": 0.0907,
      "step": 65050
    },
    {
      "epoch": 1.301043874735032,
      "grad_norm": 0.19115085899829865,
      "learning_rate": 2.832426775453612e-05,
      "loss": 0.1053,
      "step": 65060
    },
    {
      "epoch": 1.3012438507379114,
      "grad_norm": 0.28076282143592834,
      "learning_rate": 2.8320934821154798e-05,
      "loss": 0.1014,
      "step": 65070
    },
    {
      "epoch": 1.301443826740791,
      "grad_norm": 0.17977584898471832,
      "learning_rate": 2.831760188777347e-05,
      "loss": 0.1578,
      "step": 65080
    },
    {
      "epoch": 1.3016438027436708,
      "grad_norm": 0.189643993973732,
      "learning_rate": 2.8314268954392144e-05,
      "loss": 0.0749,
      "step": 65090
    },
    {
      "epoch": 1.3018437787465504,
      "grad_norm": 0.09050945937633514,
      "learning_rate": 2.8310936021010814e-05,
      "loss": 0.0717,
      "step": 65100
    },
    {
      "epoch": 1.3020437547494301,
      "grad_norm": 0.10230066627264023,
      "learning_rate": 2.8307603087629487e-05,
      "loss": 0.0549,
      "step": 65110
    },
    {
      "epoch": 1.3022437307523096,
      "grad_norm": 0.24900372326374054,
      "learning_rate": 2.830427015424816e-05,
      "loss": 0.0769,
      "step": 65120
    },
    {
      "epoch": 1.3024437067551893,
      "grad_norm": 0.2336750328540802,
      "learning_rate": 2.830093722086683e-05,
      "loss": 0.0759,
      "step": 65130
    },
    {
      "epoch": 1.302643682758069,
      "grad_norm": 0.13100364804267883,
      "learning_rate": 2.8297604287485502e-05,
      "loss": 0.0862,
      "step": 65140
    },
    {
      "epoch": 1.3028436587609487,
      "grad_norm": 0.10102540254592896,
      "learning_rate": 2.8294271354104175e-05,
      "loss": 0.0611,
      "step": 65150
    },
    {
      "epoch": 1.3030436347638283,
      "grad_norm": 0.19837361574172974,
      "learning_rate": 2.8290938420722845e-05,
      "loss": 0.0686,
      "step": 65160
    },
    {
      "epoch": 1.303243610766708,
      "grad_norm": 0.1085117980837822,
      "learning_rate": 2.8287605487341525e-05,
      "loss": 0.0553,
      "step": 65170
    },
    {
      "epoch": 1.3034435867695877,
      "grad_norm": 0.07843079417943954,
      "learning_rate": 2.8284272553960194e-05,
      "loss": 0.1008,
      "step": 65180
    },
    {
      "epoch": 1.3036435627724674,
      "grad_norm": 0.08815035969018936,
      "learning_rate": 2.8280939620578867e-05,
      "loss": 0.0724,
      "step": 65190
    },
    {
      "epoch": 1.303843538775347,
      "grad_norm": 0.274750292301178,
      "learning_rate": 2.827760668719754e-05,
      "loss": 0.1155,
      "step": 65200
    },
    {
      "epoch": 1.3040435147782266,
      "grad_norm": 0.14659301936626434,
      "learning_rate": 2.827427375381621e-05,
      "loss": 0.063,
      "step": 65210
    },
    {
      "epoch": 1.3042434907811062,
      "grad_norm": 0.21851587295532227,
      "learning_rate": 2.8270940820434883e-05,
      "loss": 0.0754,
      "step": 65220
    },
    {
      "epoch": 1.304443466783986,
      "grad_norm": 0.1320347636938095,
      "learning_rate": 2.8267607887053556e-05,
      "loss": 0.0841,
      "step": 65230
    },
    {
      "epoch": 1.3046434427868656,
      "grad_norm": 0.12265366315841675,
      "learning_rate": 2.8264274953672226e-05,
      "loss": 0.073,
      "step": 65240
    },
    {
      "epoch": 1.3048434187897453,
      "grad_norm": 0.10907533019781113,
      "learning_rate": 2.82609420202909e-05,
      "loss": 0.0583,
      "step": 65250
    },
    {
      "epoch": 1.3050433947926248,
      "grad_norm": 0.09308706969022751,
      "learning_rate": 2.825760908690957e-05,
      "loss": 0.0523,
      "step": 65260
    },
    {
      "epoch": 1.3052433707955045,
      "grad_norm": 0.10748497396707535,
      "learning_rate": 2.825427615352824e-05,
      "loss": 0.0608,
      "step": 65270
    },
    {
      "epoch": 1.3054433467983841,
      "grad_norm": 0.15769073367118835,
      "learning_rate": 2.825094322014692e-05,
      "loss": 0.0788,
      "step": 65280
    },
    {
      "epoch": 1.3056433228012638,
      "grad_norm": 0.1061510220170021,
      "learning_rate": 2.824761028676559e-05,
      "loss": 0.0806,
      "step": 65290
    },
    {
      "epoch": 1.3058432988041435,
      "grad_norm": 0.14966610074043274,
      "learning_rate": 2.8244277353384264e-05,
      "loss": 0.0682,
      "step": 65300
    },
    {
      "epoch": 1.3060432748070232,
      "grad_norm": 0.14492346346378326,
      "learning_rate": 2.8240944420002937e-05,
      "loss": 0.0424,
      "step": 65310
    },
    {
      "epoch": 1.306243250809903,
      "grad_norm": 0.22876684367656708,
      "learning_rate": 2.8237611486621606e-05,
      "loss": 0.1062,
      "step": 65320
    },
    {
      "epoch": 1.3064432268127826,
      "grad_norm": 0.16243954002857208,
      "learning_rate": 2.823427855324028e-05,
      "loss": 0.0751,
      "step": 65330
    },
    {
      "epoch": 1.306643202815662,
      "grad_norm": 0.13524767756462097,
      "learning_rate": 2.8230945619858952e-05,
      "loss": 0.0505,
      "step": 65340
    },
    {
      "epoch": 1.3068431788185417,
      "grad_norm": 0.10619889944791794,
      "learning_rate": 2.8227612686477622e-05,
      "loss": 0.0541,
      "step": 65350
    },
    {
      "epoch": 1.3070431548214214,
      "grad_norm": 0.15062406659126282,
      "learning_rate": 2.8224279753096295e-05,
      "loss": 0.0596,
      "step": 65360
    },
    {
      "epoch": 1.307243130824301,
      "grad_norm": 0.1568748652935028,
      "learning_rate": 2.8220946819714968e-05,
      "loss": 0.0933,
      "step": 65370
    },
    {
      "epoch": 1.3074431068271808,
      "grad_norm": 0.07797835022211075,
      "learning_rate": 2.8217613886333644e-05,
      "loss": 0.1002,
      "step": 65380
    },
    {
      "epoch": 1.3076430828300603,
      "grad_norm": 0.1260865032672882,
      "learning_rate": 2.8214280952952317e-05,
      "loss": 0.0954,
      "step": 65390
    },
    {
      "epoch": 1.30784305883294,
      "grad_norm": 0.1382274031639099,
      "learning_rate": 2.8210948019570987e-05,
      "loss": 0.0954,
      "step": 65400
    },
    {
      "epoch": 1.3080430348358196,
      "grad_norm": 0.2075943648815155,
      "learning_rate": 2.820761508618966e-05,
      "loss": 0.0847,
      "step": 65410
    },
    {
      "epoch": 1.3082430108386993,
      "grad_norm": 0.19442544877529144,
      "learning_rate": 2.8204282152808333e-05,
      "loss": 0.0887,
      "step": 65420
    },
    {
      "epoch": 1.308442986841579,
      "grad_norm": 0.12053069472312927,
      "learning_rate": 2.8200949219427002e-05,
      "loss": 0.0864,
      "step": 65430
    },
    {
      "epoch": 1.3086429628444587,
      "grad_norm": 0.07792899757623672,
      "learning_rate": 2.8197616286045675e-05,
      "loss": 0.0899,
      "step": 65440
    },
    {
      "epoch": 1.3088429388473384,
      "grad_norm": 0.1905616670846939,
      "learning_rate": 2.819428335266435e-05,
      "loss": 0.0755,
      "step": 65450
    },
    {
      "epoch": 1.309042914850218,
      "grad_norm": 0.084081269800663,
      "learning_rate": 2.8190950419283018e-05,
      "loss": 0.0541,
      "step": 65460
    },
    {
      "epoch": 1.3092428908530978,
      "grad_norm": 0.07486710697412491,
      "learning_rate": 2.818761748590169e-05,
      "loss": 0.0544,
      "step": 65470
    },
    {
      "epoch": 1.3094428668559772,
      "grad_norm": 0.09973631799221039,
      "learning_rate": 2.8184284552520367e-05,
      "loss": 0.0764,
      "step": 65480
    },
    {
      "epoch": 1.309642842858857,
      "grad_norm": 0.14042718708515167,
      "learning_rate": 2.818095161913904e-05,
      "loss": 0.0623,
      "step": 65490
    },
    {
      "epoch": 1.3098428188617366,
      "grad_norm": 0.23344333469867706,
      "learning_rate": 2.8177618685757713e-05,
      "loss": 0.0762,
      "step": 65500
    },
    {
      "epoch": 1.3100427948646163,
      "grad_norm": 0.08413732051849365,
      "learning_rate": 2.8174285752376383e-05,
      "loss": 0.0702,
      "step": 65510
    },
    {
      "epoch": 1.310242770867496,
      "grad_norm": 0.23515771329402924,
      "learning_rate": 2.8170952818995056e-05,
      "loss": 0.0712,
      "step": 65520
    },
    {
      "epoch": 1.3104427468703754,
      "grad_norm": 0.18300537765026093,
      "learning_rate": 2.816761988561373e-05,
      "loss": 0.0934,
      "step": 65530
    },
    {
      "epoch": 1.3106427228732551,
      "grad_norm": 0.14091356098651886,
      "learning_rate": 2.81642869522324e-05,
      "loss": 0.0874,
      "step": 65540
    },
    {
      "epoch": 1.3108426988761348,
      "grad_norm": 0.11092016100883484,
      "learning_rate": 2.8160954018851072e-05,
      "loss": 0.085,
      "step": 65550
    },
    {
      "epoch": 1.3110426748790145,
      "grad_norm": 0.17499347031116486,
      "learning_rate": 2.8157621085469745e-05,
      "loss": 0.097,
      "step": 65560
    },
    {
      "epoch": 1.3112426508818942,
      "grad_norm": 0.16693998873233795,
      "learning_rate": 2.8154288152088414e-05,
      "loss": 0.1085,
      "step": 65570
    },
    {
      "epoch": 1.3114426268847739,
      "grad_norm": 0.21421881020069122,
      "learning_rate": 2.8150955218707094e-05,
      "loss": 0.0877,
      "step": 65580
    },
    {
      "epoch": 1.3116426028876536,
      "grad_norm": 0.10783858597278595,
      "learning_rate": 2.8147622285325764e-05,
      "loss": 0.0597,
      "step": 65590
    },
    {
      "epoch": 1.3118425788905332,
      "grad_norm": 0.2548333704471588,
      "learning_rate": 2.8144289351944437e-05,
      "loss": 0.0907,
      "step": 65600
    },
    {
      "epoch": 1.312042554893413,
      "grad_norm": 0.17324501276016235,
      "learning_rate": 2.814095641856311e-05,
      "loss": 0.0816,
      "step": 65610
    },
    {
      "epoch": 1.3122425308962924,
      "grad_norm": 0.0772126317024231,
      "learning_rate": 2.813762348518178e-05,
      "loss": 0.0497,
      "step": 65620
    },
    {
      "epoch": 1.312442506899172,
      "grad_norm": 0.12596172094345093,
      "learning_rate": 2.8134290551800452e-05,
      "loss": 0.0719,
      "step": 65630
    },
    {
      "epoch": 1.3126424829020518,
      "grad_norm": 0.07734525203704834,
      "learning_rate": 2.8130957618419125e-05,
      "loss": 0.0989,
      "step": 65640
    },
    {
      "epoch": 1.3128424589049315,
      "grad_norm": 0.07335112988948822,
      "learning_rate": 2.8127624685037795e-05,
      "loss": 0.0542,
      "step": 65650
    },
    {
      "epoch": 1.3130424349078111,
      "grad_norm": 0.14189410209655762,
      "learning_rate": 2.8124291751656468e-05,
      "loss": 0.0624,
      "step": 65660
    },
    {
      "epoch": 1.3132424109106906,
      "grad_norm": 0.06961217522621155,
      "learning_rate": 2.812095881827514e-05,
      "loss": 0.0551,
      "step": 65670
    },
    {
      "epoch": 1.3134423869135703,
      "grad_norm": 0.14679579436779022,
      "learning_rate": 2.8117625884893817e-05,
      "loss": 0.0662,
      "step": 65680
    },
    {
      "epoch": 1.31364236291645,
      "grad_norm": 0.07129931449890137,
      "learning_rate": 2.8114292951512487e-05,
      "loss": 0.0512,
      "step": 65690
    },
    {
      "epoch": 1.3138423389193297,
      "grad_norm": 0.15115781128406525,
      "learning_rate": 2.811096001813116e-05,
      "loss": 0.0817,
      "step": 65700
    },
    {
      "epoch": 1.3140423149222094,
      "grad_norm": 0.21525315940380096,
      "learning_rate": 2.8107627084749833e-05,
      "loss": 0.0871,
      "step": 65710
    },
    {
      "epoch": 1.314242290925089,
      "grad_norm": 0.24452710151672363,
      "learning_rate": 2.8104294151368506e-05,
      "loss": 0.0686,
      "step": 65720
    },
    {
      "epoch": 1.3144422669279687,
      "grad_norm": 0.1684289425611496,
      "learning_rate": 2.8100961217987176e-05,
      "loss": 0.0817,
      "step": 65730
    },
    {
      "epoch": 1.3146422429308484,
      "grad_norm": 0.05202748253941536,
      "learning_rate": 2.809762828460585e-05,
      "loss": 0.0621,
      "step": 65740
    },
    {
      "epoch": 1.3148422189337279,
      "grad_norm": 0.15037134289741516,
      "learning_rate": 2.809429535122452e-05,
      "loss": 0.055,
      "step": 65750
    },
    {
      "epoch": 1.3150421949366076,
      "grad_norm": 0.08206287026405334,
      "learning_rate": 2.809096241784319e-05,
      "loss": 0.0677,
      "step": 65760
    },
    {
      "epoch": 1.3152421709394873,
      "grad_norm": 0.060522954910993576,
      "learning_rate": 2.8087629484461864e-05,
      "loss": 0.0862,
      "step": 65770
    },
    {
      "epoch": 1.315442146942367,
      "grad_norm": 0.1519736796617508,
      "learning_rate": 2.8084296551080537e-05,
      "loss": 0.0694,
      "step": 65780
    },
    {
      "epoch": 1.3156421229452466,
      "grad_norm": 0.09103237837553024,
      "learning_rate": 2.8080963617699214e-05,
      "loss": 0.0847,
      "step": 65790
    },
    {
      "epoch": 1.315842098948126,
      "grad_norm": 0.1423490196466446,
      "learning_rate": 2.8077630684317883e-05,
      "loss": 0.0755,
      "step": 65800
    },
    {
      "epoch": 1.3160420749510058,
      "grad_norm": 0.11555176973342896,
      "learning_rate": 2.8074297750936556e-05,
      "loss": 0.0606,
      "step": 65810
    },
    {
      "epoch": 1.3162420509538855,
      "grad_norm": 0.11901595443487167,
      "learning_rate": 2.807096481755523e-05,
      "loss": 0.0399,
      "step": 65820
    },
    {
      "epoch": 1.3164420269567652,
      "grad_norm": 0.05530018359422684,
      "learning_rate": 2.80676318841739e-05,
      "loss": 0.0697,
      "step": 65830
    },
    {
      "epoch": 1.3166420029596448,
      "grad_norm": 0.10905691236257553,
      "learning_rate": 2.8064298950792572e-05,
      "loss": 0.0671,
      "step": 65840
    },
    {
      "epoch": 1.3168419789625245,
      "grad_norm": 0.07851872593164444,
      "learning_rate": 2.8060966017411245e-05,
      "loss": 0.0562,
      "step": 65850
    },
    {
      "epoch": 1.3170419549654042,
      "grad_norm": 0.06560640037059784,
      "learning_rate": 2.8057633084029918e-05,
      "loss": 0.0787,
      "step": 65860
    },
    {
      "epoch": 1.317241930968284,
      "grad_norm": 0.133976012468338,
      "learning_rate": 2.8054300150648587e-05,
      "loss": 0.0816,
      "step": 65870
    },
    {
      "epoch": 1.3174419069711636,
      "grad_norm": 0.12616531550884247,
      "learning_rate": 2.805096721726726e-05,
      "loss": 0.0876,
      "step": 65880
    },
    {
      "epoch": 1.317641882974043,
      "grad_norm": 0.14014418423175812,
      "learning_rate": 2.8047634283885937e-05,
      "loss": 0.0741,
      "step": 65890
    },
    {
      "epoch": 1.3178418589769227,
      "grad_norm": 0.11479636281728745,
      "learning_rate": 2.804430135050461e-05,
      "loss": 0.0893,
      "step": 65900
    },
    {
      "epoch": 1.3180418349798024,
      "grad_norm": 0.20620620250701904,
      "learning_rate": 2.804096841712328e-05,
      "loss": 0.0828,
      "step": 65910
    },
    {
      "epoch": 1.3182418109826821,
      "grad_norm": 0.10118697583675385,
      "learning_rate": 2.8037635483741953e-05,
      "loss": 0.0786,
      "step": 65920
    },
    {
      "epoch": 1.3184417869855618,
      "grad_norm": 0.12785623967647552,
      "learning_rate": 2.8034302550360626e-05,
      "loss": 0.0944,
      "step": 65930
    },
    {
      "epoch": 1.3186417629884413,
      "grad_norm": 0.13258062303066254,
      "learning_rate": 2.8030969616979295e-05,
      "loss": 0.0658,
      "step": 65940
    },
    {
      "epoch": 1.318841738991321,
      "grad_norm": 0.2856355607509613,
      "learning_rate": 2.8027636683597968e-05,
      "loss": 0.0838,
      "step": 65950
    },
    {
      "epoch": 1.3190417149942006,
      "grad_norm": 0.09486585110425949,
      "learning_rate": 2.802430375021664e-05,
      "loss": 0.0446,
      "step": 65960
    },
    {
      "epoch": 1.3192416909970803,
      "grad_norm": 0.15586988627910614,
      "learning_rate": 2.802097081683531e-05,
      "loss": 0.0836,
      "step": 65970
    },
    {
      "epoch": 1.31944166699996,
      "grad_norm": 0.09676411002874374,
      "learning_rate": 2.8017637883453984e-05,
      "loss": 0.0842,
      "step": 65980
    },
    {
      "epoch": 1.3196416430028397,
      "grad_norm": 0.216927170753479,
      "learning_rate": 2.801430495007266e-05,
      "loss": 0.0849,
      "step": 65990
    },
    {
      "epoch": 1.3198416190057194,
      "grad_norm": 0.19687695801258087,
      "learning_rate": 2.8010972016691333e-05,
      "loss": 0.0865,
      "step": 66000
    },
    {
      "epoch": 1.320041595008599,
      "grad_norm": 0.06297179311513901,
      "learning_rate": 2.8007639083310006e-05,
      "loss": 0.0627,
      "step": 66010
    },
    {
      "epoch": 1.3202415710114785,
      "grad_norm": 0.14606168866157532,
      "learning_rate": 2.8004306149928676e-05,
      "loss": 0.0528,
      "step": 66020
    },
    {
      "epoch": 1.3204415470143582,
      "grad_norm": 0.10567671805620193,
      "learning_rate": 2.800097321654735e-05,
      "loss": 0.0657,
      "step": 66030
    },
    {
      "epoch": 1.320641523017238,
      "grad_norm": 0.12540271878242493,
      "learning_rate": 2.7997640283166022e-05,
      "loss": 0.0746,
      "step": 66040
    },
    {
      "epoch": 1.3208414990201176,
      "grad_norm": 0.09782466292381287,
      "learning_rate": 2.799430734978469e-05,
      "loss": 0.0664,
      "step": 66050
    },
    {
      "epoch": 1.3210414750229973,
      "grad_norm": 0.23267292976379395,
      "learning_rate": 2.7990974416403364e-05,
      "loss": 0.1041,
      "step": 66060
    },
    {
      "epoch": 1.3212414510258768,
      "grad_norm": 0.16055047512054443,
      "learning_rate": 2.7987641483022037e-05,
      "loss": 0.1423,
      "step": 66070
    },
    {
      "epoch": 1.3214414270287564,
      "grad_norm": 0.09118134528398514,
      "learning_rate": 2.7984308549640707e-05,
      "loss": 0.074,
      "step": 66080
    },
    {
      "epoch": 1.3216414030316361,
      "grad_norm": 0.10032130032777786,
      "learning_rate": 2.7980975616259387e-05,
      "loss": 0.0889,
      "step": 66090
    },
    {
      "epoch": 1.3218413790345158,
      "grad_norm": 0.16801339387893677,
      "learning_rate": 2.7977642682878056e-05,
      "loss": 0.0961,
      "step": 66100
    },
    {
      "epoch": 1.3220413550373955,
      "grad_norm": 0.17610500752925873,
      "learning_rate": 2.797430974949673e-05,
      "loss": 0.0801,
      "step": 66110
    },
    {
      "epoch": 1.3222413310402752,
      "grad_norm": 0.09102806448936462,
      "learning_rate": 2.7970976816115402e-05,
      "loss": 0.0661,
      "step": 66120
    },
    {
      "epoch": 1.3224413070431549,
      "grad_norm": 0.17049698531627655,
      "learning_rate": 2.7967643882734072e-05,
      "loss": 0.0533,
      "step": 66130
    },
    {
      "epoch": 1.3226412830460346,
      "grad_norm": 0.09124061465263367,
      "learning_rate": 2.7964310949352745e-05,
      "loss": 0.0796,
      "step": 66140
    },
    {
      "epoch": 1.3228412590489143,
      "grad_norm": 0.1492292732000351,
      "learning_rate": 2.7960978015971418e-05,
      "loss": 0.0904,
      "step": 66150
    },
    {
      "epoch": 1.3230412350517937,
      "grad_norm": 0.08038530498743057,
      "learning_rate": 2.7957645082590088e-05,
      "loss": 0.0588,
      "step": 66160
    },
    {
      "epoch": 1.3232412110546734,
      "grad_norm": 0.075295090675354,
      "learning_rate": 2.795431214920876e-05,
      "loss": 0.0666,
      "step": 66170
    },
    {
      "epoch": 1.323441187057553,
      "grad_norm": 0.19140203297138214,
      "learning_rate": 2.7950979215827434e-05,
      "loss": 0.1255,
      "step": 66180
    },
    {
      "epoch": 1.3236411630604328,
      "grad_norm": 0.0983312577009201,
      "learning_rate": 2.794764628244611e-05,
      "loss": 0.0632,
      "step": 66190
    },
    {
      "epoch": 1.3238411390633125,
      "grad_norm": 0.13049903512001038,
      "learning_rate": 2.7944313349064783e-05,
      "loss": 0.1044,
      "step": 66200
    },
    {
      "epoch": 1.324041115066192,
      "grad_norm": 0.19002708792686462,
      "learning_rate": 2.7940980415683453e-05,
      "loss": 0.0716,
      "step": 66210
    },
    {
      "epoch": 1.3242410910690716,
      "grad_norm": 0.12907738983631134,
      "learning_rate": 2.7937647482302126e-05,
      "loss": 0.0634,
      "step": 66220
    },
    {
      "epoch": 1.3244410670719513,
      "grad_norm": 0.08326530456542969,
      "learning_rate": 2.79343145489208e-05,
      "loss": 0.0695,
      "step": 66230
    },
    {
      "epoch": 1.324641043074831,
      "grad_norm": 0.10416058450937271,
      "learning_rate": 2.793098161553947e-05,
      "loss": 0.0626,
      "step": 66240
    },
    {
      "epoch": 1.3248410190777107,
      "grad_norm": 0.2274395227432251,
      "learning_rate": 2.792764868215814e-05,
      "loss": 0.1023,
      "step": 66250
    },
    {
      "epoch": 1.3250409950805904,
      "grad_norm": 0.15838421881198883,
      "learning_rate": 2.7924315748776814e-05,
      "loss": 0.063,
      "step": 66260
    },
    {
      "epoch": 1.32524097108347,
      "grad_norm": 0.07381321489810944,
      "learning_rate": 2.7920982815395484e-05,
      "loss": 0.0576,
      "step": 66270
    },
    {
      "epoch": 1.3254409470863497,
      "grad_norm": 0.1314450055360794,
      "learning_rate": 2.7917649882014157e-05,
      "loss": 0.0732,
      "step": 66280
    },
    {
      "epoch": 1.3256409230892294,
      "grad_norm": 0.2560455799102783,
      "learning_rate": 2.791431694863283e-05,
      "loss": 0.0559,
      "step": 66290
    },
    {
      "epoch": 1.325840899092109,
      "grad_norm": 0.05625719949603081,
      "learning_rate": 2.7910984015251506e-05,
      "loss": 0.0528,
      "step": 66300
    },
    {
      "epoch": 1.3260408750949886,
      "grad_norm": 0.14468617737293243,
      "learning_rate": 2.790765108187018e-05,
      "loss": 0.0975,
      "step": 66310
    },
    {
      "epoch": 1.3262408510978683,
      "grad_norm": 0.23828855156898499,
      "learning_rate": 2.790431814848885e-05,
      "loss": 0.141,
      "step": 66320
    },
    {
      "epoch": 1.326440827100748,
      "grad_norm": 0.09516207128763199,
      "learning_rate": 2.7900985215107522e-05,
      "loss": 0.0641,
      "step": 66330
    },
    {
      "epoch": 1.3266408031036276,
      "grad_norm": 0.06363656371831894,
      "learning_rate": 2.7897652281726195e-05,
      "loss": 0.0741,
      "step": 66340
    },
    {
      "epoch": 1.326840779106507,
      "grad_norm": 0.19986355304718018,
      "learning_rate": 2.7894319348344865e-05,
      "loss": 0.0834,
      "step": 66350
    },
    {
      "epoch": 1.3270407551093868,
      "grad_norm": 0.13345400989055634,
      "learning_rate": 2.7890986414963538e-05,
      "loss": 0.0566,
      "step": 66360
    },
    {
      "epoch": 1.3272407311122665,
      "grad_norm": 0.17392481863498688,
      "learning_rate": 2.788765348158221e-05,
      "loss": 0.0765,
      "step": 66370
    },
    {
      "epoch": 1.3274407071151462,
      "grad_norm": 0.18058975040912628,
      "learning_rate": 2.788432054820088e-05,
      "loss": 0.106,
      "step": 66380
    },
    {
      "epoch": 1.3276406831180259,
      "grad_norm": 0.07473190128803253,
      "learning_rate": 2.7880987614819553e-05,
      "loss": 0.0512,
      "step": 66390
    },
    {
      "epoch": 1.3278406591209055,
      "grad_norm": 0.1286018341779709,
      "learning_rate": 2.787765468143823e-05,
      "loss": 0.0749,
      "step": 66400
    },
    {
      "epoch": 1.3280406351237852,
      "grad_norm": 0.10437940061092377,
      "learning_rate": 2.7874321748056903e-05,
      "loss": 0.0754,
      "step": 66410
    },
    {
      "epoch": 1.328240611126665,
      "grad_norm": 0.07546339929103851,
      "learning_rate": 2.7870988814675576e-05,
      "loss": 0.0755,
      "step": 66420
    },
    {
      "epoch": 1.3284405871295444,
      "grad_norm": 0.2870800197124481,
      "learning_rate": 2.7867655881294245e-05,
      "loss": 0.0825,
      "step": 66430
    },
    {
      "epoch": 1.328640563132424,
      "grad_norm": 0.09186453372240067,
      "learning_rate": 2.7864322947912918e-05,
      "loss": 0.0839,
      "step": 66440
    },
    {
      "epoch": 1.3288405391353038,
      "grad_norm": 0.2760683298110962,
      "learning_rate": 2.786099001453159e-05,
      "loss": 0.1174,
      "step": 66450
    },
    {
      "epoch": 1.3290405151381834,
      "grad_norm": 0.11566118150949478,
      "learning_rate": 2.785765708115026e-05,
      "loss": 0.104,
      "step": 66460
    },
    {
      "epoch": 1.3292404911410631,
      "grad_norm": 0.08495225757360458,
      "learning_rate": 2.7854324147768934e-05,
      "loss": 0.0872,
      "step": 66470
    },
    {
      "epoch": 1.3294404671439426,
      "grad_norm": 0.2475125938653946,
      "learning_rate": 2.7850991214387607e-05,
      "loss": 0.1133,
      "step": 66480
    },
    {
      "epoch": 1.3296404431468223,
      "grad_norm": 0.09483983367681503,
      "learning_rate": 2.7847658281006276e-05,
      "loss": 0.054,
      "step": 66490
    },
    {
      "epoch": 1.329840419149702,
      "grad_norm": 0.06213073804974556,
      "learning_rate": 2.7844325347624956e-05,
      "loss": 0.0635,
      "step": 66500
    },
    {
      "epoch": 1.3300403951525817,
      "grad_norm": 0.084923654794693,
      "learning_rate": 2.7840992414243626e-05,
      "loss": 0.0995,
      "step": 66510
    },
    {
      "epoch": 1.3302403711554613,
      "grad_norm": 0.0690753161907196,
      "learning_rate": 2.78376594808623e-05,
      "loss": 0.0556,
      "step": 66520
    },
    {
      "epoch": 1.330440347158341,
      "grad_norm": 0.1853073239326477,
      "learning_rate": 2.7834326547480972e-05,
      "loss": 0.0779,
      "step": 66530
    },
    {
      "epoch": 1.3306403231612207,
      "grad_norm": 0.16363763809204102,
      "learning_rate": 2.783099361409964e-05,
      "loss": 0.0509,
      "step": 66540
    },
    {
      "epoch": 1.3308402991641004,
      "grad_norm": 0.23157545924186707,
      "learning_rate": 2.7827660680718315e-05,
      "loss": 0.082,
      "step": 66550
    },
    {
      "epoch": 1.33104027516698,
      "grad_norm": 0.08936445415019989,
      "learning_rate": 2.7824327747336988e-05,
      "loss": 0.0502,
      "step": 66560
    },
    {
      "epoch": 1.3312402511698596,
      "grad_norm": 0.13123749196529388,
      "learning_rate": 2.7820994813955657e-05,
      "loss": 0.0951,
      "step": 66570
    },
    {
      "epoch": 1.3314402271727392,
      "grad_norm": 0.1632862240076065,
      "learning_rate": 2.781766188057433e-05,
      "loss": 0.0854,
      "step": 66580
    },
    {
      "epoch": 1.331640203175619,
      "grad_norm": 0.08171742409467697,
      "learning_rate": 2.7814328947193003e-05,
      "loss": 0.0567,
      "step": 66590
    },
    {
      "epoch": 1.3318401791784986,
      "grad_norm": 0.0960666611790657,
      "learning_rate": 2.781099601381168e-05,
      "loss": 0.0828,
      "step": 66600
    },
    {
      "epoch": 1.3320401551813783,
      "grad_norm": 0.10256844758987427,
      "learning_rate": 2.7807663080430353e-05,
      "loss": 0.0862,
      "step": 66610
    },
    {
      "epoch": 1.3322401311842578,
      "grad_norm": 0.15734167397022247,
      "learning_rate": 2.7804330147049022e-05,
      "loss": 0.0635,
      "step": 66620
    },
    {
      "epoch": 1.3324401071871375,
      "grad_norm": 0.10004518926143646,
      "learning_rate": 2.7800997213667695e-05,
      "loss": 0.0503,
      "step": 66630
    },
    {
      "epoch": 1.3326400831900171,
      "grad_norm": 0.1239912137389183,
      "learning_rate": 2.7797664280286368e-05,
      "loss": 0.0551,
      "step": 66640
    },
    {
      "epoch": 1.3328400591928968,
      "grad_norm": 0.16431353986263275,
      "learning_rate": 2.7794331346905038e-05,
      "loss": 0.0688,
      "step": 66650
    },
    {
      "epoch": 1.3330400351957765,
      "grad_norm": 0.10398466140031815,
      "learning_rate": 2.779099841352371e-05,
      "loss": 0.0707,
      "step": 66660
    },
    {
      "epoch": 1.3332400111986562,
      "grad_norm": 0.11443459987640381,
      "learning_rate": 2.7787665480142384e-05,
      "loss": 0.0778,
      "step": 66670
    },
    {
      "epoch": 1.333439987201536,
      "grad_norm": 0.20667335391044617,
      "learning_rate": 2.7784332546761053e-05,
      "loss": 0.0903,
      "step": 66680
    },
    {
      "epoch": 1.3336399632044156,
      "grad_norm": 0.10019699484109879,
      "learning_rate": 2.7780999613379726e-05,
      "loss": 0.0491,
      "step": 66690
    },
    {
      "epoch": 1.333839939207295,
      "grad_norm": 0.09982109814882278,
      "learning_rate": 2.7777666679998403e-05,
      "loss": 0.1486,
      "step": 66700
    },
    {
      "epoch": 1.3340399152101747,
      "grad_norm": 0.08459854871034622,
      "learning_rate": 2.7774333746617076e-05,
      "loss": 0.0409,
      "step": 66710
    },
    {
      "epoch": 1.3342398912130544,
      "grad_norm": 0.13361968100070953,
      "learning_rate": 2.777100081323575e-05,
      "loss": 0.0626,
      "step": 66720
    },
    {
      "epoch": 1.334439867215934,
      "grad_norm": 0.13727812469005585,
      "learning_rate": 2.776766787985442e-05,
      "loss": 0.0743,
      "step": 66730
    },
    {
      "epoch": 1.3346398432188138,
      "grad_norm": 0.14450562000274658,
      "learning_rate": 2.776433494647309e-05,
      "loss": 0.0572,
      "step": 66740
    },
    {
      "epoch": 1.3348398192216935,
      "grad_norm": 0.05758679285645485,
      "learning_rate": 2.7761002013091764e-05,
      "loss": 0.0658,
      "step": 66750
    },
    {
      "epoch": 1.335039795224573,
      "grad_norm": 0.19942808151245117,
      "learning_rate": 2.7757669079710434e-05,
      "loss": 0.0803,
      "step": 66760
    },
    {
      "epoch": 1.3352397712274526,
      "grad_norm": 0.15041778981685638,
      "learning_rate": 2.7754336146329107e-05,
      "loss": 0.1041,
      "step": 66770
    },
    {
      "epoch": 1.3354397472303323,
      "grad_norm": 0.0840328186750412,
      "learning_rate": 2.775100321294778e-05,
      "loss": 0.0692,
      "step": 66780
    },
    {
      "epoch": 1.335639723233212,
      "grad_norm": 0.06072503700852394,
      "learning_rate": 2.774767027956645e-05,
      "loss": 0.1252,
      "step": 66790
    },
    {
      "epoch": 1.3358396992360917,
      "grad_norm": 0.09146127104759216,
      "learning_rate": 2.7744337346185123e-05,
      "loss": 0.0963,
      "step": 66800
    },
    {
      "epoch": 1.3360396752389714,
      "grad_norm": 0.06074650213122368,
      "learning_rate": 2.77410044128038e-05,
      "loss": 0.0932,
      "step": 66810
    },
    {
      "epoch": 1.336239651241851,
      "grad_norm": 0.1846659630537033,
      "learning_rate": 2.7737671479422472e-05,
      "loss": 0.0972,
      "step": 66820
    },
    {
      "epoch": 1.3364396272447308,
      "grad_norm": 0.1002117320895195,
      "learning_rate": 2.7734338546041145e-05,
      "loss": 0.0928,
      "step": 66830
    },
    {
      "epoch": 1.3366396032476102,
      "grad_norm": 0.06629036366939545,
      "learning_rate": 2.7731005612659815e-05,
      "loss": 0.0599,
      "step": 66840
    },
    {
      "epoch": 1.33683957925049,
      "grad_norm": 0.20915253460407257,
      "learning_rate": 2.7727672679278488e-05,
      "loss": 0.1051,
      "step": 66850
    },
    {
      "epoch": 1.3370395552533696,
      "grad_norm": 0.10961857438087463,
      "learning_rate": 2.772433974589716e-05,
      "loss": 0.0807,
      "step": 66860
    },
    {
      "epoch": 1.3372395312562493,
      "grad_norm": 0.21313080191612244,
      "learning_rate": 2.772100681251583e-05,
      "loss": 0.1814,
      "step": 66870
    },
    {
      "epoch": 1.337439507259129,
      "grad_norm": 0.14049777388572693,
      "learning_rate": 2.7717673879134503e-05,
      "loss": 0.0576,
      "step": 66880
    },
    {
      "epoch": 1.3376394832620084,
      "grad_norm": 0.20099198818206787,
      "learning_rate": 2.7714340945753176e-05,
      "loss": 0.1036,
      "step": 66890
    },
    {
      "epoch": 1.3378394592648881,
      "grad_norm": 0.08202038705348969,
      "learning_rate": 2.771134130570998e-05,
      "loss": 0.0577,
      "step": 66900
    },
    {
      "epoch": 1.3380394352677678,
      "grad_norm": 0.07848837226629257,
      "learning_rate": 2.7708008372328655e-05,
      "loss": 0.0588,
      "step": 66910
    },
    {
      "epoch": 1.3382394112706475,
      "grad_norm": 0.2132861465215683,
      "learning_rate": 2.7704675438947324e-05,
      "loss": 0.0952,
      "step": 66920
    },
    {
      "epoch": 1.3384393872735272,
      "grad_norm": 0.10108894109725952,
      "learning_rate": 2.7701342505566004e-05,
      "loss": 0.0431,
      "step": 66930
    },
    {
      "epoch": 1.3386393632764069,
      "grad_norm": 0.08608318865299225,
      "learning_rate": 2.7698009572184674e-05,
      "loss": 0.0465,
      "step": 66940
    },
    {
      "epoch": 1.3388393392792866,
      "grad_norm": 0.19853460788726807,
      "learning_rate": 2.7694676638803347e-05,
      "loss": 0.0917,
      "step": 66950
    },
    {
      "epoch": 1.3390393152821662,
      "grad_norm": 0.19355536997318268,
      "learning_rate": 2.769134370542202e-05,
      "loss": 0.0902,
      "step": 66960
    },
    {
      "epoch": 1.339239291285046,
      "grad_norm": 0.12901344895362854,
      "learning_rate": 2.768801077204069e-05,
      "loss": 0.056,
      "step": 66970
    },
    {
      "epoch": 1.3394392672879254,
      "grad_norm": 0.17988178133964539,
      "learning_rate": 2.7684677838659362e-05,
      "loss": 0.1045,
      "step": 66980
    },
    {
      "epoch": 1.339639243290805,
      "grad_norm": 0.1928747296333313,
      "learning_rate": 2.7681344905278035e-05,
      "loss": 0.1144,
      "step": 66990
    },
    {
      "epoch": 1.3398392192936848,
      "grad_norm": 0.11512614786624908,
      "learning_rate": 2.7678011971896705e-05,
      "loss": 0.0446,
      "step": 67000
    },
    {
      "epoch": 1.3400391952965645,
      "grad_norm": 0.09867428988218307,
      "learning_rate": 2.7674679038515378e-05,
      "loss": 0.0632,
      "step": 67010
    },
    {
      "epoch": 1.3402391712994441,
      "grad_norm": 0.12609820067882538,
      "learning_rate": 2.767134610513405e-05,
      "loss": 0.0635,
      "step": 67020
    },
    {
      "epoch": 1.3404391473023236,
      "grad_norm": 0.1203976646065712,
      "learning_rate": 2.7668013171752727e-05,
      "loss": 0.0903,
      "step": 67030
    },
    {
      "epoch": 1.3406391233052033,
      "grad_norm": 0.2728935778141022,
      "learning_rate": 2.76646802383714e-05,
      "loss": 0.064,
      "step": 67040
    },
    {
      "epoch": 1.340839099308083,
      "grad_norm": 0.14132186770439148,
      "learning_rate": 2.766134730499007e-05,
      "loss": 0.0848,
      "step": 67050
    },
    {
      "epoch": 1.3410390753109627,
      "grad_norm": 0.06439881026744843,
      "learning_rate": 2.7658014371608743e-05,
      "loss": 0.1246,
      "step": 67060
    },
    {
      "epoch": 1.3412390513138424,
      "grad_norm": 0.10840100049972534,
      "learning_rate": 2.7654681438227416e-05,
      "loss": 0.0793,
      "step": 67070
    },
    {
      "epoch": 1.341439027316722,
      "grad_norm": 0.3343179523944855,
      "learning_rate": 2.7651348504846086e-05,
      "loss": 0.1159,
      "step": 67080
    },
    {
      "epoch": 1.3416390033196017,
      "grad_norm": 0.2319631725549698,
      "learning_rate": 2.764801557146476e-05,
      "loss": 0.0755,
      "step": 67090
    },
    {
      "epoch": 1.3418389793224814,
      "grad_norm": 0.24225236475467682,
      "learning_rate": 2.764468263808343e-05,
      "loss": 0.0621,
      "step": 67100
    },
    {
      "epoch": 1.3420389553253609,
      "grad_norm": 0.16152963042259216,
      "learning_rate": 2.76413497047021e-05,
      "loss": 0.1057,
      "step": 67110
    },
    {
      "epoch": 1.3422389313282406,
      "grad_norm": 0.07041478157043457,
      "learning_rate": 2.7638016771320774e-05,
      "loss": 0.054,
      "step": 67120
    },
    {
      "epoch": 1.3424389073311203,
      "grad_norm": 0.16394208371639252,
      "learning_rate": 2.763468383793945e-05,
      "loss": 0.0568,
      "step": 67130
    },
    {
      "epoch": 1.342638883334,
      "grad_norm": 0.14947521686553955,
      "learning_rate": 2.7631350904558124e-05,
      "loss": 0.0585,
      "step": 67140
    },
    {
      "epoch": 1.3428388593368796,
      "grad_norm": 0.12381710112094879,
      "learning_rate": 2.7628017971176797e-05,
      "loss": 0.136,
      "step": 67150
    },
    {
      "epoch": 1.343038835339759,
      "grad_norm": 0.22575728595256805,
      "learning_rate": 2.7624685037795466e-05,
      "loss": 0.0739,
      "step": 67160
    },
    {
      "epoch": 1.3432388113426388,
      "grad_norm": 0.08197707682847977,
      "learning_rate": 2.762135210441414e-05,
      "loss": 0.1195,
      "step": 67170
    },
    {
      "epoch": 1.3434387873455185,
      "grad_norm": 0.0980520099401474,
      "learning_rate": 2.7618019171032812e-05,
      "loss": 0.0603,
      "step": 67180
    },
    {
      "epoch": 1.3436387633483982,
      "grad_norm": 0.13199563324451447,
      "learning_rate": 2.7614686237651482e-05,
      "loss": 0.0793,
      "step": 67190
    },
    {
      "epoch": 1.3438387393512778,
      "grad_norm": 0.18826739490032196,
      "learning_rate": 2.7611353304270155e-05,
      "loss": 0.0566,
      "step": 67200
    },
    {
      "epoch": 1.3440387153541575,
      "grad_norm": 0.064822256565094,
      "learning_rate": 2.7608020370888828e-05,
      "loss": 0.0909,
      "step": 67210
    },
    {
      "epoch": 1.3442386913570372,
      "grad_norm": 0.21412579715251923,
      "learning_rate": 2.7604687437507497e-05,
      "loss": 0.067,
      "step": 67220
    },
    {
      "epoch": 1.344438667359917,
      "grad_norm": 0.15450678765773773,
      "learning_rate": 2.760135450412617e-05,
      "loss": 0.0985,
      "step": 67230
    },
    {
      "epoch": 1.3446386433627966,
      "grad_norm": 0.16244721412658691,
      "learning_rate": 2.7598021570744847e-05,
      "loss": 0.094,
      "step": 67240
    },
    {
      "epoch": 1.344838619365676,
      "grad_norm": 0.11950331926345825,
      "learning_rate": 2.759468863736352e-05,
      "loss": 0.0699,
      "step": 67250
    },
    {
      "epoch": 1.3450385953685557,
      "grad_norm": 0.07319957762956619,
      "learning_rate": 2.7591355703982193e-05,
      "loss": 0.0645,
      "step": 67260
    },
    {
      "epoch": 1.3452385713714354,
      "grad_norm": 0.1496807336807251,
      "learning_rate": 2.7588022770600862e-05,
      "loss": 0.0814,
      "step": 67270
    },
    {
      "epoch": 1.3454385473743151,
      "grad_norm": 0.15180960297584534,
      "learning_rate": 2.7584689837219535e-05,
      "loss": 0.0595,
      "step": 67280
    },
    {
      "epoch": 1.3456385233771948,
      "grad_norm": 0.0770111009478569,
      "learning_rate": 2.758135690383821e-05,
      "loss": 0.0574,
      "step": 67290
    },
    {
      "epoch": 1.3458384993800743,
      "grad_norm": 0.16229188442230225,
      "learning_rate": 2.7578023970456878e-05,
      "loss": 0.0376,
      "step": 67300
    },
    {
      "epoch": 1.346038475382954,
      "grad_norm": 0.06820888817310333,
      "learning_rate": 2.757469103707555e-05,
      "loss": 0.0643,
      "step": 67310
    },
    {
      "epoch": 1.3462384513858336,
      "grad_norm": 0.08460849523544312,
      "learning_rate": 2.7571358103694224e-05,
      "loss": 0.0739,
      "step": 67320
    },
    {
      "epoch": 1.3464384273887133,
      "grad_norm": 0.2346913069486618,
      "learning_rate": 2.7568025170312894e-05,
      "loss": 0.1073,
      "step": 67330
    },
    {
      "epoch": 1.346638403391593,
      "grad_norm": 0.16786211729049683,
      "learning_rate": 2.7564692236931574e-05,
      "loss": 0.0643,
      "step": 67340
    },
    {
      "epoch": 1.3468383793944727,
      "grad_norm": 0.17320872843265533,
      "learning_rate": 2.7561359303550243e-05,
      "loss": 0.1748,
      "step": 67350
    },
    {
      "epoch": 1.3470383553973524,
      "grad_norm": 0.171097531914711,
      "learning_rate": 2.7558026370168916e-05,
      "loss": 0.0762,
      "step": 67360
    },
    {
      "epoch": 1.347238331400232,
      "grad_norm": 0.1694307029247284,
      "learning_rate": 2.755469343678759e-05,
      "loss": 0.0924,
      "step": 67370
    },
    {
      "epoch": 1.3474383074031115,
      "grad_norm": 0.10831159353256226,
      "learning_rate": 2.755136050340626e-05,
      "loss": 0.0762,
      "step": 67380
    },
    {
      "epoch": 1.3476382834059912,
      "grad_norm": 0.18574398756027222,
      "learning_rate": 2.7548027570024932e-05,
      "loss": 0.0549,
      "step": 67390
    },
    {
      "epoch": 1.347838259408871,
      "grad_norm": 0.06249405816197395,
      "learning_rate": 2.7544694636643605e-05,
      "loss": 0.0561,
      "step": 67400
    },
    {
      "epoch": 1.3480382354117506,
      "grad_norm": 0.12083487212657928,
      "learning_rate": 2.7541361703262274e-05,
      "loss": 0.0678,
      "step": 67410
    },
    {
      "epoch": 1.3482382114146303,
      "grad_norm": 0.09268920123577118,
      "learning_rate": 2.7538028769880947e-05,
      "loss": 0.0577,
      "step": 67420
    },
    {
      "epoch": 1.34843818741751,
      "grad_norm": 0.10246682167053223,
      "learning_rate": 2.753469583649962e-05,
      "loss": 0.0576,
      "step": 67430
    },
    {
      "epoch": 1.3486381634203894,
      "grad_norm": 0.10953622311353683,
      "learning_rate": 2.7531362903118297e-05,
      "loss": 0.06,
      "step": 67440
    },
    {
      "epoch": 1.3488381394232691,
      "grad_norm": 0.21066142618656158,
      "learning_rate": 2.752802996973697e-05,
      "loss": 0.0612,
      "step": 67450
    },
    {
      "epoch": 1.3490381154261488,
      "grad_norm": 0.10687209665775299,
      "learning_rate": 2.752469703635564e-05,
      "loss": 0.0976,
      "step": 67460
    },
    {
      "epoch": 1.3492380914290285,
      "grad_norm": 0.19152049720287323,
      "learning_rate": 2.7521364102974312e-05,
      "loss": 0.1027,
      "step": 67470
    },
    {
      "epoch": 1.3494380674319082,
      "grad_norm": 0.11651711165904999,
      "learning_rate": 2.7518031169592985e-05,
      "loss": 0.2129,
      "step": 67480
    },
    {
      "epoch": 1.3496380434347879,
      "grad_norm": 0.15833453834056854,
      "learning_rate": 2.7514698236211655e-05,
      "loss": 0.0499,
      "step": 67490
    },
    {
      "epoch": 1.3498380194376676,
      "grad_norm": 0.2029794603586197,
      "learning_rate": 2.7511365302830328e-05,
      "loss": 0.0646,
      "step": 67500
    },
    {
      "epoch": 1.3500379954405473,
      "grad_norm": 0.11965960264205933,
      "learning_rate": 2.7508032369449e-05,
      "loss": 0.065,
      "step": 67510
    },
    {
      "epoch": 1.3502379714434267,
      "grad_norm": 0.06571850180625916,
      "learning_rate": 2.750469943606767e-05,
      "loss": 0.102,
      "step": 67520
    },
    {
      "epoch": 1.3504379474463064,
      "grad_norm": 0.09187466651201248,
      "learning_rate": 2.7501366502686344e-05,
      "loss": 0.0427,
      "step": 67530
    },
    {
      "epoch": 1.350637923449186,
      "grad_norm": 0.08498220890760422,
      "learning_rate": 2.749803356930502e-05,
      "loss": 0.0807,
      "step": 67540
    },
    {
      "epoch": 1.3508378994520658,
      "grad_norm": 0.06512726098299026,
      "learning_rate": 2.7494700635923693e-05,
      "loss": 0.0698,
      "step": 67550
    },
    {
      "epoch": 1.3510378754549455,
      "grad_norm": 0.17143642902374268,
      "learning_rate": 2.7491367702542366e-05,
      "loss": 0.0617,
      "step": 67560
    },
    {
      "epoch": 1.351237851457825,
      "grad_norm": 0.08151250332593918,
      "learning_rate": 2.7488034769161036e-05,
      "loss": 0.089,
      "step": 67570
    },
    {
      "epoch": 1.3514378274607046,
      "grad_norm": 0.22354307770729065,
      "learning_rate": 2.748470183577971e-05,
      "loss": 0.0514,
      "step": 67580
    },
    {
      "epoch": 1.3516378034635843,
      "grad_norm": 0.07171373814344406,
      "learning_rate": 2.748136890239838e-05,
      "loss": 0.0682,
      "step": 67590
    },
    {
      "epoch": 1.351837779466464,
      "grad_norm": 0.08436642587184906,
      "learning_rate": 2.747803596901705e-05,
      "loss": 0.079,
      "step": 67600
    },
    {
      "epoch": 1.3520377554693437,
      "grad_norm": 0.10361439734697342,
      "learning_rate": 2.7474703035635724e-05,
      "loss": 0.0564,
      "step": 67610
    },
    {
      "epoch": 1.3522377314722234,
      "grad_norm": 0.1233089342713356,
      "learning_rate": 2.7471370102254397e-05,
      "loss": 0.0488,
      "step": 67620
    },
    {
      "epoch": 1.352437707475103,
      "grad_norm": 0.06512069702148438,
      "learning_rate": 2.7468037168873067e-05,
      "loss": 0.072,
      "step": 67630
    },
    {
      "epoch": 1.3526376834779827,
      "grad_norm": 0.11789949238300323,
      "learning_rate": 2.7464704235491743e-05,
      "loss": 0.0414,
      "step": 67640
    },
    {
      "epoch": 1.3528376594808624,
      "grad_norm": 0.12351715564727783,
      "learning_rate": 2.7461371302110416e-05,
      "loss": 0.069,
      "step": 67650
    },
    {
      "epoch": 1.353037635483742,
      "grad_norm": 0.12330495566129684,
      "learning_rate": 2.745803836872909e-05,
      "loss": 0.0582,
      "step": 67660
    },
    {
      "epoch": 1.3532376114866216,
      "grad_norm": 0.11458233743906021,
      "learning_rate": 2.745470543534776e-05,
      "loss": 0.0809,
      "step": 67670
    },
    {
      "epoch": 1.3534375874895013,
      "grad_norm": 0.16738271713256836,
      "learning_rate": 2.7451372501966432e-05,
      "loss": 0.0502,
      "step": 67680
    },
    {
      "epoch": 1.353637563492381,
      "grad_norm": 0.1179627776145935,
      "learning_rate": 2.7448039568585105e-05,
      "loss": 0.0742,
      "step": 67690
    },
    {
      "epoch": 1.3538375394952606,
      "grad_norm": 0.22424452006816864,
      "learning_rate": 2.7444706635203778e-05,
      "loss": 0.0707,
      "step": 67700
    },
    {
      "epoch": 1.35403751549814,
      "grad_norm": 0.12343201041221619,
      "learning_rate": 2.7441373701822448e-05,
      "loss": 0.0548,
      "step": 67710
    },
    {
      "epoch": 1.3542374915010198,
      "grad_norm": 0.14819039404392242,
      "learning_rate": 2.743804076844112e-05,
      "loss": 0.073,
      "step": 67720
    },
    {
      "epoch": 1.3544374675038995,
      "grad_norm": 0.05780543386936188,
      "learning_rate": 2.7434707835059794e-05,
      "loss": 0.067,
      "step": 67730
    },
    {
      "epoch": 1.3546374435067792,
      "grad_norm": 0.08707191050052643,
      "learning_rate": 2.7431374901678463e-05,
      "loss": 0.0772,
      "step": 67740
    },
    {
      "epoch": 1.3548374195096589,
      "grad_norm": 0.10990593582391739,
      "learning_rate": 2.742804196829714e-05,
      "loss": 0.1158,
      "step": 67750
    },
    {
      "epoch": 1.3550373955125385,
      "grad_norm": 0.17677612602710724,
      "learning_rate": 2.7424709034915813e-05,
      "loss": 0.0875,
      "step": 67760
    },
    {
      "epoch": 1.3552373715154182,
      "grad_norm": 0.1911379098892212,
      "learning_rate": 2.7421376101534486e-05,
      "loss": 0.0765,
      "step": 67770
    },
    {
      "epoch": 1.355437347518298,
      "grad_norm": 0.1138504147529602,
      "learning_rate": 2.7418043168153155e-05,
      "loss": 0.0618,
      "step": 67780
    },
    {
      "epoch": 1.3556373235211774,
      "grad_norm": 0.13508528470993042,
      "learning_rate": 2.7414710234771828e-05,
      "loss": 0.0931,
      "step": 67790
    },
    {
      "epoch": 1.355837299524057,
      "grad_norm": 0.13283942639827728,
      "learning_rate": 2.74113773013905e-05,
      "loss": 0.0714,
      "step": 67800
    },
    {
      "epoch": 1.3560372755269368,
      "grad_norm": 0.1848708987236023,
      "learning_rate": 2.740804436800917e-05,
      "loss": 0.0492,
      "step": 67810
    },
    {
      "epoch": 1.3562372515298164,
      "grad_norm": 0.22544817626476288,
      "learning_rate": 2.7404711434627844e-05,
      "loss": 0.0455,
      "step": 67820
    },
    {
      "epoch": 1.3564372275326961,
      "grad_norm": 0.20105016231536865,
      "learning_rate": 2.7401378501246517e-05,
      "loss": 0.095,
      "step": 67830
    },
    {
      "epoch": 1.3566372035355756,
      "grad_norm": 0.1881273239850998,
      "learning_rate": 2.739804556786519e-05,
      "loss": 0.0945,
      "step": 67840
    },
    {
      "epoch": 1.3568371795384553,
      "grad_norm": 0.08006229251623154,
      "learning_rate": 2.7394712634483866e-05,
      "loss": 0.0765,
      "step": 67850
    },
    {
      "epoch": 1.357037155541335,
      "grad_norm": 0.11416131258010864,
      "learning_rate": 2.7391379701102536e-05,
      "loss": 0.0681,
      "step": 67860
    },
    {
      "epoch": 1.3572371315442147,
      "grad_norm": 0.1194189265370369,
      "learning_rate": 2.738804676772121e-05,
      "loss": 0.2431,
      "step": 67870
    },
    {
      "epoch": 1.3574371075470943,
      "grad_norm": 0.05881257727742195,
      "learning_rate": 2.7384713834339882e-05,
      "loss": 0.0663,
      "step": 67880
    },
    {
      "epoch": 1.357637083549974,
      "grad_norm": 0.09808509796857834,
      "learning_rate": 2.738138090095855e-05,
      "loss": 0.091,
      "step": 67890
    },
    {
      "epoch": 1.3578370595528537,
      "grad_norm": 0.2314147800207138,
      "learning_rate": 2.7378047967577224e-05,
      "loss": 0.1238,
      "step": 67900
    },
    {
      "epoch": 1.3580370355557334,
      "grad_norm": 0.10268490016460419,
      "learning_rate": 2.7374715034195897e-05,
      "loss": 0.0916,
      "step": 67910
    },
    {
      "epoch": 1.358237011558613,
      "grad_norm": 0.1544378250837326,
      "learning_rate": 2.7371382100814567e-05,
      "loss": 0.0527,
      "step": 67920
    },
    {
      "epoch": 1.3584369875614926,
      "grad_norm": 0.14546003937721252,
      "learning_rate": 2.736804916743324e-05,
      "loss": 0.0906,
      "step": 67930
    },
    {
      "epoch": 1.3586369635643722,
      "grad_norm": 0.06274596601724625,
      "learning_rate": 2.7364716234051913e-05,
      "loss": 0.092,
      "step": 67940
    },
    {
      "epoch": 1.358836939567252,
      "grad_norm": 0.050465770065784454,
      "learning_rate": 2.736138330067059e-05,
      "loss": 0.0499,
      "step": 67950
    },
    {
      "epoch": 1.3590369155701316,
      "grad_norm": 0.12628085911273956,
      "learning_rate": 2.7358050367289263e-05,
      "loss": 0.0719,
      "step": 67960
    },
    {
      "epoch": 1.3592368915730113,
      "grad_norm": 0.11782681941986084,
      "learning_rate": 2.7354717433907932e-05,
      "loss": 0.0664,
      "step": 67970
    },
    {
      "epoch": 1.3594368675758908,
      "grad_norm": 0.13435816764831543,
      "learning_rate": 2.7351384500526605e-05,
      "loss": 0.1089,
      "step": 67980
    },
    {
      "epoch": 1.3596368435787705,
      "grad_norm": 0.12532487511634827,
      "learning_rate": 2.7348051567145278e-05,
      "loss": 0.0502,
      "step": 67990
    },
    {
      "epoch": 1.3598368195816501,
      "grad_norm": 0.16940991580486298,
      "learning_rate": 2.7344718633763948e-05,
      "loss": 0.0948,
      "step": 68000
    },
    {
      "epoch": 1.3600367955845298,
      "grad_norm": 0.08761019259691238,
      "learning_rate": 2.734138570038262e-05,
      "loss": 0.0659,
      "step": 68010
    },
    {
      "epoch": 1.3602367715874095,
      "grad_norm": 0.10816098749637604,
      "learning_rate": 2.7338052767001294e-05,
      "loss": 0.0982,
      "step": 68020
    },
    {
      "epoch": 1.3604367475902892,
      "grad_norm": 0.10870424658060074,
      "learning_rate": 2.7334719833619963e-05,
      "loss": 0.0373,
      "step": 68030
    },
    {
      "epoch": 1.360636723593169,
      "grad_norm": 0.11425649374723434,
      "learning_rate": 2.7331386900238636e-05,
      "loss": 0.4321,
      "step": 68040
    },
    {
      "epoch": 1.3608366995960486,
      "grad_norm": 0.05573635175824165,
      "learning_rate": 2.7328053966857313e-05,
      "loss": 0.0907,
      "step": 68050
    },
    {
      "epoch": 1.361036675598928,
      "grad_norm": 0.07728251814842224,
      "learning_rate": 2.7324721033475986e-05,
      "loss": 0.0868,
      "step": 68060
    },
    {
      "epoch": 1.3612366516018077,
      "grad_norm": 0.09254998713731766,
      "learning_rate": 2.732138810009466e-05,
      "loss": 0.072,
      "step": 68070
    },
    {
      "epoch": 1.3614366276046874,
      "grad_norm": 0.08715114742517471,
      "learning_rate": 2.731805516671333e-05,
      "loss": 0.11,
      "step": 68080
    },
    {
      "epoch": 1.361636603607567,
      "grad_norm": 0.09571213275194168,
      "learning_rate": 2.7314722233332e-05,
      "loss": 0.0704,
      "step": 68090
    },
    {
      "epoch": 1.3618365796104468,
      "grad_norm": 0.08334817737340927,
      "learning_rate": 2.7311389299950674e-05,
      "loss": 0.1154,
      "step": 68100
    },
    {
      "epoch": 1.3620365556133265,
      "grad_norm": 0.16650189459323883,
      "learning_rate": 2.7308056366569344e-05,
      "loss": 0.0628,
      "step": 68110
    },
    {
      "epoch": 1.362236531616206,
      "grad_norm": 0.05137639120221138,
      "learning_rate": 2.7304723433188017e-05,
      "loss": 0.0723,
      "step": 68120
    },
    {
      "epoch": 1.3624365076190856,
      "grad_norm": 0.23646041750907898,
      "learning_rate": 2.730139049980669e-05,
      "loss": 0.068,
      "step": 68130
    },
    {
      "epoch": 1.3626364836219653,
      "grad_norm": 0.07386890053749084,
      "learning_rate": 2.729805756642536e-05,
      "loss": 0.0734,
      "step": 68140
    },
    {
      "epoch": 1.362836459624845,
      "grad_norm": 0.09865794330835342,
      "learning_rate": 2.729472463304404e-05,
      "loss": 0.0613,
      "step": 68150
    },
    {
      "epoch": 1.3630364356277247,
      "grad_norm": 0.10841096192598343,
      "learning_rate": 2.729139169966271e-05,
      "loss": 0.0685,
      "step": 68160
    },
    {
      "epoch": 1.3632364116306044,
      "grad_norm": 0.12191644310951233,
      "learning_rate": 2.7288058766281382e-05,
      "loss": 0.0769,
      "step": 68170
    },
    {
      "epoch": 1.363436387633484,
      "grad_norm": 0.2096182256937027,
      "learning_rate": 2.7284725832900055e-05,
      "loss": 0.0838,
      "step": 68180
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.15427349507808685,
      "learning_rate": 2.7281392899518725e-05,
      "loss": 0.0505,
      "step": 68190
    },
    {
      "epoch": 1.3638363396392432,
      "grad_norm": 0.08299365639686584,
      "learning_rate": 2.7278059966137398e-05,
      "loss": 0.0676,
      "step": 68200
    },
    {
      "epoch": 1.364036315642123,
      "grad_norm": 0.058130763471126556,
      "learning_rate": 2.727472703275607e-05,
      "loss": 0.0783,
      "step": 68210
    },
    {
      "epoch": 1.3642362916450026,
      "grad_norm": 0.10168356448411942,
      "learning_rate": 2.727139409937474e-05,
      "loss": 0.0762,
      "step": 68220
    },
    {
      "epoch": 1.3644362676478823,
      "grad_norm": 0.1085939034819603,
      "learning_rate": 2.7268061165993413e-05,
      "loss": 0.0899,
      "step": 68230
    },
    {
      "epoch": 1.364636243650762,
      "grad_norm": 0.1359129250049591,
      "learning_rate": 2.7264728232612086e-05,
      "loss": 0.077,
      "step": 68240
    },
    {
      "epoch": 1.3648362196536414,
      "grad_norm": 0.059051912277936935,
      "learning_rate": 2.7261395299230756e-05,
      "loss": 0.0732,
      "step": 68250
    },
    {
      "epoch": 1.3650361956565211,
      "grad_norm": 0.11523216217756271,
      "learning_rate": 2.7258062365849436e-05,
      "loss": 0.0897,
      "step": 68260
    },
    {
      "epoch": 1.3652361716594008,
      "grad_norm": 0.08712612837553024,
      "learning_rate": 2.7254729432468105e-05,
      "loss": 0.0723,
      "step": 68270
    },
    {
      "epoch": 1.3654361476622805,
      "grad_norm": 0.16139532625675201,
      "learning_rate": 2.7251396499086778e-05,
      "loss": 0.0913,
      "step": 68280
    },
    {
      "epoch": 1.3656361236651602,
      "grad_norm": 0.07053075730800629,
      "learning_rate": 2.724806356570545e-05,
      "loss": 0.1518,
      "step": 68290
    },
    {
      "epoch": 1.3658360996680399,
      "grad_norm": 0.12248526513576508,
      "learning_rate": 2.724473063232412e-05,
      "loss": 0.0598,
      "step": 68300
    },
    {
      "epoch": 1.3660360756709196,
      "grad_norm": 0.18330466747283936,
      "learning_rate": 2.7241397698942794e-05,
      "loss": 0.062,
      "step": 68310
    },
    {
      "epoch": 1.3662360516737992,
      "grad_norm": 0.11222861707210541,
      "learning_rate": 2.7238064765561467e-05,
      "loss": 0.0615,
      "step": 68320
    },
    {
      "epoch": 1.366436027676679,
      "grad_norm": 0.18759560585021973,
      "learning_rate": 2.7234731832180137e-05,
      "loss": 0.0849,
      "step": 68330
    },
    {
      "epoch": 1.3666360036795584,
      "grad_norm": 0.10501255840063095,
      "learning_rate": 2.723139889879881e-05,
      "loss": 0.041,
      "step": 68340
    },
    {
      "epoch": 1.366835979682438,
      "grad_norm": 0.1757512092590332,
      "learning_rate": 2.7228065965417483e-05,
      "loss": 0.1279,
      "step": 68350
    },
    {
      "epoch": 1.3670359556853178,
      "grad_norm": 0.10891726613044739,
      "learning_rate": 2.722473303203616e-05,
      "loss": 0.0913,
      "step": 68360
    },
    {
      "epoch": 1.3672359316881975,
      "grad_norm": 0.18595173954963684,
      "learning_rate": 2.7221400098654832e-05,
      "loss": 0.1222,
      "step": 68370
    },
    {
      "epoch": 1.3674359076910771,
      "grad_norm": 0.09251629561185837,
      "learning_rate": 2.72180671652735e-05,
      "loss": 0.0606,
      "step": 68380
    },
    {
      "epoch": 1.3676358836939566,
      "grad_norm": 0.07385749369859695,
      "learning_rate": 2.7214734231892175e-05,
      "loss": 0.0965,
      "step": 68390
    },
    {
      "epoch": 1.3678358596968363,
      "grad_norm": 0.08083190023899078,
      "learning_rate": 2.7211401298510848e-05,
      "loss": 0.0895,
      "step": 68400
    },
    {
      "epoch": 1.368035835699716,
      "grad_norm": 0.13625399768352509,
      "learning_rate": 2.7208068365129517e-05,
      "loss": 0.0631,
      "step": 68410
    },
    {
      "epoch": 1.3682358117025957,
      "grad_norm": 0.13971851766109467,
      "learning_rate": 2.720473543174819e-05,
      "loss": 0.0638,
      "step": 68420
    },
    {
      "epoch": 1.3684357877054754,
      "grad_norm": 0.0927373543381691,
      "learning_rate": 2.7201402498366863e-05,
      "loss": 0.0972,
      "step": 68430
    },
    {
      "epoch": 1.368635763708355,
      "grad_norm": 0.11843504756689072,
      "learning_rate": 2.7198069564985533e-05,
      "loss": 0.06,
      "step": 68440
    },
    {
      "epoch": 1.3688357397112347,
      "grad_norm": 0.1167190819978714,
      "learning_rate": 2.7194736631604206e-05,
      "loss": 0.2066,
      "step": 68450
    },
    {
      "epoch": 1.3690357157141144,
      "grad_norm": 0.0852079838514328,
      "learning_rate": 2.7191403698222882e-05,
      "loss": 0.0569,
      "step": 68460
    },
    {
      "epoch": 1.3692356917169939,
      "grad_norm": 0.15476958453655243,
      "learning_rate": 2.7188070764841555e-05,
      "loss": 0.0856,
      "step": 68470
    },
    {
      "epoch": 1.3694356677198736,
      "grad_norm": 0.16256065666675568,
      "learning_rate": 2.7184737831460228e-05,
      "loss": 0.0751,
      "step": 68480
    },
    {
      "epoch": 1.3696356437227533,
      "grad_norm": 0.20343619585037231,
      "learning_rate": 2.7181404898078898e-05,
      "loss": 0.0806,
      "step": 68490
    },
    {
      "epoch": 1.369835619725633,
      "grad_norm": 0.10057749599218369,
      "learning_rate": 2.717807196469757e-05,
      "loss": 0.0389,
      "step": 68500
    },
    {
      "epoch": 1.3700355957285126,
      "grad_norm": 0.09205053746700287,
      "learning_rate": 2.7174739031316244e-05,
      "loss": 0.0532,
      "step": 68510
    },
    {
      "epoch": 1.370235571731392,
      "grad_norm": 0.07706433534622192,
      "learning_rate": 2.7171406097934913e-05,
      "loss": 0.0421,
      "step": 68520
    },
    {
      "epoch": 1.3704355477342718,
      "grad_norm": 0.18603114783763885,
      "learning_rate": 2.7168073164553586e-05,
      "loss": 0.0876,
      "step": 68530
    },
    {
      "epoch": 1.3706355237371515,
      "grad_norm": 0.11645609140396118,
      "learning_rate": 2.716474023117226e-05,
      "loss": 0.0881,
      "step": 68540
    },
    {
      "epoch": 1.3708354997400312,
      "grad_norm": 0.15574608743190765,
      "learning_rate": 2.716140729779093e-05,
      "loss": 0.0718,
      "step": 68550
    },
    {
      "epoch": 1.3710354757429108,
      "grad_norm": 0.12986847758293152,
      "learning_rate": 2.715807436440961e-05,
      "loss": 0.0845,
      "step": 68560
    },
    {
      "epoch": 1.3712354517457905,
      "grad_norm": 0.1979326605796814,
      "learning_rate": 2.715474143102828e-05,
      "loss": 0.0849,
      "step": 68570
    },
    {
      "epoch": 1.3714354277486702,
      "grad_norm": 0.07721662521362305,
      "learning_rate": 2.715140849764695e-05,
      "loss": 0.0567,
      "step": 68580
    },
    {
      "epoch": 1.37163540375155,
      "grad_norm": 0.20768463611602783,
      "learning_rate": 2.7148075564265624e-05,
      "loss": 0.094,
      "step": 68590
    },
    {
      "epoch": 1.3718353797544296,
      "grad_norm": 0.08331555128097534,
      "learning_rate": 2.7144742630884294e-05,
      "loss": 0.0635,
      "step": 68600
    },
    {
      "epoch": 1.372035355757309,
      "grad_norm": 0.07401224970817566,
      "learning_rate": 2.7141409697502967e-05,
      "loss": 0.0807,
      "step": 68610
    },
    {
      "epoch": 1.3722353317601887,
      "grad_norm": 0.1379241794347763,
      "learning_rate": 2.713807676412164e-05,
      "loss": 0.0798,
      "step": 68620
    },
    {
      "epoch": 1.3724353077630684,
      "grad_norm": 0.15871381759643555,
      "learning_rate": 2.713474383074031e-05,
      "loss": 0.0772,
      "step": 68630
    },
    {
      "epoch": 1.3726352837659481,
      "grad_norm": 0.24944771826267242,
      "learning_rate": 2.7131410897358983e-05,
      "loss": 0.1682,
      "step": 68640
    },
    {
      "epoch": 1.3728352597688278,
      "grad_norm": 0.12029462307691574,
      "learning_rate": 2.7128077963977656e-05,
      "loss": 0.07,
      "step": 68650
    },
    {
      "epoch": 1.3730352357717073,
      "grad_norm": 0.14305125176906586,
      "learning_rate": 2.7124745030596332e-05,
      "loss": 0.1231,
      "step": 68660
    },
    {
      "epoch": 1.373235211774587,
      "grad_norm": 0.24640516936779022,
      "learning_rate": 2.7121412097215005e-05,
      "loss": 0.0636,
      "step": 68670
    },
    {
      "epoch": 1.3734351877774666,
      "grad_norm": 0.11102814972400665,
      "learning_rate": 2.7118079163833675e-05,
      "loss": 0.0541,
      "step": 68680
    },
    {
      "epoch": 1.3736351637803463,
      "grad_norm": 0.09352584928274155,
      "learning_rate": 2.7114746230452348e-05,
      "loss": 0.0666,
      "step": 68690
    },
    {
      "epoch": 1.373835139783226,
      "grad_norm": 0.1396072953939438,
      "learning_rate": 2.711141329707102e-05,
      "loss": 0.0836,
      "step": 68700
    },
    {
      "epoch": 1.3740351157861057,
      "grad_norm": 0.0639597699046135,
      "learning_rate": 2.710808036368969e-05,
      "loss": 0.0762,
      "step": 68710
    },
    {
      "epoch": 1.3742350917889854,
      "grad_norm": 0.15858426690101624,
      "learning_rate": 2.7104747430308363e-05,
      "loss": 0.0753,
      "step": 68720
    },
    {
      "epoch": 1.374435067791865,
      "grad_norm": 0.16274811327457428,
      "learning_rate": 2.7101414496927036e-05,
      "loss": 0.0524,
      "step": 68730
    },
    {
      "epoch": 1.3746350437947445,
      "grad_norm": 0.10420647263526917,
      "learning_rate": 2.7098081563545706e-05,
      "loss": 0.0886,
      "step": 68740
    },
    {
      "epoch": 1.3748350197976242,
      "grad_norm": 0.09978199750185013,
      "learning_rate": 2.709474863016438e-05,
      "loss": 0.069,
      "step": 68750
    },
    {
      "epoch": 1.375034995800504,
      "grad_norm": 0.1870468407869339,
      "learning_rate": 2.7091415696783052e-05,
      "loss": 0.0758,
      "step": 68760
    },
    {
      "epoch": 1.3752349718033836,
      "grad_norm": 0.11983844637870789,
      "learning_rate": 2.708808276340173e-05,
      "loss": 0.1351,
      "step": 68770
    },
    {
      "epoch": 1.3754349478062633,
      "grad_norm": 0.08012451976537704,
      "learning_rate": 2.70847498300204e-05,
      "loss": 0.0819,
      "step": 68780
    },
    {
      "epoch": 1.375634923809143,
      "grad_norm": 0.06797671318054199,
      "learning_rate": 2.708141689663907e-05,
      "loss": 0.0384,
      "step": 68790
    },
    {
      "epoch": 1.3758348998120224,
      "grad_norm": 0.16678902506828308,
      "learning_rate": 2.7078083963257744e-05,
      "loss": 0.0706,
      "step": 68800
    },
    {
      "epoch": 1.3760348758149021,
      "grad_norm": 0.11417358368635178,
      "learning_rate": 2.7074751029876417e-05,
      "loss": 0.0644,
      "step": 68810
    },
    {
      "epoch": 1.3762348518177818,
      "grad_norm": 0.07195550203323364,
      "learning_rate": 2.7071418096495087e-05,
      "loss": 0.045,
      "step": 68820
    },
    {
      "epoch": 1.3764348278206615,
      "grad_norm": 0.10705378651618958,
      "learning_rate": 2.706808516311376e-05,
      "loss": 0.0859,
      "step": 68830
    },
    {
      "epoch": 1.3766348038235412,
      "grad_norm": 0.19122420251369476,
      "learning_rate": 2.7064752229732433e-05,
      "loss": 0.0852,
      "step": 68840
    },
    {
      "epoch": 1.3768347798264209,
      "grad_norm": 0.18851403892040253,
      "learning_rate": 2.7061419296351102e-05,
      "loss": 0.0518,
      "step": 68850
    },
    {
      "epoch": 1.3770347558293006,
      "grad_norm": 0.2096775770187378,
      "learning_rate": 2.7058086362969775e-05,
      "loss": 0.1047,
      "step": 68860
    },
    {
      "epoch": 1.3772347318321803,
      "grad_norm": 0.1054283082485199,
      "learning_rate": 2.705475342958845e-05,
      "loss": 0.0749,
      "step": 68870
    },
    {
      "epoch": 1.3774347078350597,
      "grad_norm": 0.0957847535610199,
      "learning_rate": 2.7051420496207125e-05,
      "loss": 0.0654,
      "step": 68880
    },
    {
      "epoch": 1.3776346838379394,
      "grad_norm": 0.23764441907405853,
      "learning_rate": 2.7048087562825798e-05,
      "loss": 0.0785,
      "step": 68890
    },
    {
      "epoch": 1.377834659840819,
      "grad_norm": 0.1962459832429886,
      "learning_rate": 2.7044754629444467e-05,
      "loss": 0.0889,
      "step": 68900
    },
    {
      "epoch": 1.3780346358436988,
      "grad_norm": 0.1476094275712967,
      "learning_rate": 2.704142169606314e-05,
      "loss": 0.0706,
      "step": 68910
    },
    {
      "epoch": 1.3782346118465785,
      "grad_norm": 0.07735440880060196,
      "learning_rate": 2.7038088762681813e-05,
      "loss": 0.0897,
      "step": 68920
    },
    {
      "epoch": 1.378434587849458,
      "grad_norm": 0.0872412845492363,
      "learning_rate": 2.7034755829300483e-05,
      "loss": 0.0648,
      "step": 68930
    },
    {
      "epoch": 1.3786345638523376,
      "grad_norm": 0.09590432047843933,
      "learning_rate": 2.7031422895919156e-05,
      "loss": 0.1051,
      "step": 68940
    },
    {
      "epoch": 1.3788345398552173,
      "grad_norm": 0.046767350286245346,
      "learning_rate": 2.702808996253783e-05,
      "loss": 0.0523,
      "step": 68950
    },
    {
      "epoch": 1.379034515858097,
      "grad_norm": 0.2600468099117279,
      "learning_rate": 2.70247570291565e-05,
      "loss": 0.096,
      "step": 68960
    },
    {
      "epoch": 1.3792344918609767,
      "grad_norm": 0.2022976279258728,
      "learning_rate": 2.702142409577518e-05,
      "loss": 0.0579,
      "step": 68970
    },
    {
      "epoch": 1.3794344678638564,
      "grad_norm": 0.19453178346157074,
      "learning_rate": 2.7018091162393848e-05,
      "loss": 0.0706,
      "step": 68980
    },
    {
      "epoch": 1.379634443866736,
      "grad_norm": 0.06220678612589836,
      "learning_rate": 2.701475822901252e-05,
      "loss": 0.0678,
      "step": 68990
    },
    {
      "epoch": 1.3798344198696157,
      "grad_norm": 0.1900530904531479,
      "learning_rate": 2.7011425295631194e-05,
      "loss": 0.0917,
      "step": 69000
    },
    {
      "epoch": 1.3800343958724954,
      "grad_norm": 0.10216068476438522,
      "learning_rate": 2.7008092362249864e-05,
      "loss": 0.0697,
      "step": 69010
    },
    {
      "epoch": 1.380234371875375,
      "grad_norm": 0.14785006642341614,
      "learning_rate": 2.7004759428868537e-05,
      "loss": 0.0703,
      "step": 69020
    },
    {
      "epoch": 1.3804343478782546,
      "grad_norm": 0.21783874928951263,
      "learning_rate": 2.700142649548721e-05,
      "loss": 0.0664,
      "step": 69030
    },
    {
      "epoch": 1.3806343238811343,
      "grad_norm": 0.08574037253856659,
      "learning_rate": 2.699809356210588e-05,
      "loss": 0.0485,
      "step": 69040
    },
    {
      "epoch": 1.380834299884014,
      "grad_norm": 0.06271883100271225,
      "learning_rate": 2.6994760628724552e-05,
      "loss": 0.056,
      "step": 69050
    },
    {
      "epoch": 1.3810342758868936,
      "grad_norm": 0.11642066389322281,
      "learning_rate": 2.6991427695343225e-05,
      "loss": 0.08,
      "step": 69060
    },
    {
      "epoch": 1.3812342518897731,
      "grad_norm": 0.10497935861349106,
      "learning_rate": 2.69880947619619e-05,
      "loss": 0.0713,
      "step": 69070
    },
    {
      "epoch": 1.3814342278926528,
      "grad_norm": 0.1594589799642563,
      "learning_rate": 2.6984761828580575e-05,
      "loss": 0.076,
      "step": 69080
    },
    {
      "epoch": 1.3816342038955325,
      "grad_norm": 0.10065170377492905,
      "learning_rate": 2.6981428895199244e-05,
      "loss": 0.0499,
      "step": 69090
    },
    {
      "epoch": 1.3818341798984122,
      "grad_norm": 0.16162197291851044,
      "learning_rate": 2.6978095961817917e-05,
      "loss": 0.0645,
      "step": 69100
    },
    {
      "epoch": 1.3820341559012919,
      "grad_norm": 0.0950154960155487,
      "learning_rate": 2.697476302843659e-05,
      "loss": 0.0862,
      "step": 69110
    },
    {
      "epoch": 1.3822341319041715,
      "grad_norm": 0.06429746747016907,
      "learning_rate": 2.697143009505526e-05,
      "loss": 0.0855,
      "step": 69120
    },
    {
      "epoch": 1.3824341079070512,
      "grad_norm": 0.13209570944309235,
      "learning_rate": 2.6968097161673933e-05,
      "loss": 0.0785,
      "step": 69130
    },
    {
      "epoch": 1.382634083909931,
      "grad_norm": 0.26292139291763306,
      "learning_rate": 2.6964764228292606e-05,
      "loss": 0.0964,
      "step": 69140
    },
    {
      "epoch": 1.3828340599128104,
      "grad_norm": 0.20920048654079437,
      "learning_rate": 2.6961431294911275e-05,
      "loss": 0.0908,
      "step": 69150
    },
    {
      "epoch": 1.38303403591569,
      "grad_norm": 0.16204875707626343,
      "learning_rate": 2.695809836152995e-05,
      "loss": 0.0809,
      "step": 69160
    },
    {
      "epoch": 1.3832340119185698,
      "grad_norm": 0.0954330638051033,
      "learning_rate": 2.6954765428148625e-05,
      "loss": 0.0691,
      "step": 69170
    },
    {
      "epoch": 1.3834339879214494,
      "grad_norm": 0.06545420736074448,
      "learning_rate": 2.6951432494767298e-05,
      "loss": 0.0655,
      "step": 69180
    },
    {
      "epoch": 1.3836339639243291,
      "grad_norm": 0.09477978944778442,
      "learning_rate": 2.694809956138597e-05,
      "loss": 0.0596,
      "step": 69190
    },
    {
      "epoch": 1.3838339399272086,
      "grad_norm": 0.15302467346191406,
      "learning_rate": 2.694476662800464e-05,
      "loss": 0.0636,
      "step": 69200
    },
    {
      "epoch": 1.3840339159300883,
      "grad_norm": 0.1533372402191162,
      "learning_rate": 2.6941433694623313e-05,
      "loss": 0.0842,
      "step": 69210
    },
    {
      "epoch": 1.384233891932968,
      "grad_norm": 0.12242761254310608,
      "learning_rate": 2.6938100761241986e-05,
      "loss": 0.112,
      "step": 69220
    },
    {
      "epoch": 1.3844338679358477,
      "grad_norm": 0.05244055390357971,
      "learning_rate": 2.6934767827860656e-05,
      "loss": 0.0428,
      "step": 69230
    },
    {
      "epoch": 1.3846338439387273,
      "grad_norm": 0.10807700455188751,
      "learning_rate": 2.693143489447933e-05,
      "loss": 0.0605,
      "step": 69240
    },
    {
      "epoch": 1.384833819941607,
      "grad_norm": 0.177625373005867,
      "learning_rate": 2.6928101961098002e-05,
      "loss": 0.0413,
      "step": 69250
    },
    {
      "epoch": 1.3850337959444867,
      "grad_norm": 0.13517287373542786,
      "learning_rate": 2.6924769027716672e-05,
      "loss": 0.0864,
      "step": 69260
    },
    {
      "epoch": 1.3852337719473664,
      "grad_norm": 0.1099456250667572,
      "learning_rate": 2.6921436094335345e-05,
      "loss": 0.0538,
      "step": 69270
    },
    {
      "epoch": 1.385433747950246,
      "grad_norm": 0.09202456474304199,
      "learning_rate": 2.691810316095402e-05,
      "loss": 0.1019,
      "step": 69280
    },
    {
      "epoch": 1.3856337239531256,
      "grad_norm": 0.04398258775472641,
      "learning_rate": 2.6914770227572694e-05,
      "loss": 0.0713,
      "step": 69290
    },
    {
      "epoch": 1.3858336999560052,
      "grad_norm": 0.09702357649803162,
      "learning_rate": 2.69117705875295e-05,
      "loss": 0.0701,
      "step": 69300
    },
    {
      "epoch": 1.386033675958885,
      "grad_norm": 0.14752143621444702,
      "learning_rate": 2.6908437654148172e-05,
      "loss": 0.0645,
      "step": 69310
    },
    {
      "epoch": 1.3862336519617646,
      "grad_norm": 0.1349351704120636,
      "learning_rate": 2.6905104720766845e-05,
      "loss": 0.087,
      "step": 69320
    },
    {
      "epoch": 1.3864336279646443,
      "grad_norm": 0.23733031749725342,
      "learning_rate": 2.6901771787385515e-05,
      "loss": 0.0936,
      "step": 69330
    },
    {
      "epoch": 1.3866336039675238,
      "grad_norm": 0.15942241251468658,
      "learning_rate": 2.6898438854004188e-05,
      "loss": 0.1092,
      "step": 69340
    },
    {
      "epoch": 1.3868335799704035,
      "grad_norm": 0.19931067526340485,
      "learning_rate": 2.689510592062286e-05,
      "loss": 0.0839,
      "step": 69350
    },
    {
      "epoch": 1.3870335559732831,
      "grad_norm": 0.15757907927036285,
      "learning_rate": 2.689177298724153e-05,
      "loss": 0.0565,
      "step": 69360
    },
    {
      "epoch": 1.3872335319761628,
      "grad_norm": 0.17128892242908478,
      "learning_rate": 2.6888440053860204e-05,
      "loss": 0.0475,
      "step": 69370
    },
    {
      "epoch": 1.3874335079790425,
      "grad_norm": 0.09897349029779434,
      "learning_rate": 2.6885107120478877e-05,
      "loss": 0.0763,
      "step": 69380
    },
    {
      "epoch": 1.3876334839819222,
      "grad_norm": 0.1630783975124359,
      "learning_rate": 2.6881774187097546e-05,
      "loss": 0.0776,
      "step": 69390
    },
    {
      "epoch": 1.387833459984802,
      "grad_norm": 0.17253099381923676,
      "learning_rate": 2.6878441253716226e-05,
      "loss": 0.0794,
      "step": 69400
    },
    {
      "epoch": 1.3880334359876816,
      "grad_norm": 0.11433432996273041,
      "learning_rate": 2.6875108320334896e-05,
      "loss": 0.0574,
      "step": 69410
    },
    {
      "epoch": 1.388233411990561,
      "grad_norm": 0.06365078687667847,
      "learning_rate": 2.687177538695357e-05,
      "loss": 0.0671,
      "step": 69420
    },
    {
      "epoch": 1.3884333879934407,
      "grad_norm": 0.13604411482810974,
      "learning_rate": 2.6868442453572242e-05,
      "loss": 0.0842,
      "step": 69430
    },
    {
      "epoch": 1.3886333639963204,
      "grad_norm": 0.19724315404891968,
      "learning_rate": 2.686510952019091e-05,
      "loss": 0.1041,
      "step": 69440
    },
    {
      "epoch": 1.3888333399992001,
      "grad_norm": 0.13586603105068207,
      "learning_rate": 2.6861776586809584e-05,
      "loss": 0.0657,
      "step": 69450
    },
    {
      "epoch": 1.3890333160020798,
      "grad_norm": 0.10150785744190216,
      "learning_rate": 2.6858443653428257e-05,
      "loss": 0.0487,
      "step": 69460
    },
    {
      "epoch": 1.3892332920049595,
      "grad_norm": 0.2554566562175751,
      "learning_rate": 2.6855110720046927e-05,
      "loss": 0.0934,
      "step": 69470
    },
    {
      "epoch": 1.389433268007839,
      "grad_norm": 0.18054527044296265,
      "learning_rate": 2.68517777866656e-05,
      "loss": 0.1195,
      "step": 69480
    },
    {
      "epoch": 1.3896332440107186,
      "grad_norm": 0.14490272104740143,
      "learning_rate": 2.6848444853284273e-05,
      "loss": 0.0612,
      "step": 69490
    },
    {
      "epoch": 1.3898332200135983,
      "grad_norm": 0.07113505154848099,
      "learning_rate": 2.684511191990295e-05,
      "loss": 0.0668,
      "step": 69500
    },
    {
      "epoch": 1.390033196016478,
      "grad_norm": 0.09917324781417847,
      "learning_rate": 2.6841778986521622e-05,
      "loss": 0.0605,
      "step": 69510
    },
    {
      "epoch": 1.3902331720193577,
      "grad_norm": 0.11502547562122345,
      "learning_rate": 2.6838446053140292e-05,
      "loss": 0.0858,
      "step": 69520
    },
    {
      "epoch": 1.3904331480222374,
      "grad_norm": 0.178317591547966,
      "learning_rate": 2.6835113119758965e-05,
      "loss": 0.094,
      "step": 69530
    },
    {
      "epoch": 1.390633124025117,
      "grad_norm": 0.06752388179302216,
      "learning_rate": 2.6831780186377638e-05,
      "loss": 0.0466,
      "step": 69540
    },
    {
      "epoch": 1.3908331000279968,
      "grad_norm": 0.169974684715271,
      "learning_rate": 2.6828447252996308e-05,
      "loss": 0.0697,
      "step": 69550
    },
    {
      "epoch": 1.3910330760308762,
      "grad_norm": 0.18909786641597748,
      "learning_rate": 2.682511431961498e-05,
      "loss": 0.074,
      "step": 69560
    },
    {
      "epoch": 1.391233052033756,
      "grad_norm": 0.18733079731464386,
      "learning_rate": 2.6821781386233654e-05,
      "loss": 0.0795,
      "step": 69570
    },
    {
      "epoch": 1.3914330280366356,
      "grad_norm": 0.25340843200683594,
      "learning_rate": 2.6818448452852323e-05,
      "loss": 0.1216,
      "step": 69580
    },
    {
      "epoch": 1.3916330040395153,
      "grad_norm": 0.20299233496189117,
      "learning_rate": 2.6815115519470996e-05,
      "loss": 0.058,
      "step": 69590
    },
    {
      "epoch": 1.391832980042395,
      "grad_norm": 0.1761907935142517,
      "learning_rate": 2.6811782586089673e-05,
      "loss": 0.0844,
      "step": 69600
    },
    {
      "epoch": 1.3920329560452744,
      "grad_norm": 0.1763785034418106,
      "learning_rate": 2.6808449652708346e-05,
      "loss": 0.0655,
      "step": 69610
    },
    {
      "epoch": 1.3922329320481541,
      "grad_norm": 0.07265409082174301,
      "learning_rate": 2.6805116719327015e-05,
      "loss": 0.038,
      "step": 69620
    },
    {
      "epoch": 1.3924329080510338,
      "grad_norm": 0.064102903008461,
      "learning_rate": 2.6801783785945688e-05,
      "loss": 0.0899,
      "step": 69630
    },
    {
      "epoch": 1.3926328840539135,
      "grad_norm": 0.06112602353096008,
      "learning_rate": 2.679845085256436e-05,
      "loss": 0.064,
      "step": 69640
    },
    {
      "epoch": 1.3928328600567932,
      "grad_norm": 0.10114554315805435,
      "learning_rate": 2.6795117919183034e-05,
      "loss": 0.0887,
      "step": 69650
    },
    {
      "epoch": 1.3930328360596729,
      "grad_norm": 0.057361897081136703,
      "learning_rate": 2.6791784985801704e-05,
      "loss": 0.0563,
      "step": 69660
    },
    {
      "epoch": 1.3932328120625526,
      "grad_norm": 0.16881467401981354,
      "learning_rate": 2.6788452052420377e-05,
      "loss": 0.0892,
      "step": 69670
    },
    {
      "epoch": 1.3934327880654322,
      "grad_norm": 0.16570459306240082,
      "learning_rate": 2.678511911903905e-05,
      "loss": 0.0782,
      "step": 69680
    },
    {
      "epoch": 1.393632764068312,
      "grad_norm": 0.15687426924705505,
      "learning_rate": 2.678178618565772e-05,
      "loss": 0.0806,
      "step": 69690
    },
    {
      "epoch": 1.3938327400711914,
      "grad_norm": 0.11083167791366577,
      "learning_rate": 2.6778453252276393e-05,
      "loss": 0.0571,
      "step": 69700
    },
    {
      "epoch": 1.394032716074071,
      "grad_norm": 0.16592060029506683,
      "learning_rate": 2.677512031889507e-05,
      "loss": 0.0783,
      "step": 69710
    },
    {
      "epoch": 1.3942326920769508,
      "grad_norm": 0.11357976496219635,
      "learning_rate": 2.6771787385513742e-05,
      "loss": 0.062,
      "step": 69720
    },
    {
      "epoch": 1.3944326680798305,
      "grad_norm": 0.10962678492069244,
      "learning_rate": 2.676845445213241e-05,
      "loss": 0.0813,
      "step": 69730
    },
    {
      "epoch": 1.3946326440827101,
      "grad_norm": 0.21754255890846252,
      "learning_rate": 2.6765121518751085e-05,
      "loss": 0.1223,
      "step": 69740
    },
    {
      "epoch": 1.3948326200855896,
      "grad_norm": 0.19556266069412231,
      "learning_rate": 2.6761788585369758e-05,
      "loss": 0.086,
      "step": 69750
    },
    {
      "epoch": 1.3950325960884693,
      "grad_norm": 0.08122764527797699,
      "learning_rate": 2.6758455651988427e-05,
      "loss": 0.097,
      "step": 69760
    },
    {
      "epoch": 1.395232572091349,
      "grad_norm": 0.08861033618450165,
      "learning_rate": 2.67551227186071e-05,
      "loss": 0.069,
      "step": 69770
    },
    {
      "epoch": 1.3954325480942287,
      "grad_norm": 0.08946306258440018,
      "learning_rate": 2.6751789785225773e-05,
      "loss": 0.085,
      "step": 69780
    },
    {
      "epoch": 1.3956325240971084,
      "grad_norm": 0.08800023794174194,
      "learning_rate": 2.6748456851844446e-05,
      "loss": 0.1076,
      "step": 69790
    },
    {
      "epoch": 1.395832500099988,
      "grad_norm": 0.08021679520606995,
      "learning_rate": 2.6745123918463116e-05,
      "loss": 0.0786,
      "step": 69800
    },
    {
      "epoch": 1.3960324761028677,
      "grad_norm": 0.09650661051273346,
      "learning_rate": 2.6741790985081792e-05,
      "loss": 0.0556,
      "step": 69810
    },
    {
      "epoch": 1.3962324521057474,
      "grad_norm": 0.17321765422821045,
      "learning_rate": 2.6738458051700465e-05,
      "loss": 0.0557,
      "step": 69820
    },
    {
      "epoch": 1.3964324281086269,
      "grad_norm": 0.14232835173606873,
      "learning_rate": 2.6735125118319138e-05,
      "loss": 0.0599,
      "step": 69830
    },
    {
      "epoch": 1.3966324041115066,
      "grad_norm": 0.0850975513458252,
      "learning_rate": 2.6731792184937808e-05,
      "loss": 0.0588,
      "step": 69840
    },
    {
      "epoch": 1.3968323801143863,
      "grad_norm": 0.14689771831035614,
      "learning_rate": 2.672845925155648e-05,
      "loss": 0.0673,
      "step": 69850
    },
    {
      "epoch": 1.397032356117266,
      "grad_norm": 0.17035013437271118,
      "learning_rate": 2.6725126318175154e-05,
      "loss": 0.1109,
      "step": 69860
    },
    {
      "epoch": 1.3972323321201456,
      "grad_norm": 0.08372677862644196,
      "learning_rate": 2.6721793384793823e-05,
      "loss": 0.0876,
      "step": 69870
    },
    {
      "epoch": 1.397432308123025,
      "grad_norm": 0.09321685135364532,
      "learning_rate": 2.6718460451412496e-05,
      "loss": 0.0659,
      "step": 69880
    },
    {
      "epoch": 1.3976322841259048,
      "grad_norm": 0.17388014495372772,
      "learning_rate": 2.671512751803117e-05,
      "loss": 0.0891,
      "step": 69890
    },
    {
      "epoch": 1.3978322601287845,
      "grad_norm": 0.14957599341869354,
      "learning_rate": 2.671179458464984e-05,
      "loss": 0.0736,
      "step": 69900
    },
    {
      "epoch": 1.3980322361316642,
      "grad_norm": 0.08100289851427078,
      "learning_rate": 2.670846165126852e-05,
      "loss": 0.0485,
      "step": 69910
    },
    {
      "epoch": 1.3982322121345439,
      "grad_norm": 0.22000782191753387,
      "learning_rate": 2.670512871788719e-05,
      "loss": 0.0617,
      "step": 69920
    },
    {
      "epoch": 1.3984321881374235,
      "grad_norm": 0.10401811450719833,
      "learning_rate": 2.670179578450586e-05,
      "loss": 0.0832,
      "step": 69930
    },
    {
      "epoch": 1.3986321641403032,
      "grad_norm": 0.10491994768381119,
      "learning_rate": 2.6698462851124534e-05,
      "loss": 0.0456,
      "step": 69940
    },
    {
      "epoch": 1.398832140143183,
      "grad_norm": 0.09905878454446793,
      "learning_rate": 2.6695129917743204e-05,
      "loss": 0.0582,
      "step": 69950
    },
    {
      "epoch": 1.3990321161460626,
      "grad_norm": 0.19310782849788666,
      "learning_rate": 2.6691796984361877e-05,
      "loss": 0.0754,
      "step": 69960
    },
    {
      "epoch": 1.399232092148942,
      "grad_norm": 0.14719869196414948,
      "learning_rate": 2.668846405098055e-05,
      "loss": 0.0879,
      "step": 69970
    },
    {
      "epoch": 1.3994320681518218,
      "grad_norm": 0.19069786369800568,
      "learning_rate": 2.668513111759922e-05,
      "loss": 0.0788,
      "step": 69980
    },
    {
      "epoch": 1.3996320441547014,
      "grad_norm": 0.11311401426792145,
      "learning_rate": 2.6681798184217893e-05,
      "loss": 0.0644,
      "step": 69990
    },
    {
      "epoch": 1.3998320201575811,
      "grad_norm": 0.15859480202198029,
      "learning_rate": 2.6678465250836566e-05,
      "loss": 0.1854,
      "step": 70000
    },
    {
      "epoch": 1.4000319961604608,
      "grad_norm": 0.09410951286554337,
      "learning_rate": 2.6675132317455242e-05,
      "loss": 0.0848,
      "step": 70010
    },
    {
      "epoch": 1.4002319721633403,
      "grad_norm": 0.15704628825187683,
      "learning_rate": 2.6671799384073915e-05,
      "loss": 0.103,
      "step": 70020
    },
    {
      "epoch": 1.40043194816622,
      "grad_norm": 0.25451958179473877,
      "learning_rate": 2.6668466450692585e-05,
      "loss": 0.0845,
      "step": 70030
    },
    {
      "epoch": 1.4006319241690997,
      "grad_norm": 0.16307735443115234,
      "learning_rate": 2.6665133517311258e-05,
      "loss": 0.0823,
      "step": 70040
    },
    {
      "epoch": 1.4008319001719793,
      "grad_norm": 0.10287918895483017,
      "learning_rate": 2.666180058392993e-05,
      "loss": 0.0748,
      "step": 70050
    },
    {
      "epoch": 1.401031876174859,
      "grad_norm": 0.08629358559846878,
      "learning_rate": 2.66584676505486e-05,
      "loss": 0.0577,
      "step": 70060
    },
    {
      "epoch": 1.4012318521777387,
      "grad_norm": 0.12777067720890045,
      "learning_rate": 2.6655134717167273e-05,
      "loss": 0.0795,
      "step": 70070
    },
    {
      "epoch": 1.4014318281806184,
      "grad_norm": 0.17468155920505524,
      "learning_rate": 2.6651801783785946e-05,
      "loss": 0.0994,
      "step": 70080
    },
    {
      "epoch": 1.401631804183498,
      "grad_norm": 0.11035279184579849,
      "learning_rate": 2.6648468850404616e-05,
      "loss": 0.0577,
      "step": 70090
    },
    {
      "epoch": 1.4018317801863776,
      "grad_norm": 0.18400990962982178,
      "learning_rate": 2.664513591702329e-05,
      "loss": 0.0736,
      "step": 70100
    },
    {
      "epoch": 1.4020317561892572,
      "grad_norm": 0.1514005810022354,
      "learning_rate": 2.6641802983641965e-05,
      "loss": 0.0677,
      "step": 70110
    },
    {
      "epoch": 1.402231732192137,
      "grad_norm": 0.06496556103229523,
      "learning_rate": 2.663847005026064e-05,
      "loss": 0.1936,
      "step": 70120
    },
    {
      "epoch": 1.4024317081950166,
      "grad_norm": 0.10575127601623535,
      "learning_rate": 2.663513711687931e-05,
      "loss": 0.0812,
      "step": 70130
    },
    {
      "epoch": 1.4026316841978963,
      "grad_norm": 0.10537469387054443,
      "learning_rate": 2.663180418349798e-05,
      "loss": 0.0527,
      "step": 70140
    },
    {
      "epoch": 1.402831660200776,
      "grad_norm": 0.1689358949661255,
      "learning_rate": 2.6628471250116654e-05,
      "loss": 0.061,
      "step": 70150
    },
    {
      "epoch": 1.4030316362036555,
      "grad_norm": 0.2471434623003006,
      "learning_rate": 2.6625138316735327e-05,
      "loss": 0.0757,
      "step": 70160
    },
    {
      "epoch": 1.4032316122065351,
      "grad_norm": 0.11624561250209808,
      "learning_rate": 2.6621805383353997e-05,
      "loss": 0.0658,
      "step": 70170
    },
    {
      "epoch": 1.4034315882094148,
      "grad_norm": 0.10180967301130295,
      "learning_rate": 2.661847244997267e-05,
      "loss": 0.0559,
      "step": 70180
    },
    {
      "epoch": 1.4036315642122945,
      "grad_norm": 0.11277402937412262,
      "learning_rate": 2.6615139516591343e-05,
      "loss": 0.0515,
      "step": 70190
    },
    {
      "epoch": 1.4038315402151742,
      "grad_norm": 0.07615511119365692,
      "learning_rate": 2.6611806583210012e-05,
      "loss": 0.0987,
      "step": 70200
    },
    {
      "epoch": 1.4040315162180539,
      "grad_norm": 0.15441076457500458,
      "learning_rate": 2.6608473649828685e-05,
      "loss": 0.0983,
      "step": 70210
    },
    {
      "epoch": 1.4042314922209336,
      "grad_norm": 0.07198408991098404,
      "learning_rate": 2.660514071644736e-05,
      "loss": 0.0829,
      "step": 70220
    },
    {
      "epoch": 1.4044314682238133,
      "grad_norm": 0.19536112248897552,
      "learning_rate": 2.6601807783066035e-05,
      "loss": 0.0606,
      "step": 70230
    },
    {
      "epoch": 1.4046314442266927,
      "grad_norm": 0.1595640778541565,
      "learning_rate": 2.6598474849684708e-05,
      "loss": 0.1002,
      "step": 70240
    },
    {
      "epoch": 1.4048314202295724,
      "grad_norm": 0.21312007308006287,
      "learning_rate": 2.6595141916303377e-05,
      "loss": 0.0673,
      "step": 70250
    },
    {
      "epoch": 1.405031396232452,
      "grad_norm": 0.19122277200222015,
      "learning_rate": 2.659180898292205e-05,
      "loss": 0.0993,
      "step": 70260
    },
    {
      "epoch": 1.4052313722353318,
      "grad_norm": 0.15765075385570526,
      "learning_rate": 2.6588476049540723e-05,
      "loss": 0.0883,
      "step": 70270
    },
    {
      "epoch": 1.4054313482382115,
      "grad_norm": 0.1929926872253418,
      "learning_rate": 2.6585143116159393e-05,
      "loss": 0.0613,
      "step": 70280
    },
    {
      "epoch": 1.405631324241091,
      "grad_norm": 0.18552030622959137,
      "learning_rate": 2.6581810182778066e-05,
      "loss": 0.0726,
      "step": 70290
    },
    {
      "epoch": 1.4058313002439706,
      "grad_norm": 0.19026969373226166,
      "learning_rate": 2.657847724939674e-05,
      "loss": 0.055,
      "step": 70300
    },
    {
      "epoch": 1.4060312762468503,
      "grad_norm": 0.11172233521938324,
      "learning_rate": 2.657514431601541e-05,
      "loss": 0.0674,
      "step": 70310
    },
    {
      "epoch": 1.40623125224973,
      "grad_norm": 0.13439342379570007,
      "learning_rate": 2.6571811382634088e-05,
      "loss": 0.0762,
      "step": 70320
    },
    {
      "epoch": 1.4064312282526097,
      "grad_norm": 0.08700716495513916,
      "learning_rate": 2.6568478449252758e-05,
      "loss": 0.0544,
      "step": 70330
    },
    {
      "epoch": 1.4066312042554894,
      "grad_norm": 0.21142593026161194,
      "learning_rate": 2.656514551587143e-05,
      "loss": 0.0883,
      "step": 70340
    },
    {
      "epoch": 1.406831180258369,
      "grad_norm": 0.15919965505599976,
      "learning_rate": 2.6561812582490104e-05,
      "loss": 0.0724,
      "step": 70350
    },
    {
      "epoch": 1.4070311562612487,
      "grad_norm": 0.0749245285987854,
      "learning_rate": 2.6558479649108774e-05,
      "loss": 0.0722,
      "step": 70360
    },
    {
      "epoch": 1.4072311322641284,
      "grad_norm": 0.08337607979774475,
      "learning_rate": 2.6555146715727447e-05,
      "loss": 0.0626,
      "step": 70370
    },
    {
      "epoch": 1.407431108267008,
      "grad_norm": 0.10540294647216797,
      "learning_rate": 2.655181378234612e-05,
      "loss": 0.0651,
      "step": 70380
    },
    {
      "epoch": 1.4076310842698876,
      "grad_norm": 0.12223644554615021,
      "learning_rate": 2.654848084896479e-05,
      "loss": 0.0676,
      "step": 70390
    },
    {
      "epoch": 1.4078310602727673,
      "grad_norm": 0.07263029366731644,
      "learning_rate": 2.6545147915583462e-05,
      "loss": 0.0826,
      "step": 70400
    },
    {
      "epoch": 1.408031036275647,
      "grad_norm": 0.08490108698606491,
      "learning_rate": 2.6541814982202135e-05,
      "loss": 0.0733,
      "step": 70410
    },
    {
      "epoch": 1.4082310122785267,
      "grad_norm": 0.11672256886959076,
      "learning_rate": 2.653848204882081e-05,
      "loss": 0.086,
      "step": 70420
    },
    {
      "epoch": 1.4084309882814061,
      "grad_norm": 0.32629361748695374,
      "learning_rate": 2.6535149115439485e-05,
      "loss": 0.1229,
      "step": 70430
    },
    {
      "epoch": 1.4086309642842858,
      "grad_norm": 0.08779175579547882,
      "learning_rate": 2.6531816182058154e-05,
      "loss": 0.0464,
      "step": 70440
    },
    {
      "epoch": 1.4088309402871655,
      "grad_norm": 0.19218209385871887,
      "learning_rate": 2.6528483248676827e-05,
      "loss": 0.0652,
      "step": 70450
    },
    {
      "epoch": 1.4090309162900452,
      "grad_norm": 0.20790833234786987,
      "learning_rate": 2.65251503152955e-05,
      "loss": 0.0863,
      "step": 70460
    },
    {
      "epoch": 1.4092308922929249,
      "grad_norm": 0.14150112867355347,
      "learning_rate": 2.652181738191417e-05,
      "loss": 0.0625,
      "step": 70470
    },
    {
      "epoch": 1.4094308682958046,
      "grad_norm": 0.09995657205581665,
      "learning_rate": 2.6518484448532843e-05,
      "loss": 0.0419,
      "step": 70480
    },
    {
      "epoch": 1.4096308442986842,
      "grad_norm": 0.057827580720186234,
      "learning_rate": 2.6515151515151516e-05,
      "loss": 0.0618,
      "step": 70490
    },
    {
      "epoch": 1.409830820301564,
      "grad_norm": 0.12727969884872437,
      "learning_rate": 2.6511818581770185e-05,
      "loss": 0.0616,
      "step": 70500
    },
    {
      "epoch": 1.4100307963044434,
      "grad_norm": 0.08300052583217621,
      "learning_rate": 2.650848564838886e-05,
      "loss": 0.0715,
      "step": 70510
    },
    {
      "epoch": 1.410230772307323,
      "grad_norm": 0.11459442228078842,
      "learning_rate": 2.6505152715007535e-05,
      "loss": 0.0599,
      "step": 70520
    },
    {
      "epoch": 1.4104307483102028,
      "grad_norm": 0.08756508678197861,
      "learning_rate": 2.6501819781626208e-05,
      "loss": 0.0665,
      "step": 70530
    },
    {
      "epoch": 1.4106307243130825,
      "grad_norm": 0.05803552269935608,
      "learning_rate": 2.649848684824488e-05,
      "loss": 0.0866,
      "step": 70540
    },
    {
      "epoch": 1.4108307003159621,
      "grad_norm": 0.057729776948690414,
      "learning_rate": 2.649515391486355e-05,
      "loss": 0.054,
      "step": 70550
    },
    {
      "epoch": 1.4110306763188416,
      "grad_norm": 0.1205136850476265,
      "learning_rate": 2.6491820981482223e-05,
      "loss": 0.0671,
      "step": 70560
    },
    {
      "epoch": 1.4112306523217213,
      "grad_norm": 0.10967963933944702,
      "learning_rate": 2.6488488048100896e-05,
      "loss": 0.1157,
      "step": 70570
    },
    {
      "epoch": 1.411430628324601,
      "grad_norm": 0.08636512607336044,
      "learning_rate": 2.6485155114719566e-05,
      "loss": 0.0582,
      "step": 70580
    },
    {
      "epoch": 1.4116306043274807,
      "grad_norm": 0.2176951766014099,
      "learning_rate": 2.648182218133824e-05,
      "loss": 0.0811,
      "step": 70590
    },
    {
      "epoch": 1.4118305803303604,
      "grad_norm": 0.10101315379142761,
      "learning_rate": 2.6478489247956912e-05,
      "loss": 0.5705,
      "step": 70600
    },
    {
      "epoch": 1.41203055633324,
      "grad_norm": 0.1440298706293106,
      "learning_rate": 2.647515631457558e-05,
      "loss": 0.0557,
      "step": 70610
    },
    {
      "epoch": 1.4122305323361197,
      "grad_norm": 0.20084679126739502,
      "learning_rate": 2.647182338119426e-05,
      "loss": 0.0613,
      "step": 70620
    },
    {
      "epoch": 1.4124305083389994,
      "grad_norm": 0.11471099406480789,
      "learning_rate": 2.646849044781293e-05,
      "loss": 0.1024,
      "step": 70630
    },
    {
      "epoch": 1.412630484341879,
      "grad_norm": 0.16379010677337646,
      "learning_rate": 2.6465157514431604e-05,
      "loss": 0.0864,
      "step": 70640
    },
    {
      "epoch": 1.4128304603447586,
      "grad_norm": 0.12155365198850632,
      "learning_rate": 2.6461824581050277e-05,
      "loss": 0.0495,
      "step": 70650
    },
    {
      "epoch": 1.4130304363476383,
      "grad_norm": 0.15163542330265045,
      "learning_rate": 2.6458491647668947e-05,
      "loss": 0.0819,
      "step": 70660
    },
    {
      "epoch": 1.413230412350518,
      "grad_norm": 0.13061702251434326,
      "learning_rate": 2.645515871428762e-05,
      "loss": 0.0595,
      "step": 70670
    },
    {
      "epoch": 1.4134303883533976,
      "grad_norm": 0.18781045079231262,
      "learning_rate": 2.6451825780906293e-05,
      "loss": 0.0782,
      "step": 70680
    },
    {
      "epoch": 1.4136303643562773,
      "grad_norm": 0.19696348905563354,
      "learning_rate": 2.6448492847524962e-05,
      "loss": 0.1042,
      "step": 70690
    },
    {
      "epoch": 1.4138303403591568,
      "grad_norm": 0.2028602510690689,
      "learning_rate": 2.6445159914143635e-05,
      "loss": 0.0974,
      "step": 70700
    },
    {
      "epoch": 1.4140303163620365,
      "grad_norm": 0.13513001799583435,
      "learning_rate": 2.644182698076231e-05,
      "loss": 0.0976,
      "step": 70710
    },
    {
      "epoch": 1.4142302923649162,
      "grad_norm": 0.22354334592819214,
      "learning_rate": 2.6438494047380978e-05,
      "loss": 0.0768,
      "step": 70720
    },
    {
      "epoch": 1.4144302683677958,
      "grad_norm": 0.08731799572706223,
      "learning_rate": 2.6435161113999658e-05,
      "loss": 0.08,
      "step": 70730
    },
    {
      "epoch": 1.4146302443706755,
      "grad_norm": 0.17298533022403717,
      "learning_rate": 2.6431828180618327e-05,
      "loss": 0.0661,
      "step": 70740
    },
    {
      "epoch": 1.4148302203735552,
      "grad_norm": 0.10187650471925735,
      "learning_rate": 2.6428495247237e-05,
      "loss": 0.1049,
      "step": 70750
    },
    {
      "epoch": 1.415030196376435,
      "grad_norm": 0.12550577521324158,
      "learning_rate": 2.6425162313855673e-05,
      "loss": 0.0749,
      "step": 70760
    },
    {
      "epoch": 1.4152301723793146,
      "grad_norm": 0.09504901617765427,
      "learning_rate": 2.6421829380474343e-05,
      "loss": 0.0837,
      "step": 70770
    },
    {
      "epoch": 1.4154301483821943,
      "grad_norm": 0.20958903431892395,
      "learning_rate": 2.6418496447093016e-05,
      "loss": 0.0787,
      "step": 70780
    },
    {
      "epoch": 1.4156301243850737,
      "grad_norm": 0.17066159844398499,
      "learning_rate": 2.641516351371169e-05,
      "loss": 0.1222,
      "step": 70790
    },
    {
      "epoch": 1.4158301003879534,
      "grad_norm": 0.10506677627563477,
      "learning_rate": 2.641183058033036e-05,
      "loss": 0.0665,
      "step": 70800
    },
    {
      "epoch": 1.4160300763908331,
      "grad_norm": 0.1435130089521408,
      "learning_rate": 2.640849764694903e-05,
      "loss": 0.0802,
      "step": 70810
    },
    {
      "epoch": 1.4162300523937128,
      "grad_norm": 0.21280209720134735,
      "learning_rate": 2.6405164713567705e-05,
      "loss": 0.0655,
      "step": 70820
    },
    {
      "epoch": 1.4164300283965925,
      "grad_norm": 0.12613001465797424,
      "learning_rate": 2.640183178018638e-05,
      "loss": 0.1056,
      "step": 70830
    },
    {
      "epoch": 1.416630004399472,
      "grad_norm": 0.06423722952604294,
      "learning_rate": 2.6398498846805054e-05,
      "loss": 0.0307,
      "step": 70840
    },
    {
      "epoch": 1.4168299804023516,
      "grad_norm": 0.15642447769641876,
      "learning_rate": 2.6395165913423724e-05,
      "loss": 0.0758,
      "step": 70850
    },
    {
      "epoch": 1.4170299564052313,
      "grad_norm": 0.11264205724000931,
      "learning_rate": 2.6391832980042397e-05,
      "loss": 0.0866,
      "step": 70860
    },
    {
      "epoch": 1.417229932408111,
      "grad_norm": 0.25207197666168213,
      "learning_rate": 2.638850004666107e-05,
      "loss": 0.1148,
      "step": 70870
    },
    {
      "epoch": 1.4174299084109907,
      "grad_norm": 0.09595309942960739,
      "learning_rate": 2.638516711327974e-05,
      "loss": 0.0684,
      "step": 70880
    },
    {
      "epoch": 1.4176298844138704,
      "grad_norm": 0.07451091706752777,
      "learning_rate": 2.6381834179898412e-05,
      "loss": 0.0609,
      "step": 70890
    },
    {
      "epoch": 1.41782986041675,
      "grad_norm": 0.19305725395679474,
      "learning_rate": 2.6378501246517085e-05,
      "loss": 0.0924,
      "step": 70900
    },
    {
      "epoch": 1.4180298364196298,
      "grad_norm": 0.09930330514907837,
      "learning_rate": 2.6375168313135755e-05,
      "loss": 0.0672,
      "step": 70910
    },
    {
      "epoch": 1.4182298124225092,
      "grad_norm": 0.10423073917627335,
      "learning_rate": 2.6371835379754428e-05,
      "loss": 0.0404,
      "step": 70920
    },
    {
      "epoch": 1.418429788425389,
      "grad_norm": 0.21982617676258087,
      "learning_rate": 2.6368502446373104e-05,
      "loss": 0.0705,
      "step": 70930
    },
    {
      "epoch": 1.4186297644282686,
      "grad_norm": 0.19039300084114075,
      "learning_rate": 2.6365169512991777e-05,
      "loss": 0.0955,
      "step": 70940
    },
    {
      "epoch": 1.4188297404311483,
      "grad_norm": 0.17083598673343658,
      "learning_rate": 2.636183657961045e-05,
      "loss": 0.0779,
      "step": 70950
    },
    {
      "epoch": 1.419029716434028,
      "grad_norm": 0.11829543858766556,
      "learning_rate": 2.635850364622912e-05,
      "loss": 0.0775,
      "step": 70960
    },
    {
      "epoch": 1.4192296924369074,
      "grad_norm": 0.11196383833885193,
      "learning_rate": 2.6355170712847793e-05,
      "loss": 0.0773,
      "step": 70970
    },
    {
      "epoch": 1.4194296684397871,
      "grad_norm": 0.0779886245727539,
      "learning_rate": 2.6351837779466466e-05,
      "loss": 0.0604,
      "step": 70980
    },
    {
      "epoch": 1.4196296444426668,
      "grad_norm": 0.15176622569561005,
      "learning_rate": 2.6348504846085136e-05,
      "loss": 0.1047,
      "step": 70990
    },
    {
      "epoch": 1.4198296204455465,
      "grad_norm": 0.19764797389507294,
      "learning_rate": 2.634517191270381e-05,
      "loss": 0.0998,
      "step": 71000
    },
    {
      "epoch": 1.4200295964484262,
      "grad_norm": 0.1727987676858902,
      "learning_rate": 2.634183897932248e-05,
      "loss": 0.0759,
      "step": 71010
    },
    {
      "epoch": 1.4202295724513059,
      "grad_norm": 0.09453276544809341,
      "learning_rate": 2.633850604594115e-05,
      "loss": 0.1058,
      "step": 71020
    },
    {
      "epoch": 1.4204295484541856,
      "grad_norm": 0.15711334347724915,
      "learning_rate": 2.633517311255983e-05,
      "loss": 0.0741,
      "step": 71030
    },
    {
      "epoch": 1.4206295244570653,
      "grad_norm": 0.09909165650606155,
      "learning_rate": 2.63318401791785e-05,
      "loss": 0.0969,
      "step": 71040
    },
    {
      "epoch": 1.420829500459945,
      "grad_norm": 0.0896708145737648,
      "learning_rate": 2.6328507245797174e-05,
      "loss": 0.0805,
      "step": 71050
    },
    {
      "epoch": 1.4210294764628244,
      "grad_norm": 0.15105211734771729,
      "learning_rate": 2.6325174312415847e-05,
      "loss": 0.0622,
      "step": 71060
    },
    {
      "epoch": 1.421229452465704,
      "grad_norm": 0.1453724503517151,
      "learning_rate": 2.6321841379034516e-05,
      "loss": 0.1279,
      "step": 71070
    },
    {
      "epoch": 1.4214294284685838,
      "grad_norm": 0.2247391939163208,
      "learning_rate": 2.631850844565319e-05,
      "loss": 0.0829,
      "step": 71080
    },
    {
      "epoch": 1.4216294044714635,
      "grad_norm": 0.11206775158643723,
      "learning_rate": 2.6315175512271862e-05,
      "loss": 0.0602,
      "step": 71090
    },
    {
      "epoch": 1.4218293804743432,
      "grad_norm": 0.06409700214862823,
      "learning_rate": 2.6311842578890532e-05,
      "loss": 0.0671,
      "step": 71100
    },
    {
      "epoch": 1.4220293564772226,
      "grad_norm": 0.11678925156593323,
      "learning_rate": 2.6308509645509205e-05,
      "loss": 0.148,
      "step": 71110
    },
    {
      "epoch": 1.4222293324801023,
      "grad_norm": 0.12000837922096252,
      "learning_rate": 2.6305176712127878e-05,
      "loss": 0.0438,
      "step": 71120
    },
    {
      "epoch": 1.422429308482982,
      "grad_norm": 0.13482214510440826,
      "learning_rate": 2.6301843778746554e-05,
      "loss": 0.0644,
      "step": 71130
    },
    {
      "epoch": 1.4226292844858617,
      "grad_norm": 0.208199143409729,
      "learning_rate": 2.6298510845365227e-05,
      "loss": 0.4557,
      "step": 71140
    },
    {
      "epoch": 1.4228292604887414,
      "grad_norm": 0.16666759550571442,
      "learning_rate": 2.6295177911983897e-05,
      "loss": 0.0744,
      "step": 71150
    },
    {
      "epoch": 1.423029236491621,
      "grad_norm": 0.06077361851930618,
      "learning_rate": 2.629184497860257e-05,
      "loss": 0.0749,
      "step": 71160
    },
    {
      "epoch": 1.4232292124945007,
      "grad_norm": 0.14239458739757538,
      "learning_rate": 2.6288512045221243e-05,
      "loss": 0.0993,
      "step": 71170
    },
    {
      "epoch": 1.4234291884973804,
      "grad_norm": 0.14316628873348236,
      "learning_rate": 2.6285179111839912e-05,
      "loss": 0.0674,
      "step": 71180
    },
    {
      "epoch": 1.42362916450026,
      "grad_norm": 0.10492962598800659,
      "learning_rate": 2.6281846178458585e-05,
      "loss": 0.0942,
      "step": 71190
    },
    {
      "epoch": 1.4238291405031396,
      "grad_norm": 0.05569066107273102,
      "learning_rate": 2.627851324507726e-05,
      "loss": 0.0761,
      "step": 71200
    },
    {
      "epoch": 1.4240291165060193,
      "grad_norm": 0.11939103156328201,
      "learning_rate": 2.6275180311695928e-05,
      "loss": 0.0761,
      "step": 71210
    },
    {
      "epoch": 1.424229092508899,
      "grad_norm": 0.13649608194828033,
      "learning_rate": 2.62718473783146e-05,
      "loss": 0.0784,
      "step": 71220
    },
    {
      "epoch": 1.4244290685117786,
      "grad_norm": 0.11606177687644958,
      "learning_rate": 2.6268514444933274e-05,
      "loss": 0.0809,
      "step": 71230
    },
    {
      "epoch": 1.424629044514658,
      "grad_norm": 0.09324909746646881,
      "learning_rate": 2.626518151155195e-05,
      "loss": 0.041,
      "step": 71240
    },
    {
      "epoch": 1.4248290205175378,
      "grad_norm": 0.07867106050252914,
      "learning_rate": 2.6261848578170623e-05,
      "loss": 0.0758,
      "step": 71250
    },
    {
      "epoch": 1.4250289965204175,
      "grad_norm": 0.11766640096902847,
      "learning_rate": 2.6258515644789293e-05,
      "loss": 0.0486,
      "step": 71260
    },
    {
      "epoch": 1.4252289725232972,
      "grad_norm": 0.06236068159341812,
      "learning_rate": 2.6255182711407966e-05,
      "loss": 0.0563,
      "step": 71270
    },
    {
      "epoch": 1.4254289485261769,
      "grad_norm": 0.14931204915046692,
      "learning_rate": 2.625184977802664e-05,
      "loss": 0.0824,
      "step": 71280
    },
    {
      "epoch": 1.4256289245290565,
      "grad_norm": 0.16943973302841187,
      "learning_rate": 2.624851684464531e-05,
      "loss": 0.0955,
      "step": 71290
    },
    {
      "epoch": 1.4258289005319362,
      "grad_norm": 0.16059529781341553,
      "learning_rate": 2.6245183911263982e-05,
      "loss": 0.0846,
      "step": 71300
    },
    {
      "epoch": 1.426028876534816,
      "grad_norm": 0.09801551699638367,
      "learning_rate": 2.6241850977882655e-05,
      "loss": 0.106,
      "step": 71310
    },
    {
      "epoch": 1.4262288525376956,
      "grad_norm": 0.12540124356746674,
      "learning_rate": 2.6238518044501324e-05,
      "loss": 0.0549,
      "step": 71320
    },
    {
      "epoch": 1.426428828540575,
      "grad_norm": 0.06960415095090866,
      "learning_rate": 2.6235185111119997e-05,
      "loss": 0.0771,
      "step": 71330
    },
    {
      "epoch": 1.4266288045434548,
      "grad_norm": 0.11311232298612595,
      "learning_rate": 2.6231852177738674e-05,
      "loss": 0.0557,
      "step": 71340
    },
    {
      "epoch": 1.4268287805463344,
      "grad_norm": 0.10389814525842667,
      "learning_rate": 2.6228519244357347e-05,
      "loss": 0.0743,
      "step": 71350
    },
    {
      "epoch": 1.4270287565492141,
      "grad_norm": 0.11167877912521362,
      "learning_rate": 2.622518631097602e-05,
      "loss": 0.0506,
      "step": 71360
    },
    {
      "epoch": 1.4272287325520938,
      "grad_norm": 0.10407794266939163,
      "learning_rate": 2.622185337759469e-05,
      "loss": 0.08,
      "step": 71370
    },
    {
      "epoch": 1.4274287085549733,
      "grad_norm": 0.080299973487854,
      "learning_rate": 2.6218520444213362e-05,
      "loss": 0.0647,
      "step": 71380
    },
    {
      "epoch": 1.427628684557853,
      "grad_norm": 0.11631303280591965,
      "learning_rate": 2.6215187510832035e-05,
      "loss": 0.0717,
      "step": 71390
    },
    {
      "epoch": 1.4278286605607327,
      "grad_norm": NaN,
      "learning_rate": 2.6211854577450705e-05,
      "loss": 0.0834,
      "step": 71400
    },
    {
      "epoch": 1.4280286365636123,
      "grad_norm": 0.07367464154958725,
      "learning_rate": 2.6208854937407514e-05,
      "loss": 0.0651,
      "step": 71410
    },
    {
      "epoch": 1.428228612566492,
      "grad_norm": 0.1296594738960266,
      "learning_rate": 2.6205522004026183e-05,
      "loss": 0.066,
      "step": 71420
    },
    {
      "epoch": 1.4284285885693717,
      "grad_norm": 0.09940031170845032,
      "learning_rate": 2.6202189070644856e-05,
      "loss": 0.0804,
      "step": 71430
    },
    {
      "epoch": 1.4286285645722514,
      "grad_norm": 0.11882306635379791,
      "learning_rate": 2.619885613726353e-05,
      "loss": 0.0851,
      "step": 71440
    },
    {
      "epoch": 1.428828540575131,
      "grad_norm": 0.1710001677274704,
      "learning_rate": 2.61955232038822e-05,
      "loss": 0.0896,
      "step": 71450
    },
    {
      "epoch": 1.4290285165780108,
      "grad_norm": 0.11504679173231125,
      "learning_rate": 2.6192190270500875e-05,
      "loss": 0.06,
      "step": 71460
    },
    {
      "epoch": 1.4292284925808902,
      "grad_norm": 0.08375876396894455,
      "learning_rate": 2.618885733711955e-05,
      "loss": 0.061,
      "step": 71470
    },
    {
      "epoch": 1.42942846858377,
      "grad_norm": 0.09967517852783203,
      "learning_rate": 2.618552440373822e-05,
      "loss": 0.0962,
      "step": 71480
    },
    {
      "epoch": 1.4296284445866496,
      "grad_norm": 0.07384602725505829,
      "learning_rate": 2.6182191470356894e-05,
      "loss": 0.078,
      "step": 71490
    },
    {
      "epoch": 1.4298284205895293,
      "grad_norm": 0.08028125762939453,
      "learning_rate": 2.6178858536975564e-05,
      "loss": 0.0744,
      "step": 71500
    },
    {
      "epoch": 1.430028396592409,
      "grad_norm": 0.19053934514522552,
      "learning_rate": 2.6175525603594237e-05,
      "loss": 0.0664,
      "step": 71510
    },
    {
      "epoch": 1.4302283725952885,
      "grad_norm": 0.24123695492744446,
      "learning_rate": 2.617219267021291e-05,
      "loss": 0.0926,
      "step": 71520
    },
    {
      "epoch": 1.4304283485981681,
      "grad_norm": 0.08918513357639313,
      "learning_rate": 2.616885973683158e-05,
      "loss": 0.0851,
      "step": 71530
    },
    {
      "epoch": 1.4306283246010478,
      "grad_norm": 0.17467103898525238,
      "learning_rate": 2.6165526803450253e-05,
      "loss": 0.094,
      "step": 71540
    },
    {
      "epoch": 1.4308283006039275,
      "grad_norm": 0.05884723737835884,
      "learning_rate": 2.6162193870068926e-05,
      "loss": 0.0576,
      "step": 71550
    },
    {
      "epoch": 1.4310282766068072,
      "grad_norm": 0.11087249964475632,
      "learning_rate": 2.6158860936687602e-05,
      "loss": 0.0556,
      "step": 71560
    },
    {
      "epoch": 1.431228252609687,
      "grad_norm": 0.1688600331544876,
      "learning_rate": 2.615552800330627e-05,
      "loss": 0.0808,
      "step": 71570
    },
    {
      "epoch": 1.4314282286125666,
      "grad_norm": 0.1842299848794937,
      "learning_rate": 2.6152195069924945e-05,
      "loss": 0.1392,
      "step": 71580
    },
    {
      "epoch": 1.4316282046154463,
      "grad_norm": 0.04841088503599167,
      "learning_rate": 2.6148862136543618e-05,
      "loss": 0.0535,
      "step": 71590
    },
    {
      "epoch": 1.4318281806183257,
      "grad_norm": 0.18861302733421326,
      "learning_rate": 2.6145529203162287e-05,
      "loss": 0.06,
      "step": 71600
    },
    {
      "epoch": 1.4320281566212054,
      "grad_norm": 0.13258060812950134,
      "learning_rate": 2.614219626978096e-05,
      "loss": 0.09,
      "step": 71610
    },
    {
      "epoch": 1.432228132624085,
      "grad_norm": 0.13497714698314667,
      "learning_rate": 2.6138863336399633e-05,
      "loss": 0.067,
      "step": 71620
    },
    {
      "epoch": 1.4324281086269648,
      "grad_norm": 0.17068885266780853,
      "learning_rate": 2.6135530403018306e-05,
      "loss": 0.1027,
      "step": 71630
    },
    {
      "epoch": 1.4326280846298445,
      "grad_norm": 0.13221199810504913,
      "learning_rate": 2.6132197469636976e-05,
      "loss": 0.0798,
      "step": 71640
    },
    {
      "epoch": 1.432828060632724,
      "grad_norm": 0.11878626048564911,
      "learning_rate": 2.612886453625565e-05,
      "loss": 0.0682,
      "step": 71650
    },
    {
      "epoch": 1.4330280366356036,
      "grad_norm": 0.20184005796909332,
      "learning_rate": 2.6125531602874325e-05,
      "loss": 0.0999,
      "step": 71660
    },
    {
      "epoch": 1.4332280126384833,
      "grad_norm": 0.1996525526046753,
      "learning_rate": 2.6122198669492998e-05,
      "loss": 0.044,
      "step": 71670
    },
    {
      "epoch": 1.433427988641363,
      "grad_norm": 0.09390323609113693,
      "learning_rate": 2.6118865736111668e-05,
      "loss": 0.1659,
      "step": 71680
    },
    {
      "epoch": 1.4336279646442427,
      "grad_norm": 0.11858534067869186,
      "learning_rate": 2.611553280273034e-05,
      "loss": 0.0975,
      "step": 71690
    },
    {
      "epoch": 1.4338279406471224,
      "grad_norm": 0.11340458691120148,
      "learning_rate": 2.6112199869349014e-05,
      "loss": 0.0616,
      "step": 71700
    },
    {
      "epoch": 1.434027916650002,
      "grad_norm": 0.17825256288051605,
      "learning_rate": 2.6108866935967684e-05,
      "loss": 0.075,
      "step": 71710
    },
    {
      "epoch": 1.4342278926528818,
      "grad_norm": 0.086892269551754,
      "learning_rate": 2.6105534002586357e-05,
      "loss": 0.0753,
      "step": 71720
    },
    {
      "epoch": 1.4344278686557614,
      "grad_norm": 0.16029368340969086,
      "learning_rate": 2.610220106920503e-05,
      "loss": 0.0884,
      "step": 71730
    },
    {
      "epoch": 1.434627844658641,
      "grad_norm": 0.13800927996635437,
      "learning_rate": 2.6098868135823703e-05,
      "loss": 0.114,
      "step": 71740
    },
    {
      "epoch": 1.4348278206615206,
      "grad_norm": 0.16247698664665222,
      "learning_rate": 2.6095535202442372e-05,
      "loss": 0.0739,
      "step": 71750
    },
    {
      "epoch": 1.4350277966644003,
      "grad_norm": 0.12744809687137604,
      "learning_rate": 2.6092202269061045e-05,
      "loss": 0.0918,
      "step": 71760
    },
    {
      "epoch": 1.43522777266728,
      "grad_norm": 0.09531418979167938,
      "learning_rate": 2.608886933567972e-05,
      "loss": 0.0676,
      "step": 71770
    },
    {
      "epoch": 1.4354277486701597,
      "grad_norm": 0.15165066719055176,
      "learning_rate": 2.6085536402298395e-05,
      "loss": 0.1013,
      "step": 71780
    },
    {
      "epoch": 1.4356277246730391,
      "grad_norm": 0.10234580934047699,
      "learning_rate": 2.6082203468917064e-05,
      "loss": 0.0727,
      "step": 71790
    },
    {
      "epoch": 1.4358277006759188,
      "grad_norm": 0.21632660925388336,
      "learning_rate": 2.6078870535535737e-05,
      "loss": 0.0894,
      "step": 71800
    },
    {
      "epoch": 1.4360276766787985,
      "grad_norm": 0.05452490970492363,
      "learning_rate": 2.607553760215441e-05,
      "loss": 0.0551,
      "step": 71810
    },
    {
      "epoch": 1.4362276526816782,
      "grad_norm": 0.049083199352025986,
      "learning_rate": 2.607220466877308e-05,
      "loss": 0.074,
      "step": 71820
    },
    {
      "epoch": 1.4364276286845579,
      "grad_norm": 0.16338039934635162,
      "learning_rate": 2.6068871735391753e-05,
      "loss": 0.2851,
      "step": 71830
    },
    {
      "epoch": 1.4366276046874376,
      "grad_norm": 0.09687824547290802,
      "learning_rate": 2.6065538802010426e-05,
      "loss": 0.0714,
      "step": 71840
    },
    {
      "epoch": 1.4368275806903172,
      "grad_norm": 0.10028206557035446,
      "learning_rate": 2.6062205868629095e-05,
      "loss": 0.073,
      "step": 71850
    },
    {
      "epoch": 1.437027556693197,
      "grad_norm": 0.10366731137037277,
      "learning_rate": 2.605887293524777e-05,
      "loss": 0.0953,
      "step": 71860
    },
    {
      "epoch": 1.4372275326960764,
      "grad_norm": 0.05556301772594452,
      "learning_rate": 2.6055540001866445e-05,
      "loss": 0.0803,
      "step": 71870
    },
    {
      "epoch": 1.437427508698956,
      "grad_norm": 0.10678128153085709,
      "learning_rate": 2.6052207068485118e-05,
      "loss": 0.0329,
      "step": 71880
    },
    {
      "epoch": 1.4376274847018358,
      "grad_norm": 0.1606437712907791,
      "learning_rate": 2.604887413510379e-05,
      "loss": 0.0877,
      "step": 71890
    },
    {
      "epoch": 1.4378274607047155,
      "grad_norm": 0.10174767673015594,
      "learning_rate": 2.6045874495060596e-05,
      "loss": 0.1465,
      "step": 71900
    },
    {
      "epoch": 1.4380274367075951,
      "grad_norm": 0.22756290435791016,
      "learning_rate": 2.604254156167927e-05,
      "loss": 0.0728,
      "step": 71910
    },
    {
      "epoch": 1.4382274127104746,
      "grad_norm": 0.21045300364494324,
      "learning_rate": 2.603920862829794e-05,
      "loss": 0.0752,
      "step": 71920
    },
    {
      "epoch": 1.4384273887133543,
      "grad_norm": 0.1572565734386444,
      "learning_rate": 2.6035875694916612e-05,
      "loss": 0.1064,
      "step": 71930
    },
    {
      "epoch": 1.438627364716234,
      "grad_norm": 0.1534809023141861,
      "learning_rate": 2.6032542761535285e-05,
      "loss": 0.1338,
      "step": 71940
    },
    {
      "epoch": 1.4388273407191137,
      "grad_norm": 0.24094544351100922,
      "learning_rate": 2.6029209828153954e-05,
      "loss": 0.0973,
      "step": 71950
    },
    {
      "epoch": 1.4390273167219934,
      "grad_norm": 0.06341516226530075,
      "learning_rate": 2.6025876894772627e-05,
      "loss": 0.0579,
      "step": 71960
    },
    {
      "epoch": 1.439227292724873,
      "grad_norm": 0.12957730889320374,
      "learning_rate": 2.60225439613913e-05,
      "loss": 0.0753,
      "step": 71970
    },
    {
      "epoch": 1.4394272687277527,
      "grad_norm": 0.19114132225513458,
      "learning_rate": 2.601921102800997e-05,
      "loss": 0.0916,
      "step": 71980
    },
    {
      "epoch": 1.4396272447306324,
      "grad_norm": 0.14099939167499542,
      "learning_rate": 2.601587809462865e-05,
      "loss": 0.0819,
      "step": 71990
    },
    {
      "epoch": 1.439827220733512,
      "grad_norm": 0.15581214427947998,
      "learning_rate": 2.601254516124732e-05,
      "loss": 0.0638,
      "step": 72000
    },
    {
      "epoch": 1.4400271967363916,
      "grad_norm": 0.10663812607526779,
      "learning_rate": 2.6009212227865992e-05,
      "loss": 0.0654,
      "step": 72010
    },
    {
      "epoch": 1.4402271727392713,
      "grad_norm": 0.12064854055643082,
      "learning_rate": 2.6005879294484665e-05,
      "loss": 0.0642,
      "step": 72020
    },
    {
      "epoch": 1.440427148742151,
      "grad_norm": 0.06853581219911575,
      "learning_rate": 2.6002546361103335e-05,
      "loss": 0.0535,
      "step": 72030
    },
    {
      "epoch": 1.4406271247450306,
      "grad_norm": 0.18126368522644043,
      "learning_rate": 2.5999213427722008e-05,
      "loss": 0.088,
      "step": 72040
    },
    {
      "epoch": 1.4408271007479103,
      "grad_norm": 0.1892344355583191,
      "learning_rate": 2.599588049434068e-05,
      "loss": 0.0906,
      "step": 72050
    },
    {
      "epoch": 1.4410270767507898,
      "grad_norm": 0.06755564361810684,
      "learning_rate": 2.599254756095935e-05,
      "loss": 0.0621,
      "step": 72060
    },
    {
      "epoch": 1.4412270527536695,
      "grad_norm": 0.12361950427293777,
      "learning_rate": 2.5989214627578024e-05,
      "loss": 0.0464,
      "step": 72070
    },
    {
      "epoch": 1.4414270287565492,
      "grad_norm": 0.2065262794494629,
      "learning_rate": 2.5985881694196697e-05,
      "loss": 0.0891,
      "step": 72080
    },
    {
      "epoch": 1.4416270047594288,
      "grad_norm": 0.0656580924987793,
      "learning_rate": 2.5982548760815373e-05,
      "loss": 0.0564,
      "step": 72090
    },
    {
      "epoch": 1.4418269807623085,
      "grad_norm": 0.08438853919506073,
      "learning_rate": 2.5979215827434046e-05,
      "loss": 0.099,
      "step": 72100
    },
    {
      "epoch": 1.4420269567651882,
      "grad_norm": 0.14774274826049805,
      "learning_rate": 2.5975882894052716e-05,
      "loss": 0.0621,
      "step": 72110
    },
    {
      "epoch": 1.442226932768068,
      "grad_norm": 0.14502862095832825,
      "learning_rate": 2.597254996067139e-05,
      "loss": 0.0936,
      "step": 72120
    },
    {
      "epoch": 1.4424269087709476,
      "grad_norm": 0.07422789931297302,
      "learning_rate": 2.5969217027290062e-05,
      "loss": 0.0565,
      "step": 72130
    },
    {
      "epoch": 1.4426268847738273,
      "grad_norm": 0.13722360134124756,
      "learning_rate": 2.596588409390873e-05,
      "loss": 0.0862,
      "step": 72140
    },
    {
      "epoch": 1.4428268607767067,
      "grad_norm": 0.07572142034769058,
      "learning_rate": 2.5962551160527404e-05,
      "loss": 0.0709,
      "step": 72150
    },
    {
      "epoch": 1.4430268367795864,
      "grad_norm": 0.08629240840673447,
      "learning_rate": 2.5959218227146077e-05,
      "loss": 0.0586,
      "step": 72160
    },
    {
      "epoch": 1.4432268127824661,
      "grad_norm": 0.13027706742286682,
      "learning_rate": 2.5955885293764747e-05,
      "loss": 0.0567,
      "step": 72170
    },
    {
      "epoch": 1.4434267887853458,
      "grad_norm": 0.07241936773061752,
      "learning_rate": 2.595255236038342e-05,
      "loss": 0.05,
      "step": 72180
    },
    {
      "epoch": 1.4436267647882255,
      "grad_norm": 0.05342111736536026,
      "learning_rate": 2.5949219427002093e-05,
      "loss": 0.0466,
      "step": 72190
    },
    {
      "epoch": 1.443826740791105,
      "grad_norm": 0.09900171309709549,
      "learning_rate": 2.594588649362077e-05,
      "loss": 0.0712,
      "step": 72200
    },
    {
      "epoch": 1.4440267167939846,
      "grad_norm": 0.23530006408691406,
      "learning_rate": 2.5942553560239442e-05,
      "loss": 0.1,
      "step": 72210
    },
    {
      "epoch": 1.4442266927968643,
      "grad_norm": 0.0983792096376419,
      "learning_rate": 2.5939220626858112e-05,
      "loss": 0.0533,
      "step": 72220
    },
    {
      "epoch": 1.444426668799744,
      "grad_norm": 0.10698269307613373,
      "learning_rate": 2.5935887693476785e-05,
      "loss": 0.0805,
      "step": 72230
    },
    {
      "epoch": 1.4446266448026237,
      "grad_norm": 0.07014157623052597,
      "learning_rate": 2.5932554760095458e-05,
      "loss": 0.0566,
      "step": 72240
    },
    {
      "epoch": 1.4448266208055034,
      "grad_norm": 0.12075590342283249,
      "learning_rate": 2.5929221826714128e-05,
      "loss": 0.0693,
      "step": 72250
    },
    {
      "epoch": 1.445026596808383,
      "grad_norm": 0.09906870126724243,
      "learning_rate": 2.59258888933328e-05,
      "loss": 0.0415,
      "step": 72260
    },
    {
      "epoch": 1.4452265728112628,
      "grad_norm": 0.19532480835914612,
      "learning_rate": 2.5922555959951474e-05,
      "loss": 0.1014,
      "step": 72270
    },
    {
      "epoch": 1.4454265488141422,
      "grad_norm": 0.14918825030326843,
      "learning_rate": 2.5919223026570143e-05,
      "loss": 0.1322,
      "step": 72280
    },
    {
      "epoch": 1.445626524817022,
      "grad_norm": 0.22868704795837402,
      "learning_rate": 2.5915890093188816e-05,
      "loss": 0.4924,
      "step": 72290
    },
    {
      "epoch": 1.4458265008199016,
      "grad_norm": 0.2345343381166458,
      "learning_rate": 2.5912557159807493e-05,
      "loss": 0.0696,
      "step": 72300
    },
    {
      "epoch": 1.4460264768227813,
      "grad_norm": 0.09096525609493256,
      "learning_rate": 2.5909224226426166e-05,
      "loss": 0.0807,
      "step": 72310
    },
    {
      "epoch": 1.446226452825661,
      "grad_norm": 0.140725776553154,
      "learning_rate": 2.590589129304484e-05,
      "loss": 0.0577,
      "step": 72320
    },
    {
      "epoch": 1.4464264288285404,
      "grad_norm": 0.22398945689201355,
      "learning_rate": 2.5902558359663508e-05,
      "loss": 0.0782,
      "step": 72330
    },
    {
      "epoch": 1.4466264048314201,
      "grad_norm": 0.1479036808013916,
      "learning_rate": 2.589922542628218e-05,
      "loss": 0.0969,
      "step": 72340
    },
    {
      "epoch": 1.4468263808342998,
      "grad_norm": 0.10203584283590317,
      "learning_rate": 2.5895892492900854e-05,
      "loss": 0.0488,
      "step": 72350
    },
    {
      "epoch": 1.4470263568371795,
      "grad_norm": 0.06568354368209839,
      "learning_rate": 2.5892559559519524e-05,
      "loss": 0.0621,
      "step": 72360
    },
    {
      "epoch": 1.4472263328400592,
      "grad_norm": 0.1505747139453888,
      "learning_rate": 2.5889226626138197e-05,
      "loss": 0.0597,
      "step": 72370
    },
    {
      "epoch": 1.4474263088429389,
      "grad_norm": 0.08641794323921204,
      "learning_rate": 2.588589369275687e-05,
      "loss": 0.0784,
      "step": 72380
    },
    {
      "epoch": 1.4476262848458186,
      "grad_norm": 0.20528294146060944,
      "learning_rate": 2.588256075937554e-05,
      "loss": 0.1055,
      "step": 72390
    },
    {
      "epoch": 1.4478262608486983,
      "grad_norm": 0.08997166156768799,
      "learning_rate": 2.587922782599422e-05,
      "loss": 0.0756,
      "step": 72400
    },
    {
      "epoch": 1.448026236851578,
      "grad_norm": 0.13405421376228333,
      "learning_rate": 2.587589489261289e-05,
      "loss": 0.0849,
      "step": 72410
    },
    {
      "epoch": 1.4482262128544574,
      "grad_norm": 0.11048993468284607,
      "learning_rate": 2.5872561959231562e-05,
      "loss": 0.0715,
      "step": 72420
    },
    {
      "epoch": 1.448426188857337,
      "grad_norm": 0.11457889527082443,
      "learning_rate": 2.5869229025850235e-05,
      "loss": 0.0639,
      "step": 72430
    },
    {
      "epoch": 1.4486261648602168,
      "grad_norm": 0.07059069722890854,
      "learning_rate": 2.5865896092468905e-05,
      "loss": 0.0872,
      "step": 72440
    },
    {
      "epoch": 1.4488261408630965,
      "grad_norm": 0.23958903551101685,
      "learning_rate": 2.5862563159087578e-05,
      "loss": 0.0608,
      "step": 72450
    },
    {
      "epoch": 1.4490261168659762,
      "grad_norm": 0.11611703783273697,
      "learning_rate": 2.585923022570625e-05,
      "loss": 0.0769,
      "step": 72460
    },
    {
      "epoch": 1.4492260928688556,
      "grad_norm": 0.09865260869264603,
      "learning_rate": 2.585589729232492e-05,
      "loss": 0.0608,
      "step": 72470
    },
    {
      "epoch": 1.4494260688717353,
      "grad_norm": 0.251443475484848,
      "learning_rate": 2.5852564358943593e-05,
      "loss": 0.0721,
      "step": 72480
    },
    {
      "epoch": 1.449626044874615,
      "grad_norm": 0.08203553408384323,
      "learning_rate": 2.5849231425562266e-05,
      "loss": 0.084,
      "step": 72490
    },
    {
      "epoch": 1.4498260208774947,
      "grad_norm": 0.1409105658531189,
      "learning_rate": 2.5845898492180943e-05,
      "loss": 0.0577,
      "step": 72500
    },
    {
      "epoch": 1.4500259968803744,
      "grad_norm": 0.06091304123401642,
      "learning_rate": 2.5842565558799616e-05,
      "loss": 0.0415,
      "step": 72510
    },
    {
      "epoch": 1.450225972883254,
      "grad_norm": 0.07034409791231155,
      "learning_rate": 2.5839232625418285e-05,
      "loss": 0.07,
      "step": 72520
    },
    {
      "epoch": 1.4504259488861337,
      "grad_norm": 0.14500635862350464,
      "learning_rate": 2.5835899692036958e-05,
      "loss": 0.0907,
      "step": 72530
    },
    {
      "epoch": 1.4506259248890134,
      "grad_norm": 0.2149244099855423,
      "learning_rate": 2.583256675865563e-05,
      "loss": 0.069,
      "step": 72540
    },
    {
      "epoch": 1.450825900891893,
      "grad_norm": 0.09291300922632217,
      "learning_rate": 2.58292338252743e-05,
      "loss": 0.0811,
      "step": 72550
    },
    {
      "epoch": 1.4510258768947726,
      "grad_norm": 0.14752785861492157,
      "learning_rate": 2.5825900891892974e-05,
      "loss": 0.09,
      "step": 72560
    },
    {
      "epoch": 1.4512258528976523,
      "grad_norm": 0.08077598363161087,
      "learning_rate": 2.5822567958511647e-05,
      "loss": 0.0717,
      "step": 72570
    },
    {
      "epoch": 1.451425828900532,
      "grad_norm": 0.06508523970842361,
      "learning_rate": 2.5819235025130316e-05,
      "loss": 0.0926,
      "step": 72580
    },
    {
      "epoch": 1.4516258049034116,
      "grad_norm": 0.15175767242908478,
      "learning_rate": 2.581590209174899e-05,
      "loss": 0.0564,
      "step": 72590
    },
    {
      "epoch": 1.451825780906291,
      "grad_norm": 0.12714612483978271,
      "learning_rate": 2.5812569158367666e-05,
      "loss": 0.0689,
      "step": 72600
    },
    {
      "epoch": 1.4520257569091708,
      "grad_norm": 0.17715305089950562,
      "learning_rate": 2.580923622498634e-05,
      "loss": 0.0699,
      "step": 72610
    },
    {
      "epoch": 1.4522257329120505,
      "grad_norm": 0.15894600749015808,
      "learning_rate": 2.5805903291605012e-05,
      "loss": 0.0888,
      "step": 72620
    },
    {
      "epoch": 1.4524257089149302,
      "grad_norm": 0.10329462587833405,
      "learning_rate": 2.580257035822368e-05,
      "loss": 0.1038,
      "step": 72630
    },
    {
      "epoch": 1.4526256849178099,
      "grad_norm": 0.24048319458961487,
      "learning_rate": 2.5799237424842354e-05,
      "loss": 0.1124,
      "step": 72640
    },
    {
      "epoch": 1.4528256609206895,
      "grad_norm": 0.151646688580513,
      "learning_rate": 2.5795904491461027e-05,
      "loss": 0.0888,
      "step": 72650
    },
    {
      "epoch": 1.4530256369235692,
      "grad_norm": 0.12233468890190125,
      "learning_rate": 2.5792571558079697e-05,
      "loss": 0.0842,
      "step": 72660
    },
    {
      "epoch": 1.453225612926449,
      "grad_norm": 0.19759918749332428,
      "learning_rate": 2.578923862469837e-05,
      "loss": 0.0957,
      "step": 72670
    },
    {
      "epoch": 1.4534255889293286,
      "grad_norm": 0.09184616059064865,
      "learning_rate": 2.5785905691317043e-05,
      "loss": 0.0742,
      "step": 72680
    },
    {
      "epoch": 1.453625564932208,
      "grad_norm": 0.1079465001821518,
      "learning_rate": 2.5782572757935713e-05,
      "loss": 0.0586,
      "step": 72690
    },
    {
      "epoch": 1.4538255409350878,
      "grad_norm": 0.10979566723108292,
      "learning_rate": 2.5779239824554386e-05,
      "loss": 0.0825,
      "step": 72700
    },
    {
      "epoch": 1.4540255169379674,
      "grad_norm": 0.07667980343103409,
      "learning_rate": 2.5775906891173062e-05,
      "loss": 0.0901,
      "step": 72710
    },
    {
      "epoch": 1.4542254929408471,
      "grad_norm": 0.1575089693069458,
      "learning_rate": 2.5772573957791735e-05,
      "loss": 0.1201,
      "step": 72720
    },
    {
      "epoch": 1.4544254689437268,
      "grad_norm": 0.116360142827034,
      "learning_rate": 2.5769241024410408e-05,
      "loss": 0.044,
      "step": 72730
    },
    {
      "epoch": 1.4546254449466063,
      "grad_norm": 0.13386982679367065,
      "learning_rate": 2.5765908091029078e-05,
      "loss": 0.0632,
      "step": 72740
    },
    {
      "epoch": 1.454825420949486,
      "grad_norm": 0.21714846789836884,
      "learning_rate": 2.576257515764775e-05,
      "loss": 0.108,
      "step": 72750
    },
    {
      "epoch": 1.4550253969523657,
      "grad_norm": 0.13603191077709198,
      "learning_rate": 2.5759242224266424e-05,
      "loss": 0.065,
      "step": 72760
    },
    {
      "epoch": 1.4552253729552453,
      "grad_norm": 0.1600925326347351,
      "learning_rate": 2.5755909290885093e-05,
      "loss": 0.0873,
      "step": 72770
    },
    {
      "epoch": 1.455425348958125,
      "grad_norm": 0.09111718088388443,
      "learning_rate": 2.5752576357503766e-05,
      "loss": 0.1138,
      "step": 72780
    },
    {
      "epoch": 1.4556253249610047,
      "grad_norm": 0.09808345139026642,
      "learning_rate": 2.574924342412244e-05,
      "loss": 0.0643,
      "step": 72790
    },
    {
      "epoch": 1.4558253009638844,
      "grad_norm": 0.1366792619228363,
      "learning_rate": 2.574591049074111e-05,
      "loss": 0.0351,
      "step": 72800
    },
    {
      "epoch": 1.456025276966764,
      "grad_norm": 0.0798821821808815,
      "learning_rate": 2.574257755735979e-05,
      "loss": 0.0714,
      "step": 72810
    },
    {
      "epoch": 1.4562252529696438,
      "grad_norm": 0.10041128098964691,
      "learning_rate": 2.573924462397846e-05,
      "loss": 0.0977,
      "step": 72820
    },
    {
      "epoch": 1.4564252289725232,
      "grad_norm": 0.12218914180994034,
      "learning_rate": 2.573591169059713e-05,
      "loss": 0.0502,
      "step": 72830
    },
    {
      "epoch": 1.456625204975403,
      "grad_norm": 0.08177110552787781,
      "learning_rate": 2.5732578757215804e-05,
      "loss": 0.0619,
      "step": 72840
    },
    {
      "epoch": 1.4568251809782826,
      "grad_norm": 0.25635406374931335,
      "learning_rate": 2.5729245823834474e-05,
      "loss": 0.0766,
      "step": 72850
    },
    {
      "epoch": 1.4570251569811623,
      "grad_norm": 0.1712532490491867,
      "learning_rate": 2.5725912890453147e-05,
      "loss": 0.0661,
      "step": 72860
    },
    {
      "epoch": 1.457225132984042,
      "grad_norm": 0.09693046659231186,
      "learning_rate": 2.572257995707182e-05,
      "loss": 0.0905,
      "step": 72870
    },
    {
      "epoch": 1.4574251089869215,
      "grad_norm": 0.09609635174274445,
      "learning_rate": 2.571924702369049e-05,
      "loss": 0.0998,
      "step": 72880
    },
    {
      "epoch": 1.4576250849898011,
      "grad_norm": 0.25637897849082947,
      "learning_rate": 2.5715914090309163e-05,
      "loss": 0.1173,
      "step": 72890
    },
    {
      "epoch": 1.4578250609926808,
      "grad_norm": 0.11731886118650436,
      "learning_rate": 2.5712581156927836e-05,
      "loss": 0.0371,
      "step": 72900
    },
    {
      "epoch": 1.4580250369955605,
      "grad_norm": 0.12840865552425385,
      "learning_rate": 2.5709248223546512e-05,
      "loss": 0.1028,
      "step": 72910
    },
    {
      "epoch": 1.4582250129984402,
      "grad_norm": 0.05001657083630562,
      "learning_rate": 2.5705915290165185e-05,
      "loss": 0.0728,
      "step": 72920
    },
    {
      "epoch": 1.45842498900132,
      "grad_norm": 0.0964297205209732,
      "learning_rate": 2.5702582356783855e-05,
      "loss": 0.0433,
      "step": 72930
    },
    {
      "epoch": 1.4586249650041996,
      "grad_norm": 0.24534820020198822,
      "learning_rate": 2.5699249423402528e-05,
      "loss": 0.1096,
      "step": 72940
    },
    {
      "epoch": 1.4588249410070793,
      "grad_norm": 0.14861510694026947,
      "learning_rate": 2.56959164900212e-05,
      "loss": 0.0695,
      "step": 72950
    },
    {
      "epoch": 1.4590249170099587,
      "grad_norm": 0.0962090864777565,
      "learning_rate": 2.569258355663987e-05,
      "loss": 0.0477,
      "step": 72960
    },
    {
      "epoch": 1.4592248930128384,
      "grad_norm": 0.23569251596927643,
      "learning_rate": 2.5689250623258543e-05,
      "loss": 0.0857,
      "step": 72970
    },
    {
      "epoch": 1.459424869015718,
      "grad_norm": 0.1741567850112915,
      "learning_rate": 2.5685917689877216e-05,
      "loss": 0.0592,
      "step": 72980
    },
    {
      "epoch": 1.4596248450185978,
      "grad_norm": 0.09394282102584839,
      "learning_rate": 2.5682584756495886e-05,
      "loss": 0.0733,
      "step": 72990
    },
    {
      "epoch": 1.4598248210214775,
      "grad_norm": 0.11618465185165405,
      "learning_rate": 2.567925182311456e-05,
      "loss": 0.117,
      "step": 73000
    },
    {
      "epoch": 1.460024797024357,
      "grad_norm": 0.2060898244380951,
      "learning_rate": 2.5675918889733235e-05,
      "loss": 0.0895,
      "step": 73010
    },
    {
      "epoch": 1.4602247730272366,
      "grad_norm": 0.1584266573190689,
      "learning_rate": 2.5672585956351908e-05,
      "loss": 0.0585,
      "step": 73020
    },
    {
      "epoch": 1.4604247490301163,
      "grad_norm": 0.06767447292804718,
      "learning_rate": 2.566925302297058e-05,
      "loss": 0.0472,
      "step": 73030
    },
    {
      "epoch": 1.460624725032996,
      "grad_norm": 0.12532249093055725,
      "learning_rate": 2.566592008958925e-05,
      "loss": 0.0462,
      "step": 73040
    },
    {
      "epoch": 1.4608247010358757,
      "grad_norm": 0.16098186373710632,
      "learning_rate": 2.5662587156207924e-05,
      "loss": 0.0781,
      "step": 73050
    },
    {
      "epoch": 1.4610246770387554,
      "grad_norm": 0.11601147800683975,
      "learning_rate": 2.5659254222826597e-05,
      "loss": 0.0817,
      "step": 73060
    },
    {
      "epoch": 1.461224653041635,
      "grad_norm": 0.17198899388313293,
      "learning_rate": 2.5655921289445266e-05,
      "loss": 0.103,
      "step": 73070
    },
    {
      "epoch": 1.4614246290445148,
      "grad_norm": 0.17283105850219727,
      "learning_rate": 2.565258835606394e-05,
      "loss": 0.0851,
      "step": 73080
    },
    {
      "epoch": 1.4616246050473944,
      "grad_norm": 0.18351060152053833,
      "learning_rate": 2.5649255422682612e-05,
      "loss": 0.07,
      "step": 73090
    },
    {
      "epoch": 1.461824581050274,
      "grad_norm": 0.1909589171409607,
      "learning_rate": 2.5645922489301282e-05,
      "loss": 0.0844,
      "step": 73100
    },
    {
      "epoch": 1.4620245570531536,
      "grad_norm": 0.056900233030319214,
      "learning_rate": 2.5642589555919962e-05,
      "loss": 0.0571,
      "step": 73110
    },
    {
      "epoch": 1.4622245330560333,
      "grad_norm": 0.25929224491119385,
      "learning_rate": 2.563925662253863e-05,
      "loss": 0.0744,
      "step": 73120
    },
    {
      "epoch": 1.462424509058913,
      "grad_norm": 0.07188569754362106,
      "learning_rate": 2.5635923689157305e-05,
      "loss": 0.0508,
      "step": 73130
    },
    {
      "epoch": 1.4626244850617927,
      "grad_norm": 0.22961807250976562,
      "learning_rate": 2.5632590755775978e-05,
      "loss": 0.1054,
      "step": 73140
    },
    {
      "epoch": 1.4628244610646721,
      "grad_norm": 0.06970936805009842,
      "learning_rate": 2.5629257822394647e-05,
      "loss": 0.0534,
      "step": 73150
    },
    {
      "epoch": 1.4630244370675518,
      "grad_norm": 0.1579122692346573,
      "learning_rate": 2.562592488901332e-05,
      "loss": 0.0613,
      "step": 73160
    },
    {
      "epoch": 1.4632244130704315,
      "grad_norm": 0.20298562943935394,
      "learning_rate": 2.5622591955631993e-05,
      "loss": 0.0698,
      "step": 73170
    },
    {
      "epoch": 1.4634243890733112,
      "grad_norm": 0.11539655178785324,
      "learning_rate": 2.5619259022250663e-05,
      "loss": 0.0757,
      "step": 73180
    },
    {
      "epoch": 1.4636243650761909,
      "grad_norm": 0.08213896304368973,
      "learning_rate": 2.5615926088869336e-05,
      "loss": 0.0969,
      "step": 73190
    },
    {
      "epoch": 1.4638243410790706,
      "grad_norm": 0.0940362811088562,
      "learning_rate": 2.561259315548801e-05,
      "loss": 0.0841,
      "step": 73200
    },
    {
      "epoch": 1.4640243170819502,
      "grad_norm": 0.07762233167886734,
      "learning_rate": 2.560926022210668e-05,
      "loss": 0.0758,
      "step": 73210
    },
    {
      "epoch": 1.46422429308483,
      "grad_norm": 0.19750405848026276,
      "learning_rate": 2.5605927288725358e-05,
      "loss": 0.0839,
      "step": 73220
    },
    {
      "epoch": 1.4644242690877094,
      "grad_norm": 0.11013087630271912,
      "learning_rate": 2.5602594355344028e-05,
      "loss": 0.0697,
      "step": 73230
    },
    {
      "epoch": 1.464624245090589,
      "grad_norm": 0.06617213785648346,
      "learning_rate": 2.55992614219627e-05,
      "loss": 0.0816,
      "step": 73240
    },
    {
      "epoch": 1.4648242210934688,
      "grad_norm": 0.12002062797546387,
      "learning_rate": 2.5595928488581374e-05,
      "loss": 0.0868,
      "step": 73250
    },
    {
      "epoch": 1.4650241970963485,
      "grad_norm": 0.10572883486747742,
      "learning_rate": 2.5592595555200043e-05,
      "loss": 0.0905,
      "step": 73260
    },
    {
      "epoch": 1.4652241730992281,
      "grad_norm": 0.06780701875686646,
      "learning_rate": 2.5589262621818716e-05,
      "loss": 0.0966,
      "step": 73270
    },
    {
      "epoch": 1.4654241491021076,
      "grad_norm": 0.10278317332267761,
      "learning_rate": 2.558592968843739e-05,
      "loss": 0.0653,
      "step": 73280
    },
    {
      "epoch": 1.4656241251049873,
      "grad_norm": 0.08353687077760696,
      "learning_rate": 2.558259675505606e-05,
      "loss": 0.1299,
      "step": 73290
    },
    {
      "epoch": 1.465824101107867,
      "grad_norm": 0.1339072436094284,
      "learning_rate": 2.5579263821674732e-05,
      "loss": 0.0635,
      "step": 73300
    },
    {
      "epoch": 1.4660240771107467,
      "grad_norm": 0.0959077700972557,
      "learning_rate": 2.5575930888293405e-05,
      "loss": 0.0538,
      "step": 73310
    },
    {
      "epoch": 1.4662240531136264,
      "grad_norm": 0.08538351207971573,
      "learning_rate": 2.557259795491208e-05,
      "loss": 0.0758,
      "step": 73320
    },
    {
      "epoch": 1.466424029116506,
      "grad_norm": 0.21784305572509766,
      "learning_rate": 2.5569265021530754e-05,
      "loss": 0.0676,
      "step": 73330
    },
    {
      "epoch": 1.4666240051193857,
      "grad_norm": 0.05561076104640961,
      "learning_rate": 2.5565932088149424e-05,
      "loss": 0.0521,
      "step": 73340
    },
    {
      "epoch": 1.4668239811222654,
      "grad_norm": 0.1625080555677414,
      "learning_rate": 2.5562599154768097e-05,
      "loss": 0.0442,
      "step": 73350
    },
    {
      "epoch": 1.467023957125145,
      "grad_norm": 0.1394788771867752,
      "learning_rate": 2.555926622138677e-05,
      "loss": 0.1013,
      "step": 73360
    },
    {
      "epoch": 1.4672239331280246,
      "grad_norm": 0.16993750631809235,
      "learning_rate": 2.555593328800544e-05,
      "loss": 0.0422,
      "step": 73370
    },
    {
      "epoch": 1.4674239091309043,
      "grad_norm": 0.20738090574741364,
      "learning_rate": 2.5552600354624113e-05,
      "loss": 0.0506,
      "step": 73380
    },
    {
      "epoch": 1.467623885133784,
      "grad_norm": 0.15635435283184052,
      "learning_rate": 2.5549267421242786e-05,
      "loss": 0.0741,
      "step": 73390
    },
    {
      "epoch": 1.4678238611366636,
      "grad_norm": 0.14109672605991364,
      "learning_rate": 2.5545934487861455e-05,
      "loss": 0.078,
      "step": 73400
    },
    {
      "epoch": 1.4680238371395433,
      "grad_norm": 0.08426015824079514,
      "learning_rate": 2.5542601554480128e-05,
      "loss": 0.0433,
      "step": 73410
    },
    {
      "epoch": 1.4682238131424228,
      "grad_norm": 0.08652761578559875,
      "learning_rate": 2.5539268621098805e-05,
      "loss": 0.0703,
      "step": 73420
    },
    {
      "epoch": 1.4684237891453025,
      "grad_norm": 0.11400263756513596,
      "learning_rate": 2.5535935687717478e-05,
      "loss": 0.0553,
      "step": 73430
    },
    {
      "epoch": 1.4686237651481822,
      "grad_norm": 0.08727304637432098,
      "learning_rate": 2.553260275433615e-05,
      "loss": 0.0752,
      "step": 73440
    },
    {
      "epoch": 1.4688237411510618,
      "grad_norm": 0.11947618424892426,
      "learning_rate": 2.552926982095482e-05,
      "loss": 0.0444,
      "step": 73450
    },
    {
      "epoch": 1.4690237171539415,
      "grad_norm": 0.18447810411453247,
      "learning_rate": 2.5525936887573493e-05,
      "loss": 0.1147,
      "step": 73460
    },
    {
      "epoch": 1.4692236931568212,
      "grad_norm": 0.11265312880277634,
      "learning_rate": 2.5522603954192166e-05,
      "loss": 0.1061,
      "step": 73470
    },
    {
      "epoch": 1.469423669159701,
      "grad_norm": 0.12568224966526031,
      "learning_rate": 2.5519271020810836e-05,
      "loss": 0.0773,
      "step": 73480
    },
    {
      "epoch": 1.4696236451625806,
      "grad_norm": 0.11775537580251694,
      "learning_rate": 2.551593808742951e-05,
      "loss": 0.1323,
      "step": 73490
    },
    {
      "epoch": 1.4698236211654603,
      "grad_norm": 0.06908128410577774,
      "learning_rate": 2.5512605154048182e-05,
      "loss": 0.0696,
      "step": 73500
    },
    {
      "epoch": 1.4700235971683397,
      "grad_norm": 0.1342666745185852,
      "learning_rate": 2.550927222066685e-05,
      "loss": 0.06,
      "step": 73510
    },
    {
      "epoch": 1.4702235731712194,
      "grad_norm": 0.12344671040773392,
      "learning_rate": 2.5505939287285528e-05,
      "loss": 0.0519,
      "step": 73520
    },
    {
      "epoch": 1.4704235491740991,
      "grad_norm": 0.09251036494970322,
      "learning_rate": 2.55026063539042e-05,
      "loss": 0.0648,
      "step": 73530
    },
    {
      "epoch": 1.4706235251769788,
      "grad_norm": 0.14296041429042816,
      "learning_rate": 2.5499273420522874e-05,
      "loss": 0.1324,
      "step": 73540
    },
    {
      "epoch": 1.4708235011798585,
      "grad_norm": 0.08893314003944397,
      "learning_rate": 2.5495940487141544e-05,
      "loss": 0.0918,
      "step": 73550
    },
    {
      "epoch": 1.471023477182738,
      "grad_norm": 0.1354890763759613,
      "learning_rate": 2.5492607553760217e-05,
      "loss": 0.0883,
      "step": 73560
    },
    {
      "epoch": 1.4712234531856176,
      "grad_norm": 0.27501755952835083,
      "learning_rate": 2.548927462037889e-05,
      "loss": 0.0881,
      "step": 73570
    },
    {
      "epoch": 1.4714234291884973,
      "grad_norm": 0.25702592730522156,
      "learning_rate": 2.5485941686997563e-05,
      "loss": 0.1304,
      "step": 73580
    },
    {
      "epoch": 1.471623405191377,
      "grad_norm": 0.12996715307235718,
      "learning_rate": 2.5482608753616232e-05,
      "loss": 0.0745,
      "step": 73590
    },
    {
      "epoch": 1.4718233811942567,
      "grad_norm": 0.14284616708755493,
      "learning_rate": 2.5479275820234905e-05,
      "loss": 0.0681,
      "step": 73600
    },
    {
      "epoch": 1.4720233571971364,
      "grad_norm": 0.12603525817394257,
      "learning_rate": 2.5475942886853578e-05,
      "loss": 0.0707,
      "step": 73610
    },
    {
      "epoch": 1.472223333200016,
      "grad_norm": 0.06854749470949173,
      "learning_rate": 2.5472609953472255e-05,
      "loss": 0.0672,
      "step": 73620
    },
    {
      "epoch": 1.4724233092028958,
      "grad_norm": 0.1777951866388321,
      "learning_rate": 2.5469277020090924e-05,
      "loss": 0.1176,
      "step": 73630
    },
    {
      "epoch": 1.4726232852057752,
      "grad_norm": 0.14780081808567047,
      "learning_rate": 2.5465944086709597e-05,
      "loss": 0.0581,
      "step": 73640
    },
    {
      "epoch": 1.472823261208655,
      "grad_norm": 0.10296756774187088,
      "learning_rate": 2.546261115332827e-05,
      "loss": 0.0593,
      "step": 73650
    },
    {
      "epoch": 1.4730232372115346,
      "grad_norm": 0.08471082895994186,
      "learning_rate": 2.545927821994694e-05,
      "loss": 0.3024,
      "step": 73660
    },
    {
      "epoch": 1.4732232132144143,
      "grad_norm": 0.1332245022058487,
      "learning_rate": 2.5455945286565613e-05,
      "loss": 0.0656,
      "step": 73670
    },
    {
      "epoch": 1.473423189217294,
      "grad_norm": 0.0986265316605568,
      "learning_rate": 2.5452612353184286e-05,
      "loss": 0.0626,
      "step": 73680
    },
    {
      "epoch": 1.4736231652201734,
      "grad_norm": 0.07818631082773209,
      "learning_rate": 2.5449279419802955e-05,
      "loss": 0.0551,
      "step": 73690
    },
    {
      "epoch": 1.4738231412230531,
      "grad_norm": 0.08422479778528214,
      "learning_rate": 2.544594648642163e-05,
      "loss": 0.0738,
      "step": 73700
    },
    {
      "epoch": 1.4740231172259328,
      "grad_norm": 0.20754341781139374,
      "learning_rate": 2.54426135530403e-05,
      "loss": 0.0649,
      "step": 73710
    },
    {
      "epoch": 1.4742230932288125,
      "grad_norm": 0.17616210877895355,
      "learning_rate": 2.5439280619658974e-05,
      "loss": 0.0882,
      "step": 73720
    },
    {
      "epoch": 1.4744230692316922,
      "grad_norm": 0.05903472751379013,
      "learning_rate": 2.543594768627765e-05,
      "loss": 0.0619,
      "step": 73730
    },
    {
      "epoch": 1.4746230452345719,
      "grad_norm": 0.2751583755016327,
      "learning_rate": 2.543261475289632e-05,
      "loss": 0.101,
      "step": 73740
    },
    {
      "epoch": 1.4748230212374516,
      "grad_norm": 0.08215782046318054,
      "learning_rate": 2.5429281819514993e-05,
      "loss": 0.0829,
      "step": 73750
    },
    {
      "epoch": 1.4750229972403313,
      "grad_norm": 0.08854401856660843,
      "learning_rate": 2.5425948886133666e-05,
      "loss": 0.065,
      "step": 73760
    },
    {
      "epoch": 1.475222973243211,
      "grad_norm": 0.17701829969882965,
      "learning_rate": 2.5422615952752336e-05,
      "loss": 0.094,
      "step": 73770
    },
    {
      "epoch": 1.4754229492460904,
      "grad_norm": 0.09921368211507797,
      "learning_rate": 2.541928301937101e-05,
      "loss": 0.1577,
      "step": 73780
    },
    {
      "epoch": 1.47562292524897,
      "grad_norm": 0.07448863983154297,
      "learning_rate": 2.5415950085989682e-05,
      "loss": 0.075,
      "step": 73790
    },
    {
      "epoch": 1.4758229012518498,
      "grad_norm": 0.12470625340938568,
      "learning_rate": 2.5412617152608352e-05,
      "loss": 0.0592,
      "step": 73800
    },
    {
      "epoch": 1.4760228772547295,
      "grad_norm": 0.19521185755729675,
      "learning_rate": 2.5409284219227025e-05,
      "loss": 0.0639,
      "step": 73810
    },
    {
      "epoch": 1.4762228532576092,
      "grad_norm": 0.05556374043226242,
      "learning_rate": 2.5405951285845698e-05,
      "loss": 0.0713,
      "step": 73820
    },
    {
      "epoch": 1.4764228292604886,
      "grad_norm": 0.16640393435955048,
      "learning_rate": 2.5402618352464374e-05,
      "loss": 0.0897,
      "step": 73830
    },
    {
      "epoch": 1.4766228052633683,
      "grad_norm": 0.10604002326726913,
      "learning_rate": 2.5399285419083047e-05,
      "loss": 0.0441,
      "step": 73840
    },
    {
      "epoch": 1.476822781266248,
      "grad_norm": 0.11395526677370071,
      "learning_rate": 2.5395952485701717e-05,
      "loss": 0.0736,
      "step": 73850
    },
    {
      "epoch": 1.4770227572691277,
      "grad_norm": 0.15923155844211578,
      "learning_rate": 2.539261955232039e-05,
      "loss": 0.057,
      "step": 73860
    },
    {
      "epoch": 1.4772227332720074,
      "grad_norm": 0.19501033425331116,
      "learning_rate": 2.5389286618939063e-05,
      "loss": 0.0964,
      "step": 73870
    },
    {
      "epoch": 1.477422709274887,
      "grad_norm": 0.10269978642463684,
      "learning_rate": 2.5385953685557732e-05,
      "loss": 0.0641,
      "step": 73880
    },
    {
      "epoch": 1.4776226852777667,
      "grad_norm": 0.2921215891838074,
      "learning_rate": 2.5382620752176405e-05,
      "loss": 0.1235,
      "step": 73890
    },
    {
      "epoch": 1.4778226612806464,
      "grad_norm": 0.1813175082206726,
      "learning_rate": 2.537928781879508e-05,
      "loss": 0.0961,
      "step": 73900
    },
    {
      "epoch": 1.478022637283526,
      "grad_norm": 0.09192974865436554,
      "learning_rate": 2.5375954885413748e-05,
      "loss": 0.0381,
      "step": 73910
    },
    {
      "epoch": 1.4782226132864056,
      "grad_norm": 0.15707090497016907,
      "learning_rate": 2.537262195203242e-05,
      "loss": 0.0617,
      "step": 73920
    },
    {
      "epoch": 1.4784225892892853,
      "grad_norm": 0.09852931648492813,
      "learning_rate": 2.5369289018651097e-05,
      "loss": 0.0795,
      "step": 73930
    },
    {
      "epoch": 1.478622565292165,
      "grad_norm": 0.16338768601417542,
      "learning_rate": 2.536595608526977e-05,
      "loss": 0.0638,
      "step": 73940
    },
    {
      "epoch": 1.4788225412950446,
      "grad_norm": 0.17652365565299988,
      "learning_rate": 2.5362623151888443e-05,
      "loss": 0.0724,
      "step": 73950
    },
    {
      "epoch": 1.479022517297924,
      "grad_norm": 0.07446642965078354,
      "learning_rate": 2.5359290218507113e-05,
      "loss": 0.0623,
      "step": 73960
    },
    {
      "epoch": 1.4792224933008038,
      "grad_norm": 0.23243774473667145,
      "learning_rate": 2.5355957285125786e-05,
      "loss": 0.0873,
      "step": 73970
    },
    {
      "epoch": 1.4794224693036835,
      "grad_norm": 0.10720095038414001,
      "learning_rate": 2.535262435174446e-05,
      "loss": 0.0812,
      "step": 73980
    },
    {
      "epoch": 1.4796224453065632,
      "grad_norm": 0.15236085653305054,
      "learning_rate": 2.534929141836313e-05,
      "loss": 0.0447,
      "step": 73990
    },
    {
      "epoch": 1.4798224213094429,
      "grad_norm": 0.07046069204807281,
      "learning_rate": 2.53459584849818e-05,
      "loss": 0.059,
      "step": 74000
    },
    {
      "epoch": 1.4800223973123225,
      "grad_norm": 0.1618562638759613,
      "learning_rate": 2.5342625551600475e-05,
      "loss": 0.0863,
      "step": 74010
    },
    {
      "epoch": 1.4802223733152022,
      "grad_norm": 0.12032525986433029,
      "learning_rate": 2.5339292618219144e-05,
      "loss": 0.1009,
      "step": 74020
    },
    {
      "epoch": 1.480422349318082,
      "grad_norm": 0.23445317149162292,
      "learning_rate": 2.5335959684837824e-05,
      "loss": 0.0907,
      "step": 74030
    },
    {
      "epoch": 1.4806223253209616,
      "grad_norm": 0.1454624980688095,
      "learning_rate": 2.5332626751456494e-05,
      "loss": 0.0597,
      "step": 74040
    },
    {
      "epoch": 1.480822301323841,
      "grad_norm": 0.10890547931194305,
      "learning_rate": 2.5329293818075167e-05,
      "loss": 0.0451,
      "step": 74050
    },
    {
      "epoch": 1.4810222773267208,
      "grad_norm": 0.25066372752189636,
      "learning_rate": 2.532596088469384e-05,
      "loss": 0.1084,
      "step": 74060
    },
    {
      "epoch": 1.4812222533296004,
      "grad_norm": 0.08116019517183304,
      "learning_rate": 2.532262795131251e-05,
      "loss": 0.0627,
      "step": 74070
    },
    {
      "epoch": 1.4814222293324801,
      "grad_norm": 0.1458773910999298,
      "learning_rate": 2.5319295017931182e-05,
      "loss": 0.0699,
      "step": 74080
    },
    {
      "epoch": 1.4816222053353598,
      "grad_norm": 0.0550353117287159,
      "learning_rate": 2.5315962084549855e-05,
      "loss": 0.0878,
      "step": 74090
    },
    {
      "epoch": 1.4818221813382393,
      "grad_norm": 0.18961367011070251,
      "learning_rate": 2.5312629151168525e-05,
      "loss": 0.0693,
      "step": 74100
    },
    {
      "epoch": 1.482022157341119,
      "grad_norm": 0.15761956572532654,
      "learning_rate": 2.5309296217787198e-05,
      "loss": 0.0692,
      "step": 74110
    },
    {
      "epoch": 1.4822221333439987,
      "grad_norm": 0.23547689616680145,
      "learning_rate": 2.530596328440587e-05,
      "loss": 0.088,
      "step": 74120
    },
    {
      "epoch": 1.4824221093468783,
      "grad_norm": 0.08390892297029495,
      "learning_rate": 2.5302630351024547e-05,
      "loss": 0.0806,
      "step": 74130
    },
    {
      "epoch": 1.482622085349758,
      "grad_norm": 0.07088073343038559,
      "learning_rate": 2.529929741764322e-05,
      "loss": 0.05,
      "step": 74140
    },
    {
      "epoch": 1.4828220613526377,
      "grad_norm": 0.1741231232881546,
      "learning_rate": 2.529596448426189e-05,
      "loss": 0.0529,
      "step": 74150
    },
    {
      "epoch": 1.4830220373555174,
      "grad_norm": 0.1330723613500595,
      "learning_rate": 2.5292631550880563e-05,
      "loss": 0.0768,
      "step": 74160
    },
    {
      "epoch": 1.483222013358397,
      "grad_norm": 0.2256339192390442,
      "learning_rate": 2.5289298617499236e-05,
      "loss": 0.0986,
      "step": 74170
    },
    {
      "epoch": 1.4834219893612768,
      "grad_norm": 0.13511162996292114,
      "learning_rate": 2.5285965684117906e-05,
      "loss": 0.086,
      "step": 74180
    },
    {
      "epoch": 1.4836219653641562,
      "grad_norm": 0.04567231237888336,
      "learning_rate": 2.528263275073658e-05,
      "loss": 0.0429,
      "step": 74190
    },
    {
      "epoch": 1.483821941367036,
      "grad_norm": 0.09576310962438583,
      "learning_rate": 2.527929981735525e-05,
      "loss": 0.0917,
      "step": 74200
    },
    {
      "epoch": 1.4840219173699156,
      "grad_norm": 0.22526870667934418,
      "learning_rate": 2.527596688397392e-05,
      "loss": 0.0789,
      "step": 74210
    },
    {
      "epoch": 1.4842218933727953,
      "grad_norm": 0.06518875807523727,
      "learning_rate": 2.5272633950592594e-05,
      "loss": 0.0793,
      "step": 74220
    },
    {
      "epoch": 1.484421869375675,
      "grad_norm": 0.1429002583026886,
      "learning_rate": 2.5269301017211267e-05,
      "loss": 0.0739,
      "step": 74230
    },
    {
      "epoch": 1.4846218453785545,
      "grad_norm": 0.06909593194723129,
      "learning_rate": 2.5265968083829944e-05,
      "loss": 0.0773,
      "step": 74240
    },
    {
      "epoch": 1.4848218213814341,
      "grad_norm": 0.10678524523973465,
      "learning_rate": 2.5262635150448617e-05,
      "loss": 0.0771,
      "step": 74250
    },
    {
      "epoch": 1.4850217973843138,
      "grad_norm": 0.1851542443037033,
      "learning_rate": 2.5259302217067286e-05,
      "loss": 0.0511,
      "step": 74260
    },
    {
      "epoch": 1.4852217733871935,
      "grad_norm": 0.10855768620967865,
      "learning_rate": 2.525596928368596e-05,
      "loss": 0.0504,
      "step": 74270
    },
    {
      "epoch": 1.4854217493900732,
      "grad_norm": 0.09207209944725037,
      "learning_rate": 2.5252636350304632e-05,
      "loss": 0.0571,
      "step": 74280
    },
    {
      "epoch": 1.485621725392953,
      "grad_norm": 0.19432401657104492,
      "learning_rate": 2.5249303416923302e-05,
      "loss": 0.0959,
      "step": 74290
    },
    {
      "epoch": 1.4858217013958326,
      "grad_norm": 0.10962926596403122,
      "learning_rate": 2.5245970483541975e-05,
      "loss": 0.0859,
      "step": 74300
    },
    {
      "epoch": 1.4860216773987123,
      "grad_norm": 0.12071096152067184,
      "learning_rate": 2.5242637550160648e-05,
      "loss": 0.0832,
      "step": 74310
    },
    {
      "epoch": 1.4862216534015917,
      "grad_norm": 0.13612322509288788,
      "learning_rate": 2.5239304616779317e-05,
      "loss": 0.0652,
      "step": 74320
    },
    {
      "epoch": 1.4864216294044714,
      "grad_norm": 0.11759647727012634,
      "learning_rate": 2.523597168339799e-05,
      "loss": 0.046,
      "step": 74330
    },
    {
      "epoch": 1.486621605407351,
      "grad_norm": 0.17831730842590332,
      "learning_rate": 2.5232638750016667e-05,
      "loss": 0.0614,
      "step": 74340
    },
    {
      "epoch": 1.4868215814102308,
      "grad_norm": 0.0965551808476448,
      "learning_rate": 2.522930581663534e-05,
      "loss": 0.0511,
      "step": 74350
    },
    {
      "epoch": 1.4870215574131105,
      "grad_norm": 0.11358508467674255,
      "learning_rate": 2.5225972883254013e-05,
      "loss": 0.0503,
      "step": 74360
    },
    {
      "epoch": 1.48722153341599,
      "grad_norm": 0.1277298480272293,
      "learning_rate": 2.5222639949872682e-05,
      "loss": 0.0773,
      "step": 74370
    },
    {
      "epoch": 1.4874215094188696,
      "grad_norm": 0.06295052915811539,
      "learning_rate": 2.5219307016491355e-05,
      "loss": 0.0584,
      "step": 74380
    },
    {
      "epoch": 1.4876214854217493,
      "grad_norm": 0.16790246963500977,
      "learning_rate": 2.521597408311003e-05,
      "loss": 0.0721,
      "step": 74390
    },
    {
      "epoch": 1.487821461424629,
      "grad_norm": 0.1647852212190628,
      "learning_rate": 2.5212641149728698e-05,
      "loss": 0.0891,
      "step": 74400
    },
    {
      "epoch": 1.4880214374275087,
      "grad_norm": 0.07927638292312622,
      "learning_rate": 2.520930821634737e-05,
      "loss": 0.0378,
      "step": 74410
    },
    {
      "epoch": 1.4882214134303884,
      "grad_norm": 0.07333571463823318,
      "learning_rate": 2.5205975282966044e-05,
      "loss": 0.0636,
      "step": 74420
    },
    {
      "epoch": 1.488421389433268,
      "grad_norm": 0.11746812611818314,
      "learning_rate": 2.5202642349584714e-05,
      "loss": 0.0683,
      "step": 74430
    },
    {
      "epoch": 1.4886213654361478,
      "grad_norm": 0.12585709989070892,
      "learning_rate": 2.5199309416203394e-05,
      "loss": 0.0914,
      "step": 74440
    },
    {
      "epoch": 1.4888213414390274,
      "grad_norm": 0.13089537620544434,
      "learning_rate": 2.5195976482822063e-05,
      "loss": 0.0675,
      "step": 74450
    },
    {
      "epoch": 1.489021317441907,
      "grad_norm": 0.12053902447223663,
      "learning_rate": 2.5192643549440736e-05,
      "loss": 0.075,
      "step": 74460
    },
    {
      "epoch": 1.4892212934447866,
      "grad_norm": 0.09698427468538284,
      "learning_rate": 2.518931061605941e-05,
      "loss": 0.0774,
      "step": 74470
    },
    {
      "epoch": 1.4894212694476663,
      "grad_norm": 0.23967432975769043,
      "learning_rate": 2.518597768267808e-05,
      "loss": 0.0973,
      "step": 74480
    },
    {
      "epoch": 1.489621245450546,
      "grad_norm": 0.10146904736757278,
      "learning_rate": 2.5182644749296752e-05,
      "loss": 0.068,
      "step": 74490
    },
    {
      "epoch": 1.4898212214534257,
      "grad_norm": 0.16389666497707367,
      "learning_rate": 2.5179311815915425e-05,
      "loss": 0.1635,
      "step": 74500
    },
    {
      "epoch": 1.4900211974563051,
      "grad_norm": 0.11023791134357452,
      "learning_rate": 2.5175978882534094e-05,
      "loss": 0.073,
      "step": 74510
    },
    {
      "epoch": 1.4902211734591848,
      "grad_norm": 0.061535704880952835,
      "learning_rate": 2.5172645949152767e-05,
      "loss": 0.0444,
      "step": 74520
    },
    {
      "epoch": 1.4904211494620645,
      "grad_norm": 0.11416618525981903,
      "learning_rate": 2.516931301577144e-05,
      "loss": 0.0706,
      "step": 74530
    },
    {
      "epoch": 1.4906211254649442,
      "grad_norm": 0.19622202217578888,
      "learning_rate": 2.5165980082390117e-05,
      "loss": 0.0872,
      "step": 74540
    },
    {
      "epoch": 1.4908211014678239,
      "grad_norm": 0.17831239104270935,
      "learning_rate": 2.516264714900879e-05,
      "loss": 0.0646,
      "step": 74550
    },
    {
      "epoch": 1.4910210774707036,
      "grad_norm": 0.15930020809173584,
      "learning_rate": 2.515931421562746e-05,
      "loss": 0.0772,
      "step": 74560
    },
    {
      "epoch": 1.4912210534735832,
      "grad_norm": 0.15796153247356415,
      "learning_rate": 2.5155981282246132e-05,
      "loss": 0.0668,
      "step": 74570
    },
    {
      "epoch": 1.491421029476463,
      "grad_norm": 0.194259375333786,
      "learning_rate": 2.5152648348864805e-05,
      "loss": 0.0789,
      "step": 74580
    },
    {
      "epoch": 1.4916210054793424,
      "grad_norm": 0.1552499383687973,
      "learning_rate": 2.5149315415483475e-05,
      "loss": 0.0979,
      "step": 74590
    },
    {
      "epoch": 1.491820981482222,
      "grad_norm": 0.07913415133953094,
      "learning_rate": 2.5145982482102148e-05,
      "loss": 0.0603,
      "step": 74600
    },
    {
      "epoch": 1.4920209574851018,
      "grad_norm": 0.1345362365245819,
      "learning_rate": 2.514264954872082e-05,
      "loss": 0.0607,
      "step": 74610
    },
    {
      "epoch": 1.4922209334879815,
      "grad_norm": 0.11596157401800156,
      "learning_rate": 2.513931661533949e-05,
      "loss": 0.097,
      "step": 74620
    },
    {
      "epoch": 1.4924209094908611,
      "grad_norm": 0.23386642336845398,
      "learning_rate": 2.5135983681958164e-05,
      "loss": 0.1074,
      "step": 74630
    },
    {
      "epoch": 1.4926208854937408,
      "grad_norm": 0.17986911535263062,
      "learning_rate": 2.5132650748576837e-05,
      "loss": 0.0944,
      "step": 74640
    },
    {
      "epoch": 1.4928208614966203,
      "grad_norm": 0.07497550547122955,
      "learning_rate": 2.5129317815195513e-05,
      "loss": 0.0874,
      "step": 74650
    },
    {
      "epoch": 1.4930208374995,
      "grad_norm": 0.22886702418327332,
      "learning_rate": 2.5125984881814186e-05,
      "loss": 0.0686,
      "step": 74660
    },
    {
      "epoch": 1.4932208135023797,
      "grad_norm": 0.19836382567882538,
      "learning_rate": 2.5122651948432856e-05,
      "loss": 0.1071,
      "step": 74670
    },
    {
      "epoch": 1.4934207895052594,
      "grad_norm": 0.11467815935611725,
      "learning_rate": 2.511931901505153e-05,
      "loss": 0.0699,
      "step": 74680
    },
    {
      "epoch": 1.493620765508139,
      "grad_norm": 0.25896310806274414,
      "learning_rate": 2.51159860816702e-05,
      "loss": 0.0586,
      "step": 74690
    },
    {
      "epoch": 1.4938207415110187,
      "grad_norm": 0.10677531361579895,
      "learning_rate": 2.511265314828887e-05,
      "loss": 0.0892,
      "step": 74700
    },
    {
      "epoch": 1.4940207175138984,
      "grad_norm": 0.14283829927444458,
      "learning_rate": 2.5109320214907544e-05,
      "loss": 0.0676,
      "step": 74710
    },
    {
      "epoch": 1.494220693516778,
      "grad_norm": 0.11408239603042603,
      "learning_rate": 2.5105987281526217e-05,
      "loss": 0.0407,
      "step": 74720
    },
    {
      "epoch": 1.4944206695196576,
      "grad_norm": 0.08292102068662643,
      "learning_rate": 2.5102654348144887e-05,
      "loss": 0.0487,
      "step": 74730
    },
    {
      "epoch": 1.4946206455225373,
      "grad_norm": 0.14075717329978943,
      "learning_rate": 2.509932141476356e-05,
      "loss": 0.0868,
      "step": 74740
    },
    {
      "epoch": 1.494820621525417,
      "grad_norm": 0.08319436013698578,
      "learning_rate": 2.5095988481382236e-05,
      "loss": 0.0689,
      "step": 74750
    },
    {
      "epoch": 1.4950205975282966,
      "grad_norm": 0.17618483304977417,
      "learning_rate": 2.509265554800091e-05,
      "loss": 0.063,
      "step": 74760
    },
    {
      "epoch": 1.4952205735311763,
      "grad_norm": 0.07784278690814972,
      "learning_rate": 2.5089322614619582e-05,
      "loss": 0.0693,
      "step": 74770
    },
    {
      "epoch": 1.4954205495340558,
      "grad_norm": 0.0734410285949707,
      "learning_rate": 2.5085989681238252e-05,
      "loss": 0.0469,
      "step": 74780
    },
    {
      "epoch": 1.4956205255369355,
      "grad_norm": 0.22106312215328217,
      "learning_rate": 2.5082656747856925e-05,
      "loss": 0.0962,
      "step": 74790
    },
    {
      "epoch": 1.4958205015398152,
      "grad_norm": 0.16368769109249115,
      "learning_rate": 2.5079323814475598e-05,
      "loss": 0.0636,
      "step": 74800
    },
    {
      "epoch": 1.4960204775426948,
      "grad_norm": 0.08010741323232651,
      "learning_rate": 2.5075990881094268e-05,
      "loss": 0.0627,
      "step": 74810
    },
    {
      "epoch": 1.4962204535455745,
      "grad_norm": 0.15320850908756256,
      "learning_rate": 2.507265794771294e-05,
      "loss": 0.0718,
      "step": 74820
    },
    {
      "epoch": 1.4964204295484542,
      "grad_norm": 0.0632818341255188,
      "learning_rate": 2.5069325014331614e-05,
      "loss": 0.0371,
      "step": 74830
    },
    {
      "epoch": 1.496620405551334,
      "grad_norm": 0.08745419234037399,
      "learning_rate": 2.5065992080950283e-05,
      "loss": 0.0671,
      "step": 74840
    },
    {
      "epoch": 1.4968203815542136,
      "grad_norm": 0.13049428164958954,
      "learning_rate": 2.5062659147568963e-05,
      "loss": 0.0955,
      "step": 74850
    },
    {
      "epoch": 1.4970203575570933,
      "grad_norm": 0.07562583684921265,
      "learning_rate": 2.5059326214187633e-05,
      "loss": 0.0731,
      "step": 74860
    },
    {
      "epoch": 1.4972203335599727,
      "grad_norm": 0.15110164880752563,
      "learning_rate": 2.5055993280806306e-05,
      "loss": 0.0638,
      "step": 74870
    },
    {
      "epoch": 1.4974203095628524,
      "grad_norm": 0.11548759043216705,
      "learning_rate": 2.505266034742498e-05,
      "loss": 0.0992,
      "step": 74880
    },
    {
      "epoch": 1.4976202855657321,
      "grad_norm": 0.07800442725419998,
      "learning_rate": 2.5049327414043648e-05,
      "loss": 0.0514,
      "step": 74890
    },
    {
      "epoch": 1.4978202615686118,
      "grad_norm": 0.18809698522090912,
      "learning_rate": 2.504599448066232e-05,
      "loss": 0.1009,
      "step": 74900
    },
    {
      "epoch": 1.4980202375714915,
      "grad_norm": 0.11594989150762558,
      "learning_rate": 2.5042661547280994e-05,
      "loss": 0.1109,
      "step": 74910
    },
    {
      "epoch": 1.498220213574371,
      "grad_norm": 0.11043591052293777,
      "learning_rate": 2.5039328613899664e-05,
      "loss": 0.0588,
      "step": 74920
    },
    {
      "epoch": 1.4984201895772506,
      "grad_norm": 0.10627159476280212,
      "learning_rate": 2.5035995680518337e-05,
      "loss": 0.0794,
      "step": 74930
    },
    {
      "epoch": 1.4986201655801303,
      "grad_norm": 0.15565943717956543,
      "learning_rate": 2.503266274713701e-05,
      "loss": 0.1331,
      "step": 74940
    },
    {
      "epoch": 1.49882014158301,
      "grad_norm": 0.11505768448114395,
      "learning_rate": 2.5029329813755686e-05,
      "loss": 0.0783,
      "step": 74950
    },
    {
      "epoch": 1.4990201175858897,
      "grad_norm": 0.1428494155406952,
      "learning_rate": 2.502599688037436e-05,
      "loss": 0.0953,
      "step": 74960
    },
    {
      "epoch": 1.4992200935887694,
      "grad_norm": 0.22733701765537262,
      "learning_rate": 2.502266394699303e-05,
      "loss": 0.1211,
      "step": 74970
    },
    {
      "epoch": 1.499420069591649,
      "grad_norm": 0.10011675953865051,
      "learning_rate": 2.5019331013611702e-05,
      "loss": 0.0827,
      "step": 74980
    },
    {
      "epoch": 1.4996200455945288,
      "grad_norm": 0.12543292343616486,
      "learning_rate": 2.5015998080230375e-05,
      "loss": 0.0726,
      "step": 74990
    },
    {
      "epoch": 1.4998200215974082,
      "grad_norm": 0.11052294075489044,
      "learning_rate": 2.5012665146849044e-05,
      "loss": 0.0824,
      "step": 75000
    },
    {
      "epoch": 1.500019997600288,
      "grad_norm": 0.09903378784656525,
      "learning_rate": 2.5009332213467717e-05,
      "loss": 0.0743,
      "step": 75010
    },
    {
      "epoch": 1.5002199736031676,
      "grad_norm": 0.11430469900369644,
      "learning_rate": 2.500599928008639e-05,
      "loss": 0.0716,
      "step": 75020
    },
    {
      "epoch": 1.5004199496060473,
      "grad_norm": 0.11135876923799515,
      "learning_rate": 2.500266634670506e-05,
      "loss": 0.0507,
      "step": 75030
    },
    {
      "epoch": 1.5006199256089268,
      "grad_norm": 0.07659482955932617,
      "learning_rate": 2.4999333413323736e-05,
      "loss": 0.0499,
      "step": 75040
    },
    {
      "epoch": 1.5008199016118065,
      "grad_norm": 0.07347315549850464,
      "learning_rate": 2.499600047994241e-05,
      "loss": 0.0528,
      "step": 75050
    },
    {
      "epoch": 1.5010198776146861,
      "grad_norm": 0.1221735030412674,
      "learning_rate": 2.499266754656108e-05,
      "loss": 0.0906,
      "step": 75060
    },
    {
      "epoch": 1.5012198536175658,
      "grad_norm": 0.13125278055667877,
      "learning_rate": 2.4989334613179752e-05,
      "loss": 0.1034,
      "step": 75070
    },
    {
      "epoch": 1.5014198296204455,
      "grad_norm": 0.24858731031417847,
      "learning_rate": 2.4986001679798425e-05,
      "loss": 0.0844,
      "step": 75080
    },
    {
      "epoch": 1.5016198056233252,
      "grad_norm": 0.16070282459259033,
      "learning_rate": 2.4982668746417098e-05,
      "loss": 0.1366,
      "step": 75090
    },
    {
      "epoch": 1.5018197816262049,
      "grad_norm": 0.09543756395578384,
      "learning_rate": 2.497933581303577e-05,
      "loss": 0.0717,
      "step": 75100
    },
    {
      "epoch": 1.5020197576290846,
      "grad_norm": 0.0818651095032692,
      "learning_rate": 2.497600287965444e-05,
      "loss": 0.1042,
      "step": 75110
    },
    {
      "epoch": 1.5022197336319643,
      "grad_norm": 0.10588196665048599,
      "learning_rate": 2.4972669946273114e-05,
      "loss": 0.1003,
      "step": 75120
    },
    {
      "epoch": 1.502419709634844,
      "grad_norm": 0.10909377038478851,
      "learning_rate": 2.496933701289179e-05,
      "loss": 0.0616,
      "step": 75130
    },
    {
      "epoch": 1.5026196856377236,
      "grad_norm": 0.21431241929531097,
      "learning_rate": 2.496600407951046e-05,
      "loss": 0.1392,
      "step": 75140
    },
    {
      "epoch": 1.502819661640603,
      "grad_norm": 0.10923562943935394,
      "learning_rate": 2.4962671146129133e-05,
      "loss": 0.0671,
      "step": 75150
    },
    {
      "epoch": 1.5030196376434828,
      "grad_norm": 0.27931809425354004,
      "learning_rate": 2.4959338212747806e-05,
      "loss": 0.0699,
      "step": 75160
    },
    {
      "epoch": 1.5032196136463625,
      "grad_norm": 0.06845303624868393,
      "learning_rate": 2.4956005279366475e-05,
      "loss": 0.0988,
      "step": 75170
    },
    {
      "epoch": 1.503419589649242,
      "grad_norm": 0.09098123013973236,
      "learning_rate": 2.4952672345985152e-05,
      "loss": 0.0714,
      "step": 75180
    },
    {
      "epoch": 1.5036195656521216,
      "grad_norm": 0.11537718027830124,
      "learning_rate": 2.494933941260382e-05,
      "loss": 0.0721,
      "step": 75190
    },
    {
      "epoch": 1.5038195416550013,
      "grad_norm": 0.2646678686141968,
      "learning_rate": 2.4946006479222494e-05,
      "loss": 0.1118,
      "step": 75200
    },
    {
      "epoch": 1.504019517657881,
      "grad_norm": 0.06569214165210724,
      "learning_rate": 2.4942673545841167e-05,
      "loss": 0.0486,
      "step": 75210
    },
    {
      "epoch": 1.5042194936607607,
      "grad_norm": 0.17996090650558472,
      "learning_rate": 2.4939340612459837e-05,
      "loss": 0.0682,
      "step": 75220
    },
    {
      "epoch": 1.5044194696636404,
      "grad_norm": 0.18426868319511414,
      "learning_rate": 2.4936007679078513e-05,
      "loss": 0.0978,
      "step": 75230
    },
    {
      "epoch": 1.50461944566652,
      "grad_norm": 0.17648006975650787,
      "learning_rate": 2.4932674745697186e-05,
      "loss": 0.0544,
      "step": 75240
    },
    {
      "epoch": 1.5048194216693997,
      "grad_norm": 0.07503145933151245,
      "learning_rate": 2.4929341812315856e-05,
      "loss": 0.0654,
      "step": 75250
    },
    {
      "epoch": 1.5050193976722794,
      "grad_norm": 0.11455325037240982,
      "learning_rate": 2.492600887893453e-05,
      "loss": 0.0619,
      "step": 75260
    },
    {
      "epoch": 1.5052193736751591,
      "grad_norm": 0.09646191447973251,
      "learning_rate": 2.4922675945553202e-05,
      "loss": 0.0941,
      "step": 75270
    },
    {
      "epoch": 1.5054193496780386,
      "grad_norm": 0.14225627481937408,
      "learning_rate": 2.4919343012171875e-05,
      "loss": 0.0726,
      "step": 75280
    },
    {
      "epoch": 1.5056193256809183,
      "grad_norm": 0.08491229265928268,
      "learning_rate": 2.4916010078790548e-05,
      "loss": 0.0852,
      "step": 75290
    },
    {
      "epoch": 1.505819301683798,
      "grad_norm": 0.0781155377626419,
      "learning_rate": 2.4912677145409218e-05,
      "loss": 0.0458,
      "step": 75300
    },
    {
      "epoch": 1.5060192776866776,
      "grad_norm": 0.20981857180595398,
      "learning_rate": 2.490934421202789e-05,
      "loss": 0.3349,
      "step": 75310
    },
    {
      "epoch": 1.5062192536895571,
      "grad_norm": 0.158606618642807,
      "learning_rate": 2.4906011278646564e-05,
      "loss": 0.096,
      "step": 75320
    },
    {
      "epoch": 1.5064192296924368,
      "grad_norm": 0.0622636042535305,
      "learning_rate": 2.4902678345265237e-05,
      "loss": 0.0699,
      "step": 75330
    },
    {
      "epoch": 1.5066192056953165,
      "grad_norm": 0.12484728544950485,
      "learning_rate": 2.489934541188391e-05,
      "loss": 0.0735,
      "step": 75340
    },
    {
      "epoch": 1.5068191816981962,
      "grad_norm": 0.18088555335998535,
      "learning_rate": 2.4896012478502583e-05,
      "loss": 0.0415,
      "step": 75350
    },
    {
      "epoch": 1.5070191577010759,
      "grad_norm": 0.0957784429192543,
      "learning_rate": 2.4892679545121252e-05,
      "loss": 0.0748,
      "step": 75360
    },
    {
      "epoch": 1.5072191337039555,
      "grad_norm": 0.07979679107666016,
      "learning_rate": 2.4889346611739925e-05,
      "loss": 0.0905,
      "step": 75370
    },
    {
      "epoch": 1.5074191097068352,
      "grad_norm": 0.14883621037006378,
      "learning_rate": 2.4886013678358598e-05,
      "loss": 0.0745,
      "step": 75380
    },
    {
      "epoch": 1.507619085709715,
      "grad_norm": 0.09233494848012924,
      "learning_rate": 2.488268074497727e-05,
      "loss": 0.0909,
      "step": 75390
    },
    {
      "epoch": 1.5078190617125946,
      "grad_norm": 0.18022942543029785,
      "learning_rate": 2.4879347811595944e-05,
      "loss": 0.0926,
      "step": 75400
    },
    {
      "epoch": 1.5080190377154743,
      "grad_norm": 0.05915151908993721,
      "learning_rate": 2.4876014878214614e-05,
      "loss": 0.0753,
      "step": 75410
    },
    {
      "epoch": 1.5082190137183538,
      "grad_norm": 0.06657913327217102,
      "learning_rate": 2.4872681944833287e-05,
      "loss": 0.0517,
      "step": 75420
    },
    {
      "epoch": 1.5084189897212334,
      "grad_norm": 0.07044956833124161,
      "learning_rate": 2.486934901145196e-05,
      "loss": 0.0715,
      "step": 75430
    },
    {
      "epoch": 1.5086189657241131,
      "grad_norm": 0.06215333193540573,
      "learning_rate": 2.4866016078070633e-05,
      "loss": 0.0609,
      "step": 75440
    },
    {
      "epoch": 1.5088189417269926,
      "grad_norm": 0.07058020681142807,
      "learning_rate": 2.4862683144689306e-05,
      "loss": 0.0918,
      "step": 75450
    },
    {
      "epoch": 1.5090189177298723,
      "grad_norm": 0.10270199179649353,
      "learning_rate": 2.485935021130798e-05,
      "loss": 0.0481,
      "step": 75460
    },
    {
      "epoch": 1.509218893732752,
      "grad_norm": 0.11009829491376877,
      "learning_rate": 2.485601727792665e-05,
      "loss": 0.0673,
      "step": 75470
    },
    {
      "epoch": 1.5094188697356317,
      "grad_norm": 0.16581226885318756,
      "learning_rate": 2.485268434454532e-05,
      "loss": 0.0583,
      "step": 75480
    },
    {
      "epoch": 1.5096188457385114,
      "grad_norm": 0.1310795545578003,
      "learning_rate": 2.4849351411163995e-05,
      "loss": 0.0968,
      "step": 75490
    },
    {
      "epoch": 1.509818821741391,
      "grad_norm": 0.10468617081642151,
      "learning_rate": 2.4846018477782668e-05,
      "loss": 0.0384,
      "step": 75500
    },
    {
      "epoch": 1.5100187977442707,
      "grad_norm": 0.10094249248504639,
      "learning_rate": 2.4843018837739473e-05,
      "loss": 0.0776,
      "step": 75510
    },
    {
      "epoch": 1.5102187737471504,
      "grad_norm": 0.0899728387594223,
      "learning_rate": 2.4839685904358146e-05,
      "loss": 0.0793,
      "step": 75520
    },
    {
      "epoch": 1.51041874975003,
      "grad_norm": 0.11610635370016098,
      "learning_rate": 2.483635297097682e-05,
      "loss": 0.0655,
      "step": 75530
    },
    {
      "epoch": 1.5106187257529098,
      "grad_norm": 0.13164715468883514,
      "learning_rate": 2.483302003759549e-05,
      "loss": 0.0953,
      "step": 75540
    },
    {
      "epoch": 1.5108187017557893,
      "grad_norm": 0.1337769776582718,
      "learning_rate": 2.482968710421416e-05,
      "loss": 0.1044,
      "step": 75550
    },
    {
      "epoch": 1.511018677758669,
      "grad_norm": 0.1998424082994461,
      "learning_rate": 2.4826354170832835e-05,
      "loss": 0.0732,
      "step": 75560
    },
    {
      "epoch": 1.5112186537615486,
      "grad_norm": 0.22655180096626282,
      "learning_rate": 2.4823021237451508e-05,
      "loss": 0.0739,
      "step": 75570
    },
    {
      "epoch": 1.5114186297644283,
      "grad_norm": 0.07087002694606781,
      "learning_rate": 2.481968830407018e-05,
      "loss": 0.0587,
      "step": 75580
    },
    {
      "epoch": 1.5116186057673078,
      "grad_norm": 0.13336604833602905,
      "learning_rate": 2.481635537068885e-05,
      "loss": 0.0559,
      "step": 75590
    },
    {
      "epoch": 1.5118185817701875,
      "grad_norm": 0.16902120411396027,
      "learning_rate": 2.4813022437307523e-05,
      "loss": 0.0541,
      "step": 75600
    },
    {
      "epoch": 1.5120185577730672,
      "grad_norm": 0.08955021947622299,
      "learning_rate": 2.4809689503926196e-05,
      "loss": 0.0574,
      "step": 75610
    },
    {
      "epoch": 1.5122185337759468,
      "grad_norm": 0.07293678820133209,
      "learning_rate": 2.480635657054487e-05,
      "loss": 0.0728,
      "step": 75620
    },
    {
      "epoch": 1.5124185097788265,
      "grad_norm": 0.08705241978168488,
      "learning_rate": 2.4803023637163542e-05,
      "loss": 0.0495,
      "step": 75630
    },
    {
      "epoch": 1.5126184857817062,
      "grad_norm": 0.12026146799325943,
      "learning_rate": 2.4799690703782212e-05,
      "loss": 0.0841,
      "step": 75640
    },
    {
      "epoch": 1.512818461784586,
      "grad_norm": 0.21884030103683472,
      "learning_rate": 2.4796357770400885e-05,
      "loss": 0.0806,
      "step": 75650
    },
    {
      "epoch": 1.5130184377874656,
      "grad_norm": 0.0961768850684166,
      "learning_rate": 2.479302483701956e-05,
      "loss": 0.0705,
      "step": 75660
    },
    {
      "epoch": 1.5132184137903453,
      "grad_norm": 0.07119036465883255,
      "learning_rate": 2.478969190363823e-05,
      "loss": 0.0774,
      "step": 75670
    },
    {
      "epoch": 1.513418389793225,
      "grad_norm": 0.12200471013784409,
      "learning_rate": 2.4786358970256904e-05,
      "loss": 0.032,
      "step": 75680
    },
    {
      "epoch": 1.5136183657961044,
      "grad_norm": 0.09985450655221939,
      "learning_rate": 2.4783026036875577e-05,
      "loss": 0.0657,
      "step": 75690
    },
    {
      "epoch": 1.5138183417989841,
      "grad_norm": 0.14275696873664856,
      "learning_rate": 2.4779693103494246e-05,
      "loss": 0.058,
      "step": 75700
    },
    {
      "epoch": 1.5140183178018638,
      "grad_norm": 0.19990001618862152,
      "learning_rate": 2.4776360170112923e-05,
      "loss": 0.1046,
      "step": 75710
    },
    {
      "epoch": 1.5142182938047433,
      "grad_norm": 0.1216113269329071,
      "learning_rate": 2.4773027236731592e-05,
      "loss": 0.0907,
      "step": 75720
    },
    {
      "epoch": 1.514418269807623,
      "grad_norm": 0.20119507610797882,
      "learning_rate": 2.4769694303350265e-05,
      "loss": 0.1055,
      "step": 75730
    },
    {
      "epoch": 1.5146182458105026,
      "grad_norm": 0.06071664020419121,
      "learning_rate": 2.476636136996894e-05,
      "loss": 0.0654,
      "step": 75740
    },
    {
      "epoch": 1.5148182218133823,
      "grad_norm": 0.12368527054786682,
      "learning_rate": 2.4763028436587608e-05,
      "loss": 0.095,
      "step": 75750
    },
    {
      "epoch": 1.515018197816262,
      "grad_norm": 0.11494112759828568,
      "learning_rate": 2.4759695503206284e-05,
      "loss": 0.0428,
      "step": 75760
    },
    {
      "epoch": 1.5152181738191417,
      "grad_norm": 0.23006664216518402,
      "learning_rate": 2.4756362569824957e-05,
      "loss": 0.1116,
      "step": 75770
    },
    {
      "epoch": 1.5154181498220214,
      "grad_norm": 0.09061957895755768,
      "learning_rate": 2.4753029636443627e-05,
      "loss": 0.0681,
      "step": 75780
    },
    {
      "epoch": 1.515618125824901,
      "grad_norm": 0.09400865435600281,
      "learning_rate": 2.47496967030623e-05,
      "loss": 0.0699,
      "step": 75790
    },
    {
      "epoch": 1.5158181018277808,
      "grad_norm": 0.19180405139923096,
      "learning_rate": 2.4746363769680973e-05,
      "loss": 0.0669,
      "step": 75800
    },
    {
      "epoch": 1.5160180778306604,
      "grad_norm": 0.0635766014456749,
      "learning_rate": 2.4743030836299646e-05,
      "loss": 0.0407,
      "step": 75810
    },
    {
      "epoch": 1.5162180538335401,
      "grad_norm": 0.11679390072822571,
      "learning_rate": 2.473969790291832e-05,
      "loss": 0.0422,
      "step": 75820
    },
    {
      "epoch": 1.5164180298364196,
      "grad_norm": 0.2051239013671875,
      "learning_rate": 2.473636496953699e-05,
      "loss": 0.0911,
      "step": 75830
    },
    {
      "epoch": 1.5166180058392993,
      "grad_norm": 0.06626398116350174,
      "learning_rate": 2.4733032036155662e-05,
      "loss": 0.0743,
      "step": 75840
    },
    {
      "epoch": 1.516817981842179,
      "grad_norm": 0.19380685687065125,
      "learning_rate": 2.4729699102774335e-05,
      "loss": 0.0651,
      "step": 75850
    },
    {
      "epoch": 1.5170179578450584,
      "grad_norm": 0.05565087869763374,
      "learning_rate": 2.4726366169393004e-05,
      "loss": 0.136,
      "step": 75860
    },
    {
      "epoch": 1.5172179338479381,
      "grad_norm": 0.20909957587718964,
      "learning_rate": 2.472303323601168e-05,
      "loss": 0.0612,
      "step": 75870
    },
    {
      "epoch": 1.5174179098508178,
      "grad_norm": 0.14219357073307037,
      "learning_rate": 2.4719700302630354e-05,
      "loss": 0.0751,
      "step": 75880
    },
    {
      "epoch": 1.5176178858536975,
      "grad_norm": 0.166273295879364,
      "learning_rate": 2.4716367369249023e-05,
      "loss": 0.0976,
      "step": 75890
    },
    {
      "epoch": 1.5178178618565772,
      "grad_norm": 0.22598335146903992,
      "learning_rate": 2.4713034435867696e-05,
      "loss": 0.0601,
      "step": 75900
    },
    {
      "epoch": 1.5180178378594569,
      "grad_norm": 0.22773587703704834,
      "learning_rate": 2.470970150248637e-05,
      "loss": 0.1071,
      "step": 75910
    },
    {
      "epoch": 1.5182178138623366,
      "grad_norm": 0.06795171648263931,
      "learning_rate": 2.4706368569105042e-05,
      "loss": 0.0837,
      "step": 75920
    },
    {
      "epoch": 1.5184177898652162,
      "grad_norm": 0.2027602642774582,
      "learning_rate": 2.4703035635723715e-05,
      "loss": 0.06,
      "step": 75930
    },
    {
      "epoch": 1.518617765868096,
      "grad_norm": 0.20533490180969238,
      "learning_rate": 2.4699702702342385e-05,
      "loss": 0.057,
      "step": 75940
    },
    {
      "epoch": 1.5188177418709756,
      "grad_norm": 0.0974700078368187,
      "learning_rate": 2.4696369768961058e-05,
      "loss": 0.0702,
      "step": 75950
    },
    {
      "epoch": 1.519017717873855,
      "grad_norm": 0.11052306741476059,
      "learning_rate": 2.469303683557973e-05,
      "loss": 0.0488,
      "step": 75960
    },
    {
      "epoch": 1.5192176938767348,
      "grad_norm": 0.21164819598197937,
      "learning_rate": 2.4689703902198404e-05,
      "loss": 0.0856,
      "step": 75970
    },
    {
      "epoch": 1.5194176698796145,
      "grad_norm": 0.11304143071174622,
      "learning_rate": 2.4686370968817077e-05,
      "loss": 0.0902,
      "step": 75980
    },
    {
      "epoch": 1.5196176458824942,
      "grad_norm": 0.09274253249168396,
      "learning_rate": 2.468303803543575e-05,
      "loss": 0.0673,
      "step": 75990
    },
    {
      "epoch": 1.5198176218853736,
      "grad_norm": 0.15732276439666748,
      "learning_rate": 2.467970510205442e-05,
      "loss": 0.0647,
      "step": 76000
    },
    {
      "epoch": 1.5200175978882533,
      "grad_norm": 0.15057441592216492,
      "learning_rate": 2.4676372168673093e-05,
      "loss": 0.0846,
      "step": 76010
    },
    {
      "epoch": 1.520217573891133,
      "grad_norm": 0.15973326563835144,
      "learning_rate": 2.4673039235291766e-05,
      "loss": 0.0835,
      "step": 76020
    },
    {
      "epoch": 1.5204175498940127,
      "grad_norm": 0.04211428016424179,
      "learning_rate": 2.466970630191044e-05,
      "loss": 0.0707,
      "step": 76030
    },
    {
      "epoch": 1.5206175258968924,
      "grad_norm": 0.19867390394210815,
      "learning_rate": 2.466637336852911e-05,
      "loss": 0.1054,
      "step": 76040
    },
    {
      "epoch": 1.520817501899772,
      "grad_norm": 0.06261172890663147,
      "learning_rate": 2.466304043514778e-05,
      "loss": 0.0565,
      "step": 76050
    },
    {
      "epoch": 1.5210174779026517,
      "grad_norm": 0.12819264829158783,
      "learning_rate": 2.4659707501766454e-05,
      "loss": 0.0852,
      "step": 76060
    },
    {
      "epoch": 1.5212174539055314,
      "grad_norm": 0.2206483781337738,
      "learning_rate": 2.465637456838513e-05,
      "loss": 0.0746,
      "step": 76070
    },
    {
      "epoch": 1.5214174299084111,
      "grad_norm": 0.13208527863025665,
      "learning_rate": 2.46530416350038e-05,
      "loss": 0.0927,
      "step": 76080
    },
    {
      "epoch": 1.5216174059112908,
      "grad_norm": 0.14127013087272644,
      "learning_rate": 2.4649708701622473e-05,
      "loss": 0.0843,
      "step": 76090
    },
    {
      "epoch": 1.5218173819141703,
      "grad_norm": 0.09423595666885376,
      "learning_rate": 2.4646375768241146e-05,
      "loss": 0.0654,
      "step": 76100
    },
    {
      "epoch": 1.52201735791705,
      "grad_norm": 0.06617753952741623,
      "learning_rate": 2.4643042834859816e-05,
      "loss": 0.0687,
      "step": 76110
    },
    {
      "epoch": 1.5222173339199296,
      "grad_norm": 0.20015494525432587,
      "learning_rate": 2.4639709901478492e-05,
      "loss": 0.0725,
      "step": 76120
    },
    {
      "epoch": 1.522417309922809,
      "grad_norm": 0.1356469988822937,
      "learning_rate": 2.4636376968097162e-05,
      "loss": 0.0663,
      "step": 76130
    },
    {
      "epoch": 1.5226172859256888,
      "grad_norm": 0.08267337828874588,
      "learning_rate": 2.4633044034715835e-05,
      "loss": 0.0599,
      "step": 76140
    },
    {
      "epoch": 1.5228172619285685,
      "grad_norm": 0.09419748187065125,
      "learning_rate": 2.4629711101334508e-05,
      "loss": 0.0563,
      "step": 76150
    },
    {
      "epoch": 1.5230172379314482,
      "grad_norm": 0.07022394239902496,
      "learning_rate": 2.4626378167953178e-05,
      "loss": 0.0889,
      "step": 76160
    },
    {
      "epoch": 1.5232172139343279,
      "grad_norm": 0.13792584836483002,
      "learning_rate": 2.4623045234571854e-05,
      "loss": 0.0989,
      "step": 76170
    },
    {
      "epoch": 1.5234171899372075,
      "grad_norm": 0.1379498392343521,
      "learning_rate": 2.4619712301190527e-05,
      "loss": 0.0796,
      "step": 76180
    },
    {
      "epoch": 1.5236171659400872,
      "grad_norm": 0.1324787735939026,
      "learning_rate": 2.4616379367809197e-05,
      "loss": 0.0404,
      "step": 76190
    },
    {
      "epoch": 1.523817141942967,
      "grad_norm": 0.22164331376552582,
      "learning_rate": 2.461304643442787e-05,
      "loss": 0.1092,
      "step": 76200
    },
    {
      "epoch": 1.5240171179458466,
      "grad_norm": 0.13684090971946716,
      "learning_rate": 2.4609713501046543e-05,
      "loss": 0.0594,
      "step": 76210
    },
    {
      "epoch": 1.5242170939487263,
      "grad_norm": 0.18339353799819946,
      "learning_rate": 2.4606380567665216e-05,
      "loss": 0.0765,
      "step": 76220
    },
    {
      "epoch": 1.5244170699516058,
      "grad_norm": 0.06531910598278046,
      "learning_rate": 2.460304763428389e-05,
      "loss": 0.0946,
      "step": 76230
    },
    {
      "epoch": 1.5246170459544854,
      "grad_norm": 0.086862713098526,
      "learning_rate": 2.4599714700902558e-05,
      "loss": 0.054,
      "step": 76240
    },
    {
      "epoch": 1.5248170219573651,
      "grad_norm": 0.08283510059118271,
      "learning_rate": 2.459638176752123e-05,
      "loss": 0.0584,
      "step": 76250
    },
    {
      "epoch": 1.5250169979602448,
      "grad_norm": 0.07006385922431946,
      "learning_rate": 2.4593048834139904e-05,
      "loss": 0.0825,
      "step": 76260
    },
    {
      "epoch": 1.5252169739631243,
      "grad_norm": 0.13086624443531036,
      "learning_rate": 2.4589715900758577e-05,
      "loss": 0.1351,
      "step": 76270
    },
    {
      "epoch": 1.525416949966004,
      "grad_norm": 0.05491272360086441,
      "learning_rate": 2.458638296737725e-05,
      "loss": 0.1105,
      "step": 76280
    },
    {
      "epoch": 1.5256169259688837,
      "grad_norm": 0.13759289681911469,
      "learning_rate": 2.4583050033995923e-05,
      "loss": 0.078,
      "step": 76290
    },
    {
      "epoch": 1.5258169019717633,
      "grad_norm": 0.08108002692461014,
      "learning_rate": 2.4579717100614593e-05,
      "loss": 0.083,
      "step": 76300
    },
    {
      "epoch": 1.526016877974643,
      "grad_norm": 0.2160906344652176,
      "learning_rate": 2.4576384167233266e-05,
      "loss": 0.0938,
      "step": 76310
    },
    {
      "epoch": 1.5262168539775227,
      "grad_norm": 0.17424960434436798,
      "learning_rate": 2.457305123385194e-05,
      "loss": 0.0643,
      "step": 76320
    },
    {
      "epoch": 1.5264168299804024,
      "grad_norm": 0.1090753972530365,
      "learning_rate": 2.4569718300470612e-05,
      "loss": 0.0879,
      "step": 76330
    },
    {
      "epoch": 1.526616805983282,
      "grad_norm": 0.23819021880626678,
      "learning_rate": 2.4566385367089285e-05,
      "loss": 0.094,
      "step": 76340
    },
    {
      "epoch": 1.5268167819861618,
      "grad_norm": 0.10842817276716232,
      "learning_rate": 2.4563052433707954e-05,
      "loss": 0.1013,
      "step": 76350
    },
    {
      "epoch": 1.5270167579890415,
      "grad_norm": 0.1582861989736557,
      "learning_rate": 2.4559719500326627e-05,
      "loss": 0.0742,
      "step": 76360
    },
    {
      "epoch": 1.527216733991921,
      "grad_norm": 0.11663231998682022,
      "learning_rate": 2.45563865669453e-05,
      "loss": 0.0956,
      "step": 76370
    },
    {
      "epoch": 1.5274167099948006,
      "grad_norm": 0.1387304961681366,
      "learning_rate": 2.4553053633563973e-05,
      "loss": 0.067,
      "step": 76380
    },
    {
      "epoch": 1.5276166859976803,
      "grad_norm": 0.2435421496629715,
      "learning_rate": 2.4549720700182646e-05,
      "loss": 0.0678,
      "step": 76390
    },
    {
      "epoch": 1.5278166620005598,
      "grad_norm": 0.13601508736610413,
      "learning_rate": 2.454638776680132e-05,
      "loss": 0.0716,
      "step": 76400
    },
    {
      "epoch": 1.5280166380034395,
      "grad_norm": 0.13473360240459442,
      "learning_rate": 2.454305483341999e-05,
      "loss": 0.0546,
      "step": 76410
    },
    {
      "epoch": 1.5282166140063191,
      "grad_norm": 0.10038045048713684,
      "learning_rate": 2.4539721900038662e-05,
      "loss": 0.0665,
      "step": 76420
    },
    {
      "epoch": 1.5284165900091988,
      "grad_norm": 0.1334303915500641,
      "learning_rate": 2.4536388966657335e-05,
      "loss": 0.0593,
      "step": 76430
    },
    {
      "epoch": 1.5286165660120785,
      "grad_norm": 0.1324736475944519,
      "learning_rate": 2.4533056033276008e-05,
      "loss": 0.0638,
      "step": 76440
    },
    {
      "epoch": 1.5288165420149582,
      "grad_norm": 0.17922213673591614,
      "learning_rate": 2.452972309989468e-05,
      "loss": 0.0561,
      "step": 76450
    },
    {
      "epoch": 1.5290165180178379,
      "grad_norm": 0.10289017111063004,
      "learning_rate": 2.452639016651335e-05,
      "loss": 0.0865,
      "step": 76460
    },
    {
      "epoch": 1.5292164940207176,
      "grad_norm": 0.10383503139019012,
      "learning_rate": 2.4523057233132024e-05,
      "loss": 0.0679,
      "step": 76470
    },
    {
      "epoch": 1.5294164700235973,
      "grad_norm": 0.0711086243391037,
      "learning_rate": 2.45197242997507e-05,
      "loss": 0.0494,
      "step": 76480
    },
    {
      "epoch": 1.529616446026477,
      "grad_norm": 0.18097944557666779,
      "learning_rate": 2.451639136636937e-05,
      "loss": 0.0874,
      "step": 76490
    },
    {
      "epoch": 1.5298164220293566,
      "grad_norm": 0.1828250139951706,
      "learning_rate": 2.4513058432988043e-05,
      "loss": 0.0958,
      "step": 76500
    },
    {
      "epoch": 1.530016398032236,
      "grad_norm": 0.13436374068260193,
      "learning_rate": 2.4509725499606716e-05,
      "loss": 0.1201,
      "step": 76510
    },
    {
      "epoch": 1.5302163740351158,
      "grad_norm": 0.18200473487377167,
      "learning_rate": 2.4506392566225385e-05,
      "loss": 0.0936,
      "step": 76520
    },
    {
      "epoch": 1.5304163500379955,
      "grad_norm": 0.1276121884584427,
      "learning_rate": 2.4503059632844062e-05,
      "loss": 0.1208,
      "step": 76530
    },
    {
      "epoch": 1.530616326040875,
      "grad_norm": 0.17427921295166016,
      "learning_rate": 2.449972669946273e-05,
      "loss": 0.0768,
      "step": 76540
    },
    {
      "epoch": 1.5308163020437546,
      "grad_norm": 0.1421125829219818,
      "learning_rate": 2.4496393766081404e-05,
      "loss": 0.0726,
      "step": 76550
    },
    {
      "epoch": 1.5310162780466343,
      "grad_norm": 0.11079520732164383,
      "learning_rate": 2.4493060832700077e-05,
      "loss": 0.0717,
      "step": 76560
    },
    {
      "epoch": 1.531216254049514,
      "grad_norm": 0.19828936457633972,
      "learning_rate": 2.4489727899318747e-05,
      "loss": 0.0702,
      "step": 76570
    },
    {
      "epoch": 1.5314162300523937,
      "grad_norm": 0.09997381269931793,
      "learning_rate": 2.4486394965937423e-05,
      "loss": 0.0845,
      "step": 76580
    },
    {
      "epoch": 1.5316162060552734,
      "grad_norm": 0.11150385439395905,
      "learning_rate": 2.4483062032556096e-05,
      "loss": 0.0799,
      "step": 76590
    },
    {
      "epoch": 1.531816182058153,
      "grad_norm": 0.11542076617479324,
      "learning_rate": 2.4479729099174766e-05,
      "loss": 0.0708,
      "step": 76600
    },
    {
      "epoch": 1.5320161580610328,
      "grad_norm": 0.10035839676856995,
      "learning_rate": 2.447639616579344e-05,
      "loss": 0.0687,
      "step": 76610
    },
    {
      "epoch": 1.5322161340639124,
      "grad_norm": 0.1697508990764618,
      "learning_rate": 2.4473063232412112e-05,
      "loss": 0.0827,
      "step": 76620
    },
    {
      "epoch": 1.5324161100667921,
      "grad_norm": 0.10668246448040009,
      "learning_rate": 2.4469730299030785e-05,
      "loss": 0.0916,
      "step": 76630
    },
    {
      "epoch": 1.5326160860696716,
      "grad_norm": 0.10767393559217453,
      "learning_rate": 2.4466397365649458e-05,
      "loss": 0.0615,
      "step": 76640
    },
    {
      "epoch": 1.5328160620725513,
      "grad_norm": 0.10105565190315247,
      "learning_rate": 2.4463064432268128e-05,
      "loss": 0.0707,
      "step": 76650
    },
    {
      "epoch": 1.533016038075431,
      "grad_norm": 0.2049160748720169,
      "learning_rate": 2.44597314988868e-05,
      "loss": 0.054,
      "step": 76660
    },
    {
      "epoch": 1.5332160140783107,
      "grad_norm": 0.10884373635053635,
      "learning_rate": 2.4456398565505474e-05,
      "loss": 0.0762,
      "step": 76670
    },
    {
      "epoch": 1.5334159900811901,
      "grad_norm": 0.07110436260700226,
      "learning_rate": 2.4453065632124147e-05,
      "loss": 0.0658,
      "step": 76680
    },
    {
      "epoch": 1.5336159660840698,
      "grad_norm": 0.14281751215457916,
      "learning_rate": 2.444973269874282e-05,
      "loss": 0.0771,
      "step": 76690
    },
    {
      "epoch": 1.5338159420869495,
      "grad_norm": 0.10942669212818146,
      "learning_rate": 2.4446399765361493e-05,
      "loss": 0.1285,
      "step": 76700
    },
    {
      "epoch": 1.5340159180898292,
      "grad_norm": 0.14618822932243347,
      "learning_rate": 2.4443066831980162e-05,
      "loss": 0.0745,
      "step": 76710
    },
    {
      "epoch": 1.5342158940927089,
      "grad_norm": 0.11722827702760696,
      "learning_rate": 2.4439733898598835e-05,
      "loss": 0.047,
      "step": 76720
    },
    {
      "epoch": 1.5344158700955886,
      "grad_norm": 0.22963674366474152,
      "learning_rate": 2.4436400965217508e-05,
      "loss": 0.08,
      "step": 76730
    },
    {
      "epoch": 1.5346158460984682,
      "grad_norm": 0.06607238948345184,
      "learning_rate": 2.443306803183618e-05,
      "loss": 0.069,
      "step": 76740
    },
    {
      "epoch": 1.534815822101348,
      "grad_norm": 0.13490299880504608,
      "learning_rate": 2.4429735098454854e-05,
      "loss": 0.0744,
      "step": 76750
    },
    {
      "epoch": 1.5350157981042276,
      "grad_norm": 0.1959781050682068,
      "learning_rate": 2.4426402165073524e-05,
      "loss": 0.1293,
      "step": 76760
    },
    {
      "epoch": 1.5352157741071073,
      "grad_norm": 0.18869318068027496,
      "learning_rate": 2.4423069231692197e-05,
      "loss": 0.0876,
      "step": 76770
    },
    {
      "epoch": 1.5354157501099868,
      "grad_norm": 0.24357067048549652,
      "learning_rate": 2.4419736298310873e-05,
      "loss": 0.0795,
      "step": 76780
    },
    {
      "epoch": 1.5356157261128665,
      "grad_norm": 0.0945010706782341,
      "learning_rate": 2.4416403364929543e-05,
      "loss": 0.0927,
      "step": 76790
    },
    {
      "epoch": 1.5358157021157461,
      "grad_norm": 0.18678629398345947,
      "learning_rate": 2.4413070431548216e-05,
      "loss": 0.0603,
      "step": 76800
    },
    {
      "epoch": 1.5360156781186256,
      "grad_norm": 0.18360044062137604,
      "learning_rate": 2.440973749816689e-05,
      "loss": 0.0695,
      "step": 76810
    },
    {
      "epoch": 1.5362156541215053,
      "grad_norm": 0.12615063786506653,
      "learning_rate": 2.440640456478556e-05,
      "loss": 0.065,
      "step": 76820
    },
    {
      "epoch": 1.536415630124385,
      "grad_norm": 0.19578421115875244,
      "learning_rate": 2.4403071631404235e-05,
      "loss": 0.0832,
      "step": 76830
    },
    {
      "epoch": 1.5366156061272647,
      "grad_norm": 0.06930293887853622,
      "learning_rate": 2.4399738698022905e-05,
      "loss": 0.0583,
      "step": 76840
    },
    {
      "epoch": 1.5368155821301444,
      "grad_norm": 0.17701829969882965,
      "learning_rate": 2.4396405764641578e-05,
      "loss": 0.075,
      "step": 76850
    },
    {
      "epoch": 1.537015558133024,
      "grad_norm": 0.15166984498500824,
      "learning_rate": 2.439307283126025e-05,
      "loss": 0.0705,
      "step": 76860
    },
    {
      "epoch": 1.5372155341359037,
      "grad_norm": 0.10656850785017014,
      "learning_rate": 2.438973989787892e-05,
      "loss": 0.0804,
      "step": 76870
    },
    {
      "epoch": 1.5374155101387834,
      "grad_norm": 0.08221831917762756,
      "learning_rate": 2.4386406964497593e-05,
      "loss": 0.0994,
      "step": 76880
    },
    {
      "epoch": 1.537615486141663,
      "grad_norm": 0.18110524117946625,
      "learning_rate": 2.438307403111627e-05,
      "loss": 0.0908,
      "step": 76890
    },
    {
      "epoch": 1.5378154621445428,
      "grad_norm": 0.04945679008960724,
      "learning_rate": 2.437974109773494e-05,
      "loss": 0.0554,
      "step": 76900
    },
    {
      "epoch": 1.5380154381474225,
      "grad_norm": 0.14026296138763428,
      "learning_rate": 2.4376408164353612e-05,
      "loss": 0.0591,
      "step": 76910
    },
    {
      "epoch": 1.538215414150302,
      "grad_norm": 0.1334555447101593,
      "learning_rate": 2.4373075230972285e-05,
      "loss": 0.0717,
      "step": 76920
    },
    {
      "epoch": 1.5384153901531816,
      "grad_norm": 0.15140622854232788,
      "learning_rate": 2.4369742297590955e-05,
      "loss": 0.0944,
      "step": 76930
    },
    {
      "epoch": 1.5386153661560613,
      "grad_norm": 0.20422525703907013,
      "learning_rate": 2.436640936420963e-05,
      "loss": 0.065,
      "step": 76940
    },
    {
      "epoch": 1.5388153421589408,
      "grad_norm": 0.18331055343151093,
      "learning_rate": 2.43630764308283e-05,
      "loss": 0.1062,
      "step": 76950
    },
    {
      "epoch": 1.5390153181618205,
      "grad_norm": 0.2031029611825943,
      "learning_rate": 2.4359743497446974e-05,
      "loss": 0.0866,
      "step": 76960
    },
    {
      "epoch": 1.5392152941647002,
      "grad_norm": 0.26692405343055725,
      "learning_rate": 2.4356410564065647e-05,
      "loss": 0.0942,
      "step": 76970
    },
    {
      "epoch": 1.5394152701675798,
      "grad_norm": 0.19026876986026764,
      "learning_rate": 2.4353077630684316e-05,
      "loss": 0.0996,
      "step": 76980
    },
    {
      "epoch": 1.5396152461704595,
      "grad_norm": 0.12494588643312454,
      "learning_rate": 2.4349744697302993e-05,
      "loss": 0.0511,
      "step": 76990
    },
    {
      "epoch": 1.5398152221733392,
      "grad_norm": 0.22954823076725006,
      "learning_rate": 2.4346411763921666e-05,
      "loss": 0.0731,
      "step": 77000
    },
    {
      "epoch": 1.540015198176219,
      "grad_norm": 0.07062896341085434,
      "learning_rate": 2.4343078830540335e-05,
      "loss": 0.0633,
      "step": 77010
    },
    {
      "epoch": 1.5402151741790986,
      "grad_norm": 0.2039182037115097,
      "learning_rate": 2.433974589715901e-05,
      "loss": 0.0762,
      "step": 77020
    },
    {
      "epoch": 1.5404151501819783,
      "grad_norm": 0.2473522275686264,
      "learning_rate": 2.433641296377768e-05,
      "loss": 0.1181,
      "step": 77030
    },
    {
      "epoch": 1.540615126184858,
      "grad_norm": 0.17861144244670868,
      "learning_rate": 2.4333080030396354e-05,
      "loss": 0.0813,
      "step": 77040
    },
    {
      "epoch": 1.5408151021877374,
      "grad_norm": 0.10356350243091583,
      "learning_rate": 2.4329747097015027e-05,
      "loss": 0.083,
      "step": 77050
    },
    {
      "epoch": 1.5410150781906171,
      "grad_norm": 0.15728917717933655,
      "learning_rate": 2.4326414163633697e-05,
      "loss": 0.0556,
      "step": 77060
    },
    {
      "epoch": 1.5412150541934968,
      "grad_norm": 0.06269165873527527,
      "learning_rate": 2.432308123025237e-05,
      "loss": 0.0736,
      "step": 77070
    },
    {
      "epoch": 1.5414150301963765,
      "grad_norm": 0.07780282199382782,
      "learning_rate": 2.4319748296871043e-05,
      "loss": 0.0585,
      "step": 77080
    },
    {
      "epoch": 1.541615006199256,
      "grad_norm": 0.2296144962310791,
      "learning_rate": 2.4316415363489716e-05,
      "loss": 0.1009,
      "step": 77090
    },
    {
      "epoch": 1.5418149822021356,
      "grad_norm": 0.11899028718471527,
      "learning_rate": 2.431308243010839e-05,
      "loss": 0.1174,
      "step": 77100
    },
    {
      "epoch": 1.5420149582050153,
      "grad_norm": 0.10053766518831253,
      "learning_rate": 2.4309749496727062e-05,
      "loss": 0.0679,
      "step": 77110
    },
    {
      "epoch": 1.542214934207895,
      "grad_norm": 0.04886024445295334,
      "learning_rate": 2.4306416563345732e-05,
      "loss": 0.0518,
      "step": 77120
    },
    {
      "epoch": 1.5424149102107747,
      "grad_norm": 0.1696605384349823,
      "learning_rate": 2.4303083629964405e-05,
      "loss": 0.0736,
      "step": 77130
    },
    {
      "epoch": 1.5426148862136544,
      "grad_norm": 0.20272374153137207,
      "learning_rate": 2.4299750696583078e-05,
      "loss": 0.098,
      "step": 77140
    },
    {
      "epoch": 1.542814862216534,
      "grad_norm": 0.2209174782037735,
      "learning_rate": 2.429641776320175e-05,
      "loss": 0.0645,
      "step": 77150
    },
    {
      "epoch": 1.5430148382194138,
      "grad_norm": 0.10727467387914658,
      "learning_rate": 2.4293084829820424e-05,
      "loss": 0.0582,
      "step": 77160
    },
    {
      "epoch": 1.5432148142222935,
      "grad_norm": 0.08061426877975464,
      "learning_rate": 2.4289751896439093e-05,
      "loss": 0.1243,
      "step": 77170
    },
    {
      "epoch": 1.5434147902251731,
      "grad_norm": 0.11444762349128723,
      "learning_rate": 2.4286418963057766e-05,
      "loss": 0.0679,
      "step": 77180
    },
    {
      "epoch": 1.5436147662280526,
      "grad_norm": 0.16105535626411438,
      "learning_rate": 2.4283086029676443e-05,
      "loss": 0.044,
      "step": 77190
    },
    {
      "epoch": 1.5438147422309323,
      "grad_norm": 0.08224745839834213,
      "learning_rate": 2.4279753096295112e-05,
      "loss": 0.0677,
      "step": 77200
    },
    {
      "epoch": 1.544014718233812,
      "grad_norm": 0.16643987596035004,
      "learning_rate": 2.4276420162913785e-05,
      "loss": 0.1038,
      "step": 77210
    },
    {
      "epoch": 1.5442146942366914,
      "grad_norm": 0.1425708383321762,
      "learning_rate": 2.427308722953246e-05,
      "loss": 0.0537,
      "step": 77220
    },
    {
      "epoch": 1.5444146702395711,
      "grad_norm": 0.13373790681362152,
      "learning_rate": 2.4269754296151128e-05,
      "loss": 0.0723,
      "step": 77230
    },
    {
      "epoch": 1.5446146462424508,
      "grad_norm": 0.16293856501579285,
      "learning_rate": 2.4266421362769804e-05,
      "loss": 0.0947,
      "step": 77240
    },
    {
      "epoch": 1.5448146222453305,
      "grad_norm": 0.1282922625541687,
      "learning_rate": 2.4263088429388474e-05,
      "loss": 0.0746,
      "step": 77250
    },
    {
      "epoch": 1.5450145982482102,
      "grad_norm": 0.043258678168058395,
      "learning_rate": 2.4259755496007147e-05,
      "loss": 0.0656,
      "step": 77260
    },
    {
      "epoch": 1.5452145742510899,
      "grad_norm": 0.12113948166370392,
      "learning_rate": 2.425642256262582e-05,
      "loss": 0.0663,
      "step": 77270
    },
    {
      "epoch": 1.5454145502539696,
      "grad_norm": 0.09788387268781662,
      "learning_rate": 2.425308962924449e-05,
      "loss": 0.0716,
      "step": 77280
    },
    {
      "epoch": 1.5456145262568493,
      "grad_norm": 0.08075271546840668,
      "learning_rate": 2.4249756695863166e-05,
      "loss": 0.0647,
      "step": 77290
    },
    {
      "epoch": 1.545814502259729,
      "grad_norm": 0.09485333412885666,
      "learning_rate": 2.424642376248184e-05,
      "loss": 0.0879,
      "step": 77300
    },
    {
      "epoch": 1.5460144782626086,
      "grad_norm": 0.11765188723802567,
      "learning_rate": 2.424309082910051e-05,
      "loss": 0.0505,
      "step": 77310
    },
    {
      "epoch": 1.546214454265488,
      "grad_norm": 0.1996348649263382,
      "learning_rate": 2.423975789571918e-05,
      "loss": 0.0963,
      "step": 77320
    },
    {
      "epoch": 1.5464144302683678,
      "grad_norm": 0.1811908632516861,
      "learning_rate": 2.4236424962337855e-05,
      "loss": 0.0585,
      "step": 77330
    },
    {
      "epoch": 1.5466144062712475,
      "grad_norm": 0.18567845225334167,
      "learning_rate": 2.4233092028956528e-05,
      "loss": 0.0886,
      "step": 77340
    },
    {
      "epoch": 1.5468143822741272,
      "grad_norm": 0.11963070929050446,
      "learning_rate": 2.42297590955752e-05,
      "loss": 0.0804,
      "step": 77350
    },
    {
      "epoch": 1.5470143582770066,
      "grad_norm": 0.09241357445716858,
      "learning_rate": 2.422642616219387e-05,
      "loss": 0.0989,
      "step": 77360
    },
    {
      "epoch": 1.5472143342798863,
      "grad_norm": 0.0730152353644371,
      "learning_rate": 2.4223093228812543e-05,
      "loss": 0.0475,
      "step": 77370
    },
    {
      "epoch": 1.547414310282766,
      "grad_norm": 0.13555856049060822,
      "learning_rate": 2.4219760295431216e-05,
      "loss": 0.099,
      "step": 77380
    },
    {
      "epoch": 1.5476142862856457,
      "grad_norm": 0.049334872514009476,
      "learning_rate": 2.4216427362049886e-05,
      "loss": 0.0675,
      "step": 77390
    },
    {
      "epoch": 1.5478142622885254,
      "grad_norm": 0.09587615728378296,
      "learning_rate": 2.4213094428668562e-05,
      "loss": 0.0511,
      "step": 77400
    },
    {
      "epoch": 1.548014238291405,
      "grad_norm": 0.2026938498020172,
      "learning_rate": 2.4209761495287235e-05,
      "loss": 0.0791,
      "step": 77410
    },
    {
      "epoch": 1.5482142142942847,
      "grad_norm": 0.0843031257390976,
      "learning_rate": 2.4206428561905905e-05,
      "loss": 0.0713,
      "step": 77420
    },
    {
      "epoch": 1.5484141902971644,
      "grad_norm": 0.1699254959821701,
      "learning_rate": 2.4203095628524578e-05,
      "loss": 0.0478,
      "step": 77430
    },
    {
      "epoch": 1.5486141663000441,
      "grad_norm": 0.12403734028339386,
      "learning_rate": 2.419976269514325e-05,
      "loss": 0.0633,
      "step": 77440
    },
    {
      "epoch": 1.5488141423029238,
      "grad_norm": 0.12527316808700562,
      "learning_rate": 2.4196429761761924e-05,
      "loss": 0.0492,
      "step": 77450
    },
    {
      "epoch": 1.5490141183058033,
      "grad_norm": 0.09123077988624573,
      "learning_rate": 2.4193096828380597e-05,
      "loss": 0.0624,
      "step": 77460
    },
    {
      "epoch": 1.549214094308683,
      "grad_norm": 0.12574589252471924,
      "learning_rate": 2.4189763894999267e-05,
      "loss": 0.0766,
      "step": 77470
    },
    {
      "epoch": 1.5494140703115626,
      "grad_norm": 0.18331897258758545,
      "learning_rate": 2.418643096161794e-05,
      "loss": 0.0611,
      "step": 77480
    },
    {
      "epoch": 1.549614046314442,
      "grad_norm": 0.16623374819755554,
      "learning_rate": 2.4183098028236613e-05,
      "loss": 0.0929,
      "step": 77490
    },
    {
      "epoch": 1.5498140223173218,
      "grad_norm": 0.09164301306009293,
      "learning_rate": 2.4179765094855286e-05,
      "loss": 0.0711,
      "step": 77500
    },
    {
      "epoch": 1.5500139983202015,
      "grad_norm": 0.10399819165468216,
      "learning_rate": 2.417643216147396e-05,
      "loss": 0.0645,
      "step": 77510
    },
    {
      "epoch": 1.5502139743230812,
      "grad_norm": 0.14152902364730835,
      "learning_rate": 2.417309922809263e-05,
      "loss": 0.0576,
      "step": 77520
    },
    {
      "epoch": 1.5504139503259609,
      "grad_norm": 0.1980852633714676,
      "learning_rate": 2.41697662947113e-05,
      "loss": 0.0845,
      "step": 77530
    },
    {
      "epoch": 1.5506139263288405,
      "grad_norm": 0.20018087327480316,
      "learning_rate": 2.4166433361329974e-05,
      "loss": 0.0688,
      "step": 77540
    },
    {
      "epoch": 1.5508139023317202,
      "grad_norm": 0.10616829991340637,
      "learning_rate": 2.4163100427948647e-05,
      "loss": 0.0673,
      "step": 77550
    },
    {
      "epoch": 1.5510138783346,
      "grad_norm": 0.0687795877456665,
      "learning_rate": 2.415976749456732e-05,
      "loss": 0.0924,
      "step": 77560
    },
    {
      "epoch": 1.5512138543374796,
      "grad_norm": 0.07919960469007492,
      "learning_rate": 2.4156434561185993e-05,
      "loss": 0.0476,
      "step": 77570
    },
    {
      "epoch": 1.5514138303403593,
      "grad_norm": 0.06959277391433716,
      "learning_rate": 2.4153101627804663e-05,
      "loss": 0.081,
      "step": 77580
    },
    {
      "epoch": 1.551613806343239,
      "grad_norm": 0.09395785629749298,
      "learning_rate": 2.4149768694423336e-05,
      "loss": 0.0569,
      "step": 77590
    },
    {
      "epoch": 1.5518137823461184,
      "grad_norm": 0.06473443657159805,
      "learning_rate": 2.4146435761042012e-05,
      "loss": 0.0881,
      "step": 77600
    },
    {
      "epoch": 1.5520137583489981,
      "grad_norm": 0.15996414422988892,
      "learning_rate": 2.4143102827660682e-05,
      "loss": 0.0524,
      "step": 77610
    },
    {
      "epoch": 1.5522137343518778,
      "grad_norm": 0.20575006306171417,
      "learning_rate": 2.4139769894279355e-05,
      "loss": 0.0713,
      "step": 77620
    },
    {
      "epoch": 1.5524137103547573,
      "grad_norm": 0.12998059391975403,
      "learning_rate": 2.4136436960898028e-05,
      "loss": 0.0683,
      "step": 77630
    },
    {
      "epoch": 1.552613686357637,
      "grad_norm": 0.14893510937690735,
      "learning_rate": 2.4133104027516697e-05,
      "loss": 0.0945,
      "step": 77640
    },
    {
      "epoch": 1.5528136623605167,
      "grad_norm": 0.07849730551242828,
      "learning_rate": 2.4129771094135374e-05,
      "loss": 0.082,
      "step": 77650
    },
    {
      "epoch": 1.5530136383633963,
      "grad_norm": 0.16528016328811646,
      "learning_rate": 2.4126438160754043e-05,
      "loss": 0.073,
      "step": 77660
    },
    {
      "epoch": 1.553213614366276,
      "grad_norm": 0.18649592995643616,
      "learning_rate": 2.4123105227372716e-05,
      "loss": 0.0679,
      "step": 77670
    },
    {
      "epoch": 1.5534135903691557,
      "grad_norm": 0.099922314286232,
      "learning_rate": 2.411977229399139e-05,
      "loss": 0.0743,
      "step": 77680
    },
    {
      "epoch": 1.5536135663720354,
      "grad_norm": 0.16420601308345795,
      "learning_rate": 2.411643936061006e-05,
      "loss": 0.1289,
      "step": 77690
    },
    {
      "epoch": 1.553813542374915,
      "grad_norm": 0.06079689413309097,
      "learning_rate": 2.4113106427228735e-05,
      "loss": 0.0427,
      "step": 77700
    },
    {
      "epoch": 1.5540135183777948,
      "grad_norm": 0.17125138640403748,
      "learning_rate": 2.410977349384741e-05,
      "loss": 0.1016,
      "step": 77710
    },
    {
      "epoch": 1.5542134943806745,
      "grad_norm": 0.1301913857460022,
      "learning_rate": 2.4106440560466078e-05,
      "loss": 0.0616,
      "step": 77720
    },
    {
      "epoch": 1.554413470383554,
      "grad_norm": 0.12141458690166473,
      "learning_rate": 2.410310762708475e-05,
      "loss": 0.0903,
      "step": 77730
    },
    {
      "epoch": 1.5546134463864336,
      "grad_norm": 0.1582617312669754,
      "learning_rate": 2.4099774693703424e-05,
      "loss": 0.0839,
      "step": 77740
    },
    {
      "epoch": 1.5548134223893133,
      "grad_norm": 0.10815108567476273,
      "learning_rate": 2.4096441760322097e-05,
      "loss": 0.0353,
      "step": 77750
    },
    {
      "epoch": 1.555013398392193,
      "grad_norm": 0.1769169270992279,
      "learning_rate": 2.409310882694077e-05,
      "loss": 0.0964,
      "step": 77760
    },
    {
      "epoch": 1.5552133743950725,
      "grad_norm": 0.13073480129241943,
      "learning_rate": 2.408977589355944e-05,
      "loss": 0.0838,
      "step": 77770
    },
    {
      "epoch": 1.5554133503979521,
      "grad_norm": 0.11052923649549484,
      "learning_rate": 2.4086442960178113e-05,
      "loss": 0.046,
      "step": 77780
    },
    {
      "epoch": 1.5556133264008318,
      "grad_norm": 0.27663522958755493,
      "learning_rate": 2.4083110026796786e-05,
      "loss": 0.1013,
      "step": 77790
    },
    {
      "epoch": 1.5558133024037115,
      "grad_norm": 0.18393054604530334,
      "learning_rate": 2.407977709341546e-05,
      "loss": 0.1158,
      "step": 77800
    },
    {
      "epoch": 1.5560132784065912,
      "grad_norm": 0.09905990213155746,
      "learning_rate": 2.4076444160034132e-05,
      "loss": 0.0523,
      "step": 77810
    },
    {
      "epoch": 1.556213254409471,
      "grad_norm": 0.07259505987167358,
      "learning_rate": 2.4073111226652805e-05,
      "loss": 0.0632,
      "step": 77820
    },
    {
      "epoch": 1.5564132304123506,
      "grad_norm": 0.17108865082263947,
      "learning_rate": 2.4069778293271474e-05,
      "loss": 0.1027,
      "step": 77830
    },
    {
      "epoch": 1.5566132064152303,
      "grad_norm": 0.11940501630306244,
      "learning_rate": 2.4066445359890147e-05,
      "loss": 0.0584,
      "step": 77840
    },
    {
      "epoch": 1.55681318241811,
      "grad_norm": 0.10061433911323547,
      "learning_rate": 2.406311242650882e-05,
      "loss": 0.0917,
      "step": 77850
    },
    {
      "epoch": 1.5570131584209896,
      "grad_norm": 0.07782834023237228,
      "learning_rate": 2.4059779493127493e-05,
      "loss": 0.059,
      "step": 77860
    },
    {
      "epoch": 1.557213134423869,
      "grad_norm": 0.16217131912708282,
      "learning_rate": 2.4056446559746166e-05,
      "loss": 0.0806,
      "step": 77870
    },
    {
      "epoch": 1.5574131104267488,
      "grad_norm": 0.11182147264480591,
      "learning_rate": 2.4053113626364836e-05,
      "loss": 0.0545,
      "step": 77880
    },
    {
      "epoch": 1.5576130864296285,
      "grad_norm": 0.1498805731534958,
      "learning_rate": 2.404978069298351e-05,
      "loss": 0.0523,
      "step": 77890
    },
    {
      "epoch": 1.557813062432508,
      "grad_norm": 0.10021524876356125,
      "learning_rate": 2.4046447759602182e-05,
      "loss": 0.0605,
      "step": 77900
    },
    {
      "epoch": 1.5580130384353876,
      "grad_norm": 0.11796009540557861,
      "learning_rate": 2.4043114826220855e-05,
      "loss": 0.0641,
      "step": 77910
    },
    {
      "epoch": 1.5582130144382673,
      "grad_norm": 0.16293621063232422,
      "learning_rate": 2.4039781892839528e-05,
      "loss": 0.0457,
      "step": 77920
    },
    {
      "epoch": 1.558412990441147,
      "grad_norm": 0.26037776470184326,
      "learning_rate": 2.40364489594582e-05,
      "loss": 0.0864,
      "step": 77930
    },
    {
      "epoch": 1.5586129664440267,
      "grad_norm": 0.1924014836549759,
      "learning_rate": 2.403311602607687e-05,
      "loss": 0.082,
      "step": 77940
    },
    {
      "epoch": 1.5588129424469064,
      "grad_norm": 0.13175664842128754,
      "learning_rate": 2.4029783092695544e-05,
      "loss": 0.0849,
      "step": 77950
    },
    {
      "epoch": 1.559012918449786,
      "grad_norm": 0.12275685369968414,
      "learning_rate": 2.4026450159314217e-05,
      "loss": 0.0587,
      "step": 77960
    },
    {
      "epoch": 1.5592128944526658,
      "grad_norm": 0.16791269183158875,
      "learning_rate": 2.402311722593289e-05,
      "loss": 0.0706,
      "step": 77970
    },
    {
      "epoch": 1.5594128704555454,
      "grad_norm": 0.08308766037225723,
      "learning_rate": 2.4019784292551563e-05,
      "loss": 0.0644,
      "step": 77980
    },
    {
      "epoch": 1.5596128464584251,
      "grad_norm": 0.11210915446281433,
      "learning_rate": 2.4016451359170232e-05,
      "loss": 0.0638,
      "step": 77990
    },
    {
      "epoch": 1.5598128224613046,
      "grad_norm": 0.09884248673915863,
      "learning_rate": 2.4013118425788905e-05,
      "loss": 0.0997,
      "step": 78000
    },
    {
      "epoch": 1.5600127984641843,
      "grad_norm": 0.10078239440917969,
      "learning_rate": 2.4009785492407578e-05,
      "loss": 0.062,
      "step": 78010
    },
    {
      "epoch": 1.560212774467064,
      "grad_norm": 0.1851690113544464,
      "learning_rate": 2.400645255902625e-05,
      "loss": 0.0724,
      "step": 78020
    },
    {
      "epoch": 1.5604127504699437,
      "grad_norm": 0.0897810161113739,
      "learning_rate": 2.4003119625644924e-05,
      "loss": 0.0637,
      "step": 78030
    },
    {
      "epoch": 1.5606127264728231,
      "grad_norm": 0.16188126802444458,
      "learning_rate": 2.3999786692263594e-05,
      "loss": 0.0788,
      "step": 78040
    },
    {
      "epoch": 1.5608127024757028,
      "grad_norm": 0.20487353205680847,
      "learning_rate": 2.3996453758882267e-05,
      "loss": 0.0815,
      "step": 78050
    },
    {
      "epoch": 1.5610126784785825,
      "grad_norm": 0.11840786784887314,
      "learning_rate": 2.3993120825500943e-05,
      "loss": 0.0951,
      "step": 78060
    },
    {
      "epoch": 1.5612126544814622,
      "grad_norm": 0.24715131521224976,
      "learning_rate": 2.3989787892119613e-05,
      "loss": 0.1391,
      "step": 78070
    },
    {
      "epoch": 1.5614126304843419,
      "grad_norm": 0.057815514504909515,
      "learning_rate": 2.3986454958738286e-05,
      "loss": 0.0601,
      "step": 78080
    },
    {
      "epoch": 1.5616126064872216,
      "grad_norm": 0.0776926577091217,
      "learning_rate": 2.398312202535696e-05,
      "loss": 0.0596,
      "step": 78090
    },
    {
      "epoch": 1.5618125824901012,
      "grad_norm": 0.1795574575662613,
      "learning_rate": 2.397978909197563e-05,
      "loss": 0.1397,
      "step": 78100
    },
    {
      "epoch": 1.562012558492981,
      "grad_norm": 0.15891455113887787,
      "learning_rate": 2.3976456158594305e-05,
      "loss": 0.0598,
      "step": 78110
    },
    {
      "epoch": 1.5622125344958606,
      "grad_norm": 0.11649925261735916,
      "learning_rate": 2.3973123225212975e-05,
      "loss": 0.0755,
      "step": 78120
    },
    {
      "epoch": 1.5624125104987403,
      "grad_norm": 0.15169496834278107,
      "learning_rate": 2.3969790291831648e-05,
      "loss": 0.0975,
      "step": 78130
    },
    {
      "epoch": 1.5626124865016198,
      "grad_norm": 0.16294853389263153,
      "learning_rate": 2.396645735845032e-05,
      "loss": 0.0893,
      "step": 78140
    },
    {
      "epoch": 1.5628124625044995,
      "grad_norm": 0.10533420741558075,
      "learning_rate": 2.396312442506899e-05,
      "loss": 0.0871,
      "step": 78150
    },
    {
      "epoch": 1.5630124385073791,
      "grad_norm": 0.14650790393352509,
      "learning_rate": 2.3959791491687667e-05,
      "loss": 0.0609,
      "step": 78160
    },
    {
      "epoch": 1.5632124145102586,
      "grad_norm": 0.13615912199020386,
      "learning_rate": 2.395645855830634e-05,
      "loss": 0.0404,
      "step": 78170
    },
    {
      "epoch": 1.5634123905131383,
      "grad_norm": 0.0958843007683754,
      "learning_rate": 2.395312562492501e-05,
      "loss": 0.0808,
      "step": 78180
    },
    {
      "epoch": 1.563612366516018,
      "grad_norm": 0.22148863971233368,
      "learning_rate": 2.3949792691543682e-05,
      "loss": 0.0614,
      "step": 78190
    },
    {
      "epoch": 1.5638123425188977,
      "grad_norm": 0.09737296402454376,
      "learning_rate": 2.3946459758162355e-05,
      "loss": 0.0562,
      "step": 78200
    },
    {
      "epoch": 1.5640123185217774,
      "grad_norm": 0.09736765921115875,
      "learning_rate": 2.3943126824781028e-05,
      "loss": 0.0811,
      "step": 78210
    },
    {
      "epoch": 1.564212294524657,
      "grad_norm": 0.10411527007818222,
      "learning_rate": 2.39397938913997e-05,
      "loss": 0.0711,
      "step": 78220
    },
    {
      "epoch": 1.5644122705275367,
      "grad_norm": 0.09638441354036331,
      "learning_rate": 2.393646095801837e-05,
      "loss": 0.0751,
      "step": 78230
    },
    {
      "epoch": 1.5646122465304164,
      "grad_norm": 0.19984716176986694,
      "learning_rate": 2.3933128024637044e-05,
      "loss": 0.0737,
      "step": 78240
    },
    {
      "epoch": 1.564812222533296,
      "grad_norm": 0.04451669007539749,
      "learning_rate": 2.3929795091255717e-05,
      "loss": 0.0571,
      "step": 78250
    },
    {
      "epoch": 1.5650121985361758,
      "grad_norm": 0.09925422072410583,
      "learning_rate": 2.392646215787439e-05,
      "loss": 0.0725,
      "step": 78260
    },
    {
      "epoch": 1.5652121745390555,
      "grad_norm": 0.12409374862909317,
      "learning_rate": 2.3923129224493063e-05,
      "loss": 0.0922,
      "step": 78270
    },
    {
      "epoch": 1.565412150541935,
      "grad_norm": 0.16992095112800598,
      "learning_rate": 2.3919796291111736e-05,
      "loss": 0.0728,
      "step": 78280
    },
    {
      "epoch": 1.5656121265448146,
      "grad_norm": 0.22220206260681152,
      "learning_rate": 2.3916463357730405e-05,
      "loss": 0.0873,
      "step": 78290
    },
    {
      "epoch": 1.5658121025476943,
      "grad_norm": 0.15237385034561157,
      "learning_rate": 2.391313042434908e-05,
      "loss": 0.063,
      "step": 78300
    },
    {
      "epoch": 1.5660120785505738,
      "grad_norm": 0.10915470868349075,
      "learning_rate": 2.390979749096775e-05,
      "loss": 0.0828,
      "step": 78310
    },
    {
      "epoch": 1.5662120545534535,
      "grad_norm": 0.09936502575874329,
      "learning_rate": 2.3906464557586424e-05,
      "loss": 0.0547,
      "step": 78320
    },
    {
      "epoch": 1.5664120305563332,
      "grad_norm": 0.16688306629657745,
      "learning_rate": 2.3903131624205097e-05,
      "loss": 0.0731,
      "step": 78330
    },
    {
      "epoch": 1.5666120065592128,
      "grad_norm": 0.0987139418721199,
      "learning_rate": 2.3899798690823767e-05,
      "loss": 0.0684,
      "step": 78340
    },
    {
      "epoch": 1.5668119825620925,
      "grad_norm": 0.17989274859428406,
      "learning_rate": 2.389646575744244e-05,
      "loss": 0.0999,
      "step": 78350
    },
    {
      "epoch": 1.5670119585649722,
      "grad_norm": 0.07818422466516495,
      "learning_rate": 2.3893132824061116e-05,
      "loss": 0.0816,
      "step": 78360
    },
    {
      "epoch": 1.567211934567852,
      "grad_norm": 0.19993510842323303,
      "learning_rate": 2.3889799890679786e-05,
      "loss": 0.1142,
      "step": 78370
    },
    {
      "epoch": 1.5674119105707316,
      "grad_norm": 0.22492246329784393,
      "learning_rate": 2.388646695729846e-05,
      "loss": 0.0671,
      "step": 78380
    },
    {
      "epoch": 1.5676118865736113,
      "grad_norm": 0.1299673616886139,
      "learning_rate": 2.3883134023917132e-05,
      "loss": 0.0738,
      "step": 78390
    },
    {
      "epoch": 1.567811862576491,
      "grad_norm": 0.21002884209156036,
      "learning_rate": 2.38798010905358e-05,
      "loss": 0.0946,
      "step": 78400
    },
    {
      "epoch": 1.5680118385793704,
      "grad_norm": 0.1725098043680191,
      "learning_rate": 2.3876468157154475e-05,
      "loss": 0.0778,
      "step": 78410
    },
    {
      "epoch": 1.5682118145822501,
      "grad_norm": 0.19176651537418365,
      "learning_rate": 2.3873135223773148e-05,
      "loss": 0.0756,
      "step": 78420
    },
    {
      "epoch": 1.5684117905851298,
      "grad_norm": 0.12182233482599258,
      "learning_rate": 2.386980229039182e-05,
      "loss": 0.08,
      "step": 78430
    },
    {
      "epoch": 1.5686117665880095,
      "grad_norm": 0.191654235124588,
      "learning_rate": 2.3866469357010494e-05,
      "loss": 0.0578,
      "step": 78440
    },
    {
      "epoch": 1.568811742590889,
      "grad_norm": 0.08151143789291382,
      "learning_rate": 2.3863136423629163e-05,
      "loss": 0.108,
      "step": 78450
    },
    {
      "epoch": 1.5690117185937686,
      "grad_norm": 0.23142094910144806,
      "learning_rate": 2.3859803490247836e-05,
      "loss": 0.0923,
      "step": 78460
    },
    {
      "epoch": 1.5692116945966483,
      "grad_norm": 0.15049397945404053,
      "learning_rate": 2.3856470556866513e-05,
      "loss": 0.0751,
      "step": 78470
    },
    {
      "epoch": 1.569411670599528,
      "grad_norm": 0.0843857154250145,
      "learning_rate": 2.3853137623485182e-05,
      "loss": 0.1279,
      "step": 78480
    },
    {
      "epoch": 1.5696116466024077,
      "grad_norm": 0.2063530534505844,
      "learning_rate": 2.3849804690103855e-05,
      "loss": 0.0772,
      "step": 78490
    },
    {
      "epoch": 1.5698116226052874,
      "grad_norm": 0.16880933940410614,
      "learning_rate": 2.384647175672253e-05,
      "loss": 0.0605,
      "step": 78500
    },
    {
      "epoch": 1.570011598608167,
      "grad_norm": 0.13928568363189697,
      "learning_rate": 2.3843138823341198e-05,
      "loss": 0.0605,
      "step": 78510
    },
    {
      "epoch": 1.5702115746110468,
      "grad_norm": 0.1268133521080017,
      "learning_rate": 2.3839805889959874e-05,
      "loss": 0.0922,
      "step": 78520
    },
    {
      "epoch": 1.5704115506139265,
      "grad_norm": 0.1771000474691391,
      "learning_rate": 2.3836472956578544e-05,
      "loss": 0.1219,
      "step": 78530
    },
    {
      "epoch": 1.5706115266168061,
      "grad_norm": 0.0929781049489975,
      "learning_rate": 2.3833140023197217e-05,
      "loss": 0.1012,
      "step": 78540
    },
    {
      "epoch": 1.5708115026196856,
      "grad_norm": 0.05544191598892212,
      "learning_rate": 2.382980708981589e-05,
      "loss": 0.0554,
      "step": 78550
    },
    {
      "epoch": 1.5710114786225653,
      "grad_norm": 0.17152000963687897,
      "learning_rate": 2.382647415643456e-05,
      "loss": 0.0796,
      "step": 78560
    },
    {
      "epoch": 1.571211454625445,
      "grad_norm": 0.05219549685716629,
      "learning_rate": 2.3823141223053236e-05,
      "loss": 0.0698,
      "step": 78570
    },
    {
      "epoch": 1.5714114306283244,
      "grad_norm": 0.1873389333486557,
      "learning_rate": 2.381980828967191e-05,
      "loss": 0.0859,
      "step": 78580
    },
    {
      "epoch": 1.5716114066312041,
      "grad_norm": 0.16157355904579163,
      "learning_rate": 2.381647535629058e-05,
      "loss": 0.0634,
      "step": 78590
    },
    {
      "epoch": 1.5718113826340838,
      "grad_norm": 0.18027694523334503,
      "learning_rate": 2.381314242290925e-05,
      "loss": 0.0719,
      "step": 78600
    },
    {
      "epoch": 1.5720113586369635,
      "grad_norm": 0.1860211044549942,
      "learning_rate": 2.3809809489527925e-05,
      "loss": 0.0676,
      "step": 78610
    },
    {
      "epoch": 1.5722113346398432,
      "grad_norm": 0.18931584060192108,
      "learning_rate": 2.3806476556146598e-05,
      "loss": 0.0748,
      "step": 78620
    },
    {
      "epoch": 1.5724113106427229,
      "grad_norm": 0.11218187212944031,
      "learning_rate": 2.380314362276527e-05,
      "loss": 0.1126,
      "step": 78630
    },
    {
      "epoch": 1.5726112866456026,
      "grad_norm": 0.217465341091156,
      "learning_rate": 2.379981068938394e-05,
      "loss": 0.0921,
      "step": 78640
    },
    {
      "epoch": 1.5728112626484823,
      "grad_norm": 0.3040398955345154,
      "learning_rate": 2.3796477756002613e-05,
      "loss": 0.1392,
      "step": 78650
    },
    {
      "epoch": 1.573011238651362,
      "grad_norm": 0.08313623815774918,
      "learning_rate": 2.3793144822621286e-05,
      "loss": 0.07,
      "step": 78660
    },
    {
      "epoch": 1.5732112146542416,
      "grad_norm": 0.13109900057315826,
      "learning_rate": 2.378981188923996e-05,
      "loss": 0.0633,
      "step": 78670
    },
    {
      "epoch": 1.573411190657121,
      "grad_norm": 0.14242027699947357,
      "learning_rate": 2.3786478955858632e-05,
      "loss": 0.0723,
      "step": 78680
    },
    {
      "epoch": 1.5736111666600008,
      "grad_norm": 0.1256541609764099,
      "learning_rate": 2.3783146022477305e-05,
      "loss": 0.0665,
      "step": 78690
    },
    {
      "epoch": 1.5738111426628805,
      "grad_norm": 0.10602305829524994,
      "learning_rate": 2.3779813089095975e-05,
      "loss": 0.0416,
      "step": 78700
    },
    {
      "epoch": 1.5740111186657602,
      "grad_norm": 0.2582295536994934,
      "learning_rate": 2.3776480155714648e-05,
      "loss": 0.0623,
      "step": 78710
    },
    {
      "epoch": 1.5742110946686396,
      "grad_norm": 0.08722834289073944,
      "learning_rate": 2.377314722233332e-05,
      "loss": 0.0757,
      "step": 78720
    },
    {
      "epoch": 1.5744110706715193,
      "grad_norm": 0.11046581715345383,
      "learning_rate": 2.3769814288951994e-05,
      "loss": 0.0564,
      "step": 78730
    },
    {
      "epoch": 1.574611046674399,
      "grad_norm": 0.1443791389465332,
      "learning_rate": 2.3766481355570667e-05,
      "loss": 0.0497,
      "step": 78740
    },
    {
      "epoch": 1.5748110226772787,
      "grad_norm": 0.1888636201620102,
      "learning_rate": 2.3763148422189336e-05,
      "loss": 0.0761,
      "step": 78750
    },
    {
      "epoch": 1.5750109986801584,
      "grad_norm": 0.10286518931388855,
      "learning_rate": 2.375981548880801e-05,
      "loss": 0.0836,
      "step": 78760
    },
    {
      "epoch": 1.575210974683038,
      "grad_norm": 0.10906577855348587,
      "learning_rate": 2.3756482555426686e-05,
      "loss": 0.0608,
      "step": 78770
    },
    {
      "epoch": 1.5754109506859177,
      "grad_norm": 0.09817737340927124,
      "learning_rate": 2.3753149622045356e-05,
      "loss": 0.0682,
      "step": 78780
    },
    {
      "epoch": 1.5756109266887974,
      "grad_norm": 0.1708272099494934,
      "learning_rate": 2.374981668866403e-05,
      "loss": 0.0675,
      "step": 78790
    },
    {
      "epoch": 1.5758109026916771,
      "grad_norm": 0.06569148600101471,
      "learning_rate": 2.37464837552827e-05,
      "loss": 0.0446,
      "step": 78800
    },
    {
      "epoch": 1.5760108786945568,
      "grad_norm": 0.1461414247751236,
      "learning_rate": 2.374315082190137e-05,
      "loss": 0.0481,
      "step": 78810
    },
    {
      "epoch": 1.5762108546974363,
      "grad_norm": 0.1647409200668335,
      "learning_rate": 2.3739817888520048e-05,
      "loss": 0.0674,
      "step": 78820
    },
    {
      "epoch": 1.576410830700316,
      "grad_norm": 0.21738244593143463,
      "learning_rate": 2.3736484955138717e-05,
      "loss": 0.0867,
      "step": 78830
    },
    {
      "epoch": 1.5766108067031956,
      "grad_norm": 0.181072399020195,
      "learning_rate": 2.373315202175739e-05,
      "loss": 0.0736,
      "step": 78840
    },
    {
      "epoch": 1.576810782706075,
      "grad_norm": 0.10769028961658478,
      "learning_rate": 2.3729819088376063e-05,
      "loss": 0.0629,
      "step": 78850
    },
    {
      "epoch": 1.5770107587089548,
      "grad_norm": 0.12579144537448883,
      "learning_rate": 2.3726486154994733e-05,
      "loss": 0.0978,
      "step": 78860
    },
    {
      "epoch": 1.5772107347118345,
      "grad_norm": 0.06055168807506561,
      "learning_rate": 2.3723153221613406e-05,
      "loss": 0.079,
      "step": 78870
    },
    {
      "epoch": 1.5774107107147142,
      "grad_norm": 0.09505344927310944,
      "learning_rate": 2.3719820288232082e-05,
      "loss": 0.0534,
      "step": 78880
    },
    {
      "epoch": 1.5776106867175939,
      "grad_norm": 0.0866243839263916,
      "learning_rate": 2.3716487354850752e-05,
      "loss": 0.071,
      "step": 78890
    },
    {
      "epoch": 1.5778106627204735,
      "grad_norm": 0.056897666305303574,
      "learning_rate": 2.3713154421469425e-05,
      "loss": 0.0572,
      "step": 78900
    },
    {
      "epoch": 1.5780106387233532,
      "grad_norm": 0.11151792109012604,
      "learning_rate": 2.3709821488088098e-05,
      "loss": 0.0692,
      "step": 78910
    },
    {
      "epoch": 1.578210614726233,
      "grad_norm": 0.18151478469371796,
      "learning_rate": 2.3706488554706767e-05,
      "loss": 0.0813,
      "step": 78920
    },
    {
      "epoch": 1.5784105907291126,
      "grad_norm": 0.06251263618469238,
      "learning_rate": 2.3703155621325444e-05,
      "loss": 0.0773,
      "step": 78930
    },
    {
      "epoch": 1.5786105667319923,
      "grad_norm": 0.18438935279846191,
      "learning_rate": 2.3699822687944113e-05,
      "loss": 0.0737,
      "step": 78940
    },
    {
      "epoch": 1.578810542734872,
      "grad_norm": 0.13805720210075378,
      "learning_rate": 2.3696489754562786e-05,
      "loss": 0.0863,
      "step": 78950
    },
    {
      "epoch": 1.5790105187377514,
      "grad_norm": 0.10133036226034164,
      "learning_rate": 2.369315682118146e-05,
      "loss": 0.0641,
      "step": 78960
    },
    {
      "epoch": 1.5792104947406311,
      "grad_norm": 0.16708572208881378,
      "learning_rate": 2.368982388780013e-05,
      "loss": 0.0764,
      "step": 78970
    },
    {
      "epoch": 1.5794104707435108,
      "grad_norm": 0.07496953010559082,
      "learning_rate": 2.3686490954418805e-05,
      "loss": 0.0664,
      "step": 78980
    },
    {
      "epoch": 1.5796104467463903,
      "grad_norm": 0.09846934676170349,
      "learning_rate": 2.368315802103748e-05,
      "loss": 0.0809,
      "step": 78990
    },
    {
      "epoch": 1.57981042274927,
      "grad_norm": 0.10647639632225037,
      "learning_rate": 2.3679825087656148e-05,
      "loss": 0.0636,
      "step": 79000
    },
    {
      "epoch": 1.5800103987521497,
      "grad_norm": 0.10464317351579666,
      "learning_rate": 2.367649215427482e-05,
      "loss": 0.0855,
      "step": 79010
    },
    {
      "epoch": 1.5802103747550293,
      "grad_norm": 0.10976392030715942,
      "learning_rate": 2.3673159220893494e-05,
      "loss": 0.0687,
      "step": 79020
    },
    {
      "epoch": 1.580410350757909,
      "grad_norm": 0.13453859090805054,
      "learning_rate": 2.3669826287512167e-05,
      "loss": 0.0477,
      "step": 79030
    },
    {
      "epoch": 1.5806103267607887,
      "grad_norm": 0.09647994488477707,
      "learning_rate": 2.366649335413084e-05,
      "loss": 0.0705,
      "step": 79040
    },
    {
      "epoch": 1.5808103027636684,
      "grad_norm": 0.09540607035160065,
      "learning_rate": 2.366316042074951e-05,
      "loss": 0.0356,
      "step": 79050
    },
    {
      "epoch": 1.581010278766548,
      "grad_norm": 0.07468441128730774,
      "learning_rate": 2.3659827487368183e-05,
      "loss": 0.0706,
      "step": 79060
    },
    {
      "epoch": 1.5812102547694278,
      "grad_norm": 0.1706443428993225,
      "learning_rate": 2.3656494553986856e-05,
      "loss": 0.064,
      "step": 79070
    },
    {
      "epoch": 1.5814102307723075,
      "grad_norm": 0.10294967144727707,
      "learning_rate": 2.365316162060553e-05,
      "loss": 0.0719,
      "step": 79080
    },
    {
      "epoch": 1.581610206775187,
      "grad_norm": 0.11888941377401352,
      "learning_rate": 2.36498286872242e-05,
      "loss": 0.0709,
      "step": 79090
    },
    {
      "epoch": 1.5818101827780666,
      "grad_norm": 0.19728942215442657,
      "learning_rate": 2.3646495753842875e-05,
      "loss": 0.082,
      "step": 79100
    },
    {
      "epoch": 1.5820101587809463,
      "grad_norm": 0.12063001096248627,
      "learning_rate": 2.3643162820461544e-05,
      "loss": 0.0736,
      "step": 79110
    },
    {
      "epoch": 1.582210134783826,
      "grad_norm": 0.056798066943883896,
      "learning_rate": 2.3639829887080217e-05,
      "loss": 0.1031,
      "step": 79120
    },
    {
      "epoch": 1.5824101107867055,
      "grad_norm": 0.12664206326007843,
      "learning_rate": 2.363649695369889e-05,
      "loss": 0.0644,
      "step": 79130
    },
    {
      "epoch": 1.5826100867895851,
      "grad_norm": 0.14252915978431702,
      "learning_rate": 2.3633164020317563e-05,
      "loss": 0.0624,
      "step": 79140
    },
    {
      "epoch": 1.5828100627924648,
      "grad_norm": 0.20444214344024658,
      "learning_rate": 2.3629831086936236e-05,
      "loss": 0.071,
      "step": 79150
    },
    {
      "epoch": 1.5830100387953445,
      "grad_norm": 0.07420694082975388,
      "learning_rate": 2.3626498153554906e-05,
      "loss": 0.0519,
      "step": 79160
    },
    {
      "epoch": 1.5832100147982242,
      "grad_norm": 0.09585978835821152,
      "learning_rate": 2.362316522017358e-05,
      "loss": 0.0868,
      "step": 79170
    },
    {
      "epoch": 1.583409990801104,
      "grad_norm": 0.100029356777668,
      "learning_rate": 2.3619832286792255e-05,
      "loss": 0.0854,
      "step": 79180
    },
    {
      "epoch": 1.5836099668039836,
      "grad_norm": 0.1484619677066803,
      "learning_rate": 2.3616499353410925e-05,
      "loss": 0.0677,
      "step": 79190
    },
    {
      "epoch": 1.5838099428068633,
      "grad_norm": 0.13105976581573486,
      "learning_rate": 2.3613166420029598e-05,
      "loss": 0.0883,
      "step": 79200
    },
    {
      "epoch": 1.584009918809743,
      "grad_norm": 0.06951810419559479,
      "learning_rate": 2.360983348664827e-05,
      "loss": 0.0455,
      "step": 79210
    },
    {
      "epoch": 1.5842098948126226,
      "grad_norm": 0.21190842986106873,
      "learning_rate": 2.360650055326694e-05,
      "loss": 0.1105,
      "step": 79220
    },
    {
      "epoch": 1.584409870815502,
      "grad_norm": 0.2582763433456421,
      "learning_rate": 2.3603167619885617e-05,
      "loss": 0.0831,
      "step": 79230
    },
    {
      "epoch": 1.5846098468183818,
      "grad_norm": 0.21344168484210968,
      "learning_rate": 2.3599834686504287e-05,
      "loss": 0.0803,
      "step": 79240
    },
    {
      "epoch": 1.5848098228212615,
      "grad_norm": 0.07306574285030365,
      "learning_rate": 2.359650175312296e-05,
      "loss": 0.0821,
      "step": 79250
    },
    {
      "epoch": 1.585009798824141,
      "grad_norm": 0.15604451298713684,
      "learning_rate": 2.3593168819741633e-05,
      "loss": 0.0706,
      "step": 79260
    },
    {
      "epoch": 1.5852097748270206,
      "grad_norm": 0.1982143670320511,
      "learning_rate": 2.3589835886360302e-05,
      "loss": 0.0823,
      "step": 79270
    },
    {
      "epoch": 1.5854097508299003,
      "grad_norm": 0.17251485586166382,
      "learning_rate": 2.358650295297898e-05,
      "loss": 0.0833,
      "step": 79280
    },
    {
      "epoch": 1.58560972683278,
      "grad_norm": 0.1791769564151764,
      "learning_rate": 2.358317001959765e-05,
      "loss": 0.1084,
      "step": 79290
    },
    {
      "epoch": 1.5858097028356597,
      "grad_norm": 0.12406107783317566,
      "learning_rate": 2.357983708621632e-05,
      "loss": 0.0807,
      "step": 79300
    },
    {
      "epoch": 1.5860096788385394,
      "grad_norm": 0.19256915152072906,
      "learning_rate": 2.3576504152834994e-05,
      "loss": 0.1013,
      "step": 79310
    },
    {
      "epoch": 1.586209654841419,
      "grad_norm": 0.12972991168498993,
      "learning_rate": 2.3573171219453667e-05,
      "loss": 0.078,
      "step": 79320
    },
    {
      "epoch": 1.5864096308442988,
      "grad_norm": 0.0820666253566742,
      "learning_rate": 2.356983828607234e-05,
      "loss": 0.0681,
      "step": 79330
    },
    {
      "epoch": 1.5866096068471784,
      "grad_norm": 0.13512487709522247,
      "learning_rate": 2.3566505352691013e-05,
      "loss": 0.0932,
      "step": 79340
    },
    {
      "epoch": 1.5868095828500581,
      "grad_norm": 0.2040424644947052,
      "learning_rate": 2.3563172419309683e-05,
      "loss": 0.0796,
      "step": 79350
    },
    {
      "epoch": 1.5870095588529376,
      "grad_norm": 0.14088518917560577,
      "learning_rate": 2.3559839485928356e-05,
      "loss": 0.0567,
      "step": 79360
    },
    {
      "epoch": 1.5872095348558173,
      "grad_norm": 0.16867563128471375,
      "learning_rate": 2.355650655254703e-05,
      "loss": 0.0792,
      "step": 79370
    },
    {
      "epoch": 1.587409510858697,
      "grad_norm": 0.11782097816467285,
      "learning_rate": 2.35531736191657e-05,
      "loss": 0.077,
      "step": 79380
    },
    {
      "epoch": 1.5876094868615767,
      "grad_norm": 0.11920050531625748,
      "learning_rate": 2.3549840685784375e-05,
      "loss": 0.0519,
      "step": 79390
    },
    {
      "epoch": 1.5878094628644561,
      "grad_norm": 0.10904961079359055,
      "learning_rate": 2.3546507752403048e-05,
      "loss": 0.085,
      "step": 79400
    },
    {
      "epoch": 1.5880094388673358,
      "grad_norm": 0.13390183448791504,
      "learning_rate": 2.3543174819021717e-05,
      "loss": 0.0916,
      "step": 79410
    },
    {
      "epoch": 1.5882094148702155,
      "grad_norm": 0.08802363276481628,
      "learning_rate": 2.353984188564039e-05,
      "loss": 0.0598,
      "step": 79420
    },
    {
      "epoch": 1.5884093908730952,
      "grad_norm": 0.0772385522723198,
      "learning_rate": 2.3536508952259063e-05,
      "loss": 0.0496,
      "step": 79430
    },
    {
      "epoch": 1.5886093668759749,
      "grad_norm": 0.1708911806344986,
      "learning_rate": 2.3533176018877737e-05,
      "loss": 0.0643,
      "step": 79440
    },
    {
      "epoch": 1.5888093428788546,
      "grad_norm": 0.25528883934020996,
      "learning_rate": 2.352984308549641e-05,
      "loss": 0.0874,
      "step": 79450
    },
    {
      "epoch": 1.5890093188817342,
      "grad_norm": 0.10289648175239563,
      "learning_rate": 2.352651015211508e-05,
      "loss": 0.1002,
      "step": 79460
    },
    {
      "epoch": 1.589209294884614,
      "grad_norm": 0.2013775259256363,
      "learning_rate": 2.3523177218733752e-05,
      "loss": 0.0897,
      "step": 79470
    },
    {
      "epoch": 1.5894092708874936,
      "grad_norm": 0.07972663640975952,
      "learning_rate": 2.3519844285352425e-05,
      "loss": 0.0684,
      "step": 79480
    },
    {
      "epoch": 1.5896092468903733,
      "grad_norm": 0.10834674537181854,
      "learning_rate": 2.3516511351971098e-05,
      "loss": 0.0715,
      "step": 79490
    },
    {
      "epoch": 1.5898092228932528,
      "grad_norm": 0.08874130994081497,
      "learning_rate": 2.351317841858977e-05,
      "loss": 0.0745,
      "step": 79500
    },
    {
      "epoch": 1.5900091988961325,
      "grad_norm": 0.07708311080932617,
      "learning_rate": 2.3509845485208444e-05,
      "loss": 0.0277,
      "step": 79510
    },
    {
      "epoch": 1.5902091748990121,
      "grad_norm": 0.09453169256448746,
      "learning_rate": 2.3506512551827114e-05,
      "loss": 0.0621,
      "step": 79520
    },
    {
      "epoch": 1.5904091509018916,
      "grad_norm": 0.14224062860012054,
      "learning_rate": 2.3503179618445787e-05,
      "loss": 0.0361,
      "step": 79530
    },
    {
      "epoch": 1.5906091269047713,
      "grad_norm": 0.11688096076250076,
      "learning_rate": 2.349984668506446e-05,
      "loss": 0.077,
      "step": 79540
    },
    {
      "epoch": 1.590809102907651,
      "grad_norm": 0.056053221225738525,
      "learning_rate": 2.3496513751683133e-05,
      "loss": 0.0839,
      "step": 79550
    },
    {
      "epoch": 1.5910090789105307,
      "grad_norm": 0.16241034865379333,
      "learning_rate": 2.3493180818301806e-05,
      "loss": 0.084,
      "step": 79560
    },
    {
      "epoch": 1.5912090549134104,
      "grad_norm": 0.042424675077199936,
      "learning_rate": 2.3489847884920475e-05,
      "loss": 0.0817,
      "step": 79570
    },
    {
      "epoch": 1.59140903091629,
      "grad_norm": 0.11231005936861038,
      "learning_rate": 2.348651495153915e-05,
      "loss": 0.0742,
      "step": 79580
    },
    {
      "epoch": 1.5916090069191697,
      "grad_norm": 0.21327541768550873,
      "learning_rate": 2.3483182018157825e-05,
      "loss": 0.0999,
      "step": 79590
    },
    {
      "epoch": 1.5918089829220494,
      "grad_norm": 0.08334442973136902,
      "learning_rate": 2.3479849084776494e-05,
      "loss": 0.0575,
      "step": 79600
    },
    {
      "epoch": 1.592008958924929,
      "grad_norm": 0.07733277976512909,
      "learning_rate": 2.3476516151395167e-05,
      "loss": 0.0615,
      "step": 79610
    },
    {
      "epoch": 1.5922089349278088,
      "grad_norm": 0.06111055985093117,
      "learning_rate": 2.347318321801384e-05,
      "loss": 0.0807,
      "step": 79620
    },
    {
      "epoch": 1.5924089109306885,
      "grad_norm": 0.11643858253955841,
      "learning_rate": 2.346985028463251e-05,
      "loss": 0.1023,
      "step": 79630
    },
    {
      "epoch": 1.592608886933568,
      "grad_norm": 0.1777876913547516,
      "learning_rate": 2.3466517351251186e-05,
      "loss": 0.0993,
      "step": 79640
    },
    {
      "epoch": 1.5928088629364476,
      "grad_norm": 0.22802351415157318,
      "learning_rate": 2.3463184417869856e-05,
      "loss": 0.0983,
      "step": 79650
    },
    {
      "epoch": 1.5930088389393273,
      "grad_norm": 0.11448901891708374,
      "learning_rate": 2.3460184777826665e-05,
      "loss": 0.0771,
      "step": 79660
    },
    {
      "epoch": 1.5932088149422068,
      "grad_norm": 0.0943981483578682,
      "learning_rate": 2.3456851844445334e-05,
      "loss": 0.0396,
      "step": 79670
    },
    {
      "epoch": 1.5934087909450865,
      "grad_norm": 0.07993273437023163,
      "learning_rate": 2.3453518911064007e-05,
      "loss": 0.074,
      "step": 79680
    },
    {
      "epoch": 1.5936087669479662,
      "grad_norm": 0.1147926077246666,
      "learning_rate": 2.345018597768268e-05,
      "loss": 0.0684,
      "step": 79690
    },
    {
      "epoch": 1.5938087429508458,
      "grad_norm": 0.0652238205075264,
      "learning_rate": 2.344685304430135e-05,
      "loss": 0.0564,
      "step": 79700
    },
    {
      "epoch": 1.5940087189537255,
      "grad_norm": 0.2192675918340683,
      "learning_rate": 2.3443520110920026e-05,
      "loss": 0.0651,
      "step": 79710
    },
    {
      "epoch": 1.5942086949566052,
      "grad_norm": 0.2454618662595749,
      "learning_rate": 2.3440187177538696e-05,
      "loss": 0.1969,
      "step": 79720
    },
    {
      "epoch": 1.594408670959485,
      "grad_norm": 0.062287621200084686,
      "learning_rate": 2.343685424415737e-05,
      "loss": 0.0903,
      "step": 79730
    },
    {
      "epoch": 1.5946086469623646,
      "grad_norm": 0.09207867085933685,
      "learning_rate": 2.3433521310776042e-05,
      "loss": 0.0811,
      "step": 79740
    },
    {
      "epoch": 1.5948086229652443,
      "grad_norm": 0.12460560351610184,
      "learning_rate": 2.343018837739471e-05,
      "loss": 0.0939,
      "step": 79750
    },
    {
      "epoch": 1.595008598968124,
      "grad_norm": 0.13322286307811737,
      "learning_rate": 2.3426855444013388e-05,
      "loss": 0.0793,
      "step": 79760
    },
    {
      "epoch": 1.5952085749710034,
      "grad_norm": 0.16331641376018524,
      "learning_rate": 2.342352251063206e-05,
      "loss": 0.0594,
      "step": 79770
    },
    {
      "epoch": 1.5954085509738831,
      "grad_norm": 0.12646512687206268,
      "learning_rate": 2.342018957725073e-05,
      "loss": 0.0576,
      "step": 79780
    },
    {
      "epoch": 1.5956085269767628,
      "grad_norm": 0.1038799062371254,
      "learning_rate": 2.3416856643869404e-05,
      "loss": 0.0541,
      "step": 79790
    },
    {
      "epoch": 1.5958085029796425,
      "grad_norm": 0.11211038380861282,
      "learning_rate": 2.3413523710488077e-05,
      "loss": 0.079,
      "step": 79800
    },
    {
      "epoch": 1.596008478982522,
      "grad_norm": 0.23508156836032867,
      "learning_rate": 2.341019077710675e-05,
      "loss": 0.0913,
      "step": 79810
    },
    {
      "epoch": 1.5962084549854016,
      "grad_norm": 0.0918845608830452,
      "learning_rate": 2.3406857843725423e-05,
      "loss": 0.0506,
      "step": 79820
    },
    {
      "epoch": 1.5964084309882813,
      "grad_norm": 0.07218477874994278,
      "learning_rate": 2.3403524910344092e-05,
      "loss": 0.0799,
      "step": 79830
    },
    {
      "epoch": 1.596608406991161,
      "grad_norm": 0.15759822726249695,
      "learning_rate": 2.3400191976962765e-05,
      "loss": 0.13,
      "step": 79840
    },
    {
      "epoch": 1.5968083829940407,
      "grad_norm": 0.16192947328090668,
      "learning_rate": 2.339685904358144e-05,
      "loss": 0.0952,
      "step": 79850
    },
    {
      "epoch": 1.5970083589969204,
      "grad_norm": 0.1578231304883957,
      "learning_rate": 2.3393526110200108e-05,
      "loss": 0.0654,
      "step": 79860
    },
    {
      "epoch": 1.5972083349998,
      "grad_norm": 0.12330163270235062,
      "learning_rate": 2.3390193176818784e-05,
      "loss": 0.0635,
      "step": 79870
    },
    {
      "epoch": 1.5974083110026798,
      "grad_norm": 0.269813597202301,
      "learning_rate": 2.3386860243437457e-05,
      "loss": 0.0851,
      "step": 79880
    },
    {
      "epoch": 1.5976082870055595,
      "grad_norm": 0.08370522409677505,
      "learning_rate": 2.3383527310056127e-05,
      "loss": 0.1116,
      "step": 79890
    },
    {
      "epoch": 1.5978082630084391,
      "grad_norm": 0.07939546555280685,
      "learning_rate": 2.33801943766748e-05,
      "loss": 0.0814,
      "step": 79900
    },
    {
      "epoch": 1.5980082390113186,
      "grad_norm": 0.09636041522026062,
      "learning_rate": 2.3376861443293473e-05,
      "loss": 0.0764,
      "step": 79910
    },
    {
      "epoch": 1.5982082150141983,
      "grad_norm": 0.14607004821300507,
      "learning_rate": 2.3373528509912146e-05,
      "loss": 0.0641,
      "step": 79920
    },
    {
      "epoch": 1.598408191017078,
      "grad_norm": 0.16955901682376862,
      "learning_rate": 2.337019557653082e-05,
      "loss": 0.104,
      "step": 79930
    },
    {
      "epoch": 1.5986081670199574,
      "grad_norm": 0.15365953743457794,
      "learning_rate": 2.336686264314949e-05,
      "loss": 0.0931,
      "step": 79940
    },
    {
      "epoch": 1.5988081430228371,
      "grad_norm": 0.09921880811452866,
      "learning_rate": 2.336352970976816e-05,
      "loss": 0.0736,
      "step": 79950
    },
    {
      "epoch": 1.5990081190257168,
      "grad_norm": 0.13678684830665588,
      "learning_rate": 2.3360196776386835e-05,
      "loss": 0.0443,
      "step": 79960
    },
    {
      "epoch": 1.5992080950285965,
      "grad_norm": 0.08345791697502136,
      "learning_rate": 2.3356863843005508e-05,
      "loss": 0.0465,
      "step": 79970
    },
    {
      "epoch": 1.5994080710314762,
      "grad_norm": 0.1421288549900055,
      "learning_rate": 2.335353090962418e-05,
      "loss": 0.0598,
      "step": 79980
    },
    {
      "epoch": 1.5996080470343559,
      "grad_norm": 0.11178911477327347,
      "learning_rate": 2.335019797624285e-05,
      "loss": 0.0818,
      "step": 79990
    },
    {
      "epoch": 1.5998080230372356,
      "grad_norm": 0.14793844521045685,
      "learning_rate": 2.3346865042861523e-05,
      "loss": 0.0939,
      "step": 80000
    },
    {
      "epoch": 1.6000079990401153,
      "grad_norm": 0.17366930842399597,
      "learning_rate": 2.3343532109480196e-05,
      "loss": 0.1055,
      "step": 80010
    },
    {
      "epoch": 1.600207975042995,
      "grad_norm": 0.2699619233608246,
      "learning_rate": 2.334019917609887e-05,
      "loss": 0.1096,
      "step": 80020
    },
    {
      "epoch": 1.6004079510458746,
      "grad_norm": 0.1551400125026703,
      "learning_rate": 2.3336866242717542e-05,
      "loss": 0.0886,
      "step": 80030
    },
    {
      "epoch": 1.600607927048754,
      "grad_norm": 0.12740583717823029,
      "learning_rate": 2.3333533309336215e-05,
      "loss": 0.0628,
      "step": 80040
    },
    {
      "epoch": 1.6008079030516338,
      "grad_norm": 0.06417929381132126,
      "learning_rate": 2.3330200375954885e-05,
      "loss": 0.0806,
      "step": 80050
    },
    {
      "epoch": 1.6010078790545135,
      "grad_norm": 0.08862841874361038,
      "learning_rate": 2.3326867442573558e-05,
      "loss": 0.0475,
      "step": 80060
    },
    {
      "epoch": 1.6012078550573932,
      "grad_norm": 0.12582512199878693,
      "learning_rate": 2.332353450919223e-05,
      "loss": 0.0536,
      "step": 80070
    },
    {
      "epoch": 1.6014078310602726,
      "grad_norm": 0.13703817129135132,
      "learning_rate": 2.3320201575810904e-05,
      "loss": 0.0877,
      "step": 80080
    },
    {
      "epoch": 1.6016078070631523,
      "grad_norm": 0.05559217184782028,
      "learning_rate": 2.3316868642429577e-05,
      "loss": 0.0447,
      "step": 80090
    },
    {
      "epoch": 1.601807783066032,
      "grad_norm": 0.11669490486383438,
      "learning_rate": 2.3313535709048246e-05,
      "loss": 0.0994,
      "step": 80100
    },
    {
      "epoch": 1.6020077590689117,
      "grad_norm": 0.12383626401424408,
      "learning_rate": 2.331020277566692e-05,
      "loss": 0.0702,
      "step": 80110
    },
    {
      "epoch": 1.6022077350717914,
      "grad_norm": 0.2310790717601776,
      "learning_rate": 2.3306869842285596e-05,
      "loss": 0.0802,
      "step": 80120
    },
    {
      "epoch": 1.602407711074671,
      "grad_norm": 0.07981220632791519,
      "learning_rate": 2.3303536908904265e-05,
      "loss": 0.0541,
      "step": 80130
    },
    {
      "epoch": 1.6026076870775507,
      "grad_norm": 0.14635959267616272,
      "learning_rate": 2.330020397552294e-05,
      "loss": 0.1062,
      "step": 80140
    },
    {
      "epoch": 1.6028076630804304,
      "grad_norm": 0.07794248312711716,
      "learning_rate": 2.329687104214161e-05,
      "loss": 0.1079,
      "step": 80150
    },
    {
      "epoch": 1.6030076390833101,
      "grad_norm": 0.1888212263584137,
      "learning_rate": 2.329353810876028e-05,
      "loss": 0.0945,
      "step": 80160
    },
    {
      "epoch": 1.6032076150861898,
      "grad_norm": 0.06502056121826172,
      "learning_rate": 2.3290205175378957e-05,
      "loss": 0.0931,
      "step": 80170
    },
    {
      "epoch": 1.6034075910890693,
      "grad_norm": 0.12540914118289948,
      "learning_rate": 2.3286872241997627e-05,
      "loss": 0.0895,
      "step": 80180
    },
    {
      "epoch": 1.603607567091949,
      "grad_norm": 0.22762298583984375,
      "learning_rate": 2.32835393086163e-05,
      "loss": 0.0785,
      "step": 80190
    },
    {
      "epoch": 1.6038075430948286,
      "grad_norm": 0.11278530955314636,
      "learning_rate": 2.3280206375234973e-05,
      "loss": 0.0846,
      "step": 80200
    },
    {
      "epoch": 1.6040075190977081,
      "grad_norm": 0.20910035073757172,
      "learning_rate": 2.3276873441853643e-05,
      "loss": 0.1107,
      "step": 80210
    },
    {
      "epoch": 1.6042074951005878,
      "grad_norm": 0.22231769561767578,
      "learning_rate": 2.327354050847232e-05,
      "loss": 0.0845,
      "step": 80220
    },
    {
      "epoch": 1.6044074711034675,
      "grad_norm": 0.11344441026449203,
      "learning_rate": 2.3270207575090992e-05,
      "loss": 0.0973,
      "step": 80230
    },
    {
      "epoch": 1.6046074471063472,
      "grad_norm": 0.16058729588985443,
      "learning_rate": 2.3266874641709662e-05,
      "loss": 0.0732,
      "step": 80240
    },
    {
      "epoch": 1.6048074231092269,
      "grad_norm": 0.1577804982662201,
      "learning_rate": 2.3263541708328335e-05,
      "loss": 0.0719,
      "step": 80250
    },
    {
      "epoch": 1.6050073991121065,
      "grad_norm": 0.12886811792850494,
      "learning_rate": 2.3260208774947008e-05,
      "loss": 0.1134,
      "step": 80260
    },
    {
      "epoch": 1.6052073751149862,
      "grad_norm": 0.24929095804691315,
      "learning_rate": 2.325687584156568e-05,
      "loss": 0.0704,
      "step": 80270
    },
    {
      "epoch": 1.605407351117866,
      "grad_norm": 0.1366657018661499,
      "learning_rate": 2.3253542908184354e-05,
      "loss": 0.0622,
      "step": 80280
    },
    {
      "epoch": 1.6056073271207456,
      "grad_norm": 0.16731764376163483,
      "learning_rate": 2.3250209974803023e-05,
      "loss": 0.1032,
      "step": 80290
    },
    {
      "epoch": 1.6058073031236253,
      "grad_norm": 0.16772159934043884,
      "learning_rate": 2.3246877041421696e-05,
      "loss": 0.1055,
      "step": 80300
    },
    {
      "epoch": 1.606007279126505,
      "grad_norm": 0.25019827485084534,
      "learning_rate": 2.324354410804037e-05,
      "loss": 0.0655,
      "step": 80310
    },
    {
      "epoch": 1.6062072551293844,
      "grad_norm": 0.13110269606113434,
      "learning_rate": 2.3240211174659042e-05,
      "loss": 0.0535,
      "step": 80320
    },
    {
      "epoch": 1.6064072311322641,
      "grad_norm": 0.06937015801668167,
      "learning_rate": 2.3236878241277715e-05,
      "loss": 0.0659,
      "step": 80330
    },
    {
      "epoch": 1.6066072071351438,
      "grad_norm": 0.1224951446056366,
      "learning_rate": 2.323354530789639e-05,
      "loss": 0.0808,
      "step": 80340
    },
    {
      "epoch": 1.6068071831380233,
      "grad_norm": 0.19279064238071442,
      "learning_rate": 2.3230212374515058e-05,
      "loss": 0.0629,
      "step": 80350
    },
    {
      "epoch": 1.607007159140903,
      "grad_norm": 0.1329694241285324,
      "learning_rate": 2.322687944113373e-05,
      "loss": 0.0962,
      "step": 80360
    },
    {
      "epoch": 1.6072071351437827,
      "grad_norm": 0.1299721598625183,
      "learning_rate": 2.3223546507752404e-05,
      "loss": 0.071,
      "step": 80370
    },
    {
      "epoch": 1.6074071111466623,
      "grad_norm": 0.17840264737606049,
      "learning_rate": 2.3220213574371077e-05,
      "loss": 0.0721,
      "step": 80380
    },
    {
      "epoch": 1.607607087149542,
      "grad_norm": 0.09077470004558563,
      "learning_rate": 2.321688064098975e-05,
      "loss": 0.2962,
      "step": 80390
    },
    {
      "epoch": 1.6078070631524217,
      "grad_norm": 0.09009731560945511,
      "learning_rate": 2.321354770760842e-05,
      "loss": 0.0841,
      "step": 80400
    },
    {
      "epoch": 1.6080070391553014,
      "grad_norm": 0.2088659256696701,
      "learning_rate": 2.3210214774227093e-05,
      "loss": 0.0698,
      "step": 80410
    },
    {
      "epoch": 1.608207015158181,
      "grad_norm": 0.21067795157432556,
      "learning_rate": 2.3206881840845766e-05,
      "loss": 0.092,
      "step": 80420
    },
    {
      "epoch": 1.6084069911610608,
      "grad_norm": 0.12395184487104416,
      "learning_rate": 2.320354890746444e-05,
      "loss": 0.0696,
      "step": 80430
    },
    {
      "epoch": 1.6086069671639405,
      "grad_norm": 0.06541941314935684,
      "learning_rate": 2.320021597408311e-05,
      "loss": 0.0548,
      "step": 80440
    },
    {
      "epoch": 1.60880694316682,
      "grad_norm": 0.20680344104766846,
      "learning_rate": 2.3196883040701785e-05,
      "loss": 0.1028,
      "step": 80450
    },
    {
      "epoch": 1.6090069191696996,
      "grad_norm": 0.11762221157550812,
      "learning_rate": 2.3193550107320454e-05,
      "loss": 0.0462,
      "step": 80460
    },
    {
      "epoch": 1.6092068951725793,
      "grad_norm": 0.07331839948892593,
      "learning_rate": 2.3190217173939127e-05,
      "loss": 0.0449,
      "step": 80470
    },
    {
      "epoch": 1.609406871175459,
      "grad_norm": 0.06501960009336472,
      "learning_rate": 2.31868842405578e-05,
      "loss": 0.0783,
      "step": 80480
    },
    {
      "epoch": 1.6096068471783385,
      "grad_norm": 0.26292264461517334,
      "learning_rate": 2.3183551307176473e-05,
      "loss": 0.1215,
      "step": 80490
    },
    {
      "epoch": 1.6098068231812181,
      "grad_norm": 0.1166863888502121,
      "learning_rate": 2.3180218373795146e-05,
      "loss": 0.0713,
      "step": 80500
    },
    {
      "epoch": 1.6100067991840978,
      "grad_norm": 0.17797420918941498,
      "learning_rate": 2.3176885440413816e-05,
      "loss": 0.0817,
      "step": 80510
    },
    {
      "epoch": 1.6102067751869775,
      "grad_norm": 0.18209829926490784,
      "learning_rate": 2.317355250703249e-05,
      "loss": 0.077,
      "step": 80520
    },
    {
      "epoch": 1.6104067511898572,
      "grad_norm": 0.08069413900375366,
      "learning_rate": 2.3170219573651165e-05,
      "loss": 0.0438,
      "step": 80530
    },
    {
      "epoch": 1.610606727192737,
      "grad_norm": 0.16323105990886688,
      "learning_rate": 2.3166886640269835e-05,
      "loss": 0.1167,
      "step": 80540
    },
    {
      "epoch": 1.6108067031956166,
      "grad_norm": 0.15065385401248932,
      "learning_rate": 2.3163553706888508e-05,
      "loss": 0.0465,
      "step": 80550
    },
    {
      "epoch": 1.6110066791984963,
      "grad_norm": 0.09981206804513931,
      "learning_rate": 2.316022077350718e-05,
      "loss": 0.0451,
      "step": 80560
    },
    {
      "epoch": 1.611206655201376,
      "grad_norm": 0.1342216581106186,
      "learning_rate": 2.315688784012585e-05,
      "loss": 0.0658,
      "step": 80570
    },
    {
      "epoch": 1.6114066312042556,
      "grad_norm": 0.19674794375896454,
      "learning_rate": 2.3153554906744527e-05,
      "loss": 0.0554,
      "step": 80580
    },
    {
      "epoch": 1.6116066072071351,
      "grad_norm": 0.17103435099124908,
      "learning_rate": 2.3150221973363197e-05,
      "loss": 0.0751,
      "step": 80590
    },
    {
      "epoch": 1.6118065832100148,
      "grad_norm": 0.12369165569543839,
      "learning_rate": 2.314688903998187e-05,
      "loss": 0.0453,
      "step": 80600
    },
    {
      "epoch": 1.6120065592128945,
      "grad_norm": 0.12072335928678513,
      "learning_rate": 2.3143556106600543e-05,
      "loss": 0.0625,
      "step": 80610
    },
    {
      "epoch": 1.612206535215774,
      "grad_norm": 0.16897684335708618,
      "learning_rate": 2.3140223173219212e-05,
      "loss": 0.0698,
      "step": 80620
    },
    {
      "epoch": 1.6124065112186536,
      "grad_norm": 0.08289643377065659,
      "learning_rate": 2.313689023983789e-05,
      "loss": 0.069,
      "step": 80630
    },
    {
      "epoch": 1.6126064872215333,
      "grad_norm": 0.11752831190824509,
      "learning_rate": 2.313355730645656e-05,
      "loss": 0.0736,
      "step": 80640
    },
    {
      "epoch": 1.612806463224413,
      "grad_norm": 0.22650085389614105,
      "learning_rate": 2.313022437307523e-05,
      "loss": 0.0982,
      "step": 80650
    },
    {
      "epoch": 1.6130064392272927,
      "grad_norm": 0.06422090530395508,
      "learning_rate": 2.3126891439693904e-05,
      "loss": 0.0832,
      "step": 80660
    },
    {
      "epoch": 1.6132064152301724,
      "grad_norm": 0.1881352961063385,
      "learning_rate": 2.3123558506312577e-05,
      "loss": 0.0994,
      "step": 80670
    },
    {
      "epoch": 1.613406391233052,
      "grad_norm": 0.08266142010688782,
      "learning_rate": 2.312022557293125e-05,
      "loss": 0.0821,
      "step": 80680
    },
    {
      "epoch": 1.6136063672359318,
      "grad_norm": 0.1387205868959427,
      "learning_rate": 2.3116892639549923e-05,
      "loss": 0.0948,
      "step": 80690
    },
    {
      "epoch": 1.6138063432388114,
      "grad_norm": 0.27030429244041443,
      "learning_rate": 2.3113559706168593e-05,
      "loss": 0.0653,
      "step": 80700
    },
    {
      "epoch": 1.6140063192416911,
      "grad_norm": 0.1208508089184761,
      "learning_rate": 2.3110226772787266e-05,
      "loss": 0.0559,
      "step": 80710
    },
    {
      "epoch": 1.6142062952445706,
      "grad_norm": 0.22329340875148773,
      "learning_rate": 2.310689383940594e-05,
      "loss": 0.0699,
      "step": 80720
    },
    {
      "epoch": 1.6144062712474503,
      "grad_norm": 0.22572246193885803,
      "learning_rate": 2.3103560906024612e-05,
      "loss": 0.094,
      "step": 80730
    },
    {
      "epoch": 1.61460624725033,
      "grad_norm": 0.19386860728263855,
      "learning_rate": 2.3100227972643285e-05,
      "loss": 0.0701,
      "step": 80740
    },
    {
      "epoch": 1.6148062232532097,
      "grad_norm": 0.07860346138477325,
      "learning_rate": 2.3096895039261958e-05,
      "loss": 0.0528,
      "step": 80750
    },
    {
      "epoch": 1.6150061992560891,
      "grad_norm": 0.10692475736141205,
      "learning_rate": 2.3093562105880627e-05,
      "loss": 0.0783,
      "step": 80760
    },
    {
      "epoch": 1.6152061752589688,
      "grad_norm": 0.14881329238414764,
      "learning_rate": 2.30902291724993e-05,
      "loss": 0.0529,
      "step": 80770
    },
    {
      "epoch": 1.6154061512618485,
      "grad_norm": 0.17768914997577667,
      "learning_rate": 2.3086896239117973e-05,
      "loss": 0.0717,
      "step": 80780
    },
    {
      "epoch": 1.6156061272647282,
      "grad_norm": 0.2201470583677292,
      "learning_rate": 2.3083563305736646e-05,
      "loss": 0.0949,
      "step": 80790
    },
    {
      "epoch": 1.6158061032676079,
      "grad_norm": 0.17006678879261017,
      "learning_rate": 2.308023037235532e-05,
      "loss": 0.1034,
      "step": 80800
    },
    {
      "epoch": 1.6160060792704876,
      "grad_norm": 0.11308816820383072,
      "learning_rate": 2.307689743897399e-05,
      "loss": 0.0741,
      "step": 80810
    },
    {
      "epoch": 1.6162060552733672,
      "grad_norm": 0.16290655732154846,
      "learning_rate": 2.3073564505592662e-05,
      "loss": 0.1094,
      "step": 80820
    },
    {
      "epoch": 1.616406031276247,
      "grad_norm": 0.07764620333909988,
      "learning_rate": 2.307023157221134e-05,
      "loss": 0.0743,
      "step": 80830
    },
    {
      "epoch": 1.6166060072791266,
      "grad_norm": 0.08785255253314972,
      "learning_rate": 2.3066898638830008e-05,
      "loss": 0.0555,
      "step": 80840
    },
    {
      "epoch": 1.6168059832820063,
      "grad_norm": 0.23132573068141937,
      "learning_rate": 2.306356570544868e-05,
      "loss": 0.0838,
      "step": 80850
    },
    {
      "epoch": 1.6170059592848858,
      "grad_norm": 0.21228079497814178,
      "learning_rate": 2.3060232772067354e-05,
      "loss": 0.0695,
      "step": 80860
    },
    {
      "epoch": 1.6172059352877655,
      "grad_norm": 0.2051452398300171,
      "learning_rate": 2.3056899838686024e-05,
      "loss": 0.0993,
      "step": 80870
    },
    {
      "epoch": 1.6174059112906451,
      "grad_norm": 0.17977029085159302,
      "learning_rate": 2.3053566905304697e-05,
      "loss": 0.0679,
      "step": 80880
    },
    {
      "epoch": 1.6176058872935246,
      "grad_norm": 0.15417702496051788,
      "learning_rate": 2.305023397192337e-05,
      "loss": 0.061,
      "step": 80890
    },
    {
      "epoch": 1.6178058632964043,
      "grad_norm": 0.07581428438425064,
      "learning_rate": 2.3046901038542043e-05,
      "loss": 0.0656,
      "step": 80900
    },
    {
      "epoch": 1.618005839299284,
      "grad_norm": 0.10257930308580399,
      "learning_rate": 2.3043568105160716e-05,
      "loss": 0.0517,
      "step": 80910
    },
    {
      "epoch": 1.6182058153021637,
      "grad_norm": 0.2364952564239502,
      "learning_rate": 2.3040235171779385e-05,
      "loss": 0.0948,
      "step": 80920
    },
    {
      "epoch": 1.6184057913050434,
      "grad_norm": 0.10481992363929749,
      "learning_rate": 2.303690223839806e-05,
      "loss": 0.0749,
      "step": 80930
    },
    {
      "epoch": 1.618605767307923,
      "grad_norm": 0.2161206305027008,
      "learning_rate": 2.3033569305016735e-05,
      "loss": 0.0895,
      "step": 80940
    },
    {
      "epoch": 1.6188057433108027,
      "grad_norm": 0.11198994517326355,
      "learning_rate": 2.3030236371635404e-05,
      "loss": 0.0919,
      "step": 80950
    },
    {
      "epoch": 1.6190057193136824,
      "grad_norm": 0.16126862168312073,
      "learning_rate": 2.3026903438254077e-05,
      "loss": 0.0768,
      "step": 80960
    },
    {
      "epoch": 1.619205695316562,
      "grad_norm": 0.21859656274318695,
      "learning_rate": 2.302357050487275e-05,
      "loss": 0.1127,
      "step": 80970
    },
    {
      "epoch": 1.6194056713194418,
      "grad_norm": 0.13738036155700684,
      "learning_rate": 2.302023757149142e-05,
      "loss": 0.0945,
      "step": 80980
    },
    {
      "epoch": 1.6196056473223215,
      "grad_norm": 0.08757304400205612,
      "learning_rate": 2.3016904638110096e-05,
      "loss": 0.0763,
      "step": 80990
    },
    {
      "epoch": 1.619805623325201,
      "grad_norm": 0.18338273465633392,
      "learning_rate": 2.3013571704728766e-05,
      "loss": 0.0536,
      "step": 81000
    },
    {
      "epoch": 1.6200055993280806,
      "grad_norm": 0.24388661980628967,
      "learning_rate": 2.301023877134744e-05,
      "loss": 0.1418,
      "step": 81010
    },
    {
      "epoch": 1.6202055753309603,
      "grad_norm": 0.11048358678817749,
      "learning_rate": 2.3006905837966112e-05,
      "loss": 0.054,
      "step": 81020
    },
    {
      "epoch": 1.6204055513338398,
      "grad_norm": 0.09328297525644302,
      "learning_rate": 2.300357290458478e-05,
      "loss": 0.0783,
      "step": 81030
    },
    {
      "epoch": 1.6206055273367195,
      "grad_norm": 0.19149181246757507,
      "learning_rate": 2.3000239971203458e-05,
      "loss": 0.059,
      "step": 81040
    },
    {
      "epoch": 1.6208055033395992,
      "grad_norm": 0.21399760246276855,
      "learning_rate": 2.299690703782213e-05,
      "loss": 0.0744,
      "step": 81050
    },
    {
      "epoch": 1.6210054793424788,
      "grad_norm": 0.16212144494056702,
      "learning_rate": 2.29935741044408e-05,
      "loss": 0.0744,
      "step": 81060
    },
    {
      "epoch": 1.6212054553453585,
      "grad_norm": 0.1861650049686432,
      "learning_rate": 2.2990241171059474e-05,
      "loss": 0.0558,
      "step": 81070
    },
    {
      "epoch": 1.6214054313482382,
      "grad_norm": 0.14605069160461426,
      "learning_rate": 2.2986908237678147e-05,
      "loss": 0.0618,
      "step": 81080
    },
    {
      "epoch": 1.621605407351118,
      "grad_norm": 0.07168754935264587,
      "learning_rate": 2.298357530429682e-05,
      "loss": 0.0454,
      "step": 81090
    },
    {
      "epoch": 1.6218053833539976,
      "grad_norm": 0.06774596869945526,
      "learning_rate": 2.2980242370915493e-05,
      "loss": 0.0872,
      "step": 81100
    },
    {
      "epoch": 1.6220053593568773,
      "grad_norm": 0.0886474996805191,
      "learning_rate": 2.2976909437534162e-05,
      "loss": 0.032,
      "step": 81110
    },
    {
      "epoch": 1.622205335359757,
      "grad_norm": 0.1037701666355133,
      "learning_rate": 2.2973576504152835e-05,
      "loss": 0.1023,
      "step": 81120
    },
    {
      "epoch": 1.6224053113626364,
      "grad_norm": 0.1879217028617859,
      "learning_rate": 2.2970243570771508e-05,
      "loss": 0.0952,
      "step": 81130
    },
    {
      "epoch": 1.6226052873655161,
      "grad_norm": 0.05393339321017265,
      "learning_rate": 2.296691063739018e-05,
      "loss": 0.0627,
      "step": 81140
    },
    {
      "epoch": 1.6228052633683958,
      "grad_norm": 0.1357603520154953,
      "learning_rate": 2.2963577704008854e-05,
      "loss": 0.0496,
      "step": 81150
    },
    {
      "epoch": 1.6230052393712755,
      "grad_norm": 0.1388167142868042,
      "learning_rate": 2.2960244770627527e-05,
      "loss": 0.1057,
      "step": 81160
    },
    {
      "epoch": 1.623205215374155,
      "grad_norm": 0.10011066496372223,
      "learning_rate": 2.2956911837246197e-05,
      "loss": 0.0582,
      "step": 81170
    },
    {
      "epoch": 1.6234051913770347,
      "grad_norm": 0.25948649644851685,
      "learning_rate": 2.295357890386487e-05,
      "loss": 0.1184,
      "step": 81180
    },
    {
      "epoch": 1.6236051673799143,
      "grad_norm": 0.09448963403701782,
      "learning_rate": 2.2950245970483543e-05,
      "loss": 0.0704,
      "step": 81190
    },
    {
      "epoch": 1.623805143382794,
      "grad_norm": 0.18583907186985016,
      "learning_rate": 2.2946913037102216e-05,
      "loss": 0.0958,
      "step": 81200
    },
    {
      "epoch": 1.6240051193856737,
      "grad_norm": 0.20467238128185272,
      "learning_rate": 2.294358010372089e-05,
      "loss": 0.0782,
      "step": 81210
    },
    {
      "epoch": 1.6242050953885534,
      "grad_norm": 0.1159651055932045,
      "learning_rate": 2.294024717033956e-05,
      "loss": 0.0904,
      "step": 81220
    },
    {
      "epoch": 1.624405071391433,
      "grad_norm": 0.15620453655719757,
      "learning_rate": 2.293691423695823e-05,
      "loss": 0.06,
      "step": 81230
    },
    {
      "epoch": 1.6246050473943128,
      "grad_norm": 0.07868203520774841,
      "learning_rate": 2.2933581303576908e-05,
      "loss": 0.0646,
      "step": 81240
    },
    {
      "epoch": 1.6248050233971925,
      "grad_norm": 0.10741604119539261,
      "learning_rate": 2.2930248370195578e-05,
      "loss": 0.0448,
      "step": 81250
    },
    {
      "epoch": 1.6250049994000721,
      "grad_norm": 0.1968241035938263,
      "learning_rate": 2.292691543681425e-05,
      "loss": 0.0723,
      "step": 81260
    },
    {
      "epoch": 1.6252049754029516,
      "grad_norm": 0.11925104260444641,
      "learning_rate": 2.2923582503432924e-05,
      "loss": 0.0766,
      "step": 81270
    },
    {
      "epoch": 1.6254049514058313,
      "grad_norm": 0.1748449206352234,
      "learning_rate": 2.2920249570051593e-05,
      "loss": 0.073,
      "step": 81280
    },
    {
      "epoch": 1.625604927408711,
      "grad_norm": 0.22051571309566498,
      "learning_rate": 2.291691663667027e-05,
      "loss": 0.0996,
      "step": 81290
    },
    {
      "epoch": 1.6258049034115905,
      "grad_norm": 0.15470509231090546,
      "learning_rate": 2.291358370328894e-05,
      "loss": 0.1006,
      "step": 81300
    },
    {
      "epoch": 1.6260048794144701,
      "grad_norm": 0.07547053694725037,
      "learning_rate": 2.2910250769907612e-05,
      "loss": 0.08,
      "step": 81310
    },
    {
      "epoch": 1.6262048554173498,
      "grad_norm": 0.09302107989788055,
      "learning_rate": 2.2906917836526285e-05,
      "loss": 0.0603,
      "step": 81320
    },
    {
      "epoch": 1.6264048314202295,
      "grad_norm": 0.1178775504231453,
      "learning_rate": 2.2903584903144955e-05,
      "loss": 0.0641,
      "step": 81330
    },
    {
      "epoch": 1.6266048074231092,
      "grad_norm": 0.09605120867490768,
      "learning_rate": 2.2900251969763628e-05,
      "loss": 0.0768,
      "step": 81340
    },
    {
      "epoch": 1.6268047834259889,
      "grad_norm": 0.1411009579896927,
      "learning_rate": 2.2896919036382304e-05,
      "loss": 0.0887,
      "step": 81350
    },
    {
      "epoch": 1.6270047594288686,
      "grad_norm": 0.15875911712646484,
      "learning_rate": 2.2893586103000974e-05,
      "loss": 0.0966,
      "step": 81360
    },
    {
      "epoch": 1.6272047354317483,
      "grad_norm": 0.11428160965442657,
      "learning_rate": 2.2890253169619647e-05,
      "loss": 0.1075,
      "step": 81370
    },
    {
      "epoch": 1.627404711434628,
      "grad_norm": 0.16737864911556244,
      "learning_rate": 2.288692023623832e-05,
      "loss": 0.0747,
      "step": 81380
    },
    {
      "epoch": 1.6276046874375076,
      "grad_norm": 0.08184218406677246,
      "learning_rate": 2.288358730285699e-05,
      "loss": 0.0662,
      "step": 81390
    },
    {
      "epoch": 1.627804663440387,
      "grad_norm": 0.1946812868118286,
      "learning_rate": 2.2880254369475666e-05,
      "loss": 0.0756,
      "step": 81400
    },
    {
      "epoch": 1.6280046394432668,
      "grad_norm": 0.08893697708845139,
      "learning_rate": 2.2876921436094335e-05,
      "loss": 0.0654,
      "step": 81410
    },
    {
      "epoch": 1.6282046154461465,
      "grad_norm": 0.14271770417690277,
      "learning_rate": 2.287358850271301e-05,
      "loss": 0.0942,
      "step": 81420
    },
    {
      "epoch": 1.6284045914490262,
      "grad_norm": 0.2482786327600479,
      "learning_rate": 2.287025556933168e-05,
      "loss": 0.1326,
      "step": 81430
    },
    {
      "epoch": 1.6286045674519056,
      "grad_norm": 0.20582270622253418,
      "learning_rate": 2.286692263595035e-05,
      "loss": 0.1048,
      "step": 81440
    },
    {
      "epoch": 1.6288045434547853,
      "grad_norm": 0.2096046656370163,
      "learning_rate": 2.2863589702569027e-05,
      "loss": 0.1037,
      "step": 81450
    },
    {
      "epoch": 1.629004519457665,
      "grad_norm": 0.08019476383924484,
      "learning_rate": 2.28602567691877e-05,
      "loss": 0.0624,
      "step": 81460
    },
    {
      "epoch": 1.6292044954605447,
      "grad_norm": 0.1959472894668579,
      "learning_rate": 2.285692383580637e-05,
      "loss": 0.0659,
      "step": 81470
    },
    {
      "epoch": 1.6294044714634244,
      "grad_norm": 0.09901390224695206,
      "learning_rate": 2.2853590902425043e-05,
      "loss": 0.0767,
      "step": 81480
    },
    {
      "epoch": 1.629604447466304,
      "grad_norm": 0.21007370948791504,
      "learning_rate": 2.2850257969043716e-05,
      "loss": 0.0734,
      "step": 81490
    },
    {
      "epoch": 1.6298044234691837,
      "grad_norm": 0.11085467040538788,
      "learning_rate": 2.284692503566239e-05,
      "loss": 0.0805,
      "step": 81500
    },
    {
      "epoch": 1.6300043994720634,
      "grad_norm": 0.07370279729366302,
      "learning_rate": 2.2843592102281062e-05,
      "loss": 0.0935,
      "step": 81510
    },
    {
      "epoch": 1.6302043754749431,
      "grad_norm": 0.21177217364311218,
      "learning_rate": 2.2840259168899732e-05,
      "loss": 0.1068,
      "step": 81520
    },
    {
      "epoch": 1.6304043514778228,
      "grad_norm": 0.08848247677087784,
      "learning_rate": 2.2836926235518405e-05,
      "loss": 0.0781,
      "step": 81530
    },
    {
      "epoch": 1.6306043274807023,
      "grad_norm": 0.1533966362476349,
      "learning_rate": 2.2833593302137078e-05,
      "loss": 0.0728,
      "step": 81540
    },
    {
      "epoch": 1.630804303483582,
      "grad_norm": 0.05250999704003334,
      "learning_rate": 2.283026036875575e-05,
      "loss": 0.0649,
      "step": 81550
    },
    {
      "epoch": 1.6310042794864616,
      "grad_norm": 0.10187843441963196,
      "learning_rate": 2.2826927435374424e-05,
      "loss": 0.0672,
      "step": 81560
    },
    {
      "epoch": 1.6312042554893411,
      "grad_norm": 0.12101081758737564,
      "learning_rate": 2.2823594501993097e-05,
      "loss": 0.0816,
      "step": 81570
    },
    {
      "epoch": 1.6314042314922208,
      "grad_norm": 0.10502815246582031,
      "learning_rate": 2.2820261568611766e-05,
      "loss": 0.0791,
      "step": 81580
    },
    {
      "epoch": 1.6316042074951005,
      "grad_norm": 0.13717994093894958,
      "learning_rate": 2.281692863523044e-05,
      "loss": 0.1164,
      "step": 81590
    },
    {
      "epoch": 1.6318041834979802,
      "grad_norm": 0.18565689027309418,
      "learning_rate": 2.2813595701849112e-05,
      "loss": 0.08,
      "step": 81600
    },
    {
      "epoch": 1.6320041595008599,
      "grad_norm": 0.14741161465644836,
      "learning_rate": 2.2810262768467785e-05,
      "loss": 0.0818,
      "step": 81610
    },
    {
      "epoch": 1.6322041355037396,
      "grad_norm": 0.14246459305286407,
      "learning_rate": 2.280692983508646e-05,
      "loss": 0.105,
      "step": 81620
    },
    {
      "epoch": 1.6324041115066192,
      "grad_norm": 0.11029191315174103,
      "learning_rate": 2.2803596901705128e-05,
      "loss": 0.0749,
      "step": 81630
    },
    {
      "epoch": 1.632604087509499,
      "grad_norm": 0.13083325326442719,
      "learning_rate": 2.28002639683238e-05,
      "loss": 0.095,
      "step": 81640
    },
    {
      "epoch": 1.6328040635123786,
      "grad_norm": 0.11832717061042786,
      "learning_rate": 2.2796931034942477e-05,
      "loss": 0.1017,
      "step": 81650
    },
    {
      "epoch": 1.6330040395152583,
      "grad_norm": 0.15814636647701263,
      "learning_rate": 2.2793598101561147e-05,
      "loss": 0.1022,
      "step": 81660
    },
    {
      "epoch": 1.633204015518138,
      "grad_norm": 0.2450287640094757,
      "learning_rate": 2.279026516817982e-05,
      "loss": 0.089,
      "step": 81670
    },
    {
      "epoch": 1.6334039915210175,
      "grad_norm": 0.23024089634418488,
      "learning_rate": 2.2786932234798493e-05,
      "loss": 0.0985,
      "step": 81680
    },
    {
      "epoch": 1.6336039675238971,
      "grad_norm": 0.18490654230117798,
      "learning_rate": 2.2783599301417163e-05,
      "loss": 0.0957,
      "step": 81690
    },
    {
      "epoch": 1.6338039435267768,
      "grad_norm": 0.20087434351444244,
      "learning_rate": 2.278026636803584e-05,
      "loss": 0.1283,
      "step": 81700
    },
    {
      "epoch": 1.6340039195296563,
      "grad_norm": 0.14970402419567108,
      "learning_rate": 2.277693343465451e-05,
      "loss": 0.1243,
      "step": 81710
    },
    {
      "epoch": 1.634203895532536,
      "grad_norm": 0.13688646256923676,
      "learning_rate": 2.277360050127318e-05,
      "loss": 0.0521,
      "step": 81720
    },
    {
      "epoch": 1.6344038715354157,
      "grad_norm": 0.19777196645736694,
      "learning_rate": 2.2770267567891855e-05,
      "loss": 0.1036,
      "step": 81730
    },
    {
      "epoch": 1.6346038475382954,
      "grad_norm": 0.14703482389450073,
      "learning_rate": 2.2766934634510524e-05,
      "loss": 0.0622,
      "step": 81740
    },
    {
      "epoch": 1.634803823541175,
      "grad_norm": 0.19545656442642212,
      "learning_rate": 2.27636017011292e-05,
      "loss": 0.0838,
      "step": 81750
    },
    {
      "epoch": 1.6350037995440547,
      "grad_norm": 0.12576012313365936,
      "learning_rate": 2.2760268767747874e-05,
      "loss": 0.0807,
      "step": 81760
    },
    {
      "epoch": 1.6352037755469344,
      "grad_norm": 0.0948973298072815,
      "learning_rate": 2.2756935834366543e-05,
      "loss": 0.0896,
      "step": 81770
    },
    {
      "epoch": 1.635403751549814,
      "grad_norm": 0.09961515665054321,
      "learning_rate": 2.2753602900985216e-05,
      "loss": 0.0667,
      "step": 81780
    },
    {
      "epoch": 1.6356037275526938,
      "grad_norm": 0.13122722506523132,
      "learning_rate": 2.275026996760389e-05,
      "loss": 0.074,
      "step": 81790
    },
    {
      "epoch": 1.6358037035555735,
      "grad_norm": 0.16047774255275726,
      "learning_rate": 2.2746937034222562e-05,
      "loss": 0.0875,
      "step": 81800
    },
    {
      "epoch": 1.636003679558453,
      "grad_norm": 0.1386682689189911,
      "learning_rate": 2.2743604100841235e-05,
      "loss": 0.085,
      "step": 81810
    },
    {
      "epoch": 1.6362036555613326,
      "grad_norm": 0.23702308535575867,
      "learning_rate": 2.2740271167459905e-05,
      "loss": 0.0617,
      "step": 81820
    },
    {
      "epoch": 1.6364036315642123,
      "grad_norm": 0.07613961398601532,
      "learning_rate": 2.2736938234078578e-05,
      "loss": 0.0753,
      "step": 81830
    },
    {
      "epoch": 1.636603607567092,
      "grad_norm": 0.0747113823890686,
      "learning_rate": 2.273360530069725e-05,
      "loss": 0.0386,
      "step": 81840
    },
    {
      "epoch": 1.6368035835699715,
      "grad_norm": 0.21053843200206757,
      "learning_rate": 2.273027236731592e-05,
      "loss": 0.113,
      "step": 81850
    },
    {
      "epoch": 1.6370035595728512,
      "grad_norm": 0.12198225408792496,
      "learning_rate": 2.2726939433934597e-05,
      "loss": 0.0531,
      "step": 81860
    },
    {
      "epoch": 1.6372035355757308,
      "grad_norm": 0.13526104390621185,
      "learning_rate": 2.272360650055327e-05,
      "loss": 0.0469,
      "step": 81870
    },
    {
      "epoch": 1.6374035115786105,
      "grad_norm": 0.13819079101085663,
      "learning_rate": 2.272027356717194e-05,
      "loss": 0.059,
      "step": 81880
    },
    {
      "epoch": 1.6376034875814902,
      "grad_norm": 0.12167690694332123,
      "learning_rate": 2.2716940633790613e-05,
      "loss": 0.0701,
      "step": 81890
    },
    {
      "epoch": 1.63780346358437,
      "grad_norm": 0.21405240893363953,
      "learning_rate": 2.2713607700409286e-05,
      "loss": 0.1064,
      "step": 81900
    },
    {
      "epoch": 1.6380034395872496,
      "grad_norm": 0.08161243796348572,
      "learning_rate": 2.271027476702796e-05,
      "loss": 0.0909,
      "step": 81910
    },
    {
      "epoch": 1.6382034155901293,
      "grad_norm": 0.10052123665809631,
      "learning_rate": 2.270694183364663e-05,
      "loss": 0.0386,
      "step": 81920
    },
    {
      "epoch": 1.638403391593009,
      "grad_norm": 0.07971873879432678,
      "learning_rate": 2.27036089002653e-05,
      "loss": 0.0508,
      "step": 81930
    },
    {
      "epoch": 1.6386033675958886,
      "grad_norm": 0.13933591544628143,
      "learning_rate": 2.2700275966883974e-05,
      "loss": 0.0423,
      "step": 81940
    },
    {
      "epoch": 1.6388033435987681,
      "grad_norm": 0.1643190085887909,
      "learning_rate": 2.2696943033502647e-05,
      "loss": 0.104,
      "step": 81950
    },
    {
      "epoch": 1.6390033196016478,
      "grad_norm": 0.08544637262821198,
      "learning_rate": 2.269361010012132e-05,
      "loss": 0.0932,
      "step": 81960
    },
    {
      "epoch": 1.6392032956045275,
      "grad_norm": 0.21024377644062042,
      "learning_rate": 2.2690277166739993e-05,
      "loss": 0.0738,
      "step": 81970
    },
    {
      "epoch": 1.639403271607407,
      "grad_norm": 0.12825630605220795,
      "learning_rate": 2.2686944233358666e-05,
      "loss": 0.0558,
      "step": 81980
    },
    {
      "epoch": 1.6396032476102866,
      "grad_norm": 0.10128892958164215,
      "learning_rate": 2.2683611299977336e-05,
      "loss": 0.0741,
      "step": 81990
    },
    {
      "epoch": 1.6398032236131663,
      "grad_norm": 0.12643006443977356,
      "learning_rate": 2.268027836659601e-05,
      "loss": 0.0981,
      "step": 82000
    },
    {
      "epoch": 1.640003199616046,
      "grad_norm": 0.20124369859695435,
      "learning_rate": 2.2676945433214682e-05,
      "loss": 0.0709,
      "step": 82010
    },
    {
      "epoch": 1.6402031756189257,
      "grad_norm": 0.12694115936756134,
      "learning_rate": 2.2673612499833355e-05,
      "loss": 0.089,
      "step": 82020
    },
    {
      "epoch": 1.6404031516218054,
      "grad_norm": 0.10614896565675735,
      "learning_rate": 2.2670279566452028e-05,
      "loss": 0.0808,
      "step": 82030
    },
    {
      "epoch": 1.640603127624685,
      "grad_norm": 0.12844626605510712,
      "learning_rate": 2.2666946633070697e-05,
      "loss": 0.0802,
      "step": 82040
    },
    {
      "epoch": 1.6408031036275648,
      "grad_norm": 0.11870181560516357,
      "learning_rate": 2.266361369968937e-05,
      "loss": 0.0428,
      "step": 82050
    },
    {
      "epoch": 1.6410030796304445,
      "grad_norm": 0.1445678323507309,
      "learning_rate": 2.2660280766308047e-05,
      "loss": 0.0727,
      "step": 82060
    },
    {
      "epoch": 1.6412030556333241,
      "grad_norm": 0.15545064210891724,
      "learning_rate": 2.2656947832926716e-05,
      "loss": 0.0677,
      "step": 82070
    },
    {
      "epoch": 1.6414030316362036,
      "grad_norm": 0.1756577342748642,
      "learning_rate": 2.265361489954539e-05,
      "loss": 0.0857,
      "step": 82080
    },
    {
      "epoch": 1.6416030076390833,
      "grad_norm": 0.14171455800533295,
      "learning_rate": 2.2650281966164062e-05,
      "loss": 0.0815,
      "step": 82090
    },
    {
      "epoch": 1.641802983641963,
      "grad_norm": 0.0973011702299118,
      "learning_rate": 2.2646949032782732e-05,
      "loss": 0.0686,
      "step": 82100
    },
    {
      "epoch": 1.6420029596448427,
      "grad_norm": 0.14353737235069275,
      "learning_rate": 2.264361609940141e-05,
      "loss": 0.1042,
      "step": 82110
    },
    {
      "epoch": 1.6422029356477221,
      "grad_norm": 0.16437669098377228,
      "learning_rate": 2.2640283166020078e-05,
      "loss": 0.0957,
      "step": 82120
    },
    {
      "epoch": 1.6424029116506018,
      "grad_norm": 0.11575215309858322,
      "learning_rate": 2.263695023263875e-05,
      "loss": 0.0664,
      "step": 82130
    },
    {
      "epoch": 1.6426028876534815,
      "grad_norm": 0.09792210906744003,
      "learning_rate": 2.2633617299257424e-05,
      "loss": 0.0838,
      "step": 82140
    },
    {
      "epoch": 1.6428028636563612,
      "grad_norm": 0.09636608511209488,
      "learning_rate": 2.2630284365876094e-05,
      "loss": 0.066,
      "step": 82150
    },
    {
      "epoch": 1.6430028396592409,
      "grad_norm": 0.25869911909103394,
      "learning_rate": 2.262695143249477e-05,
      "loss": 0.0652,
      "step": 82160
    },
    {
      "epoch": 1.6432028156621206,
      "grad_norm": 0.11216690391302109,
      "learning_rate": 2.2623618499113443e-05,
      "loss": 0.0458,
      "step": 82170
    },
    {
      "epoch": 1.6434027916650003,
      "grad_norm": 0.12499304860830307,
      "learning_rate": 2.2620285565732113e-05,
      "loss": 0.0846,
      "step": 82180
    },
    {
      "epoch": 1.64360276766788,
      "grad_norm": 0.13346165418624878,
      "learning_rate": 2.2616952632350786e-05,
      "loss": 0.1032,
      "step": 82190
    },
    {
      "epoch": 1.6438027436707596,
      "grad_norm": 0.1251850575208664,
      "learning_rate": 2.261361969896946e-05,
      "loss": 0.0807,
      "step": 82200
    },
    {
      "epoch": 1.6440027196736393,
      "grad_norm": 0.07119426876306534,
      "learning_rate": 2.2610286765588132e-05,
      "loss": 0.1499,
      "step": 82210
    },
    {
      "epoch": 1.6442026956765188,
      "grad_norm": 0.0865207314491272,
      "learning_rate": 2.2606953832206805e-05,
      "loss": 0.0909,
      "step": 82220
    },
    {
      "epoch": 1.6444026716793985,
      "grad_norm": 0.16346371173858643,
      "learning_rate": 2.2603620898825474e-05,
      "loss": 0.0804,
      "step": 82230
    },
    {
      "epoch": 1.6446026476822782,
      "grad_norm": 0.07293904572725296,
      "learning_rate": 2.2600287965444147e-05,
      "loss": 0.0931,
      "step": 82240
    },
    {
      "epoch": 1.6448026236851576,
      "grad_norm": 0.044807858765125275,
      "learning_rate": 2.259695503206282e-05,
      "loss": 0.0822,
      "step": 82250
    },
    {
      "epoch": 1.6450025996880373,
      "grad_norm": 0.07301735132932663,
      "learning_rate": 2.2593622098681493e-05,
      "loss": 0.0858,
      "step": 82260
    },
    {
      "epoch": 1.645202575690917,
      "grad_norm": 0.15700556337833405,
      "learning_rate": 2.2590289165300166e-05,
      "loss": 0.0501,
      "step": 82270
    },
    {
      "epoch": 1.6454025516937967,
      "grad_norm": 0.13617125153541565,
      "learning_rate": 2.258695623191884e-05,
      "loss": 0.0743,
      "step": 82280
    },
    {
      "epoch": 1.6456025276966764,
      "grad_norm": 0.10421790182590485,
      "learning_rate": 2.258362329853751e-05,
      "loss": 0.0712,
      "step": 82290
    },
    {
      "epoch": 1.645802503699556,
      "grad_norm": 0.19265636801719666,
      "learning_rate": 2.2580290365156182e-05,
      "loss": 0.136,
      "step": 82300
    },
    {
      "epoch": 1.6460024797024357,
      "grad_norm": 0.062081143260002136,
      "learning_rate": 2.2576957431774855e-05,
      "loss": 0.1295,
      "step": 82310
    },
    {
      "epoch": 1.6462024557053154,
      "grad_norm": 0.10239856690168381,
      "learning_rate": 2.2573624498393528e-05,
      "loss": 0.0717,
      "step": 82320
    },
    {
      "epoch": 1.6464024317081951,
      "grad_norm": 0.1441374123096466,
      "learning_rate": 2.25702915650122e-05,
      "loss": 0.0728,
      "step": 82330
    },
    {
      "epoch": 1.6466024077110748,
      "grad_norm": 0.08977628499269485,
      "learning_rate": 2.256695863163087e-05,
      "loss": 0.2916,
      "step": 82340
    },
    {
      "epoch": 1.6468023837139545,
      "grad_norm": 0.16545984148979187,
      "learning_rate": 2.2563625698249544e-05,
      "loss": 0.0511,
      "step": 82350
    },
    {
      "epoch": 1.647002359716834,
      "grad_norm": 0.10998210310935974,
      "learning_rate": 2.2560292764868217e-05,
      "loss": 0.0664,
      "step": 82360
    },
    {
      "epoch": 1.6472023357197136,
      "grad_norm": 0.23064446449279785,
      "learning_rate": 2.255695983148689e-05,
      "loss": 0.1048,
      "step": 82370
    },
    {
      "epoch": 1.6474023117225933,
      "grad_norm": 0.09172093123197556,
      "learning_rate": 2.2553626898105563e-05,
      "loss": 0.1157,
      "step": 82380
    },
    {
      "epoch": 1.6476022877254728,
      "grad_norm": 0.15238714218139648,
      "learning_rate": 2.2550293964724232e-05,
      "loss": 0.1517,
      "step": 82390
    },
    {
      "epoch": 1.6478022637283525,
      "grad_norm": 0.14729976654052734,
      "learning_rate": 2.2546961031342905e-05,
      "loss": 0.0841,
      "step": 82400
    },
    {
      "epoch": 1.6480022397312322,
      "grad_norm": 0.08852290362119675,
      "learning_rate": 2.2543628097961578e-05,
      "loss": 0.2023,
      "step": 82410
    },
    {
      "epoch": 1.6482022157341119,
      "grad_norm": 0.19823551177978516,
      "learning_rate": 2.254029516458025e-05,
      "loss": 0.102,
      "step": 82420
    },
    {
      "epoch": 1.6484021917369915,
      "grad_norm": 0.10671152174472809,
      "learning_rate": 2.2536962231198924e-05,
      "loss": 0.0619,
      "step": 82430
    },
    {
      "epoch": 1.6486021677398712,
      "grad_norm": 0.15892834961414337,
      "learning_rate": 2.2533629297817597e-05,
      "loss": 0.1115,
      "step": 82440
    },
    {
      "epoch": 1.648802143742751,
      "grad_norm": 0.15990817546844482,
      "learning_rate": 2.2530296364436267e-05,
      "loss": 0.0757,
      "step": 82450
    },
    {
      "epoch": 1.6490021197456306,
      "grad_norm": 0.07201109081506729,
      "learning_rate": 2.252696343105494e-05,
      "loss": 0.0871,
      "step": 82460
    },
    {
      "epoch": 1.6492020957485103,
      "grad_norm": 0.13869398832321167,
      "learning_rate": 2.2523630497673613e-05,
      "loss": 0.0565,
      "step": 82470
    },
    {
      "epoch": 1.64940207175139,
      "grad_norm": 0.07242994010448456,
      "learning_rate": 2.2520297564292286e-05,
      "loss": 0.0647,
      "step": 82480
    },
    {
      "epoch": 1.6496020477542694,
      "grad_norm": 0.1749558299779892,
      "learning_rate": 2.251696463091096e-05,
      "loss": 0.1075,
      "step": 82490
    },
    {
      "epoch": 1.6498020237571491,
      "grad_norm": 0.14197130501270294,
      "learning_rate": 2.251363169752963e-05,
      "loss": 0.0784,
      "step": 82500
    },
    {
      "epoch": 1.6500019997600288,
      "grad_norm": 0.07134966552257538,
      "learning_rate": 2.25102987641483e-05,
      "loss": 0.0721,
      "step": 82510
    },
    {
      "epoch": 1.6502019757629085,
      "grad_norm": 0.1140342727303505,
      "learning_rate": 2.2506965830766978e-05,
      "loss": 0.0751,
      "step": 82520
    },
    {
      "epoch": 1.650401951765788,
      "grad_norm": 0.1524713784456253,
      "learning_rate": 2.2503632897385648e-05,
      "loss": 0.0605,
      "step": 82530
    },
    {
      "epoch": 1.6506019277686677,
      "grad_norm": 0.09101446717977524,
      "learning_rate": 2.250029996400432e-05,
      "loss": 0.0907,
      "step": 82540
    },
    {
      "epoch": 1.6508019037715473,
      "grad_norm": 0.12281282991170883,
      "learning_rate": 2.2496967030622994e-05,
      "loss": 0.0566,
      "step": 82550
    },
    {
      "epoch": 1.651001879774427,
      "grad_norm": 0.23106233775615692,
      "learning_rate": 2.2493634097241663e-05,
      "loss": 0.0969,
      "step": 82560
    },
    {
      "epoch": 1.6512018557773067,
      "grad_norm": 0.11611228436231613,
      "learning_rate": 2.249030116386034e-05,
      "loss": 0.0607,
      "step": 82570
    },
    {
      "epoch": 1.6514018317801864,
      "grad_norm": 0.21557176113128662,
      "learning_rate": 2.248696823047901e-05,
      "loss": 0.1035,
      "step": 82580
    },
    {
      "epoch": 1.651601807783066,
      "grad_norm": 0.19770747423171997,
      "learning_rate": 2.2483635297097682e-05,
      "loss": 0.082,
      "step": 82590
    },
    {
      "epoch": 1.6518017837859458,
      "grad_norm": 0.1555021107196808,
      "learning_rate": 2.2480302363716355e-05,
      "loss": 0.1188,
      "step": 82600
    },
    {
      "epoch": 1.6520017597888255,
      "grad_norm": 0.15718035399913788,
      "learning_rate": 2.2476969430335025e-05,
      "loss": 0.0808,
      "step": 82610
    },
    {
      "epoch": 1.6522017357917052,
      "grad_norm": 0.10084407776594162,
      "learning_rate": 2.24736364969537e-05,
      "loss": 0.0966,
      "step": 82620
    },
    {
      "epoch": 1.6524017117945846,
      "grad_norm": 0.09177543222904205,
      "learning_rate": 2.2470303563572374e-05,
      "loss": 0.0865,
      "step": 82630
    },
    {
      "epoch": 1.6526016877974643,
      "grad_norm": 0.07049097120761871,
      "learning_rate": 2.2466970630191044e-05,
      "loss": 0.0574,
      "step": 82640
    },
    {
      "epoch": 1.652801663800344,
      "grad_norm": 0.09261925518512726,
      "learning_rate": 2.2463637696809717e-05,
      "loss": 0.0471,
      "step": 82650
    },
    {
      "epoch": 1.6530016398032235,
      "grad_norm": 0.18233104050159454,
      "learning_rate": 2.246030476342839e-05,
      "loss": 0.064,
      "step": 82660
    },
    {
      "epoch": 1.6532016158061031,
      "grad_norm": 0.1803494095802307,
      "learning_rate": 2.2456971830047063e-05,
      "loss": 0.0679,
      "step": 82670
    },
    {
      "epoch": 1.6534015918089828,
      "grad_norm": 0.08732245117425919,
      "learning_rate": 2.2453638896665736e-05,
      "loss": 0.0711,
      "step": 82680
    },
    {
      "epoch": 1.6536015678118625,
      "grad_norm": 0.1603717803955078,
      "learning_rate": 2.2450305963284405e-05,
      "loss": 0.0748,
      "step": 82690
    },
    {
      "epoch": 1.6538015438147422,
      "grad_norm": 0.19823609292507172,
      "learning_rate": 2.244697302990308e-05,
      "loss": 0.0873,
      "step": 82700
    },
    {
      "epoch": 1.654001519817622,
      "grad_norm": 0.07521308958530426,
      "learning_rate": 2.244364009652175e-05,
      "loss": 0.0606,
      "step": 82710
    },
    {
      "epoch": 1.6542014958205016,
      "grad_norm": 0.12135442346334457,
      "learning_rate": 2.2440307163140424e-05,
      "loss": 0.0873,
      "step": 82720
    },
    {
      "epoch": 1.6544014718233813,
      "grad_norm": 0.06974855810403824,
      "learning_rate": 2.2436974229759097e-05,
      "loss": 0.1536,
      "step": 82730
    },
    {
      "epoch": 1.654601447826261,
      "grad_norm": 0.06327962875366211,
      "learning_rate": 2.243364129637777e-05,
      "loss": 0.0451,
      "step": 82740
    },
    {
      "epoch": 1.6548014238291406,
      "grad_norm": 0.0614689439535141,
      "learning_rate": 2.243030836299644e-05,
      "loss": 0.0667,
      "step": 82750
    },
    {
      "epoch": 1.65500139983202,
      "grad_norm": 0.1469925045967102,
      "learning_rate": 2.2426975429615113e-05,
      "loss": 0.0796,
      "step": 82760
    },
    {
      "epoch": 1.6552013758348998,
      "grad_norm": 0.11715405434370041,
      "learning_rate": 2.2423642496233786e-05,
      "loss": 0.056,
      "step": 82770
    },
    {
      "epoch": 1.6554013518377795,
      "grad_norm": 0.05975119397044182,
      "learning_rate": 2.242030956285246e-05,
      "loss": 0.0734,
      "step": 82780
    },
    {
      "epoch": 1.6556013278406592,
      "grad_norm": 0.10361897200345993,
      "learning_rate": 2.2416976629471132e-05,
      "loss": 0.1089,
      "step": 82790
    },
    {
      "epoch": 1.6558013038435386,
      "grad_norm": 0.1992914378643036,
      "learning_rate": 2.2413643696089802e-05,
      "loss": 0.1089,
      "step": 82800
    },
    {
      "epoch": 1.6560012798464183,
      "grad_norm": 0.10036690533161163,
      "learning_rate": 2.2410310762708475e-05,
      "loss": 0.0571,
      "step": 82810
    },
    {
      "epoch": 1.656201255849298,
      "grad_norm": 0.1432117521762848,
      "learning_rate": 2.240697782932715e-05,
      "loss": 0.0866,
      "step": 82820
    },
    {
      "epoch": 1.6564012318521777,
      "grad_norm": 0.1316453516483307,
      "learning_rate": 2.240364489594582e-05,
      "loss": 0.0984,
      "step": 82830
    },
    {
      "epoch": 1.6566012078550574,
      "grad_norm": 0.09244821965694427,
      "learning_rate": 2.2400311962564494e-05,
      "loss": 0.1204,
      "step": 82840
    },
    {
      "epoch": 1.656801183857937,
      "grad_norm": 0.17414958775043488,
      "learning_rate": 2.2396979029183167e-05,
      "loss": 0.0731,
      "step": 82850
    },
    {
      "epoch": 1.6570011598608168,
      "grad_norm": 0.16901159286499023,
      "learning_rate": 2.2393646095801836e-05,
      "loss": 0.082,
      "step": 82860
    },
    {
      "epoch": 1.6572011358636964,
      "grad_norm": 0.12775181233882904,
      "learning_rate": 2.239031316242051e-05,
      "loss": 0.0802,
      "step": 82870
    },
    {
      "epoch": 1.6574011118665761,
      "grad_norm": 0.07406199723482132,
      "learning_rate": 2.2386980229039182e-05,
      "loss": 0.0813,
      "step": 82880
    },
    {
      "epoch": 1.6576010878694558,
      "grad_norm": 0.06672413647174835,
      "learning_rate": 2.2383647295657855e-05,
      "loss": 0.0724,
      "step": 82890
    },
    {
      "epoch": 1.6578010638723353,
      "grad_norm": 0.21646316349506378,
      "learning_rate": 2.238031436227653e-05,
      "loss": 0.1054,
      "step": 82900
    },
    {
      "epoch": 1.658001039875215,
      "grad_norm": 0.09091980755329132,
      "learning_rate": 2.2376981428895198e-05,
      "loss": 0.0715,
      "step": 82910
    },
    {
      "epoch": 1.6582010158780947,
      "grad_norm": 0.11325887590646744,
      "learning_rate": 2.237364849551387e-05,
      "loss": 0.0563,
      "step": 82920
    },
    {
      "epoch": 1.6584009918809741,
      "grad_norm": 0.16567401587963104,
      "learning_rate": 2.2370315562132547e-05,
      "loss": 0.0385,
      "step": 82930
    },
    {
      "epoch": 1.6586009678838538,
      "grad_norm": 0.2552073001861572,
      "learning_rate": 2.2366982628751217e-05,
      "loss": 0.0964,
      "step": 82940
    },
    {
      "epoch": 1.6588009438867335,
      "grad_norm": 0.08190049976110458,
      "learning_rate": 2.236364969536989e-05,
      "loss": 0.0487,
      "step": 82950
    },
    {
      "epoch": 1.6590009198896132,
      "grad_norm": 0.13505619764328003,
      "learning_rate": 2.2360316761988563e-05,
      "loss": 0.0777,
      "step": 82960
    },
    {
      "epoch": 1.6592008958924929,
      "grad_norm": 0.08834370970726013,
      "learning_rate": 2.2356983828607233e-05,
      "loss": 0.0402,
      "step": 82970
    },
    {
      "epoch": 1.6594008718953726,
      "grad_norm": 0.10460153222084045,
      "learning_rate": 2.235365089522591e-05,
      "loss": 0.0466,
      "step": 82980
    },
    {
      "epoch": 1.6596008478982522,
      "grad_norm": 0.1201731264591217,
      "learning_rate": 2.235031796184458e-05,
      "loss": 0.0569,
      "step": 82990
    },
    {
      "epoch": 1.659800823901132,
      "grad_norm": 0.0747099295258522,
      "learning_rate": 2.234698502846325e-05,
      "loss": 0.0794,
      "step": 83000
    },
    {
      "epoch": 1.6600007999040116,
      "grad_norm": 0.15684401988983154,
      "learning_rate": 2.2343652095081925e-05,
      "loss": 0.0487,
      "step": 83010
    },
    {
      "epoch": 1.6602007759068913,
      "grad_norm": 0.17981913685798645,
      "learning_rate": 2.2340319161700594e-05,
      "loss": 0.0938,
      "step": 83020
    },
    {
      "epoch": 1.660400751909771,
      "grad_norm": 0.10972236841917038,
      "learning_rate": 2.233698622831927e-05,
      "loss": 0.1006,
      "step": 83030
    },
    {
      "epoch": 1.6606007279126505,
      "grad_norm": 0.12056005746126175,
      "learning_rate": 2.2333653294937944e-05,
      "loss": 0.0675,
      "step": 83040
    },
    {
      "epoch": 1.6608007039155301,
      "grad_norm": 0.26143330335617065,
      "learning_rate": 2.2330320361556613e-05,
      "loss": 0.0583,
      "step": 83050
    },
    {
      "epoch": 1.6610006799184098,
      "grad_norm": 0.11409933865070343,
      "learning_rate": 2.2326987428175286e-05,
      "loss": 0.0834,
      "step": 83060
    },
    {
      "epoch": 1.6612006559212893,
      "grad_norm": 0.11588296294212341,
      "learning_rate": 2.232365449479396e-05,
      "loss": 0.0749,
      "step": 83070
    },
    {
      "epoch": 1.661400631924169,
      "grad_norm": 0.17209696769714355,
      "learning_rate": 2.2320321561412632e-05,
      "loss": 0.1034,
      "step": 83080
    },
    {
      "epoch": 1.6616006079270487,
      "grad_norm": 0.17602577805519104,
      "learning_rate": 2.2316988628031305e-05,
      "loss": 0.0652,
      "step": 83090
    },
    {
      "epoch": 1.6618005839299284,
      "grad_norm": 0.17536522448062897,
      "learning_rate": 2.231398898798811e-05,
      "loss": 0.2471,
      "step": 83100
    },
    {
      "epoch": 1.662000559932808,
      "grad_norm": 0.09919001907110214,
      "learning_rate": 2.2310656054606784e-05,
      "loss": 0.063,
      "step": 83110
    },
    {
      "epoch": 1.6622005359356877,
      "grad_norm": 0.20723655819892883,
      "learning_rate": 2.2307323121225453e-05,
      "loss": 0.0753,
      "step": 83120
    },
    {
      "epoch": 1.6624005119385674,
      "grad_norm": 0.2385416179895401,
      "learning_rate": 2.2303990187844126e-05,
      "loss": 0.0798,
      "step": 83130
    },
    {
      "epoch": 1.662600487941447,
      "grad_norm": 0.1335870772600174,
      "learning_rate": 2.23006572544628e-05,
      "loss": 0.0382,
      "step": 83140
    },
    {
      "epoch": 1.6628004639443268,
      "grad_norm": 0.11405495554208755,
      "learning_rate": 2.2297324321081472e-05,
      "loss": 0.0525,
      "step": 83150
    },
    {
      "epoch": 1.6630004399472065,
      "grad_norm": 0.14145022630691528,
      "learning_rate": 2.2293991387700145e-05,
      "loss": 0.081,
      "step": 83160
    },
    {
      "epoch": 1.663200415950086,
      "grad_norm": 0.11054540425539017,
      "learning_rate": 2.2290658454318815e-05,
      "loss": 0.0474,
      "step": 83170
    },
    {
      "epoch": 1.6634003919529656,
      "grad_norm": 0.12337496131658554,
      "learning_rate": 2.2287325520937488e-05,
      "loss": 0.0766,
      "step": 83180
    },
    {
      "epoch": 1.6636003679558453,
      "grad_norm": 0.07185735553503036,
      "learning_rate": 2.228399258755616e-05,
      "loss": 0.0739,
      "step": 83190
    },
    {
      "epoch": 1.663800343958725,
      "grad_norm": 0.16798695921897888,
      "learning_rate": 2.2280659654174834e-05,
      "loss": 0.0706,
      "step": 83200
    },
    {
      "epoch": 1.6640003199616045,
      "grad_norm": 0.13782119750976562,
      "learning_rate": 2.2277326720793507e-05,
      "loss": 0.0933,
      "step": 83210
    },
    {
      "epoch": 1.6642002959644842,
      "grad_norm": 0.12964588403701782,
      "learning_rate": 2.227399378741218e-05,
      "loss": 0.0954,
      "step": 83220
    },
    {
      "epoch": 1.6644002719673638,
      "grad_norm": 0.07945126295089722,
      "learning_rate": 2.227066085403085e-05,
      "loss": 0.0744,
      "step": 83230
    },
    {
      "epoch": 1.6646002479702435,
      "grad_norm": 0.1177087351679802,
      "learning_rate": 2.2267327920649523e-05,
      "loss": 0.0508,
      "step": 83240
    },
    {
      "epoch": 1.6648002239731232,
      "grad_norm": 0.07762376964092255,
      "learning_rate": 2.2263994987268196e-05,
      "loss": 0.0874,
      "step": 83250
    },
    {
      "epoch": 1.665000199976003,
      "grad_norm": 0.12713512778282166,
      "learning_rate": 2.226066205388687e-05,
      "loss": 0.084,
      "step": 83260
    },
    {
      "epoch": 1.6652001759788826,
      "grad_norm": 0.17466703057289124,
      "learning_rate": 2.225732912050554e-05,
      "loss": 0.0717,
      "step": 83270
    },
    {
      "epoch": 1.6654001519817623,
      "grad_norm": 0.2133597731590271,
      "learning_rate": 2.225399618712421e-05,
      "loss": 0.0947,
      "step": 83280
    },
    {
      "epoch": 1.665600127984642,
      "grad_norm": 0.07812922447919846,
      "learning_rate": 2.2250663253742884e-05,
      "loss": 0.0642,
      "step": 83290
    },
    {
      "epoch": 1.6658001039875217,
      "grad_norm": 0.12718245387077332,
      "learning_rate": 2.224733032036156e-05,
      "loss": 0.0663,
      "step": 83300
    },
    {
      "epoch": 1.6660000799904011,
      "grad_norm": 0.09633078426122665,
      "learning_rate": 2.224399738698023e-05,
      "loss": 0.0471,
      "step": 83310
    },
    {
      "epoch": 1.6662000559932808,
      "grad_norm": 0.09314678609371185,
      "learning_rate": 2.2240664453598903e-05,
      "loss": 0.0582,
      "step": 83320
    },
    {
      "epoch": 1.6664000319961605,
      "grad_norm": 0.1535046398639679,
      "learning_rate": 2.2237331520217576e-05,
      "loss": 0.1099,
      "step": 83330
    },
    {
      "epoch": 1.66660000799904,
      "grad_norm": 0.05889769271016121,
      "learning_rate": 2.2233998586836246e-05,
      "loss": 0.0671,
      "step": 83340
    },
    {
      "epoch": 1.6667999840019196,
      "grad_norm": 0.12767499685287476,
      "learning_rate": 2.223066565345492e-05,
      "loss": 0.0588,
      "step": 83350
    },
    {
      "epoch": 1.6669999600047993,
      "grad_norm": 0.057434018701314926,
      "learning_rate": 2.2227332720073592e-05,
      "loss": 0.0626,
      "step": 83360
    },
    {
      "epoch": 1.667199936007679,
      "grad_norm": 0.15473288297653198,
      "learning_rate": 2.2223999786692265e-05,
      "loss": 0.0711,
      "step": 83370
    },
    {
      "epoch": 1.6673999120105587,
      "grad_norm": 0.2121828943490982,
      "learning_rate": 2.2220666853310938e-05,
      "loss": 0.0685,
      "step": 83380
    },
    {
      "epoch": 1.6675998880134384,
      "grad_norm": 0.13496467471122742,
      "learning_rate": 2.2217333919929607e-05,
      "loss": 0.1079,
      "step": 83390
    },
    {
      "epoch": 1.667799864016318,
      "grad_norm": 0.16132022440433502,
      "learning_rate": 2.221400098654828e-05,
      "loss": 0.0734,
      "step": 83400
    },
    {
      "epoch": 1.6679998400191978,
      "grad_norm": 0.16316308081150055,
      "learning_rate": 2.2210668053166957e-05,
      "loss": 0.1063,
      "step": 83410
    },
    {
      "epoch": 1.6681998160220775,
      "grad_norm": 0.07338801771402359,
      "learning_rate": 2.2207335119785626e-05,
      "loss": 0.0966,
      "step": 83420
    },
    {
      "epoch": 1.6683997920249571,
      "grad_norm": 0.12268095463514328,
      "learning_rate": 2.22040021864043e-05,
      "loss": 0.0871,
      "step": 83430
    },
    {
      "epoch": 1.6685997680278366,
      "grad_norm": 0.12347861379384995,
      "learning_rate": 2.2200669253022972e-05,
      "loss": 0.0768,
      "step": 83440
    },
    {
      "epoch": 1.6687997440307163,
      "grad_norm": 0.25253981351852417,
      "learning_rate": 2.2197336319641642e-05,
      "loss": 0.0919,
      "step": 83450
    },
    {
      "epoch": 1.668999720033596,
      "grad_norm": 0.06569314002990723,
      "learning_rate": 2.219400338626032e-05,
      "loss": 0.0675,
      "step": 83460
    },
    {
      "epoch": 1.6691996960364757,
      "grad_norm": 0.167290598154068,
      "learning_rate": 2.2190670452878988e-05,
      "loss": 0.0649,
      "step": 83470
    },
    {
      "epoch": 1.6693996720393551,
      "grad_norm": 0.10602539777755737,
      "learning_rate": 2.218733751949766e-05,
      "loss": 0.0825,
      "step": 83480
    },
    {
      "epoch": 1.6695996480422348,
      "grad_norm": 0.18871226906776428,
      "learning_rate": 2.2184004586116334e-05,
      "loss": 0.0964,
      "step": 83490
    },
    {
      "epoch": 1.6697996240451145,
      "grad_norm": 0.15837819874286652,
      "learning_rate": 2.2180671652735004e-05,
      "loss": 0.1048,
      "step": 83500
    },
    {
      "epoch": 1.6699996000479942,
      "grad_norm": 0.26071399450302124,
      "learning_rate": 2.217733871935368e-05,
      "loss": 0.0626,
      "step": 83510
    },
    {
      "epoch": 1.6701995760508739,
      "grad_norm": 0.13044752180576324,
      "learning_rate": 2.2174005785972353e-05,
      "loss": 0.0763,
      "step": 83520
    },
    {
      "epoch": 1.6703995520537536,
      "grad_norm": 0.09337875247001648,
      "learning_rate": 2.2170672852591023e-05,
      "loss": 0.0585,
      "step": 83530
    },
    {
      "epoch": 1.6705995280566333,
      "grad_norm": 0.10817041248083115,
      "learning_rate": 2.2167339919209696e-05,
      "loss": 0.0618,
      "step": 83540
    },
    {
      "epoch": 1.670799504059513,
      "grad_norm": 0.18638114631175995,
      "learning_rate": 2.216400698582837e-05,
      "loss": 0.0413,
      "step": 83550
    },
    {
      "epoch": 1.6709994800623926,
      "grad_norm": 0.162051722407341,
      "learning_rate": 2.2160674052447042e-05,
      "loss": 0.0671,
      "step": 83560
    },
    {
      "epoch": 1.6711994560652723,
      "grad_norm": 0.13425998389720917,
      "learning_rate": 2.2157341119065715e-05,
      "loss": 0.0783,
      "step": 83570
    },
    {
      "epoch": 1.6713994320681518,
      "grad_norm": 0.16086114943027496,
      "learning_rate": 2.2154008185684384e-05,
      "loss": 0.0828,
      "step": 83580
    },
    {
      "epoch": 1.6715994080710315,
      "grad_norm": 0.1562952846288681,
      "learning_rate": 2.2150675252303057e-05,
      "loss": 0.0701,
      "step": 83590
    },
    {
      "epoch": 1.6717993840739112,
      "grad_norm": 0.21482841670513153,
      "learning_rate": 2.214734231892173e-05,
      "loss": 0.0543,
      "step": 83600
    },
    {
      "epoch": 1.6719993600767906,
      "grad_norm": 0.07708535343408585,
      "learning_rate": 2.2144009385540403e-05,
      "loss": 0.0904,
      "step": 83610
    },
    {
      "epoch": 1.6721993360796703,
      "grad_norm": 0.10095957666635513,
      "learning_rate": 2.2140676452159076e-05,
      "loss": 0.0633,
      "step": 83620
    },
    {
      "epoch": 1.67239931208255,
      "grad_norm": 0.14203324913978577,
      "learning_rate": 2.213734351877775e-05,
      "loss": 0.072,
      "step": 83630
    },
    {
      "epoch": 1.6725992880854297,
      "grad_norm": 0.05482092127203941,
      "learning_rate": 2.213401058539642e-05,
      "loss": 0.0404,
      "step": 83640
    },
    {
      "epoch": 1.6727992640883094,
      "grad_norm": 0.04978690296411514,
      "learning_rate": 2.2130677652015092e-05,
      "loss": 0.0745,
      "step": 83650
    },
    {
      "epoch": 1.672999240091189,
      "grad_norm": 0.06547210365533829,
      "learning_rate": 2.2127344718633765e-05,
      "loss": 0.0539,
      "step": 83660
    },
    {
      "epoch": 1.6731992160940687,
      "grad_norm": 0.21557869017124176,
      "learning_rate": 2.2124011785252438e-05,
      "loss": 0.0832,
      "step": 83670
    },
    {
      "epoch": 1.6733991920969484,
      "grad_norm": 0.2268417924642563,
      "learning_rate": 2.212067885187111e-05,
      "loss": 0.1039,
      "step": 83680
    },
    {
      "epoch": 1.6735991680998281,
      "grad_norm": 0.1460360437631607,
      "learning_rate": 2.211734591848978e-05,
      "loss": 0.0838,
      "step": 83690
    },
    {
      "epoch": 1.6737991441027078,
      "grad_norm": 0.17811183631420135,
      "learning_rate": 2.2114012985108454e-05,
      "loss": 0.0672,
      "step": 83700
    },
    {
      "epoch": 1.6739991201055875,
      "grad_norm": 0.15594196319580078,
      "learning_rate": 2.211068005172713e-05,
      "loss": 0.1163,
      "step": 83710
    },
    {
      "epoch": 1.674199096108467,
      "grad_norm": 0.1408429741859436,
      "learning_rate": 2.21073471183458e-05,
      "loss": 0.0871,
      "step": 83720
    },
    {
      "epoch": 1.6743990721113466,
      "grad_norm": 0.11386377364397049,
      "learning_rate": 2.2104014184964473e-05,
      "loss": 0.0827,
      "step": 83730
    },
    {
      "epoch": 1.6745990481142263,
      "grad_norm": 0.13953928649425507,
      "learning_rate": 2.2100681251583146e-05,
      "loss": 0.0976,
      "step": 83740
    },
    {
      "epoch": 1.6747990241171058,
      "grad_norm": 0.11057665199041367,
      "learning_rate": 2.2097348318201815e-05,
      "loss": 0.1488,
      "step": 83750
    },
    {
      "epoch": 1.6749990001199855,
      "grad_norm": 0.21059782803058624,
      "learning_rate": 2.209401538482049e-05,
      "loss": 0.0644,
      "step": 83760
    },
    {
      "epoch": 1.6751989761228652,
      "grad_norm": 0.13580812513828278,
      "learning_rate": 2.209068245143916e-05,
      "loss": 0.1113,
      "step": 83770
    },
    {
      "epoch": 1.6753989521257449,
      "grad_norm": 0.21147441864013672,
      "learning_rate": 2.2087349518057834e-05,
      "loss": 0.0521,
      "step": 83780
    },
    {
      "epoch": 1.6755989281286245,
      "grad_norm": 0.1593279242515564,
      "learning_rate": 2.2084016584676507e-05,
      "loss": 0.06,
      "step": 83790
    },
    {
      "epoch": 1.6757989041315042,
      "grad_norm": 0.056164324283599854,
      "learning_rate": 2.2080683651295177e-05,
      "loss": 0.0604,
      "step": 83800
    },
    {
      "epoch": 1.675998880134384,
      "grad_norm": 0.07750653475522995,
      "learning_rate": 2.207735071791385e-05,
      "loss": 0.0997,
      "step": 83810
    },
    {
      "epoch": 1.6761988561372636,
      "grad_norm": 0.18387465178966522,
      "learning_rate": 2.2074017784532526e-05,
      "loss": 0.0564,
      "step": 83820
    },
    {
      "epoch": 1.6763988321401433,
      "grad_norm": 0.07286052405834198,
      "learning_rate": 2.2070684851151196e-05,
      "loss": 0.045,
      "step": 83830
    },
    {
      "epoch": 1.676598808143023,
      "grad_norm": 0.12399165332317352,
      "learning_rate": 2.206735191776987e-05,
      "loss": 0.0675,
      "step": 83840
    },
    {
      "epoch": 1.6767987841459024,
      "grad_norm": 0.17533279955387115,
      "learning_rate": 2.2064018984388542e-05,
      "loss": 0.0697,
      "step": 83850
    },
    {
      "epoch": 1.6769987601487821,
      "grad_norm": 0.0939430221915245,
      "learning_rate": 2.206068605100721e-05,
      "loss": 0.0677,
      "step": 83860
    },
    {
      "epoch": 1.6771987361516618,
      "grad_norm": 0.24201421439647675,
      "learning_rate": 2.2057353117625888e-05,
      "loss": 0.0749,
      "step": 83870
    },
    {
      "epoch": 1.6773987121545415,
      "grad_norm": 0.10414434969425201,
      "learning_rate": 2.2054020184244558e-05,
      "loss": 0.2141,
      "step": 83880
    },
    {
      "epoch": 1.677598688157421,
      "grad_norm": 0.11512942612171173,
      "learning_rate": 2.205068725086323e-05,
      "loss": 0.0992,
      "step": 83890
    },
    {
      "epoch": 1.6777986641603007,
      "grad_norm": 0.20552799105644226,
      "learning_rate": 2.2047354317481904e-05,
      "loss": 0.0712,
      "step": 83900
    },
    {
      "epoch": 1.6779986401631803,
      "grad_norm": 0.1924593597650528,
      "learning_rate": 2.2044021384100573e-05,
      "loss": 0.096,
      "step": 83910
    },
    {
      "epoch": 1.67819861616606,
      "grad_norm": 0.15102940797805786,
      "learning_rate": 2.204068845071925e-05,
      "loss": 0.0582,
      "step": 83920
    },
    {
      "epoch": 1.6783985921689397,
      "grad_norm": 0.091175377368927,
      "learning_rate": 2.2037355517337923e-05,
      "loss": 0.0888,
      "step": 83930
    },
    {
      "epoch": 1.6785985681718194,
      "grad_norm": 0.19337503612041473,
      "learning_rate": 2.2034022583956592e-05,
      "loss": 0.0865,
      "step": 83940
    },
    {
      "epoch": 1.678798544174699,
      "grad_norm": 0.18079723417758942,
      "learning_rate": 2.2030689650575265e-05,
      "loss": 0.0805,
      "step": 83950
    },
    {
      "epoch": 1.6789985201775788,
      "grad_norm": 0.06660421937704086,
      "learning_rate": 2.2027356717193938e-05,
      "loss": 0.0708,
      "step": 83960
    },
    {
      "epoch": 1.6791984961804585,
      "grad_norm": 0.18688763678073883,
      "learning_rate": 2.202402378381261e-05,
      "loss": 0.1045,
      "step": 83970
    },
    {
      "epoch": 1.6793984721833382,
      "grad_norm": 0.2110297530889511,
      "learning_rate": 2.2020690850431284e-05,
      "loss": 0.077,
      "step": 83980
    },
    {
      "epoch": 1.6795984481862176,
      "grad_norm": 0.09950017184019089,
      "learning_rate": 2.2017357917049954e-05,
      "loss": 0.0615,
      "step": 83990
    },
    {
      "epoch": 1.6797984241890973,
      "grad_norm": 0.18523819744586945,
      "learning_rate": 2.2014024983668627e-05,
      "loss": 0.0891,
      "step": 84000
    },
    {
      "epoch": 1.679998400191977,
      "grad_norm": 0.0696791559457779,
      "learning_rate": 2.20106920502873e-05,
      "loss": 0.1087,
      "step": 84010
    },
    {
      "epoch": 1.6801983761948565,
      "grad_norm": 0.08275467902421951,
      "learning_rate": 2.2007359116905973e-05,
      "loss": 0.0815,
      "step": 84020
    },
    {
      "epoch": 1.6803983521977361,
      "grad_norm": 0.21504420042037964,
      "learning_rate": 2.2004026183524646e-05,
      "loss": 0.0997,
      "step": 84030
    },
    {
      "epoch": 1.6805983282006158,
      "grad_norm": 0.13354843854904175,
      "learning_rate": 2.200069325014332e-05,
      "loss": 0.0799,
      "step": 84040
    },
    {
      "epoch": 1.6807983042034955,
      "grad_norm": 0.17520755529403687,
      "learning_rate": 2.199736031676199e-05,
      "loss": 0.089,
      "step": 84050
    },
    {
      "epoch": 1.6809982802063752,
      "grad_norm": 0.24612466990947723,
      "learning_rate": 2.199402738338066e-05,
      "loss": 0.0538,
      "step": 84060
    },
    {
      "epoch": 1.681198256209255,
      "grad_norm": 0.16811954975128174,
      "learning_rate": 2.1990694449999334e-05,
      "loss": 0.0786,
      "step": 84070
    },
    {
      "epoch": 1.6813982322121346,
      "grad_norm": 0.10020849853754044,
      "learning_rate": 2.1987361516618007e-05,
      "loss": 0.0461,
      "step": 84080
    },
    {
      "epoch": 1.6815982082150143,
      "grad_norm": 0.11881490796804428,
      "learning_rate": 2.198402858323668e-05,
      "loss": 0.097,
      "step": 84090
    },
    {
      "epoch": 1.681798184217894,
      "grad_norm": 0.12445197254419327,
      "learning_rate": 2.198069564985535e-05,
      "loss": 0.0675,
      "step": 84100
    },
    {
      "epoch": 1.6819981602207736,
      "grad_norm": 0.10204429924488068,
      "learning_rate": 2.1977362716474023e-05,
      "loss": 0.0949,
      "step": 84110
    },
    {
      "epoch": 1.682198136223653,
      "grad_norm": 0.14649923145771027,
      "learning_rate": 2.19740297830927e-05,
      "loss": 0.0835,
      "step": 84120
    },
    {
      "epoch": 1.6823981122265328,
      "grad_norm": 0.09906914830207825,
      "learning_rate": 2.197069684971137e-05,
      "loss": 0.0646,
      "step": 84130
    },
    {
      "epoch": 1.6825980882294125,
      "grad_norm": 0.28028419613838196,
      "learning_rate": 2.1967363916330042e-05,
      "loss": 0.13,
      "step": 84140
    },
    {
      "epoch": 1.6827980642322922,
      "grad_norm": 0.20435012876987457,
      "learning_rate": 2.1964030982948715e-05,
      "loss": 0.1108,
      "step": 84150
    },
    {
      "epoch": 1.6829980402351716,
      "grad_norm": 0.10048326104879379,
      "learning_rate": 2.1960698049567385e-05,
      "loss": 0.0706,
      "step": 84160
    },
    {
      "epoch": 1.6831980162380513,
      "grad_norm": 0.1251118779182434,
      "learning_rate": 2.195736511618606e-05,
      "loss": 0.2307,
      "step": 84170
    },
    {
      "epoch": 1.683397992240931,
      "grad_norm": 0.0905727967619896,
      "learning_rate": 2.195403218280473e-05,
      "loss": 0.4756,
      "step": 84180
    },
    {
      "epoch": 1.6835979682438107,
      "grad_norm": 0.12467040121555328,
      "learning_rate": 2.1950699249423404e-05,
      "loss": 0.0659,
      "step": 84190
    },
    {
      "epoch": 1.6837979442466904,
      "grad_norm": 0.1836809664964676,
      "learning_rate": 2.1947366316042077e-05,
      "loss": 0.0847,
      "step": 84200
    },
    {
      "epoch": 1.68399792024957,
      "grad_norm": 0.06508815288543701,
      "learning_rate": 2.1944033382660746e-05,
      "loss": 0.0592,
      "step": 84210
    },
    {
      "epoch": 1.6841978962524498,
      "grad_norm": 0.09409528225660324,
      "learning_rate": 2.1940700449279423e-05,
      "loss": 0.0991,
      "step": 84220
    },
    {
      "epoch": 1.6843978722553294,
      "grad_norm": 0.19394782185554504,
      "learning_rate": 2.1937367515898096e-05,
      "loss": 0.0787,
      "step": 84230
    },
    {
      "epoch": 1.6845978482582091,
      "grad_norm": 0.11909793317317963,
      "learning_rate": 2.1934034582516765e-05,
      "loss": 0.0773,
      "step": 84240
    },
    {
      "epoch": 1.6847978242610888,
      "grad_norm": 0.15351776778697968,
      "learning_rate": 2.193070164913544e-05,
      "loss": 0.0882,
      "step": 84250
    },
    {
      "epoch": 1.6849978002639683,
      "grad_norm": 0.22930264472961426,
      "learning_rate": 2.192736871575411e-05,
      "loss": 0.0776,
      "step": 84260
    },
    {
      "epoch": 1.685197776266848,
      "grad_norm": 0.14289340376853943,
      "learning_rate": 2.1924035782372784e-05,
      "loss": 0.047,
      "step": 84270
    },
    {
      "epoch": 1.6853977522697277,
      "grad_norm": 0.12705858051776886,
      "learning_rate": 2.1920702848991457e-05,
      "loss": 0.0791,
      "step": 84280
    },
    {
      "epoch": 1.6855977282726071,
      "grad_norm": 0.07435867935419083,
      "learning_rate": 2.1917369915610127e-05,
      "loss": 0.0594,
      "step": 84290
    },
    {
      "epoch": 1.6857977042754868,
      "grad_norm": 0.20873606204986572,
      "learning_rate": 2.19140369822288e-05,
      "loss": 0.0812,
      "step": 84300
    },
    {
      "epoch": 1.6859976802783665,
      "grad_norm": 0.16944877803325653,
      "learning_rate": 2.1910704048847473e-05,
      "loss": 0.0629,
      "step": 84310
    },
    {
      "epoch": 1.6861976562812462,
      "grad_norm": 0.12362214922904968,
      "learning_rate": 2.1907371115466143e-05,
      "loss": 0.0717,
      "step": 84320
    },
    {
      "epoch": 1.6863976322841259,
      "grad_norm": 0.11608054488897324,
      "learning_rate": 2.190403818208482e-05,
      "loss": 0.0916,
      "step": 84330
    },
    {
      "epoch": 1.6865976082870056,
      "grad_norm": 0.06124094873666763,
      "learning_rate": 2.190070524870349e-05,
      "loss": 0.067,
      "step": 84340
    },
    {
      "epoch": 1.6867975842898852,
      "grad_norm": 0.2171504646539688,
      "learning_rate": 2.189737231532216e-05,
      "loss": 0.0967,
      "step": 84350
    },
    {
      "epoch": 1.686997560292765,
      "grad_norm": 0.1507672369480133,
      "learning_rate": 2.1894039381940835e-05,
      "loss": 0.0767,
      "step": 84360
    },
    {
      "epoch": 1.6871975362956446,
      "grad_norm": 0.07445311546325684,
      "learning_rate": 2.1890706448559508e-05,
      "loss": 0.0521,
      "step": 84370
    },
    {
      "epoch": 1.6873975122985243,
      "grad_norm": 0.06922169029712677,
      "learning_rate": 2.188737351517818e-05,
      "loss": 0.0488,
      "step": 84380
    },
    {
      "epoch": 1.687597488301404,
      "grad_norm": 0.07922482490539551,
      "learning_rate": 2.1884040581796854e-05,
      "loss": 0.0516,
      "step": 84390
    },
    {
      "epoch": 1.6877974643042835,
      "grad_norm": 0.17204570770263672,
      "learning_rate": 2.1880707648415523e-05,
      "loss": 0.0828,
      "step": 84400
    },
    {
      "epoch": 1.6879974403071631,
      "grad_norm": 0.109133780002594,
      "learning_rate": 2.1877374715034196e-05,
      "loss": 0.0561,
      "step": 84410
    },
    {
      "epoch": 1.6881974163100428,
      "grad_norm": 0.1025540754199028,
      "learning_rate": 2.187404178165287e-05,
      "loss": 0.0643,
      "step": 84420
    },
    {
      "epoch": 1.6883973923129223,
      "grad_norm": 0.12201350182294846,
      "learning_rate": 2.1870708848271542e-05,
      "loss": 0.0683,
      "step": 84430
    },
    {
      "epoch": 1.688597368315802,
      "grad_norm": 0.14354504644870758,
      "learning_rate": 2.1867375914890215e-05,
      "loss": 0.0459,
      "step": 84440
    },
    {
      "epoch": 1.6887973443186817,
      "grad_norm": 0.11685116589069366,
      "learning_rate": 2.1864042981508885e-05,
      "loss": 0.0417,
      "step": 84450
    },
    {
      "epoch": 1.6889973203215614,
      "grad_norm": 0.2171821892261505,
      "learning_rate": 2.1860710048127558e-05,
      "loss": 0.0766,
      "step": 84460
    },
    {
      "epoch": 1.689197296324441,
      "grad_norm": 0.1618800163269043,
      "learning_rate": 2.185737711474623e-05,
      "loss": 0.0681,
      "step": 84470
    },
    {
      "epoch": 1.6893972723273207,
      "grad_norm": 0.21046657860279083,
      "learning_rate": 2.1854044181364904e-05,
      "loss": 0.0564,
      "step": 84480
    },
    {
      "epoch": 1.6895972483302004,
      "grad_norm": 0.13711124658584595,
      "learning_rate": 2.1850711247983577e-05,
      "loss": 0.1045,
      "step": 84490
    },
    {
      "epoch": 1.68979722433308,
      "grad_norm": 0.1362045258283615,
      "learning_rate": 2.184737831460225e-05,
      "loss": 0.0782,
      "step": 84500
    },
    {
      "epoch": 1.6899972003359598,
      "grad_norm": 0.13477018475532532,
      "learning_rate": 2.184404538122092e-05,
      "loss": 0.052,
      "step": 84510
    },
    {
      "epoch": 1.6901971763388395,
      "grad_norm": 0.1937086284160614,
      "learning_rate": 2.1840712447839593e-05,
      "loss": 0.1058,
      "step": 84520
    },
    {
      "epoch": 1.690397152341719,
      "grad_norm": 0.0534546822309494,
      "learning_rate": 2.1837379514458266e-05,
      "loss": 0.0486,
      "step": 84530
    },
    {
      "epoch": 1.6905971283445986,
      "grad_norm": 0.14758799970149994,
      "learning_rate": 2.183404658107694e-05,
      "loss": 0.0547,
      "step": 84540
    },
    {
      "epoch": 1.6907971043474783,
      "grad_norm": 0.09117391705513,
      "learning_rate": 2.183071364769561e-05,
      "loss": 0.0462,
      "step": 84550
    },
    {
      "epoch": 1.690997080350358,
      "grad_norm": 0.08473985642194748,
      "learning_rate": 2.182738071431428e-05,
      "loss": 0.067,
      "step": 84560
    },
    {
      "epoch": 1.6911970563532375,
      "grad_norm": 0.18873144686222076,
      "learning_rate": 2.1824047780932954e-05,
      "loss": 0.0994,
      "step": 84570
    },
    {
      "epoch": 1.6913970323561172,
      "grad_norm": 0.0763823539018631,
      "learning_rate": 2.182071484755163e-05,
      "loss": 0.0687,
      "step": 84580
    },
    {
      "epoch": 1.6915970083589968,
      "grad_norm": 0.12875834107398987,
      "learning_rate": 2.18173819141703e-05,
      "loss": 0.0563,
      "step": 84590
    },
    {
      "epoch": 1.6917969843618765,
      "grad_norm": 0.22391963005065918,
      "learning_rate": 2.1814048980788973e-05,
      "loss": 0.0927,
      "step": 84600
    },
    {
      "epoch": 1.6919969603647562,
      "grad_norm": 0.19324445724487305,
      "learning_rate": 2.1810716047407646e-05,
      "loss": 0.1041,
      "step": 84610
    },
    {
      "epoch": 1.692196936367636,
      "grad_norm": 0.1560290902853012,
      "learning_rate": 2.1807383114026316e-05,
      "loss": 0.086,
      "step": 84620
    },
    {
      "epoch": 1.6923969123705156,
      "grad_norm": 0.1850106567144394,
      "learning_rate": 2.1804050180644992e-05,
      "loss": 0.0563,
      "step": 84630
    },
    {
      "epoch": 1.6925968883733953,
      "grad_norm": 0.2057899534702301,
      "learning_rate": 2.1800717247263662e-05,
      "loss": 0.0588,
      "step": 84640
    },
    {
      "epoch": 1.692796864376275,
      "grad_norm": 0.12186121940612793,
      "learning_rate": 2.1797384313882335e-05,
      "loss": 0.0599,
      "step": 84650
    },
    {
      "epoch": 1.6929968403791547,
      "grad_norm": 0.13650226593017578,
      "learning_rate": 2.1794051380501008e-05,
      "loss": 0.0616,
      "step": 84660
    },
    {
      "epoch": 1.6931968163820341,
      "grad_norm": 0.0812578797340393,
      "learning_rate": 2.1790718447119677e-05,
      "loss": 0.0682,
      "step": 84670
    },
    {
      "epoch": 1.6933967923849138,
      "grad_norm": 0.19175922870635986,
      "learning_rate": 2.1787385513738354e-05,
      "loss": 0.0819,
      "step": 84680
    },
    {
      "epoch": 1.6935967683877935,
      "grad_norm": 0.2238229364156723,
      "learning_rate": 2.1784052580357027e-05,
      "loss": 0.0747,
      "step": 84690
    },
    {
      "epoch": 1.693796744390673,
      "grad_norm": 0.13895772397518158,
      "learning_rate": 2.1780719646975696e-05,
      "loss": 0.079,
      "step": 84700
    },
    {
      "epoch": 1.6939967203935526,
      "grad_norm": 0.19837911427021027,
      "learning_rate": 2.177738671359437e-05,
      "loss": 0.0816,
      "step": 84710
    },
    {
      "epoch": 1.6941966963964323,
      "grad_norm": 0.10906770080327988,
      "learning_rate": 2.1774053780213042e-05,
      "loss": 0.0612,
      "step": 84720
    },
    {
      "epoch": 1.694396672399312,
      "grad_norm": 0.1988859325647354,
      "learning_rate": 2.1770720846831715e-05,
      "loss": 0.0654,
      "step": 84730
    },
    {
      "epoch": 1.6945966484021917,
      "grad_norm": 0.18367302417755127,
      "learning_rate": 2.176738791345039e-05,
      "loss": 0.0779,
      "step": 84740
    },
    {
      "epoch": 1.6947966244050714,
      "grad_norm": 0.05421394854784012,
      "learning_rate": 2.1764054980069058e-05,
      "loss": 0.0782,
      "step": 84750
    },
    {
      "epoch": 1.694996600407951,
      "grad_norm": 0.06262842565774918,
      "learning_rate": 2.176072204668773e-05,
      "loss": 0.1189,
      "step": 84760
    },
    {
      "epoch": 1.6951965764108308,
      "grad_norm": 0.21453715860843658,
      "learning_rate": 2.1757389113306404e-05,
      "loss": 0.0859,
      "step": 84770
    },
    {
      "epoch": 1.6953965524137105,
      "grad_norm": 0.24333710968494415,
      "learning_rate": 2.1754056179925077e-05,
      "loss": 0.0992,
      "step": 84780
    },
    {
      "epoch": 1.6955965284165901,
      "grad_norm": 0.1760219931602478,
      "learning_rate": 2.175072324654375e-05,
      "loss": 0.0829,
      "step": 84790
    },
    {
      "epoch": 1.6957965044194698,
      "grad_norm": 0.13717323541641235,
      "learning_rate": 2.1747390313162423e-05,
      "loss": 0.1131,
      "step": 84800
    },
    {
      "epoch": 1.6959964804223493,
      "grad_norm": 0.10218940675258636,
      "learning_rate": 2.1744057379781093e-05,
      "loss": 0.0655,
      "step": 84810
    },
    {
      "epoch": 1.696196456425229,
      "grad_norm": 0.08245450258255005,
      "learning_rate": 2.1740724446399766e-05,
      "loss": 0.0827,
      "step": 84820
    },
    {
      "epoch": 1.6963964324281087,
      "grad_norm": 0.24007682502269745,
      "learning_rate": 2.173739151301844e-05,
      "loss": 0.1213,
      "step": 84830
    },
    {
      "epoch": 1.6965964084309881,
      "grad_norm": 0.09674536436796188,
      "learning_rate": 2.173405857963711e-05,
      "loss": 0.0421,
      "step": 84840
    },
    {
      "epoch": 1.6967963844338678,
      "grad_norm": 0.21850350499153137,
      "learning_rate": 2.1730725646255785e-05,
      "loss": 0.0917,
      "step": 84850
    },
    {
      "epoch": 1.6969963604367475,
      "grad_norm": 0.1874580979347229,
      "learning_rate": 2.1727392712874454e-05,
      "loss": 0.0809,
      "step": 84860
    },
    {
      "epoch": 1.6971963364396272,
      "grad_norm": 0.12155723571777344,
      "learning_rate": 2.1724059779493127e-05,
      "loss": 0.075,
      "step": 84870
    },
    {
      "epoch": 1.6973963124425069,
      "grad_norm": 0.12010911852121353,
      "learning_rate": 2.17207268461118e-05,
      "loss": 0.0852,
      "step": 84880
    },
    {
      "epoch": 1.6975962884453866,
      "grad_norm": 0.06929436326026917,
      "learning_rate": 2.1717393912730473e-05,
      "loss": 0.0508,
      "step": 84890
    },
    {
      "epoch": 1.6977962644482663,
      "grad_norm": 0.142981618642807,
      "learning_rate": 2.1714060979349146e-05,
      "loss": 0.0754,
      "step": 84900
    },
    {
      "epoch": 1.697996240451146,
      "grad_norm": 0.1352115124464035,
      "learning_rate": 2.171072804596782e-05,
      "loss": 0.0651,
      "step": 84910
    },
    {
      "epoch": 1.6981962164540256,
      "grad_norm": 0.18410177528858185,
      "learning_rate": 2.170739511258649e-05,
      "loss": 0.0865,
      "step": 84920
    },
    {
      "epoch": 1.6983961924569053,
      "grad_norm": 0.18450726568698883,
      "learning_rate": 2.1704062179205162e-05,
      "loss": 0.0855,
      "step": 84930
    },
    {
      "epoch": 1.6985961684597848,
      "grad_norm": 0.1886628121137619,
      "learning_rate": 2.1700729245823835e-05,
      "loss": 0.097,
      "step": 84940
    },
    {
      "epoch": 1.6987961444626645,
      "grad_norm": 0.16256581246852875,
      "learning_rate": 2.1697396312442508e-05,
      "loss": 0.0939,
      "step": 84950
    },
    {
      "epoch": 1.6989961204655442,
      "grad_norm": 0.09480012208223343,
      "learning_rate": 2.169406337906118e-05,
      "loss": 0.0739,
      "step": 84960
    },
    {
      "epoch": 1.6991960964684238,
      "grad_norm": 0.1971307396888733,
      "learning_rate": 2.169073044567985e-05,
      "loss": 0.0756,
      "step": 84970
    },
    {
      "epoch": 1.6993960724713033,
      "grad_norm": 0.08068643510341644,
      "learning_rate": 2.1687397512298524e-05,
      "loss": 0.0536,
      "step": 84980
    },
    {
      "epoch": 1.699596048474183,
      "grad_norm": 0.1879683881998062,
      "learning_rate": 2.16840645789172e-05,
      "loss": 0.0644,
      "step": 84990
    },
    {
      "epoch": 1.6997960244770627,
      "grad_norm": 0.14477458596229553,
      "learning_rate": 2.168073164553587e-05,
      "loss": 0.0471,
      "step": 85000
    },
    {
      "epoch": 1.6999960004799424,
      "grad_norm": 0.11266699433326721,
      "learning_rate": 2.1677398712154543e-05,
      "loss": 0.0615,
      "step": 85010
    },
    {
      "epoch": 1.700195976482822,
      "grad_norm": 0.11688484996557236,
      "learning_rate": 2.1674065778773216e-05,
      "loss": 0.0656,
      "step": 85020
    },
    {
      "epoch": 1.7003959524857017,
      "grad_norm": 0.10626424103975296,
      "learning_rate": 2.1670732845391885e-05,
      "loss": 0.0494,
      "step": 85030
    },
    {
      "epoch": 1.7005959284885814,
      "grad_norm": 0.14777612686157227,
      "learning_rate": 2.166739991201056e-05,
      "loss": 0.0718,
      "step": 85040
    },
    {
      "epoch": 1.7007959044914611,
      "grad_norm": 0.17207564413547516,
      "learning_rate": 2.166406697862923e-05,
      "loss": 0.0724,
      "step": 85050
    },
    {
      "epoch": 1.7009958804943408,
      "grad_norm": 0.16167274117469788,
      "learning_rate": 2.1660734045247904e-05,
      "loss": 0.0713,
      "step": 85060
    },
    {
      "epoch": 1.7011958564972205,
      "grad_norm": 0.24038195610046387,
      "learning_rate": 2.1657401111866577e-05,
      "loss": 0.1121,
      "step": 85070
    },
    {
      "epoch": 1.7013958325001,
      "grad_norm": 0.07219202071428299,
      "learning_rate": 2.1654068178485247e-05,
      "loss": 0.0787,
      "step": 85080
    },
    {
      "epoch": 1.7015958085029796,
      "grad_norm": 0.15020138025283813,
      "learning_rate": 2.1650735245103923e-05,
      "loss": 0.0592,
      "step": 85090
    },
    {
      "epoch": 1.7017957845058593,
      "grad_norm": 0.07614420354366302,
      "learning_rate": 2.1647402311722596e-05,
      "loss": 0.0756,
      "step": 85100
    },
    {
      "epoch": 1.7019957605087388,
      "grad_norm": 0.09095479547977448,
      "learning_rate": 2.1644069378341266e-05,
      "loss": 0.0915,
      "step": 85110
    },
    {
      "epoch": 1.7021957365116185,
      "grad_norm": 0.13227924704551697,
      "learning_rate": 2.164073644495994e-05,
      "loss": 0.0723,
      "step": 85120
    },
    {
      "epoch": 1.7023957125144982,
      "grad_norm": 0.054863717406988144,
      "learning_rate": 2.1637403511578612e-05,
      "loss": 0.1017,
      "step": 85130
    },
    {
      "epoch": 1.7025956885173779,
      "grad_norm": 0.12888893485069275,
      "learning_rate": 2.1634070578197285e-05,
      "loss": 0.0878,
      "step": 85140
    },
    {
      "epoch": 1.7027956645202575,
      "grad_norm": 0.19983117282390594,
      "learning_rate": 2.1630737644815958e-05,
      "loss": 0.0702,
      "step": 85150
    },
    {
      "epoch": 1.7029956405231372,
      "grad_norm": 0.12666501104831696,
      "learning_rate": 2.1627404711434627e-05,
      "loss": 0.0748,
      "step": 85160
    },
    {
      "epoch": 1.703195616526017,
      "grad_norm": 0.15447480976581573,
      "learning_rate": 2.16240717780533e-05,
      "loss": 0.0666,
      "step": 85170
    },
    {
      "epoch": 1.7033955925288966,
      "grad_norm": 0.08351349085569382,
      "learning_rate": 2.1620738844671974e-05,
      "loss": 0.0616,
      "step": 85180
    },
    {
      "epoch": 1.7035955685317763,
      "grad_norm": 0.1766575127840042,
      "learning_rate": 2.1617405911290647e-05,
      "loss": 0.1125,
      "step": 85190
    },
    {
      "epoch": 1.703795544534656,
      "grad_norm": 0.10094735771417618,
      "learning_rate": 2.161407297790932e-05,
      "loss": 0.0417,
      "step": 85200
    },
    {
      "epoch": 1.7039955205375354,
      "grad_norm": 0.18824391067028046,
      "learning_rate": 2.1610740044527993e-05,
      "loss": 0.0877,
      "step": 85210
    },
    {
      "epoch": 1.7041954965404151,
      "grad_norm": 0.12471607327461243,
      "learning_rate": 2.1607407111146662e-05,
      "loss": 0.0457,
      "step": 85220
    },
    {
      "epoch": 1.7043954725432948,
      "grad_norm": 0.07448993623256683,
      "learning_rate": 2.1604074177765335e-05,
      "loss": 0.0578,
      "step": 85230
    },
    {
      "epoch": 1.7045954485461745,
      "grad_norm": 0.1540604829788208,
      "learning_rate": 2.1600741244384008e-05,
      "loss": 0.1093,
      "step": 85240
    },
    {
      "epoch": 1.704795424549054,
      "grad_norm": 0.18352669477462769,
      "learning_rate": 2.159740831100268e-05,
      "loss": 0.0767,
      "step": 85250
    },
    {
      "epoch": 1.7049954005519337,
      "grad_norm": 0.2199469953775406,
      "learning_rate": 2.1594075377621354e-05,
      "loss": 0.0595,
      "step": 85260
    },
    {
      "epoch": 1.7051953765548133,
      "grad_norm": 0.09244299679994583,
      "learning_rate": 2.1590742444240024e-05,
      "loss": 0.0633,
      "step": 85270
    },
    {
      "epoch": 1.705395352557693,
      "grad_norm": 0.09636647999286652,
      "learning_rate": 2.1587409510858697e-05,
      "loss": 0.0909,
      "step": 85280
    },
    {
      "epoch": 1.7055953285605727,
      "grad_norm": 0.21700310707092285,
      "learning_rate": 2.1584076577477373e-05,
      "loss": 0.0766,
      "step": 85290
    },
    {
      "epoch": 1.7057953045634524,
      "grad_norm": 0.16225747764110565,
      "learning_rate": 2.1580743644096043e-05,
      "loss": 0.0833,
      "step": 85300
    },
    {
      "epoch": 1.705995280566332,
      "grad_norm": 0.08374480158090591,
      "learning_rate": 2.1577410710714716e-05,
      "loss": 0.0494,
      "step": 85310
    },
    {
      "epoch": 1.7061952565692118,
      "grad_norm": 0.11650725454092026,
      "learning_rate": 2.157407777733339e-05,
      "loss": 0.0763,
      "step": 85320
    },
    {
      "epoch": 1.7063952325720915,
      "grad_norm": 0.10699298232793808,
      "learning_rate": 2.157074484395206e-05,
      "loss": 0.0745,
      "step": 85330
    },
    {
      "epoch": 1.7065952085749712,
      "grad_norm": 0.12572988867759705,
      "learning_rate": 2.156741191057073e-05,
      "loss": 0.0747,
      "step": 85340
    },
    {
      "epoch": 1.7067951845778506,
      "grad_norm": 0.1482182890176773,
      "learning_rate": 2.1564078977189404e-05,
      "loss": 0.1082,
      "step": 85350
    },
    {
      "epoch": 1.7069951605807303,
      "grad_norm": 0.164896622300148,
      "learning_rate": 2.1560746043808077e-05,
      "loss": 0.0766,
      "step": 85360
    },
    {
      "epoch": 1.70719513658361,
      "grad_norm": 0.06854525953531265,
      "learning_rate": 2.155741311042675e-05,
      "loss": 0.0724,
      "step": 85370
    },
    {
      "epoch": 1.7073951125864895,
      "grad_norm": 0.20607149600982666,
      "learning_rate": 2.155408017704542e-05,
      "loss": 0.0626,
      "step": 85380
    },
    {
      "epoch": 1.7075950885893691,
      "grad_norm": 0.08747082948684692,
      "learning_rate": 2.1550747243664093e-05,
      "loss": 0.0927,
      "step": 85390
    },
    {
      "epoch": 1.7077950645922488,
      "grad_norm": 0.11668943613767624,
      "learning_rate": 2.154741431028277e-05,
      "loss": 0.0438,
      "step": 85400
    },
    {
      "epoch": 1.7079950405951285,
      "grad_norm": 0.09545046836137772,
      "learning_rate": 2.154408137690144e-05,
      "loss": 0.1234,
      "step": 85410
    },
    {
      "epoch": 1.7081950165980082,
      "grad_norm": 0.15895646810531616,
      "learning_rate": 2.1540748443520112e-05,
      "loss": 0.0802,
      "step": 85420
    },
    {
      "epoch": 1.708394992600888,
      "grad_norm": 0.07905103266239166,
      "learning_rate": 2.1537415510138785e-05,
      "loss": 0.0791,
      "step": 85430
    },
    {
      "epoch": 1.7085949686037676,
      "grad_norm": 0.06473653018474579,
      "learning_rate": 2.1534082576757455e-05,
      "loss": 0.1229,
      "step": 85440
    },
    {
      "epoch": 1.7087949446066473,
      "grad_norm": 0.13465800881385803,
      "learning_rate": 2.153074964337613e-05,
      "loss": 0.0792,
      "step": 85450
    },
    {
      "epoch": 1.708994920609527,
      "grad_norm": 0.11085275560617447,
      "learning_rate": 2.15274167099948e-05,
      "loss": 0.0474,
      "step": 85460
    },
    {
      "epoch": 1.7091948966124066,
      "grad_norm": 0.080045185983181,
      "learning_rate": 2.1524083776613474e-05,
      "loss": 0.0706,
      "step": 85470
    },
    {
      "epoch": 1.7093948726152863,
      "grad_norm": 0.12479889392852783,
      "learning_rate": 2.1520750843232147e-05,
      "loss": 0.0817,
      "step": 85480
    },
    {
      "epoch": 1.7095948486181658,
      "grad_norm": 0.1499151885509491,
      "learning_rate": 2.1517417909850816e-05,
      "loss": 0.0664,
      "step": 85490
    },
    {
      "epoch": 1.7097948246210455,
      "grad_norm": 0.2148449569940567,
      "learning_rate": 2.1514084976469493e-05,
      "loss": 0.064,
      "step": 85500
    },
    {
      "epoch": 1.7099948006239252,
      "grad_norm": 0.19984284043312073,
      "learning_rate": 2.1510752043088166e-05,
      "loss": 0.0919,
      "step": 85510
    },
    {
      "epoch": 1.7101947766268046,
      "grad_norm": 0.10215267539024353,
      "learning_rate": 2.1507419109706835e-05,
      "loss": 0.1156,
      "step": 85520
    },
    {
      "epoch": 1.7103947526296843,
      "grad_norm": 0.20814046263694763,
      "learning_rate": 2.150408617632551e-05,
      "loss": 0.1035,
      "step": 85530
    },
    {
      "epoch": 1.710594728632564,
      "grad_norm": 0.1891757994890213,
      "learning_rate": 2.150075324294418e-05,
      "loss": 0.0885,
      "step": 85540
    },
    {
      "epoch": 1.7107947046354437,
      "grad_norm": 0.15945376455783844,
      "learning_rate": 2.1497420309562854e-05,
      "loss": 0.0992,
      "step": 85550
    },
    {
      "epoch": 1.7109946806383234,
      "grad_norm": 0.11232549697160721,
      "learning_rate": 2.1494087376181527e-05,
      "loss": 0.0644,
      "step": 85560
    },
    {
      "epoch": 1.711194656641203,
      "grad_norm": 0.23050326108932495,
      "learning_rate": 2.1490754442800197e-05,
      "loss": 0.089,
      "step": 85570
    },
    {
      "epoch": 1.7113946326440828,
      "grad_norm": 0.20570382475852966,
      "learning_rate": 2.148742150941887e-05,
      "loss": 0.0746,
      "step": 85580
    },
    {
      "epoch": 1.7115946086469624,
      "grad_norm": 0.11159022152423859,
      "learning_rate": 2.1484088576037543e-05,
      "loss": 0.0495,
      "step": 85590
    },
    {
      "epoch": 1.7117945846498421,
      "grad_norm": 0.14828285574913025,
      "learning_rate": 2.1480755642656216e-05,
      "loss": 0.0719,
      "step": 85600
    },
    {
      "epoch": 1.7119945606527218,
      "grad_norm": 0.117585688829422,
      "learning_rate": 2.147742270927489e-05,
      "loss": 0.0811,
      "step": 85610
    },
    {
      "epoch": 1.7121945366556013,
      "grad_norm": 0.18252450227737427,
      "learning_rate": 2.1474089775893562e-05,
      "loss": 0.0773,
      "step": 85620
    },
    {
      "epoch": 1.712394512658481,
      "grad_norm": 0.07703553140163422,
      "learning_rate": 2.147075684251223e-05,
      "loss": 0.057,
      "step": 85630
    },
    {
      "epoch": 1.7125944886613607,
      "grad_norm": 0.2231893390417099,
      "learning_rate": 2.1467423909130905e-05,
      "loss": 0.0786,
      "step": 85640
    },
    {
      "epoch": 1.7127944646642403,
      "grad_norm": 0.14974601566791534,
      "learning_rate": 2.1464090975749578e-05,
      "loss": 0.0773,
      "step": 85650
    },
    {
      "epoch": 1.7129944406671198,
      "grad_norm": 0.11750712990760803,
      "learning_rate": 2.146075804236825e-05,
      "loss": 0.0493,
      "step": 85660
    },
    {
      "epoch": 1.7131944166699995,
      "grad_norm": 0.10155574977397919,
      "learning_rate": 2.1457425108986924e-05,
      "loss": 0.08,
      "step": 85670
    },
    {
      "epoch": 1.7133943926728792,
      "grad_norm": 0.11811424046754837,
      "learning_rate": 2.1454092175605593e-05,
      "loss": 0.0744,
      "step": 85680
    },
    {
      "epoch": 1.7135943686757589,
      "grad_norm": 0.07081981748342514,
      "learning_rate": 2.1450759242224266e-05,
      "loss": 0.0661,
      "step": 85690
    },
    {
      "epoch": 1.7137943446786386,
      "grad_norm": 0.09543377161026001,
      "learning_rate": 2.1447426308842943e-05,
      "loss": 0.0524,
      "step": 85700
    },
    {
      "epoch": 1.7139943206815182,
      "grad_norm": 0.10996374487876892,
      "learning_rate": 2.1444093375461612e-05,
      "loss": 0.051,
      "step": 85710
    },
    {
      "epoch": 1.714194296684398,
      "grad_norm": 0.17220254242420197,
      "learning_rate": 2.1440760442080285e-05,
      "loss": 0.0763,
      "step": 85720
    },
    {
      "epoch": 1.7143942726872776,
      "grad_norm": 0.15571697056293488,
      "learning_rate": 2.1437427508698958e-05,
      "loss": 0.0743,
      "step": 85730
    },
    {
      "epoch": 1.7145942486901573,
      "grad_norm": 0.1281139999628067,
      "learning_rate": 2.1434094575317628e-05,
      "loss": 0.0603,
      "step": 85740
    },
    {
      "epoch": 1.714794224693037,
      "grad_norm": 0.2047664225101471,
      "learning_rate": 2.1430761641936304e-05,
      "loss": 0.0869,
      "step": 85750
    },
    {
      "epoch": 1.7149942006959165,
      "grad_norm": 0.1387256532907486,
      "learning_rate": 2.1427428708554974e-05,
      "loss": 0.0497,
      "step": 85760
    },
    {
      "epoch": 1.7151941766987961,
      "grad_norm": 0.13647165894508362,
      "learning_rate": 2.1424095775173647e-05,
      "loss": 0.0846,
      "step": 85770
    },
    {
      "epoch": 1.7153941527016758,
      "grad_norm": 0.13358764350414276,
      "learning_rate": 2.142076284179232e-05,
      "loss": 0.0755,
      "step": 85780
    },
    {
      "epoch": 1.7155941287045553,
      "grad_norm": 0.20223955810070038,
      "learning_rate": 2.141742990841099e-05,
      "loss": 0.1089,
      "step": 85790
    },
    {
      "epoch": 1.715794104707435,
      "grad_norm": 0.16864368319511414,
      "learning_rate": 2.1414096975029666e-05,
      "loss": 0.0806,
      "step": 85800
    },
    {
      "epoch": 1.7159940807103147,
      "grad_norm": 0.19562874734401703,
      "learning_rate": 2.141076404164834e-05,
      "loss": 0.0611,
      "step": 85810
    },
    {
      "epoch": 1.7161940567131944,
      "grad_norm": 0.09865325689315796,
      "learning_rate": 2.140743110826701e-05,
      "loss": 0.0443,
      "step": 85820
    },
    {
      "epoch": 1.716394032716074,
      "grad_norm": 0.2049727737903595,
      "learning_rate": 2.140409817488568e-05,
      "loss": 0.1046,
      "step": 85830
    },
    {
      "epoch": 1.7165940087189537,
      "grad_norm": 0.10665567219257355,
      "learning_rate": 2.1400765241504354e-05,
      "loss": 0.0771,
      "step": 85840
    },
    {
      "epoch": 1.7167939847218334,
      "grad_norm": 0.16924040019512177,
      "learning_rate": 2.1397432308123024e-05,
      "loss": 0.0875,
      "step": 85850
    },
    {
      "epoch": 1.716993960724713,
      "grad_norm": 0.07793695479631424,
      "learning_rate": 2.13940993747417e-05,
      "loss": 0.0814,
      "step": 85860
    },
    {
      "epoch": 1.7171939367275928,
      "grad_norm": 0.10801474750041962,
      "learning_rate": 2.139076644136037e-05,
      "loss": 0.0557,
      "step": 85870
    },
    {
      "epoch": 1.7173939127304725,
      "grad_norm": 0.2374105453491211,
      "learning_rate": 2.1387433507979043e-05,
      "loss": 0.0692,
      "step": 85880
    },
    {
      "epoch": 1.717593888733352,
      "grad_norm": 0.14965803921222687,
      "learning_rate": 2.1384100574597716e-05,
      "loss": 0.0642,
      "step": 85890
    },
    {
      "epoch": 1.7177938647362316,
      "grad_norm": 0.18507640063762665,
      "learning_rate": 2.1380767641216386e-05,
      "loss": 0.0897,
      "step": 85900
    },
    {
      "epoch": 1.7179938407391113,
      "grad_norm": 0.08015483617782593,
      "learning_rate": 2.1377434707835062e-05,
      "loss": 0.061,
      "step": 85910
    },
    {
      "epoch": 1.718193816741991,
      "grad_norm": 0.17579832673072815,
      "learning_rate": 2.1374101774453735e-05,
      "loss": 0.057,
      "step": 85920
    },
    {
      "epoch": 1.7183937927448705,
      "grad_norm": 0.10984744131565094,
      "learning_rate": 2.1370768841072405e-05,
      "loss": 0.0587,
      "step": 85930
    },
    {
      "epoch": 1.7185937687477502,
      "grad_norm": 0.14173002541065216,
      "learning_rate": 2.1367435907691078e-05,
      "loss": 0.0949,
      "step": 85940
    },
    {
      "epoch": 1.7187937447506298,
      "grad_norm": 0.05306742712855339,
      "learning_rate": 2.136410297430975e-05,
      "loss": 0.0665,
      "step": 85950
    },
    {
      "epoch": 1.7189937207535095,
      "grad_norm": 0.3248215913772583,
      "learning_rate": 2.1360770040928424e-05,
      "loss": 0.1044,
      "step": 85960
    },
    {
      "epoch": 1.7191936967563892,
      "grad_norm": 0.11736585944890976,
      "learning_rate": 2.1357437107547097e-05,
      "loss": 0.073,
      "step": 85970
    },
    {
      "epoch": 1.719393672759269,
      "grad_norm": 0.212093785405159,
      "learning_rate": 2.1354104174165766e-05,
      "loss": 0.0627,
      "step": 85980
    },
    {
      "epoch": 1.7195936487621486,
      "grad_norm": 0.08342062681913376,
      "learning_rate": 2.135077124078444e-05,
      "loss": 0.0731,
      "step": 85990
    },
    {
      "epoch": 1.7197936247650283,
      "grad_norm": 0.18122097849845886,
      "learning_rate": 2.1347438307403112e-05,
      "loss": 0.0735,
      "step": 86000
    },
    {
      "epoch": 1.719993600767908,
      "grad_norm": 0.21030667424201965,
      "learning_rate": 2.1344105374021785e-05,
      "loss": 0.0745,
      "step": 86010
    },
    {
      "epoch": 1.7201935767707877,
      "grad_norm": 0.07205236703157425,
      "learning_rate": 2.134077244064046e-05,
      "loss": 0.0478,
      "step": 86020
    },
    {
      "epoch": 1.7203935527736671,
      "grad_norm": 0.1455913782119751,
      "learning_rate": 2.133743950725913e-05,
      "loss": 0.0692,
      "step": 86030
    },
    {
      "epoch": 1.7205935287765468,
      "grad_norm": 0.2679606080055237,
      "learning_rate": 2.13341065738778e-05,
      "loss": 0.0732,
      "step": 86040
    },
    {
      "epoch": 1.7207935047794265,
      "grad_norm": 0.157480388879776,
      "learning_rate": 2.1330773640496474e-05,
      "loss": 0.0519,
      "step": 86050
    },
    {
      "epoch": 1.720993480782306,
      "grad_norm": 0.1848224699497223,
      "learning_rate": 2.1327440707115147e-05,
      "loss": 0.0524,
      "step": 86060
    },
    {
      "epoch": 1.7211934567851856,
      "grad_norm": 0.20346850156784058,
      "learning_rate": 2.132410777373382e-05,
      "loss": 0.0603,
      "step": 86070
    },
    {
      "epoch": 1.7213934327880653,
      "grad_norm": 0.20970028638839722,
      "learning_rate": 2.1320774840352493e-05,
      "loss": 0.1012,
      "step": 86080
    },
    {
      "epoch": 1.721593408790945,
      "grad_norm": 0.1874154955148697,
      "learning_rate": 2.1317441906971163e-05,
      "loss": 0.0796,
      "step": 86090
    },
    {
      "epoch": 1.7217933847938247,
      "grad_norm": 0.07600522041320801,
      "learning_rate": 2.1314108973589836e-05,
      "loss": 0.0962,
      "step": 86100
    },
    {
      "epoch": 1.7219933607967044,
      "grad_norm": 0.1711932122707367,
      "learning_rate": 2.1310776040208512e-05,
      "loss": 0.0766,
      "step": 86110
    },
    {
      "epoch": 1.722193336799584,
      "grad_norm": 0.16537389159202576,
      "learning_rate": 2.130744310682718e-05,
      "loss": 0.0711,
      "step": 86120
    },
    {
      "epoch": 1.7223933128024638,
      "grad_norm": 0.13064326345920563,
      "learning_rate": 2.1304110173445855e-05,
      "loss": 0.0658,
      "step": 86130
    },
    {
      "epoch": 1.7225932888053435,
      "grad_norm": 0.16502152383327484,
      "learning_rate": 2.1300777240064528e-05,
      "loss": 0.074,
      "step": 86140
    },
    {
      "epoch": 1.7227932648082231,
      "grad_norm": 0.10099313408136368,
      "learning_rate": 2.1297444306683197e-05,
      "loss": 0.0698,
      "step": 86150
    },
    {
      "epoch": 1.7229932408111028,
      "grad_norm": 0.2475566267967224,
      "learning_rate": 2.1294111373301874e-05,
      "loss": 0.1031,
      "step": 86160
    },
    {
      "epoch": 1.7231932168139823,
      "grad_norm": 0.16104575991630554,
      "learning_rate": 2.1290778439920543e-05,
      "loss": 0.0932,
      "step": 86170
    },
    {
      "epoch": 1.723393192816862,
      "grad_norm": 0.17638596892356873,
      "learning_rate": 2.1287445506539216e-05,
      "loss": 0.0701,
      "step": 86180
    },
    {
      "epoch": 1.7235931688197417,
      "grad_norm": 0.07279946655035019,
      "learning_rate": 2.128411257315789e-05,
      "loss": 0.0826,
      "step": 86190
    },
    {
      "epoch": 1.7237931448226211,
      "grad_norm": 0.1772601157426834,
      "learning_rate": 2.128077963977656e-05,
      "loss": 0.0897,
      "step": 86200
    },
    {
      "epoch": 1.7239931208255008,
      "grad_norm": 0.10167671740055084,
      "learning_rate": 2.1277446706395235e-05,
      "loss": 0.0786,
      "step": 86210
    },
    {
      "epoch": 1.7241930968283805,
      "grad_norm": 0.07334685325622559,
      "learning_rate": 2.127411377301391e-05,
      "loss": 0.0785,
      "step": 86220
    },
    {
      "epoch": 1.7243930728312602,
      "grad_norm": 0.14185626804828644,
      "learning_rate": 2.1270780839632578e-05,
      "loss": 0.1574,
      "step": 86230
    },
    {
      "epoch": 1.7245930488341399,
      "grad_norm": 0.12990312278270721,
      "learning_rate": 2.126744790625125e-05,
      "loss": 0.0718,
      "step": 86240
    },
    {
      "epoch": 1.7247930248370196,
      "grad_norm": 0.05481090396642685,
      "learning_rate": 2.1264114972869924e-05,
      "loss": 0.0941,
      "step": 86250
    },
    {
      "epoch": 1.7249930008398993,
      "grad_norm": 0.2414434850215912,
      "learning_rate": 2.1260782039488597e-05,
      "loss": 0.0669,
      "step": 86260
    },
    {
      "epoch": 1.725192976842779,
      "grad_norm": 0.23195230960845947,
      "learning_rate": 2.125744910610727e-05,
      "loss": 0.0812,
      "step": 86270
    },
    {
      "epoch": 1.7253929528456586,
      "grad_norm": 0.1664966344833374,
      "learning_rate": 2.125411617272594e-05,
      "loss": 0.0792,
      "step": 86280
    },
    {
      "epoch": 1.7255929288485383,
      "grad_norm": 0.11745703965425491,
      "learning_rate": 2.1250783239344613e-05,
      "loss": 0.0757,
      "step": 86290
    },
    {
      "epoch": 1.7257929048514178,
      "grad_norm": 0.10678242892026901,
      "learning_rate": 2.1247450305963286e-05,
      "loss": 0.1261,
      "step": 86300
    },
    {
      "epoch": 1.7259928808542975,
      "grad_norm": 0.1355077624320984,
      "learning_rate": 2.124411737258196e-05,
      "loss": 0.0777,
      "step": 86310
    },
    {
      "epoch": 1.7261928568571772,
      "grad_norm": 0.098948173224926,
      "learning_rate": 2.124078443920063e-05,
      "loss": 0.0687,
      "step": 86320
    },
    {
      "epoch": 1.7263928328600568,
      "grad_norm": 0.09922974556684494,
      "learning_rate": 2.1237451505819305e-05,
      "loss": 0.0715,
      "step": 86330
    },
    {
      "epoch": 1.7265928088629363,
      "grad_norm": 0.18515226244926453,
      "learning_rate": 2.1234118572437974e-05,
      "loss": 0.0797,
      "step": 86340
    },
    {
      "epoch": 1.726792784865816,
      "grad_norm": 0.23763418197631836,
      "learning_rate": 2.1230785639056647e-05,
      "loss": 0.0897,
      "step": 86350
    },
    {
      "epoch": 1.7269927608686957,
      "grad_norm": 0.08548073470592499,
      "learning_rate": 2.122745270567532e-05,
      "loss": 0.0634,
      "step": 86360
    },
    {
      "epoch": 1.7271927368715754,
      "grad_norm": 0.3041118085384369,
      "learning_rate": 2.1224119772293993e-05,
      "loss": 0.0742,
      "step": 86370
    },
    {
      "epoch": 1.727392712874455,
      "grad_norm": 0.10656723380088806,
      "learning_rate": 2.1220786838912666e-05,
      "loss": 0.0741,
      "step": 86380
    },
    {
      "epoch": 1.7275926888773347,
      "grad_norm": 0.178661048412323,
      "learning_rate": 2.1217453905531336e-05,
      "loss": 0.0975,
      "step": 86390
    },
    {
      "epoch": 1.7277926648802144,
      "grad_norm": 0.21897032856941223,
      "learning_rate": 2.121412097215001e-05,
      "loss": 0.0736,
      "step": 86400
    },
    {
      "epoch": 1.7279926408830941,
      "grad_norm": 0.13812023401260376,
      "learning_rate": 2.1210788038768682e-05,
      "loss": 0.0952,
      "step": 86410
    },
    {
      "epoch": 1.7281926168859738,
      "grad_norm": 0.24924378097057343,
      "learning_rate": 2.1207455105387355e-05,
      "loss": 0.0765,
      "step": 86420
    },
    {
      "epoch": 1.7283925928888535,
      "grad_norm": 0.1460142880678177,
      "learning_rate": 2.1204122172006028e-05,
      "loss": 0.0603,
      "step": 86430
    },
    {
      "epoch": 1.728592568891733,
      "grad_norm": 0.143984854221344,
      "learning_rate": 2.12007892386247e-05,
      "loss": 0.064,
      "step": 86440
    },
    {
      "epoch": 1.7287925448946126,
      "grad_norm": 0.190031036734581,
      "learning_rate": 2.119745630524337e-05,
      "loss": 0.0826,
      "step": 86450
    },
    {
      "epoch": 1.7289925208974923,
      "grad_norm": 0.11894021928310394,
      "learning_rate": 2.1194123371862043e-05,
      "loss": 0.0599,
      "step": 86460
    },
    {
      "epoch": 1.7291924969003718,
      "grad_norm": 0.07799214869737625,
      "learning_rate": 2.1190790438480716e-05,
      "loss": 0.0805,
      "step": 86470
    },
    {
      "epoch": 1.7293924729032515,
      "grad_norm": 0.23023584485054016,
      "learning_rate": 2.118745750509939e-05,
      "loss": 0.0471,
      "step": 86480
    },
    {
      "epoch": 1.7295924489061312,
      "grad_norm": 0.05456928536295891,
      "learning_rate": 2.1184124571718062e-05,
      "loss": 0.0764,
      "step": 86490
    },
    {
      "epoch": 1.7297924249090109,
      "grad_norm": 0.172134667634964,
      "learning_rate": 2.1180791638336732e-05,
      "loss": 0.0688,
      "step": 86500
    },
    {
      "epoch": 1.7299924009118905,
      "grad_norm": 0.18401765823364258,
      "learning_rate": 2.1177458704955405e-05,
      "loss": 0.0575,
      "step": 86510
    },
    {
      "epoch": 1.7301923769147702,
      "grad_norm": 0.1779981255531311,
      "learning_rate": 2.117412577157408e-05,
      "loss": 0.0554,
      "step": 86520
    },
    {
      "epoch": 1.73039235291765,
      "grad_norm": 0.10867057740688324,
      "learning_rate": 2.117079283819275e-05,
      "loss": 0.0646,
      "step": 86530
    },
    {
      "epoch": 1.7305923289205296,
      "grad_norm": 0.09889799356460571,
      "learning_rate": 2.1167459904811424e-05,
      "loss": 0.0728,
      "step": 86540
    },
    {
      "epoch": 1.7307923049234093,
      "grad_norm": 0.07073748111724854,
      "learning_rate": 2.1164126971430097e-05,
      "loss": 0.0477,
      "step": 86550
    },
    {
      "epoch": 1.730992280926289,
      "grad_norm": 0.15934154391288757,
      "learning_rate": 2.1160794038048767e-05,
      "loss": 0.0701,
      "step": 86560
    },
    {
      "epoch": 1.7311922569291684,
      "grad_norm": 0.07166298478841782,
      "learning_rate": 2.1157461104667443e-05,
      "loss": 0.051,
      "step": 86570
    },
    {
      "epoch": 1.7313922329320481,
      "grad_norm": 0.18259026110172272,
      "learning_rate": 2.1154128171286113e-05,
      "loss": 0.0513,
      "step": 86580
    },
    {
      "epoch": 1.7315922089349278,
      "grad_norm": 0.11905304342508316,
      "learning_rate": 2.1150795237904786e-05,
      "loss": 0.08,
      "step": 86590
    },
    {
      "epoch": 1.7317921849378075,
      "grad_norm": 0.044701047241687775,
      "learning_rate": 2.114746230452346e-05,
      "loss": 0.0571,
      "step": 86600
    },
    {
      "epoch": 1.731992160940687,
      "grad_norm": 0.11521050333976746,
      "learning_rate": 2.114412937114213e-05,
      "loss": 0.0944,
      "step": 86610
    },
    {
      "epoch": 1.7321921369435667,
      "grad_norm": 0.10675815492868423,
      "learning_rate": 2.1140796437760805e-05,
      "loss": 0.0551,
      "step": 86620
    },
    {
      "epoch": 1.7323921129464463,
      "grad_norm": 0.07925544679164886,
      "learning_rate": 2.1137463504379478e-05,
      "loss": 0.0487,
      "step": 86630
    },
    {
      "epoch": 1.732592088949326,
      "grad_norm": 0.051414139568805695,
      "learning_rate": 2.1134130570998147e-05,
      "loss": 0.0872,
      "step": 86640
    },
    {
      "epoch": 1.7327920649522057,
      "grad_norm": 0.13400523364543915,
      "learning_rate": 2.113079763761682e-05,
      "loss": 0.0609,
      "step": 86650
    },
    {
      "epoch": 1.7329920409550854,
      "grad_norm": 0.17403526604175568,
      "learning_rate": 2.1127464704235493e-05,
      "loss": 0.1002,
      "step": 86660
    },
    {
      "epoch": 1.733192016957965,
      "grad_norm": 0.07810100167989731,
      "learning_rate": 2.1124131770854166e-05,
      "loss": 0.0701,
      "step": 86670
    },
    {
      "epoch": 1.7333919929608448,
      "grad_norm": 0.145625039935112,
      "learning_rate": 2.112079883747284e-05,
      "loss": 0.0982,
      "step": 86680
    },
    {
      "epoch": 1.7335919689637245,
      "grad_norm": 0.08233795315027237,
      "learning_rate": 2.111746590409151e-05,
      "loss": 0.0734,
      "step": 86690
    },
    {
      "epoch": 1.7337919449666042,
      "grad_norm": 0.11939745396375656,
      "learning_rate": 2.1114132970710182e-05,
      "loss": 0.1224,
      "step": 86700
    },
    {
      "epoch": 1.7339919209694836,
      "grad_norm": 0.18297389149665833,
      "learning_rate": 2.1110800037328855e-05,
      "loss": 0.0644,
      "step": 86710
    },
    {
      "epoch": 1.7341918969723633,
      "grad_norm": 0.08321084082126617,
      "learning_rate": 2.1107467103947528e-05,
      "loss": 0.0757,
      "step": 86720
    },
    {
      "epoch": 1.734391872975243,
      "grad_norm": 0.08347306400537491,
      "learning_rate": 2.11041341705662e-05,
      "loss": 0.0894,
      "step": 86730
    },
    {
      "epoch": 1.7345918489781225,
      "grad_norm": 0.15705803036689758,
      "learning_rate": 2.110080123718487e-05,
      "loss": 0.0717,
      "step": 86740
    },
    {
      "epoch": 1.7347918249810022,
      "grad_norm": 0.05741511657834053,
      "learning_rate": 2.1097468303803544e-05,
      "loss": 0.0752,
      "step": 86750
    },
    {
      "epoch": 1.7349918009838818,
      "grad_norm": 0.13747824728488922,
      "learning_rate": 2.1094135370422217e-05,
      "loss": 0.0567,
      "step": 86760
    },
    {
      "epoch": 1.7351917769867615,
      "grad_norm": 0.20848315954208374,
      "learning_rate": 2.109080243704089e-05,
      "loss": 0.0793,
      "step": 86770
    },
    {
      "epoch": 1.7353917529896412,
      "grad_norm": 0.089178167283535,
      "learning_rate": 2.1087469503659563e-05,
      "loss": 0.1005,
      "step": 86780
    },
    {
      "epoch": 1.735591728992521,
      "grad_norm": 0.16604989767074585,
      "learning_rate": 2.1084136570278236e-05,
      "loss": 0.0519,
      "step": 86790
    },
    {
      "epoch": 1.7357917049954006,
      "grad_norm": 0.0495133250951767,
      "learning_rate": 2.1080803636896905e-05,
      "loss": 0.0967,
      "step": 86800
    },
    {
      "epoch": 1.7359916809982803,
      "grad_norm": 0.24542735517024994,
      "learning_rate": 2.1077470703515578e-05,
      "loss": 0.112,
      "step": 86810
    },
    {
      "epoch": 1.73619165700116,
      "grad_norm": 0.190082386136055,
      "learning_rate": 2.107413777013425e-05,
      "loss": 0.061,
      "step": 86820
    },
    {
      "epoch": 1.7363916330040396,
      "grad_norm": 0.10898485034704208,
      "learning_rate": 2.1070804836752924e-05,
      "loss": 0.0684,
      "step": 86830
    },
    {
      "epoch": 1.7365916090069193,
      "grad_norm": 0.08732320368289948,
      "learning_rate": 2.1067471903371597e-05,
      "loss": 0.068,
      "step": 86840
    },
    {
      "epoch": 1.7367915850097988,
      "grad_norm": 0.15662720799446106,
      "learning_rate": 2.1064138969990267e-05,
      "loss": 0.0678,
      "step": 86850
    },
    {
      "epoch": 1.7369915610126785,
      "grad_norm": 0.12342890352010727,
      "learning_rate": 2.106080603660894e-05,
      "loss": 0.0727,
      "step": 86860
    },
    {
      "epoch": 1.7371915370155582,
      "grad_norm": 0.11041989922523499,
      "learning_rate": 2.1057473103227613e-05,
      "loss": 0.0553,
      "step": 86870
    },
    {
      "epoch": 1.7373915130184376,
      "grad_norm": 0.21749457716941833,
      "learning_rate": 2.1054140169846286e-05,
      "loss": 0.1071,
      "step": 86880
    },
    {
      "epoch": 1.7375914890213173,
      "grad_norm": 0.19775541126728058,
      "learning_rate": 2.105080723646496e-05,
      "loss": 0.0877,
      "step": 86890
    },
    {
      "epoch": 1.737791465024197,
      "grad_norm": 0.20671719312667847,
      "learning_rate": 2.1047474303083632e-05,
      "loss": 0.0555,
      "step": 86900
    },
    {
      "epoch": 1.7379914410270767,
      "grad_norm": 0.09577040374279022,
      "learning_rate": 2.10441413697023e-05,
      "loss": 0.062,
      "step": 86910
    },
    {
      "epoch": 1.7381914170299564,
      "grad_norm": 0.2129683494567871,
      "learning_rate": 2.1040808436320975e-05,
      "loss": 0.0954,
      "step": 86920
    },
    {
      "epoch": 1.738391393032836,
      "grad_norm": 0.10817291587591171,
      "learning_rate": 2.1037475502939648e-05,
      "loss": 0.0648,
      "step": 86930
    },
    {
      "epoch": 1.7385913690357158,
      "grad_norm": 0.13979259133338928,
      "learning_rate": 2.103414256955832e-05,
      "loss": 0.0551,
      "step": 86940
    },
    {
      "epoch": 1.7387913450385954,
      "grad_norm": 0.11179077625274658,
      "learning_rate": 2.1030809636176994e-05,
      "loss": 0.0557,
      "step": 86950
    },
    {
      "epoch": 1.7389913210414751,
      "grad_norm": 0.10299958288669586,
      "learning_rate": 2.1027476702795663e-05,
      "loss": 0.0732,
      "step": 86960
    },
    {
      "epoch": 1.7391912970443548,
      "grad_norm": 0.21319687366485596,
      "learning_rate": 2.1024143769414336e-05,
      "loss": 0.0983,
      "step": 86970
    },
    {
      "epoch": 1.7393912730472343,
      "grad_norm": 0.09347216039896011,
      "learning_rate": 2.1020810836033013e-05,
      "loss": 0.0774,
      "step": 86980
    },
    {
      "epoch": 1.739591249050114,
      "grad_norm": 0.14302128553390503,
      "learning_rate": 2.1017477902651682e-05,
      "loss": 0.0953,
      "step": 86990
    },
    {
      "epoch": 1.7397912250529937,
      "grad_norm": 0.16620077192783356,
      "learning_rate": 2.1014144969270355e-05,
      "loss": 0.0672,
      "step": 87000
    },
    {
      "epoch": 1.7399912010558733,
      "grad_norm": 0.0748959556221962,
      "learning_rate": 2.1010812035889028e-05,
      "loss": 0.0599,
      "step": 87010
    },
    {
      "epoch": 1.7401911770587528,
      "grad_norm": 0.10817962139844894,
      "learning_rate": 2.1007479102507698e-05,
      "loss": 0.081,
      "step": 87020
    },
    {
      "epoch": 1.7403911530616325,
      "grad_norm": 0.08991362154483795,
      "learning_rate": 2.1004146169126374e-05,
      "loss": 0.0749,
      "step": 87030
    },
    {
      "epoch": 1.7405911290645122,
      "grad_norm": 0.057683199644088745,
      "learning_rate": 2.1000813235745044e-05,
      "loss": 0.0519,
      "step": 87040
    },
    {
      "epoch": 1.7407911050673919,
      "grad_norm": 0.14060501754283905,
      "learning_rate": 2.0997480302363717e-05,
      "loss": 0.0749,
      "step": 87050
    },
    {
      "epoch": 1.7409910810702716,
      "grad_norm": 0.05718427151441574,
      "learning_rate": 2.099414736898239e-05,
      "loss": 0.0875,
      "step": 87060
    },
    {
      "epoch": 1.7411910570731512,
      "grad_norm": 0.22575309872627258,
      "learning_rate": 2.099081443560106e-05,
      "loss": 0.0723,
      "step": 87070
    },
    {
      "epoch": 1.741391033076031,
      "grad_norm": 0.27279481291770935,
      "learning_rate": 2.0987481502219736e-05,
      "loss": 0.1163,
      "step": 87080
    },
    {
      "epoch": 1.7415910090789106,
      "grad_norm": 0.16754215955734253,
      "learning_rate": 2.098414856883841e-05,
      "loss": 0.076,
      "step": 87090
    },
    {
      "epoch": 1.7417909850817903,
      "grad_norm": 0.18198055028915405,
      "learning_rate": 2.098081563545708e-05,
      "loss": 0.0642,
      "step": 87100
    },
    {
      "epoch": 1.74199096108467,
      "grad_norm": 0.08864564448595047,
      "learning_rate": 2.097748270207575e-05,
      "loss": 0.0701,
      "step": 87110
    },
    {
      "epoch": 1.7421909370875495,
      "grad_norm": 0.19828227162361145,
      "learning_rate": 2.0974149768694424e-05,
      "loss": 0.1029,
      "step": 87120
    },
    {
      "epoch": 1.7423909130904291,
      "grad_norm": 0.19318775832653046,
      "learning_rate": 2.097115012865123e-05,
      "loss": 0.0698,
      "step": 87130
    },
    {
      "epoch": 1.7425908890933088,
      "grad_norm": 0.12636570632457733,
      "learning_rate": 2.09678171952699e-05,
      "loss": 0.072,
      "step": 87140
    },
    {
      "epoch": 1.7427908650961883,
      "grad_norm": 0.2536813020706177,
      "learning_rate": 2.0964484261888576e-05,
      "loss": 0.0819,
      "step": 87150
    },
    {
      "epoch": 1.742990841099068,
      "grad_norm": 0.13898445665836334,
      "learning_rate": 2.096115132850725e-05,
      "loss": 0.0444,
      "step": 87160
    },
    {
      "epoch": 1.7431908171019477,
      "grad_norm": 0.10183250904083252,
      "learning_rate": 2.095781839512592e-05,
      "loss": 0.0708,
      "step": 87170
    },
    {
      "epoch": 1.7433907931048274,
      "grad_norm": 0.0629037469625473,
      "learning_rate": 2.095448546174459e-05,
      "loss": 0.0596,
      "step": 87180
    },
    {
      "epoch": 1.743590769107707,
      "grad_norm": 0.10722474008798599,
      "learning_rate": 2.0951152528363264e-05,
      "loss": 0.1043,
      "step": 87190
    },
    {
      "epoch": 1.7437907451105867,
      "grad_norm": 0.06620615720748901,
      "learning_rate": 2.0947819594981937e-05,
      "loss": 0.0867,
      "step": 87200
    },
    {
      "epoch": 1.7439907211134664,
      "grad_norm": 0.0835757851600647,
      "learning_rate": 2.094448666160061e-05,
      "loss": 0.0685,
      "step": 87210
    },
    {
      "epoch": 1.7441906971163461,
      "grad_norm": 0.13266834616661072,
      "learning_rate": 2.094115372821928e-05,
      "loss": 0.077,
      "step": 87220
    },
    {
      "epoch": 1.7443906731192258,
      "grad_norm": 0.19293873012065887,
      "learning_rate": 2.0937820794837953e-05,
      "loss": 0.1454,
      "step": 87230
    },
    {
      "epoch": 1.7445906491221055,
      "grad_norm": 0.14975334703922272,
      "learning_rate": 2.0934487861456626e-05,
      "loss": 0.0527,
      "step": 87240
    },
    {
      "epoch": 1.744790625124985,
      "grad_norm": 0.08598901331424713,
      "learning_rate": 2.09311549280753e-05,
      "loss": 0.0772,
      "step": 87250
    },
    {
      "epoch": 1.7449906011278646,
      "grad_norm": 0.07788149267435074,
      "learning_rate": 2.0927821994693972e-05,
      "loss": 0.0502,
      "step": 87260
    },
    {
      "epoch": 1.7451905771307443,
      "grad_norm": 0.17421893775463104,
      "learning_rate": 2.0924489061312645e-05,
      "loss": 0.0433,
      "step": 87270
    },
    {
      "epoch": 1.745390553133624,
      "grad_norm": 0.046172820031642914,
      "learning_rate": 2.0921156127931315e-05,
      "loss": 0.0388,
      "step": 87280
    },
    {
      "epoch": 1.7455905291365035,
      "grad_norm": 0.08879046887159348,
      "learning_rate": 2.0917823194549988e-05,
      "loss": 0.0569,
      "step": 87290
    },
    {
      "epoch": 1.7457905051393832,
      "grad_norm": 0.26088404655456543,
      "learning_rate": 2.091449026116866e-05,
      "loss": 0.1558,
      "step": 87300
    },
    {
      "epoch": 1.7459904811422629,
      "grad_norm": 0.0732545405626297,
      "learning_rate": 2.0911157327787334e-05,
      "loss": 0.0595,
      "step": 87310
    },
    {
      "epoch": 1.7461904571451425,
      "grad_norm": 0.12161104381084442,
      "learning_rate": 2.0907824394406007e-05,
      "loss": 0.0568,
      "step": 87320
    },
    {
      "epoch": 1.7463904331480222,
      "grad_norm": 0.1097903773188591,
      "learning_rate": 2.0904491461024676e-05,
      "loss": 0.0884,
      "step": 87330
    },
    {
      "epoch": 1.746590409150902,
      "grad_norm": 0.10518977791070938,
      "learning_rate": 2.090115852764335e-05,
      "loss": 0.0574,
      "step": 87340
    },
    {
      "epoch": 1.7467903851537816,
      "grad_norm": 0.10973884910345078,
      "learning_rate": 2.0897825594262022e-05,
      "loss": 0.042,
      "step": 87350
    },
    {
      "epoch": 1.7469903611566613,
      "grad_norm": 0.12748238444328308,
      "learning_rate": 2.0894492660880695e-05,
      "loss": 0.0977,
      "step": 87360
    },
    {
      "epoch": 1.747190337159541,
      "grad_norm": 0.11492808908224106,
      "learning_rate": 2.089115972749937e-05,
      "loss": 0.0818,
      "step": 87370
    },
    {
      "epoch": 1.7473903131624207,
      "grad_norm": 0.13936534523963928,
      "learning_rate": 2.088782679411804e-05,
      "loss": 0.0667,
      "step": 87380
    },
    {
      "epoch": 1.7475902891653001,
      "grad_norm": 0.11182946711778641,
      "learning_rate": 2.088449386073671e-05,
      "loss": 0.0346,
      "step": 87390
    },
    {
      "epoch": 1.7477902651681798,
      "grad_norm": 0.0909510999917984,
      "learning_rate": 2.0881160927355384e-05,
      "loss": 0.0686,
      "step": 87400
    },
    {
      "epoch": 1.7479902411710595,
      "grad_norm": 0.19484031200408936,
      "learning_rate": 2.0877827993974057e-05,
      "loss": 0.0782,
      "step": 87410
    },
    {
      "epoch": 1.748190217173939,
      "grad_norm": 0.1214122325181961,
      "learning_rate": 2.087449506059273e-05,
      "loss": 0.0736,
      "step": 87420
    },
    {
      "epoch": 1.7483901931768187,
      "grad_norm": 0.05721033364534378,
      "learning_rate": 2.0871162127211403e-05,
      "loss": 0.0555,
      "step": 87430
    },
    {
      "epoch": 1.7485901691796983,
      "grad_norm": 0.21772438287734985,
      "learning_rate": 2.0867829193830073e-05,
      "loss": 0.0699,
      "step": 87440
    },
    {
      "epoch": 1.748790145182578,
      "grad_norm": 0.11614463478326797,
      "learning_rate": 2.0864496260448746e-05,
      "loss": 0.089,
      "step": 87450
    },
    {
      "epoch": 1.7489901211854577,
      "grad_norm": 0.0966806635260582,
      "learning_rate": 2.0861163327067422e-05,
      "loss": 0.0841,
      "step": 87460
    },
    {
      "epoch": 1.7491900971883374,
      "grad_norm": 0.19342158734798431,
      "learning_rate": 2.085783039368609e-05,
      "loss": 0.09,
      "step": 87470
    },
    {
      "epoch": 1.749390073191217,
      "grad_norm": 0.1507962942123413,
      "learning_rate": 2.0854497460304765e-05,
      "loss": 0.0595,
      "step": 87480
    },
    {
      "epoch": 1.7495900491940968,
      "grad_norm": 0.12284374237060547,
      "learning_rate": 2.0851164526923438e-05,
      "loss": 0.0741,
      "step": 87490
    },
    {
      "epoch": 1.7497900251969765,
      "grad_norm": 0.14643357694149017,
      "learning_rate": 2.0847831593542107e-05,
      "loss": 0.0666,
      "step": 87500
    },
    {
      "epoch": 1.7499900011998561,
      "grad_norm": 0.11092554777860641,
      "learning_rate": 2.0844498660160784e-05,
      "loss": 0.0646,
      "step": 87510
    },
    {
      "epoch": 1.7501899772027358,
      "grad_norm": 0.10941918194293976,
      "learning_rate": 2.0841165726779453e-05,
      "loss": 0.0693,
      "step": 87520
    },
    {
      "epoch": 1.7503899532056153,
      "grad_norm": 0.18042047321796417,
      "learning_rate": 2.0837832793398126e-05,
      "loss": 0.0748,
      "step": 87530
    },
    {
      "epoch": 1.750589929208495,
      "grad_norm": 0.11985484510660172,
      "learning_rate": 2.08344998600168e-05,
      "loss": 0.0686,
      "step": 87540
    },
    {
      "epoch": 1.7507899052113747,
      "grad_norm": 0.12470118701457977,
      "learning_rate": 2.083116692663547e-05,
      "loss": 0.0772,
      "step": 87550
    },
    {
      "epoch": 1.7509898812142541,
      "grad_norm": 0.22791790962219238,
      "learning_rate": 2.0827833993254145e-05,
      "loss": 0.0645,
      "step": 87560
    },
    {
      "epoch": 1.7511898572171338,
      "grad_norm": 0.08868181705474854,
      "learning_rate": 2.0824501059872818e-05,
      "loss": 0.0729,
      "step": 87570
    },
    {
      "epoch": 1.7513898332200135,
      "grad_norm": 0.30621448159217834,
      "learning_rate": 2.0821168126491488e-05,
      "loss": 0.3394,
      "step": 87580
    },
    {
      "epoch": 1.7515898092228932,
      "grad_norm": 0.08101281523704529,
      "learning_rate": 2.081783519311016e-05,
      "loss": 0.0945,
      "step": 87590
    },
    {
      "epoch": 1.7517897852257729,
      "grad_norm": 0.2019285410642624,
      "learning_rate": 2.0814502259728834e-05,
      "loss": 0.0467,
      "step": 87600
    },
    {
      "epoch": 1.7519897612286526,
      "grad_norm": 0.20419898629188538,
      "learning_rate": 2.0811169326347507e-05,
      "loss": 0.0893,
      "step": 87610
    },
    {
      "epoch": 1.7521897372315323,
      "grad_norm": 0.17135843634605408,
      "learning_rate": 2.080783639296618e-05,
      "loss": 0.0675,
      "step": 87620
    },
    {
      "epoch": 1.752389713234412,
      "grad_norm": 0.10745678842067719,
      "learning_rate": 2.080450345958485e-05,
      "loss": 0.0566,
      "step": 87630
    },
    {
      "epoch": 1.7525896892372916,
      "grad_norm": 0.19335882365703583,
      "learning_rate": 2.0801170526203523e-05,
      "loss": 0.1047,
      "step": 87640
    },
    {
      "epoch": 1.7527896652401713,
      "grad_norm": 0.06386307626962662,
      "learning_rate": 2.0797837592822196e-05,
      "loss": 0.0455,
      "step": 87650
    },
    {
      "epoch": 1.7529896412430508,
      "grad_norm": 0.26195570826530457,
      "learning_rate": 2.079450465944087e-05,
      "loss": 0.0849,
      "step": 87660
    },
    {
      "epoch": 1.7531896172459305,
      "grad_norm": 0.17267152667045593,
      "learning_rate": 2.079117172605954e-05,
      "loss": 0.0642,
      "step": 87670
    },
    {
      "epoch": 1.7533895932488102,
      "grad_norm": 0.13750864565372467,
      "learning_rate": 2.0787838792678215e-05,
      "loss": 0.0597,
      "step": 87680
    },
    {
      "epoch": 1.7535895692516899,
      "grad_norm": 0.09480267018079758,
      "learning_rate": 2.078483915263502e-05,
      "loss": 0.0798,
      "step": 87690
    },
    {
      "epoch": 1.7537895452545693,
      "grad_norm": 0.05551990121603012,
      "learning_rate": 2.078150621925369e-05,
      "loss": 0.0755,
      "step": 87700
    },
    {
      "epoch": 1.753989521257449,
      "grad_norm": 0.11387594789266586,
      "learning_rate": 2.0778173285872363e-05,
      "loss": 0.0811,
      "step": 87710
    },
    {
      "epoch": 1.7541894972603287,
      "grad_norm": 0.20010901987552643,
      "learning_rate": 2.0774840352491036e-05,
      "loss": 0.0625,
      "step": 87720
    },
    {
      "epoch": 1.7543894732632084,
      "grad_norm": 0.18082284927368164,
      "learning_rate": 2.077150741910971e-05,
      "loss": 0.2194,
      "step": 87730
    },
    {
      "epoch": 1.754589449266088,
      "grad_norm": 0.08645769208669662,
      "learning_rate": 2.076817448572838e-05,
      "loss": 0.1408,
      "step": 87740
    },
    {
      "epoch": 1.7547894252689678,
      "grad_norm": 0.10910006612539291,
      "learning_rate": 2.0764841552347055e-05,
      "loss": 0.1002,
      "step": 87750
    },
    {
      "epoch": 1.7549894012718474,
      "grad_norm": 0.10164282470941544,
      "learning_rate": 2.0761508618965724e-05,
      "loss": 0.1079,
      "step": 87760
    },
    {
      "epoch": 1.7551893772747271,
      "grad_norm": 0.1461322009563446,
      "learning_rate": 2.0758175685584397e-05,
      "loss": 0.0812,
      "step": 87770
    },
    {
      "epoch": 1.7553893532776068,
      "grad_norm": 0.2228047102689743,
      "learning_rate": 2.075484275220307e-05,
      "loss": 0.2855,
      "step": 87780
    },
    {
      "epoch": 1.7555893292804865,
      "grad_norm": 0.09476599097251892,
      "learning_rate": 2.0751509818821743e-05,
      "loss": 0.532,
      "step": 87790
    },
    {
      "epoch": 1.755789305283366,
      "grad_norm": 0.07763116806745529,
      "learning_rate": 2.0748176885440416e-05,
      "loss": 0.0613,
      "step": 87800
    },
    {
      "epoch": 1.7559892812862457,
      "grad_norm": 0.07069415599107742,
      "learning_rate": 2.0744843952059086e-05,
      "loss": 0.0547,
      "step": 87810
    },
    {
      "epoch": 1.7561892572891253,
      "grad_norm": 0.1751624196767807,
      "learning_rate": 2.074151101867776e-05,
      "loss": 0.0812,
      "step": 87820
    },
    {
      "epoch": 1.7563892332920048,
      "grad_norm": 0.07719496637582779,
      "learning_rate": 2.0738178085296432e-05,
      "loss": 0.0672,
      "step": 87830
    },
    {
      "epoch": 1.7565892092948845,
      "grad_norm": 0.21227072179317474,
      "learning_rate": 2.0734845151915105e-05,
      "loss": 0.1013,
      "step": 87840
    },
    {
      "epoch": 1.7567891852977642,
      "grad_norm": 0.20555585622787476,
      "learning_rate": 2.0731512218533778e-05,
      "loss": 0.0919,
      "step": 87850
    },
    {
      "epoch": 1.7569891613006439,
      "grad_norm": 0.050223931670188904,
      "learning_rate": 2.072817928515245e-05,
      "loss": 0.068,
      "step": 87860
    },
    {
      "epoch": 1.7571891373035236,
      "grad_norm": 0.15016798675060272,
      "learning_rate": 2.072484635177112e-05,
      "loss": 0.0601,
      "step": 87870
    },
    {
      "epoch": 1.7573891133064032,
      "grad_norm": 0.1573948711156845,
      "learning_rate": 2.0721513418389793e-05,
      "loss": 0.0565,
      "step": 87880
    },
    {
      "epoch": 1.757589089309283,
      "grad_norm": 0.15532976388931274,
      "learning_rate": 2.0718180485008466e-05,
      "loss": 0.0924,
      "step": 87890
    },
    {
      "epoch": 1.7577890653121626,
      "grad_norm": 0.18768349289894104,
      "learning_rate": 2.071484755162714e-05,
      "loss": 0.0678,
      "step": 87900
    },
    {
      "epoch": 1.7579890413150423,
      "grad_norm": 0.11937256902456284,
      "learning_rate": 2.0711514618245812e-05,
      "loss": 0.0552,
      "step": 87910
    },
    {
      "epoch": 1.758189017317922,
      "grad_norm": 0.20532895624637604,
      "learning_rate": 2.0708181684864482e-05,
      "loss": 0.0757,
      "step": 87920
    },
    {
      "epoch": 1.7583889933208015,
      "grad_norm": 0.16694895923137665,
      "learning_rate": 2.0704848751483155e-05,
      "loss": 0.075,
      "step": 87930
    },
    {
      "epoch": 1.7585889693236811,
      "grad_norm": 0.09898053854703903,
      "learning_rate": 2.070151581810183e-05,
      "loss": 0.0939,
      "step": 87940
    },
    {
      "epoch": 1.7587889453265608,
      "grad_norm": 0.11837992072105408,
      "learning_rate": 2.06981828847205e-05,
      "loss": 0.0687,
      "step": 87950
    },
    {
      "epoch": 1.7589889213294405,
      "grad_norm": 0.08741000294685364,
      "learning_rate": 2.0694849951339174e-05,
      "loss": 0.0658,
      "step": 87960
    },
    {
      "epoch": 1.75918889733232,
      "grad_norm": 0.12830370664596558,
      "learning_rate": 2.0691517017957847e-05,
      "loss": 0.0634,
      "step": 87970
    },
    {
      "epoch": 1.7593888733351997,
      "grad_norm": 0.2024555206298828,
      "learning_rate": 2.0688184084576517e-05,
      "loss": 0.0507,
      "step": 87980
    },
    {
      "epoch": 1.7595888493380794,
      "grad_norm": 0.20205199718475342,
      "learning_rate": 2.0684851151195193e-05,
      "loss": 0.0805,
      "step": 87990
    },
    {
      "epoch": 1.759788825340959,
      "grad_norm": 0.16163724660873413,
      "learning_rate": 2.0681518217813863e-05,
      "loss": 0.0678,
      "step": 88000
    },
    {
      "epoch": 1.7599888013438387,
      "grad_norm": 0.09008695185184479,
      "learning_rate": 2.0678185284432536e-05,
      "loss": 0.0489,
      "step": 88010
    },
    {
      "epoch": 1.7601887773467184,
      "grad_norm": 0.17646285891532898,
      "learning_rate": 2.067485235105121e-05,
      "loss": 0.0783,
      "step": 88020
    },
    {
      "epoch": 1.760388753349598,
      "grad_norm": 0.08532039821147919,
      "learning_rate": 2.067151941766988e-05,
      "loss": 0.0882,
      "step": 88030
    },
    {
      "epoch": 1.7605887293524778,
      "grad_norm": 0.18076585233211517,
      "learning_rate": 2.0668186484288555e-05,
      "loss": 0.0826,
      "step": 88040
    },
    {
      "epoch": 1.7607887053553575,
      "grad_norm": 0.13615575432777405,
      "learning_rate": 2.0664853550907228e-05,
      "loss": 0.0505,
      "step": 88050
    },
    {
      "epoch": 1.7609886813582372,
      "grad_norm": 0.24840648472309113,
      "learning_rate": 2.0661520617525897e-05,
      "loss": 0.0937,
      "step": 88060
    },
    {
      "epoch": 1.7611886573611166,
      "grad_norm": 0.20335055887699127,
      "learning_rate": 2.065818768414457e-05,
      "loss": 0.0746,
      "step": 88070
    },
    {
      "epoch": 1.7613886333639963,
      "grad_norm": 0.19954445958137512,
      "learning_rate": 2.0654854750763243e-05,
      "loss": 0.0899,
      "step": 88080
    },
    {
      "epoch": 1.761588609366876,
      "grad_norm": 0.15305283665657043,
      "learning_rate": 2.0651521817381916e-05,
      "loss": 0.1035,
      "step": 88090
    },
    {
      "epoch": 1.7617885853697555,
      "grad_norm": 0.19324451684951782,
      "learning_rate": 2.064818888400059e-05,
      "loss": 0.0719,
      "step": 88100
    },
    {
      "epoch": 1.7619885613726352,
      "grad_norm": 0.0756939947605133,
      "learning_rate": 2.064485595061926e-05,
      "loss": 0.0589,
      "step": 88110
    },
    {
      "epoch": 1.7621885373755148,
      "grad_norm": 0.25315576791763306,
      "learning_rate": 2.0641523017237932e-05,
      "loss": 0.1091,
      "step": 88120
    },
    {
      "epoch": 1.7623885133783945,
      "grad_norm": 0.05586610361933708,
      "learning_rate": 2.0638190083856605e-05,
      "loss": 0.0556,
      "step": 88130
    },
    {
      "epoch": 1.7625884893812742,
      "grad_norm": 0.16671235859394073,
      "learning_rate": 2.0634857150475278e-05,
      "loss": 0.0605,
      "step": 88140
    },
    {
      "epoch": 1.762788465384154,
      "grad_norm": 0.1670871376991272,
      "learning_rate": 2.063152421709395e-05,
      "loss": 0.0627,
      "step": 88150
    },
    {
      "epoch": 1.7629884413870336,
      "grad_norm": 0.11966196447610855,
      "learning_rate": 2.0628191283712624e-05,
      "loss": 0.0741,
      "step": 88160
    },
    {
      "epoch": 1.7631884173899133,
      "grad_norm": 0.16738121211528778,
      "learning_rate": 2.0624858350331294e-05,
      "loss": 0.0889,
      "step": 88170
    },
    {
      "epoch": 1.763388393392793,
      "grad_norm": 0.08961383998394012,
      "learning_rate": 2.0621525416949967e-05,
      "loss": 0.0786,
      "step": 88180
    },
    {
      "epoch": 1.7635883693956727,
      "grad_norm": 0.16816754639148712,
      "learning_rate": 2.061819248356864e-05,
      "loss": 0.177,
      "step": 88190
    },
    {
      "epoch": 1.7637883453985523,
      "grad_norm": 0.16958217322826385,
      "learning_rate": 2.0614859550187313e-05,
      "loss": 0.0667,
      "step": 88200
    },
    {
      "epoch": 1.7639883214014318,
      "grad_norm": 0.0921577736735344,
      "learning_rate": 2.0611526616805986e-05,
      "loss": 0.0623,
      "step": 88210
    },
    {
      "epoch": 1.7641882974043115,
      "grad_norm": 0.0576334148645401,
      "learning_rate": 2.0608193683424655e-05,
      "loss": 0.0651,
      "step": 88220
    },
    {
      "epoch": 1.7643882734071912,
      "grad_norm": 0.128149151802063,
      "learning_rate": 2.0604860750043328e-05,
      "loss": 0.1076,
      "step": 88230
    },
    {
      "epoch": 1.7645882494100706,
      "grad_norm": 0.1761690229177475,
      "learning_rate": 2.0601527816662e-05,
      "loss": 0.0725,
      "step": 88240
    },
    {
      "epoch": 1.7647882254129503,
      "grad_norm": 0.07659381628036499,
      "learning_rate": 2.0598194883280674e-05,
      "loss": 0.0678,
      "step": 88250
    },
    {
      "epoch": 1.76498820141583,
      "grad_norm": 0.2286294400691986,
      "learning_rate": 2.0594861949899347e-05,
      "loss": 0.0846,
      "step": 88260
    },
    {
      "epoch": 1.7651881774187097,
      "grad_norm": 0.22609899938106537,
      "learning_rate": 2.0591529016518017e-05,
      "loss": 0.0691,
      "step": 88270
    },
    {
      "epoch": 1.7653881534215894,
      "grad_norm": 0.06711792945861816,
      "learning_rate": 2.058819608313669e-05,
      "loss": 0.0709,
      "step": 88280
    },
    {
      "epoch": 1.765588129424469,
      "grad_norm": 0.137467622756958,
      "learning_rate": 2.0584863149755363e-05,
      "loss": 0.0584,
      "step": 88290
    },
    {
      "epoch": 1.7657881054273488,
      "grad_norm": 0.19304972887039185,
      "learning_rate": 2.0581530216374036e-05,
      "loss": 0.049,
      "step": 88300
    },
    {
      "epoch": 1.7659880814302285,
      "grad_norm": 0.11163409054279327,
      "learning_rate": 2.057819728299271e-05,
      "loss": 0.0532,
      "step": 88310
    },
    {
      "epoch": 1.7661880574331081,
      "grad_norm": 0.1999329775571823,
      "learning_rate": 2.0574864349611382e-05,
      "loss": 0.0561,
      "step": 88320
    },
    {
      "epoch": 1.7663880334359878,
      "grad_norm": 0.21046853065490723,
      "learning_rate": 2.057153141623005e-05,
      "loss": 0.1171,
      "step": 88330
    },
    {
      "epoch": 1.7665880094388673,
      "grad_norm": 0.10817895084619522,
      "learning_rate": 2.0568198482848725e-05,
      "loss": 0.0639,
      "step": 88340
    },
    {
      "epoch": 1.766787985441747,
      "grad_norm": 0.09014112502336502,
      "learning_rate": 2.0564865549467398e-05,
      "loss": 0.048,
      "step": 88350
    },
    {
      "epoch": 1.7669879614446267,
      "grad_norm": 0.11977355927228928,
      "learning_rate": 2.056153261608607e-05,
      "loss": 0.0516,
      "step": 88360
    },
    {
      "epoch": 1.7671879374475064,
      "grad_norm": 0.22941270470619202,
      "learning_rate": 2.0558199682704744e-05,
      "loss": 0.149,
      "step": 88370
    },
    {
      "epoch": 1.7673879134503858,
      "grad_norm": 0.184040829539299,
      "learning_rate": 2.0554866749323413e-05,
      "loss": 0.0719,
      "step": 88380
    },
    {
      "epoch": 1.7675878894532655,
      "grad_norm": 0.06973455101251602,
      "learning_rate": 2.0551533815942086e-05,
      "loss": 0.0642,
      "step": 88390
    },
    {
      "epoch": 1.7677878654561452,
      "grad_norm": 0.1181001365184784,
      "learning_rate": 2.0548200882560763e-05,
      "loss": 0.1033,
      "step": 88400
    },
    {
      "epoch": 1.7679878414590249,
      "grad_norm": 0.139730766415596,
      "learning_rate": 2.0544867949179432e-05,
      "loss": 0.0868,
      "step": 88410
    },
    {
      "epoch": 1.7681878174619046,
      "grad_norm": 0.12432432174682617,
      "learning_rate": 2.0541535015798105e-05,
      "loss": 0.0535,
      "step": 88420
    },
    {
      "epoch": 1.7683877934647843,
      "grad_norm": 0.26408621668815613,
      "learning_rate": 2.0538202082416778e-05,
      "loss": 0.0992,
      "step": 88430
    },
    {
      "epoch": 1.768587769467664,
      "grad_norm": 0.06781087815761566,
      "learning_rate": 2.0534869149035448e-05,
      "loss": 0.0907,
      "step": 88440
    },
    {
      "epoch": 1.7687877454705436,
      "grad_norm": 0.18116527795791626,
      "learning_rate": 2.0531536215654124e-05,
      "loss": 0.0449,
      "step": 88450
    },
    {
      "epoch": 1.7689877214734233,
      "grad_norm": 0.09444000571966171,
      "learning_rate": 2.0528203282272794e-05,
      "loss": 0.0561,
      "step": 88460
    },
    {
      "epoch": 1.769187697476303,
      "grad_norm": 0.11986727267503738,
      "learning_rate": 2.0524870348891467e-05,
      "loss": 0.0726,
      "step": 88470
    },
    {
      "epoch": 1.7693876734791825,
      "grad_norm": 0.15910956263542175,
      "learning_rate": 2.052153741551014e-05,
      "loss": 0.0614,
      "step": 88480
    },
    {
      "epoch": 1.7695876494820622,
      "grad_norm": 0.13198961317539215,
      "learning_rate": 2.051820448212881e-05,
      "loss": 0.0695,
      "step": 88490
    },
    {
      "epoch": 1.7697876254849418,
      "grad_norm": 0.07428119331598282,
      "learning_rate": 2.0514871548747486e-05,
      "loss": 0.0666,
      "step": 88500
    },
    {
      "epoch": 1.7699876014878213,
      "grad_norm": 0.21998634934425354,
      "learning_rate": 2.051153861536616e-05,
      "loss": 0.0958,
      "step": 88510
    },
    {
      "epoch": 1.770187577490701,
      "grad_norm": 0.21417130529880524,
      "learning_rate": 2.050820568198483e-05,
      "loss": 0.0738,
      "step": 88520
    },
    {
      "epoch": 1.7703875534935807,
      "grad_norm": 0.05917341634631157,
      "learning_rate": 2.05048727486035e-05,
      "loss": 0.1033,
      "step": 88530
    },
    {
      "epoch": 1.7705875294964604,
      "grad_norm": 0.21786029636859894,
      "learning_rate": 2.0501539815222174e-05,
      "loss": 0.1018,
      "step": 88540
    },
    {
      "epoch": 1.77078750549934,
      "grad_norm": 0.08714602142572403,
      "learning_rate": 2.0498206881840847e-05,
      "loss": 0.0449,
      "step": 88550
    },
    {
      "epoch": 1.7709874815022197,
      "grad_norm": 0.10815057158470154,
      "learning_rate": 2.049487394845952e-05,
      "loss": 0.0569,
      "step": 88560
    },
    {
      "epoch": 1.7711874575050994,
      "grad_norm": 0.07951623946428299,
      "learning_rate": 2.049154101507819e-05,
      "loss": 0.0917,
      "step": 88570
    },
    {
      "epoch": 1.7713874335079791,
      "grad_norm": 0.14246688783168793,
      "learning_rate": 2.0488208081696863e-05,
      "loss": 0.1137,
      "step": 88580
    },
    {
      "epoch": 1.7715874095108588,
      "grad_norm": 0.17282137274742126,
      "learning_rate": 2.0484875148315536e-05,
      "loss": 0.0808,
      "step": 88590
    },
    {
      "epoch": 1.7717873855137385,
      "grad_norm": 0.07297737896442413,
      "learning_rate": 2.048154221493421e-05,
      "loss": 0.0762,
      "step": 88600
    },
    {
      "epoch": 1.771987361516618,
      "grad_norm": 0.26984792947769165,
      "learning_rate": 2.0478209281552882e-05,
      "loss": 0.1027,
      "step": 88610
    },
    {
      "epoch": 1.7721873375194976,
      "grad_norm": 0.17829786241054535,
      "learning_rate": 2.0474876348171555e-05,
      "loss": 0.072,
      "step": 88620
    },
    {
      "epoch": 1.7723873135223773,
      "grad_norm": 0.2542097270488739,
      "learning_rate": 2.0471543414790225e-05,
      "loss": 0.0809,
      "step": 88630
    },
    {
      "epoch": 1.772587289525257,
      "grad_norm": 0.12874402105808258,
      "learning_rate": 2.0468210481408898e-05,
      "loss": 0.0876,
      "step": 88640
    },
    {
      "epoch": 1.7727872655281365,
      "grad_norm": 0.18437552452087402,
      "learning_rate": 2.046487754802757e-05,
      "loss": 0.1021,
      "step": 88650
    },
    {
      "epoch": 1.7729872415310162,
      "grad_norm": 0.07458045333623886,
      "learning_rate": 2.0461544614646244e-05,
      "loss": 0.0789,
      "step": 88660
    },
    {
      "epoch": 1.7731872175338959,
      "grad_norm": 0.08939913660287857,
      "learning_rate": 2.0458211681264917e-05,
      "loss": 0.0507,
      "step": 88670
    },
    {
      "epoch": 1.7733871935367755,
      "grad_norm": 0.06954063475131989,
      "learning_rate": 2.0454878747883586e-05,
      "loss": 0.057,
      "step": 88680
    },
    {
      "epoch": 1.7735871695396552,
      "grad_norm": 0.11678960919380188,
      "learning_rate": 2.045154581450226e-05,
      "loss": 0.0688,
      "step": 88690
    },
    {
      "epoch": 1.773787145542535,
      "grad_norm": 0.1284657120704651,
      "learning_rate": 2.0448212881120936e-05,
      "loss": 0.0747,
      "step": 88700
    },
    {
      "epoch": 1.7739871215454146,
      "grad_norm": 0.04296666756272316,
      "learning_rate": 2.0444879947739605e-05,
      "loss": 0.0592,
      "step": 88710
    },
    {
      "epoch": 1.7741870975482943,
      "grad_norm": 0.09380888193845749,
      "learning_rate": 2.044154701435828e-05,
      "loss": 0.0597,
      "step": 88720
    },
    {
      "epoch": 1.774387073551174,
      "grad_norm": 0.20184804499149323,
      "learning_rate": 2.043821408097695e-05,
      "loss": 0.1309,
      "step": 88730
    },
    {
      "epoch": 1.7745870495540537,
      "grad_norm": 0.07960954308509827,
      "learning_rate": 2.043488114759562e-05,
      "loss": 0.0707,
      "step": 88740
    },
    {
      "epoch": 1.7747870255569331,
      "grad_norm": 0.1891203671693802,
      "learning_rate": 2.0431548214214294e-05,
      "loss": 0.059,
      "step": 88750
    },
    {
      "epoch": 1.7749870015598128,
      "grad_norm": 0.12155035883188248,
      "learning_rate": 2.0428215280832967e-05,
      "loss": 0.1006,
      "step": 88760
    },
    {
      "epoch": 1.7751869775626925,
      "grad_norm": 0.11038386821746826,
      "learning_rate": 2.042488234745164e-05,
      "loss": 0.0724,
      "step": 88770
    },
    {
      "epoch": 1.775386953565572,
      "grad_norm": 0.09931544214487076,
      "learning_rate": 2.0421549414070313e-05,
      "loss": 0.0597,
      "step": 88780
    },
    {
      "epoch": 1.7755869295684517,
      "grad_norm": 0.17049846053123474,
      "learning_rate": 2.0418216480688983e-05,
      "loss": 0.0868,
      "step": 88790
    },
    {
      "epoch": 1.7757869055713313,
      "grad_norm": 0.13271436095237732,
      "learning_rate": 2.0414883547307656e-05,
      "loss": 0.0835,
      "step": 88800
    },
    {
      "epoch": 1.775986881574211,
      "grad_norm": 0.10948456078767776,
      "learning_rate": 2.0411550613926332e-05,
      "loss": 0.0883,
      "step": 88810
    },
    {
      "epoch": 1.7761868575770907,
      "grad_norm": 0.22936959564685822,
      "learning_rate": 2.0408217680545e-05,
      "loss": 0.11,
      "step": 88820
    },
    {
      "epoch": 1.7763868335799704,
      "grad_norm": 0.1760757565498352,
      "learning_rate": 2.0404884747163675e-05,
      "loss": 0.0842,
      "step": 88830
    },
    {
      "epoch": 1.77658680958285,
      "grad_norm": 0.1407742202281952,
      "learning_rate": 2.0401551813782348e-05,
      "loss": 0.0751,
      "step": 88840
    },
    {
      "epoch": 1.7767867855857298,
      "grad_norm": 0.14308761060237885,
      "learning_rate": 2.0398218880401017e-05,
      "loss": 0.0465,
      "step": 88850
    },
    {
      "epoch": 1.7769867615886095,
      "grad_norm": 0.1635046750307083,
      "learning_rate": 2.0394885947019694e-05,
      "loss": 0.062,
      "step": 88860
    },
    {
      "epoch": 1.7771867375914892,
      "grad_norm": 0.18935196101665497,
      "learning_rate": 2.0391553013638363e-05,
      "loss": 0.0861,
      "step": 88870
    },
    {
      "epoch": 1.7773867135943688,
      "grad_norm": 0.053724952042102814,
      "learning_rate": 2.0388220080257036e-05,
      "loss": 0.0514,
      "step": 88880
    },
    {
      "epoch": 1.7775866895972483,
      "grad_norm": 0.06978853046894073,
      "learning_rate": 2.038488714687571e-05,
      "loss": 0.0721,
      "step": 88890
    },
    {
      "epoch": 1.777786665600128,
      "grad_norm": 0.10664262622594833,
      "learning_rate": 2.038155421349438e-05,
      "loss": 0.0744,
      "step": 88900
    },
    {
      "epoch": 1.7779866416030077,
      "grad_norm": 0.1317298263311386,
      "learning_rate": 2.0378221280113055e-05,
      "loss": 0.0859,
      "step": 88910
    },
    {
      "epoch": 1.7781866176058871,
      "grad_norm": 0.19488216936588287,
      "learning_rate": 2.0374888346731728e-05,
      "loss": 0.1251,
      "step": 88920
    },
    {
      "epoch": 1.7783865936087668,
      "grad_norm": 0.2342529296875,
      "learning_rate": 2.0371555413350398e-05,
      "loss": 0.0842,
      "step": 88930
    },
    {
      "epoch": 1.7785865696116465,
      "grad_norm": 0.20773442089557648,
      "learning_rate": 2.036822247996907e-05,
      "loss": 0.0943,
      "step": 88940
    },
    {
      "epoch": 1.7787865456145262,
      "grad_norm": 0.11455419659614563,
      "learning_rate": 2.0364889546587744e-05,
      "loss": 0.0465,
      "step": 88950
    },
    {
      "epoch": 1.778986521617406,
      "grad_norm": 0.14464454352855682,
      "learning_rate": 2.0361556613206417e-05,
      "loss": 0.0803,
      "step": 88960
    },
    {
      "epoch": 1.7791864976202856,
      "grad_norm": 0.14057885110378265,
      "learning_rate": 2.035822367982509e-05,
      "loss": 0.0677,
      "step": 88970
    },
    {
      "epoch": 1.7793864736231653,
      "grad_norm": 0.1860368251800537,
      "learning_rate": 2.035489074644376e-05,
      "loss": 0.0815,
      "step": 88980
    },
    {
      "epoch": 1.779586449626045,
      "grad_norm": 0.18144263327121735,
      "learning_rate": 2.0351557813062433e-05,
      "loss": 0.0823,
      "step": 88990
    },
    {
      "epoch": 1.7797864256289246,
      "grad_norm": 0.20275138318538666,
      "learning_rate": 2.0348224879681106e-05,
      "loss": 0.0753,
      "step": 89000
    },
    {
      "epoch": 1.7799864016318043,
      "grad_norm": 0.18214692175388336,
      "learning_rate": 2.034489194629978e-05,
      "loss": 0.0665,
      "step": 89010
    },
    {
      "epoch": 1.7801863776346838,
      "grad_norm": 0.06874988228082657,
      "learning_rate": 2.034155901291845e-05,
      "loss": 0.0607,
      "step": 89020
    },
    {
      "epoch": 1.7803863536375635,
      "grad_norm": 0.1748470813035965,
      "learning_rate": 2.0338226079537125e-05,
      "loss": 0.0752,
      "step": 89030
    },
    {
      "epoch": 1.7805863296404432,
      "grad_norm": 0.06391879916191101,
      "learning_rate": 2.0334893146155794e-05,
      "loss": 0.0473,
      "step": 89040
    },
    {
      "epoch": 1.7807863056433229,
      "grad_norm": 0.19596077501773834,
      "learning_rate": 2.0331560212774467e-05,
      "loss": 0.0765,
      "step": 89050
    },
    {
      "epoch": 1.7809862816462023,
      "grad_norm": 0.10403274744749069,
      "learning_rate": 2.032822727939314e-05,
      "loss": 0.0457,
      "step": 89060
    },
    {
      "epoch": 1.781186257649082,
      "grad_norm": 0.09763891249895096,
      "learning_rate": 2.0324894346011813e-05,
      "loss": 0.0637,
      "step": 89070
    },
    {
      "epoch": 1.7813862336519617,
      "grad_norm": 0.1119070053100586,
      "learning_rate": 2.0321561412630486e-05,
      "loss": 0.1215,
      "step": 89080
    },
    {
      "epoch": 1.7815862096548414,
      "grad_norm": 0.15541979670524597,
      "learning_rate": 2.0318228479249156e-05,
      "loss": 0.0996,
      "step": 89090
    },
    {
      "epoch": 1.781786185657721,
      "grad_norm": 0.16882582008838654,
      "learning_rate": 2.031489554586783e-05,
      "loss": 0.0559,
      "step": 89100
    },
    {
      "epoch": 1.7819861616606008,
      "grad_norm": 0.073616623878479,
      "learning_rate": 2.0311562612486505e-05,
      "loss": 0.0537,
      "step": 89110
    },
    {
      "epoch": 1.7821861376634804,
      "grad_norm": 0.21418575942516327,
      "learning_rate": 2.0308229679105175e-05,
      "loss": 0.0895,
      "step": 89120
    },
    {
      "epoch": 1.7823861136663601,
      "grad_norm": 0.2119036763906479,
      "learning_rate": 2.0304896745723848e-05,
      "loss": 0.1022,
      "step": 89130
    },
    {
      "epoch": 1.7825860896692398,
      "grad_norm": 0.16713662445545197,
      "learning_rate": 2.030156381234252e-05,
      "loss": 0.0648,
      "step": 89140
    },
    {
      "epoch": 1.7827860656721195,
      "grad_norm": 0.1095026507973671,
      "learning_rate": 2.029823087896119e-05,
      "loss": 0.0453,
      "step": 89150
    },
    {
      "epoch": 1.782986041674999,
      "grad_norm": 0.10445381700992584,
      "learning_rate": 2.0294897945579867e-05,
      "loss": 0.0583,
      "step": 89160
    },
    {
      "epoch": 1.7831860176778787,
      "grad_norm": 0.11653593927621841,
      "learning_rate": 2.0291565012198536e-05,
      "loss": 0.084,
      "step": 89170
    },
    {
      "epoch": 1.7833859936807583,
      "grad_norm": 0.14545854926109314,
      "learning_rate": 2.028823207881721e-05,
      "loss": 0.0809,
      "step": 89180
    },
    {
      "epoch": 1.7835859696836378,
      "grad_norm": 0.059846583753824234,
      "learning_rate": 2.0284899145435882e-05,
      "loss": 0.0829,
      "step": 89190
    },
    {
      "epoch": 1.7837859456865175,
      "grad_norm": 0.1138804703950882,
      "learning_rate": 2.0281566212054552e-05,
      "loss": 0.0703,
      "step": 89200
    },
    {
      "epoch": 1.7839859216893972,
      "grad_norm": 0.07989535480737686,
      "learning_rate": 2.027823327867323e-05,
      "loss": 0.1013,
      "step": 89210
    },
    {
      "epoch": 1.7841858976922769,
      "grad_norm": 0.15479980409145355,
      "learning_rate": 2.02749003452919e-05,
      "loss": 0.0777,
      "step": 89220
    },
    {
      "epoch": 1.7843858736951566,
      "grad_norm": 0.17361702024936676,
      "learning_rate": 2.027156741191057e-05,
      "loss": 0.1132,
      "step": 89230
    },
    {
      "epoch": 1.7845858496980362,
      "grad_norm": 0.058359693735837936,
      "learning_rate": 2.0268234478529244e-05,
      "loss": 0.0688,
      "step": 89240
    },
    {
      "epoch": 1.784785825700916,
      "grad_norm": 0.18997864425182343,
      "learning_rate": 2.0264901545147917e-05,
      "loss": 0.0679,
      "step": 89250
    },
    {
      "epoch": 1.7849858017037956,
      "grad_norm": 0.13940978050231934,
      "learning_rate": 2.0261568611766587e-05,
      "loss": 0.0937,
      "step": 89260
    },
    {
      "epoch": 1.7851857777066753,
      "grad_norm": 0.06978145241737366,
      "learning_rate": 2.0258235678385263e-05,
      "loss": 0.0752,
      "step": 89270
    },
    {
      "epoch": 1.785385753709555,
      "grad_norm": 0.12347853183746338,
      "learning_rate": 2.0254902745003933e-05,
      "loss": 0.0531,
      "step": 89280
    },
    {
      "epoch": 1.7855857297124345,
      "grad_norm": 0.17876644432544708,
      "learning_rate": 2.0251569811622606e-05,
      "loss": 0.0654,
      "step": 89290
    },
    {
      "epoch": 1.7857857057153141,
      "grad_norm": 0.18851348757743835,
      "learning_rate": 2.024823687824128e-05,
      "loss": 0.0636,
      "step": 89300
    },
    {
      "epoch": 1.7859856817181938,
      "grad_norm": 0.22385825216770172,
      "learning_rate": 2.024490394485995e-05,
      "loss": 0.1266,
      "step": 89310
    },
    {
      "epoch": 1.7861856577210735,
      "grad_norm": 0.15995816886425018,
      "learning_rate": 2.0241571011478625e-05,
      "loss": 0.0844,
      "step": 89320
    },
    {
      "epoch": 1.786385633723953,
      "grad_norm": 0.08447631448507309,
      "learning_rate": 2.0238238078097298e-05,
      "loss": 0.0794,
      "step": 89330
    },
    {
      "epoch": 1.7865856097268327,
      "grad_norm": 0.13026779890060425,
      "learning_rate": 2.0234905144715967e-05,
      "loss": 0.0522,
      "step": 89340
    },
    {
      "epoch": 1.7867855857297124,
      "grad_norm": 0.062332507222890854,
      "learning_rate": 2.023157221133464e-05,
      "loss": 0.0589,
      "step": 89350
    },
    {
      "epoch": 1.786985561732592,
      "grad_norm": 0.17732608318328857,
      "learning_rate": 2.0228239277953313e-05,
      "loss": 0.0825,
      "step": 89360
    },
    {
      "epoch": 1.7871855377354717,
      "grad_norm": 0.12257719784975052,
      "learning_rate": 2.0224906344571986e-05,
      "loss": 0.0944,
      "step": 89370
    },
    {
      "epoch": 1.7873855137383514,
      "grad_norm": 0.18190471827983856,
      "learning_rate": 2.022157341119066e-05,
      "loss": 0.0955,
      "step": 89380
    },
    {
      "epoch": 1.787585489741231,
      "grad_norm": 0.1852605640888214,
      "learning_rate": 2.021824047780933e-05,
      "loss": 0.0619,
      "step": 89390
    },
    {
      "epoch": 1.7877854657441108,
      "grad_norm": 0.06886793673038483,
      "learning_rate": 2.0214907544428002e-05,
      "loss": 0.0522,
      "step": 89400
    },
    {
      "epoch": 1.7879854417469905,
      "grad_norm": 0.16601288318634033,
      "learning_rate": 2.0211574611046675e-05,
      "loss": 0.0891,
      "step": 89410
    },
    {
      "epoch": 1.7881854177498702,
      "grad_norm": 0.12968765199184418,
      "learning_rate": 2.0208241677665348e-05,
      "loss": 0.0826,
      "step": 89420
    },
    {
      "epoch": 1.7883853937527496,
      "grad_norm": 0.19290855526924133,
      "learning_rate": 2.020490874428402e-05,
      "loss": 0.081,
      "step": 89430
    },
    {
      "epoch": 1.7885853697556293,
      "grad_norm": 0.11191496253013611,
      "learning_rate": 2.0201575810902694e-05,
      "loss": 0.0865,
      "step": 89440
    },
    {
      "epoch": 1.788785345758509,
      "grad_norm": 0.13538599014282227,
      "learning_rate": 2.0198242877521364e-05,
      "loss": 0.0594,
      "step": 89450
    },
    {
      "epoch": 1.7889853217613885,
      "grad_norm": 0.21709267795085907,
      "learning_rate": 2.0194909944140037e-05,
      "loss": 0.0844,
      "step": 89460
    },
    {
      "epoch": 1.7891852977642682,
      "grad_norm": 0.11846207082271576,
      "learning_rate": 2.019157701075871e-05,
      "loss": 0.0602,
      "step": 89470
    },
    {
      "epoch": 1.7893852737671478,
      "grad_norm": 0.10846234112977982,
      "learning_rate": 2.0188244077377383e-05,
      "loss": 0.0696,
      "step": 89480
    },
    {
      "epoch": 1.7895852497700275,
      "grad_norm": 0.05610327050089836,
      "learning_rate": 2.0184911143996056e-05,
      "loss": 0.0512,
      "step": 89490
    },
    {
      "epoch": 1.7897852257729072,
      "grad_norm": 0.10229384899139404,
      "learning_rate": 2.0181578210614725e-05,
      "loss": 0.4704,
      "step": 89500
    },
    {
      "epoch": 1.789985201775787,
      "grad_norm": 0.0878523513674736,
      "learning_rate": 2.0178245277233398e-05,
      "loss": 0.069,
      "step": 89510
    },
    {
      "epoch": 1.7901851777786666,
      "grad_norm": 0.12549953162670135,
      "learning_rate": 2.0174912343852075e-05,
      "loss": 0.0632,
      "step": 89520
    },
    {
      "epoch": 1.7903851537815463,
      "grad_norm": 0.1084490418434143,
      "learning_rate": 2.0171579410470744e-05,
      "loss": 0.0627,
      "step": 89530
    },
    {
      "epoch": 1.790585129784426,
      "grad_norm": 0.16111940145492554,
      "learning_rate": 2.0168246477089417e-05,
      "loss": 0.0747,
      "step": 89540
    },
    {
      "epoch": 1.7907851057873057,
      "grad_norm": 0.22332872450351715,
      "learning_rate": 2.016491354370809e-05,
      "loss": 0.0994,
      "step": 89550
    },
    {
      "epoch": 1.7909850817901853,
      "grad_norm": 0.08699145168066025,
      "learning_rate": 2.016158061032676e-05,
      "loss": 0.0449,
      "step": 89560
    },
    {
      "epoch": 1.7911850577930648,
      "grad_norm": 0.10743715614080429,
      "learning_rate": 2.0158247676945436e-05,
      "loss": 0.0569,
      "step": 89570
    },
    {
      "epoch": 1.7913850337959445,
      "grad_norm": 0.19602657854557037,
      "learning_rate": 2.0154914743564106e-05,
      "loss": 0.0624,
      "step": 89580
    },
    {
      "epoch": 1.7915850097988242,
      "grad_norm": 0.18072839081287384,
      "learning_rate": 2.015158181018278e-05,
      "loss": 0.0632,
      "step": 89590
    },
    {
      "epoch": 1.7917849858017036,
      "grad_norm": 0.16781805455684662,
      "learning_rate": 2.0148248876801452e-05,
      "loss": 0.1306,
      "step": 89600
    },
    {
      "epoch": 1.7919849618045833,
      "grad_norm": 0.061767131090164185,
      "learning_rate": 2.014491594342012e-05,
      "loss": 0.0632,
      "step": 89610
    },
    {
      "epoch": 1.792184937807463,
      "grad_norm": 0.1387697160243988,
      "learning_rate": 2.0141583010038798e-05,
      "loss": 0.0873,
      "step": 89620
    },
    {
      "epoch": 1.7923849138103427,
      "grad_norm": 0.07849548012018204,
      "learning_rate": 2.013825007665747e-05,
      "loss": 0.0894,
      "step": 89630
    },
    {
      "epoch": 1.7925848898132224,
      "grad_norm": 0.08646944165229797,
      "learning_rate": 2.013491714327614e-05,
      "loss": 0.0879,
      "step": 89640
    },
    {
      "epoch": 1.792784865816102,
      "grad_norm": 0.1700185239315033,
      "learning_rate": 2.0131584209894814e-05,
      "loss": 0.0639,
      "step": 89650
    },
    {
      "epoch": 1.7929848418189818,
      "grad_norm": 0.16123263537883759,
      "learning_rate": 2.0128251276513487e-05,
      "loss": 0.0745,
      "step": 89660
    },
    {
      "epoch": 1.7931848178218615,
      "grad_norm": 0.05148763954639435,
      "learning_rate": 2.012491834313216e-05,
      "loss": 0.049,
      "step": 89670
    },
    {
      "epoch": 1.7933847938247411,
      "grad_norm": 0.15718740224838257,
      "learning_rate": 2.0121585409750833e-05,
      "loss": 0.0534,
      "step": 89680
    },
    {
      "epoch": 1.7935847698276208,
      "grad_norm": 0.1702323853969574,
      "learning_rate": 2.0118252476369502e-05,
      "loss": 0.0944,
      "step": 89690
    },
    {
      "epoch": 1.7937847458305003,
      "grad_norm": 0.18764691054821014,
      "learning_rate": 2.0114919542988175e-05,
      "loss": 0.0903,
      "step": 89700
    },
    {
      "epoch": 1.79398472183338,
      "grad_norm": 0.1212053969502449,
      "learning_rate": 2.0111586609606848e-05,
      "loss": 0.093,
      "step": 89710
    },
    {
      "epoch": 1.7941846978362597,
      "grad_norm": 0.1008015125989914,
      "learning_rate": 2.010825367622552e-05,
      "loss": 0.0566,
      "step": 89720
    },
    {
      "epoch": 1.7943846738391394,
      "grad_norm": 0.08969346433877945,
      "learning_rate": 2.0104920742844194e-05,
      "loss": 0.0453,
      "step": 89730
    },
    {
      "epoch": 1.7945846498420188,
      "grad_norm": 0.15549764037132263,
      "learning_rate": 2.0101587809462867e-05,
      "loss": 0.0903,
      "step": 89740
    },
    {
      "epoch": 1.7947846258448985,
      "grad_norm": 0.06942925602197647,
      "learning_rate": 2.0098254876081537e-05,
      "loss": 0.067,
      "step": 89750
    },
    {
      "epoch": 1.7949846018477782,
      "grad_norm": 0.12483535706996918,
      "learning_rate": 2.009492194270021e-05,
      "loss": 0.0349,
      "step": 89760
    },
    {
      "epoch": 1.7951845778506579,
      "grad_norm": 0.15917178988456726,
      "learning_rate": 2.0091589009318883e-05,
      "loss": 0.0783,
      "step": 89770
    },
    {
      "epoch": 1.7953845538535376,
      "grad_norm": 0.18013477325439453,
      "learning_rate": 2.0088256075937556e-05,
      "loss": 0.0658,
      "step": 89780
    },
    {
      "epoch": 1.7955845298564173,
      "grad_norm": 0.14119824767112732,
      "learning_rate": 2.008492314255623e-05,
      "loss": 0.0513,
      "step": 89790
    },
    {
      "epoch": 1.795784505859297,
      "grad_norm": 0.1706562638282776,
      "learning_rate": 2.00815902091749e-05,
      "loss": 0.0892,
      "step": 89800
    },
    {
      "epoch": 1.7959844818621766,
      "grad_norm": 0.20371633768081665,
      "learning_rate": 2.007825727579357e-05,
      "loss": 0.0692,
      "step": 89810
    },
    {
      "epoch": 1.7961844578650563,
      "grad_norm": 0.08307977020740509,
      "learning_rate": 2.0074924342412244e-05,
      "loss": 0.0758,
      "step": 89820
    },
    {
      "epoch": 1.796384433867936,
      "grad_norm": 0.06116972118616104,
      "learning_rate": 2.0071591409030917e-05,
      "loss": 0.0822,
      "step": 89830
    },
    {
      "epoch": 1.7965844098708155,
      "grad_norm": 0.156247079372406,
      "learning_rate": 2.006825847564959e-05,
      "loss": 0.0511,
      "step": 89840
    },
    {
      "epoch": 1.7967843858736952,
      "grad_norm": 0.07985228300094604,
      "learning_rate": 2.0064925542268263e-05,
      "loss": 0.0781,
      "step": 89850
    },
    {
      "epoch": 1.7969843618765748,
      "grad_norm": 0.14655661582946777,
      "learning_rate": 2.0061592608886933e-05,
      "loss": 0.0839,
      "step": 89860
    },
    {
      "epoch": 1.7971843378794543,
      "grad_norm": 0.14023244380950928,
      "learning_rate": 2.0058259675505606e-05,
      "loss": 0.0774,
      "step": 89870
    },
    {
      "epoch": 1.797384313882334,
      "grad_norm": 0.21023589372634888,
      "learning_rate": 2.005492674212428e-05,
      "loss": 0.0922,
      "step": 89880
    },
    {
      "epoch": 1.7975842898852137,
      "grad_norm": 0.14185968041419983,
      "learning_rate": 2.0051593808742952e-05,
      "loss": 0.0876,
      "step": 89890
    },
    {
      "epoch": 1.7977842658880934,
      "grad_norm": 0.11662371456623077,
      "learning_rate": 2.0048260875361625e-05,
      "loss": 0.119,
      "step": 89900
    },
    {
      "epoch": 1.797984241890973,
      "grad_norm": 0.23026475310325623,
      "learning_rate": 2.0044927941980295e-05,
      "loss": 0.0993,
      "step": 89910
    },
    {
      "epoch": 1.7981842178938527,
      "grad_norm": 0.11176691204309464,
      "learning_rate": 2.0041595008598968e-05,
      "loss": 0.079,
      "step": 89920
    },
    {
      "epoch": 1.7983841938967324,
      "grad_norm": 0.13812217116355896,
      "learning_rate": 2.0038262075217644e-05,
      "loss": 0.0451,
      "step": 89930
    },
    {
      "epoch": 1.7985841698996121,
      "grad_norm": 0.24660813808441162,
      "learning_rate": 2.0034929141836314e-05,
      "loss": 0.0931,
      "step": 89940
    },
    {
      "epoch": 1.7987841459024918,
      "grad_norm": 0.10770098865032196,
      "learning_rate": 2.0031596208454987e-05,
      "loss": 0.0308,
      "step": 89950
    },
    {
      "epoch": 1.7989841219053715,
      "grad_norm": 0.0909656211733818,
      "learning_rate": 2.002826327507366e-05,
      "loss": 0.0546,
      "step": 89960
    },
    {
      "epoch": 1.799184097908251,
      "grad_norm": 0.1891462504863739,
      "learning_rate": 2.002493034169233e-05,
      "loss": 0.05,
      "step": 89970
    },
    {
      "epoch": 1.7993840739111306,
      "grad_norm": 0.1589246243238449,
      "learning_rate": 2.0021597408311006e-05,
      "loss": 0.0521,
      "step": 89980
    },
    {
      "epoch": 1.7995840499140103,
      "grad_norm": 0.16534170508384705,
      "learning_rate": 2.0018264474929675e-05,
      "loss": 0.085,
      "step": 89990
    },
    {
      "epoch": 1.79978402591689,
      "grad_norm": 0.17920254170894623,
      "learning_rate": 2.001493154154835e-05,
      "loss": 0.041,
      "step": 90000
    },
    {
      "epoch": 1.7999840019197695,
      "grad_norm": 0.2890920639038086,
      "learning_rate": 2.0011931901505154e-05,
      "loss": 0.5227,
      "step": 90010
    },
    {
      "epoch": 1.8001839779226492,
      "grad_norm": 0.06075221300125122,
      "learning_rate": 2.0008598968123827e-05,
      "loss": 0.1126,
      "step": 90020
    },
    {
      "epoch": 1.8003839539255289,
      "grad_norm": 0.08141998946666718,
      "learning_rate": 2.00052660347425e-05,
      "loss": 0.0587,
      "step": 90030
    },
    {
      "epoch": 1.8005839299284085,
      "grad_norm": 0.08105338364839554,
      "learning_rate": 2.000193310136117e-05,
      "loss": 0.1467,
      "step": 90040
    },
    {
      "epoch": 1.8007839059312882,
      "grad_norm": 0.15510646998882294,
      "learning_rate": 1.9998600167979846e-05,
      "loss": 0.1183,
      "step": 90050
    },
    {
      "epoch": 1.800983881934168,
      "grad_norm": 0.09446603059768677,
      "learning_rate": 1.9995267234598515e-05,
      "loss": 0.0707,
      "step": 90060
    },
    {
      "epoch": 1.8011838579370476,
      "grad_norm": 0.13766829669475555,
      "learning_rate": 1.999193430121719e-05,
      "loss": 0.0635,
      "step": 90070
    },
    {
      "epoch": 1.8013838339399273,
      "grad_norm": 0.14342261850833893,
      "learning_rate": 1.998860136783586e-05,
      "loss": 0.0401,
      "step": 90080
    },
    {
      "epoch": 1.801583809942807,
      "grad_norm": 0.10716380178928375,
      "learning_rate": 1.998526843445453e-05,
      "loss": 0.0586,
      "step": 90090
    },
    {
      "epoch": 1.8017837859456867,
      "grad_norm": 0.1118064597249031,
      "learning_rate": 1.9981935501073207e-05,
      "loss": 0.0551,
      "step": 90100
    },
    {
      "epoch": 1.8019837619485661,
      "grad_norm": 0.24406179785728455,
      "learning_rate": 1.9978602567691877e-05,
      "loss": 0.0985,
      "step": 90110
    },
    {
      "epoch": 1.8021837379514458,
      "grad_norm": 0.11059465259313583,
      "learning_rate": 1.997526963431055e-05,
      "loss": 0.0505,
      "step": 90120
    },
    {
      "epoch": 1.8023837139543255,
      "grad_norm": 0.16565196216106415,
      "learning_rate": 1.9971936700929223e-05,
      "loss": 0.0812,
      "step": 90130
    },
    {
      "epoch": 1.802583689957205,
      "grad_norm": 0.17059266567230225,
      "learning_rate": 1.9968603767547896e-05,
      "loss": 0.126,
      "step": 90140
    },
    {
      "epoch": 1.8027836659600847,
      "grad_norm": 0.20762211084365845,
      "learning_rate": 1.996527083416657e-05,
      "loss": 0.0747,
      "step": 90150
    },
    {
      "epoch": 1.8029836419629643,
      "grad_norm": 0.07841119170188904,
      "learning_rate": 1.9961937900785242e-05,
      "loss": 0.0986,
      "step": 90160
    },
    {
      "epoch": 1.803183617965844,
      "grad_norm": 0.1668122261762619,
      "learning_rate": 1.995860496740391e-05,
      "loss": 0.0475,
      "step": 90170
    },
    {
      "epoch": 1.8033835939687237,
      "grad_norm": 0.12341921776533127,
      "learning_rate": 1.9955272034022585e-05,
      "loss": 0.0882,
      "step": 90180
    },
    {
      "epoch": 1.8035835699716034,
      "grad_norm": 0.21873600780963898,
      "learning_rate": 1.9951939100641258e-05,
      "loss": 0.1165,
      "step": 90190
    },
    {
      "epoch": 1.803783545974483,
      "grad_norm": 0.07126830518245697,
      "learning_rate": 1.994860616725993e-05,
      "loss": 0.1148,
      "step": 90200
    },
    {
      "epoch": 1.8039835219773628,
      "grad_norm": 0.1243848130106926,
      "learning_rate": 1.9945273233878604e-05,
      "loss": 0.0877,
      "step": 90210
    },
    {
      "epoch": 1.8041834979802425,
      "grad_norm": 0.11429135501384735,
      "learning_rate": 1.9941940300497273e-05,
      "loss": 0.0546,
      "step": 90220
    },
    {
      "epoch": 1.8043834739831222,
      "grad_norm": 0.17765705287456512,
      "learning_rate": 1.9938607367115946e-05,
      "loss": 0.0789,
      "step": 90230
    },
    {
      "epoch": 1.8045834499860018,
      "grad_norm": 0.20595082640647888,
      "learning_rate": 1.993527443373462e-05,
      "loss": 0.1133,
      "step": 90240
    },
    {
      "epoch": 1.8047834259888813,
      "grad_norm": 0.18031267821788788,
      "learning_rate": 1.993194150035329e-05,
      "loss": 0.0755,
      "step": 90250
    },
    {
      "epoch": 1.804983401991761,
      "grad_norm": 0.16716788709163666,
      "learning_rate": 1.9928608566971965e-05,
      "loss": 0.0876,
      "step": 90260
    },
    {
      "epoch": 1.8051833779946407,
      "grad_norm": 0.07195854187011719,
      "learning_rate": 1.9925275633590638e-05,
      "loss": 0.5688,
      "step": 90270
    },
    {
      "epoch": 1.8053833539975201,
      "grad_norm": 0.07699695974588394,
      "learning_rate": 1.9921942700209308e-05,
      "loss": 0.0811,
      "step": 90280
    },
    {
      "epoch": 1.8055833300003998,
      "grad_norm": 0.19902372360229492,
      "learning_rate": 1.991860976682798e-05,
      "loss": 0.0807,
      "step": 90290
    },
    {
      "epoch": 1.8057833060032795,
      "grad_norm": 0.1970190405845642,
      "learning_rate": 1.9915276833446654e-05,
      "loss": 0.0588,
      "step": 90300
    },
    {
      "epoch": 1.8059832820061592,
      "grad_norm": 0.10844680666923523,
      "learning_rate": 1.9911943900065327e-05,
      "loss": 0.0611,
      "step": 90310
    },
    {
      "epoch": 1.806183258009039,
      "grad_norm": 0.11317388713359833,
      "learning_rate": 1.9908610966684e-05,
      "loss": 0.0857,
      "step": 90320
    },
    {
      "epoch": 1.8063832340119186,
      "grad_norm": 0.07249410450458527,
      "learning_rate": 1.990527803330267e-05,
      "loss": 0.0632,
      "step": 90330
    },
    {
      "epoch": 1.8065832100147983,
      "grad_norm": 0.3425919711589813,
      "learning_rate": 1.9901945099921343e-05,
      "loss": 0.0927,
      "step": 90340
    },
    {
      "epoch": 1.806783186017678,
      "grad_norm": 0.11201437562704086,
      "learning_rate": 1.9898612166540016e-05,
      "loss": 0.0322,
      "step": 90350
    },
    {
      "epoch": 1.8069831620205576,
      "grad_norm": 0.1829746812582016,
      "learning_rate": 1.989527923315869e-05,
      "loss": 0.0866,
      "step": 90360
    },
    {
      "epoch": 1.8071831380234373,
      "grad_norm": 0.07869665324687958,
      "learning_rate": 1.989194629977736e-05,
      "loss": 0.0761,
      "step": 90370
    },
    {
      "epoch": 1.8073831140263168,
      "grad_norm": 0.14101003110408783,
      "learning_rate": 1.9888613366396035e-05,
      "loss": 0.0747,
      "step": 90380
    },
    {
      "epoch": 1.8075830900291965,
      "grad_norm": 0.12157741189002991,
      "learning_rate": 1.9885280433014704e-05,
      "loss": 0.0771,
      "step": 90390
    },
    {
      "epoch": 1.8077830660320762,
      "grad_norm": 0.08083058893680573,
      "learning_rate": 1.9881947499633377e-05,
      "loss": 0.084,
      "step": 90400
    },
    {
      "epoch": 1.8079830420349559,
      "grad_norm": 0.10828310996294022,
      "learning_rate": 1.987861456625205e-05,
      "loss": 0.0604,
      "step": 90410
    },
    {
      "epoch": 1.8081830180378353,
      "grad_norm": 0.20160174369812012,
      "learning_rate": 1.9875281632870723e-05,
      "loss": 0.0654,
      "step": 90420
    },
    {
      "epoch": 1.808382994040715,
      "grad_norm": 0.12779532372951508,
      "learning_rate": 1.9871948699489396e-05,
      "loss": 0.0625,
      "step": 90430
    },
    {
      "epoch": 1.8085829700435947,
      "grad_norm": 0.033686891198158264,
      "learning_rate": 1.9868615766108066e-05,
      "loss": 0.0611,
      "step": 90440
    },
    {
      "epoch": 1.8087829460464744,
      "grad_norm": 0.23495055735111237,
      "learning_rate": 1.986528283272674e-05,
      "loss": 0.0768,
      "step": 90450
    },
    {
      "epoch": 1.808982922049354,
      "grad_norm": 0.0953730046749115,
      "learning_rate": 1.9861949899345415e-05,
      "loss": 0.0696,
      "step": 90460
    },
    {
      "epoch": 1.8091828980522338,
      "grad_norm": 0.08958750218153,
      "learning_rate": 1.9858616965964085e-05,
      "loss": 0.0449,
      "step": 90470
    },
    {
      "epoch": 1.8093828740551134,
      "grad_norm": 0.22268421947956085,
      "learning_rate": 1.9855284032582758e-05,
      "loss": 0.0749,
      "step": 90480
    },
    {
      "epoch": 1.8095828500579931,
      "grad_norm": 0.060891587287187576,
      "learning_rate": 1.985195109920143e-05,
      "loss": 0.0903,
      "step": 90490
    },
    {
      "epoch": 1.8097828260608728,
      "grad_norm": 0.051304254680871964,
      "learning_rate": 1.98486181658201e-05,
      "loss": 0.0476,
      "step": 90500
    },
    {
      "epoch": 1.8099828020637525,
      "grad_norm": 0.2367568016052246,
      "learning_rate": 1.9845285232438777e-05,
      "loss": 0.0479,
      "step": 90510
    },
    {
      "epoch": 1.810182778066632,
      "grad_norm": 0.09906817227602005,
      "learning_rate": 1.9841952299057446e-05,
      "loss": 0.053,
      "step": 90520
    },
    {
      "epoch": 1.8103827540695117,
      "grad_norm": 0.15552426874637604,
      "learning_rate": 1.983861936567612e-05,
      "loss": 0.1451,
      "step": 90530
    },
    {
      "epoch": 1.8105827300723913,
      "grad_norm": 0.04820128530263901,
      "learning_rate": 1.9835286432294792e-05,
      "loss": 0.0585,
      "step": 90540
    },
    {
      "epoch": 1.8107827060752708,
      "grad_norm": 0.2763083279132843,
      "learning_rate": 1.9831953498913462e-05,
      "loss": 0.2111,
      "step": 90550
    },
    {
      "epoch": 1.8109826820781505,
      "grad_norm": 0.11902520805597305,
      "learning_rate": 1.982862056553214e-05,
      "loss": 0.1289,
      "step": 90560
    },
    {
      "epoch": 1.8111826580810302,
      "grad_norm": 0.15816158056259155,
      "learning_rate": 1.982528763215081e-05,
      "loss": 0.1119,
      "step": 90570
    },
    {
      "epoch": 1.8113826340839099,
      "grad_norm": 0.1568669080734253,
      "learning_rate": 1.982195469876948e-05,
      "loss": 0.0853,
      "step": 90580
    },
    {
      "epoch": 1.8115826100867896,
      "grad_norm": 0.117513008415699,
      "learning_rate": 1.9818621765388154e-05,
      "loss": 0.0959,
      "step": 90590
    },
    {
      "epoch": 1.8117825860896692,
      "grad_norm": 0.2216162383556366,
      "learning_rate": 1.9815288832006827e-05,
      "loss": 0.1036,
      "step": 90600
    },
    {
      "epoch": 1.811982562092549,
      "grad_norm": 0.1836327463388443,
      "learning_rate": 1.98119558986255e-05,
      "loss": 0.0676,
      "step": 90610
    },
    {
      "epoch": 1.8121825380954286,
      "grad_norm": 0.11141147464513779,
      "learning_rate": 1.9808622965244173e-05,
      "loss": 0.0619,
      "step": 90620
    },
    {
      "epoch": 1.8123825140983083,
      "grad_norm": 0.13534754514694214,
      "learning_rate": 1.9805290031862843e-05,
      "loss": 0.0769,
      "step": 90630
    },
    {
      "epoch": 1.812582490101188,
      "grad_norm": 0.14011307060718536,
      "learning_rate": 1.9801957098481516e-05,
      "loss": 0.0515,
      "step": 90640
    },
    {
      "epoch": 1.8127824661040675,
      "grad_norm": 0.15741592645645142,
      "learning_rate": 1.979862416510019e-05,
      "loss": 0.0753,
      "step": 90650
    },
    {
      "epoch": 1.8129824421069471,
      "grad_norm": 0.15474125742912292,
      "learning_rate": 1.9795291231718862e-05,
      "loss": 0.0858,
      "step": 90660
    },
    {
      "epoch": 1.8131824181098268,
      "grad_norm": 0.15640975534915924,
      "learning_rate": 1.9791958298337535e-05,
      "loss": 0.0406,
      "step": 90670
    },
    {
      "epoch": 1.8133823941127065,
      "grad_norm": 0.09399961680173874,
      "learning_rate": 1.9788625364956208e-05,
      "loss": 0.0737,
      "step": 90680
    },
    {
      "epoch": 1.813582370115586,
      "grad_norm": 0.19707085192203522,
      "learning_rate": 1.9785292431574877e-05,
      "loss": 0.1011,
      "step": 90690
    },
    {
      "epoch": 1.8137823461184657,
      "grad_norm": 0.17031794786453247,
      "learning_rate": 1.978195949819355e-05,
      "loss": 0.0876,
      "step": 90700
    },
    {
      "epoch": 1.8139823221213454,
      "grad_norm": 0.14393284916877747,
      "learning_rate": 1.9778626564812223e-05,
      "loss": 0.06,
      "step": 90710
    },
    {
      "epoch": 1.814182298124225,
      "grad_norm": 0.10005762428045273,
      "learning_rate": 1.9775293631430896e-05,
      "loss": 0.1059,
      "step": 90720
    },
    {
      "epoch": 1.8143822741271047,
      "grad_norm": 0.14114661514759064,
      "learning_rate": 1.977196069804957e-05,
      "loss": 0.0645,
      "step": 90730
    },
    {
      "epoch": 1.8145822501299844,
      "grad_norm": 0.12081534415483475,
      "learning_rate": 1.976862776466824e-05,
      "loss": 0.0713,
      "step": 90740
    },
    {
      "epoch": 1.814782226132864,
      "grad_norm": 0.11259740591049194,
      "learning_rate": 1.9765294831286912e-05,
      "loss": 0.0827,
      "step": 90750
    },
    {
      "epoch": 1.8149822021357438,
      "grad_norm": 0.1440984010696411,
      "learning_rate": 1.9761961897905585e-05,
      "loss": 0.0589,
      "step": 90760
    },
    {
      "epoch": 1.8151821781386235,
      "grad_norm": 0.11768462508916855,
      "learning_rate": 1.9758628964524258e-05,
      "loss": 0.0727,
      "step": 90770
    },
    {
      "epoch": 1.8153821541415032,
      "grad_norm": 0.07413236051797867,
      "learning_rate": 1.975529603114293e-05,
      "loss": 0.0474,
      "step": 90780
    },
    {
      "epoch": 1.8155821301443826,
      "grad_norm": 0.14047637581825256,
      "learning_rate": 1.9751963097761604e-05,
      "loss": 0.1017,
      "step": 90790
    },
    {
      "epoch": 1.8157821061472623,
      "grad_norm": 0.165561243891716,
      "learning_rate": 1.9748630164380274e-05,
      "loss": 0.1135,
      "step": 90800
    },
    {
      "epoch": 1.815982082150142,
      "grad_norm": 0.12188824266195297,
      "learning_rate": 1.9745297230998947e-05,
      "loss": 0.0738,
      "step": 90810
    },
    {
      "epoch": 1.8161820581530215,
      "grad_norm": 0.07601448148488998,
      "learning_rate": 1.974196429761762e-05,
      "loss": 0.078,
      "step": 90820
    },
    {
      "epoch": 1.8163820341559012,
      "grad_norm": 0.15488335490226746,
      "learning_rate": 1.9738631364236293e-05,
      "loss": 0.0914,
      "step": 90830
    },
    {
      "epoch": 1.8165820101587808,
      "grad_norm": 0.10527903586626053,
      "learning_rate": 1.9735298430854966e-05,
      "loss": 0.0608,
      "step": 90840
    },
    {
      "epoch": 1.8167819861616605,
      "grad_norm": 0.23485048115253448,
      "learning_rate": 1.9731965497473635e-05,
      "loss": 0.0983,
      "step": 90850
    },
    {
      "epoch": 1.8169819621645402,
      "grad_norm": 0.08801858872175217,
      "learning_rate": 1.9728632564092308e-05,
      "loss": 0.0556,
      "step": 90860
    },
    {
      "epoch": 1.81718193816742,
      "grad_norm": 0.17115220427513123,
      "learning_rate": 1.9725299630710985e-05,
      "loss": 0.0742,
      "step": 90870
    },
    {
      "epoch": 1.8173819141702996,
      "grad_norm": 0.2291995733976364,
      "learning_rate": 1.9721966697329654e-05,
      "loss": 0.0921,
      "step": 90880
    },
    {
      "epoch": 1.8175818901731793,
      "grad_norm": 0.14498814940452576,
      "learning_rate": 1.9718633763948327e-05,
      "loss": 0.0699,
      "step": 90890
    },
    {
      "epoch": 1.817781866176059,
      "grad_norm": 0.15736442804336548,
      "learning_rate": 1.9715300830567e-05,
      "loss": 0.084,
      "step": 90900
    },
    {
      "epoch": 1.8179818421789387,
      "grad_norm": 0.08598821610212326,
      "learning_rate": 1.971196789718567e-05,
      "loss": 0.0487,
      "step": 90910
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.15539835393428802,
      "learning_rate": 1.9708634963804346e-05,
      "loss": 0.0891,
      "step": 90920
    },
    {
      "epoch": 1.8183817941846978,
      "grad_norm": 0.10564996302127838,
      "learning_rate": 1.9705302030423016e-05,
      "loss": 0.0645,
      "step": 90930
    },
    {
      "epoch": 1.8185817701875775,
      "grad_norm": 0.08070769906044006,
      "learning_rate": 1.970196909704169e-05,
      "loss": 0.0611,
      "step": 90940
    },
    {
      "epoch": 1.8187817461904572,
      "grad_norm": 0.08121170848608017,
      "learning_rate": 1.9698636163660362e-05,
      "loss": 0.1161,
      "step": 90950
    },
    {
      "epoch": 1.8189817221933366,
      "grad_norm": 0.11257653683423996,
      "learning_rate": 1.969530323027903e-05,
      "loss": 0.0674,
      "step": 90960
    },
    {
      "epoch": 1.8191816981962163,
      "grad_norm": 0.1848541498184204,
      "learning_rate": 1.9691970296897708e-05,
      "loss": 0.0636,
      "step": 90970
    },
    {
      "epoch": 1.819381674199096,
      "grad_norm": 0.0825488492846489,
      "learning_rate": 1.968863736351638e-05,
      "loss": 0.0685,
      "step": 90980
    },
    {
      "epoch": 1.8195816502019757,
      "grad_norm": 0.1692812293767929,
      "learning_rate": 1.968530443013505e-05,
      "loss": 0.0955,
      "step": 90990
    },
    {
      "epoch": 1.8197816262048554,
      "grad_norm": 0.09004112333059311,
      "learning_rate": 1.9681971496753724e-05,
      "loss": 0.0763,
      "step": 91000
    },
    {
      "epoch": 1.819981602207735,
      "grad_norm": 0.20857040584087372,
      "learning_rate": 1.9678638563372397e-05,
      "loss": 0.0821,
      "step": 91010
    },
    {
      "epoch": 1.8201815782106148,
      "grad_norm": 0.1354161500930786,
      "learning_rate": 1.967530562999107e-05,
      "loss": 0.078,
      "step": 91020
    },
    {
      "epoch": 1.8203815542134945,
      "grad_norm": 0.16449904441833496,
      "learning_rate": 1.9671972696609743e-05,
      "loss": 0.052,
      "step": 91030
    },
    {
      "epoch": 1.8205815302163741,
      "grad_norm": 0.08959504216909409,
      "learning_rate": 1.9668639763228412e-05,
      "loss": 0.0772,
      "step": 91040
    },
    {
      "epoch": 1.8207815062192538,
      "grad_norm": 0.07748478651046753,
      "learning_rate": 1.9665306829847085e-05,
      "loss": 0.0757,
      "step": 91050
    },
    {
      "epoch": 1.8209814822221333,
      "grad_norm": 0.22303734719753265,
      "learning_rate": 1.9661973896465758e-05,
      "loss": 0.0951,
      "step": 91060
    },
    {
      "epoch": 1.821181458225013,
      "grad_norm": 0.0619596466422081,
      "learning_rate": 1.965864096308443e-05,
      "loss": 0.0728,
      "step": 91070
    },
    {
      "epoch": 1.8213814342278927,
      "grad_norm": 0.09944898635149002,
      "learning_rate": 1.9655308029703104e-05,
      "loss": 0.0632,
      "step": 91080
    },
    {
      "epoch": 1.8215814102307724,
      "grad_norm": 0.12160351872444153,
      "learning_rate": 1.9651975096321777e-05,
      "loss": 0.0832,
      "step": 91090
    },
    {
      "epoch": 1.8217813862336518,
      "grad_norm": 0.12945221364498138,
      "learning_rate": 1.9648642162940447e-05,
      "loss": 0.1005,
      "step": 91100
    },
    {
      "epoch": 1.8219813622365315,
      "grad_norm": 0.13415414094924927,
      "learning_rate": 1.964530922955912e-05,
      "loss": 0.1064,
      "step": 91110
    },
    {
      "epoch": 1.8221813382394112,
      "grad_norm": 0.1851423680782318,
      "learning_rate": 1.9641976296177793e-05,
      "loss": 0.0585,
      "step": 91120
    },
    {
      "epoch": 1.8223813142422909,
      "grad_norm": 0.18005743622779846,
      "learning_rate": 1.9638643362796466e-05,
      "loss": 0.0718,
      "step": 91130
    },
    {
      "epoch": 1.8225812902451706,
      "grad_norm": 0.1416463851928711,
      "learning_rate": 1.963531042941514e-05,
      "loss": 0.0707,
      "step": 91140
    },
    {
      "epoch": 1.8227812662480503,
      "grad_norm": 0.15548104047775269,
      "learning_rate": 1.963197749603381e-05,
      "loss": 0.0607,
      "step": 91150
    },
    {
      "epoch": 1.82298124225093,
      "grad_norm": 0.09103342145681381,
      "learning_rate": 1.962864456265248e-05,
      "loss": 0.0614,
      "step": 91160
    },
    {
      "epoch": 1.8231812182538096,
      "grad_norm": 0.22741815447807312,
      "learning_rate": 1.9625311629271158e-05,
      "loss": 0.0819,
      "step": 91170
    },
    {
      "epoch": 1.8233811942566893,
      "grad_norm": 0.26118868589401245,
      "learning_rate": 1.9621978695889827e-05,
      "loss": 0.0782,
      "step": 91180
    },
    {
      "epoch": 1.823581170259569,
      "grad_norm": 0.14065125584602356,
      "learning_rate": 1.96186457625085e-05,
      "loss": 0.0725,
      "step": 91190
    },
    {
      "epoch": 1.8237811462624485,
      "grad_norm": 0.06419462710618973,
      "learning_rate": 1.9615312829127173e-05,
      "loss": 0.0802,
      "step": 91200
    },
    {
      "epoch": 1.8239811222653282,
      "grad_norm": 0.08008315414190292,
      "learning_rate": 1.9611979895745843e-05,
      "loss": 0.063,
      "step": 91210
    },
    {
      "epoch": 1.8241810982682078,
      "grad_norm": 0.10515391826629639,
      "learning_rate": 1.9608646962364516e-05,
      "loss": 0.1463,
      "step": 91220
    },
    {
      "epoch": 1.8243810742710873,
      "grad_norm": 0.07169150561094284,
      "learning_rate": 1.960531402898319e-05,
      "loss": 0.0771,
      "step": 91230
    },
    {
      "epoch": 1.824581050273967,
      "grad_norm": 0.0705891028046608,
      "learning_rate": 1.9601981095601862e-05,
      "loss": 0.0473,
      "step": 91240
    },
    {
      "epoch": 1.8247810262768467,
      "grad_norm": 0.24136464297771454,
      "learning_rate": 1.9598648162220535e-05,
      "loss": 0.079,
      "step": 91250
    },
    {
      "epoch": 1.8249810022797264,
      "grad_norm": 0.14957864582538605,
      "learning_rate": 1.9595315228839205e-05,
      "loss": 0.0801,
      "step": 91260
    },
    {
      "epoch": 1.825180978282606,
      "grad_norm": 0.1824876368045807,
      "learning_rate": 1.9591982295457878e-05,
      "loss": 0.0531,
      "step": 91270
    },
    {
      "epoch": 1.8253809542854857,
      "grad_norm": 0.21580003201961517,
      "learning_rate": 1.9588649362076554e-05,
      "loss": 0.0696,
      "step": 91280
    },
    {
      "epoch": 1.8255809302883654,
      "grad_norm": 0.09463310986757278,
      "learning_rate": 1.9585316428695224e-05,
      "loss": 0.0458,
      "step": 91290
    },
    {
      "epoch": 1.8257809062912451,
      "grad_norm": 0.09471786767244339,
      "learning_rate": 1.9581983495313897e-05,
      "loss": 0.061,
      "step": 91300
    },
    {
      "epoch": 1.8259808822941248,
      "grad_norm": 0.07856830209493637,
      "learning_rate": 1.957865056193257e-05,
      "loss": 0.0644,
      "step": 91310
    },
    {
      "epoch": 1.8261808582970045,
      "grad_norm": 0.11895749717950821,
      "learning_rate": 1.957531762855124e-05,
      "loss": 0.0528,
      "step": 91320
    },
    {
      "epoch": 1.826380834299884,
      "grad_norm": 0.0704631358385086,
      "learning_rate": 1.9571984695169916e-05,
      "loss": 0.084,
      "step": 91330
    },
    {
      "epoch": 1.8265808103027636,
      "grad_norm": 0.15782307088375092,
      "learning_rate": 1.9568651761788585e-05,
      "loss": 0.0914,
      "step": 91340
    },
    {
      "epoch": 1.8267807863056433,
      "grad_norm": 0.11355414986610413,
      "learning_rate": 1.956531882840726e-05,
      "loss": 0.0792,
      "step": 91350
    },
    {
      "epoch": 1.826980762308523,
      "grad_norm": 0.20224085450172424,
      "learning_rate": 1.956198589502593e-05,
      "loss": 0.0694,
      "step": 91360
    },
    {
      "epoch": 1.8271807383114025,
      "grad_norm": 0.09476149827241898,
      "learning_rate": 1.95586529616446e-05,
      "loss": 0.0454,
      "step": 91370
    },
    {
      "epoch": 1.8273807143142822,
      "grad_norm": 0.06810211390256882,
      "learning_rate": 1.9555320028263277e-05,
      "loss": 0.0774,
      "step": 91380
    },
    {
      "epoch": 1.8275806903171619,
      "grad_norm": 0.11492963880300522,
      "learning_rate": 1.955198709488195e-05,
      "loss": 0.0681,
      "step": 91390
    },
    {
      "epoch": 1.8277806663200415,
      "grad_norm": 0.12735600769519806,
      "learning_rate": 1.954865416150062e-05,
      "loss": 0.0712,
      "step": 91400
    },
    {
      "epoch": 1.8279806423229212,
      "grad_norm": 0.20636166632175446,
      "learning_rate": 1.9545321228119293e-05,
      "loss": 0.068,
      "step": 91410
    },
    {
      "epoch": 1.828180618325801,
      "grad_norm": 0.07386789470911026,
      "learning_rate": 1.9541988294737966e-05,
      "loss": 0.0836,
      "step": 91420
    },
    {
      "epoch": 1.8283805943286806,
      "grad_norm": 0.11874706298112869,
      "learning_rate": 1.953865536135664e-05,
      "loss": 0.0838,
      "step": 91430
    },
    {
      "epoch": 1.8285805703315603,
      "grad_norm": 0.09055041521787643,
      "learning_rate": 1.9535322427975312e-05,
      "loss": 0.0821,
      "step": 91440
    },
    {
      "epoch": 1.82878054633444,
      "grad_norm": 0.22446797788143158,
      "learning_rate": 1.953198949459398e-05,
      "loss": 0.0877,
      "step": 91450
    },
    {
      "epoch": 1.8289805223373197,
      "grad_norm": 0.18099652230739594,
      "learning_rate": 1.9528656561212655e-05,
      "loss": 0.0857,
      "step": 91460
    },
    {
      "epoch": 1.8291804983401991,
      "grad_norm": 0.19238702952861786,
      "learning_rate": 1.9525323627831328e-05,
      "loss": 0.0867,
      "step": 91470
    },
    {
      "epoch": 1.8293804743430788,
      "grad_norm": 0.07747244834899902,
      "learning_rate": 1.952199069445e-05,
      "loss": 0.0665,
      "step": 91480
    },
    {
      "epoch": 1.8295804503459585,
      "grad_norm": 0.11464210599660873,
      "learning_rate": 1.9518657761068674e-05,
      "loss": 0.1051,
      "step": 91490
    },
    {
      "epoch": 1.829780426348838,
      "grad_norm": 0.06806883960962296,
      "learning_rate": 1.9515324827687347e-05,
      "loss": 0.0584,
      "step": 91500
    },
    {
      "epoch": 1.8299804023517177,
      "grad_norm": 0.1401379555463791,
      "learning_rate": 1.9511991894306016e-05,
      "loss": 0.0629,
      "step": 91510
    },
    {
      "epoch": 1.8301803783545973,
      "grad_norm": 0.07474532723426819,
      "learning_rate": 1.950865896092469e-05,
      "loss": 0.0723,
      "step": 91520
    },
    {
      "epoch": 1.830380354357477,
      "grad_norm": 0.21786421537399292,
      "learning_rate": 1.9505326027543362e-05,
      "loss": 0.0682,
      "step": 91530
    },
    {
      "epoch": 1.8305803303603567,
      "grad_norm": 0.12003670632839203,
      "learning_rate": 1.9501993094162035e-05,
      "loss": 0.0813,
      "step": 91540
    },
    {
      "epoch": 1.8307803063632364,
      "grad_norm": 0.09105394035577774,
      "learning_rate": 1.9498660160780708e-05,
      "loss": 0.0859,
      "step": 91550
    },
    {
      "epoch": 1.830980282366116,
      "grad_norm": 0.15881559252738953,
      "learning_rate": 1.9495327227399378e-05,
      "loss": 0.0881,
      "step": 91560
    },
    {
      "epoch": 1.8311802583689958,
      "grad_norm": 0.1213669553399086,
      "learning_rate": 1.949199429401805e-05,
      "loss": 0.0831,
      "step": 91570
    },
    {
      "epoch": 1.8313802343718755,
      "grad_norm": 0.08935508877038956,
      "learning_rate": 1.9488661360636727e-05,
      "loss": 0.06,
      "step": 91580
    },
    {
      "epoch": 1.8315802103747552,
      "grad_norm": 0.14007484912872314,
      "learning_rate": 1.9485328427255397e-05,
      "loss": 0.0505,
      "step": 91590
    },
    {
      "epoch": 1.8317801863776348,
      "grad_norm": 0.1776471585035324,
      "learning_rate": 1.948199549387407e-05,
      "loss": 0.0948,
      "step": 91600
    },
    {
      "epoch": 1.8319801623805143,
      "grad_norm": 0.15213829278945923,
      "learning_rate": 1.9478662560492743e-05,
      "loss": 0.0907,
      "step": 91610
    },
    {
      "epoch": 1.832180138383394,
      "grad_norm": 0.1777440309524536,
      "learning_rate": 1.9475329627111412e-05,
      "loss": 0.086,
      "step": 91620
    },
    {
      "epoch": 1.8323801143862737,
      "grad_norm": 0.1916447877883911,
      "learning_rate": 1.947199669373009e-05,
      "loss": 0.0894,
      "step": 91630
    },
    {
      "epoch": 1.8325800903891531,
      "grad_norm": 0.1221408024430275,
      "learning_rate": 1.946866376034876e-05,
      "loss": 0.0879,
      "step": 91640
    },
    {
      "epoch": 1.8327800663920328,
      "grad_norm": 0.1975085735321045,
      "learning_rate": 1.946533082696743e-05,
      "loss": 0.0809,
      "step": 91650
    },
    {
      "epoch": 1.8329800423949125,
      "grad_norm": 0.10825273394584656,
      "learning_rate": 1.9461997893586105e-05,
      "loss": 0.0791,
      "step": 91660
    },
    {
      "epoch": 1.8331800183977922,
      "grad_norm": 0.18879275023937225,
      "learning_rate": 1.9458664960204774e-05,
      "loss": 0.0665,
      "step": 91670
    },
    {
      "epoch": 1.833379994400672,
      "grad_norm": 0.07911846786737442,
      "learning_rate": 1.945533202682345e-05,
      "loss": 0.0665,
      "step": 91680
    },
    {
      "epoch": 1.8335799704035516,
      "grad_norm": 0.2852913737297058,
      "learning_rate": 1.9451999093442124e-05,
      "loss": 0.0793,
      "step": 91690
    },
    {
      "epoch": 1.8337799464064313,
      "grad_norm": 0.17580656707286835,
      "learning_rate": 1.9448666160060793e-05,
      "loss": 0.0904,
      "step": 91700
    },
    {
      "epoch": 1.833979922409311,
      "grad_norm": 0.1392948180437088,
      "learning_rate": 1.9445333226679466e-05,
      "loss": 0.0772,
      "step": 91710
    },
    {
      "epoch": 1.8341798984121906,
      "grad_norm": 0.13556846976280212,
      "learning_rate": 1.944200029329814e-05,
      "loss": 0.0624,
      "step": 91720
    },
    {
      "epoch": 1.8343798744150703,
      "grad_norm": 0.1280362904071808,
      "learning_rate": 1.943866735991681e-05,
      "loss": 0.0555,
      "step": 91730
    },
    {
      "epoch": 1.8345798504179498,
      "grad_norm": 0.17214088141918182,
      "learning_rate": 1.9435334426535485e-05,
      "loss": 0.1535,
      "step": 91740
    },
    {
      "epoch": 1.8347798264208295,
      "grad_norm": 0.15518704056739807,
      "learning_rate": 1.9432001493154155e-05,
      "loss": 0.0729,
      "step": 91750
    },
    {
      "epoch": 1.8349798024237092,
      "grad_norm": 0.0971035286784172,
      "learning_rate": 1.9428668559772828e-05,
      "loss": 0.0729,
      "step": 91760
    },
    {
      "epoch": 1.8351797784265889,
      "grad_norm": 0.17044208943843842,
      "learning_rate": 1.94253356263915e-05,
      "loss": 0.0788,
      "step": 91770
    },
    {
      "epoch": 1.8353797544294683,
      "grad_norm": 0.2658766508102417,
      "learning_rate": 1.942200269301017e-05,
      "loss": 0.0776,
      "step": 91780
    },
    {
      "epoch": 1.835579730432348,
      "grad_norm": 0.09931058436632156,
      "learning_rate": 1.9418669759628847e-05,
      "loss": 0.0671,
      "step": 91790
    },
    {
      "epoch": 1.8357797064352277,
      "grad_norm": 0.07604892551898956,
      "learning_rate": 1.941533682624752e-05,
      "loss": 0.0441,
      "step": 91800
    },
    {
      "epoch": 1.8359796824381074,
      "grad_norm": 0.11378026008605957,
      "learning_rate": 1.941200389286619e-05,
      "loss": 0.0653,
      "step": 91810
    },
    {
      "epoch": 1.836179658440987,
      "grad_norm": 0.10305190086364746,
      "learning_rate": 1.9408670959484862e-05,
      "loss": 0.0432,
      "step": 91820
    },
    {
      "epoch": 1.8363796344438668,
      "grad_norm": 0.15312518179416656,
      "learning_rate": 1.9405338026103535e-05,
      "loss": 0.0884,
      "step": 91830
    },
    {
      "epoch": 1.8365796104467464,
      "grad_norm": 0.13043619692325592,
      "learning_rate": 1.940200509272221e-05,
      "loss": 0.0394,
      "step": 91840
    },
    {
      "epoch": 1.8367795864496261,
      "grad_norm": 0.1329319030046463,
      "learning_rate": 1.939867215934088e-05,
      "loss": 0.0531,
      "step": 91850
    },
    {
      "epoch": 1.8369795624525058,
      "grad_norm": 0.07641525566577911,
      "learning_rate": 1.939533922595955e-05,
      "loss": 0.0567,
      "step": 91860
    },
    {
      "epoch": 1.8371795384553855,
      "grad_norm": 0.10818309336900711,
      "learning_rate": 1.9392006292578224e-05,
      "loss": 0.0562,
      "step": 91870
    },
    {
      "epoch": 1.837379514458265,
      "grad_norm": 0.15383508801460266,
      "learning_rate": 1.9388673359196897e-05,
      "loss": 0.0505,
      "step": 91880
    },
    {
      "epoch": 1.8375794904611447,
      "grad_norm": 0.07872313261032104,
      "learning_rate": 1.938534042581557e-05,
      "loss": 0.0827,
      "step": 91890
    },
    {
      "epoch": 1.8377794664640243,
      "grad_norm": 0.1479199379682541,
      "learning_rate": 1.9382007492434243e-05,
      "loss": 0.0961,
      "step": 91900
    },
    {
      "epoch": 1.8379794424669038,
      "grad_norm": 0.1613921970129013,
      "learning_rate": 1.9378674559052916e-05,
      "loss": 0.054,
      "step": 91910
    },
    {
      "epoch": 1.8381794184697835,
      "grad_norm": 0.105234295129776,
      "learning_rate": 1.9375341625671586e-05,
      "loss": 0.075,
      "step": 91920
    },
    {
      "epoch": 1.8383793944726632,
      "grad_norm": 0.15873295068740845,
      "learning_rate": 1.937200869229026e-05,
      "loss": 0.0788,
      "step": 91930
    },
    {
      "epoch": 1.8385793704755429,
      "grad_norm": 0.1319328099489212,
      "learning_rate": 1.936867575890893e-05,
      "loss": 0.0771,
      "step": 91940
    },
    {
      "epoch": 1.8387793464784226,
      "grad_norm": 0.21028022468090057,
      "learning_rate": 1.9365342825527605e-05,
      "loss": 0.0786,
      "step": 91950
    },
    {
      "epoch": 1.8389793224813022,
      "grad_norm": 0.09257657825946808,
      "learning_rate": 1.9362009892146278e-05,
      "loss": 0.0721,
      "step": 91960
    },
    {
      "epoch": 1.839179298484182,
      "grad_norm": 0.08104714006185532,
      "learning_rate": 1.9358676958764947e-05,
      "loss": 0.0591,
      "step": 91970
    },
    {
      "epoch": 1.8393792744870616,
      "grad_norm": 0.1971830278635025,
      "learning_rate": 1.935534402538362e-05,
      "loss": 0.0749,
      "step": 91980
    },
    {
      "epoch": 1.8395792504899413,
      "grad_norm": 0.09527835249900818,
      "learning_rate": 1.9352011092002297e-05,
      "loss": 0.064,
      "step": 91990
    },
    {
      "epoch": 1.839779226492821,
      "grad_norm": 0.23009030520915985,
      "learning_rate": 1.9348678158620966e-05,
      "loss": 0.068,
      "step": 92000
    },
    {
      "epoch": 1.8399792024957005,
      "grad_norm": 0.13287454843521118,
      "learning_rate": 1.934534522523964e-05,
      "loss": 0.0552,
      "step": 92010
    },
    {
      "epoch": 1.8401791784985801,
      "grad_norm": 0.10668109357357025,
      "learning_rate": 1.9342012291858312e-05,
      "loss": 0.0371,
      "step": 92020
    },
    {
      "epoch": 1.8403791545014598,
      "grad_norm": 0.06967715919017792,
      "learning_rate": 1.9339012651815118e-05,
      "loss": 0.0587,
      "step": 92030
    },
    {
      "epoch": 1.8405791305043395,
      "grad_norm": 0.18650242686271667,
      "learning_rate": 1.9335679718433787e-05,
      "loss": 0.0982,
      "step": 92040
    },
    {
      "epoch": 1.840779106507219,
      "grad_norm": 0.10775794833898544,
      "learning_rate": 1.933234678505246e-05,
      "loss": 0.0818,
      "step": 92050
    },
    {
      "epoch": 1.8409790825100987,
      "grad_norm": 0.09413634985685349,
      "learning_rate": 1.9329013851671133e-05,
      "loss": 0.0699,
      "step": 92060
    },
    {
      "epoch": 1.8411790585129784,
      "grad_norm": 0.06800205260515213,
      "learning_rate": 1.9325680918289806e-05,
      "loss": 0.0864,
      "step": 92070
    },
    {
      "epoch": 1.841379034515858,
      "grad_norm": 0.19811508059501648,
      "learning_rate": 1.932234798490848e-05,
      "loss": 0.0958,
      "step": 92080
    },
    {
      "epoch": 1.8415790105187377,
      "grad_norm": 0.09110087156295776,
      "learning_rate": 1.9319015051527152e-05,
      "loss": 0.0583,
      "step": 92090
    },
    {
      "epoch": 1.8417789865216174,
      "grad_norm": 0.19791178405284882,
      "learning_rate": 1.9315682118145822e-05,
      "loss": 0.0869,
      "step": 92100
    },
    {
      "epoch": 1.841978962524497,
      "grad_norm": 0.1443304717540741,
      "learning_rate": 1.93123491847645e-05,
      "loss": 0.1115,
      "step": 92110
    },
    {
      "epoch": 1.8421789385273768,
      "grad_norm": 0.090843066573143,
      "learning_rate": 1.9309016251383168e-05,
      "loss": 0.0475,
      "step": 92120
    },
    {
      "epoch": 1.8423789145302565,
      "grad_norm": 0.11831405013799667,
      "learning_rate": 1.930568331800184e-05,
      "loss": 0.0534,
      "step": 92130
    },
    {
      "epoch": 1.8425788905331362,
      "grad_norm": 0.15299133956432343,
      "learning_rate": 1.9302350384620514e-05,
      "loss": 0.0866,
      "step": 92140
    },
    {
      "epoch": 1.8427788665360156,
      "grad_norm": 0.19691412150859833,
      "learning_rate": 1.9299017451239184e-05,
      "loss": 0.0465,
      "step": 92150
    },
    {
      "epoch": 1.8429788425388953,
      "grad_norm": 0.424533873796463,
      "learning_rate": 1.929568451785786e-05,
      "loss": 0.5969,
      "step": 92160
    },
    {
      "epoch": 1.843178818541775,
      "grad_norm": 0.0933670923113823,
      "learning_rate": 1.929235158447653e-05,
      "loss": 0.0509,
      "step": 92170
    },
    {
      "epoch": 1.8433787945446545,
      "grad_norm": 0.15316236019134521,
      "learning_rate": 1.9289018651095203e-05,
      "loss": 0.0698,
      "step": 92180
    },
    {
      "epoch": 1.8435787705475342,
      "grad_norm": 0.1640131026506424,
      "learning_rate": 1.9285685717713876e-05,
      "loss": 0.0636,
      "step": 92190
    },
    {
      "epoch": 1.8437787465504138,
      "grad_norm": 0.11623968929052353,
      "learning_rate": 1.9282352784332545e-05,
      "loss": 0.07,
      "step": 92200
    },
    {
      "epoch": 1.8439787225532935,
      "grad_norm": 0.16624005138874054,
      "learning_rate": 1.9279019850951218e-05,
      "loss": 0.1027,
      "step": 92210
    },
    {
      "epoch": 1.8441786985561732,
      "grad_norm": 0.07355616986751556,
      "learning_rate": 1.9275686917569895e-05,
      "loss": 0.0874,
      "step": 92220
    },
    {
      "epoch": 1.844378674559053,
      "grad_norm": 0.09373222291469574,
      "learning_rate": 1.9272353984188564e-05,
      "loss": 0.0711,
      "step": 92230
    },
    {
      "epoch": 1.8445786505619326,
      "grad_norm": 0.10543893277645111,
      "learning_rate": 1.9269021050807237e-05,
      "loss": 0.0588,
      "step": 92240
    },
    {
      "epoch": 1.8447786265648123,
      "grad_norm": 0.20755162835121155,
      "learning_rate": 1.926568811742591e-05,
      "loss": 0.0747,
      "step": 92250
    },
    {
      "epoch": 1.844978602567692,
      "grad_norm": 0.057449765503406525,
      "learning_rate": 1.926235518404458e-05,
      "loss": 0.0624,
      "step": 92260
    },
    {
      "epoch": 1.8451785785705717,
      "grad_norm": 0.07220728695392609,
      "learning_rate": 1.9259022250663256e-05,
      "loss": 0.0568,
      "step": 92270
    },
    {
      "epoch": 1.8453785545734513,
      "grad_norm": 0.2001330405473709,
      "learning_rate": 1.9255689317281926e-05,
      "loss": 0.0861,
      "step": 92280
    },
    {
      "epoch": 1.8455785305763308,
      "grad_norm": 0.1382051706314087,
      "learning_rate": 1.92523563839006e-05,
      "loss": 0.0647,
      "step": 92290
    },
    {
      "epoch": 1.8457785065792105,
      "grad_norm": 0.13054673373699188,
      "learning_rate": 1.9249023450519272e-05,
      "loss": 0.3738,
      "step": 92300
    },
    {
      "epoch": 1.8459784825820902,
      "grad_norm": 0.07680218666791916,
      "learning_rate": 1.924569051713794e-05,
      "loss": 0.0813,
      "step": 92310
    },
    {
      "epoch": 1.8461784585849697,
      "grad_norm": 0.1662161946296692,
      "learning_rate": 1.9242357583756618e-05,
      "loss": 0.0809,
      "step": 92320
    },
    {
      "epoch": 1.8463784345878493,
      "grad_norm": 0.10273662954568863,
      "learning_rate": 1.923902465037529e-05,
      "loss": 0.054,
      "step": 92330
    },
    {
      "epoch": 1.846578410590729,
      "grad_norm": 0.19005805253982544,
      "learning_rate": 1.923569171699396e-05,
      "loss": 0.0624,
      "step": 92340
    },
    {
      "epoch": 1.8467783865936087,
      "grad_norm": 0.16799478232860565,
      "learning_rate": 1.9232358783612633e-05,
      "loss": 0.0748,
      "step": 92350
    },
    {
      "epoch": 1.8469783625964884,
      "grad_norm": 0.09814631193876266,
      "learning_rate": 1.9229025850231306e-05,
      "loss": 0.0513,
      "step": 92360
    },
    {
      "epoch": 1.847178338599368,
      "grad_norm": 0.13366834819316864,
      "learning_rate": 1.922569291684998e-05,
      "loss": 0.0644,
      "step": 92370
    },
    {
      "epoch": 1.8473783146022478,
      "grad_norm": 0.21071922779083252,
      "learning_rate": 1.9222359983468652e-05,
      "loss": 0.069,
      "step": 92380
    },
    {
      "epoch": 1.8475782906051275,
      "grad_norm": 0.11062244325876236,
      "learning_rate": 1.9219027050087322e-05,
      "loss": 0.0656,
      "step": 92390
    },
    {
      "epoch": 1.8477782666080071,
      "grad_norm": 0.0634206160902977,
      "learning_rate": 1.9215694116705995e-05,
      "loss": 0.0491,
      "step": 92400
    },
    {
      "epoch": 1.8479782426108868,
      "grad_norm": 0.2528728246688843,
      "learning_rate": 1.9212361183324668e-05,
      "loss": 0.1041,
      "step": 92410
    },
    {
      "epoch": 1.8481782186137663,
      "grad_norm": 0.07898618280887604,
      "learning_rate": 1.920902824994334e-05,
      "loss": 0.0781,
      "step": 92420
    },
    {
      "epoch": 1.848378194616646,
      "grad_norm": 0.20162485539913177,
      "learning_rate": 1.9205695316562014e-05,
      "loss": 0.0804,
      "step": 92430
    },
    {
      "epoch": 1.8485781706195257,
      "grad_norm": 0.24603252112865448,
      "learning_rate": 1.9202362383180687e-05,
      "loss": 0.0884,
      "step": 92440
    },
    {
      "epoch": 1.8487781466224054,
      "grad_norm": 0.049527332186698914,
      "learning_rate": 1.9199029449799357e-05,
      "loss": 0.0416,
      "step": 92450
    },
    {
      "epoch": 1.8489781226252848,
      "grad_norm": 0.13197731971740723,
      "learning_rate": 1.919569651641803e-05,
      "loss": 0.0761,
      "step": 92460
    },
    {
      "epoch": 1.8491780986281645,
      "grad_norm": 0.24015454947948456,
      "learning_rate": 1.9192363583036703e-05,
      "loss": 0.1017,
      "step": 92470
    },
    {
      "epoch": 1.8493780746310442,
      "grad_norm": 0.06548389047384262,
      "learning_rate": 1.9189030649655376e-05,
      "loss": 0.0586,
      "step": 92480
    },
    {
      "epoch": 1.8495780506339239,
      "grad_norm": 0.11752492934465408,
      "learning_rate": 1.918569771627405e-05,
      "loss": 0.0509,
      "step": 92490
    },
    {
      "epoch": 1.8497780266368036,
      "grad_norm": 0.06361931562423706,
      "learning_rate": 1.918236478289272e-05,
      "loss": 0.0485,
      "step": 92500
    },
    {
      "epoch": 1.8499780026396833,
      "grad_norm": 0.12107037752866745,
      "learning_rate": 1.917903184951139e-05,
      "loss": 0.1035,
      "step": 92510
    },
    {
      "epoch": 1.850177978642563,
      "grad_norm": 0.07927186042070389,
      "learning_rate": 1.9175698916130068e-05,
      "loss": 0.0542,
      "step": 92520
    },
    {
      "epoch": 1.8503779546454426,
      "grad_norm": 0.11397692561149597,
      "learning_rate": 1.9172365982748737e-05,
      "loss": 0.0748,
      "step": 92530
    },
    {
      "epoch": 1.8505779306483223,
      "grad_norm": 0.24584636092185974,
      "learning_rate": 1.916903304936741e-05,
      "loss": 0.1153,
      "step": 92540
    },
    {
      "epoch": 1.850777906651202,
      "grad_norm": 0.11248931288719177,
      "learning_rate": 1.9165700115986083e-05,
      "loss": 0.0565,
      "step": 92550
    },
    {
      "epoch": 1.8509778826540815,
      "grad_norm": 0.11004549264907837,
      "learning_rate": 1.9162367182604753e-05,
      "loss": 0.053,
      "step": 92560
    },
    {
      "epoch": 1.8511778586569612,
      "grad_norm": 0.10402315109968185,
      "learning_rate": 1.915903424922343e-05,
      "loss": 0.0716,
      "step": 92570
    },
    {
      "epoch": 1.8513778346598408,
      "grad_norm": 0.05655328184366226,
      "learning_rate": 1.91557013158421e-05,
      "loss": 0.0835,
      "step": 92580
    },
    {
      "epoch": 1.8515778106627203,
      "grad_norm": 0.09586430341005325,
      "learning_rate": 1.9152368382460772e-05,
      "loss": 0.0609,
      "step": 92590
    },
    {
      "epoch": 1.8517777866656,
      "grad_norm": 0.08092295378446579,
      "learning_rate": 1.9149035449079445e-05,
      "loss": 0.081,
      "step": 92600
    },
    {
      "epoch": 1.8519777626684797,
      "grad_norm": 0.1718924641609192,
      "learning_rate": 1.9145702515698115e-05,
      "loss": 0.0864,
      "step": 92610
    },
    {
      "epoch": 1.8521777386713594,
      "grad_norm": 0.0711759477853775,
      "learning_rate": 1.914236958231679e-05,
      "loss": 0.0407,
      "step": 92620
    },
    {
      "epoch": 1.852377714674239,
      "grad_norm": 0.15987391769886017,
      "learning_rate": 1.9139036648935464e-05,
      "loss": 0.0664,
      "step": 92630
    },
    {
      "epoch": 1.8525776906771187,
      "grad_norm": 0.08037539571523666,
      "learning_rate": 1.9135703715554134e-05,
      "loss": 0.0738,
      "step": 92640
    },
    {
      "epoch": 1.8527776666799984,
      "grad_norm": 0.09185458719730377,
      "learning_rate": 1.9132370782172807e-05,
      "loss": 0.0528,
      "step": 92650
    },
    {
      "epoch": 1.8529776426828781,
      "grad_norm": 0.2127411663532257,
      "learning_rate": 1.912903784879148e-05,
      "loss": 0.0651,
      "step": 92660
    },
    {
      "epoch": 1.8531776186857578,
      "grad_norm": 0.062234777957201004,
      "learning_rate": 1.9125704915410153e-05,
      "loss": 0.0881,
      "step": 92670
    },
    {
      "epoch": 1.8533775946886375,
      "grad_norm": 0.09723511338233948,
      "learning_rate": 1.9122371982028826e-05,
      "loss": 0.0526,
      "step": 92680
    },
    {
      "epoch": 1.853577570691517,
      "grad_norm": 0.1999298632144928,
      "learning_rate": 1.9119039048647495e-05,
      "loss": 0.0948,
      "step": 92690
    },
    {
      "epoch": 1.8537775466943966,
      "grad_norm": 0.11341743171215057,
      "learning_rate": 1.9115706115266168e-05,
      "loss": 0.0669,
      "step": 92700
    },
    {
      "epoch": 1.8539775226972763,
      "grad_norm": 0.18119847774505615,
      "learning_rate": 1.911237318188484e-05,
      "loss": 0.0848,
      "step": 92710
    },
    {
      "epoch": 1.854177498700156,
      "grad_norm": 0.1061740592122078,
      "learning_rate": 1.910904024850351e-05,
      "loss": 0.0605,
      "step": 92720
    },
    {
      "epoch": 1.8543774747030355,
      "grad_norm": 0.23050656914710999,
      "learning_rate": 1.9105707315122187e-05,
      "loss": 0.0944,
      "step": 92730
    },
    {
      "epoch": 1.8545774507059152,
      "grad_norm": 0.0769568532705307,
      "learning_rate": 1.910237438174086e-05,
      "loss": 0.0517,
      "step": 92740
    },
    {
      "epoch": 1.8547774267087949,
      "grad_norm": 0.09935012459754944,
      "learning_rate": 1.909904144835953e-05,
      "loss": 0.0489,
      "step": 92750
    },
    {
      "epoch": 1.8549774027116746,
      "grad_norm": 0.11433406919240952,
      "learning_rate": 1.9095708514978203e-05,
      "loss": 0.0894,
      "step": 92760
    },
    {
      "epoch": 1.8551773787145542,
      "grad_norm": 0.2128244936466217,
      "learning_rate": 1.9092375581596876e-05,
      "loss": 0.0677,
      "step": 92770
    },
    {
      "epoch": 1.855377354717434,
      "grad_norm": 0.09647560864686966,
      "learning_rate": 1.908904264821555e-05,
      "loss": 0.0839,
      "step": 92780
    },
    {
      "epoch": 1.8555773307203136,
      "grad_norm": 0.12142465263605118,
      "learning_rate": 1.9085709714834222e-05,
      "loss": 0.0584,
      "step": 92790
    },
    {
      "epoch": 1.8557773067231933,
      "grad_norm": 0.09511073678731918,
      "learning_rate": 1.908237678145289e-05,
      "loss": 0.0573,
      "step": 92800
    },
    {
      "epoch": 1.855977282726073,
      "grad_norm": 0.08396308869123459,
      "learning_rate": 1.9079043848071565e-05,
      "loss": 0.0433,
      "step": 92810
    },
    {
      "epoch": 1.8561772587289527,
      "grad_norm": 0.1857466697692871,
      "learning_rate": 1.9075710914690238e-05,
      "loss": 0.1012,
      "step": 92820
    },
    {
      "epoch": 1.8563772347318321,
      "grad_norm": 0.10029727965593338,
      "learning_rate": 1.907237798130891e-05,
      "loss": 0.0485,
      "step": 92830
    },
    {
      "epoch": 1.8565772107347118,
      "grad_norm": 0.10731412470340729,
      "learning_rate": 1.9069045047927584e-05,
      "loss": 0.0488,
      "step": 92840
    },
    {
      "epoch": 1.8567771867375915,
      "grad_norm": 0.1432725191116333,
      "learning_rate": 1.9065712114546257e-05,
      "loss": 0.0505,
      "step": 92850
    },
    {
      "epoch": 1.8569771627404712,
      "grad_norm": 0.07928516715765,
      "learning_rate": 1.9062379181164926e-05,
      "loss": 0.0662,
      "step": 92860
    },
    {
      "epoch": 1.8571771387433507,
      "grad_norm": 0.07089157402515411,
      "learning_rate": 1.90590462477836e-05,
      "loss": 0.0508,
      "step": 92870
    },
    {
      "epoch": 1.8573771147462304,
      "grad_norm": 0.05234215036034584,
      "learning_rate": 1.9055713314402272e-05,
      "loss": 0.0514,
      "step": 92880
    },
    {
      "epoch": 1.85757709074911,
      "grad_norm": 0.12615875899791718,
      "learning_rate": 1.9052380381020945e-05,
      "loss": 0.0917,
      "step": 92890
    },
    {
      "epoch": 1.8577770667519897,
      "grad_norm": 0.2192971557378769,
      "learning_rate": 1.9049047447639618e-05,
      "loss": 0.0868,
      "step": 92900
    },
    {
      "epoch": 1.8579770427548694,
      "grad_norm": 0.2264099270105362,
      "learning_rate": 1.9045714514258288e-05,
      "loss": 0.0763,
      "step": 92910
    },
    {
      "epoch": 1.858177018757749,
      "grad_norm": 0.2501462697982788,
      "learning_rate": 1.904238158087696e-05,
      "loss": 0.0763,
      "step": 92920
    },
    {
      "epoch": 1.8583769947606288,
      "grad_norm": 0.21993407607078552,
      "learning_rate": 1.9039048647495637e-05,
      "loss": 0.0837,
      "step": 92930
    },
    {
      "epoch": 1.8585769707635085,
      "grad_norm": 0.09184861928224564,
      "learning_rate": 1.9035715714114307e-05,
      "loss": 0.078,
      "step": 92940
    },
    {
      "epoch": 1.8587769467663882,
      "grad_norm": 0.0647452175617218,
      "learning_rate": 1.903238278073298e-05,
      "loss": 0.0665,
      "step": 92950
    },
    {
      "epoch": 1.8589769227692678,
      "grad_norm": 0.22809278964996338,
      "learning_rate": 1.9029049847351653e-05,
      "loss": 0.111,
      "step": 92960
    },
    {
      "epoch": 1.8591768987721473,
      "grad_norm": 0.23950566351413727,
      "learning_rate": 1.9025716913970322e-05,
      "loss": 0.0937,
      "step": 92970
    },
    {
      "epoch": 1.859376874775027,
      "grad_norm": 0.10633781552314758,
      "learning_rate": 1.9022383980589e-05,
      "loss": 0.0481,
      "step": 92980
    },
    {
      "epoch": 1.8595768507779067,
      "grad_norm": 0.23139236867427826,
      "learning_rate": 1.901905104720767e-05,
      "loss": 0.1085,
      "step": 92990
    },
    {
      "epoch": 1.8597768267807862,
      "grad_norm": 0.19348753988742828,
      "learning_rate": 1.901571811382634e-05,
      "loss": 0.0787,
      "step": 93000
    },
    {
      "epoch": 1.8599768027836658,
      "grad_norm": 0.20649932324886322,
      "learning_rate": 1.9012385180445014e-05,
      "loss": 0.0906,
      "step": 93010
    },
    {
      "epoch": 1.8601767787865455,
      "grad_norm": 0.14815707504749298,
      "learning_rate": 1.9009052247063684e-05,
      "loss": 0.0666,
      "step": 93020
    },
    {
      "epoch": 1.8603767547894252,
      "grad_norm": 0.19770652055740356,
      "learning_rate": 1.900571931368236e-05,
      "loss": 0.0768,
      "step": 93030
    },
    {
      "epoch": 1.860576730792305,
      "grad_norm": 0.09573250263929367,
      "learning_rate": 1.9002386380301033e-05,
      "loss": 0.0825,
      "step": 93040
    },
    {
      "epoch": 1.8607767067951846,
      "grad_norm": 0.07667981833219528,
      "learning_rate": 1.8999053446919703e-05,
      "loss": 0.0578,
      "step": 93050
    },
    {
      "epoch": 1.8609766827980643,
      "grad_norm": 0.12626393139362335,
      "learning_rate": 1.8995720513538376e-05,
      "loss": 0.0607,
      "step": 93060
    },
    {
      "epoch": 1.861176658800944,
      "grad_norm": 0.12707018852233887,
      "learning_rate": 1.899238758015705e-05,
      "loss": 0.079,
      "step": 93070
    },
    {
      "epoch": 1.8613766348038236,
      "grad_norm": 0.19326892495155334,
      "learning_rate": 1.8989054646775722e-05,
      "loss": 0.0576,
      "step": 93080
    },
    {
      "epoch": 1.8615766108067033,
      "grad_norm": 0.055083226412534714,
      "learning_rate": 1.8985721713394395e-05,
      "loss": 0.0995,
      "step": 93090
    },
    {
      "epoch": 1.8617765868095828,
      "grad_norm": 0.169714093208313,
      "learning_rate": 1.8982388780013065e-05,
      "loss": 0.1097,
      "step": 93100
    },
    {
      "epoch": 1.8619765628124625,
      "grad_norm": 0.20773601531982422,
      "learning_rate": 1.8979055846631738e-05,
      "loss": 0.0661,
      "step": 93110
    },
    {
      "epoch": 1.8621765388153422,
      "grad_norm": 0.1058116927742958,
      "learning_rate": 1.897572291325041e-05,
      "loss": 0.0976,
      "step": 93120
    },
    {
      "epoch": 1.8623765148182219,
      "grad_norm": 0.18935555219650269,
      "learning_rate": 1.8972389979869084e-05,
      "loss": 0.0847,
      "step": 93130
    },
    {
      "epoch": 1.8625764908211013,
      "grad_norm": 0.22130128741264343,
      "learning_rate": 1.8969057046487757e-05,
      "loss": 0.0866,
      "step": 93140
    },
    {
      "epoch": 1.862776466823981,
      "grad_norm": 0.08975977450609207,
      "learning_rate": 1.896572411310643e-05,
      "loss": 0.0501,
      "step": 93150
    },
    {
      "epoch": 1.8629764428268607,
      "grad_norm": 0.10563600808382034,
      "learning_rate": 1.89623911797251e-05,
      "loss": 0.0688,
      "step": 93160
    },
    {
      "epoch": 1.8631764188297404,
      "grad_norm": 0.21365192532539368,
      "learning_rate": 1.8959058246343772e-05,
      "loss": 0.09,
      "step": 93170
    },
    {
      "epoch": 1.86337639483262,
      "grad_norm": 0.19146166741847992,
      "learning_rate": 1.8955725312962445e-05,
      "loss": 0.0956,
      "step": 93180
    },
    {
      "epoch": 1.8635763708354998,
      "grad_norm": 0.2692898213863373,
      "learning_rate": 1.895239237958112e-05,
      "loss": 0.1109,
      "step": 93190
    },
    {
      "epoch": 1.8637763468383794,
      "grad_norm": 0.2126050591468811,
      "learning_rate": 1.894905944619979e-05,
      "loss": 0.0491,
      "step": 93200
    },
    {
      "epoch": 1.8639763228412591,
      "grad_norm": 0.13949982821941376,
      "learning_rate": 1.894572651281846e-05,
      "loss": 0.0728,
      "step": 93210
    },
    {
      "epoch": 1.8641762988441388,
      "grad_norm": 0.23335175216197968,
      "learning_rate": 1.8942393579437134e-05,
      "loss": 0.0693,
      "step": 93220
    },
    {
      "epoch": 1.8643762748470185,
      "grad_norm": 0.1148182675242424,
      "learning_rate": 1.8939060646055807e-05,
      "loss": 0.1154,
      "step": 93230
    },
    {
      "epoch": 1.864576250849898,
      "grad_norm": 0.21104125678539276,
      "learning_rate": 1.893572771267448e-05,
      "loss": 0.1083,
      "step": 93240
    },
    {
      "epoch": 1.8647762268527777,
      "grad_norm": 0.26666736602783203,
      "learning_rate": 1.8932394779293153e-05,
      "loss": 0.0855,
      "step": 93250
    },
    {
      "epoch": 1.8649762028556574,
      "grad_norm": 0.26843592524528503,
      "learning_rate": 1.8929061845911826e-05,
      "loss": 0.059,
      "step": 93260
    },
    {
      "epoch": 1.8651761788585368,
      "grad_norm": 0.1172434389591217,
      "learning_rate": 1.8925728912530496e-05,
      "loss": 0.0682,
      "step": 93270
    },
    {
      "epoch": 1.8653761548614165,
      "grad_norm": 0.1319788098335266,
      "learning_rate": 1.892239597914917e-05,
      "loss": 0.0854,
      "step": 93280
    },
    {
      "epoch": 1.8655761308642962,
      "grad_norm": 0.10337908565998077,
      "learning_rate": 1.891906304576784e-05,
      "loss": 0.0899,
      "step": 93290
    },
    {
      "epoch": 1.8657761068671759,
      "grad_norm": 0.1392945647239685,
      "learning_rate": 1.8915730112386515e-05,
      "loss": 0.0799,
      "step": 93300
    },
    {
      "epoch": 1.8659760828700556,
      "grad_norm": 0.06475687772035599,
      "learning_rate": 1.8912397179005188e-05,
      "loss": 0.0929,
      "step": 93310
    },
    {
      "epoch": 1.8661760588729353,
      "grad_norm": 0.08458052575588226,
      "learning_rate": 1.8909064245623857e-05,
      "loss": 0.0737,
      "step": 93320
    },
    {
      "epoch": 1.866376034875815,
      "grad_norm": 0.07091239839792252,
      "learning_rate": 1.890573131224253e-05,
      "loss": 0.0726,
      "step": 93330
    },
    {
      "epoch": 1.8665760108786946,
      "grad_norm": 0.13390111923217773,
      "learning_rate": 1.8902398378861207e-05,
      "loss": 0.0973,
      "step": 93340
    },
    {
      "epoch": 1.8667759868815743,
      "grad_norm": 0.09241219609975815,
      "learning_rate": 1.8899065445479876e-05,
      "loss": 0.0763,
      "step": 93350
    },
    {
      "epoch": 1.866975962884454,
      "grad_norm": 0.23447012901306152,
      "learning_rate": 1.889573251209855e-05,
      "loss": 0.0666,
      "step": 93360
    },
    {
      "epoch": 1.8671759388873337,
      "grad_norm": 0.0800500139594078,
      "learning_rate": 1.8892399578717222e-05,
      "loss": 0.0761,
      "step": 93370
    },
    {
      "epoch": 1.8673759148902132,
      "grad_norm": 0.08715203404426575,
      "learning_rate": 1.8889066645335892e-05,
      "loss": 0.0759,
      "step": 93380
    },
    {
      "epoch": 1.8675758908930928,
      "grad_norm": 0.16308444738388062,
      "learning_rate": 1.8885733711954568e-05,
      "loss": 0.0523,
      "step": 93390
    },
    {
      "epoch": 1.8677758668959725,
      "grad_norm": 0.21277789771556854,
      "learning_rate": 1.8882400778573238e-05,
      "loss": 0.0835,
      "step": 93400
    },
    {
      "epoch": 1.867975842898852,
      "grad_norm": 0.1955946683883667,
      "learning_rate": 1.887906784519191e-05,
      "loss": 0.0789,
      "step": 93410
    },
    {
      "epoch": 1.8681758189017317,
      "grad_norm": 0.12494277954101562,
      "learning_rate": 1.8875734911810584e-05,
      "loss": 0.0585,
      "step": 93420
    },
    {
      "epoch": 1.8683757949046114,
      "grad_norm": 0.2229664921760559,
      "learning_rate": 1.8872401978429254e-05,
      "loss": 0.0797,
      "step": 93430
    },
    {
      "epoch": 1.868575770907491,
      "grad_norm": 0.08979862928390503,
      "learning_rate": 1.886906904504793e-05,
      "loss": 0.0669,
      "step": 93440
    },
    {
      "epoch": 1.8687757469103707,
      "grad_norm": 0.09275197982788086,
      "learning_rate": 1.8865736111666603e-05,
      "loss": 0.0528,
      "step": 93450
    },
    {
      "epoch": 1.8689757229132504,
      "grad_norm": 0.15151360630989075,
      "learning_rate": 1.8862403178285273e-05,
      "loss": 0.0789,
      "step": 93460
    },
    {
      "epoch": 1.8691756989161301,
      "grad_norm": 0.13220399618148804,
      "learning_rate": 1.8859070244903946e-05,
      "loss": 0.0826,
      "step": 93470
    },
    {
      "epoch": 1.8693756749190098,
      "grad_norm": 0.09125679731369019,
      "learning_rate": 1.885573731152262e-05,
      "loss": 0.0693,
      "step": 93480
    },
    {
      "epoch": 1.8695756509218895,
      "grad_norm": 0.155859112739563,
      "learning_rate": 1.885240437814129e-05,
      "loss": 0.0834,
      "step": 93490
    },
    {
      "epoch": 1.8697756269247692,
      "grad_norm": 0.13556481897830963,
      "learning_rate": 1.8849071444759965e-05,
      "loss": 0.0719,
      "step": 93500
    },
    {
      "epoch": 1.8699756029276486,
      "grad_norm": 0.12705491483211517,
      "learning_rate": 1.8845738511378634e-05,
      "loss": 0.0761,
      "step": 93510
    },
    {
      "epoch": 1.8701755789305283,
      "grad_norm": 0.12125228345394135,
      "learning_rate": 1.8842405577997307e-05,
      "loss": 0.1232,
      "step": 93520
    },
    {
      "epoch": 1.870375554933408,
      "grad_norm": 0.18089234828948975,
      "learning_rate": 1.883907264461598e-05,
      "loss": 0.0432,
      "step": 93530
    },
    {
      "epoch": 1.8705755309362877,
      "grad_norm": 0.13168814778327942,
      "learning_rate": 1.8835739711234653e-05,
      "loss": 0.0507,
      "step": 93540
    },
    {
      "epoch": 1.8707755069391672,
      "grad_norm": 0.12270921468734741,
      "learning_rate": 1.8832406777853326e-05,
      "loss": 0.0619,
      "step": 93550
    },
    {
      "epoch": 1.8709754829420469,
      "grad_norm": 0.21361635625362396,
      "learning_rate": 1.8829073844472e-05,
      "loss": 0.0576,
      "step": 93560
    },
    {
      "epoch": 1.8711754589449265,
      "grad_norm": 0.18505874276161194,
      "learning_rate": 1.882574091109067e-05,
      "loss": 0.0635,
      "step": 93570
    },
    {
      "epoch": 1.8713754349478062,
      "grad_norm": 0.12117891758680344,
      "learning_rate": 1.8822407977709342e-05,
      "loss": 0.0757,
      "step": 93580
    },
    {
      "epoch": 1.871575410950686,
      "grad_norm": 0.11644940823316574,
      "learning_rate": 1.8819075044328015e-05,
      "loss": 0.0872,
      "step": 93590
    },
    {
      "epoch": 1.8717753869535656,
      "grad_norm": 0.0734919086098671,
      "learning_rate": 1.8815742110946688e-05,
      "loss": 0.0902,
      "step": 93600
    },
    {
      "epoch": 1.8719753629564453,
      "grad_norm": 0.23724240064620972,
      "learning_rate": 1.881240917756536e-05,
      "loss": 0.0958,
      "step": 93610
    },
    {
      "epoch": 1.872175338959325,
      "grad_norm": 0.198212131857872,
      "learning_rate": 1.880907624418403e-05,
      "loss": 0.0738,
      "step": 93620
    },
    {
      "epoch": 1.8723753149622047,
      "grad_norm": 0.08482092618942261,
      "learning_rate": 1.8805743310802703e-05,
      "loss": 0.0808,
      "step": 93630
    },
    {
      "epoch": 1.8725752909650843,
      "grad_norm": 0.08502957224845886,
      "learning_rate": 1.880241037742138e-05,
      "loss": 0.072,
      "step": 93640
    },
    {
      "epoch": 1.8727752669679638,
      "grad_norm": 0.12357912212610245,
      "learning_rate": 1.879907744404005e-05,
      "loss": 0.0646,
      "step": 93650
    },
    {
      "epoch": 1.8729752429708435,
      "grad_norm": 0.16048841178417206,
      "learning_rate": 1.8795744510658722e-05,
      "loss": 0.0589,
      "step": 93660
    },
    {
      "epoch": 1.8731752189737232,
      "grad_norm": 0.22610703110694885,
      "learning_rate": 1.8792411577277395e-05,
      "loss": 0.0436,
      "step": 93670
    },
    {
      "epoch": 1.8733751949766027,
      "grad_norm": 0.3053458333015442,
      "learning_rate": 1.8789078643896065e-05,
      "loss": 0.0934,
      "step": 93680
    },
    {
      "epoch": 1.8735751709794823,
      "grad_norm": 0.13503900170326233,
      "learning_rate": 1.8785745710514738e-05,
      "loss": 0.0833,
      "step": 93690
    },
    {
      "epoch": 1.873775146982362,
      "grad_norm": 0.1291230469942093,
      "learning_rate": 1.878241277713341e-05,
      "loss": 0.0716,
      "step": 93700
    },
    {
      "epoch": 1.8739751229852417,
      "grad_norm": 0.17509736120700836,
      "learning_rate": 1.8779079843752084e-05,
      "loss": 0.0758,
      "step": 93710
    },
    {
      "epoch": 1.8741750989881214,
      "grad_norm": 0.16738465428352356,
      "learning_rate": 1.8775746910370757e-05,
      "loss": 0.0982,
      "step": 93720
    },
    {
      "epoch": 1.874375074991001,
      "grad_norm": 0.09161926060914993,
      "learning_rate": 1.8772413976989427e-05,
      "loss": 0.0648,
      "step": 93730
    },
    {
      "epoch": 1.8745750509938808,
      "grad_norm": 0.1981869488954544,
      "learning_rate": 1.87690810436081e-05,
      "loss": 0.1067,
      "step": 93740
    },
    {
      "epoch": 1.8747750269967605,
      "grad_norm": 0.06651902943849564,
      "learning_rate": 1.8765748110226776e-05,
      "loss": 0.0832,
      "step": 93750
    },
    {
      "epoch": 1.8749750029996402,
      "grad_norm": 0.2239518016576767,
      "learning_rate": 1.8762415176845446e-05,
      "loss": 0.0664,
      "step": 93760
    },
    {
      "epoch": 1.8751749790025198,
      "grad_norm": 0.10848642885684967,
      "learning_rate": 1.875908224346412e-05,
      "loss": 0.1204,
      "step": 93770
    },
    {
      "epoch": 1.8753749550053993,
      "grad_norm": 0.16653937101364136,
      "learning_rate": 1.8755749310082792e-05,
      "loss": 0.0648,
      "step": 93780
    },
    {
      "epoch": 1.875574931008279,
      "grad_norm": 0.13894541561603546,
      "learning_rate": 1.875241637670146e-05,
      "loss": 0.0591,
      "step": 93790
    },
    {
      "epoch": 1.8757749070111587,
      "grad_norm": 0.09273447096347809,
      "learning_rate": 1.8749083443320138e-05,
      "loss": 0.0331,
      "step": 93800
    },
    {
      "epoch": 1.8759748830140384,
      "grad_norm": 0.06855206936597824,
      "learning_rate": 1.8745750509938807e-05,
      "loss": 0.0562,
      "step": 93810
    },
    {
      "epoch": 1.8761748590169178,
      "grad_norm": 0.23260022699832916,
      "learning_rate": 1.874241757655748e-05,
      "loss": 0.0667,
      "step": 93820
    },
    {
      "epoch": 1.8763748350197975,
      "grad_norm": 0.06881046295166016,
      "learning_rate": 1.8739084643176153e-05,
      "loss": 0.0472,
      "step": 93830
    },
    {
      "epoch": 1.8765748110226772,
      "grad_norm": 0.06265773624181747,
      "learning_rate": 1.8735751709794823e-05,
      "loss": 0.0471,
      "step": 93840
    },
    {
      "epoch": 1.876774787025557,
      "grad_norm": 0.10120132565498352,
      "learning_rate": 1.87324187764135e-05,
      "loss": 0.0461,
      "step": 93850
    },
    {
      "epoch": 1.8769747630284366,
      "grad_norm": 0.1581162065267563,
      "learning_rate": 1.8729085843032172e-05,
      "loss": 0.0359,
      "step": 93860
    },
    {
      "epoch": 1.8771747390313163,
      "grad_norm": 0.15684226155281067,
      "learning_rate": 1.8725752909650842e-05,
      "loss": 0.0693,
      "step": 93870
    },
    {
      "epoch": 1.877374715034196,
      "grad_norm": 0.2005082666873932,
      "learning_rate": 1.8722419976269515e-05,
      "loss": 0.0899,
      "step": 93880
    },
    {
      "epoch": 1.8775746910370756,
      "grad_norm": 0.22133851051330566,
      "learning_rate": 1.8719087042888188e-05,
      "loss": 0.0871,
      "step": 93890
    },
    {
      "epoch": 1.8777746670399553,
      "grad_norm": 0.13611112534999847,
      "learning_rate": 1.871575410950686e-05,
      "loss": 0.0648,
      "step": 93900
    },
    {
      "epoch": 1.877974643042835,
      "grad_norm": 0.09375905990600586,
      "learning_rate": 1.8712421176125534e-05,
      "loss": 0.0744,
      "step": 93910
    },
    {
      "epoch": 1.8781746190457145,
      "grad_norm": 0.1122598871588707,
      "learning_rate": 1.8709088242744204e-05,
      "loss": 0.0651,
      "step": 93920
    },
    {
      "epoch": 1.8783745950485942,
      "grad_norm": 0.16849876940250397,
      "learning_rate": 1.8705755309362877e-05,
      "loss": 0.0609,
      "step": 93930
    },
    {
      "epoch": 1.8785745710514739,
      "grad_norm": 0.10673889517784119,
      "learning_rate": 1.870242237598155e-05,
      "loss": 0.064,
      "step": 93940
    },
    {
      "epoch": 1.8787745470543533,
      "grad_norm": 0.18123658001422882,
      "learning_rate": 1.8699089442600223e-05,
      "loss": 0.0942,
      "step": 93950
    },
    {
      "epoch": 1.878974523057233,
      "grad_norm": 0.12091173231601715,
      "learning_rate": 1.8695756509218896e-05,
      "loss": 0.0593,
      "step": 93960
    },
    {
      "epoch": 1.8791744990601127,
      "grad_norm": 0.11363059282302856,
      "learning_rate": 1.869242357583757e-05,
      "loss": 0.0733,
      "step": 93970
    },
    {
      "epoch": 1.8793744750629924,
      "grad_norm": 0.2128554731607437,
      "learning_rate": 1.8689090642456238e-05,
      "loss": 0.1264,
      "step": 93980
    },
    {
      "epoch": 1.879574451065872,
      "grad_norm": 0.10593920201063156,
      "learning_rate": 1.868575770907491e-05,
      "loss": 0.0547,
      "step": 93990
    },
    {
      "epoch": 1.8797744270687518,
      "grad_norm": 0.07981936633586884,
      "learning_rate": 1.8682424775693584e-05,
      "loss": 0.0803,
      "step": 94000
    },
    {
      "epoch": 1.8799744030716314,
      "grad_norm": 0.19740857183933258,
      "learning_rate": 1.8679091842312257e-05,
      "loss": 0.0887,
      "step": 94010
    },
    {
      "epoch": 1.8801743790745111,
      "grad_norm": 0.15336939692497253,
      "learning_rate": 1.867575890893093e-05,
      "loss": 0.0827,
      "step": 94020
    },
    {
      "epoch": 1.8803743550773908,
      "grad_norm": 0.11119004338979721,
      "learning_rate": 1.86724259755496e-05,
      "loss": 0.102,
      "step": 94030
    },
    {
      "epoch": 1.8805743310802705,
      "grad_norm": 0.17872628569602966,
      "learning_rate": 1.8669093042168273e-05,
      "loss": 0.0441,
      "step": 94040
    },
    {
      "epoch": 1.8807743070831502,
      "grad_norm": 0.17768841981887817,
      "learning_rate": 1.866576010878695e-05,
      "loss": 0.0643,
      "step": 94050
    },
    {
      "epoch": 1.8809742830860297,
      "grad_norm": 0.0826343223452568,
      "learning_rate": 1.866242717540562e-05,
      "loss": 0.0901,
      "step": 94060
    },
    {
      "epoch": 1.8811742590889093,
      "grad_norm": 0.20627614855766296,
      "learning_rate": 1.8659094242024292e-05,
      "loss": 0.0769,
      "step": 94070
    },
    {
      "epoch": 1.881374235091789,
      "grad_norm": 0.1357845664024353,
      "learning_rate": 1.8655761308642965e-05,
      "loss": 0.0634,
      "step": 94080
    },
    {
      "epoch": 1.8815742110946685,
      "grad_norm": 0.27586615085601807,
      "learning_rate": 1.8652428375261635e-05,
      "loss": 0.1098,
      "step": 94090
    },
    {
      "epoch": 1.8817741870975482,
      "grad_norm": 0.15779463946819305,
      "learning_rate": 1.864909544188031e-05,
      "loss": 0.0745,
      "step": 94100
    },
    {
      "epoch": 1.8819741631004279,
      "grad_norm": 0.13363179564476013,
      "learning_rate": 1.864576250849898e-05,
      "loss": 0.0774,
      "step": 94110
    },
    {
      "epoch": 1.8821741391033076,
      "grad_norm": 0.08746516704559326,
      "learning_rate": 1.8642429575117654e-05,
      "loss": 0.0628,
      "step": 94120
    },
    {
      "epoch": 1.8823741151061872,
      "grad_norm": 0.25220364332199097,
      "learning_rate": 1.8639096641736327e-05,
      "loss": 0.0731,
      "step": 94130
    },
    {
      "epoch": 1.882574091109067,
      "grad_norm": 0.09001065790653229,
      "learning_rate": 1.8635763708354996e-05,
      "loss": 0.053,
      "step": 94140
    },
    {
      "epoch": 1.8827740671119466,
      "grad_norm": 0.09366558492183685,
      "learning_rate": 1.8632430774973673e-05,
      "loss": 0.0941,
      "step": 94150
    },
    {
      "epoch": 1.8829740431148263,
      "grad_norm": 0.11967236548662186,
      "learning_rate": 1.8629097841592346e-05,
      "loss": 0.0675,
      "step": 94160
    },
    {
      "epoch": 1.883174019117706,
      "grad_norm": 0.1075999066233635,
      "learning_rate": 1.8625764908211015e-05,
      "loss": 0.0843,
      "step": 94170
    },
    {
      "epoch": 1.8833739951205857,
      "grad_norm": 0.2692103981971741,
      "learning_rate": 1.8622431974829688e-05,
      "loss": 0.2167,
      "step": 94180
    },
    {
      "epoch": 1.8835739711234651,
      "grad_norm": 0.07865950465202332,
      "learning_rate": 1.861909904144836e-05,
      "loss": 0.0844,
      "step": 94190
    },
    {
      "epoch": 1.8837739471263448,
      "grad_norm": 0.16967739164829254,
      "learning_rate": 1.861576610806703e-05,
      "loss": 0.0493,
      "step": 94200
    },
    {
      "epoch": 1.8839739231292245,
      "grad_norm": 0.16584554314613342,
      "learning_rate": 1.8612433174685707e-05,
      "loss": 0.0694,
      "step": 94210
    },
    {
      "epoch": 1.8841738991321042,
      "grad_norm": 0.15518315136432648,
      "learning_rate": 1.8609100241304377e-05,
      "loss": 0.053,
      "step": 94220
    },
    {
      "epoch": 1.8843738751349837,
      "grad_norm": 0.22845043241977692,
      "learning_rate": 1.860576730792305e-05,
      "loss": 0.0532,
      "step": 94230
    },
    {
      "epoch": 1.8845738511378634,
      "grad_norm": 0.13578642904758453,
      "learning_rate": 1.8602434374541723e-05,
      "loss": 0.0798,
      "step": 94240
    },
    {
      "epoch": 1.884773827140743,
      "grad_norm": 0.1902669370174408,
      "learning_rate": 1.8599101441160392e-05,
      "loss": 0.0701,
      "step": 94250
    },
    {
      "epoch": 1.8849738031436227,
      "grad_norm": 0.05921321362257004,
      "learning_rate": 1.859576850777907e-05,
      "loss": 0.0579,
      "step": 94260
    },
    {
      "epoch": 1.8851737791465024,
      "grad_norm": 0.07542915642261505,
      "learning_rate": 1.8592435574397742e-05,
      "loss": 0.0602,
      "step": 94270
    },
    {
      "epoch": 1.885373755149382,
      "grad_norm": 0.09948789328336716,
      "learning_rate": 1.858910264101641e-05,
      "loss": 0.0736,
      "step": 94280
    },
    {
      "epoch": 1.8855737311522618,
      "grad_norm": 0.16897006332874298,
      "learning_rate": 1.8585769707635084e-05,
      "loss": 0.1046,
      "step": 94290
    },
    {
      "epoch": 1.8857737071551415,
      "grad_norm": 0.07604330778121948,
      "learning_rate": 1.8582436774253757e-05,
      "loss": 0.0902,
      "step": 94300
    },
    {
      "epoch": 1.8859736831580212,
      "grad_norm": 0.21183572709560394,
      "learning_rate": 1.857910384087243e-05,
      "loss": 0.077,
      "step": 94310
    },
    {
      "epoch": 1.8861736591609009,
      "grad_norm": 0.1460120975971222,
      "learning_rate": 1.8576104200829232e-05,
      "loss": 0.0853,
      "step": 94320
    },
    {
      "epoch": 1.8863736351637803,
      "grad_norm": 0.1410587728023529,
      "learning_rate": 1.857277126744791e-05,
      "loss": 0.0783,
      "step": 94330
    },
    {
      "epoch": 1.88657361116666,
      "grad_norm": 0.26025643944740295,
      "learning_rate": 1.856943833406658e-05,
      "loss": 0.0687,
      "step": 94340
    },
    {
      "epoch": 1.8867735871695397,
      "grad_norm": 0.10024740546941757,
      "learning_rate": 1.856610540068525e-05,
      "loss": 0.0743,
      "step": 94350
    },
    {
      "epoch": 1.8869735631724192,
      "grad_norm": 0.12393840402364731,
      "learning_rate": 1.8562772467303924e-05,
      "loss": 0.068,
      "step": 94360
    },
    {
      "epoch": 1.8871735391752988,
      "grad_norm": 0.08324342966079712,
      "learning_rate": 1.8559439533922594e-05,
      "loss": 0.0552,
      "step": 94370
    },
    {
      "epoch": 1.8873735151781785,
      "grad_norm": 0.18009261786937714,
      "learning_rate": 1.855610660054127e-05,
      "loss": 0.0576,
      "step": 94380
    },
    {
      "epoch": 1.8875734911810582,
      "grad_norm": 0.17365726828575134,
      "learning_rate": 1.8552773667159943e-05,
      "loss": 0.074,
      "step": 94390
    },
    {
      "epoch": 1.887773467183938,
      "grad_norm": 0.2031262069940567,
      "learning_rate": 1.8549440733778613e-05,
      "loss": 0.0946,
      "step": 94400
    },
    {
      "epoch": 1.8879734431868176,
      "grad_norm": 0.22873686254024506,
      "learning_rate": 1.8546107800397286e-05,
      "loss": 0.0851,
      "step": 94410
    },
    {
      "epoch": 1.8881734191896973,
      "grad_norm": 0.2362220138311386,
      "learning_rate": 1.854277486701596e-05,
      "loss": 0.0806,
      "step": 94420
    },
    {
      "epoch": 1.888373395192577,
      "grad_norm": 0.14377270638942719,
      "learning_rate": 1.8539441933634632e-05,
      "loss": 0.0499,
      "step": 94430
    },
    {
      "epoch": 1.8885733711954567,
      "grad_norm": 0.24870720505714417,
      "learning_rate": 1.8536109000253305e-05,
      "loss": 0.0859,
      "step": 94440
    },
    {
      "epoch": 1.8887733471983363,
      "grad_norm": 0.1474856436252594,
      "learning_rate": 1.8532776066871975e-05,
      "loss": 0.1011,
      "step": 94450
    },
    {
      "epoch": 1.8889733232012158,
      "grad_norm": 0.19463306665420532,
      "learning_rate": 1.8529443133490648e-05,
      "loss": 0.0782,
      "step": 94460
    },
    {
      "epoch": 1.8891732992040955,
      "grad_norm": 0.1083926260471344,
      "learning_rate": 1.852611020010932e-05,
      "loss": 0.0841,
      "step": 94470
    },
    {
      "epoch": 1.8893732752069752,
      "grad_norm": 0.1675696223974228,
      "learning_rate": 1.8522777266727994e-05,
      "loss": 0.0619,
      "step": 94480
    },
    {
      "epoch": 1.8895732512098549,
      "grad_norm": 0.17675884068012238,
      "learning_rate": 1.8519444333346667e-05,
      "loss": 0.06,
      "step": 94490
    },
    {
      "epoch": 1.8897732272127343,
      "grad_norm": 0.15110577642917633,
      "learning_rate": 1.851611139996534e-05,
      "loss": 0.0884,
      "step": 94500
    },
    {
      "epoch": 1.889973203215614,
      "grad_norm": 0.19812743365764618,
      "learning_rate": 1.851277846658401e-05,
      "loss": 0.0837,
      "step": 94510
    },
    {
      "epoch": 1.8901731792184937,
      "grad_norm": 0.21367765963077545,
      "learning_rate": 1.8509445533202682e-05,
      "loss": 0.0913,
      "step": 94520
    },
    {
      "epoch": 1.8903731552213734,
      "grad_norm": 0.0807841494679451,
      "learning_rate": 1.8506112599821355e-05,
      "loss": 0.0475,
      "step": 94530
    },
    {
      "epoch": 1.890573131224253,
      "grad_norm": 0.1269848495721817,
      "learning_rate": 1.850277966644003e-05,
      "loss": 0.0624,
      "step": 94540
    },
    {
      "epoch": 1.8907731072271328,
      "grad_norm": 0.1591729074716568,
      "learning_rate": 1.84994467330587e-05,
      "loss": 0.1111,
      "step": 94550
    },
    {
      "epoch": 1.8909730832300125,
      "grad_norm": 0.30616089701652527,
      "learning_rate": 1.849611379967737e-05,
      "loss": 0.105,
      "step": 94560
    },
    {
      "epoch": 1.8911730592328921,
      "grad_norm": 0.16085661947727203,
      "learning_rate": 1.8492780866296044e-05,
      "loss": 0.0871,
      "step": 94570
    },
    {
      "epoch": 1.8913730352357718,
      "grad_norm": 0.14751684665679932,
      "learning_rate": 1.848944793291472e-05,
      "loss": 0.0728,
      "step": 94580
    },
    {
      "epoch": 1.8915730112386515,
      "grad_norm": 0.06984694302082062,
      "learning_rate": 1.848611499953339e-05,
      "loss": 0.0564,
      "step": 94590
    },
    {
      "epoch": 1.891772987241531,
      "grad_norm": 0.20511315762996674,
      "learning_rate": 1.8482782066152063e-05,
      "loss": 0.0896,
      "step": 94600
    },
    {
      "epoch": 1.8919729632444107,
      "grad_norm": 0.11513691395521164,
      "learning_rate": 1.8479449132770736e-05,
      "loss": 0.1539,
      "step": 94610
    },
    {
      "epoch": 1.8921729392472904,
      "grad_norm": 0.11590712517499924,
      "learning_rate": 1.8476116199389406e-05,
      "loss": 0.0444,
      "step": 94620
    },
    {
      "epoch": 1.8923729152501698,
      "grad_norm": 0.06176364794373512,
      "learning_rate": 1.8472783266008082e-05,
      "loss": 0.0657,
      "step": 94630
    },
    {
      "epoch": 1.8925728912530495,
      "grad_norm": 0.19696412980556488,
      "learning_rate": 1.846945033262675e-05,
      "loss": 0.1028,
      "step": 94640
    },
    {
      "epoch": 1.8927728672559292,
      "grad_norm": 0.09692670404911041,
      "learning_rate": 1.8466117399245425e-05,
      "loss": 0.0722,
      "step": 94650
    },
    {
      "epoch": 1.8929728432588089,
      "grad_norm": 0.10884957760572433,
      "learning_rate": 1.8462784465864098e-05,
      "loss": 0.0705,
      "step": 94660
    },
    {
      "epoch": 1.8931728192616886,
      "grad_norm": 0.1574173867702484,
      "learning_rate": 1.8459451532482767e-05,
      "loss": 0.0639,
      "step": 94670
    },
    {
      "epoch": 1.8933727952645683,
      "grad_norm": 0.17223508656024933,
      "learning_rate": 1.845611859910144e-05,
      "loss": 0.0863,
      "step": 94680
    },
    {
      "epoch": 1.893572771267448,
      "grad_norm": 0.1101088747382164,
      "learning_rate": 1.8452785665720117e-05,
      "loss": 0.1017,
      "step": 94690
    },
    {
      "epoch": 1.8937727472703276,
      "grad_norm": 0.17645074427127838,
      "learning_rate": 1.8449452732338786e-05,
      "loss": 0.0669,
      "step": 94700
    },
    {
      "epoch": 1.8939727232732073,
      "grad_norm": 0.1977808028459549,
      "learning_rate": 1.844611979895746e-05,
      "loss": 0.0597,
      "step": 94710
    },
    {
      "epoch": 1.894172699276087,
      "grad_norm": 0.11195055395364761,
      "learning_rate": 1.8442786865576132e-05,
      "loss": 0.0643,
      "step": 94720
    },
    {
      "epoch": 1.8943726752789667,
      "grad_norm": 0.09888671338558197,
      "learning_rate": 1.8439453932194802e-05,
      "loss": 0.0543,
      "step": 94730
    },
    {
      "epoch": 1.8945726512818462,
      "grad_norm": 0.12924207746982574,
      "learning_rate": 1.8436120998813478e-05,
      "loss": 0.0746,
      "step": 94740
    },
    {
      "epoch": 1.8947726272847258,
      "grad_norm": 0.17261716723442078,
      "learning_rate": 1.8432788065432148e-05,
      "loss": 0.1044,
      "step": 94750
    },
    {
      "epoch": 1.8949726032876055,
      "grad_norm": 0.05524236708879471,
      "learning_rate": 1.842945513205082e-05,
      "loss": 0.1046,
      "step": 94760
    },
    {
      "epoch": 1.895172579290485,
      "grad_norm": 0.10748343169689178,
      "learning_rate": 1.8426122198669494e-05,
      "loss": 0.0561,
      "step": 94770
    },
    {
      "epoch": 1.8953725552933647,
      "grad_norm": 0.17554274201393127,
      "learning_rate": 1.8422789265288164e-05,
      "loss": 0.0959,
      "step": 94780
    },
    {
      "epoch": 1.8955725312962444,
      "grad_norm": 0.14216287434101105,
      "learning_rate": 1.841945633190684e-05,
      "loss": 0.0957,
      "step": 94790
    },
    {
      "epoch": 1.895772507299124,
      "grad_norm": 0.11600063741207123,
      "learning_rate": 1.8416123398525513e-05,
      "loss": 0.0475,
      "step": 94800
    },
    {
      "epoch": 1.8959724833020037,
      "grad_norm": 0.050583239644765854,
      "learning_rate": 1.8412790465144183e-05,
      "loss": 0.0699,
      "step": 94810
    },
    {
      "epoch": 1.8961724593048834,
      "grad_norm": 0.1251453459262848,
      "learning_rate": 1.8409457531762856e-05,
      "loss": 0.0704,
      "step": 94820
    },
    {
      "epoch": 1.8963724353077631,
      "grad_norm": 0.06226016953587532,
      "learning_rate": 1.840612459838153e-05,
      "loss": 0.0636,
      "step": 94830
    },
    {
      "epoch": 1.8965724113106428,
      "grad_norm": 0.07125236839056015,
      "learning_rate": 1.84027916650002e-05,
      "loss": 0.0835,
      "step": 94840
    },
    {
      "epoch": 1.8967723873135225,
      "grad_norm": 0.12985236942768097,
      "learning_rate": 1.8399458731618875e-05,
      "loss": 0.0897,
      "step": 94850
    },
    {
      "epoch": 1.8969723633164022,
      "grad_norm": 0.13386429846286774,
      "learning_rate": 1.8396125798237544e-05,
      "loss": 0.0534,
      "step": 94860
    },
    {
      "epoch": 1.8971723393192816,
      "grad_norm": 0.16022825241088867,
      "learning_rate": 1.8392792864856217e-05,
      "loss": 0.0757,
      "step": 94870
    },
    {
      "epoch": 1.8973723153221613,
      "grad_norm": 0.08160760998725891,
      "learning_rate": 1.838945993147489e-05,
      "loss": 0.069,
      "step": 94880
    },
    {
      "epoch": 1.897572291325041,
      "grad_norm": 0.241049125790596,
      "learning_rate": 1.8386126998093563e-05,
      "loss": 0.1111,
      "step": 94890
    },
    {
      "epoch": 1.8977722673279207,
      "grad_norm": 0.06777041405439377,
      "learning_rate": 1.8382794064712236e-05,
      "loss": 0.0451,
      "step": 94900
    },
    {
      "epoch": 1.8979722433308002,
      "grad_norm": 0.20468470454216003,
      "learning_rate": 1.837946113133091e-05,
      "loss": 0.1074,
      "step": 94910
    },
    {
      "epoch": 1.8981722193336799,
      "grad_norm": 0.12965326011180878,
      "learning_rate": 1.837612819794958e-05,
      "loss": 0.0523,
      "step": 94920
    },
    {
      "epoch": 1.8983721953365595,
      "grad_norm": 0.16289855539798737,
      "learning_rate": 1.8372795264568252e-05,
      "loss": 0.0638,
      "step": 94930
    },
    {
      "epoch": 1.8985721713394392,
      "grad_norm": 0.1178952008485794,
      "learning_rate": 1.8369462331186925e-05,
      "loss": 0.075,
      "step": 94940
    },
    {
      "epoch": 1.898772147342319,
      "grad_norm": 0.19745463132858276,
      "learning_rate": 1.8366129397805598e-05,
      "loss": 0.0622,
      "step": 94950
    },
    {
      "epoch": 1.8989721233451986,
      "grad_norm": 0.11682143807411194,
      "learning_rate": 1.836279646442427e-05,
      "loss": 0.0902,
      "step": 94960
    },
    {
      "epoch": 1.8991720993480783,
      "grad_norm": 0.07785142213106155,
      "learning_rate": 1.835946353104294e-05,
      "loss": 0.0717,
      "step": 94970
    },
    {
      "epoch": 1.899372075350958,
      "grad_norm": 0.18344007432460785,
      "learning_rate": 1.8356130597661613e-05,
      "loss": 0.0818,
      "step": 94980
    },
    {
      "epoch": 1.8995720513538377,
      "grad_norm": 0.1055312529206276,
      "learning_rate": 1.835279766428029e-05,
      "loss": 0.0599,
      "step": 94990
    },
    {
      "epoch": 1.8997720273567174,
      "grad_norm": 0.07413879781961441,
      "learning_rate": 1.834946473089896e-05,
      "loss": 0.0738,
      "step": 95000
    },
    {
      "epoch": 1.8999720033595968,
      "grad_norm": 0.18554328382015228,
      "learning_rate": 1.8346131797517632e-05,
      "loss": 0.0737,
      "step": 95010
    },
    {
      "epoch": 1.9001719793624765,
      "grad_norm": 0.07335906475782394,
      "learning_rate": 1.8342798864136305e-05,
      "loss": 0.0649,
      "step": 95020
    },
    {
      "epoch": 1.9003719553653562,
      "grad_norm": 0.20755045115947723,
      "learning_rate": 1.8339465930754975e-05,
      "loss": 0.0907,
      "step": 95030
    },
    {
      "epoch": 1.9005719313682357,
      "grad_norm": 0.2057259976863861,
      "learning_rate": 1.833613299737365e-05,
      "loss": 0.0702,
      "step": 95040
    },
    {
      "epoch": 1.9007719073711153,
      "grad_norm": 0.11466553807258606,
      "learning_rate": 1.833280006399232e-05,
      "loss": 0.0789,
      "step": 95050
    },
    {
      "epoch": 1.900971883373995,
      "grad_norm": 0.07734638452529907,
      "learning_rate": 1.8329467130610994e-05,
      "loss": 0.0703,
      "step": 95060
    },
    {
      "epoch": 1.9011718593768747,
      "grad_norm": 0.10667194426059723,
      "learning_rate": 1.8326134197229667e-05,
      "loss": 0.0482,
      "step": 95070
    },
    {
      "epoch": 1.9013718353797544,
      "grad_norm": 0.12473150342702866,
      "learning_rate": 1.8322801263848337e-05,
      "loss": 0.0889,
      "step": 95080
    },
    {
      "epoch": 1.901571811382634,
      "grad_norm": 0.20004837214946747,
      "learning_rate": 1.8319468330467013e-05,
      "loss": 0.0833,
      "step": 95090
    },
    {
      "epoch": 1.9017717873855138,
      "grad_norm": 0.08548305183649063,
      "learning_rate": 1.8316135397085686e-05,
      "loss": 0.0715,
      "step": 95100
    },
    {
      "epoch": 1.9019717633883935,
      "grad_norm": 0.05380689725279808,
      "learning_rate": 1.8312802463704356e-05,
      "loss": 0.1218,
      "step": 95110
    },
    {
      "epoch": 1.9021717393912732,
      "grad_norm": 0.20958445966243744,
      "learning_rate": 1.830946953032303e-05,
      "loss": 0.0772,
      "step": 95120
    },
    {
      "epoch": 1.9023717153941528,
      "grad_norm": 0.13809771835803986,
      "learning_rate": 1.8306136596941702e-05,
      "loss": 0.1013,
      "step": 95130
    },
    {
      "epoch": 1.9025716913970323,
      "grad_norm": 0.1737346351146698,
      "learning_rate": 1.8302803663560375e-05,
      "loss": 0.0688,
      "step": 95140
    },
    {
      "epoch": 1.902771667399912,
      "grad_norm": 0.12546658515930176,
      "learning_rate": 1.8299470730179048e-05,
      "loss": 0.0637,
      "step": 95150
    },
    {
      "epoch": 1.9029716434027917,
      "grad_norm": 0.13370554149150848,
      "learning_rate": 1.8296137796797717e-05,
      "loss": 0.0575,
      "step": 95160
    },
    {
      "epoch": 1.9031716194056714,
      "grad_norm": 0.07575461268424988,
      "learning_rate": 1.829280486341639e-05,
      "loss": 0.0581,
      "step": 95170
    },
    {
      "epoch": 1.9033715954085508,
      "grad_norm": 0.09311435371637344,
      "learning_rate": 1.8289471930035063e-05,
      "loss": 0.0802,
      "step": 95180
    },
    {
      "epoch": 1.9035715714114305,
      "grad_norm": 0.0977567806839943,
      "learning_rate": 1.8286138996653733e-05,
      "loss": 0.0611,
      "step": 95190
    },
    {
      "epoch": 1.9037715474143102,
      "grad_norm": 0.21686182916164398,
      "learning_rate": 1.828280606327241e-05,
      "loss": 0.0785,
      "step": 95200
    },
    {
      "epoch": 1.90397152341719,
      "grad_norm": 0.08385849744081497,
      "learning_rate": 1.8279473129891082e-05,
      "loss": 0.0561,
      "step": 95210
    },
    {
      "epoch": 1.9041714994200696,
      "grad_norm": 0.08835657685995102,
      "learning_rate": 1.8276140196509752e-05,
      "loss": 0.0573,
      "step": 95220
    },
    {
      "epoch": 1.9043714754229493,
      "grad_norm": 0.1286434680223465,
      "learning_rate": 1.8272807263128425e-05,
      "loss": 0.0806,
      "step": 95230
    },
    {
      "epoch": 1.904571451425829,
      "grad_norm": 0.0755871906876564,
      "learning_rate": 1.8269474329747098e-05,
      "loss": 0.0715,
      "step": 95240
    },
    {
      "epoch": 1.9047714274287086,
      "grad_norm": 0.10718996822834015,
      "learning_rate": 1.826614139636577e-05,
      "loss": 0.048,
      "step": 95250
    },
    {
      "epoch": 1.9049714034315883,
      "grad_norm": 0.1832391768693924,
      "learning_rate": 1.8262808462984444e-05,
      "loss": 0.0552,
      "step": 95260
    },
    {
      "epoch": 1.905171379434468,
      "grad_norm": 0.08855681866407394,
      "learning_rate": 1.8259475529603114e-05,
      "loss": 0.0838,
      "step": 95270
    },
    {
      "epoch": 1.9053713554373475,
      "grad_norm": 0.09515028446912766,
      "learning_rate": 1.8256142596221787e-05,
      "loss": 0.0928,
      "step": 95280
    },
    {
      "epoch": 1.9055713314402272,
      "grad_norm": 0.16496741771697998,
      "learning_rate": 1.825280966284046e-05,
      "loss": 0.0885,
      "step": 95290
    },
    {
      "epoch": 1.9057713074431069,
      "grad_norm": 0.15048767626285553,
      "learning_rate": 1.8249476729459133e-05,
      "loss": 0.0621,
      "step": 95300
    },
    {
      "epoch": 1.9059712834459863,
      "grad_norm": 0.1674775928258896,
      "learning_rate": 1.8246143796077806e-05,
      "loss": 0.093,
      "step": 95310
    },
    {
      "epoch": 1.906171259448866,
      "grad_norm": 0.15209606289863586,
      "learning_rate": 1.824281086269648e-05,
      "loss": 0.0711,
      "step": 95320
    },
    {
      "epoch": 1.9063712354517457,
      "grad_norm": 0.15147416293621063,
      "learning_rate": 1.8239477929315148e-05,
      "loss": 0.0587,
      "step": 95330
    },
    {
      "epoch": 1.9065712114546254,
      "grad_norm": 0.13851791620254517,
      "learning_rate": 1.823614499593382e-05,
      "loss": 0.066,
      "step": 95340
    },
    {
      "epoch": 1.906771187457505,
      "grad_norm": 0.21512305736541748,
      "learning_rate": 1.8232812062552494e-05,
      "loss": 0.0805,
      "step": 95350
    },
    {
      "epoch": 1.9069711634603848,
      "grad_norm": 0.19366738200187683,
      "learning_rate": 1.8229479129171167e-05,
      "loss": 0.0745,
      "step": 95360
    },
    {
      "epoch": 1.9071711394632644,
      "grad_norm": 0.19309794902801514,
      "learning_rate": 1.822614619578984e-05,
      "loss": 0.0841,
      "step": 95370
    },
    {
      "epoch": 1.9073711154661441,
      "grad_norm": 0.17852932214736938,
      "learning_rate": 1.822281326240851e-05,
      "loss": 0.0658,
      "step": 95380
    },
    {
      "epoch": 1.9075710914690238,
      "grad_norm": 0.05160485953092575,
      "learning_rate": 1.8219480329027183e-05,
      "loss": 0.0428,
      "step": 95390
    },
    {
      "epoch": 1.9077710674719035,
      "grad_norm": 0.11433129012584686,
      "learning_rate": 1.821614739564586e-05,
      "loss": 0.1068,
      "step": 95400
    },
    {
      "epoch": 1.9079710434747832,
      "grad_norm": 0.19556325674057007,
      "learning_rate": 1.821281446226453e-05,
      "loss": 0.0927,
      "step": 95410
    },
    {
      "epoch": 1.9081710194776627,
      "grad_norm": 0.09982006996870041,
      "learning_rate": 1.8209481528883202e-05,
      "loss": 0.0709,
      "step": 95420
    },
    {
      "epoch": 1.9083709954805423,
      "grad_norm": 0.1464076191186905,
      "learning_rate": 1.8206148595501875e-05,
      "loss": 0.071,
      "step": 95430
    },
    {
      "epoch": 1.908570971483422,
      "grad_norm": 0.10347447544336319,
      "learning_rate": 1.8202815662120545e-05,
      "loss": 0.0373,
      "step": 95440
    },
    {
      "epoch": 1.9087709474863015,
      "grad_norm": 0.06851617246866226,
      "learning_rate": 1.819948272873922e-05,
      "loss": 0.0666,
      "step": 95450
    },
    {
      "epoch": 1.9089709234891812,
      "grad_norm": 0.11711344122886658,
      "learning_rate": 1.819614979535789e-05,
      "loss": 0.0482,
      "step": 95460
    },
    {
      "epoch": 1.9091708994920609,
      "grad_norm": 0.12416066229343414,
      "learning_rate": 1.8192816861976564e-05,
      "loss": 0.0651,
      "step": 95470
    },
    {
      "epoch": 1.9093708754949406,
      "grad_norm": 0.10892738401889801,
      "learning_rate": 1.8189483928595237e-05,
      "loss": 0.0611,
      "step": 95480
    },
    {
      "epoch": 1.9095708514978202,
      "grad_norm": 0.17011778056621552,
      "learning_rate": 1.8186150995213906e-05,
      "loss": 0.0992,
      "step": 95490
    },
    {
      "epoch": 1.9097708275007,
      "grad_norm": 0.10626336932182312,
      "learning_rate": 1.8182818061832583e-05,
      "loss": 0.0579,
      "step": 95500
    },
    {
      "epoch": 1.9099708035035796,
      "grad_norm": 0.07490610331296921,
      "learning_rate": 1.8179485128451256e-05,
      "loss": 0.1088,
      "step": 95510
    },
    {
      "epoch": 1.9101707795064593,
      "grad_norm": 0.09965044260025024,
      "learning_rate": 1.8176152195069925e-05,
      "loss": 0.0754,
      "step": 95520
    },
    {
      "epoch": 1.910370755509339,
      "grad_norm": 0.15458577871322632,
      "learning_rate": 1.8172819261688598e-05,
      "loss": 0.0858,
      "step": 95530
    },
    {
      "epoch": 1.9105707315122187,
      "grad_norm": 0.14740660786628723,
      "learning_rate": 1.816948632830727e-05,
      "loss": 0.0879,
      "step": 95540
    },
    {
      "epoch": 1.9107707075150981,
      "grad_norm": 0.10991901159286499,
      "learning_rate": 1.8166153394925944e-05,
      "loss": 0.0638,
      "step": 95550
    },
    {
      "epoch": 1.9109706835179778,
      "grad_norm": 0.11139201372861862,
      "learning_rate": 1.8162820461544617e-05,
      "loss": 0.0738,
      "step": 95560
    },
    {
      "epoch": 1.9111706595208575,
      "grad_norm": 0.1929464191198349,
      "learning_rate": 1.8159487528163287e-05,
      "loss": 0.1099,
      "step": 95570
    },
    {
      "epoch": 1.9113706355237372,
      "grad_norm": 0.06611848622560501,
      "learning_rate": 1.815615459478196e-05,
      "loss": 0.0782,
      "step": 95580
    },
    {
      "epoch": 1.9115706115266167,
      "grad_norm": 0.1291227638721466,
      "learning_rate": 1.8152821661400633e-05,
      "loss": 0.0752,
      "step": 95590
    },
    {
      "epoch": 1.9117705875294964,
      "grad_norm": 0.09721454977989197,
      "learning_rate": 1.8149488728019306e-05,
      "loss": 0.0912,
      "step": 95600
    },
    {
      "epoch": 1.911970563532376,
      "grad_norm": 0.13312655687332153,
      "learning_rate": 1.814615579463798e-05,
      "loss": 0.0785,
      "step": 95610
    },
    {
      "epoch": 1.9121705395352557,
      "grad_norm": 0.17711961269378662,
      "learning_rate": 1.8142822861256652e-05,
      "loss": 0.0987,
      "step": 95620
    },
    {
      "epoch": 1.9123705155381354,
      "grad_norm": 0.07869071513414383,
      "learning_rate": 1.813948992787532e-05,
      "loss": 0.0468,
      "step": 95630
    },
    {
      "epoch": 1.912570491541015,
      "grad_norm": 0.21494725346565247,
      "learning_rate": 1.8136156994493994e-05,
      "loss": 0.0743,
      "step": 95640
    },
    {
      "epoch": 1.9127704675438948,
      "grad_norm": 0.22689519822597504,
      "learning_rate": 1.8132824061112667e-05,
      "loss": 0.0901,
      "step": 95650
    },
    {
      "epoch": 1.9129704435467745,
      "grad_norm": 0.1916068196296692,
      "learning_rate": 1.812949112773134e-05,
      "loss": 0.093,
      "step": 95660
    },
    {
      "epoch": 1.9131704195496542,
      "grad_norm": 0.09811447560787201,
      "learning_rate": 1.8126158194350013e-05,
      "loss": 0.0909,
      "step": 95670
    },
    {
      "epoch": 1.9133703955525339,
      "grad_norm": 0.22780653834342957,
      "learning_rate": 1.8122825260968683e-05,
      "loss": 0.0705,
      "step": 95680
    },
    {
      "epoch": 1.9135703715554133,
      "grad_norm": 0.11987554281949997,
      "learning_rate": 1.8119492327587356e-05,
      "loss": 0.0698,
      "step": 95690
    },
    {
      "epoch": 1.913770347558293,
      "grad_norm": 0.1844836175441742,
      "learning_rate": 1.811615939420603e-05,
      "loss": 0.077,
      "step": 95700
    },
    {
      "epoch": 1.9139703235611727,
      "grad_norm": 0.13062183558940887,
      "learning_rate": 1.8112826460824702e-05,
      "loss": 0.0737,
      "step": 95710
    },
    {
      "epoch": 1.9141702995640522,
      "grad_norm": 0.1697237342596054,
      "learning_rate": 1.8109493527443375e-05,
      "loss": 0.0892,
      "step": 95720
    },
    {
      "epoch": 1.9143702755669318,
      "grad_norm": 0.1345660239458084,
      "learning_rate": 1.8106160594062048e-05,
      "loss": 0.0736,
      "step": 95730
    },
    {
      "epoch": 1.9145702515698115,
      "grad_norm": 0.07831283658742905,
      "learning_rate": 1.8102827660680718e-05,
      "loss": 0.084,
      "step": 95740
    },
    {
      "epoch": 1.9147702275726912,
      "grad_norm": 0.11566359549760818,
      "learning_rate": 1.809949472729939e-05,
      "loss": 0.1116,
      "step": 95750
    },
    {
      "epoch": 1.914970203575571,
      "grad_norm": 0.09004266560077667,
      "learning_rate": 1.8096161793918064e-05,
      "loss": 0.0739,
      "step": 95760
    },
    {
      "epoch": 1.9151701795784506,
      "grad_norm": 0.13962043821811676,
      "learning_rate": 1.8092828860536737e-05,
      "loss": 0.0467,
      "step": 95770
    },
    {
      "epoch": 1.9153701555813303,
      "grad_norm": 0.16791991889476776,
      "learning_rate": 1.808949592715541e-05,
      "loss": 0.0986,
      "step": 95780
    },
    {
      "epoch": 1.91557013158421,
      "grad_norm": 0.08473331481218338,
      "learning_rate": 1.808616299377408e-05,
      "loss": 0.0691,
      "step": 95790
    },
    {
      "epoch": 1.9157701075870897,
      "grad_norm": 0.0632777214050293,
      "learning_rate": 1.8082830060392752e-05,
      "loss": 0.0671,
      "step": 95800
    },
    {
      "epoch": 1.9159700835899693,
      "grad_norm": 0.07556457072496414,
      "learning_rate": 1.807949712701143e-05,
      "loss": 0.0632,
      "step": 95810
    },
    {
      "epoch": 1.9161700595928488,
      "grad_norm": 0.1607891470193863,
      "learning_rate": 1.80761641936301e-05,
      "loss": 0.0701,
      "step": 95820
    },
    {
      "epoch": 1.9163700355957285,
      "grad_norm": 0.07036111503839493,
      "learning_rate": 1.807283126024877e-05,
      "loss": 0.0468,
      "step": 95830
    },
    {
      "epoch": 1.9165700115986082,
      "grad_norm": 0.10951586812734604,
      "learning_rate": 1.8069498326867444e-05,
      "loss": 0.0414,
      "step": 95840
    },
    {
      "epoch": 1.9167699876014879,
      "grad_norm": 0.13382786512374878,
      "learning_rate": 1.8066165393486114e-05,
      "loss": 0.1147,
      "step": 95850
    },
    {
      "epoch": 1.9169699636043673,
      "grad_norm": 0.18612493574619293,
      "learning_rate": 1.806283246010479e-05,
      "loss": 0.0808,
      "step": 95860
    },
    {
      "epoch": 1.917169939607247,
      "grad_norm": 0.1921214610338211,
      "learning_rate": 1.805949952672346e-05,
      "loss": 0.0761,
      "step": 95870
    },
    {
      "epoch": 1.9173699156101267,
      "grad_norm": 0.07804346829652786,
      "learning_rate": 1.8056166593342133e-05,
      "loss": 0.0734,
      "step": 95880
    },
    {
      "epoch": 1.9175698916130064,
      "grad_norm": 0.10097818076610565,
      "learning_rate": 1.8052833659960806e-05,
      "loss": 0.0425,
      "step": 95890
    },
    {
      "epoch": 1.917769867615886,
      "grad_norm": 0.11934991925954819,
      "learning_rate": 1.8049500726579476e-05,
      "loss": 0.0851,
      "step": 95900
    },
    {
      "epoch": 1.9179698436187658,
      "grad_norm": 0.17016339302062988,
      "learning_rate": 1.8046167793198152e-05,
      "loss": 0.0817,
      "step": 95910
    },
    {
      "epoch": 1.9181698196216455,
      "grad_norm": 0.17913196980953217,
      "learning_rate": 1.8042834859816825e-05,
      "loss": 0.0607,
      "step": 95920
    },
    {
      "epoch": 1.9183697956245251,
      "grad_norm": 0.15787191689014435,
      "learning_rate": 1.8039501926435495e-05,
      "loss": 0.0693,
      "step": 95930
    },
    {
      "epoch": 1.9185697716274048,
      "grad_norm": 0.10903238505125046,
      "learning_rate": 1.8036168993054168e-05,
      "loss": 0.0746,
      "step": 95940
    },
    {
      "epoch": 1.9187697476302845,
      "grad_norm": 0.07742510735988617,
      "learning_rate": 1.803283605967284e-05,
      "loss": 0.0575,
      "step": 95950
    },
    {
      "epoch": 1.918969723633164,
      "grad_norm": 0.11681186407804489,
      "learning_rate": 1.8029503126291514e-05,
      "loss": 0.0705,
      "step": 95960
    },
    {
      "epoch": 1.9191696996360437,
      "grad_norm": 0.10823383182287216,
      "learning_rate": 1.8026170192910187e-05,
      "loss": 0.0765,
      "step": 95970
    },
    {
      "epoch": 1.9193696756389234,
      "grad_norm": 0.08235391974449158,
      "learning_rate": 1.8022837259528856e-05,
      "loss": 0.0629,
      "step": 95980
    },
    {
      "epoch": 1.9195696516418028,
      "grad_norm": 0.07064925879240036,
      "learning_rate": 1.801950432614753e-05,
      "loss": 0.0406,
      "step": 95990
    },
    {
      "epoch": 1.9197696276446825,
      "grad_norm": 0.2544459104537964,
      "learning_rate": 1.8016171392766202e-05,
      "loss": 0.1373,
      "step": 96000
    },
    {
      "epoch": 1.9199696036475622,
      "grad_norm": 0.1754588633775711,
      "learning_rate": 1.8012838459384875e-05,
      "loss": 0.0772,
      "step": 96010
    },
    {
      "epoch": 1.9201695796504419,
      "grad_norm": 0.2033316195011139,
      "learning_rate": 1.8009505526003548e-05,
      "loss": 0.0495,
      "step": 96020
    },
    {
      "epoch": 1.9203695556533216,
      "grad_norm": 0.12053327262401581,
      "learning_rate": 1.800617259262222e-05,
      "loss": 0.0922,
      "step": 96030
    },
    {
      "epoch": 1.9205695316562013,
      "grad_norm": 0.06194471940398216,
      "learning_rate": 1.800283965924089e-05,
      "loss": 0.0625,
      "step": 96040
    },
    {
      "epoch": 1.920769507659081,
      "grad_norm": 0.10017597675323486,
      "learning_rate": 1.7999506725859564e-05,
      "loss": 0.0823,
      "step": 96050
    },
    {
      "epoch": 1.9209694836619606,
      "grad_norm": 0.12638981640338898,
      "learning_rate": 1.7996173792478237e-05,
      "loss": 0.077,
      "step": 96060
    },
    {
      "epoch": 1.9211694596648403,
      "grad_norm": 0.06623945385217667,
      "learning_rate": 1.799284085909691e-05,
      "loss": 0.0562,
      "step": 96070
    },
    {
      "epoch": 1.92136943566772,
      "grad_norm": 0.10387419164180756,
      "learning_rate": 1.7989507925715583e-05,
      "loss": 0.0613,
      "step": 96080
    },
    {
      "epoch": 1.9215694116705997,
      "grad_norm": 0.09649895131587982,
      "learning_rate": 1.7986174992334253e-05,
      "loss": 0.0568,
      "step": 96090
    },
    {
      "epoch": 1.9217693876734792,
      "grad_norm": 0.10369743406772614,
      "learning_rate": 1.7982842058952926e-05,
      "loss": 0.0492,
      "step": 96100
    },
    {
      "epoch": 1.9219693636763588,
      "grad_norm": 0.07492619752883911,
      "learning_rate": 1.7979509125571602e-05,
      "loss": 0.0691,
      "step": 96110
    },
    {
      "epoch": 1.9221693396792385,
      "grad_norm": 0.08944062143564224,
      "learning_rate": 1.797617619219027e-05,
      "loss": 0.0755,
      "step": 96120
    },
    {
      "epoch": 1.922369315682118,
      "grad_norm": 0.07426504790782928,
      "learning_rate": 1.7972843258808945e-05,
      "loss": 0.0544,
      "step": 96130
    },
    {
      "epoch": 1.9225692916849977,
      "grad_norm": 0.11078344285488129,
      "learning_rate": 1.7969510325427618e-05,
      "loss": 0.0661,
      "step": 96140
    },
    {
      "epoch": 1.9227692676878774,
      "grad_norm": 0.18296413123607635,
      "learning_rate": 1.7966177392046287e-05,
      "loss": 0.0947,
      "step": 96150
    },
    {
      "epoch": 1.922969243690757,
      "grad_norm": 0.1450069099664688,
      "learning_rate": 1.796284445866496e-05,
      "loss": 0.0591,
      "step": 96160
    },
    {
      "epoch": 1.9231692196936367,
      "grad_norm": 0.20542632043361664,
      "learning_rate": 1.7959511525283633e-05,
      "loss": 0.1033,
      "step": 96170
    },
    {
      "epoch": 1.9233691956965164,
      "grad_norm": 0.06579053401947021,
      "learning_rate": 1.7956178591902306e-05,
      "loss": 0.0964,
      "step": 96180
    },
    {
      "epoch": 1.9235691716993961,
      "grad_norm": 0.11546789854764938,
      "learning_rate": 1.795284565852098e-05,
      "loss": 0.0519,
      "step": 96190
    },
    {
      "epoch": 1.9237691477022758,
      "grad_norm": 0.16878922283649445,
      "learning_rate": 1.794951272513965e-05,
      "loss": 0.1213,
      "step": 96200
    },
    {
      "epoch": 1.9239691237051555,
      "grad_norm": 0.1823522448539734,
      "learning_rate": 1.7946179791758322e-05,
      "loss": 0.0965,
      "step": 96210
    },
    {
      "epoch": 1.9241690997080352,
      "grad_norm": 0.13003049790859222,
      "learning_rate": 1.7942846858376998e-05,
      "loss": 0.0896,
      "step": 96220
    },
    {
      "epoch": 1.9243690757109146,
      "grad_norm": 0.1212359368801117,
      "learning_rate": 1.7939513924995668e-05,
      "loss": 0.0921,
      "step": 96230
    },
    {
      "epoch": 1.9245690517137943,
      "grad_norm": 0.1401456743478775,
      "learning_rate": 1.793618099161434e-05,
      "loss": 0.0644,
      "step": 96240
    },
    {
      "epoch": 1.924769027716674,
      "grad_norm": 0.10593854635953903,
      "learning_rate": 1.7932848058233014e-05,
      "loss": 0.1469,
      "step": 96250
    },
    {
      "epoch": 1.9249690037195537,
      "grad_norm": 0.26186010241508484,
      "learning_rate": 1.7929515124851683e-05,
      "loss": 0.0947,
      "step": 96260
    },
    {
      "epoch": 1.9251689797224332,
      "grad_norm": 0.12835736572742462,
      "learning_rate": 1.792618219147036e-05,
      "loss": 0.084,
      "step": 96270
    },
    {
      "epoch": 1.9253689557253129,
      "grad_norm": 0.10233884304761887,
      "learning_rate": 1.792284925808903e-05,
      "loss": 0.0744,
      "step": 96280
    },
    {
      "epoch": 1.9255689317281925,
      "grad_norm": 0.2090846747159958,
      "learning_rate": 1.7919516324707702e-05,
      "loss": 0.0842,
      "step": 96290
    },
    {
      "epoch": 1.9257689077310722,
      "grad_norm": 0.17125073075294495,
      "learning_rate": 1.7916183391326375e-05,
      "loss": 0.093,
      "step": 96300
    },
    {
      "epoch": 1.925968883733952,
      "grad_norm": 0.16136658191680908,
      "learning_rate": 1.7912850457945045e-05,
      "loss": 0.0823,
      "step": 96310
    },
    {
      "epoch": 1.9261688597368316,
      "grad_norm": 0.08623188734054565,
      "learning_rate": 1.790951752456372e-05,
      "loss": 0.0649,
      "step": 96320
    },
    {
      "epoch": 1.9263688357397113,
      "grad_norm": 0.20806708931922913,
      "learning_rate": 1.7906184591182394e-05,
      "loss": 0.1021,
      "step": 96330
    },
    {
      "epoch": 1.926568811742591,
      "grad_norm": 0.11790092289447784,
      "learning_rate": 1.7902851657801064e-05,
      "loss": 0.0791,
      "step": 96340
    },
    {
      "epoch": 1.9267687877454707,
      "grad_norm": 0.09739973396062851,
      "learning_rate": 1.7899518724419737e-05,
      "loss": 0.0573,
      "step": 96350
    },
    {
      "epoch": 1.9269687637483504,
      "grad_norm": 0.21881937980651855,
      "learning_rate": 1.789618579103841e-05,
      "loss": 0.0899,
      "step": 96360
    },
    {
      "epoch": 1.9271687397512298,
      "grad_norm": 0.19643980264663696,
      "learning_rate": 1.7892852857657083e-05,
      "loss": 0.0579,
      "step": 96370
    },
    {
      "epoch": 1.9273687157541095,
      "grad_norm": 0.07946702092885971,
      "learning_rate": 1.7889519924275756e-05,
      "loss": 0.1105,
      "step": 96380
    },
    {
      "epoch": 1.9275686917569892,
      "grad_norm": 0.12308907508850098,
      "learning_rate": 1.7886186990894426e-05,
      "loss": 0.1014,
      "step": 96390
    },
    {
      "epoch": 1.9277686677598687,
      "grad_norm": 0.15745483338832855,
      "learning_rate": 1.78828540575131e-05,
      "loss": 0.052,
      "step": 96400
    },
    {
      "epoch": 1.9279686437627483,
      "grad_norm": 0.08688061684370041,
      "learning_rate": 1.7879521124131772e-05,
      "loss": 0.0489,
      "step": 96410
    },
    {
      "epoch": 1.928168619765628,
      "grad_norm": 0.2094445377588272,
      "learning_rate": 1.7876188190750445e-05,
      "loss": 0.0775,
      "step": 96420
    },
    {
      "epoch": 1.9283685957685077,
      "grad_norm": 0.15389183163642883,
      "learning_rate": 1.7872855257369118e-05,
      "loss": 0.0997,
      "step": 96430
    },
    {
      "epoch": 1.9285685717713874,
      "grad_norm": 0.14870092272758484,
      "learning_rate": 1.786952232398779e-05,
      "loss": 0.0656,
      "step": 96440
    },
    {
      "epoch": 1.928768547774267,
      "grad_norm": 0.14281849563121796,
      "learning_rate": 1.786618939060646e-05,
      "loss": 0.0822,
      "step": 96450
    },
    {
      "epoch": 1.9289685237771468,
      "grad_norm": 0.21015231311321259,
      "learning_rate": 1.7862856457225133e-05,
      "loss": 0.0745,
      "step": 96460
    },
    {
      "epoch": 1.9291684997800265,
      "grad_norm": 0.18431492149829865,
      "learning_rate": 1.7859523523843806e-05,
      "loss": 0.0649,
      "step": 96470
    },
    {
      "epoch": 1.9293684757829062,
      "grad_norm": 0.12633995711803436,
      "learning_rate": 1.785619059046248e-05,
      "loss": 0.0726,
      "step": 96480
    },
    {
      "epoch": 1.9295684517857858,
      "grad_norm": 0.11513452976942062,
      "learning_rate": 1.7852857657081152e-05,
      "loss": 0.0564,
      "step": 96490
    },
    {
      "epoch": 1.9297684277886653,
      "grad_norm": 0.07080484926700592,
      "learning_rate": 1.7849524723699822e-05,
      "loss": 0.0433,
      "step": 96500
    },
    {
      "epoch": 1.929968403791545,
      "grad_norm": 0.21189910173416138,
      "learning_rate": 1.7846191790318495e-05,
      "loss": 0.0836,
      "step": 96510
    },
    {
      "epoch": 1.9301683797944247,
      "grad_norm": 0.07946380227804184,
      "learning_rate": 1.7842858856937168e-05,
      "loss": 0.048,
      "step": 96520
    },
    {
      "epoch": 1.9303683557973044,
      "grad_norm": 0.08694754540920258,
      "learning_rate": 1.783952592355584e-05,
      "loss": 0.0738,
      "step": 96530
    },
    {
      "epoch": 1.9305683318001838,
      "grad_norm": 0.16455067694187164,
      "learning_rate": 1.7836192990174514e-05,
      "loss": 0.0838,
      "step": 96540
    },
    {
      "epoch": 1.9307683078030635,
      "grad_norm": 0.18189918994903564,
      "learning_rate": 1.7832860056793184e-05,
      "loss": 0.0658,
      "step": 96550
    },
    {
      "epoch": 1.9309682838059432,
      "grad_norm": 0.08526656776666641,
      "learning_rate": 1.7829527123411857e-05,
      "loss": 0.0582,
      "step": 96560
    },
    {
      "epoch": 1.931168259808823,
      "grad_norm": 0.20384956896305084,
      "learning_rate": 1.7826194190030533e-05,
      "loss": 0.0925,
      "step": 96570
    },
    {
      "epoch": 1.9313682358117026,
      "grad_norm": 0.18052615225315094,
      "learning_rate": 1.7822861256649203e-05,
      "loss": 0.0698,
      "step": 96580
    },
    {
      "epoch": 1.9315682118145823,
      "grad_norm": 0.06784664839506149,
      "learning_rate": 1.7819528323267876e-05,
      "loss": 0.0543,
      "step": 96590
    },
    {
      "epoch": 1.931768187817462,
      "grad_norm": 0.08010949194431305,
      "learning_rate": 1.781619538988655e-05,
      "loss": 0.0782,
      "step": 96600
    },
    {
      "epoch": 1.9319681638203416,
      "grad_norm": 0.14672847092151642,
      "learning_rate": 1.7812862456505218e-05,
      "loss": 0.0566,
      "step": 96610
    },
    {
      "epoch": 1.9321681398232213,
      "grad_norm": 0.14498677849769592,
      "learning_rate": 1.7809529523123895e-05,
      "loss": 0.0727,
      "step": 96620
    },
    {
      "epoch": 1.932368115826101,
      "grad_norm": 0.030118107795715332,
      "learning_rate": 1.7806196589742564e-05,
      "loss": 0.0695,
      "step": 96630
    },
    {
      "epoch": 1.9325680918289805,
      "grad_norm": 0.19504867494106293,
      "learning_rate": 1.7802863656361237e-05,
      "loss": 0.1111,
      "step": 96640
    },
    {
      "epoch": 1.9327680678318602,
      "grad_norm": 0.08905194699764252,
      "learning_rate": 1.779953072297991e-05,
      "loss": 0.0988,
      "step": 96650
    },
    {
      "epoch": 1.9329680438347399,
      "grad_norm": 0.09479415416717529,
      "learning_rate": 1.7796531082936716e-05,
      "loss": 0.0959,
      "step": 96660
    },
    {
      "epoch": 1.9331680198376193,
      "grad_norm": 0.07974517345428467,
      "learning_rate": 1.779319814955539e-05,
      "loss": 0.0802,
      "step": 96670
    },
    {
      "epoch": 1.933367995840499,
      "grad_norm": 0.0824110209941864,
      "learning_rate": 1.7789865216174058e-05,
      "loss": 0.0436,
      "step": 96680
    },
    {
      "epoch": 1.9335679718433787,
      "grad_norm": 0.23274444043636322,
      "learning_rate": 1.778653228279273e-05,
      "loss": 0.0866,
      "step": 96690
    },
    {
      "epoch": 1.9337679478462584,
      "grad_norm": 0.20810957252979279,
      "learning_rate": 1.7783199349411404e-05,
      "loss": 0.0655,
      "step": 96700
    },
    {
      "epoch": 1.933967923849138,
      "grad_norm": 0.13724206387996674,
      "learning_rate": 1.7779866416030077e-05,
      "loss": 0.1159,
      "step": 96710
    },
    {
      "epoch": 1.9341678998520178,
      "grad_norm": 0.11439856141805649,
      "learning_rate": 1.777653348264875e-05,
      "loss": 0.0658,
      "step": 96720
    },
    {
      "epoch": 1.9343678758548974,
      "grad_norm": 0.18434317409992218,
      "learning_rate": 1.777320054926742e-05,
      "loss": 0.0811,
      "step": 96730
    },
    {
      "epoch": 1.9345678518577771,
      "grad_norm": 0.1881982833147049,
      "learning_rate": 1.7769867615886093e-05,
      "loss": 0.0558,
      "step": 96740
    },
    {
      "epoch": 1.9347678278606568,
      "grad_norm": 0.1648692786693573,
      "learning_rate": 1.776653468250477e-05,
      "loss": 0.1563,
      "step": 96750
    },
    {
      "epoch": 1.9349678038635365,
      "grad_norm": 0.11392239481210709,
      "learning_rate": 1.776320174912344e-05,
      "loss": 0.0947,
      "step": 96760
    },
    {
      "epoch": 1.9351677798664162,
      "grad_norm": 0.15545570850372314,
      "learning_rate": 1.7759868815742112e-05,
      "loss": 0.1012,
      "step": 96770
    },
    {
      "epoch": 1.9353677558692957,
      "grad_norm": 0.11831285804510117,
      "learning_rate": 1.7756535882360785e-05,
      "loss": 0.1106,
      "step": 96780
    },
    {
      "epoch": 1.9355677318721753,
      "grad_norm": 0.1388453245162964,
      "learning_rate": 1.7753202948979454e-05,
      "loss": 0.1029,
      "step": 96790
    },
    {
      "epoch": 1.935767707875055,
      "grad_norm": 0.16548645496368408,
      "learning_rate": 1.774987001559813e-05,
      "loss": 0.1016,
      "step": 96800
    },
    {
      "epoch": 1.9359676838779345,
      "grad_norm": 0.19968156516551971,
      "learning_rate": 1.77465370822168e-05,
      "loss": 0.0533,
      "step": 96810
    },
    {
      "epoch": 1.9361676598808142,
      "grad_norm": 0.14943663775920868,
      "learning_rate": 1.7743204148835474e-05,
      "loss": 0.0658,
      "step": 96820
    },
    {
      "epoch": 1.9363676358836939,
      "grad_norm": 0.16481292247772217,
      "learning_rate": 1.7739871215454147e-05,
      "loss": 0.0807,
      "step": 96830
    },
    {
      "epoch": 1.9365676118865736,
      "grad_norm": 0.1493551880121231,
      "learning_rate": 1.7736538282072816e-05,
      "loss": 0.0951,
      "step": 96840
    },
    {
      "epoch": 1.9367675878894532,
      "grad_norm": 0.1876363307237625,
      "learning_rate": 1.7733205348691493e-05,
      "loss": 0.0682,
      "step": 96850
    },
    {
      "epoch": 1.936967563892333,
      "grad_norm": 0.20088964700698853,
      "learning_rate": 1.7729872415310166e-05,
      "loss": 0.1163,
      "step": 96860
    },
    {
      "epoch": 1.9371675398952126,
      "grad_norm": 0.14453758299350739,
      "learning_rate": 1.7726539481928835e-05,
      "loss": 0.0843,
      "step": 96870
    },
    {
      "epoch": 1.9373675158980923,
      "grad_norm": 0.09617844223976135,
      "learning_rate": 1.7723206548547508e-05,
      "loss": 0.0796,
      "step": 96880
    },
    {
      "epoch": 1.937567491900972,
      "grad_norm": 0.09676139801740646,
      "learning_rate": 1.771987361516618e-05,
      "loss": 0.075,
      "step": 96890
    },
    {
      "epoch": 1.9377674679038517,
      "grad_norm": 0.16837966442108154,
      "learning_rate": 1.7716540681784854e-05,
      "loss": 0.0703,
      "step": 96900
    },
    {
      "epoch": 1.9379674439067311,
      "grad_norm": 0.09573136270046234,
      "learning_rate": 1.7713207748403527e-05,
      "loss": 0.0944,
      "step": 96910
    },
    {
      "epoch": 1.9381674199096108,
      "grad_norm": 0.11237502098083496,
      "learning_rate": 1.7709874815022197e-05,
      "loss": 0.0678,
      "step": 96920
    },
    {
      "epoch": 1.9383673959124905,
      "grad_norm": 0.1049332320690155,
      "learning_rate": 1.770654188164087e-05,
      "loss": 0.0894,
      "step": 96930
    },
    {
      "epoch": 1.9385673719153702,
      "grad_norm": 0.17539121210575104,
      "learning_rate": 1.7703208948259543e-05,
      "loss": 0.0477,
      "step": 96940
    },
    {
      "epoch": 1.9387673479182497,
      "grad_norm": 0.2344498634338379,
      "learning_rate": 1.7699876014878216e-05,
      "loss": 0.0944,
      "step": 96950
    },
    {
      "epoch": 1.9389673239211294,
      "grad_norm": 0.16728074848651886,
      "learning_rate": 1.769654308149689e-05,
      "loss": 0.0581,
      "step": 96960
    },
    {
      "epoch": 1.939167299924009,
      "grad_norm": 0.07789114862680435,
      "learning_rate": 1.7693210148115562e-05,
      "loss": 0.0662,
      "step": 96970
    },
    {
      "epoch": 1.9393672759268887,
      "grad_norm": 0.13079102337360382,
      "learning_rate": 1.768987721473423e-05,
      "loss": 0.0525,
      "step": 96980
    },
    {
      "epoch": 1.9395672519297684,
      "grad_norm": 0.07818278670310974,
      "learning_rate": 1.7686544281352904e-05,
      "loss": 0.0942,
      "step": 96990
    },
    {
      "epoch": 1.939767227932648,
      "grad_norm": 0.08088773488998413,
      "learning_rate": 1.7683211347971577e-05,
      "loss": 0.0985,
      "step": 97000
    },
    {
      "epoch": 1.9399672039355278,
      "grad_norm": 0.11071628332138062,
      "learning_rate": 1.767987841459025e-05,
      "loss": 0.0601,
      "step": 97010
    },
    {
      "epoch": 1.9401671799384075,
      "grad_norm": 0.09424518793821335,
      "learning_rate": 1.7676545481208923e-05,
      "loss": 0.0725,
      "step": 97020
    },
    {
      "epoch": 1.9403671559412872,
      "grad_norm": 0.06414932012557983,
      "learning_rate": 1.7673212547827593e-05,
      "loss": 0.0732,
      "step": 97030
    },
    {
      "epoch": 1.9405671319441669,
      "grad_norm": 0.10851893573999405,
      "learning_rate": 1.7669879614446266e-05,
      "loss": 0.1004,
      "step": 97040
    },
    {
      "epoch": 1.9407671079470463,
      "grad_norm": 0.13629643619060516,
      "learning_rate": 1.7666546681064942e-05,
      "loss": 0.0592,
      "step": 97050
    },
    {
      "epoch": 1.940967083949926,
      "grad_norm": 0.11492908000946045,
      "learning_rate": 1.7663213747683612e-05,
      "loss": 0.064,
      "step": 97060
    },
    {
      "epoch": 1.9411670599528057,
      "grad_norm": 0.197238951921463,
      "learning_rate": 1.7659880814302285e-05,
      "loss": 0.0928,
      "step": 97070
    },
    {
      "epoch": 1.9413670359556852,
      "grad_norm": 0.15372607111930847,
      "learning_rate": 1.7656547880920958e-05,
      "loss": 0.043,
      "step": 97080
    },
    {
      "epoch": 1.9415670119585648,
      "grad_norm": 0.0992051213979721,
      "learning_rate": 1.7653214947539628e-05,
      "loss": 0.0541,
      "step": 97090
    },
    {
      "epoch": 1.9417669879614445,
      "grad_norm": 0.05053064227104187,
      "learning_rate": 1.7649882014158304e-05,
      "loss": 0.1012,
      "step": 97100
    },
    {
      "epoch": 1.9419669639643242,
      "grad_norm": 0.16837017238140106,
      "learning_rate": 1.7646549080776974e-05,
      "loss": 0.0741,
      "step": 97110
    },
    {
      "epoch": 1.942166939967204,
      "grad_norm": 0.18143458664417267,
      "learning_rate": 1.7643216147395647e-05,
      "loss": 0.08,
      "step": 97120
    },
    {
      "epoch": 1.9423669159700836,
      "grad_norm": 0.19029192626476288,
      "learning_rate": 1.763988321401432e-05,
      "loss": 0.0488,
      "step": 97130
    },
    {
      "epoch": 1.9425668919729633,
      "grad_norm": 0.18110424280166626,
      "learning_rate": 1.763655028063299e-05,
      "loss": 0.0717,
      "step": 97140
    },
    {
      "epoch": 1.942766867975843,
      "grad_norm": 0.11002164334058762,
      "learning_rate": 1.7633217347251662e-05,
      "loss": 0.0477,
      "step": 97150
    },
    {
      "epoch": 1.9429668439787227,
      "grad_norm": 0.14105983078479767,
      "learning_rate": 1.762988441387034e-05,
      "loss": 0.0654,
      "step": 97160
    },
    {
      "epoch": 1.9431668199816023,
      "grad_norm": 0.154586523771286,
      "learning_rate": 1.762655148048901e-05,
      "loss": 0.0703,
      "step": 97170
    },
    {
      "epoch": 1.9433667959844818,
      "grad_norm": 0.18431255221366882,
      "learning_rate": 1.762321854710768e-05,
      "loss": 0.079,
      "step": 97180
    },
    {
      "epoch": 1.9435667719873615,
      "grad_norm": 0.11534204334020615,
      "learning_rate": 1.7619885613726354e-05,
      "loss": 0.0675,
      "step": 97190
    },
    {
      "epoch": 1.9437667479902412,
      "grad_norm": 0.17166829109191895,
      "learning_rate": 1.7616552680345024e-05,
      "loss": 0.0656,
      "step": 97200
    },
    {
      "epoch": 1.9439667239931209,
      "grad_norm": 0.20928825438022614,
      "learning_rate": 1.76132197469637e-05,
      "loss": 0.1067,
      "step": 97210
    },
    {
      "epoch": 1.9441666999960003,
      "grad_norm": 0.15229588747024536,
      "learning_rate": 1.760988681358237e-05,
      "loss": 0.0754,
      "step": 97220
    },
    {
      "epoch": 1.94436667599888,
      "grad_norm": 0.09814262390136719,
      "learning_rate": 1.7606553880201043e-05,
      "loss": 0.0802,
      "step": 97230
    },
    {
      "epoch": 1.9445666520017597,
      "grad_norm": 0.16103260219097137,
      "learning_rate": 1.7603220946819716e-05,
      "loss": 0.1039,
      "step": 97240
    },
    {
      "epoch": 1.9447666280046394,
      "grad_norm": 0.1951301097869873,
      "learning_rate": 1.7599888013438386e-05,
      "loss": 0.086,
      "step": 97250
    },
    {
      "epoch": 1.944966604007519,
      "grad_norm": 0.18362295627593994,
      "learning_rate": 1.7596555080057062e-05,
      "loss": 0.0688,
      "step": 97260
    },
    {
      "epoch": 1.9451665800103988,
      "grad_norm": 0.21042710542678833,
      "learning_rate": 1.7593222146675735e-05,
      "loss": 0.0839,
      "step": 97270
    },
    {
      "epoch": 1.9453665560132785,
      "grad_norm": 0.09836095571517944,
      "learning_rate": 1.7589889213294405e-05,
      "loss": 0.0642,
      "step": 97280
    },
    {
      "epoch": 1.9455665320161581,
      "grad_norm": 0.18948087096214294,
      "learning_rate": 1.7586556279913078e-05,
      "loss": 0.0905,
      "step": 97290
    },
    {
      "epoch": 1.9457665080190378,
      "grad_norm": 0.11723481863737106,
      "learning_rate": 1.758322334653175e-05,
      "loss": 0.0709,
      "step": 97300
    },
    {
      "epoch": 1.9459664840219175,
      "grad_norm": 0.09087830036878586,
      "learning_rate": 1.7579890413150424e-05,
      "loss": 0.0858,
      "step": 97310
    },
    {
      "epoch": 1.946166460024797,
      "grad_norm": 0.19576774537563324,
      "learning_rate": 1.7576557479769097e-05,
      "loss": 0.06,
      "step": 97320
    },
    {
      "epoch": 1.9463664360276767,
      "grad_norm": 0.1517200469970703,
      "learning_rate": 1.7573224546387766e-05,
      "loss": 0.037,
      "step": 97330
    },
    {
      "epoch": 1.9465664120305564,
      "grad_norm": 0.10419904440641403,
      "learning_rate": 1.756989161300644e-05,
      "loss": 0.0692,
      "step": 97340
    },
    {
      "epoch": 1.9467663880334358,
      "grad_norm": 0.1251002997159958,
      "learning_rate": 1.7566558679625112e-05,
      "loss": 0.0456,
      "step": 97350
    },
    {
      "epoch": 1.9469663640363155,
      "grad_norm": 0.14034119248390198,
      "learning_rate": 1.7563225746243785e-05,
      "loss": 0.066,
      "step": 97360
    },
    {
      "epoch": 1.9471663400391952,
      "grad_norm": 0.15475694835186005,
      "learning_rate": 1.7559892812862458e-05,
      "loss": 0.0483,
      "step": 97370
    },
    {
      "epoch": 1.9473663160420749,
      "grad_norm": 0.23773325979709625,
      "learning_rate": 1.755655987948113e-05,
      "loss": 0.083,
      "step": 97380
    },
    {
      "epoch": 1.9475662920449546,
      "grad_norm": 0.09279309213161469,
      "learning_rate": 1.75532269460998e-05,
      "loss": 0.0677,
      "step": 97390
    },
    {
      "epoch": 1.9477662680478343,
      "grad_norm": 0.07095010578632355,
      "learning_rate": 1.7549894012718474e-05,
      "loss": 0.0742,
      "step": 97400
    },
    {
      "epoch": 1.947966244050714,
      "grad_norm": 0.11897977441549301,
      "learning_rate": 1.7546561079337147e-05,
      "loss": 0.0649,
      "step": 97410
    },
    {
      "epoch": 1.9481662200535936,
      "grad_norm": 0.15435443818569183,
      "learning_rate": 1.754322814595582e-05,
      "loss": 0.0638,
      "step": 97420
    },
    {
      "epoch": 1.9483661960564733,
      "grad_norm": 0.1528691053390503,
      "learning_rate": 1.7539895212574493e-05,
      "loss": 0.0597,
      "step": 97430
    },
    {
      "epoch": 1.948566172059353,
      "grad_norm": 0.11068841814994812,
      "learning_rate": 1.7536562279193162e-05,
      "loss": 0.041,
      "step": 97440
    },
    {
      "epoch": 1.9487661480622327,
      "grad_norm": 0.06538566201925278,
      "learning_rate": 1.7533229345811835e-05,
      "loss": 0.0942,
      "step": 97450
    },
    {
      "epoch": 1.9489661240651122,
      "grad_norm": 0.09063415229320526,
      "learning_rate": 1.7529896412430512e-05,
      "loss": 0.084,
      "step": 97460
    },
    {
      "epoch": 1.9491661000679918,
      "grad_norm": 0.1802290976047516,
      "learning_rate": 1.752656347904918e-05,
      "loss": 0.0973,
      "step": 97470
    },
    {
      "epoch": 1.9493660760708715,
      "grad_norm": 0.13911598920822144,
      "learning_rate": 1.7523230545667855e-05,
      "loss": 0.1057,
      "step": 97480
    },
    {
      "epoch": 1.949566052073751,
      "grad_norm": 0.07896474003791809,
      "learning_rate": 1.7519897612286528e-05,
      "loss": 0.0614,
      "step": 97490
    },
    {
      "epoch": 1.9497660280766307,
      "grad_norm": 0.09377017617225647,
      "learning_rate": 1.7516564678905197e-05,
      "loss": 0.1199,
      "step": 97500
    },
    {
      "epoch": 1.9499660040795104,
      "grad_norm": 0.14029699563980103,
      "learning_rate": 1.7513231745523874e-05,
      "loss": 0.042,
      "step": 97510
    },
    {
      "epoch": 1.95016598008239,
      "grad_norm": 0.13022877275943756,
      "learning_rate": 1.7509898812142543e-05,
      "loss": 0.0629,
      "step": 97520
    },
    {
      "epoch": 1.9503659560852697,
      "grad_norm": 0.20799589157104492,
      "learning_rate": 1.7506565878761216e-05,
      "loss": 0.0798,
      "step": 97530
    },
    {
      "epoch": 1.9505659320881494,
      "grad_norm": 0.09078279137611389,
      "learning_rate": 1.750323294537989e-05,
      "loss": 0.054,
      "step": 97540
    },
    {
      "epoch": 1.9507659080910291,
      "grad_norm": 0.06610202044248581,
      "learning_rate": 1.749990001199856e-05,
      "loss": 0.0416,
      "step": 97550
    },
    {
      "epoch": 1.9509658840939088,
      "grad_norm": 0.2104002982378006,
      "learning_rate": 1.7496567078617235e-05,
      "loss": 0.054,
      "step": 97560
    },
    {
      "epoch": 1.9511658600967885,
      "grad_norm": 0.17079326510429382,
      "learning_rate": 1.7493234145235908e-05,
      "loss": 0.1313,
      "step": 97570
    },
    {
      "epoch": 1.9513658360996682,
      "grad_norm": 0.31470030546188354,
      "learning_rate": 1.7489901211854578e-05,
      "loss": 0.132,
      "step": 97580
    },
    {
      "epoch": 1.9515658121025476,
      "grad_norm": 0.11206423491239548,
      "learning_rate": 1.748656827847325e-05,
      "loss": 0.1184,
      "step": 97590
    },
    {
      "epoch": 1.9517657881054273,
      "grad_norm": 0.11317719519138336,
      "learning_rate": 1.7483235345091924e-05,
      "loss": 0.0874,
      "step": 97600
    },
    {
      "epoch": 1.951965764108307,
      "grad_norm": 0.13980069756507874,
      "learning_rate": 1.7479902411710597e-05,
      "loss": 0.0521,
      "step": 97610
    },
    {
      "epoch": 1.9521657401111867,
      "grad_norm": 0.10036450624465942,
      "learning_rate": 1.747656947832927e-05,
      "loss": 0.0903,
      "step": 97620
    },
    {
      "epoch": 1.9523657161140662,
      "grad_norm": 0.10831515491008759,
      "learning_rate": 1.747323654494794e-05,
      "loss": 0.0666,
      "step": 97630
    },
    {
      "epoch": 1.9525656921169459,
      "grad_norm": 0.2555607855319977,
      "learning_rate": 1.7469903611566612e-05,
      "loss": 0.1039,
      "step": 97640
    },
    {
      "epoch": 1.9527656681198255,
      "grad_norm": 0.2492363452911377,
      "learning_rate": 1.7466570678185285e-05,
      "loss": 0.103,
      "step": 97650
    },
    {
      "epoch": 1.9529656441227052,
      "grad_norm": 0.13005885481834412,
      "learning_rate": 1.7463237744803955e-05,
      "loss": 0.1068,
      "step": 97660
    },
    {
      "epoch": 1.953165620125585,
      "grad_norm": 0.07967808842658997,
      "learning_rate": 1.745990481142263e-05,
      "loss": 0.1106,
      "step": 97670
    },
    {
      "epoch": 1.9533655961284646,
      "grad_norm": 0.1620054692029953,
      "learning_rate": 1.7456571878041304e-05,
      "loss": 0.062,
      "step": 97680
    },
    {
      "epoch": 1.9535655721313443,
      "grad_norm": 0.19378487765789032,
      "learning_rate": 1.7453238944659974e-05,
      "loss": 0.066,
      "step": 97690
    },
    {
      "epoch": 1.953765548134224,
      "grad_norm": 0.0875496044754982,
      "learning_rate": 1.7449906011278647e-05,
      "loss": 0.0645,
      "step": 97700
    },
    {
      "epoch": 1.9539655241371037,
      "grad_norm": 0.22795170545578003,
      "learning_rate": 1.744657307789732e-05,
      "loss": 0.0638,
      "step": 97710
    },
    {
      "epoch": 1.9541655001399834,
      "grad_norm": 0.09659165889024734,
      "learning_rate": 1.7443240144515993e-05,
      "loss": 0.074,
      "step": 97720
    },
    {
      "epoch": 1.9543654761428628,
      "grad_norm": 0.06842206418514252,
      "learning_rate": 1.7439907211134666e-05,
      "loss": 0.065,
      "step": 97730
    },
    {
      "epoch": 1.9545654521457425,
      "grad_norm": 0.1557779163122177,
      "learning_rate": 1.7436574277753336e-05,
      "loss": 0.0582,
      "step": 97740
    },
    {
      "epoch": 1.9547654281486222,
      "grad_norm": 0.14565302431583405,
      "learning_rate": 1.743324134437201e-05,
      "loss": 0.0763,
      "step": 97750
    },
    {
      "epoch": 1.9549654041515017,
      "grad_norm": 0.11538901925086975,
      "learning_rate": 1.742990841099068e-05,
      "loss": 0.0671,
      "step": 97760
    },
    {
      "epoch": 1.9551653801543813,
      "grad_norm": 0.1689867377281189,
      "learning_rate": 1.7426575477609355e-05,
      "loss": 0.0843,
      "step": 97770
    },
    {
      "epoch": 1.955365356157261,
      "grad_norm": 0.17285864055156708,
      "learning_rate": 1.7423242544228028e-05,
      "loss": 0.0632,
      "step": 97780
    },
    {
      "epoch": 1.9555653321601407,
      "grad_norm": 0.09375283867120743,
      "learning_rate": 1.74199096108467e-05,
      "loss": 0.0863,
      "step": 97790
    },
    {
      "epoch": 1.9557653081630204,
      "grad_norm": 0.15664297342300415,
      "learning_rate": 1.741657667746537e-05,
      "loss": 0.0459,
      "step": 97800
    },
    {
      "epoch": 1.9559652841659,
      "grad_norm": 0.06421802937984467,
      "learning_rate": 1.7413243744084043e-05,
      "loss": 0.0823,
      "step": 97810
    },
    {
      "epoch": 1.9561652601687798,
      "grad_norm": 0.09274716675281525,
      "learning_rate": 1.7409910810702716e-05,
      "loss": 0.0707,
      "step": 97820
    },
    {
      "epoch": 1.9563652361716595,
      "grad_norm": 0.2060730755329132,
      "learning_rate": 1.740657787732139e-05,
      "loss": 0.115,
      "step": 97830
    },
    {
      "epoch": 1.9565652121745392,
      "grad_norm": 0.05803488567471504,
      "learning_rate": 1.7403244943940062e-05,
      "loss": 0.0643,
      "step": 97840
    },
    {
      "epoch": 1.9567651881774188,
      "grad_norm": 0.18067575991153717,
      "learning_rate": 1.7399912010558732e-05,
      "loss": 0.093,
      "step": 97850
    },
    {
      "epoch": 1.9569651641802983,
      "grad_norm": 0.06155019998550415,
      "learning_rate": 1.7396579077177405e-05,
      "loss": 0.0524,
      "step": 97860
    },
    {
      "epoch": 1.957165140183178,
      "grad_norm": 0.15923462808132172,
      "learning_rate": 1.739324614379608e-05,
      "loss": 0.0591,
      "step": 97870
    },
    {
      "epoch": 1.9573651161860577,
      "grad_norm": 0.256595253944397,
      "learning_rate": 1.738991321041475e-05,
      "loss": 0.1033,
      "step": 97880
    },
    {
      "epoch": 1.9575650921889374,
      "grad_norm": 0.07990972697734833,
      "learning_rate": 1.7386580277033424e-05,
      "loss": 0.0592,
      "step": 97890
    },
    {
      "epoch": 1.9577650681918168,
      "grad_norm": 0.1179424524307251,
      "learning_rate": 1.7383247343652097e-05,
      "loss": 0.0585,
      "step": 97900
    },
    {
      "epoch": 1.9579650441946965,
      "grad_norm": 0.059091489762067795,
      "learning_rate": 1.7379914410270767e-05,
      "loss": 0.0452,
      "step": 97910
    },
    {
      "epoch": 1.9581650201975762,
      "grad_norm": 0.09473702311515808,
      "learning_rate": 1.7376581476889443e-05,
      "loss": 0.0732,
      "step": 97920
    },
    {
      "epoch": 1.958364996200456,
      "grad_norm": 0.10118038207292557,
      "learning_rate": 1.7373248543508113e-05,
      "loss": 0.0753,
      "step": 97930
    },
    {
      "epoch": 1.9585649722033356,
      "grad_norm": 0.13683292269706726,
      "learning_rate": 1.7369915610126786e-05,
      "loss": 0.0665,
      "step": 97940
    },
    {
      "epoch": 1.9587649482062153,
      "grad_norm": 0.11499928683042526,
      "learning_rate": 1.736658267674546e-05,
      "loss": 0.042,
      "step": 97950
    },
    {
      "epoch": 1.958964924209095,
      "grad_norm": 0.12529198825359344,
      "learning_rate": 1.7363249743364128e-05,
      "loss": 0.0864,
      "step": 97960
    },
    {
      "epoch": 1.9591649002119746,
      "grad_norm": 0.06507518142461777,
      "learning_rate": 1.7359916809982805e-05,
      "loss": 0.0673,
      "step": 97970
    },
    {
      "epoch": 1.9593648762148543,
      "grad_norm": 0.1743735671043396,
      "learning_rate": 1.7356583876601478e-05,
      "loss": 0.0925,
      "step": 97980
    },
    {
      "epoch": 1.959564852217734,
      "grad_norm": 0.05578020215034485,
      "learning_rate": 1.7353250943220147e-05,
      "loss": 0.0783,
      "step": 97990
    },
    {
      "epoch": 1.9597648282206135,
      "grad_norm": 0.13693057000637054,
      "learning_rate": 1.734991800983882e-05,
      "loss": 0.0669,
      "step": 98000
    },
    {
      "epoch": 1.9599648042234932,
      "grad_norm": 0.11487060785293579,
      "learning_rate": 1.7346585076457493e-05,
      "loss": 0.0608,
      "step": 98010
    },
    {
      "epoch": 1.9601647802263729,
      "grad_norm": 0.1173839345574379,
      "learning_rate": 1.7343252143076166e-05,
      "loss": 0.0572,
      "step": 98020
    },
    {
      "epoch": 1.9603647562292523,
      "grad_norm": 0.11334226280450821,
      "learning_rate": 1.733991920969484e-05,
      "loss": 0.0593,
      "step": 98030
    },
    {
      "epoch": 1.960564732232132,
      "grad_norm": 0.1459667980670929,
      "learning_rate": 1.733658627631351e-05,
      "loss": 0.0568,
      "step": 98040
    },
    {
      "epoch": 1.9607647082350117,
      "grad_norm": 0.14963731169700623,
      "learning_rate": 1.7333253342932182e-05,
      "loss": 0.0665,
      "step": 98050
    },
    {
      "epoch": 1.9609646842378914,
      "grad_norm": 0.1578548103570938,
      "learning_rate": 1.7329920409550855e-05,
      "loss": 0.0465,
      "step": 98060
    },
    {
      "epoch": 1.961164660240771,
      "grad_norm": 0.16308651864528656,
      "learning_rate": 1.7326587476169528e-05,
      "loss": 0.057,
      "step": 98070
    },
    {
      "epoch": 1.9613646362436508,
      "grad_norm": 0.13176554441452026,
      "learning_rate": 1.73232545427882e-05,
      "loss": 0.1335,
      "step": 98080
    },
    {
      "epoch": 1.9615646122465304,
      "grad_norm": 0.15404173731803894,
      "learning_rate": 1.7319921609406874e-05,
      "loss": 0.0652,
      "step": 98090
    },
    {
      "epoch": 1.9617645882494101,
      "grad_norm": 0.07833392173051834,
      "learning_rate": 1.7316588676025543e-05,
      "loss": 0.0672,
      "step": 98100
    },
    {
      "epoch": 1.9619645642522898,
      "grad_norm": 0.1300283819437027,
      "learning_rate": 1.7313255742644216e-05,
      "loss": 0.0716,
      "step": 98110
    },
    {
      "epoch": 1.9621645402551695,
      "grad_norm": 0.19717946648597717,
      "learning_rate": 1.730992280926289e-05,
      "loss": 0.0885,
      "step": 98120
    },
    {
      "epoch": 1.9623645162580492,
      "grad_norm": 0.05898464471101761,
      "learning_rate": 1.7306589875881562e-05,
      "loss": 0.1041,
      "step": 98130
    },
    {
      "epoch": 1.9625644922609287,
      "grad_norm": 0.09588143974542618,
      "learning_rate": 1.7303256942500236e-05,
      "loss": 0.1079,
      "step": 98140
    },
    {
      "epoch": 1.9627644682638083,
      "grad_norm": 0.10159862041473389,
      "learning_rate": 1.7299924009118905e-05,
      "loss": 0.0785,
      "step": 98150
    },
    {
      "epoch": 1.962964444266688,
      "grad_norm": 0.08775052428245544,
      "learning_rate": 1.7296591075737578e-05,
      "loss": 0.0681,
      "step": 98160
    },
    {
      "epoch": 1.9631644202695675,
      "grad_norm": 0.09270603209733963,
      "learning_rate": 1.729325814235625e-05,
      "loss": 0.0528,
      "step": 98170
    },
    {
      "epoch": 1.9633643962724472,
      "grad_norm": 0.11343467980623245,
      "learning_rate": 1.7289925208974924e-05,
      "loss": 0.0921,
      "step": 98180
    },
    {
      "epoch": 1.9635643722753269,
      "grad_norm": 0.08610819280147552,
      "learning_rate": 1.7286592275593597e-05,
      "loss": 0.1047,
      "step": 98190
    },
    {
      "epoch": 1.9637643482782066,
      "grad_norm": 0.11817426234483719,
      "learning_rate": 1.728325934221227e-05,
      "loss": 0.0797,
      "step": 98200
    },
    {
      "epoch": 1.9639643242810862,
      "grad_norm": 0.10127118229866028,
      "learning_rate": 1.727992640883094e-05,
      "loss": 0.0595,
      "step": 98210
    },
    {
      "epoch": 1.964164300283966,
      "grad_norm": 0.14145460724830627,
      "learning_rate": 1.7276593475449613e-05,
      "loss": 0.0686,
      "step": 98220
    },
    {
      "epoch": 1.9643642762868456,
      "grad_norm": 0.2639617621898651,
      "learning_rate": 1.7273260542068286e-05,
      "loss": 0.1025,
      "step": 98230
    },
    {
      "epoch": 1.9645642522897253,
      "grad_norm": 0.09493222832679749,
      "learning_rate": 1.726992760868696e-05,
      "loss": 0.0481,
      "step": 98240
    },
    {
      "epoch": 1.964764228292605,
      "grad_norm": 0.09447638690471649,
      "learning_rate": 1.7266594675305632e-05,
      "loss": 0.0697,
      "step": 98250
    },
    {
      "epoch": 1.9649642042954847,
      "grad_norm": 0.07997839152812958,
      "learning_rate": 1.72632617419243e-05,
      "loss": 0.0297,
      "step": 98260
    },
    {
      "epoch": 1.9651641802983641,
      "grad_norm": 0.15407852828502655,
      "learning_rate": 1.7259928808542974e-05,
      "loss": 0.0651,
      "step": 98270
    },
    {
      "epoch": 1.9653641563012438,
      "grad_norm": 0.2179649919271469,
      "learning_rate": 1.725659587516165e-05,
      "loss": 0.0637,
      "step": 98280
    },
    {
      "epoch": 1.9655641323041235,
      "grad_norm": 0.07574957609176636,
      "learning_rate": 1.725326294178032e-05,
      "loss": 0.0485,
      "step": 98290
    },
    {
      "epoch": 1.9657641083070032,
      "grad_norm": 0.09827527403831482,
      "learning_rate": 1.7249930008398993e-05,
      "loss": 0.0736,
      "step": 98300
    },
    {
      "epoch": 1.9659640843098827,
      "grad_norm": 0.1535576730966568,
      "learning_rate": 1.7246597075017666e-05,
      "loss": 0.0859,
      "step": 98310
    },
    {
      "epoch": 1.9661640603127624,
      "grad_norm": 0.11696261912584305,
      "learning_rate": 1.7243264141636336e-05,
      "loss": 0.0632,
      "step": 98320
    },
    {
      "epoch": 1.966364036315642,
      "grad_norm": 0.11479277163743973,
      "learning_rate": 1.7239931208255012e-05,
      "loss": 0.0434,
      "step": 98330
    },
    {
      "epoch": 1.9665640123185217,
      "grad_norm": 0.11264389008283615,
      "learning_rate": 1.7236598274873682e-05,
      "loss": 0.0906,
      "step": 98340
    },
    {
      "epoch": 1.9667639883214014,
      "grad_norm": 0.09719034284353256,
      "learning_rate": 1.7233265341492355e-05,
      "loss": 0.0857,
      "step": 98350
    },
    {
      "epoch": 1.9669639643242811,
      "grad_norm": 0.18219012022018433,
      "learning_rate": 1.7229932408111028e-05,
      "loss": 0.1019,
      "step": 98360
    },
    {
      "epoch": 1.9671639403271608,
      "grad_norm": 0.09899501502513885,
      "learning_rate": 1.7226599474729698e-05,
      "loss": 0.0963,
      "step": 98370
    },
    {
      "epoch": 1.9673639163300405,
      "grad_norm": 0.2348669171333313,
      "learning_rate": 1.7223266541348374e-05,
      "loss": 0.0742,
      "step": 98380
    },
    {
      "epoch": 1.9675638923329202,
      "grad_norm": 0.08268148452043533,
      "learning_rate": 1.7219933607967044e-05,
      "loss": 0.0757,
      "step": 98390
    },
    {
      "epoch": 1.9677638683357999,
      "grad_norm": 0.14407570660114288,
      "learning_rate": 1.7216600674585717e-05,
      "loss": 0.0698,
      "step": 98400
    },
    {
      "epoch": 1.9679638443386793,
      "grad_norm": 0.22900941967964172,
      "learning_rate": 1.721326774120439e-05,
      "loss": 0.0599,
      "step": 98410
    },
    {
      "epoch": 1.968163820341559,
      "grad_norm": 0.13589785993099213,
      "learning_rate": 1.7209934807823063e-05,
      "loss": 0.0487,
      "step": 98420
    },
    {
      "epoch": 1.9683637963444387,
      "grad_norm": 0.1207328736782074,
      "learning_rate": 1.7206601874441736e-05,
      "loss": 0.0517,
      "step": 98430
    },
    {
      "epoch": 1.9685637723473182,
      "grad_norm": 0.06742092967033386,
      "learning_rate": 1.720326894106041e-05,
      "loss": 0.0999,
      "step": 98440
    },
    {
      "epoch": 1.9687637483501979,
      "grad_norm": 0.0748569592833519,
      "learning_rate": 1.7199936007679078e-05,
      "loss": 0.0721,
      "step": 98450
    },
    {
      "epoch": 1.9689637243530775,
      "grad_norm": 0.1382356584072113,
      "learning_rate": 1.719660307429775e-05,
      "loss": 0.0679,
      "step": 98460
    },
    {
      "epoch": 1.9691637003559572,
      "grad_norm": 0.07502742856740952,
      "learning_rate": 1.7193270140916424e-05,
      "loss": 0.0712,
      "step": 98470
    },
    {
      "epoch": 1.969363676358837,
      "grad_norm": 0.21791556477546692,
      "learning_rate": 1.7189937207535097e-05,
      "loss": 0.1158,
      "step": 98480
    },
    {
      "epoch": 1.9695636523617166,
      "grad_norm": 0.17255628108978271,
      "learning_rate": 1.718660427415377e-05,
      "loss": 0.083,
      "step": 98490
    },
    {
      "epoch": 1.9697636283645963,
      "grad_norm": 0.1112082451581955,
      "learning_rate": 1.718327134077244e-05,
      "loss": 0.0669,
      "step": 98500
    },
    {
      "epoch": 1.969963604367476,
      "grad_norm": 0.11339613795280457,
      "learning_rate": 1.7179938407391113e-05,
      "loss": 0.0507,
      "step": 98510
    },
    {
      "epoch": 1.9701635803703557,
      "grad_norm": 0.21028870344161987,
      "learning_rate": 1.7176605474009786e-05,
      "loss": 0.0919,
      "step": 98520
    },
    {
      "epoch": 1.9703635563732353,
      "grad_norm": 0.21109987795352936,
      "learning_rate": 1.717327254062846e-05,
      "loss": 0.0671,
      "step": 98530
    },
    {
      "epoch": 1.9705635323761148,
      "grad_norm": 0.14836567640304565,
      "learning_rate": 1.7169939607247132e-05,
      "loss": 0.0824,
      "step": 98540
    },
    {
      "epoch": 1.9707635083789945,
      "grad_norm": 0.13272081315517426,
      "learning_rate": 1.7166606673865805e-05,
      "loss": 0.0524,
      "step": 98550
    },
    {
      "epoch": 1.9709634843818742,
      "grad_norm": 0.18085865676403046,
      "learning_rate": 1.7163273740484475e-05,
      "loss": 0.0678,
      "step": 98560
    },
    {
      "epoch": 1.9711634603847539,
      "grad_norm": 0.07841890305280685,
      "learning_rate": 1.7159940807103148e-05,
      "loss": 0.0267,
      "step": 98570
    },
    {
      "epoch": 1.9713634363876333,
      "grad_norm": 0.1347631961107254,
      "learning_rate": 1.715660787372182e-05,
      "loss": 0.0972,
      "step": 98580
    },
    {
      "epoch": 1.971563412390513,
      "grad_norm": 0.18184088170528412,
      "learning_rate": 1.7153274940340494e-05,
      "loss": 0.0856,
      "step": 98590
    },
    {
      "epoch": 1.9717633883933927,
      "grad_norm": 0.10717189311981201,
      "learning_rate": 1.7149942006959167e-05,
      "loss": 0.0595,
      "step": 98600
    },
    {
      "epoch": 1.9719633643962724,
      "grad_norm": 0.12134190648794174,
      "learning_rate": 1.7146609073577836e-05,
      "loss": 0.103,
      "step": 98610
    },
    {
      "epoch": 1.972163340399152,
      "grad_norm": 0.10614214092493057,
      "learning_rate": 1.714327614019651e-05,
      "loss": 0.0544,
      "step": 98620
    },
    {
      "epoch": 1.9723633164020318,
      "grad_norm": 0.14816102385520935,
      "learning_rate": 1.7139943206815182e-05,
      "loss": 0.0958,
      "step": 98630
    },
    {
      "epoch": 1.9725632924049115,
      "grad_norm": 0.19149518013000488,
      "learning_rate": 1.7136610273433855e-05,
      "loss": 0.0777,
      "step": 98640
    },
    {
      "epoch": 1.9727632684077911,
      "grad_norm": 0.13398075103759766,
      "learning_rate": 1.7133277340052528e-05,
      "loss": 0.0791,
      "step": 98650
    },
    {
      "epoch": 1.9729632444106708,
      "grad_norm": 0.07923692464828491,
      "learning_rate": 1.71299444066712e-05,
      "loss": 0.0748,
      "step": 98660
    },
    {
      "epoch": 1.9731632204135505,
      "grad_norm": 0.1575206071138382,
      "learning_rate": 1.712661147328987e-05,
      "loss": 0.0793,
      "step": 98670
    },
    {
      "epoch": 1.97336319641643,
      "grad_norm": 0.12093941867351532,
      "learning_rate": 1.7123278539908544e-05,
      "loss": 0.0665,
      "step": 98680
    },
    {
      "epoch": 1.9735631724193097,
      "grad_norm": 0.09009349346160889,
      "learning_rate": 1.7119945606527217e-05,
      "loss": 0.0705,
      "step": 98690
    },
    {
      "epoch": 1.9737631484221894,
      "grad_norm": 0.11143046617507935,
      "learning_rate": 1.711661267314589e-05,
      "loss": 0.0531,
      "step": 98700
    },
    {
      "epoch": 1.9739631244250688,
      "grad_norm": 0.12535986304283142,
      "learning_rate": 1.7113279739764563e-05,
      "loss": 0.0477,
      "step": 98710
    },
    {
      "epoch": 1.9741631004279485,
      "grad_norm": 0.08091622591018677,
      "learning_rate": 1.7109946806383232e-05,
      "loss": 0.1232,
      "step": 98720
    },
    {
      "epoch": 1.9743630764308282,
      "grad_norm": 0.26201847195625305,
      "learning_rate": 1.7106613873001905e-05,
      "loss": 0.0692,
      "step": 98730
    },
    {
      "epoch": 1.9745630524337079,
      "grad_norm": 0.21109716594219208,
      "learning_rate": 1.7103280939620582e-05,
      "loss": 0.066,
      "step": 98740
    },
    {
      "epoch": 1.9747630284365876,
      "grad_norm": 0.11272162944078445,
      "learning_rate": 1.709994800623925e-05,
      "loss": 0.042,
      "step": 98750
    },
    {
      "epoch": 1.9749630044394673,
      "grad_norm": 0.1727108359336853,
      "learning_rate": 1.7096615072857924e-05,
      "loss": 0.0648,
      "step": 98760
    },
    {
      "epoch": 1.975162980442347,
      "grad_norm": 0.13399046659469604,
      "learning_rate": 1.7093282139476597e-05,
      "loss": 0.0462,
      "step": 98770
    },
    {
      "epoch": 1.9753629564452266,
      "grad_norm": 0.10572260618209839,
      "learning_rate": 1.7089949206095267e-05,
      "loss": 0.0618,
      "step": 98780
    },
    {
      "epoch": 1.9755629324481063,
      "grad_norm": 0.15623031556606293,
      "learning_rate": 1.7086616272713943e-05,
      "loss": 0.2104,
      "step": 98790
    },
    {
      "epoch": 1.975762908450986,
      "grad_norm": 0.12662053108215332,
      "learning_rate": 1.7083283339332613e-05,
      "loss": 0.0854,
      "step": 98800
    },
    {
      "epoch": 1.9759628844538657,
      "grad_norm": 0.11253628134727478,
      "learning_rate": 1.7079950405951286e-05,
      "loss": 0.0669,
      "step": 98810
    },
    {
      "epoch": 1.9761628604567452,
      "grad_norm": 0.05982564017176628,
      "learning_rate": 1.707661747256996e-05,
      "loss": 0.0667,
      "step": 98820
    },
    {
      "epoch": 1.9763628364596248,
      "grad_norm": 0.11982857435941696,
      "learning_rate": 1.707328453918863e-05,
      "loss": 0.0632,
      "step": 98830
    },
    {
      "epoch": 1.9765628124625045,
      "grad_norm": 0.07782310992479324,
      "learning_rate": 1.7069951605807305e-05,
      "loss": 0.0771,
      "step": 98840
    },
    {
      "epoch": 1.976762788465384,
      "grad_norm": 0.15878964960575104,
      "learning_rate": 1.7066618672425978e-05,
      "loss": 0.0638,
      "step": 98850
    },
    {
      "epoch": 1.9769627644682637,
      "grad_norm": 0.18543444573879242,
      "learning_rate": 1.7063285739044648e-05,
      "loss": 0.1036,
      "step": 98860
    },
    {
      "epoch": 1.9771627404711434,
      "grad_norm": 0.1608155518770218,
      "learning_rate": 1.705995280566332e-05,
      "loss": 0.0872,
      "step": 98870
    },
    {
      "epoch": 1.977362716474023,
      "grad_norm": 0.1843183934688568,
      "learning_rate": 1.7056619872281994e-05,
      "loss": 0.0776,
      "step": 98880
    },
    {
      "epoch": 1.9775626924769028,
      "grad_norm": 0.1768927276134491,
      "learning_rate": 1.7053286938900667e-05,
      "loss": 0.0869,
      "step": 98890
    },
    {
      "epoch": 1.9777626684797824,
      "grad_norm": 0.13215197622776031,
      "learning_rate": 1.704995400551934e-05,
      "loss": 0.067,
      "step": 98900
    },
    {
      "epoch": 1.9779626444826621,
      "grad_norm": 0.1903601437807083,
      "learning_rate": 1.7046954365476145e-05,
      "loss": 0.0729,
      "step": 98910
    },
    {
      "epoch": 1.9781626204855418,
      "grad_norm": 0.1393885612487793,
      "learning_rate": 1.7043621432094818e-05,
      "loss": 0.064,
      "step": 98920
    },
    {
      "epoch": 1.9783625964884215,
      "grad_norm": 0.14319837093353271,
      "learning_rate": 1.7040288498713488e-05,
      "loss": 0.0674,
      "step": 98930
    },
    {
      "epoch": 1.9785625724913012,
      "grad_norm": 0.0709628090262413,
      "learning_rate": 1.703695556533216e-05,
      "loss": 0.0832,
      "step": 98940
    },
    {
      "epoch": 1.9787625484941807,
      "grad_norm": 0.2184717357158661,
      "learning_rate": 1.7033622631950834e-05,
      "loss": 0.0606,
      "step": 98950
    },
    {
      "epoch": 1.9789625244970603,
      "grad_norm": 0.21958239376544952,
      "learning_rate": 1.7030289698569507e-05,
      "loss": 0.0775,
      "step": 98960
    },
    {
      "epoch": 1.97916250049994,
      "grad_norm": 0.0672193318605423,
      "learning_rate": 1.702695676518818e-05,
      "loss": 0.0649,
      "step": 98970
    },
    {
      "epoch": 1.9793624765028197,
      "grad_norm": 0.24822837114334106,
      "learning_rate": 1.702362383180685e-05,
      "loss": 0.0982,
      "step": 98980
    },
    {
      "epoch": 1.9795624525056992,
      "grad_norm": 0.09340181946754456,
      "learning_rate": 1.7020290898425522e-05,
      "loss": 0.0789,
      "step": 98990
    },
    {
      "epoch": 1.9797624285085789,
      "grad_norm": 0.18759623169898987,
      "learning_rate": 1.7016957965044195e-05,
      "loss": 0.0712,
      "step": 99000
    },
    {
      "epoch": 1.9799624045114586,
      "grad_norm": 0.16954012215137482,
      "learning_rate": 1.701362503166287e-05,
      "loss": 0.054,
      "step": 99010
    },
    {
      "epoch": 1.9801623805143382,
      "grad_norm": 0.21559417247772217,
      "learning_rate": 1.701029209828154e-05,
      "loss": 0.1345,
      "step": 99020
    },
    {
      "epoch": 1.980362356517218,
      "grad_norm": 0.25640037655830383,
      "learning_rate": 1.7006959164900214e-05,
      "loss": 0.0961,
      "step": 99030
    },
    {
      "epoch": 1.9805623325200976,
      "grad_norm": 0.12012999504804611,
      "learning_rate": 1.7003626231518884e-05,
      "loss": 0.0575,
      "step": 99040
    },
    {
      "epoch": 1.9807623085229773,
      "grad_norm": 0.1338677555322647,
      "learning_rate": 1.7000293298137557e-05,
      "loss": 0.0856,
      "step": 99050
    },
    {
      "epoch": 1.980962284525857,
      "grad_norm": 0.09335421770811081,
      "learning_rate": 1.699696036475623e-05,
      "loss": 0.0743,
      "step": 99060
    },
    {
      "epoch": 1.9811622605287367,
      "grad_norm": 0.1052045226097107,
      "learning_rate": 1.6993627431374903e-05,
      "loss": 0.105,
      "step": 99070
    },
    {
      "epoch": 1.9813622365316164,
      "grad_norm": 0.06129704788327217,
      "learning_rate": 1.6990294497993576e-05,
      "loss": 0.0699,
      "step": 99080
    },
    {
      "epoch": 1.9815622125344958,
      "grad_norm": 0.10934251546859741,
      "learning_rate": 1.6986961564612246e-05,
      "loss": 0.0821,
      "step": 99090
    },
    {
      "epoch": 1.9817621885373755,
      "grad_norm": 0.1529807150363922,
      "learning_rate": 1.698362863123092e-05,
      "loss": 0.0596,
      "step": 99100
    },
    {
      "epoch": 1.9819621645402552,
      "grad_norm": 0.19433553516864777,
      "learning_rate": 1.698029569784959e-05,
      "loss": 0.0736,
      "step": 99110
    },
    {
      "epoch": 1.9821621405431347,
      "grad_norm": 0.14492164552211761,
      "learning_rate": 1.6976962764468265e-05,
      "loss": 0.0703,
      "step": 99120
    },
    {
      "epoch": 1.9823621165460144,
      "grad_norm": 0.1005840003490448,
      "learning_rate": 1.6973629831086938e-05,
      "loss": 0.0495,
      "step": 99130
    },
    {
      "epoch": 1.982562092548894,
      "grad_norm": 0.11703471839427948,
      "learning_rate": 1.697029689770561e-05,
      "loss": 0.0628,
      "step": 99140
    },
    {
      "epoch": 1.9827620685517737,
      "grad_norm": 0.10726924985647202,
      "learning_rate": 1.696696396432428e-05,
      "loss": 0.0659,
      "step": 99150
    },
    {
      "epoch": 1.9829620445546534,
      "grad_norm": 0.23037633299827576,
      "learning_rate": 1.6963631030942953e-05,
      "loss": 0.0961,
      "step": 99160
    },
    {
      "epoch": 1.983162020557533,
      "grad_norm": 0.07613358646631241,
      "learning_rate": 1.6960298097561626e-05,
      "loss": 0.0625,
      "step": 99170
    },
    {
      "epoch": 1.9833619965604128,
      "grad_norm": 0.17841310799121857,
      "learning_rate": 1.69569651641803e-05,
      "loss": 0.088,
      "step": 99180
    },
    {
      "epoch": 1.9835619725632925,
      "grad_norm": 0.0817912146449089,
      "learning_rate": 1.6953632230798972e-05,
      "loss": 0.0842,
      "step": 99190
    },
    {
      "epoch": 1.9837619485661722,
      "grad_norm": 0.12537646293640137,
      "learning_rate": 1.6950299297417642e-05,
      "loss": 0.059,
      "step": 99200
    },
    {
      "epoch": 1.9839619245690518,
      "grad_norm": 0.16396008431911469,
      "learning_rate": 1.6946966364036315e-05,
      "loss": 0.0724,
      "step": 99210
    },
    {
      "epoch": 1.9841619005719313,
      "grad_norm": 0.21284227073192596,
      "learning_rate": 1.694363343065499e-05,
      "loss": 0.0701,
      "step": 99220
    },
    {
      "epoch": 1.984361876574811,
      "grad_norm": 0.182418555021286,
      "learning_rate": 1.694030049727366e-05,
      "loss": 0.0424,
      "step": 99230
    },
    {
      "epoch": 1.9845618525776907,
      "grad_norm": 0.0786675214767456,
      "learning_rate": 1.6936967563892334e-05,
      "loss": 0.0668,
      "step": 99240
    },
    {
      "epoch": 1.9847618285805704,
      "grad_norm": 0.08336333930492401,
      "learning_rate": 1.6933634630511007e-05,
      "loss": 0.0545,
      "step": 99250
    },
    {
      "epoch": 1.9849618045834498,
      "grad_norm": 0.11402978003025055,
      "learning_rate": 1.6930301697129677e-05,
      "loss": 0.069,
      "step": 99260
    },
    {
      "epoch": 1.9851617805863295,
      "grad_norm": 0.16696660220623016,
      "learning_rate": 1.6926968763748353e-05,
      "loss": 0.0697,
      "step": 99270
    },
    {
      "epoch": 1.9853617565892092,
      "grad_norm": 0.0854642316699028,
      "learning_rate": 1.6923635830367023e-05,
      "loss": 0.065,
      "step": 99280
    },
    {
      "epoch": 1.985561732592089,
      "grad_norm": 0.13158653676509857,
      "learning_rate": 1.6920302896985696e-05,
      "loss": 0.0675,
      "step": 99290
    },
    {
      "epoch": 1.9857617085949686,
      "grad_norm": 0.13766920566558838,
      "learning_rate": 1.691696996360437e-05,
      "loss": 0.0863,
      "step": 99300
    },
    {
      "epoch": 1.9859616845978483,
      "grad_norm": 0.2480912208557129,
      "learning_rate": 1.6913637030223038e-05,
      "loss": 0.0913,
      "step": 99310
    },
    {
      "epoch": 1.986161660600728,
      "grad_norm": 0.17328105866909027,
      "learning_rate": 1.6910304096841715e-05,
      "loss": 0.0761,
      "step": 99320
    },
    {
      "epoch": 1.9863616366036076,
      "grad_norm": 0.18147031962871552,
      "learning_rate": 1.6906971163460388e-05,
      "loss": 0.1052,
      "step": 99330
    },
    {
      "epoch": 1.9865616126064873,
      "grad_norm": 0.10178451985120773,
      "learning_rate": 1.6903638230079057e-05,
      "loss": 0.0637,
      "step": 99340
    },
    {
      "epoch": 1.986761588609367,
      "grad_norm": 0.12618300318717957,
      "learning_rate": 1.690030529669773e-05,
      "loss": 0.1893,
      "step": 99350
    },
    {
      "epoch": 1.9869615646122465,
      "grad_norm": 0.19448603689670563,
      "learning_rate": 1.6896972363316403e-05,
      "loss": 0.0642,
      "step": 99360
    },
    {
      "epoch": 1.9871615406151262,
      "grad_norm": 0.08736970275640488,
      "learning_rate": 1.6893639429935076e-05,
      "loss": 0.0573,
      "step": 99370
    },
    {
      "epoch": 1.9873615166180059,
      "grad_norm": 0.19723275303840637,
      "learning_rate": 1.689030649655375e-05,
      "loss": 0.0737,
      "step": 99380
    },
    {
      "epoch": 1.9875614926208853,
      "grad_norm": 0.08747176080942154,
      "learning_rate": 1.688697356317242e-05,
      "loss": 0.0499,
      "step": 99390
    },
    {
      "epoch": 1.987761468623765,
      "grad_norm": 0.06771595776081085,
      "learning_rate": 1.6883640629791092e-05,
      "loss": 0.0698,
      "step": 99400
    },
    {
      "epoch": 1.9879614446266447,
      "grad_norm": 0.25206366181373596,
      "learning_rate": 1.6880307696409765e-05,
      "loss": 0.1057,
      "step": 99410
    },
    {
      "epoch": 1.9881614206295244,
      "grad_norm": 0.19637706875801086,
      "learning_rate": 1.6876974763028438e-05,
      "loss": 0.0572,
      "step": 99420
    },
    {
      "epoch": 1.988361396632404,
      "grad_norm": 0.19756677746772766,
      "learning_rate": 1.687364182964711e-05,
      "loss": 0.0773,
      "step": 99430
    },
    {
      "epoch": 1.9885613726352838,
      "grad_norm": 0.2253294140100479,
      "learning_rate": 1.6870308896265784e-05,
      "loss": 0.0694,
      "step": 99440
    },
    {
      "epoch": 1.9887613486381635,
      "grad_norm": 0.13390512764453888,
      "learning_rate": 1.6866975962884453e-05,
      "loss": 0.059,
      "step": 99450
    },
    {
      "epoch": 1.9889613246410431,
      "grad_norm": 0.20745772123336792,
      "learning_rate": 1.6863643029503126e-05,
      "loss": 0.1191,
      "step": 99460
    },
    {
      "epoch": 1.9891613006439228,
      "grad_norm": 0.06264006346464157,
      "learning_rate": 1.68603100961218e-05,
      "loss": 0.0707,
      "step": 99470
    },
    {
      "epoch": 1.9893612766468025,
      "grad_norm": 0.1151011511683464,
      "learning_rate": 1.6856977162740472e-05,
      "loss": 0.0352,
      "step": 99480
    },
    {
      "epoch": 1.9895612526496822,
      "grad_norm": 0.16076433658599854,
      "learning_rate": 1.6853644229359145e-05,
      "loss": 0.0757,
      "step": 99490
    },
    {
      "epoch": 1.9897612286525617,
      "grad_norm": 0.05561475455760956,
      "learning_rate": 1.6850311295977815e-05,
      "loss": 0.5353,
      "step": 99500
    },
    {
      "epoch": 1.9899612046554414,
      "grad_norm": 0.09514497220516205,
      "learning_rate": 1.6846978362596488e-05,
      "loss": 0.0619,
      "step": 99510
    },
    {
      "epoch": 1.990161180658321,
      "grad_norm": 0.21378950774669647,
      "learning_rate": 1.6843645429215164e-05,
      "loss": 0.0926,
      "step": 99520
    },
    {
      "epoch": 1.9903611566612005,
      "grad_norm": 0.2607273757457733,
      "learning_rate": 1.6840312495833834e-05,
      "loss": 0.0733,
      "step": 99530
    },
    {
      "epoch": 1.9905611326640802,
      "grad_norm": 0.1300676316022873,
      "learning_rate": 1.6836979562452507e-05,
      "loss": 0.0635,
      "step": 99540
    },
    {
      "epoch": 1.9907611086669599,
      "grad_norm": 0.19682712852954865,
      "learning_rate": 1.683364662907118e-05,
      "loss": 0.0643,
      "step": 99550
    },
    {
      "epoch": 1.9909610846698396,
      "grad_norm": 0.09241548180580139,
      "learning_rate": 1.683031369568985e-05,
      "loss": 0.314,
      "step": 99560
    },
    {
      "epoch": 1.9911610606727193,
      "grad_norm": 0.13026288151741028,
      "learning_rate": 1.6826980762308526e-05,
      "loss": 0.0694,
      "step": 99570
    },
    {
      "epoch": 1.991361036675599,
      "grad_norm": 0.12216410785913467,
      "learning_rate": 1.6823647828927196e-05,
      "loss": 0.075,
      "step": 99580
    },
    {
      "epoch": 1.9915610126784786,
      "grad_norm": 0.20056003332138062,
      "learning_rate": 1.682031489554587e-05,
      "loss": 0.0697,
      "step": 99590
    },
    {
      "epoch": 1.9917609886813583,
      "grad_norm": 0.070880226790905,
      "learning_rate": 1.6816981962164542e-05,
      "loss": 0.0405,
      "step": 99600
    },
    {
      "epoch": 1.991960964684238,
      "grad_norm": 0.25242879986763,
      "learning_rate": 1.681364902878321e-05,
      "loss": 0.1962,
      "step": 99610
    },
    {
      "epoch": 1.9921609406871177,
      "grad_norm": 0.09957186132669449,
      "learning_rate": 1.6810316095401884e-05,
      "loss": 0.0478,
      "step": 99620
    },
    {
      "epoch": 1.9923609166899972,
      "grad_norm": 0.11887901276350021,
      "learning_rate": 1.680698316202056e-05,
      "loss": 0.0755,
      "step": 99630
    },
    {
      "epoch": 1.9925608926928768,
      "grad_norm": 0.11475572735071182,
      "learning_rate": 1.680365022863923e-05,
      "loss": 0.0753,
      "step": 99640
    },
    {
      "epoch": 1.9927608686957565,
      "grad_norm": 0.20570838451385498,
      "learning_rate": 1.6800317295257903e-05,
      "loss": 0.0879,
      "step": 99650
    },
    {
      "epoch": 1.9929608446986362,
      "grad_norm": 0.11194649338722229,
      "learning_rate": 1.6796984361876576e-05,
      "loss": 0.0683,
      "step": 99660
    },
    {
      "epoch": 1.9931608207015157,
      "grad_norm": 0.15436048805713654,
      "learning_rate": 1.6793651428495246e-05,
      "loss": 0.0877,
      "step": 99670
    },
    {
      "epoch": 1.9933607967043954,
      "grad_norm": 0.170940563082695,
      "learning_rate": 1.6790318495113922e-05,
      "loss": 0.0426,
      "step": 99680
    },
    {
      "epoch": 1.993560772707275,
      "grad_norm": 0.1564507782459259,
      "learning_rate": 1.6786985561732592e-05,
      "loss": 0.0791,
      "step": 99690
    },
    {
      "epoch": 1.9937607487101547,
      "grad_norm": 0.13755078613758087,
      "learning_rate": 1.6783652628351265e-05,
      "loss": 0.0771,
      "step": 99700
    },
    {
      "epoch": 1.9939607247130344,
      "grad_norm": 0.09978670626878738,
      "learning_rate": 1.6780319694969938e-05,
      "loss": 0.0577,
      "step": 99710
    },
    {
      "epoch": 1.9941607007159141,
      "grad_norm": 0.2020985633134842,
      "learning_rate": 1.6776986761588608e-05,
      "loss": 0.0738,
      "step": 99720
    },
    {
      "epoch": 1.9943606767187938,
      "grad_norm": 0.179582417011261,
      "learning_rate": 1.6773653828207284e-05,
      "loss": 0.0697,
      "step": 99730
    },
    {
      "epoch": 1.9945606527216735,
      "grad_norm": 0.2208578735589981,
      "learning_rate": 1.6770320894825957e-05,
      "loss": 0.1004,
      "step": 99740
    },
    {
      "epoch": 1.9947606287245532,
      "grad_norm": 0.1056177169084549,
      "learning_rate": 1.6766987961444627e-05,
      "loss": 0.0681,
      "step": 99750
    },
    {
      "epoch": 1.9949606047274329,
      "grad_norm": 0.08631753921508789,
      "learning_rate": 1.67636550280633e-05,
      "loss": 0.0984,
      "step": 99760
    },
    {
      "epoch": 1.9951605807303123,
      "grad_norm": 0.10589265078306198,
      "learning_rate": 1.6760322094681973e-05,
      "loss": 0.1043,
      "step": 99770
    },
    {
      "epoch": 1.995360556733192,
      "grad_norm": 0.09760585427284241,
      "learning_rate": 1.6756989161300646e-05,
      "loss": 0.0544,
      "step": 99780
    },
    {
      "epoch": 1.9955605327360717,
      "grad_norm": 0.20696048438549042,
      "learning_rate": 1.675365622791932e-05,
      "loss": 0.1013,
      "step": 99790
    },
    {
      "epoch": 1.9957605087389512,
      "grad_norm": 0.19504085183143616,
      "learning_rate": 1.6750323294537988e-05,
      "loss": 0.0952,
      "step": 99800
    },
    {
      "epoch": 1.9959604847418309,
      "grad_norm": 0.24351516366004944,
      "learning_rate": 1.674699036115666e-05,
      "loss": 0.0851,
      "step": 99810
    },
    {
      "epoch": 1.9961604607447105,
      "grad_norm": 0.0881178081035614,
      "learning_rate": 1.6743657427775334e-05,
      "loss": 0.0648,
      "step": 99820
    },
    {
      "epoch": 1.9963604367475902,
      "grad_norm": 0.14519500732421875,
      "learning_rate": 1.6740324494394007e-05,
      "loss": 0.0815,
      "step": 99830
    },
    {
      "epoch": 1.99656041275047,
      "grad_norm": 0.10265485942363739,
      "learning_rate": 1.673699156101268e-05,
      "loss": 0.1014,
      "step": 99840
    },
    {
      "epoch": 1.9967603887533496,
      "grad_norm": 0.11159445345401764,
      "learning_rate": 1.6733658627631353e-05,
      "loss": 0.0426,
      "step": 99850
    },
    {
      "epoch": 1.9969603647562293,
      "grad_norm": 0.0777619332075119,
      "learning_rate": 1.6730325694250023e-05,
      "loss": 0.0482,
      "step": 99860
    },
    {
      "epoch": 1.997160340759109,
      "grad_norm": 0.06123507767915726,
      "learning_rate": 1.6726992760868696e-05,
      "loss": 0.0287,
      "step": 99870
    },
    {
      "epoch": 1.9973603167619887,
      "grad_norm": 0.14475826919078827,
      "learning_rate": 1.672365982748737e-05,
      "loss": 0.0605,
      "step": 99880
    },
    {
      "epoch": 1.9975602927648684,
      "grad_norm": 0.09686263650655746,
      "learning_rate": 1.6720326894106042e-05,
      "loss": 0.0663,
      "step": 99890
    },
    {
      "epoch": 1.9977602687677478,
      "grad_norm": 0.17092132568359375,
      "learning_rate": 1.6716993960724715e-05,
      "loss": 0.0915,
      "step": 99900
    },
    {
      "epoch": 1.9979602447706275,
      "grad_norm": 0.19234611093997955,
      "learning_rate": 1.6713661027343385e-05,
      "loss": 0.1011,
      "step": 99910
    },
    {
      "epoch": 1.9981602207735072,
      "grad_norm": 0.13644714653491974,
      "learning_rate": 1.6710328093962058e-05,
      "loss": 0.0854,
      "step": 99920
    },
    {
      "epoch": 1.9983601967763869,
      "grad_norm": 0.11109984666109085,
      "learning_rate": 1.6706995160580734e-05,
      "loss": 0.0565,
      "step": 99930
    },
    {
      "epoch": 1.9985601727792663,
      "grad_norm": 0.22188624739646912,
      "learning_rate": 1.6703662227199404e-05,
      "loss": 0.0827,
      "step": 99940
    },
    {
      "epoch": 1.998760148782146,
      "grad_norm": 0.1595713049173355,
      "learning_rate": 1.6700329293818077e-05,
      "loss": 0.0742,
      "step": 99950
    },
    {
      "epoch": 1.9989601247850257,
      "grad_norm": 0.1141008734703064,
      "learning_rate": 1.669699636043675e-05,
      "loss": 0.0985,
      "step": 99960
    },
    {
      "epoch": 1.9991601007879054,
      "grad_norm": 0.1670892834663391,
      "learning_rate": 1.669366342705542e-05,
      "loss": 0.0555,
      "step": 99970
    },
    {
      "epoch": 1.999360076790785,
      "grad_norm": 0.25039365887641907,
      "learning_rate": 1.6690330493674096e-05,
      "loss": 0.0907,
      "step": 99980
    },
    {
      "epoch": 1.9995600527936648,
      "grad_norm": 0.0990680381655693,
      "learning_rate": 1.6686997560292765e-05,
      "loss": 0.4327,
      "step": 99990
    },
    {
      "epoch": 1.9997600287965445,
      "grad_norm": 0.12421222031116486,
      "learning_rate": 1.6683664626911438e-05,
      "loss": 0.0738,
      "step": 100000
    },
    {
      "epoch": 1.9999600047994242,
      "grad_norm": 0.1471647173166275,
      "learning_rate": 1.668033169353011e-05,
      "loss": 0.0862,
      "step": 100010
    },
    {
      "epoch": 2.000159980802304,
      "grad_norm": 0.11648082733154297,
      "learning_rate": 1.667699876014878e-05,
      "loss": 0.0778,
      "step": 100020
    },
    {
      "epoch": 2.0003599568051835,
      "grad_norm": 0.1951734870672226,
      "learning_rate": 1.6673665826767457e-05,
      "loss": 0.0844,
      "step": 100030
    },
    {
      "epoch": 2.000559932808063,
      "grad_norm": 0.09696992486715317,
      "learning_rate": 1.667033289338613e-05,
      "loss": 0.0508,
      "step": 100040
    },
    {
      "epoch": 2.000759908810943,
      "grad_norm": 0.23299671709537506,
      "learning_rate": 1.66669999600048e-05,
      "loss": 0.0856,
      "step": 100050
    },
    {
      "epoch": 2.000959884813822,
      "grad_norm": 0.06127314269542694,
      "learning_rate": 1.6663667026623473e-05,
      "loss": 0.0775,
      "step": 100060
    },
    {
      "epoch": 2.001159860816702,
      "grad_norm": 0.11226008087396622,
      "learning_rate": 1.6660334093242146e-05,
      "loss": 0.08,
      "step": 100070
    },
    {
      "epoch": 2.0013598368195815,
      "grad_norm": 0.07760732620954514,
      "learning_rate": 1.665700115986082e-05,
      "loss": 0.0607,
      "step": 100080
    },
    {
      "epoch": 2.001559812822461,
      "grad_norm": 0.14817234873771667,
      "learning_rate": 1.6653668226479492e-05,
      "loss": 0.0705,
      "step": 100090
    },
    {
      "epoch": 2.001759788825341,
      "grad_norm": 0.17732974886894226,
      "learning_rate": 1.665033529309816e-05,
      "loss": 0.0873,
      "step": 100100
    },
    {
      "epoch": 2.0019597648282206,
      "grad_norm": 0.11626507341861725,
      "learning_rate": 1.6647002359716834e-05,
      "loss": 0.0668,
      "step": 100110
    },
    {
      "epoch": 2.0021597408311003,
      "grad_norm": 0.13933978974819183,
      "learning_rate": 1.6643669426335507e-05,
      "loss": 0.0706,
      "step": 100120
    },
    {
      "epoch": 2.00235971683398,
      "grad_norm": 0.15240667760372162,
      "learning_rate": 1.6640336492954177e-05,
      "loss": 0.0757,
      "step": 100130
    },
    {
      "epoch": 2.0025596928368596,
      "grad_norm": 0.18519122898578644,
      "learning_rate": 1.6637003559572853e-05,
      "loss": 0.0935,
      "step": 100140
    },
    {
      "epoch": 2.0027596688397393,
      "grad_norm": 0.15352630615234375,
      "learning_rate": 1.6633670626191526e-05,
      "loss": 0.0426,
      "step": 100150
    },
    {
      "epoch": 2.002959644842619,
      "grad_norm": 0.1358295977115631,
      "learning_rate": 1.6630337692810196e-05,
      "loss": 0.0594,
      "step": 100160
    },
    {
      "epoch": 2.0031596208454987,
      "grad_norm": 0.22627215087413788,
      "learning_rate": 1.662700475942887e-05,
      "loss": 0.0824,
      "step": 100170
    },
    {
      "epoch": 2.0033595968483784,
      "grad_norm": 0.13503031432628632,
      "learning_rate": 1.6623671826047542e-05,
      "loss": 0.0872,
      "step": 100180
    },
    {
      "epoch": 2.0035595728512576,
      "grad_norm": 0.10868819802999496,
      "learning_rate": 1.6620338892666215e-05,
      "loss": 0.0587,
      "step": 100190
    },
    {
      "epoch": 2.0037595488541373,
      "grad_norm": 0.05677512288093567,
      "learning_rate": 1.6617005959284888e-05,
      "loss": 0.1059,
      "step": 100200
    },
    {
      "epoch": 2.003959524857017,
      "grad_norm": 0.05741407722234726,
      "learning_rate": 1.6613673025903558e-05,
      "loss": 0.0582,
      "step": 100210
    },
    {
      "epoch": 2.0041595008598967,
      "grad_norm": 0.08722031116485596,
      "learning_rate": 1.661034009252223e-05,
      "loss": 0.0721,
      "step": 100220
    },
    {
      "epoch": 2.0043594768627764,
      "grad_norm": 0.08638644218444824,
      "learning_rate": 1.6607007159140904e-05,
      "loss": 0.0902,
      "step": 100230
    },
    {
      "epoch": 2.004559452865656,
      "grad_norm": 0.07412318885326385,
      "learning_rate": 1.6603674225759577e-05,
      "loss": 0.0872,
      "step": 100240
    },
    {
      "epoch": 2.0047594288685358,
      "grad_norm": 0.0777783915400505,
      "learning_rate": 1.660034129237825e-05,
      "loss": 0.0793,
      "step": 100250
    },
    {
      "epoch": 2.0049594048714154,
      "grad_norm": 0.16084937751293182,
      "learning_rate": 1.6597008358996923e-05,
      "loss": 0.0777,
      "step": 100260
    },
    {
      "epoch": 2.005159380874295,
      "grad_norm": 0.1332438439130783,
      "learning_rate": 1.6593675425615592e-05,
      "loss": 0.0766,
      "step": 100270
    },
    {
      "epoch": 2.005359356877175,
      "grad_norm": 0.10355798900127411,
      "learning_rate": 1.6590342492234265e-05,
      "loss": 0.0754,
      "step": 100280
    },
    {
      "epoch": 2.0055593328800545,
      "grad_norm": 0.1608557552099228,
      "learning_rate": 1.658700955885294e-05,
      "loss": 0.0992,
      "step": 100290
    },
    {
      "epoch": 2.005759308882934,
      "grad_norm": 0.17833323776721954,
      "learning_rate": 1.658367662547161e-05,
      "loss": 0.075,
      "step": 100300
    },
    {
      "epoch": 2.005959284885814,
      "grad_norm": 0.06937004625797272,
      "learning_rate": 1.6580343692090284e-05,
      "loss": 0.0598,
      "step": 100310
    },
    {
      "epoch": 2.0061592608886936,
      "grad_norm": 0.10072744637727737,
      "learning_rate": 1.6577010758708954e-05,
      "loss": 0.0565,
      "step": 100320
    },
    {
      "epoch": 2.006359236891573,
      "grad_norm": 0.12180343270301819,
      "learning_rate": 1.6573677825327627e-05,
      "loss": 0.0874,
      "step": 100330
    },
    {
      "epoch": 2.0065592128944525,
      "grad_norm": 0.19025912880897522,
      "learning_rate": 1.65703448919463e-05,
      "loss": 0.0605,
      "step": 100340
    },
    {
      "epoch": 2.006759188897332,
      "grad_norm": 0.1741083860397339,
      "learning_rate": 1.6567011958564973e-05,
      "loss": 0.0796,
      "step": 100350
    },
    {
      "epoch": 2.006959164900212,
      "grad_norm": 0.0845847949385643,
      "learning_rate": 1.6563679025183646e-05,
      "loss": 0.0635,
      "step": 100360
    },
    {
      "epoch": 2.0071591409030916,
      "grad_norm": 0.2073127180337906,
      "learning_rate": 1.656034609180232e-05,
      "loss": 0.1355,
      "step": 100370
    },
    {
      "epoch": 2.0073591169059712,
      "grad_norm": 0.10367485880851746,
      "learning_rate": 1.655701315842099e-05,
      "loss": 0.0922,
      "step": 100380
    },
    {
      "epoch": 2.007559092908851,
      "grad_norm": 0.14905798435211182,
      "learning_rate": 1.6553680225039665e-05,
      "loss": 0.0643,
      "step": 100390
    },
    {
      "epoch": 2.0077590689117306,
      "grad_norm": 0.20957979559898376,
      "learning_rate": 1.6550347291658335e-05,
      "loss": 0.0904,
      "step": 100400
    },
    {
      "epoch": 2.0079590449146103,
      "grad_norm": 0.0792238786816597,
      "learning_rate": 1.6547014358277008e-05,
      "loss": 0.0842,
      "step": 100410
    },
    {
      "epoch": 2.00815902091749,
      "grad_norm": 0.12071889638900757,
      "learning_rate": 1.654368142489568e-05,
      "loss": 0.0749,
      "step": 100420
    },
    {
      "epoch": 2.0083589969203697,
      "grad_norm": 0.13976682722568512,
      "learning_rate": 1.654034849151435e-05,
      "loss": 0.0648,
      "step": 100430
    },
    {
      "epoch": 2.0085589729232494,
      "grad_norm": 0.18820661306381226,
      "learning_rate": 1.6537015558133027e-05,
      "loss": 0.0734,
      "step": 100440
    },
    {
      "epoch": 2.008758948926129,
      "grad_norm": 0.12729674577713013,
      "learning_rate": 1.6533682624751696e-05,
      "loss": 0.0884,
      "step": 100450
    },
    {
      "epoch": 2.0089589249290087,
      "grad_norm": 0.18975040316581726,
      "learning_rate": 1.653034969137037e-05,
      "loss": 0.0873,
      "step": 100460
    },
    {
      "epoch": 2.009158900931888,
      "grad_norm": 0.18823686242103577,
      "learning_rate": 1.6527016757989042e-05,
      "loss": 0.0932,
      "step": 100470
    },
    {
      "epoch": 2.0093588769347677,
      "grad_norm": 0.07329363375902176,
      "learning_rate": 1.6523683824607712e-05,
      "loss": 0.045,
      "step": 100480
    },
    {
      "epoch": 2.0095588529376474,
      "grad_norm": 0.08647146075963974,
      "learning_rate": 1.6520350891226388e-05,
      "loss": 0.0645,
      "step": 100490
    },
    {
      "epoch": 2.009758828940527,
      "grad_norm": 0.15236499905586243,
      "learning_rate": 1.651701795784506e-05,
      "loss": 0.0711,
      "step": 100500
    },
    {
      "epoch": 2.0099588049434067,
      "grad_norm": 0.22033308446407318,
      "learning_rate": 1.651368502446373e-05,
      "loss": 0.0838,
      "step": 100510
    },
    {
      "epoch": 2.0101587809462864,
      "grad_norm": 0.2018180936574936,
      "learning_rate": 1.6510352091082404e-05,
      "loss": 0.0744,
      "step": 100520
    },
    {
      "epoch": 2.010358756949166,
      "grad_norm": 0.05211108177900314,
      "learning_rate": 1.6507019157701077e-05,
      "loss": 0.0452,
      "step": 100530
    },
    {
      "epoch": 2.010558732952046,
      "grad_norm": 0.1086878851056099,
      "learning_rate": 1.650368622431975e-05,
      "loss": 0.0902,
      "step": 100540
    },
    {
      "epoch": 2.0107587089549255,
      "grad_norm": 0.09381067007780075,
      "learning_rate": 1.6500353290938423e-05,
      "loss": 0.1304,
      "step": 100550
    },
    {
      "epoch": 2.010958684957805,
      "grad_norm": 0.060858216136693954,
      "learning_rate": 1.6497020357557093e-05,
      "loss": 0.0915,
      "step": 100560
    },
    {
      "epoch": 2.011158660960685,
      "grad_norm": 0.17479480803012848,
      "learning_rate": 1.6493687424175766e-05,
      "loss": 0.0749,
      "step": 100570
    },
    {
      "epoch": 2.0113586369635645,
      "grad_norm": 0.05482732877135277,
      "learning_rate": 1.649035449079444e-05,
      "loss": 0.053,
      "step": 100580
    },
    {
      "epoch": 2.0115586129664442,
      "grad_norm": 0.11183316260576248,
      "learning_rate": 1.6487021557413108e-05,
      "loss": 0.0946,
      "step": 100590
    },
    {
      "epoch": 2.0117585889693235,
      "grad_norm": 0.07941652834415436,
      "learning_rate": 1.6483688624031785e-05,
      "loss": 0.0772,
      "step": 100600
    },
    {
      "epoch": 2.011958564972203,
      "grad_norm": 0.10913136601448059,
      "learning_rate": 1.6480355690650458e-05,
      "loss": 0.072,
      "step": 100610
    },
    {
      "epoch": 2.012158540975083,
      "grad_norm": 0.25812390446662903,
      "learning_rate": 1.6477022757269127e-05,
      "loss": 0.0962,
      "step": 100620
    },
    {
      "epoch": 2.0123585169779625,
      "grad_norm": 0.08445150405168533,
      "learning_rate": 1.64736898238878e-05,
      "loss": 0.0837,
      "step": 100630
    },
    {
      "epoch": 2.012558492980842,
      "grad_norm": 0.2046617716550827,
      "learning_rate": 1.6470356890506473e-05,
      "loss": 0.0727,
      "step": 100640
    },
    {
      "epoch": 2.012758468983722,
      "grad_norm": 0.16347713768482208,
      "learning_rate": 1.6467023957125146e-05,
      "loss": 0.0799,
      "step": 100650
    },
    {
      "epoch": 2.0129584449866016,
      "grad_norm": 0.18295317888259888,
      "learning_rate": 1.646369102374382e-05,
      "loss": 0.106,
      "step": 100660
    },
    {
      "epoch": 2.0131584209894813,
      "grad_norm": 0.1870068609714508,
      "learning_rate": 1.646035809036249e-05,
      "loss": 0.0881,
      "step": 100670
    },
    {
      "epoch": 2.013358396992361,
      "grad_norm": 0.06777295470237732,
      "learning_rate": 1.6457025156981162e-05,
      "loss": 0.0634,
      "step": 100680
    },
    {
      "epoch": 2.0135583729952407,
      "grad_norm": 0.11815090477466583,
      "learning_rate": 1.6453692223599835e-05,
      "loss": 0.0576,
      "step": 100690
    },
    {
      "epoch": 2.0137583489981203,
      "grad_norm": 0.15633654594421387,
      "learning_rate": 1.6450359290218508e-05,
      "loss": 0.0892,
      "step": 100700
    },
    {
      "epoch": 2.013958325001,
      "grad_norm": 0.12666772305965424,
      "learning_rate": 1.644702635683718e-05,
      "loss": 0.0529,
      "step": 100710
    },
    {
      "epoch": 2.0141583010038797,
      "grad_norm": 0.18586349487304688,
      "learning_rate": 1.6443693423455854e-05,
      "loss": 0.077,
      "step": 100720
    },
    {
      "epoch": 2.0143582770067594,
      "grad_norm": 0.12521731853485107,
      "learning_rate": 1.6440360490074523e-05,
      "loss": 0.069,
      "step": 100730
    },
    {
      "epoch": 2.0145582530096386,
      "grad_norm": 0.097743920981884,
      "learning_rate": 1.6437027556693196e-05,
      "loss": 0.0514,
      "step": 100740
    },
    {
      "epoch": 2.0147582290125183,
      "grad_norm": 0.1244020089507103,
      "learning_rate": 1.643369462331187e-05,
      "loss": 0.0277,
      "step": 100750
    },
    {
      "epoch": 2.014958205015398,
      "grad_norm": 0.1380643993616104,
      "learning_rate": 1.6430361689930542e-05,
      "loss": 0.093,
      "step": 100760
    },
    {
      "epoch": 2.0151581810182777,
      "grad_norm": 0.05741189047694206,
      "learning_rate": 1.6427028756549215e-05,
      "loss": 0.0771,
      "step": 100770
    },
    {
      "epoch": 2.0153581570211574,
      "grad_norm": 0.07177180051803589,
      "learning_rate": 1.6423695823167885e-05,
      "loss": 0.0431,
      "step": 100780
    },
    {
      "epoch": 2.015558133024037,
      "grad_norm": 0.11248341202735901,
      "learning_rate": 1.6420362889786558e-05,
      "loss": 0.0836,
      "step": 100790
    },
    {
      "epoch": 2.0157581090269168,
      "grad_norm": 0.14159172773361206,
      "learning_rate": 1.6417029956405234e-05,
      "loss": 0.0429,
      "step": 100800
    },
    {
      "epoch": 2.0159580850297965,
      "grad_norm": 0.20357933640480042,
      "learning_rate": 1.6413697023023904e-05,
      "loss": 0.0707,
      "step": 100810
    },
    {
      "epoch": 2.016158061032676,
      "grad_norm": 0.11389928311109543,
      "learning_rate": 1.6410364089642577e-05,
      "loss": 0.1108,
      "step": 100820
    },
    {
      "epoch": 2.016358037035556,
      "grad_norm": 0.1509009152650833,
      "learning_rate": 1.640703115626125e-05,
      "loss": 0.0548,
      "step": 100830
    },
    {
      "epoch": 2.0165580130384355,
      "grad_norm": 0.10682594776153564,
      "learning_rate": 1.640369822287992e-05,
      "loss": 0.0358,
      "step": 100840
    },
    {
      "epoch": 2.016757989041315,
      "grad_norm": 0.07718370854854584,
      "learning_rate": 1.6400365289498596e-05,
      "loss": 0.0791,
      "step": 100850
    },
    {
      "epoch": 2.016957965044195,
      "grad_norm": 0.05831180140376091,
      "learning_rate": 1.6397032356117266e-05,
      "loss": 0.0614,
      "step": 100860
    },
    {
      "epoch": 2.017157941047074,
      "grad_norm": 0.24392026662826538,
      "learning_rate": 1.639369942273594e-05,
      "loss": 0.0682,
      "step": 100870
    },
    {
      "epoch": 2.017357917049954,
      "grad_norm": 0.15177488327026367,
      "learning_rate": 1.6390366489354612e-05,
      "loss": 0.053,
      "step": 100880
    },
    {
      "epoch": 2.0175578930528335,
      "grad_norm": 0.1172778382897377,
      "learning_rate": 1.638703355597328e-05,
      "loss": 0.052,
      "step": 100890
    },
    {
      "epoch": 2.017757869055713,
      "grad_norm": 0.1680999994277954,
      "learning_rate": 1.6383700622591958e-05,
      "loss": 0.0858,
      "step": 100900
    },
    {
      "epoch": 2.017957845058593,
      "grad_norm": 0.23298713564872742,
      "learning_rate": 1.638036768921063e-05,
      "loss": 0.0564,
      "step": 100910
    },
    {
      "epoch": 2.0181578210614726,
      "grad_norm": 0.15559858083724976,
      "learning_rate": 1.63770347558293e-05,
      "loss": 0.0721,
      "step": 100920
    },
    {
      "epoch": 2.0183577970643523,
      "grad_norm": 0.2434176206588745,
      "learning_rate": 1.6373701822447973e-05,
      "loss": 0.0949,
      "step": 100930
    },
    {
      "epoch": 2.018557773067232,
      "grad_norm": 0.16737546026706696,
      "learning_rate": 1.6370368889066646e-05,
      "loss": 0.2573,
      "step": 100940
    },
    {
      "epoch": 2.0187577490701116,
      "grad_norm": 0.10078854858875275,
      "learning_rate": 1.636703595568532e-05,
      "loss": 0.0911,
      "step": 100950
    },
    {
      "epoch": 2.0189577250729913,
      "grad_norm": 0.17241160571575165,
      "learning_rate": 1.6363703022303992e-05,
      "loss": 0.0729,
      "step": 100960
    },
    {
      "epoch": 2.019157701075871,
      "grad_norm": 0.14729516208171844,
      "learning_rate": 1.6360370088922662e-05,
      "loss": 0.0779,
      "step": 100970
    },
    {
      "epoch": 2.0193576770787507,
      "grad_norm": 0.09219463914632797,
      "learning_rate": 1.6357037155541335e-05,
      "loss": 0.0876,
      "step": 100980
    },
    {
      "epoch": 2.0195576530816304,
      "grad_norm": 0.18112990260124207,
      "learning_rate": 1.6353704222160008e-05,
      "loss": 0.1014,
      "step": 100990
    },
    {
      "epoch": 2.01975762908451,
      "grad_norm": 0.0923694521188736,
      "learning_rate": 1.635037128877868e-05,
      "loss": 0.0729,
      "step": 101000
    },
    {
      "epoch": 2.0199576050873893,
      "grad_norm": 0.13949579000473022,
      "learning_rate": 1.6347038355397354e-05,
      "loss": 0.0545,
      "step": 101010
    },
    {
      "epoch": 2.020157581090269,
      "grad_norm": 0.12684203684329987,
      "learning_rate": 1.6343705422016027e-05,
      "loss": 0.0894,
      "step": 101020
    },
    {
      "epoch": 2.0203575570931487,
      "grad_norm": 0.06815031915903091,
      "learning_rate": 1.6340372488634697e-05,
      "loss": 0.0582,
      "step": 101030
    },
    {
      "epoch": 2.0205575330960284,
      "grad_norm": 0.14463390409946442,
      "learning_rate": 1.633703955525337e-05,
      "loss": 0.097,
      "step": 101040
    },
    {
      "epoch": 2.020757509098908,
      "grad_norm": 0.20924177765846252,
      "learning_rate": 1.6333706621872043e-05,
      "loss": 0.1027,
      "step": 101050
    },
    {
      "epoch": 2.0209574851017877,
      "grad_norm": 0.17120744287967682,
      "learning_rate": 1.6330373688490716e-05,
      "loss": 0.0454,
      "step": 101060
    },
    {
      "epoch": 2.0211574611046674,
      "grad_norm": 0.0682670846581459,
      "learning_rate": 1.632704075510939e-05,
      "loss": 0.0481,
      "step": 101070
    },
    {
      "epoch": 2.021357437107547,
      "grad_norm": 0.1353827863931656,
      "learning_rate": 1.6323707821728058e-05,
      "loss": 0.0538,
      "step": 101080
    },
    {
      "epoch": 2.021557413110427,
      "grad_norm": 0.1167379766702652,
      "learning_rate": 1.632037488834673e-05,
      "loss": 0.0765,
      "step": 101090
    },
    {
      "epoch": 2.0217573891133065,
      "grad_norm": 0.09985490143299103,
      "learning_rate": 1.6317041954965404e-05,
      "loss": 0.0405,
      "step": 101100
    },
    {
      "epoch": 2.021957365116186,
      "grad_norm": 0.17518559098243713,
      "learning_rate": 1.6313709021584077e-05,
      "loss": 0.0641,
      "step": 101110
    },
    {
      "epoch": 2.022157341119066,
      "grad_norm": 0.20616525411605835,
      "learning_rate": 1.631037608820275e-05,
      "loss": 0.0809,
      "step": 101120
    },
    {
      "epoch": 2.0223573171219456,
      "grad_norm": 0.1691671460866928,
      "learning_rate": 1.6307043154821423e-05,
      "loss": 0.0724,
      "step": 101130
    },
    {
      "epoch": 2.0225572931248252,
      "grad_norm": 0.08206939697265625,
      "learning_rate": 1.6303710221440093e-05,
      "loss": 0.0751,
      "step": 101140
    },
    {
      "epoch": 2.0227572691277045,
      "grad_norm": 0.1526276022195816,
      "learning_rate": 1.6300377288058766e-05,
      "loss": 0.1014,
      "step": 101150
    },
    {
      "epoch": 2.022957245130584,
      "grad_norm": 0.06560932099819183,
      "learning_rate": 1.629704435467744e-05,
      "loss": 0.0678,
      "step": 101160
    },
    {
      "epoch": 2.023157221133464,
      "grad_norm": 0.14240193367004395,
      "learning_rate": 1.6293711421296112e-05,
      "loss": 0.0643,
      "step": 101170
    },
    {
      "epoch": 2.0233571971363435,
      "grad_norm": 0.22188319265842438,
      "learning_rate": 1.6290378487914785e-05,
      "loss": 0.0812,
      "step": 101180
    },
    {
      "epoch": 2.0235571731392232,
      "grad_norm": 0.12629176676273346,
      "learning_rate": 1.6287045554533455e-05,
      "loss": 0.1113,
      "step": 101190
    },
    {
      "epoch": 2.023757149142103,
      "grad_norm": 0.07893739640712738,
      "learning_rate": 1.6283712621152128e-05,
      "loss": 0.0569,
      "step": 101200
    },
    {
      "epoch": 2.0239571251449826,
      "grad_norm": 0.12245773524045944,
      "learning_rate": 1.6280379687770804e-05,
      "loss": 0.0637,
      "step": 101210
    },
    {
      "epoch": 2.0241571011478623,
      "grad_norm": 0.08747004717588425,
      "learning_rate": 1.6277046754389474e-05,
      "loss": 0.0935,
      "step": 101220
    },
    {
      "epoch": 2.024357077150742,
      "grad_norm": 0.14505352079868317,
      "learning_rate": 1.6273713821008147e-05,
      "loss": 0.0699,
      "step": 101230
    },
    {
      "epoch": 2.0245570531536217,
      "grad_norm": 0.1565713733434677,
      "learning_rate": 1.627038088762682e-05,
      "loss": 0.1385,
      "step": 101240
    },
    {
      "epoch": 2.0247570291565014,
      "grad_norm": 0.10459037125110626,
      "learning_rate": 1.626704795424549e-05,
      "loss": 0.1003,
      "step": 101250
    },
    {
      "epoch": 2.024957005159381,
      "grad_norm": 0.12493554502725601,
      "learning_rate": 1.6263715020864166e-05,
      "loss": 0.0675,
      "step": 101260
    },
    {
      "epoch": 2.0251569811622607,
      "grad_norm": 0.05385766550898552,
      "learning_rate": 1.6260382087482835e-05,
      "loss": 0.0573,
      "step": 101270
    },
    {
      "epoch": 2.02535695716514,
      "grad_norm": 0.10151731967926025,
      "learning_rate": 1.6257049154101508e-05,
      "loss": 0.0708,
      "step": 101280
    },
    {
      "epoch": 2.0255569331680197,
      "grad_norm": 0.10536738485097885,
      "learning_rate": 1.625371622072018e-05,
      "loss": 0.072,
      "step": 101290
    },
    {
      "epoch": 2.0257569091708993,
      "grad_norm": 0.20715203881263733,
      "learning_rate": 1.625038328733885e-05,
      "loss": 0.0793,
      "step": 101300
    },
    {
      "epoch": 2.025956885173779,
      "grad_norm": 0.062448080629110336,
      "learning_rate": 1.6247050353957527e-05,
      "loss": 0.0721,
      "step": 101310
    },
    {
      "epoch": 2.0261568611766587,
      "grad_norm": 0.09678782522678375,
      "learning_rate": 1.62437174205762e-05,
      "loss": 0.0446,
      "step": 101320
    },
    {
      "epoch": 2.0263568371795384,
      "grad_norm": 0.1698366403579712,
      "learning_rate": 1.624038448719487e-05,
      "loss": 0.071,
      "step": 101330
    },
    {
      "epoch": 2.026556813182418,
      "grad_norm": 0.20503342151641846,
      "learning_rate": 1.6237051553813543e-05,
      "loss": 0.152,
      "step": 101340
    },
    {
      "epoch": 2.026756789185298,
      "grad_norm": 0.28854119777679443,
      "learning_rate": 1.6233718620432216e-05,
      "loss": 0.0834,
      "step": 101350
    },
    {
      "epoch": 2.0269567651881775,
      "grad_norm": 0.08140670508146286,
      "learning_rate": 1.623038568705089e-05,
      "loss": 0.0762,
      "step": 101360
    },
    {
      "epoch": 2.027156741191057,
      "grad_norm": 0.11253029853105545,
      "learning_rate": 1.6227052753669562e-05,
      "loss": 0.0583,
      "step": 101370
    },
    {
      "epoch": 2.027356717193937,
      "grad_norm": 0.12085101753473282,
      "learning_rate": 1.622371982028823e-05,
      "loss": 0.0524,
      "step": 101380
    },
    {
      "epoch": 2.0275566931968165,
      "grad_norm": 0.1402221918106079,
      "learning_rate": 1.6220386886906904e-05,
      "loss": 0.0621,
      "step": 101390
    },
    {
      "epoch": 2.027756669199696,
      "grad_norm": 0.12636500597000122,
      "learning_rate": 1.6217053953525577e-05,
      "loss": 0.0444,
      "step": 101400
    },
    {
      "epoch": 2.027956645202576,
      "grad_norm": 0.10435222089290619,
      "learning_rate": 1.621372102014425e-05,
      "loss": 0.0495,
      "step": 101410
    },
    {
      "epoch": 2.028156621205455,
      "grad_norm": 0.0624469593167305,
      "learning_rate": 1.6210388086762923e-05,
      "loss": 0.0582,
      "step": 101420
    },
    {
      "epoch": 2.028356597208335,
      "grad_norm": 0.07893508672714233,
      "learning_rate": 1.6207055153381596e-05,
      "loss": 0.1242,
      "step": 101430
    },
    {
      "epoch": 2.0285565732112145,
      "grad_norm": 0.1377638727426529,
      "learning_rate": 1.6203722220000266e-05,
      "loss": 0.0695,
      "step": 101440
    },
    {
      "epoch": 2.028756549214094,
      "grad_norm": 0.10845272988080978,
      "learning_rate": 1.620038928661894e-05,
      "loss": 0.0543,
      "step": 101450
    },
    {
      "epoch": 2.028956525216974,
      "grad_norm": 0.14112848043441772,
      "learning_rate": 1.6197056353237612e-05,
      "loss": 0.0662,
      "step": 101460
    },
    {
      "epoch": 2.0291565012198536,
      "grad_norm": 0.16481485962867737,
      "learning_rate": 1.6193723419856285e-05,
      "loss": 0.0847,
      "step": 101470
    },
    {
      "epoch": 2.0293564772227333,
      "grad_norm": 0.2170579582452774,
      "learning_rate": 1.6190390486474958e-05,
      "loss": 0.0788,
      "step": 101480
    },
    {
      "epoch": 2.029556453225613,
      "grad_norm": 0.30580881237983704,
      "learning_rate": 1.6187057553093628e-05,
      "loss": 0.0884,
      "step": 101490
    },
    {
      "epoch": 2.0297564292284926,
      "grad_norm": 0.07127885520458221,
      "learning_rate": 1.61837246197123e-05,
      "loss": 0.0914,
      "step": 101500
    },
    {
      "epoch": 2.0299564052313723,
      "grad_norm": 0.09511590003967285,
      "learning_rate": 1.6180391686330977e-05,
      "loss": 0.0733,
      "step": 101510
    },
    {
      "epoch": 2.030156381234252,
      "grad_norm": 0.15173055231571198,
      "learning_rate": 1.6177058752949647e-05,
      "loss": 0.0702,
      "step": 101520
    },
    {
      "epoch": 2.0303563572371317,
      "grad_norm": 0.09404629468917847,
      "learning_rate": 1.617372581956832e-05,
      "loss": 0.0506,
      "step": 101530
    },
    {
      "epoch": 2.0305563332400114,
      "grad_norm": 0.10914798825979233,
      "learning_rate": 1.6170392886186993e-05,
      "loss": 0.0555,
      "step": 101540
    },
    {
      "epoch": 2.0307563092428906,
      "grad_norm": 0.2053065001964569,
      "learning_rate": 1.6167059952805662e-05,
      "loss": 0.06,
      "step": 101550
    },
    {
      "epoch": 2.0309562852457703,
      "grad_norm": 0.12175330519676208,
      "learning_rate": 1.616372701942434e-05,
      "loss": 0.0847,
      "step": 101560
    },
    {
      "epoch": 2.03115626124865,
      "grad_norm": 0.06775188446044922,
      "learning_rate": 1.616039408604301e-05,
      "loss": 0.0515,
      "step": 101570
    },
    {
      "epoch": 2.0313562372515297,
      "grad_norm": 0.08989463001489639,
      "learning_rate": 1.615706115266168e-05,
      "loss": 0.0796,
      "step": 101580
    },
    {
      "epoch": 2.0315562132544094,
      "grad_norm": 0.2071026861667633,
      "learning_rate": 1.6153728219280354e-05,
      "loss": 0.0606,
      "step": 101590
    },
    {
      "epoch": 2.031756189257289,
      "grad_norm": 0.10599824041128159,
      "learning_rate": 1.6150395285899024e-05,
      "loss": 0.0479,
      "step": 101600
    },
    {
      "epoch": 2.0319561652601688,
      "grad_norm": 0.2451377958059311,
      "learning_rate": 1.6147062352517697e-05,
      "loss": 0.0823,
      "step": 101610
    },
    {
      "epoch": 2.0321561412630484,
      "grad_norm": 0.08799636363983154,
      "learning_rate": 1.6143729419136373e-05,
      "loss": 0.0601,
      "step": 101620
    },
    {
      "epoch": 2.032356117265928,
      "grad_norm": 0.1574435830116272,
      "learning_rate": 1.6140396485755043e-05,
      "loss": 0.0823,
      "step": 101630
    },
    {
      "epoch": 2.032556093268808,
      "grad_norm": 0.16083621978759766,
      "learning_rate": 1.6137063552373716e-05,
      "loss": 0.0592,
      "step": 101640
    },
    {
      "epoch": 2.0327560692716875,
      "grad_norm": 0.06254265457391739,
      "learning_rate": 1.613373061899239e-05,
      "loss": 0.066,
      "step": 101650
    },
    {
      "epoch": 2.032956045274567,
      "grad_norm": 0.1019149199128151,
      "learning_rate": 1.613039768561106e-05,
      "loss": 0.1588,
      "step": 101660
    },
    {
      "epoch": 2.033156021277447,
      "grad_norm": 0.19071684777736664,
      "learning_rate": 1.6127064752229735e-05,
      "loss": 0.0809,
      "step": 101670
    },
    {
      "epoch": 2.0333559972803266,
      "grad_norm": 0.16250678896903992,
      "learning_rate": 1.6123731818848405e-05,
      "loss": 0.1024,
      "step": 101680
    },
    {
      "epoch": 2.033555973283206,
      "grad_norm": 0.11629585176706314,
      "learning_rate": 1.6120398885467078e-05,
      "loss": 0.0793,
      "step": 101690
    },
    {
      "epoch": 2.0337559492860855,
      "grad_norm": 0.11139032989740372,
      "learning_rate": 1.611706595208575e-05,
      "loss": 0.081,
      "step": 101700
    },
    {
      "epoch": 2.033955925288965,
      "grad_norm": 0.21434731781482697,
      "learning_rate": 1.611373301870442e-05,
      "loss": 0.069,
      "step": 101710
    },
    {
      "epoch": 2.034155901291845,
      "grad_norm": 0.10213946551084518,
      "learning_rate": 1.6110400085323097e-05,
      "loss": 0.0814,
      "step": 101720
    },
    {
      "epoch": 2.0343558772947246,
      "grad_norm": 0.09049692004919052,
      "learning_rate": 1.610706715194177e-05,
      "loss": 0.068,
      "step": 101730
    },
    {
      "epoch": 2.0345558532976042,
      "grad_norm": 0.10946641862392426,
      "learning_rate": 1.610373421856044e-05,
      "loss": 0.0905,
      "step": 101740
    },
    {
      "epoch": 2.034755829300484,
      "grad_norm": 0.07436412572860718,
      "learning_rate": 1.6100401285179112e-05,
      "loss": 0.0394,
      "step": 101750
    },
    {
      "epoch": 2.0349558053033636,
      "grad_norm": 0.07093068957328796,
      "learning_rate": 1.6097068351797785e-05,
      "loss": 0.1036,
      "step": 101760
    },
    {
      "epoch": 2.0351557813062433,
      "grad_norm": 0.1997934728860855,
      "learning_rate": 1.6093735418416458e-05,
      "loss": 0.0873,
      "step": 101770
    },
    {
      "epoch": 2.035355757309123,
      "grad_norm": 0.07632990181446075,
      "learning_rate": 1.609040248503513e-05,
      "loss": 0.0732,
      "step": 101780
    },
    {
      "epoch": 2.0355557333120027,
      "grad_norm": 0.20016849040985107,
      "learning_rate": 1.60870695516538e-05,
      "loss": 0.0992,
      "step": 101790
    },
    {
      "epoch": 2.0357557093148824,
      "grad_norm": 0.11029394716024399,
      "learning_rate": 1.6083736618272474e-05,
      "loss": 0.0482,
      "step": 101800
    },
    {
      "epoch": 2.035955685317762,
      "grad_norm": 0.21675588190555573,
      "learning_rate": 1.6080403684891147e-05,
      "loss": 0.0914,
      "step": 101810
    },
    {
      "epoch": 2.0361556613206417,
      "grad_norm": 0.10001882910728455,
      "learning_rate": 1.607707075150982e-05,
      "loss": 0.0836,
      "step": 101820
    },
    {
      "epoch": 2.036355637323521,
      "grad_norm": 0.08294560760259628,
      "learning_rate": 1.6073737818128493e-05,
      "loss": 0.0821,
      "step": 101830
    },
    {
      "epoch": 2.0365556133264007,
      "grad_norm": 0.15414395928382874,
      "learning_rate": 1.6070738178085298e-05,
      "loss": 0.0897,
      "step": 101840
    },
    {
      "epoch": 2.0367555893292804,
      "grad_norm": 0.06496986746788025,
      "learning_rate": 1.606740524470397e-05,
      "loss": 0.0369,
      "step": 101850
    },
    {
      "epoch": 2.03695556533216,
      "grad_norm": 0.24502553045749664,
      "learning_rate": 1.606407231132264e-05,
      "loss": 0.0847,
      "step": 101860
    },
    {
      "epoch": 2.0371555413350397,
      "grad_norm": 0.21552403271198273,
      "learning_rate": 1.6060739377941314e-05,
      "loss": 0.0793,
      "step": 101870
    },
    {
      "epoch": 2.0373555173379194,
      "grad_norm": 0.1699143946170807,
      "learning_rate": 1.6057406444559987e-05,
      "loss": 0.0694,
      "step": 101880
    },
    {
      "epoch": 2.037555493340799,
      "grad_norm": 0.19750921428203583,
      "learning_rate": 1.605407351117866e-05,
      "loss": 0.1071,
      "step": 101890
    },
    {
      "epoch": 2.037755469343679,
      "grad_norm": 0.06401319056749344,
      "learning_rate": 1.6050740577797333e-05,
      "loss": 0.0733,
      "step": 101900
    },
    {
      "epoch": 2.0379554453465585,
      "grad_norm": 0.08482382446527481,
      "learning_rate": 1.6047407644416006e-05,
      "loss": 0.0577,
      "step": 101910
    },
    {
      "epoch": 2.038155421349438,
      "grad_norm": 0.046760719269514084,
      "learning_rate": 1.6044074711034676e-05,
      "loss": 0.0631,
      "step": 101920
    },
    {
      "epoch": 2.038355397352318,
      "grad_norm": 0.13281631469726562,
      "learning_rate": 1.604074177765335e-05,
      "loss": 0.1241,
      "step": 101930
    },
    {
      "epoch": 2.0385553733551975,
      "grad_norm": 0.06610193103551865,
      "learning_rate": 1.603740884427202e-05,
      "loss": 0.0788,
      "step": 101940
    },
    {
      "epoch": 2.0387553493580772,
      "grad_norm": 0.1974940001964569,
      "learning_rate": 1.6034075910890695e-05,
      "loss": 0.0726,
      "step": 101950
    },
    {
      "epoch": 2.0389553253609565,
      "grad_norm": 0.09305156022310257,
      "learning_rate": 1.6030742977509368e-05,
      "loss": 0.0797,
      "step": 101960
    },
    {
      "epoch": 2.039155301363836,
      "grad_norm": 0.16060741245746613,
      "learning_rate": 1.6027410044128037e-05,
      "loss": 0.0717,
      "step": 101970
    },
    {
      "epoch": 2.039355277366716,
      "grad_norm": 0.13397759199142456,
      "learning_rate": 1.602407711074671e-05,
      "loss": 0.0506,
      "step": 101980
    },
    {
      "epoch": 2.0395552533695955,
      "grad_norm": 0.10025067627429962,
      "learning_rate": 1.6020744177365387e-05,
      "loss": 0.0792,
      "step": 101990
    },
    {
      "epoch": 2.039755229372475,
      "grad_norm": 0.1042747050523758,
      "learning_rate": 1.6017411243984056e-05,
      "loss": 0.5789,
      "step": 102000
    },
    {
      "epoch": 2.039955205375355,
      "grad_norm": 0.19820410013198853,
      "learning_rate": 1.601407831060273e-05,
      "loss": 0.0787,
      "step": 102010
    },
    {
      "epoch": 2.0401551813782346,
      "grad_norm": 0.10640551894903183,
      "learning_rate": 1.6010745377221402e-05,
      "loss": 0.068,
      "step": 102020
    },
    {
      "epoch": 2.0403551573811143,
      "grad_norm": 0.08078830689191818,
      "learning_rate": 1.6007412443840072e-05,
      "loss": 0.0711,
      "step": 102030
    },
    {
      "epoch": 2.040555133383994,
      "grad_norm": 0.07418897747993469,
      "learning_rate": 1.6004079510458748e-05,
      "loss": 0.0747,
      "step": 102040
    },
    {
      "epoch": 2.0407551093868737,
      "grad_norm": 0.0850401520729065,
      "learning_rate": 1.6000746577077418e-05,
      "loss": 0.0775,
      "step": 102050
    },
    {
      "epoch": 2.0409550853897533,
      "grad_norm": 0.16371968388557434,
      "learning_rate": 1.599741364369609e-05,
      "loss": 0.105,
      "step": 102060
    },
    {
      "epoch": 2.041155061392633,
      "grad_norm": 0.08461827039718628,
      "learning_rate": 1.5994080710314764e-05,
      "loss": 0.0801,
      "step": 102070
    },
    {
      "epoch": 2.0413550373955127,
      "grad_norm": 0.16923975944519043,
      "learning_rate": 1.5990747776933433e-05,
      "loss": 0.0783,
      "step": 102080
    },
    {
      "epoch": 2.0415550133983924,
      "grad_norm": 0.12713657319545746,
      "learning_rate": 1.5987414843552106e-05,
      "loss": 0.0687,
      "step": 102090
    },
    {
      "epoch": 2.0417549894012716,
      "grad_norm": 0.21771734952926636,
      "learning_rate": 1.5984081910170783e-05,
      "loss": 0.0728,
      "step": 102100
    },
    {
      "epoch": 2.0419549654041513,
      "grad_norm": 0.07363420724868774,
      "learning_rate": 1.5980748976789452e-05,
      "loss": 0.0674,
      "step": 102110
    },
    {
      "epoch": 2.042154941407031,
      "grad_norm": 0.12317096441984177,
      "learning_rate": 1.5977416043408125e-05,
      "loss": 0.0869,
      "step": 102120
    },
    {
      "epoch": 2.0423549174099107,
      "grad_norm": 0.17596575617790222,
      "learning_rate": 1.59740831100268e-05,
      "loss": 0.1032,
      "step": 102130
    },
    {
      "epoch": 2.0425548934127904,
      "grad_norm": 0.0582539439201355,
      "learning_rate": 1.5970750176645468e-05,
      "loss": 0.071,
      "step": 102140
    },
    {
      "epoch": 2.04275486941567,
      "grad_norm": 0.16119323670864105,
      "learning_rate": 1.5967417243264144e-05,
      "loss": 0.0726,
      "step": 102150
    },
    {
      "epoch": 2.0429548454185498,
      "grad_norm": 0.174309641122818,
      "learning_rate": 1.5964084309882814e-05,
      "loss": 0.073,
      "step": 102160
    },
    {
      "epoch": 2.0431548214214295,
      "grad_norm": 0.1889299601316452,
      "learning_rate": 1.5960751376501487e-05,
      "loss": 0.0806,
      "step": 102170
    },
    {
      "epoch": 2.043354797424309,
      "grad_norm": 0.09690770506858826,
      "learning_rate": 1.595741844312016e-05,
      "loss": 0.0921,
      "step": 102180
    },
    {
      "epoch": 2.043554773427189,
      "grad_norm": 0.2149198055267334,
      "learning_rate": 1.595408550973883e-05,
      "loss": 0.0758,
      "step": 102190
    },
    {
      "epoch": 2.0437547494300685,
      "grad_norm": 0.057332951575517654,
      "learning_rate": 1.5950752576357506e-05,
      "loss": 0.0753,
      "step": 102200
    },
    {
      "epoch": 2.043954725432948,
      "grad_norm": 0.09731760621070862,
      "learning_rate": 1.594741964297618e-05,
      "loss": 0.062,
      "step": 102210
    },
    {
      "epoch": 2.044154701435828,
      "grad_norm": 0.16928423941135406,
      "learning_rate": 1.594408670959485e-05,
      "loss": 0.0791,
      "step": 102220
    },
    {
      "epoch": 2.044354677438707,
      "grad_norm": 0.17769025266170502,
      "learning_rate": 1.5940753776213522e-05,
      "loss": 0.1128,
      "step": 102230
    },
    {
      "epoch": 2.044554653441587,
      "grad_norm": 0.12845222651958466,
      "learning_rate": 1.5937420842832195e-05,
      "loss": 0.0742,
      "step": 102240
    },
    {
      "epoch": 2.0447546294444665,
      "grad_norm": 0.11046652495861053,
      "learning_rate": 1.5934087909450868e-05,
      "loss": 0.0639,
      "step": 102250
    },
    {
      "epoch": 2.044954605447346,
      "grad_norm": 0.17462705075740814,
      "learning_rate": 1.593075497606954e-05,
      "loss": 0.0656,
      "step": 102260
    },
    {
      "epoch": 2.045154581450226,
      "grad_norm": 0.09524904191493988,
      "learning_rate": 1.592742204268821e-05,
      "loss": 0.0696,
      "step": 102270
    },
    {
      "epoch": 2.0453545574531056,
      "grad_norm": 0.08218447864055634,
      "learning_rate": 1.5924089109306883e-05,
      "loss": 0.0701,
      "step": 102280
    },
    {
      "epoch": 2.0455545334559853,
      "grad_norm": 0.1296233832836151,
      "learning_rate": 1.5920756175925556e-05,
      "loss": 0.0605,
      "step": 102290
    },
    {
      "epoch": 2.045754509458865,
      "grad_norm": 0.20495541393756866,
      "learning_rate": 1.591742324254423e-05,
      "loss": 0.0884,
      "step": 102300
    },
    {
      "epoch": 2.0459544854617446,
      "grad_norm": 0.15457966923713684,
      "learning_rate": 1.5914090309162902e-05,
      "loss": 0.0674,
      "step": 102310
    },
    {
      "epoch": 2.0461544614646243,
      "grad_norm": 0.09238282591104507,
      "learning_rate": 1.5910757375781575e-05,
      "loss": 0.0378,
      "step": 102320
    },
    {
      "epoch": 2.046354437467504,
      "grad_norm": 0.1998218595981598,
      "learning_rate": 1.5907424442400245e-05,
      "loss": 0.0832,
      "step": 102330
    },
    {
      "epoch": 2.0465544134703837,
      "grad_norm": 0.1139528676867485,
      "learning_rate": 1.5904091509018918e-05,
      "loss": 0.0476,
      "step": 102340
    },
    {
      "epoch": 2.0467543894732634,
      "grad_norm": 0.17690856754779816,
      "learning_rate": 1.590075857563759e-05,
      "loss": 0.077,
      "step": 102350
    },
    {
      "epoch": 2.046954365476143,
      "grad_norm": 0.22111745178699493,
      "learning_rate": 1.5897425642256264e-05,
      "loss": 0.1099,
      "step": 102360
    },
    {
      "epoch": 2.0471543414790223,
      "grad_norm": 0.1282155066728592,
      "learning_rate": 1.5894092708874937e-05,
      "loss": 0.0458,
      "step": 102370
    },
    {
      "epoch": 2.047354317481902,
      "grad_norm": 0.22839508950710297,
      "learning_rate": 1.5890759775493607e-05,
      "loss": 0.0888,
      "step": 102380
    },
    {
      "epoch": 2.0475542934847817,
      "grad_norm": 0.06631721556186676,
      "learning_rate": 1.588742684211228e-05,
      "loss": 0.1077,
      "step": 102390
    },
    {
      "epoch": 2.0477542694876614,
      "grad_norm": 0.2632288634777069,
      "learning_rate": 1.5884093908730953e-05,
      "loss": 0.0738,
      "step": 102400
    },
    {
      "epoch": 2.047954245490541,
      "grad_norm": 0.20415166020393372,
      "learning_rate": 1.5880760975349626e-05,
      "loss": 0.1004,
      "step": 102410
    },
    {
      "epoch": 2.0481542214934207,
      "grad_norm": 0.07415059953927994,
      "learning_rate": 1.58774280419683e-05,
      "loss": 0.0705,
      "step": 102420
    },
    {
      "epoch": 2.0483541974963004,
      "grad_norm": 0.19488996267318726,
      "learning_rate": 1.5874095108586968e-05,
      "loss": 0.0842,
      "step": 102430
    },
    {
      "epoch": 2.04855417349918,
      "grad_norm": 0.20202766358852386,
      "learning_rate": 1.587076217520564e-05,
      "loss": 0.0905,
      "step": 102440
    },
    {
      "epoch": 2.04875414950206,
      "grad_norm": 0.16901512444019318,
      "learning_rate": 1.5867429241824318e-05,
      "loss": 0.1086,
      "step": 102450
    },
    {
      "epoch": 2.0489541255049395,
      "grad_norm": 0.10733083635568619,
      "learning_rate": 1.5864096308442987e-05,
      "loss": 0.0591,
      "step": 102460
    },
    {
      "epoch": 2.049154101507819,
      "grad_norm": 0.1552770733833313,
      "learning_rate": 1.586076337506166e-05,
      "loss": 0.1012,
      "step": 102470
    },
    {
      "epoch": 2.049354077510699,
      "grad_norm": 0.16243897378444672,
      "learning_rate": 1.5857430441680333e-05,
      "loss": 0.0776,
      "step": 102480
    },
    {
      "epoch": 2.0495540535135786,
      "grad_norm": 0.260540246963501,
      "learning_rate": 1.5854097508299003e-05,
      "loss": 0.1086,
      "step": 102490
    },
    {
      "epoch": 2.0497540295164582,
      "grad_norm": 0.16598577797412872,
      "learning_rate": 1.585076457491768e-05,
      "loss": 0.0576,
      "step": 102500
    },
    {
      "epoch": 2.0499540055193375,
      "grad_norm": 0.19728520512580872,
      "learning_rate": 1.584743164153635e-05,
      "loss": 0.0628,
      "step": 102510
    },
    {
      "epoch": 2.050153981522217,
      "grad_norm": 0.12586449086666107,
      "learning_rate": 1.5844098708155022e-05,
      "loss": 0.0642,
      "step": 102520
    },
    {
      "epoch": 2.050353957525097,
      "grad_norm": 0.0947137400507927,
      "learning_rate": 1.5840765774773695e-05,
      "loss": 0.0518,
      "step": 102530
    },
    {
      "epoch": 2.0505539335279765,
      "grad_norm": 0.19758658111095428,
      "learning_rate": 1.5837432841392365e-05,
      "loss": 0.0922,
      "step": 102540
    },
    {
      "epoch": 2.0507539095308562,
      "grad_norm": 0.1805383563041687,
      "learning_rate": 1.583409990801104e-05,
      "loss": 0.0644,
      "step": 102550
    },
    {
      "epoch": 2.050953885533736,
      "grad_norm": 0.11889787018299103,
      "learning_rate": 1.5830766974629714e-05,
      "loss": 0.0878,
      "step": 102560
    },
    {
      "epoch": 2.0511538615366156,
      "grad_norm": 0.09334667026996613,
      "learning_rate": 1.5827434041248384e-05,
      "loss": 0.0502,
      "step": 102570
    },
    {
      "epoch": 2.0513538375394953,
      "grad_norm": 0.12122544646263123,
      "learning_rate": 1.5824101107867057e-05,
      "loss": 0.042,
      "step": 102580
    },
    {
      "epoch": 2.051553813542375,
      "grad_norm": 0.14065738022327423,
      "learning_rate": 1.582076817448573e-05,
      "loss": 0.0831,
      "step": 102590
    },
    {
      "epoch": 2.0517537895452547,
      "grad_norm": 0.12883980572223663,
      "learning_rate": 1.58174352411044e-05,
      "loss": 0.0531,
      "step": 102600
    },
    {
      "epoch": 2.0519537655481344,
      "grad_norm": 0.21889525651931763,
      "learning_rate": 1.5814102307723076e-05,
      "loss": 0.0688,
      "step": 102610
    },
    {
      "epoch": 2.052153741551014,
      "grad_norm": 0.07199794799089432,
      "learning_rate": 1.5810769374341745e-05,
      "loss": 0.0948,
      "step": 102620
    },
    {
      "epoch": 2.0523537175538937,
      "grad_norm": 0.07140690088272095,
      "learning_rate": 1.5807436440960418e-05,
      "loss": 0.0382,
      "step": 102630
    },
    {
      "epoch": 2.052553693556773,
      "grad_norm": 0.1127067357301712,
      "learning_rate": 1.580410350757909e-05,
      "loss": 0.0728,
      "step": 102640
    },
    {
      "epoch": 2.0527536695596527,
      "grad_norm": 0.21849235892295837,
      "learning_rate": 1.580077057419776e-05,
      "loss": 0.1137,
      "step": 102650
    },
    {
      "epoch": 2.0529536455625323,
      "grad_norm": 0.1355774849653244,
      "learning_rate": 1.5797437640816437e-05,
      "loss": 0.1194,
      "step": 102660
    },
    {
      "epoch": 2.053153621565412,
      "grad_norm": 0.1832069754600525,
      "learning_rate": 1.579410470743511e-05,
      "loss": 0.0856,
      "step": 102670
    },
    {
      "epoch": 2.0533535975682917,
      "grad_norm": 0.1530134379863739,
      "learning_rate": 1.579077177405378e-05,
      "loss": 0.0438,
      "step": 102680
    },
    {
      "epoch": 2.0535535735711714,
      "grad_norm": 0.20071148872375488,
      "learning_rate": 1.5787438840672453e-05,
      "loss": 0.0677,
      "step": 102690
    },
    {
      "epoch": 2.053753549574051,
      "grad_norm": 0.09784126281738281,
      "learning_rate": 1.5784105907291126e-05,
      "loss": 0.092,
      "step": 102700
    },
    {
      "epoch": 2.053953525576931,
      "grad_norm": 0.0731801688671112,
      "learning_rate": 1.57807729739098e-05,
      "loss": 0.0446,
      "step": 102710
    },
    {
      "epoch": 2.0541535015798105,
      "grad_norm": 0.15413308143615723,
      "learning_rate": 1.5777440040528472e-05,
      "loss": 0.0686,
      "step": 102720
    },
    {
      "epoch": 2.05435347758269,
      "grad_norm": 0.11078599095344543,
      "learning_rate": 1.577410710714714e-05,
      "loss": 0.0571,
      "step": 102730
    },
    {
      "epoch": 2.05455345358557,
      "grad_norm": 0.11086376756429672,
      "learning_rate": 1.5770774173765814e-05,
      "loss": 0.059,
      "step": 102740
    },
    {
      "epoch": 2.0547534295884495,
      "grad_norm": 0.07976189255714417,
      "learning_rate": 1.5767441240384487e-05,
      "loss": 0.0514,
      "step": 102750
    },
    {
      "epoch": 2.054953405591329,
      "grad_norm": 0.15459249913692474,
      "learning_rate": 1.576410830700316e-05,
      "loss": 0.0579,
      "step": 102760
    },
    {
      "epoch": 2.055153381594209,
      "grad_norm": 0.09393243491649628,
      "learning_rate": 1.5760775373621833e-05,
      "loss": 0.0702,
      "step": 102770
    },
    {
      "epoch": 2.055353357597088,
      "grad_norm": 0.23377510905265808,
      "learning_rate": 1.5757442440240506e-05,
      "loss": 0.0937,
      "step": 102780
    },
    {
      "epoch": 2.055553333599968,
      "grad_norm": 0.1268574297428131,
      "learning_rate": 1.5754109506859176e-05,
      "loss": 0.0597,
      "step": 102790
    },
    {
      "epoch": 2.0557533096028475,
      "grad_norm": 0.07132475078105927,
      "learning_rate": 1.575077657347785e-05,
      "loss": 0.0643,
      "step": 102800
    },
    {
      "epoch": 2.055953285605727,
      "grad_norm": 0.09078136086463928,
      "learning_rate": 1.5747443640096522e-05,
      "loss": 0.4342,
      "step": 102810
    },
    {
      "epoch": 2.056153261608607,
      "grad_norm": 0.16967864334583282,
      "learning_rate": 1.5744110706715195e-05,
      "loss": 0.1065,
      "step": 102820
    },
    {
      "epoch": 2.0563532376114866,
      "grad_norm": 0.10914251208305359,
      "learning_rate": 1.5740777773333868e-05,
      "loss": 0.0692,
      "step": 102830
    },
    {
      "epoch": 2.0565532136143663,
      "grad_norm": 0.12453551590442657,
      "learning_rate": 1.5737444839952538e-05,
      "loss": 0.0947,
      "step": 102840
    },
    {
      "epoch": 2.056753189617246,
      "grad_norm": 0.14563333988189697,
      "learning_rate": 1.573411190657121e-05,
      "loss": 0.0773,
      "step": 102850
    },
    {
      "epoch": 2.0569531656201256,
      "grad_norm": 0.22116202116012573,
      "learning_rate": 1.5730778973189887e-05,
      "loss": 0.1297,
      "step": 102860
    },
    {
      "epoch": 2.0571531416230053,
      "grad_norm": 0.14734545350074768,
      "learning_rate": 1.5727446039808557e-05,
      "loss": 0.046,
      "step": 102870
    },
    {
      "epoch": 2.057353117625885,
      "grad_norm": 0.19200894236564636,
      "learning_rate": 1.572411310642723e-05,
      "loss": 0.0817,
      "step": 102880
    },
    {
      "epoch": 2.0575530936287647,
      "grad_norm": 0.261940598487854,
      "learning_rate": 1.5720780173045903e-05,
      "loss": 0.0763,
      "step": 102890
    },
    {
      "epoch": 2.0577530696316444,
      "grad_norm": 0.1375858038663864,
      "learning_rate": 1.5717447239664572e-05,
      "loss": 0.0673,
      "step": 102900
    },
    {
      "epoch": 2.057953045634524,
      "grad_norm": 0.060376234352588654,
      "learning_rate": 1.571411430628325e-05,
      "loss": 0.0845,
      "step": 102910
    },
    {
      "epoch": 2.0581530216374033,
      "grad_norm": 0.10512036830186844,
      "learning_rate": 1.571078137290192e-05,
      "loss": 0.0805,
      "step": 102920
    },
    {
      "epoch": 2.058352997640283,
      "grad_norm": 0.12853677570819855,
      "learning_rate": 1.570744843952059e-05,
      "loss": 0.0744,
      "step": 102930
    },
    {
      "epoch": 2.0585529736431627,
      "grad_norm": 0.20992794632911682,
      "learning_rate": 1.5704115506139264e-05,
      "loss": 0.0773,
      "step": 102940
    },
    {
      "epoch": 2.0587529496460424,
      "grad_norm": 0.18439297378063202,
      "learning_rate": 1.5700782572757934e-05,
      "loss": 0.0479,
      "step": 102950
    },
    {
      "epoch": 2.058952925648922,
      "grad_norm": 0.106022909283638,
      "learning_rate": 1.569744963937661e-05,
      "loss": 0.0612,
      "step": 102960
    },
    {
      "epoch": 2.0591529016518018,
      "grad_norm": 0.22750291228294373,
      "learning_rate": 1.5694116705995283e-05,
      "loss": 0.0821,
      "step": 102970
    },
    {
      "epoch": 2.0593528776546814,
      "grad_norm": 0.1242588609457016,
      "learning_rate": 1.5690783772613953e-05,
      "loss": 0.0512,
      "step": 102980
    },
    {
      "epoch": 2.059552853657561,
      "grad_norm": 0.15827445685863495,
      "learning_rate": 1.5687450839232626e-05,
      "loss": 0.0526,
      "step": 102990
    },
    {
      "epoch": 2.059752829660441,
      "grad_norm": 0.223760724067688,
      "learning_rate": 1.56841179058513e-05,
      "loss": 0.0947,
      "step": 103000
    },
    {
      "epoch": 2.0599528056633205,
      "grad_norm": 0.1401829868555069,
      "learning_rate": 1.5680784972469972e-05,
      "loss": 0.0635,
      "step": 103010
    },
    {
      "epoch": 2.0601527816662,
      "grad_norm": 0.09281425923109055,
      "learning_rate": 1.5677452039088645e-05,
      "loss": 0.0567,
      "step": 103020
    },
    {
      "epoch": 2.06035275766908,
      "grad_norm": 0.2328297197818756,
      "learning_rate": 1.5674119105707315e-05,
      "loss": 0.1035,
      "step": 103030
    },
    {
      "epoch": 2.0605527336719596,
      "grad_norm": 0.07501740008592606,
      "learning_rate": 1.5670786172325988e-05,
      "loss": 0.0771,
      "step": 103040
    },
    {
      "epoch": 2.060752709674839,
      "grad_norm": 0.143539160490036,
      "learning_rate": 1.566745323894466e-05,
      "loss": 0.0867,
      "step": 103050
    },
    {
      "epoch": 2.0609526856777185,
      "grad_norm": 0.1630697101354599,
      "learning_rate": 1.566412030556333e-05,
      "loss": 0.0788,
      "step": 103060
    },
    {
      "epoch": 2.061152661680598,
      "grad_norm": 0.2788084149360657,
      "learning_rate": 1.5660787372182007e-05,
      "loss": 0.0873,
      "step": 103070
    },
    {
      "epoch": 2.061352637683478,
      "grad_norm": 0.06553030014038086,
      "learning_rate": 1.565745443880068e-05,
      "loss": 0.0513,
      "step": 103080
    },
    {
      "epoch": 2.0615526136863576,
      "grad_norm": 0.19574308395385742,
      "learning_rate": 1.565412150541935e-05,
      "loss": 0.118,
      "step": 103090
    },
    {
      "epoch": 2.0617525896892372,
      "grad_norm": 0.19476677477359772,
      "learning_rate": 1.5650788572038022e-05,
      "loss": 0.0657,
      "step": 103100
    },
    {
      "epoch": 2.061952565692117,
      "grad_norm": 0.1746659278869629,
      "learning_rate": 1.5647455638656695e-05,
      "loss": 0.1039,
      "step": 103110
    },
    {
      "epoch": 2.0621525416949966,
      "grad_norm": 0.20750097930431366,
      "learning_rate": 1.5644122705275368e-05,
      "loss": 0.0953,
      "step": 103120
    },
    {
      "epoch": 2.0623525176978763,
      "grad_norm": 0.17856216430664062,
      "learning_rate": 1.564078977189404e-05,
      "loss": 0.0678,
      "step": 103130
    },
    {
      "epoch": 2.062552493700756,
      "grad_norm": 0.14187441766262054,
      "learning_rate": 1.563745683851271e-05,
      "loss": 0.0851,
      "step": 103140
    },
    {
      "epoch": 2.0627524697036357,
      "grad_norm": 0.11273343861103058,
      "learning_rate": 1.5634123905131384e-05,
      "loss": 0.0649,
      "step": 103150
    },
    {
      "epoch": 2.0629524457065154,
      "grad_norm": 0.251434862613678,
      "learning_rate": 1.5630790971750057e-05,
      "loss": 0.0821,
      "step": 103160
    },
    {
      "epoch": 2.063152421709395,
      "grad_norm": 0.21538549661636353,
      "learning_rate": 1.562745803836873e-05,
      "loss": 0.0694,
      "step": 103170
    },
    {
      "epoch": 2.0633523977122747,
      "grad_norm": 0.05962177738547325,
      "learning_rate": 1.5624125104987403e-05,
      "loss": 0.059,
      "step": 103180
    },
    {
      "epoch": 2.063552373715154,
      "grad_norm": 0.12017861753702164,
      "learning_rate": 1.5620792171606076e-05,
      "loss": 0.0438,
      "step": 103190
    },
    {
      "epoch": 2.0637523497180337,
      "grad_norm": 0.1058318167924881,
      "learning_rate": 1.5617459238224745e-05,
      "loss": 0.0419,
      "step": 103200
    },
    {
      "epoch": 2.0639523257209134,
      "grad_norm": 0.1362629234790802,
      "learning_rate": 1.561412630484342e-05,
      "loss": 0.0832,
      "step": 103210
    },
    {
      "epoch": 2.064152301723793,
      "grad_norm": 0.18285970389842987,
      "learning_rate": 1.561079337146209e-05,
      "loss": 0.0726,
      "step": 103220
    },
    {
      "epoch": 2.0643522777266727,
      "grad_norm": 0.17765210568904877,
      "learning_rate": 1.5607460438080765e-05,
      "loss": 0.0824,
      "step": 103230
    },
    {
      "epoch": 2.0645522537295524,
      "grad_norm": 0.14429634809494019,
      "learning_rate": 1.5604127504699438e-05,
      "loss": 0.0614,
      "step": 103240
    },
    {
      "epoch": 2.064752229732432,
      "grad_norm": 0.18448947370052338,
      "learning_rate": 1.5600794571318107e-05,
      "loss": 0.079,
      "step": 103250
    },
    {
      "epoch": 2.064952205735312,
      "grad_norm": 0.15963464975357056,
      "learning_rate": 1.559746163793678e-05,
      "loss": 0.0655,
      "step": 103260
    },
    {
      "epoch": 2.0651521817381915,
      "grad_norm": 0.15084154903888702,
      "learning_rate": 1.5594128704555457e-05,
      "loss": 0.0833,
      "step": 103270
    },
    {
      "epoch": 2.065352157741071,
      "grad_norm": 0.08936116099357605,
      "learning_rate": 1.5590795771174126e-05,
      "loss": 0.0874,
      "step": 103280
    },
    {
      "epoch": 2.065552133743951,
      "grad_norm": 0.1932414174079895,
      "learning_rate": 1.55874628377928e-05,
      "loss": 0.057,
      "step": 103290
    },
    {
      "epoch": 2.0657521097468305,
      "grad_norm": 0.09345914423465729,
      "learning_rate": 1.5584129904411472e-05,
      "loss": 0.085,
      "step": 103300
    },
    {
      "epoch": 2.0659520857497102,
      "grad_norm": 0.24459727108478546,
      "learning_rate": 1.5580796971030142e-05,
      "loss": 0.0919,
      "step": 103310
    },
    {
      "epoch": 2.0661520617525895,
      "grad_norm": 0.2034754455089569,
      "learning_rate": 1.5577464037648818e-05,
      "loss": 0.0975,
      "step": 103320
    },
    {
      "epoch": 2.066352037755469,
      "grad_norm": 0.19134365022182465,
      "learning_rate": 1.5574131104267488e-05,
      "loss": 0.06,
      "step": 103330
    },
    {
      "epoch": 2.066552013758349,
      "grad_norm": 0.20299284160137177,
      "learning_rate": 1.557079817088616e-05,
      "loss": 0.0948,
      "step": 103340
    },
    {
      "epoch": 2.0667519897612285,
      "grad_norm": 0.09847958385944366,
      "learning_rate": 1.5567465237504834e-05,
      "loss": 0.0451,
      "step": 103350
    },
    {
      "epoch": 2.0669519657641082,
      "grad_norm": 0.13500523567199707,
      "learning_rate": 1.5564132304123503e-05,
      "loss": 0.1074,
      "step": 103360
    },
    {
      "epoch": 2.067151941766988,
      "grad_norm": 0.28106287121772766,
      "learning_rate": 1.556079937074218e-05,
      "loss": 0.0512,
      "step": 103370
    },
    {
      "epoch": 2.0673519177698676,
      "grad_norm": 0.19882725179195404,
      "learning_rate": 1.5557466437360853e-05,
      "loss": 0.0382,
      "step": 103380
    },
    {
      "epoch": 2.0675518937727473,
      "grad_norm": 0.08006642013788223,
      "learning_rate": 1.5554133503979522e-05,
      "loss": 0.057,
      "step": 103390
    },
    {
      "epoch": 2.067751869775627,
      "grad_norm": 0.12297608703374863,
      "learning_rate": 1.5550800570598195e-05,
      "loss": 0.0646,
      "step": 103400
    },
    {
      "epoch": 2.0679518457785067,
      "grad_norm": 0.08419640362262726,
      "learning_rate": 1.554746763721687e-05,
      "loss": 0.0609,
      "step": 103410
    },
    {
      "epoch": 2.0681518217813863,
      "grad_norm": 0.19733183085918427,
      "learning_rate": 1.554413470383554e-05,
      "loss": 0.093,
      "step": 103420
    },
    {
      "epoch": 2.068351797784266,
      "grad_norm": 0.2297983169555664,
      "learning_rate": 1.5540801770454214e-05,
      "loss": 0.0705,
      "step": 103430
    },
    {
      "epoch": 2.0685517737871457,
      "grad_norm": 0.12812738120555878,
      "learning_rate": 1.5537468837072884e-05,
      "loss": 0.1172,
      "step": 103440
    },
    {
      "epoch": 2.0687517497900254,
      "grad_norm": 0.08395195752382278,
      "learning_rate": 1.5534135903691557e-05,
      "loss": 0.0702,
      "step": 103450
    },
    {
      "epoch": 2.0689517257929047,
      "grad_norm": 0.11498262733221054,
      "learning_rate": 1.553080297031023e-05,
      "loss": 0.0715,
      "step": 103460
    },
    {
      "epoch": 2.0691517017957843,
      "grad_norm": 0.15357497334480286,
      "learning_rate": 1.5527470036928903e-05,
      "loss": 0.0747,
      "step": 103470
    },
    {
      "epoch": 2.069351677798664,
      "grad_norm": 0.28644996881484985,
      "learning_rate": 1.5524137103547576e-05,
      "loss": 0.0598,
      "step": 103480
    },
    {
      "epoch": 2.0695516538015437,
      "grad_norm": 0.20985117554664612,
      "learning_rate": 1.552080417016625e-05,
      "loss": 0.0837,
      "step": 103490
    },
    {
      "epoch": 2.0697516298044234,
      "grad_norm": 0.10887312144041061,
      "learning_rate": 1.551747123678492e-05,
      "loss": 0.0917,
      "step": 103500
    },
    {
      "epoch": 2.069951605807303,
      "grad_norm": 0.14010131359100342,
      "learning_rate": 1.551413830340359e-05,
      "loss": 0.042,
      "step": 103510
    },
    {
      "epoch": 2.0701515818101828,
      "grad_norm": 0.0741400271654129,
      "learning_rate": 1.5510805370022265e-05,
      "loss": 0.0862,
      "step": 103520
    },
    {
      "epoch": 2.0703515578130625,
      "grad_norm": 0.07092677801847458,
      "learning_rate": 1.5507472436640938e-05,
      "loss": 0.0681,
      "step": 103530
    },
    {
      "epoch": 2.070551533815942,
      "grad_norm": 0.28615888953208923,
      "learning_rate": 1.550413950325961e-05,
      "loss": 0.0741,
      "step": 103540
    },
    {
      "epoch": 2.070751509818822,
      "grad_norm": 0.08260372281074524,
      "learning_rate": 1.550080656987828e-05,
      "loss": 0.0645,
      "step": 103550
    },
    {
      "epoch": 2.0709514858217015,
      "grad_norm": 0.05333031341433525,
      "learning_rate": 1.5497473636496953e-05,
      "loss": 0.079,
      "step": 103560
    },
    {
      "epoch": 2.071151461824581,
      "grad_norm": 0.1419796645641327,
      "learning_rate": 1.5494140703115626e-05,
      "loss": 0.0827,
      "step": 103570
    },
    {
      "epoch": 2.071351437827461,
      "grad_norm": 0.08767480403184891,
      "learning_rate": 1.54908077697343e-05,
      "loss": 0.045,
      "step": 103580
    },
    {
      "epoch": 2.07155141383034,
      "grad_norm": 0.11363398283720016,
      "learning_rate": 1.5487474836352972e-05,
      "loss": 0.0847,
      "step": 103590
    },
    {
      "epoch": 2.07175138983322,
      "grad_norm": 0.11908642947673798,
      "learning_rate": 1.5484141902971645e-05,
      "loss": 0.0886,
      "step": 103600
    },
    {
      "epoch": 2.0719513658360995,
      "grad_norm": 0.24768663942813873,
      "learning_rate": 1.5480808969590315e-05,
      "loss": 0.0751,
      "step": 103610
    },
    {
      "epoch": 2.072151341838979,
      "grad_norm": 0.12994855642318726,
      "learning_rate": 1.5477476036208988e-05,
      "loss": 0.0647,
      "step": 103620
    },
    {
      "epoch": 2.072351317841859,
      "grad_norm": 0.1133723109960556,
      "learning_rate": 1.547414310282766e-05,
      "loss": 0.0718,
      "step": 103630
    },
    {
      "epoch": 2.0725512938447386,
      "grad_norm": 0.18177832663059235,
      "learning_rate": 1.5470810169446334e-05,
      "loss": 0.0814,
      "step": 103640
    },
    {
      "epoch": 2.0727512698476183,
      "grad_norm": 0.07007681578397751,
      "learning_rate": 1.5467477236065007e-05,
      "loss": 0.0843,
      "step": 103650
    },
    {
      "epoch": 2.072951245850498,
      "grad_norm": 0.09739143401384354,
      "learning_rate": 1.5464144302683677e-05,
      "loss": 0.057,
      "step": 103660
    },
    {
      "epoch": 2.0731512218533776,
      "grad_norm": 0.08532129228115082,
      "learning_rate": 1.546081136930235e-05,
      "loss": 0.0818,
      "step": 103670
    },
    {
      "epoch": 2.0733511978562573,
      "grad_norm": 0.21649594604969025,
      "learning_rate": 1.5457478435921026e-05,
      "loss": 0.0718,
      "step": 103680
    },
    {
      "epoch": 2.073551173859137,
      "grad_norm": 0.20172299444675446,
      "learning_rate": 1.5454145502539696e-05,
      "loss": 0.0989,
      "step": 103690
    },
    {
      "epoch": 2.0737511498620167,
      "grad_norm": 0.19032584130764008,
      "learning_rate": 1.545081256915837e-05,
      "loss": 0.0733,
      "step": 103700
    },
    {
      "epoch": 2.0739511258648964,
      "grad_norm": 0.08663634955883026,
      "learning_rate": 1.544747963577704e-05,
      "loss": 0.0775,
      "step": 103710
    },
    {
      "epoch": 2.074151101867776,
      "grad_norm": 0.06807131320238113,
      "learning_rate": 1.544414670239571e-05,
      "loss": 0.1607,
      "step": 103720
    },
    {
      "epoch": 2.0743510778706553,
      "grad_norm": 0.09951179474592209,
      "learning_rate": 1.5440813769014388e-05,
      "loss": 0.0655,
      "step": 103730
    },
    {
      "epoch": 2.074551053873535,
      "grad_norm": 0.11380436271429062,
      "learning_rate": 1.5437480835633057e-05,
      "loss": 0.0948,
      "step": 103740
    },
    {
      "epoch": 2.0747510298764147,
      "grad_norm": 0.09603122621774673,
      "learning_rate": 1.543414790225173e-05,
      "loss": 0.0731,
      "step": 103750
    },
    {
      "epoch": 2.0749510058792944,
      "grad_norm": 0.14097975194454193,
      "learning_rate": 1.5430814968870403e-05,
      "loss": 0.0625,
      "step": 103760
    },
    {
      "epoch": 2.075150981882174,
      "grad_norm": 0.08509083092212677,
      "learning_rate": 1.5427482035489073e-05,
      "loss": 0.0524,
      "step": 103770
    },
    {
      "epoch": 2.0753509578850537,
      "grad_norm": 0.15548300743103027,
      "learning_rate": 1.542414910210775e-05,
      "loss": 0.0596,
      "step": 103780
    },
    {
      "epoch": 2.0755509338879334,
      "grad_norm": 0.0629449263215065,
      "learning_rate": 1.5420816168726422e-05,
      "loss": 0.0402,
      "step": 103790
    },
    {
      "epoch": 2.075750909890813,
      "grad_norm": 0.13055603206157684,
      "learning_rate": 1.5417483235345092e-05,
      "loss": 0.1145,
      "step": 103800
    },
    {
      "epoch": 2.075950885893693,
      "grad_norm": 0.20502206683158875,
      "learning_rate": 1.5414150301963765e-05,
      "loss": 0.087,
      "step": 103810
    },
    {
      "epoch": 2.0761508618965725,
      "grad_norm": 0.15373778343200684,
      "learning_rate": 1.5410817368582438e-05,
      "loss": 0.0678,
      "step": 103820
    },
    {
      "epoch": 2.076350837899452,
      "grad_norm": 0.13029621541500092,
      "learning_rate": 1.540748443520111e-05,
      "loss": 0.0745,
      "step": 103830
    },
    {
      "epoch": 2.076550813902332,
      "grad_norm": 0.08294158428907394,
      "learning_rate": 1.5404151501819784e-05,
      "loss": 0.0694,
      "step": 103840
    },
    {
      "epoch": 2.0767507899052116,
      "grad_norm": 0.17130914330482483,
      "learning_rate": 1.5400818568438453e-05,
      "loss": 0.0664,
      "step": 103850
    },
    {
      "epoch": 2.076950765908091,
      "grad_norm": 0.12001477181911469,
      "learning_rate": 1.5397485635057126e-05,
      "loss": 0.0709,
      "step": 103860
    },
    {
      "epoch": 2.0771507419109705,
      "grad_norm": 0.17165960371494293,
      "learning_rate": 1.53941527016758e-05,
      "loss": 0.0424,
      "step": 103870
    },
    {
      "epoch": 2.07735071791385,
      "grad_norm": 0.08800722658634186,
      "learning_rate": 1.5390819768294473e-05,
      "loss": 0.0656,
      "step": 103880
    },
    {
      "epoch": 2.07755069391673,
      "grad_norm": 0.13478872179985046,
      "learning_rate": 1.5387486834913146e-05,
      "loss": 0.0943,
      "step": 103890
    },
    {
      "epoch": 2.0777506699196095,
      "grad_norm": 0.11319554597139359,
      "learning_rate": 1.538415390153182e-05,
      "loss": 0.1253,
      "step": 103900
    },
    {
      "epoch": 2.0779506459224892,
      "grad_norm": 0.11316541582345963,
      "learning_rate": 1.5380820968150488e-05,
      "loss": 0.0647,
      "step": 103910
    },
    {
      "epoch": 2.078150621925369,
      "grad_norm": 0.1252916306257248,
      "learning_rate": 1.537748803476916e-05,
      "loss": 0.0473,
      "step": 103920
    },
    {
      "epoch": 2.0783505979282486,
      "grad_norm": 0.16731494665145874,
      "learning_rate": 1.5374155101387834e-05,
      "loss": 0.0748,
      "step": 103930
    },
    {
      "epoch": 2.0785505739311283,
      "grad_norm": 0.10995350033044815,
      "learning_rate": 1.5370822168006507e-05,
      "loss": 0.0749,
      "step": 103940
    },
    {
      "epoch": 2.078750549934008,
      "grad_norm": 0.13347764313220978,
      "learning_rate": 1.536748923462518e-05,
      "loss": 0.1104,
      "step": 103950
    },
    {
      "epoch": 2.0789505259368877,
      "grad_norm": 0.11732271313667297,
      "learning_rate": 1.536415630124385e-05,
      "loss": 0.0981,
      "step": 103960
    },
    {
      "epoch": 2.0791505019397674,
      "grad_norm": 0.12736690044403076,
      "learning_rate": 1.5360823367862523e-05,
      "loss": 0.0853,
      "step": 103970
    },
    {
      "epoch": 2.079350477942647,
      "grad_norm": 0.1783854067325592,
      "learning_rate": 1.53574904344812e-05,
      "loss": 0.0634,
      "step": 103980
    },
    {
      "epoch": 2.0795504539455267,
      "grad_norm": 0.1477360874414444,
      "learning_rate": 1.535415750109987e-05,
      "loss": 0.0545,
      "step": 103990
    },
    {
      "epoch": 2.079750429948406,
      "grad_norm": 0.13773086667060852,
      "learning_rate": 1.5350824567718542e-05,
      "loss": 0.1594,
      "step": 104000
    },
    {
      "epoch": 2.0799504059512857,
      "grad_norm": 0.238460972905159,
      "learning_rate": 1.5347491634337215e-05,
      "loss": 0.0784,
      "step": 104010
    },
    {
      "epoch": 2.0801503819541654,
      "grad_norm": 0.13837307691574097,
      "learning_rate": 1.5344158700955884e-05,
      "loss": 0.0833,
      "step": 104020
    },
    {
      "epoch": 2.080350357957045,
      "grad_norm": 0.20467254519462585,
      "learning_rate": 1.534082576757456e-05,
      "loss": 0.0622,
      "step": 104030
    },
    {
      "epoch": 2.0805503339599247,
      "grad_norm": 0.10456373542547226,
      "learning_rate": 1.533749283419323e-05,
      "loss": 0.1036,
      "step": 104040
    },
    {
      "epoch": 2.0807503099628044,
      "grad_norm": 0.11141687631607056,
      "learning_rate": 1.5334159900811903e-05,
      "loss": 0.0693,
      "step": 104050
    },
    {
      "epoch": 2.080950285965684,
      "grad_norm": 0.09261874109506607,
      "learning_rate": 1.5330826967430576e-05,
      "loss": 0.088,
      "step": 104060
    },
    {
      "epoch": 2.081150261968564,
      "grad_norm": 0.16635730862617493,
      "learning_rate": 1.5327494034049246e-05,
      "loss": 0.0873,
      "step": 104070
    },
    {
      "epoch": 2.0813502379714435,
      "grad_norm": 0.20132170617580414,
      "learning_rate": 1.532416110066792e-05,
      "loss": 0.091,
      "step": 104080
    },
    {
      "epoch": 2.081550213974323,
      "grad_norm": 0.1356096863746643,
      "learning_rate": 1.5320828167286595e-05,
      "loss": 0.0443,
      "step": 104090
    },
    {
      "epoch": 2.081750189977203,
      "grad_norm": 0.13514842092990875,
      "learning_rate": 1.5317495233905265e-05,
      "loss": 0.0572,
      "step": 104100
    },
    {
      "epoch": 2.0819501659800825,
      "grad_norm": 0.171504408121109,
      "learning_rate": 1.5314162300523938e-05,
      "loss": 0.068,
      "step": 104110
    },
    {
      "epoch": 2.082150141982962,
      "grad_norm": 0.07856030762195587,
      "learning_rate": 1.531082936714261e-05,
      "loss": 0.0571,
      "step": 104120
    },
    {
      "epoch": 2.082350117985842,
      "grad_norm": 0.18327714502811432,
      "learning_rate": 1.530749643376128e-05,
      "loss": 0.073,
      "step": 104130
    },
    {
      "epoch": 2.082550093988721,
      "grad_norm": 0.1140744537115097,
      "learning_rate": 1.5304163500379957e-05,
      "loss": 0.0754,
      "step": 104140
    },
    {
      "epoch": 2.082750069991601,
      "grad_norm": 0.20421123504638672,
      "learning_rate": 1.5300830566998627e-05,
      "loss": 0.0771,
      "step": 104150
    },
    {
      "epoch": 2.0829500459944805,
      "grad_norm": 0.16729356348514557,
      "learning_rate": 1.52974976336173e-05,
      "loss": 0.0881,
      "step": 104160
    },
    {
      "epoch": 2.08315002199736,
      "grad_norm": 0.201288640499115,
      "learning_rate": 1.5294164700235973e-05,
      "loss": 0.0519,
      "step": 104170
    },
    {
      "epoch": 2.08334999800024,
      "grad_norm": 0.12501594424247742,
      "learning_rate": 1.5290831766854642e-05,
      "loss": 0.1004,
      "step": 104180
    },
    {
      "epoch": 2.0835499740031196,
      "grad_norm": 0.08913355320692062,
      "learning_rate": 1.528749883347332e-05,
      "loss": 0.0626,
      "step": 104190
    },
    {
      "epoch": 2.0837499500059993,
      "grad_norm": 0.13814404606819153,
      "learning_rate": 1.528416590009199e-05,
      "loss": 0.0628,
      "step": 104200
    },
    {
      "epoch": 2.083949926008879,
      "grad_norm": 0.06230489909648895,
      "learning_rate": 1.528083296671066e-05,
      "loss": 0.0482,
      "step": 104210
    },
    {
      "epoch": 2.0841499020117586,
      "grad_norm": 0.17838169634342194,
      "learning_rate": 1.5277500033329334e-05,
      "loss": 0.0574,
      "step": 104220
    },
    {
      "epoch": 2.0843498780146383,
      "grad_norm": 0.1957639753818512,
      "learning_rate": 1.5274167099948007e-05,
      "loss": 0.0786,
      "step": 104230
    },
    {
      "epoch": 2.084549854017518,
      "grad_norm": 0.21489736437797546,
      "learning_rate": 1.527083416656668e-05,
      "loss": 0.101,
      "step": 104240
    },
    {
      "epoch": 2.0847498300203977,
      "grad_norm": 0.1718667596578598,
      "learning_rate": 1.5267501233185353e-05,
      "loss": 0.097,
      "step": 104250
    },
    {
      "epoch": 2.0849498060232774,
      "grad_norm": 0.20739872753620148,
      "learning_rate": 1.5264168299804023e-05,
      "loss": 0.0723,
      "step": 104260
    },
    {
      "epoch": 2.085149782026157,
      "grad_norm": 0.09303339570760727,
      "learning_rate": 1.5260835366422696e-05,
      "loss": 0.0692,
      "step": 104270
    },
    {
      "epoch": 2.0853497580290363,
      "grad_norm": 0.10282541066408157,
      "learning_rate": 1.5257502433041367e-05,
      "loss": 0.0655,
      "step": 104280
    },
    {
      "epoch": 2.085549734031916,
      "grad_norm": 0.2290707230567932,
      "learning_rate": 1.5254169499660042e-05,
      "loss": 0.0797,
      "step": 104290
    },
    {
      "epoch": 2.0857497100347957,
      "grad_norm": 0.0929524227976799,
      "learning_rate": 1.5250836566278715e-05,
      "loss": 0.0814,
      "step": 104300
    },
    {
      "epoch": 2.0859496860376754,
      "grad_norm": 0.17889705300331116,
      "learning_rate": 1.5247503632897386e-05,
      "loss": 0.0795,
      "step": 104310
    },
    {
      "epoch": 2.086149662040555,
      "grad_norm": 0.13949908316135406,
      "learning_rate": 1.5244170699516058e-05,
      "loss": 0.0691,
      "step": 104320
    },
    {
      "epoch": 2.0863496380434348,
      "grad_norm": 0.1525537073612213,
      "learning_rate": 1.524083776613473e-05,
      "loss": 0.0407,
      "step": 104330
    },
    {
      "epoch": 2.0865496140463144,
      "grad_norm": 0.06300175189971924,
      "learning_rate": 1.5237504832753405e-05,
      "loss": 0.0508,
      "step": 104340
    },
    {
      "epoch": 2.086749590049194,
      "grad_norm": 0.20429328083992004,
      "learning_rate": 1.5234171899372077e-05,
      "loss": 0.0914,
      "step": 104350
    },
    {
      "epoch": 2.086949566052074,
      "grad_norm": 0.17601360380649567,
      "learning_rate": 1.5230838965990748e-05,
      "loss": 0.0759,
      "step": 104360
    },
    {
      "epoch": 2.0871495420549535,
      "grad_norm": 0.06895811855792999,
      "learning_rate": 1.5227506032609421e-05,
      "loss": 0.0896,
      "step": 104370
    },
    {
      "epoch": 2.087349518057833,
      "grad_norm": 0.10421827435493469,
      "learning_rate": 1.5224173099228092e-05,
      "loss": 0.0792,
      "step": 104380
    },
    {
      "epoch": 2.087549494060713,
      "grad_norm": 0.1812928318977356,
      "learning_rate": 1.5220840165846767e-05,
      "loss": 0.0887,
      "step": 104390
    },
    {
      "epoch": 2.0877494700635926,
      "grad_norm": 0.07596568018198013,
      "learning_rate": 1.5217507232465438e-05,
      "loss": 0.094,
      "step": 104400
    },
    {
      "epoch": 2.087949446066472,
      "grad_norm": 0.10085009783506393,
      "learning_rate": 1.5214174299084111e-05,
      "loss": 0.061,
      "step": 104410
    },
    {
      "epoch": 2.0881494220693515,
      "grad_norm": 0.12146226316690445,
      "learning_rate": 1.5210841365702783e-05,
      "loss": 0.0483,
      "step": 104420
    },
    {
      "epoch": 2.088349398072231,
      "grad_norm": 0.06205310299992561,
      "learning_rate": 1.5207508432321454e-05,
      "loss": 0.0445,
      "step": 104430
    },
    {
      "epoch": 2.088549374075111,
      "grad_norm": 0.2446797788143158,
      "learning_rate": 1.5204175498940129e-05,
      "loss": 0.0911,
      "step": 104440
    },
    {
      "epoch": 2.0887493500779906,
      "grad_norm": 0.1422272026538849,
      "learning_rate": 1.5200842565558802e-05,
      "loss": 0.0828,
      "step": 104450
    },
    {
      "epoch": 2.0889493260808703,
      "grad_norm": 0.11377166956663132,
      "learning_rate": 1.5197509632177473e-05,
      "loss": 0.0476,
      "step": 104460
    },
    {
      "epoch": 2.08914930208375,
      "grad_norm": 0.25047147274017334,
      "learning_rate": 1.5194176698796144e-05,
      "loss": 0.0788,
      "step": 104470
    },
    {
      "epoch": 2.0893492780866296,
      "grad_norm": 0.11831173300743103,
      "learning_rate": 1.5190843765414817e-05,
      "loss": 0.0867,
      "step": 104480
    },
    {
      "epoch": 2.0895492540895093,
      "grad_norm": 0.11537513881921768,
      "learning_rate": 1.5187510832033492e-05,
      "loss": 0.0538,
      "step": 104490
    },
    {
      "epoch": 2.089749230092389,
      "grad_norm": 0.12431756407022476,
      "learning_rate": 1.5184177898652163e-05,
      "loss": 0.0746,
      "step": 104500
    },
    {
      "epoch": 2.0899492060952687,
      "grad_norm": 0.11828910559415817,
      "learning_rate": 1.5180844965270834e-05,
      "loss": 0.1007,
      "step": 104510
    },
    {
      "epoch": 2.0901491820981484,
      "grad_norm": 0.10494466871023178,
      "learning_rate": 1.5177512031889507e-05,
      "loss": 0.0697,
      "step": 104520
    },
    {
      "epoch": 2.090349158101028,
      "grad_norm": 0.17886272072792053,
      "learning_rate": 1.5174179098508179e-05,
      "loss": 0.0403,
      "step": 104530
    },
    {
      "epoch": 2.0905491341039077,
      "grad_norm": 0.21377892792224884,
      "learning_rate": 1.5170846165126853e-05,
      "loss": 0.0893,
      "step": 104540
    },
    {
      "epoch": 2.090749110106787,
      "grad_norm": 0.1886395514011383,
      "learning_rate": 1.5167513231745525e-05,
      "loss": 0.1045,
      "step": 104550
    },
    {
      "epoch": 2.0909490861096667,
      "grad_norm": 0.10772792249917984,
      "learning_rate": 1.5164180298364198e-05,
      "loss": 0.0802,
      "step": 104560
    },
    {
      "epoch": 2.0911490621125464,
      "grad_norm": 0.11114627122879028,
      "learning_rate": 1.5160847364982869e-05,
      "loss": 0.0955,
      "step": 104570
    },
    {
      "epoch": 2.091349038115426,
      "grad_norm": 0.17641021311283112,
      "learning_rate": 1.515751443160154e-05,
      "loss": 0.0652,
      "step": 104580
    },
    {
      "epoch": 2.0915490141183057,
      "grad_norm": 0.1350671648979187,
      "learning_rate": 1.5154181498220213e-05,
      "loss": 0.0667,
      "step": 104590
    },
    {
      "epoch": 2.0917489901211854,
      "grad_norm": 0.13317100703716278,
      "learning_rate": 1.5150848564838888e-05,
      "loss": 0.092,
      "step": 104600
    },
    {
      "epoch": 2.091948966124065,
      "grad_norm": 0.09100265800952911,
      "learning_rate": 1.514751563145756e-05,
      "loss": 0.1003,
      "step": 104610
    },
    {
      "epoch": 2.092148942126945,
      "grad_norm": 0.1693890541791916,
      "learning_rate": 1.514418269807623e-05,
      "loss": 0.0738,
      "step": 104620
    },
    {
      "epoch": 2.0923489181298245,
      "grad_norm": 0.16205555200576782,
      "learning_rate": 1.5140849764694904e-05,
      "loss": 0.0863,
      "step": 104630
    },
    {
      "epoch": 2.092548894132704,
      "grad_norm": 0.19824017584323883,
      "learning_rate": 1.5137516831313575e-05,
      "loss": 0.0811,
      "step": 104640
    },
    {
      "epoch": 2.092748870135584,
      "grad_norm": 0.08031024038791656,
      "learning_rate": 1.513418389793225e-05,
      "loss": 0.0798,
      "step": 104650
    },
    {
      "epoch": 2.0929488461384635,
      "grad_norm": 0.20273905992507935,
      "learning_rate": 1.5130850964550921e-05,
      "loss": 0.0441,
      "step": 104660
    },
    {
      "epoch": 2.0931488221413432,
      "grad_norm": 0.1367114782333374,
      "learning_rate": 1.5127518031169594e-05,
      "loss": 0.0606,
      "step": 104670
    },
    {
      "epoch": 2.0933487981442225,
      "grad_norm": 0.06426224857568741,
      "learning_rate": 1.5124185097788265e-05,
      "loss": 0.0826,
      "step": 104680
    },
    {
      "epoch": 2.093548774147102,
      "grad_norm": 0.12825889885425568,
      "learning_rate": 1.5120852164406937e-05,
      "loss": 0.0461,
      "step": 104690
    },
    {
      "epoch": 2.093748750149982,
      "grad_norm": 0.17269772291183472,
      "learning_rate": 1.5117519231025611e-05,
      "loss": 0.0847,
      "step": 104700
    },
    {
      "epoch": 2.0939487261528615,
      "grad_norm": 0.2067308872938156,
      "learning_rate": 1.5114186297644284e-05,
      "loss": 0.0938,
      "step": 104710
    },
    {
      "epoch": 2.0941487021557412,
      "grad_norm": 0.0881950631737709,
      "learning_rate": 1.5110853364262956e-05,
      "loss": 0.0656,
      "step": 104720
    },
    {
      "epoch": 2.094348678158621,
      "grad_norm": 0.13494938611984253,
      "learning_rate": 1.5107520430881627e-05,
      "loss": 0.0971,
      "step": 104730
    },
    {
      "epoch": 2.0945486541615006,
      "grad_norm": 0.1818535029888153,
      "learning_rate": 1.51041874975003e-05,
      "loss": 0.0561,
      "step": 104740
    },
    {
      "epoch": 2.0947486301643803,
      "grad_norm": 0.12448745965957642,
      "learning_rate": 1.5100854564118975e-05,
      "loss": 0.0708,
      "step": 104750
    },
    {
      "epoch": 2.09494860616726,
      "grad_norm": 0.1013488918542862,
      "learning_rate": 1.5097521630737646e-05,
      "loss": 0.058,
      "step": 104760
    },
    {
      "epoch": 2.0951485821701397,
      "grad_norm": 0.13264931738376617,
      "learning_rate": 1.5094188697356317e-05,
      "loss": 0.0756,
      "step": 104770
    },
    {
      "epoch": 2.0953485581730193,
      "grad_norm": 0.12589439749717712,
      "learning_rate": 1.509085576397499e-05,
      "loss": 0.0615,
      "step": 104780
    },
    {
      "epoch": 2.095548534175899,
      "grad_norm": 0.1667533814907074,
      "learning_rate": 1.5087856123931796e-05,
      "loss": 0.0755,
      "step": 104790
    },
    {
      "epoch": 2.0957485101787787,
      "grad_norm": 0.18341413140296936,
      "learning_rate": 1.5084523190550467e-05,
      "loss": 0.0726,
      "step": 104800
    },
    {
      "epoch": 2.0959484861816584,
      "grad_norm": 0.14339028298854828,
      "learning_rate": 1.508119025716914e-05,
      "loss": 0.0711,
      "step": 104810
    },
    {
      "epoch": 2.0961484621845377,
      "grad_norm": 0.12260240316390991,
      "learning_rate": 1.5077857323787815e-05,
      "loss": 0.0721,
      "step": 104820
    },
    {
      "epoch": 2.0963484381874173,
      "grad_norm": 0.07374604046344757,
      "learning_rate": 1.5074524390406486e-05,
      "loss": 0.0881,
      "step": 104830
    },
    {
      "epoch": 2.096548414190297,
      "grad_norm": 0.22766801714897156,
      "learning_rate": 1.5071191457025157e-05,
      "loss": 0.0712,
      "step": 104840
    },
    {
      "epoch": 2.0967483901931767,
      "grad_norm": 0.1392071694135666,
      "learning_rate": 1.506785852364383e-05,
      "loss": 0.0797,
      "step": 104850
    },
    {
      "epoch": 2.0969483661960564,
      "grad_norm": 0.1335562914609909,
      "learning_rate": 1.5064525590262502e-05,
      "loss": 0.0865,
      "step": 104860
    },
    {
      "epoch": 2.097148342198936,
      "grad_norm": 0.1810535043478012,
      "learning_rate": 1.5061192656881176e-05,
      "loss": 0.1076,
      "step": 104870
    },
    {
      "epoch": 2.0973483182018158,
      "grad_norm": 0.08480044454336166,
      "learning_rate": 1.5057859723499848e-05,
      "loss": 0.0794,
      "step": 104880
    },
    {
      "epoch": 2.0975482942046955,
      "grad_norm": 0.18966174125671387,
      "learning_rate": 1.505452679011852e-05,
      "loss": 0.0766,
      "step": 104890
    },
    {
      "epoch": 2.097748270207575,
      "grad_norm": 0.13611339032649994,
      "learning_rate": 1.5051193856737192e-05,
      "loss": 0.0764,
      "step": 104900
    },
    {
      "epoch": 2.097948246210455,
      "grad_norm": 0.13839773833751678,
      "learning_rate": 1.5047860923355863e-05,
      "loss": 0.0911,
      "step": 104910
    },
    {
      "epoch": 2.0981482222133345,
      "grad_norm": 0.18508170545101166,
      "learning_rate": 1.5044527989974538e-05,
      "loss": 0.045,
      "step": 104920
    },
    {
      "epoch": 2.098348198216214,
      "grad_norm": 0.12538127601146698,
      "learning_rate": 1.5041195056593211e-05,
      "loss": 0.0767,
      "step": 104930
    },
    {
      "epoch": 2.098548174219094,
      "grad_norm": 0.0980333611369133,
      "learning_rate": 1.5037862123211882e-05,
      "loss": 0.086,
      "step": 104940
    },
    {
      "epoch": 2.098748150221973,
      "grad_norm": 0.09394214302301407,
      "learning_rate": 1.5034529189830554e-05,
      "loss": 0.058,
      "step": 104950
    },
    {
      "epoch": 2.098948126224853,
      "grad_norm": 0.12732668220996857,
      "learning_rate": 1.5031196256449227e-05,
      "loss": 0.0887,
      "step": 104960
    },
    {
      "epoch": 2.0991481022277325,
      "grad_norm": 0.11531683057546616,
      "learning_rate": 1.5027863323067901e-05,
      "loss": 0.1053,
      "step": 104970
    },
    {
      "epoch": 2.099348078230612,
      "grad_norm": 0.11527124047279358,
      "learning_rate": 1.5024530389686573e-05,
      "loss": 0.0614,
      "step": 104980
    },
    {
      "epoch": 2.099548054233492,
      "grad_norm": 0.1984068602323532,
      "learning_rate": 1.5021197456305244e-05,
      "loss": 0.0555,
      "step": 104990
    },
    {
      "epoch": 2.0997480302363716,
      "grad_norm": 0.1823321431875229,
      "learning_rate": 1.5017864522923917e-05,
      "loss": 0.0775,
      "step": 105000
    },
    {
      "epoch": 2.0999480062392513,
      "grad_norm": 0.2650269567966461,
      "learning_rate": 1.5014531589542588e-05,
      "loss": 0.086,
      "step": 105010
    },
    {
      "epoch": 2.100147982242131,
      "grad_norm": 0.08219283819198608,
      "learning_rate": 1.5011198656161263e-05,
      "loss": 0.0373,
      "step": 105020
    },
    {
      "epoch": 2.1003479582450106,
      "grad_norm": 0.17504726350307465,
      "learning_rate": 1.5007865722779934e-05,
      "loss": 0.0576,
      "step": 105030
    },
    {
      "epoch": 2.1005479342478903,
      "grad_norm": 0.19703690707683563,
      "learning_rate": 1.5004532789398607e-05,
      "loss": 0.0804,
      "step": 105040
    },
    {
      "epoch": 2.10074791025077,
      "grad_norm": 0.15682174265384674,
      "learning_rate": 1.5001199856017279e-05,
      "loss": 0.0567,
      "step": 105050
    },
    {
      "epoch": 2.1009478862536497,
      "grad_norm": 0.059011224657297134,
      "learning_rate": 1.499786692263595e-05,
      "loss": 0.0502,
      "step": 105060
    },
    {
      "epoch": 2.1011478622565294,
      "grad_norm": 0.25987324118614197,
      "learning_rate": 1.4994533989254623e-05,
      "loss": 0.0733,
      "step": 105070
    },
    {
      "epoch": 2.101347838259409,
      "grad_norm": 0.11591611057519913,
      "learning_rate": 1.4991201055873298e-05,
      "loss": 0.0531,
      "step": 105080
    },
    {
      "epoch": 2.1015478142622883,
      "grad_norm": 0.14937065541744232,
      "learning_rate": 1.4987868122491969e-05,
      "loss": 0.0666,
      "step": 105090
    },
    {
      "epoch": 2.101747790265168,
      "grad_norm": 0.12330589443445206,
      "learning_rate": 1.498453518911064e-05,
      "loss": 0.1001,
      "step": 105100
    },
    {
      "epoch": 2.1019477662680477,
      "grad_norm": 0.17467503249645233,
      "learning_rate": 1.4981202255729313e-05,
      "loss": 0.052,
      "step": 105110
    },
    {
      "epoch": 2.1021477422709274,
      "grad_norm": 0.129959836602211,
      "learning_rate": 1.4977869322347985e-05,
      "loss": 0.0658,
      "step": 105120
    },
    {
      "epoch": 2.102347718273807,
      "grad_norm": 0.11536571383476257,
      "learning_rate": 1.497453638896666e-05,
      "loss": 0.0629,
      "step": 105130
    },
    {
      "epoch": 2.1025476942766868,
      "grad_norm": 0.1415221095085144,
      "learning_rate": 1.497120345558533e-05,
      "loss": 0.0706,
      "step": 105140
    },
    {
      "epoch": 2.1027476702795664,
      "grad_norm": 0.12781962752342224,
      "learning_rate": 1.4967870522204004e-05,
      "loss": 0.0623,
      "step": 105150
    },
    {
      "epoch": 2.102947646282446,
      "grad_norm": 0.10706987977027893,
      "learning_rate": 1.4964537588822675e-05,
      "loss": 0.0858,
      "step": 105160
    },
    {
      "epoch": 2.103147622285326,
      "grad_norm": 0.18744124472141266,
      "learning_rate": 1.4961204655441346e-05,
      "loss": 0.0906,
      "step": 105170
    },
    {
      "epoch": 2.1033475982882055,
      "grad_norm": 0.15263371169567108,
      "learning_rate": 1.4957871722060021e-05,
      "loss": 0.0539,
      "step": 105180
    },
    {
      "epoch": 2.103547574291085,
      "grad_norm": 0.14013753831386566,
      "learning_rate": 1.4954538788678694e-05,
      "loss": 0.0512,
      "step": 105190
    },
    {
      "epoch": 2.103747550293965,
      "grad_norm": 0.10204631090164185,
      "learning_rate": 1.4951205855297365e-05,
      "loss": 0.0436,
      "step": 105200
    },
    {
      "epoch": 2.1039475262968446,
      "grad_norm": 0.14545725286006927,
      "learning_rate": 1.4947872921916036e-05,
      "loss": 0.0628,
      "step": 105210
    },
    {
      "epoch": 2.104147502299724,
      "grad_norm": 0.18026043474674225,
      "learning_rate": 1.494453998853471e-05,
      "loss": 0.0809,
      "step": 105220
    },
    {
      "epoch": 2.1043474783026035,
      "grad_norm": 0.15153612196445465,
      "learning_rate": 1.4941207055153384e-05,
      "loss": 0.0706,
      "step": 105230
    },
    {
      "epoch": 2.104547454305483,
      "grad_norm": 0.08637848496437073,
      "learning_rate": 1.4937874121772055e-05,
      "loss": 0.0714,
      "step": 105240
    },
    {
      "epoch": 2.104747430308363,
      "grad_norm": 0.12139220535755157,
      "learning_rate": 1.4934541188390727e-05,
      "loss": 0.0747,
      "step": 105250
    },
    {
      "epoch": 2.1049474063112426,
      "grad_norm": 0.09046391397714615,
      "learning_rate": 1.49312082550094e-05,
      "loss": 0.0548,
      "step": 105260
    },
    {
      "epoch": 2.1051473823141222,
      "grad_norm": 0.11144467443227768,
      "learning_rate": 1.4927875321628071e-05,
      "loss": 0.0929,
      "step": 105270
    },
    {
      "epoch": 2.105347358317002,
      "grad_norm": 0.12490247189998627,
      "learning_rate": 1.4924542388246746e-05,
      "loss": 0.0672,
      "step": 105280
    },
    {
      "epoch": 2.1055473343198816,
      "grad_norm": 0.2231045961380005,
      "learning_rate": 1.4921209454865417e-05,
      "loss": 0.071,
      "step": 105290
    },
    {
      "epoch": 2.1057473103227613,
      "grad_norm": 0.07845437526702881,
      "learning_rate": 1.491787652148409e-05,
      "loss": 0.0365,
      "step": 105300
    },
    {
      "epoch": 2.105947286325641,
      "grad_norm": 0.07224676758050919,
      "learning_rate": 1.4914543588102761e-05,
      "loss": 0.0468,
      "step": 105310
    },
    {
      "epoch": 2.1061472623285207,
      "grad_norm": 0.1084771677851677,
      "learning_rate": 1.4911210654721433e-05,
      "loss": 0.0724,
      "step": 105320
    },
    {
      "epoch": 2.1063472383314004,
      "grad_norm": 0.1800338178873062,
      "learning_rate": 1.4907877721340107e-05,
      "loss": 0.0434,
      "step": 105330
    },
    {
      "epoch": 2.10654721433428,
      "grad_norm": 0.1239086240530014,
      "learning_rate": 1.490454478795878e-05,
      "loss": 0.0789,
      "step": 105340
    },
    {
      "epoch": 2.1067471903371597,
      "grad_norm": 0.06982087343931198,
      "learning_rate": 1.4901211854577452e-05,
      "loss": 0.1537,
      "step": 105350
    },
    {
      "epoch": 2.1069471663400394,
      "grad_norm": 0.1640615314245224,
      "learning_rate": 1.4897878921196123e-05,
      "loss": 0.1052,
      "step": 105360
    },
    {
      "epoch": 2.1071471423429187,
      "grad_norm": 0.12284619361162186,
      "learning_rate": 1.4894545987814796e-05,
      "loss": 0.0893,
      "step": 105370
    },
    {
      "epoch": 2.1073471183457984,
      "grad_norm": 0.15485726296901703,
      "learning_rate": 1.489121305443347e-05,
      "loss": 0.0752,
      "step": 105380
    },
    {
      "epoch": 2.107547094348678,
      "grad_norm": 0.1509467214345932,
      "learning_rate": 1.4887880121052142e-05,
      "loss": 0.0466,
      "step": 105390
    },
    {
      "epoch": 2.1077470703515577,
      "grad_norm": 0.13556921482086182,
      "learning_rate": 1.4884547187670813e-05,
      "loss": 0.0394,
      "step": 105400
    },
    {
      "epoch": 2.1079470463544374,
      "grad_norm": 0.1150270476937294,
      "learning_rate": 1.4881214254289486e-05,
      "loss": 0.072,
      "step": 105410
    },
    {
      "epoch": 2.108147022357317,
      "grad_norm": 0.03541960194706917,
      "learning_rate": 1.4877881320908158e-05,
      "loss": 0.0699,
      "step": 105420
    },
    {
      "epoch": 2.108346998360197,
      "grad_norm": 0.07992402464151382,
      "learning_rate": 1.4874548387526832e-05,
      "loss": 0.1075,
      "step": 105430
    },
    {
      "epoch": 2.1085469743630765,
      "grad_norm": 0.047461532056331635,
      "learning_rate": 1.4871215454145504e-05,
      "loss": 0.0737,
      "step": 105440
    },
    {
      "epoch": 2.108746950365956,
      "grad_norm": 0.2051127851009369,
      "learning_rate": 1.4867882520764177e-05,
      "loss": 0.0888,
      "step": 105450
    },
    {
      "epoch": 2.108946926368836,
      "grad_norm": 0.07257574051618576,
      "learning_rate": 1.4864549587382848e-05,
      "loss": 0.0499,
      "step": 105460
    },
    {
      "epoch": 2.1091469023717155,
      "grad_norm": 0.22522279620170593,
      "learning_rate": 1.486121665400152e-05,
      "loss": 0.079,
      "step": 105470
    },
    {
      "epoch": 2.1093468783745952,
      "grad_norm": 0.17834223806858063,
      "learning_rate": 1.4857883720620194e-05,
      "loss": 0.0745,
      "step": 105480
    },
    {
      "epoch": 2.109546854377475,
      "grad_norm": 0.2341119647026062,
      "learning_rate": 1.4854550787238865e-05,
      "loss": 0.0669,
      "step": 105490
    },
    {
      "epoch": 2.109746830380354,
      "grad_norm": 0.07285241037607193,
      "learning_rate": 1.4851217853857538e-05,
      "loss": 0.0685,
      "step": 105500
    },
    {
      "epoch": 2.109946806383234,
      "grad_norm": 0.1295386105775833,
      "learning_rate": 1.484788492047621e-05,
      "loss": 0.0728,
      "step": 105510
    },
    {
      "epoch": 2.1101467823861135,
      "grad_norm": 0.0751378983259201,
      "learning_rate": 1.4844551987094883e-05,
      "loss": 0.0571,
      "step": 105520
    },
    {
      "epoch": 2.110346758388993,
      "grad_norm": 0.20233799517154694,
      "learning_rate": 1.4841219053713554e-05,
      "loss": 0.0914,
      "step": 105530
    },
    {
      "epoch": 2.110546734391873,
      "grad_norm": 0.1292569488286972,
      "learning_rate": 1.4837886120332229e-05,
      "loss": 0.0626,
      "step": 105540
    },
    {
      "epoch": 2.1107467103947526,
      "grad_norm": 0.09287066757678986,
      "learning_rate": 1.48345531869509e-05,
      "loss": 0.0848,
      "step": 105550
    },
    {
      "epoch": 2.1109466863976323,
      "grad_norm": 0.1987379640340805,
      "learning_rate": 1.4831220253569571e-05,
      "loss": 0.0614,
      "step": 105560
    },
    {
      "epoch": 2.111146662400512,
      "grad_norm": 0.16751882433891296,
      "learning_rate": 1.4827887320188244e-05,
      "loss": 0.0915,
      "step": 105570
    },
    {
      "epoch": 2.1113466384033917,
      "grad_norm": 0.15445837378501892,
      "learning_rate": 1.4824554386806916e-05,
      "loss": 0.0621,
      "step": 105580
    },
    {
      "epoch": 2.1115466144062713,
      "grad_norm": 0.05462491884827614,
      "learning_rate": 1.482122145342559e-05,
      "loss": 0.0593,
      "step": 105590
    },
    {
      "epoch": 2.111746590409151,
      "grad_norm": 0.199848473072052,
      "learning_rate": 1.4817888520044262e-05,
      "loss": 0.0974,
      "step": 105600
    },
    {
      "epoch": 2.1119465664120307,
      "grad_norm": 0.0790998712182045,
      "learning_rate": 1.4814555586662935e-05,
      "loss": 0.1029,
      "step": 105610
    },
    {
      "epoch": 2.1121465424149104,
      "grad_norm": 0.2027023285627365,
      "learning_rate": 1.4811222653281606e-05,
      "loss": 0.0799,
      "step": 105620
    },
    {
      "epoch": 2.11234651841779,
      "grad_norm": 0.09359303116798401,
      "learning_rate": 1.4807889719900277e-05,
      "loss": 0.0526,
      "step": 105630
    },
    {
      "epoch": 2.1125464944206693,
      "grad_norm": 0.16277775168418884,
      "learning_rate": 1.4804556786518952e-05,
      "loss": 0.0755,
      "step": 105640
    },
    {
      "epoch": 2.112746470423549,
      "grad_norm": 0.16874736547470093,
      "learning_rate": 1.4801223853137625e-05,
      "loss": 0.0963,
      "step": 105650
    },
    {
      "epoch": 2.1129464464264287,
      "grad_norm": 0.10756932944059372,
      "learning_rate": 1.4797890919756296e-05,
      "loss": 0.0706,
      "step": 105660
    },
    {
      "epoch": 2.1131464224293084,
      "grad_norm": 0.10567041486501694,
      "learning_rate": 1.4794557986374968e-05,
      "loss": 0.0652,
      "step": 105670
    },
    {
      "epoch": 2.113346398432188,
      "grad_norm": 0.14555183053016663,
      "learning_rate": 1.479122505299364e-05,
      "loss": 0.138,
      "step": 105680
    },
    {
      "epoch": 2.1135463744350678,
      "grad_norm": 0.10381443053483963,
      "learning_rate": 1.4787892119612315e-05,
      "loss": 0.0604,
      "step": 105690
    },
    {
      "epoch": 2.1137463504379475,
      "grad_norm": 0.10189878940582275,
      "learning_rate": 1.4784559186230987e-05,
      "loss": 0.0664,
      "step": 105700
    },
    {
      "epoch": 2.113946326440827,
      "grad_norm": 0.22965189814567566,
      "learning_rate": 1.4781226252849658e-05,
      "loss": 0.0889,
      "step": 105710
    },
    {
      "epoch": 2.114146302443707,
      "grad_norm": 0.21861757338047028,
      "learning_rate": 1.4777893319468331e-05,
      "loss": 0.0999,
      "step": 105720
    },
    {
      "epoch": 2.1143462784465865,
      "grad_norm": 0.06439518928527832,
      "learning_rate": 1.4774560386087002e-05,
      "loss": 0.0814,
      "step": 105730
    },
    {
      "epoch": 2.114546254449466,
      "grad_norm": 0.05854198709130287,
      "learning_rate": 1.4771227452705677e-05,
      "loss": 0.0557,
      "step": 105740
    },
    {
      "epoch": 2.114746230452346,
      "grad_norm": 0.12014858424663544,
      "learning_rate": 1.4767894519324348e-05,
      "loss": 0.069,
      "step": 105750
    },
    {
      "epoch": 2.1149462064552256,
      "grad_norm": 0.17482562363147736,
      "learning_rate": 1.4764561585943021e-05,
      "loss": 0.0546,
      "step": 105760
    },
    {
      "epoch": 2.115146182458105,
      "grad_norm": 0.0658782422542572,
      "learning_rate": 1.4761228652561693e-05,
      "loss": 0.0561,
      "step": 105770
    },
    {
      "epoch": 2.1153461584609845,
      "grad_norm": 0.09033592790365219,
      "learning_rate": 1.4757895719180364e-05,
      "loss": 0.0582,
      "step": 105780
    },
    {
      "epoch": 2.115546134463864,
      "grad_norm": 0.0874154344201088,
      "learning_rate": 1.4754562785799039e-05,
      "loss": 0.0615,
      "step": 105790
    },
    {
      "epoch": 2.115746110466744,
      "grad_norm": 0.22567744553089142,
      "learning_rate": 1.4751229852417712e-05,
      "loss": 0.1112,
      "step": 105800
    },
    {
      "epoch": 2.1159460864696236,
      "grad_norm": 0.2031536102294922,
      "learning_rate": 1.4747896919036383e-05,
      "loss": 0.1041,
      "step": 105810
    },
    {
      "epoch": 2.1161460624725033,
      "grad_norm": 0.06291984766721725,
      "learning_rate": 1.4744563985655054e-05,
      "loss": 0.0976,
      "step": 105820
    },
    {
      "epoch": 2.116346038475383,
      "grad_norm": 0.13223430514335632,
      "learning_rate": 1.4741231052273727e-05,
      "loss": 0.0555,
      "step": 105830
    },
    {
      "epoch": 2.1165460144782626,
      "grad_norm": 0.12500865757465363,
      "learning_rate": 1.4737898118892402e-05,
      "loss": 0.0858,
      "step": 105840
    },
    {
      "epoch": 2.1167459904811423,
      "grad_norm": 0.16853037476539612,
      "learning_rate": 1.4734565185511073e-05,
      "loss": 0.0689,
      "step": 105850
    },
    {
      "epoch": 2.116945966484022,
      "grad_norm": 0.11533737927675247,
      "learning_rate": 1.4731232252129744e-05,
      "loss": 0.1136,
      "step": 105860
    },
    {
      "epoch": 2.1171459424869017,
      "grad_norm": 0.12956327199935913,
      "learning_rate": 1.4727899318748417e-05,
      "loss": 0.0618,
      "step": 105870
    },
    {
      "epoch": 2.1173459184897814,
      "grad_norm": 0.10838703066110611,
      "learning_rate": 1.4724566385367089e-05,
      "loss": 0.0468,
      "step": 105880
    },
    {
      "epoch": 2.117545894492661,
      "grad_norm": 0.12912903726100922,
      "learning_rate": 1.4721233451985763e-05,
      "loss": 0.0967,
      "step": 105890
    },
    {
      "epoch": 2.1177458704955407,
      "grad_norm": 0.10485202074050903,
      "learning_rate": 1.4717900518604435e-05,
      "loss": 0.1142,
      "step": 105900
    },
    {
      "epoch": 2.11794584649842,
      "grad_norm": 0.14208444952964783,
      "learning_rate": 1.4714567585223108e-05,
      "loss": 0.0803,
      "step": 105910
    },
    {
      "epoch": 2.1181458225012997,
      "grad_norm": 0.13331899046897888,
      "learning_rate": 1.4711234651841779e-05,
      "loss": 0.0935,
      "step": 105920
    },
    {
      "epoch": 2.1183457985041794,
      "grad_norm": 0.10243239998817444,
      "learning_rate": 1.470790171846045e-05,
      "loss": 0.0972,
      "step": 105930
    },
    {
      "epoch": 2.118545774507059,
      "grad_norm": 0.20697461068630219,
      "learning_rate": 1.4704568785079125e-05,
      "loss": 0.0335,
      "step": 105940
    },
    {
      "epoch": 2.1187457505099387,
      "grad_norm": 0.22215969860553741,
      "learning_rate": 1.4701235851697798e-05,
      "loss": 0.0648,
      "step": 105950
    },
    {
      "epoch": 2.1189457265128184,
      "grad_norm": 0.17397665977478027,
      "learning_rate": 1.469790291831647e-05,
      "loss": 0.1056,
      "step": 105960
    },
    {
      "epoch": 2.119145702515698,
      "grad_norm": 0.13852332532405853,
      "learning_rate": 1.469456998493514e-05,
      "loss": 0.056,
      "step": 105970
    },
    {
      "epoch": 2.119345678518578,
      "grad_norm": 0.11738598346710205,
      "learning_rate": 1.4691237051553814e-05,
      "loss": 0.0759,
      "step": 105980
    },
    {
      "epoch": 2.1195456545214575,
      "grad_norm": 0.1528986245393753,
      "learning_rate": 1.4687904118172488e-05,
      "loss": 0.0647,
      "step": 105990
    },
    {
      "epoch": 2.119745630524337,
      "grad_norm": 0.10769079625606537,
      "learning_rate": 1.468457118479116e-05,
      "loss": 0.0876,
      "step": 106000
    },
    {
      "epoch": 2.119945606527217,
      "grad_norm": 0.109345443546772,
      "learning_rate": 1.4681238251409831e-05,
      "loss": 0.0669,
      "step": 106010
    },
    {
      "epoch": 2.1201455825300966,
      "grad_norm": 0.2590932250022888,
      "learning_rate": 1.4677905318028504e-05,
      "loss": 0.117,
      "step": 106020
    },
    {
      "epoch": 2.1203455585329762,
      "grad_norm": 0.21628299355506897,
      "learning_rate": 1.4674572384647175e-05,
      "loss": 0.0546,
      "step": 106030
    },
    {
      "epoch": 2.1205455345358555,
      "grad_norm": 0.18522688746452332,
      "learning_rate": 1.4671239451265847e-05,
      "loss": 0.116,
      "step": 106040
    },
    {
      "epoch": 2.120745510538735,
      "grad_norm": 0.09224376082420349,
      "learning_rate": 1.4667906517884521e-05,
      "loss": 0.0827,
      "step": 106050
    },
    {
      "epoch": 2.120945486541615,
      "grad_norm": 0.10914908349514008,
      "learning_rate": 1.4664573584503194e-05,
      "loss": 0.1085,
      "step": 106060
    },
    {
      "epoch": 2.1211454625444945,
      "grad_norm": 0.18101724982261658,
      "learning_rate": 1.4661240651121866e-05,
      "loss": 0.061,
      "step": 106070
    },
    {
      "epoch": 2.1213454385473742,
      "grad_norm": 0.05754748731851578,
      "learning_rate": 1.4657907717740537e-05,
      "loss": 0.0448,
      "step": 106080
    },
    {
      "epoch": 2.121545414550254,
      "grad_norm": 0.13803629577159882,
      "learning_rate": 1.465457478435921e-05,
      "loss": 0.0882,
      "step": 106090
    },
    {
      "epoch": 2.1217453905531336,
      "grad_norm": 0.21276886761188507,
      "learning_rate": 1.4651241850977885e-05,
      "loss": 0.0588,
      "step": 106100
    },
    {
      "epoch": 2.1219453665560133,
      "grad_norm": 0.14996042847633362,
      "learning_rate": 1.4647908917596556e-05,
      "loss": 0.0675,
      "step": 106110
    },
    {
      "epoch": 2.122145342558893,
      "grad_norm": 0.11745327711105347,
      "learning_rate": 1.4644575984215227e-05,
      "loss": 0.0403,
      "step": 106120
    },
    {
      "epoch": 2.1223453185617727,
      "grad_norm": 0.12734825909137726,
      "learning_rate": 1.46412430508339e-05,
      "loss": 0.0477,
      "step": 106130
    },
    {
      "epoch": 2.1225452945646524,
      "grad_norm": 0.08229077607393265,
      "learning_rate": 1.4637910117452572e-05,
      "loss": 0.075,
      "step": 106140
    },
    {
      "epoch": 2.122745270567532,
      "grad_norm": 0.1714227795600891,
      "learning_rate": 1.4634577184071246e-05,
      "loss": 0.0975,
      "step": 106150
    },
    {
      "epoch": 2.1229452465704117,
      "grad_norm": 0.21700924634933472,
      "learning_rate": 1.4631244250689918e-05,
      "loss": 0.0686,
      "step": 106160
    },
    {
      "epoch": 2.1231452225732914,
      "grad_norm": 0.1925487220287323,
      "learning_rate": 1.462791131730859e-05,
      "loss": 0.1042,
      "step": 106170
    },
    {
      "epoch": 2.1233451985761707,
      "grad_norm": 0.16704052686691284,
      "learning_rate": 1.4624578383927262e-05,
      "loss": 0.0668,
      "step": 106180
    },
    {
      "epoch": 2.1235451745790503,
      "grad_norm": 0.20570142567157745,
      "learning_rate": 1.4621245450545933e-05,
      "loss": 0.1074,
      "step": 106190
    },
    {
      "epoch": 2.12374515058193,
      "grad_norm": 0.1017657071352005,
      "learning_rate": 1.4617912517164608e-05,
      "loss": 0.0388,
      "step": 106200
    },
    {
      "epoch": 2.1239451265848097,
      "grad_norm": 0.1669093370437622,
      "learning_rate": 1.4614579583783281e-05,
      "loss": 0.0905,
      "step": 106210
    },
    {
      "epoch": 2.1241451025876894,
      "grad_norm": 0.23617230355739594,
      "learning_rate": 1.4611246650401952e-05,
      "loss": 0.0818,
      "step": 106220
    },
    {
      "epoch": 2.124345078590569,
      "grad_norm": 0.16534364223480225,
      "learning_rate": 1.4607913717020624e-05,
      "loss": 0.0714,
      "step": 106230
    },
    {
      "epoch": 2.124545054593449,
      "grad_norm": 0.23580746352672577,
      "learning_rate": 1.4604580783639297e-05,
      "loss": 0.0987,
      "step": 106240
    },
    {
      "epoch": 2.1247450305963285,
      "grad_norm": 0.12039706110954285,
      "learning_rate": 1.4601247850257971e-05,
      "loss": 0.0359,
      "step": 106250
    },
    {
      "epoch": 2.124945006599208,
      "grad_norm": 0.18785357475280762,
      "learning_rate": 1.4597914916876643e-05,
      "loss": 0.0811,
      "step": 106260
    },
    {
      "epoch": 2.125144982602088,
      "grad_norm": 0.2264857441186905,
      "learning_rate": 1.4594581983495314e-05,
      "loss": 0.069,
      "step": 106270
    },
    {
      "epoch": 2.1253449586049675,
      "grad_norm": 0.09144333750009537,
      "learning_rate": 1.4591249050113987e-05,
      "loss": 0.0462,
      "step": 106280
    },
    {
      "epoch": 2.125544934607847,
      "grad_norm": 0.10066413134336472,
      "learning_rate": 1.4587916116732658e-05,
      "loss": 0.0308,
      "step": 106290
    },
    {
      "epoch": 2.125744910610727,
      "grad_norm": 0.06674478948116302,
      "learning_rate": 1.4584583183351333e-05,
      "loss": 0.0628,
      "step": 106300
    },
    {
      "epoch": 2.125944886613606,
      "grad_norm": 0.08106507360935211,
      "learning_rate": 1.4581250249970004e-05,
      "loss": 0.0849,
      "step": 106310
    },
    {
      "epoch": 2.126144862616486,
      "grad_norm": 0.1824551224708557,
      "learning_rate": 1.4577917316588677e-05,
      "loss": 0.0606,
      "step": 106320
    },
    {
      "epoch": 2.1263448386193655,
      "grad_norm": 0.18494713306427002,
      "learning_rate": 1.4574584383207349e-05,
      "loss": 0.0481,
      "step": 106330
    },
    {
      "epoch": 2.126544814622245,
      "grad_norm": 0.19488570094108582,
      "learning_rate": 1.457125144982602e-05,
      "loss": 0.0829,
      "step": 106340
    },
    {
      "epoch": 2.126744790625125,
      "grad_norm": 0.22091172635555267,
      "learning_rate": 1.4567918516444695e-05,
      "loss": 0.0659,
      "step": 106350
    },
    {
      "epoch": 2.1269447666280046,
      "grad_norm": 0.21543262898921967,
      "learning_rate": 1.4564585583063368e-05,
      "loss": 0.0741,
      "step": 106360
    },
    {
      "epoch": 2.1271447426308843,
      "grad_norm": 0.08258851617574692,
      "learning_rate": 1.4561252649682039e-05,
      "loss": 0.0472,
      "step": 106370
    },
    {
      "epoch": 2.127344718633764,
      "grad_norm": 0.07768765091896057,
      "learning_rate": 1.455791971630071e-05,
      "loss": 0.0872,
      "step": 106380
    },
    {
      "epoch": 2.1275446946366436,
      "grad_norm": 0.07612378895282745,
      "learning_rate": 1.4554586782919383e-05,
      "loss": 0.0588,
      "step": 106390
    },
    {
      "epoch": 2.1277446706395233,
      "grad_norm": 0.21828553080558777,
      "learning_rate": 1.4551253849538058e-05,
      "loss": 0.0837,
      "step": 106400
    },
    {
      "epoch": 2.127944646642403,
      "grad_norm": 0.08262038975954056,
      "learning_rate": 1.454792091615673e-05,
      "loss": 0.0731,
      "step": 106410
    },
    {
      "epoch": 2.1281446226452827,
      "grad_norm": 0.2059929221868515,
      "learning_rate": 1.45445879827754e-05,
      "loss": 0.0775,
      "step": 106420
    },
    {
      "epoch": 2.1283445986481624,
      "grad_norm": 0.2387785017490387,
      "learning_rate": 1.4541255049394074e-05,
      "loss": 0.0764,
      "step": 106430
    },
    {
      "epoch": 2.128544574651042,
      "grad_norm": 0.08491227775812149,
      "learning_rate": 1.4537922116012745e-05,
      "loss": 0.0531,
      "step": 106440
    },
    {
      "epoch": 2.1287445506539218,
      "grad_norm": 0.12319435924291611,
      "learning_rate": 1.453458918263142e-05,
      "loss": 0.0801,
      "step": 106450
    },
    {
      "epoch": 2.128944526656801,
      "grad_norm": 0.0635741651058197,
      "learning_rate": 1.453125624925009e-05,
      "loss": 0.0686,
      "step": 106460
    },
    {
      "epoch": 2.1291445026596807,
      "grad_norm": 0.20513860881328583,
      "learning_rate": 1.4527923315868764e-05,
      "loss": 0.0669,
      "step": 106470
    },
    {
      "epoch": 2.1293444786625604,
      "grad_norm": 0.1351681649684906,
      "learning_rate": 1.4524590382487435e-05,
      "loss": 0.1169,
      "step": 106480
    },
    {
      "epoch": 2.12954445466544,
      "grad_norm": 0.1634751260280609,
      "learning_rate": 1.4521257449106106e-05,
      "loss": 0.0768,
      "step": 106490
    },
    {
      "epoch": 2.1297444306683198,
      "grad_norm": 0.12321213632822037,
      "learning_rate": 1.4517924515724781e-05,
      "loss": 0.0805,
      "step": 106500
    },
    {
      "epoch": 2.1299444066711994,
      "grad_norm": 0.1438535898923874,
      "learning_rate": 1.4514591582343454e-05,
      "loss": 0.0785,
      "step": 106510
    },
    {
      "epoch": 2.130144382674079,
      "grad_norm": 0.08333577960729599,
      "learning_rate": 1.4511258648962125e-05,
      "loss": 0.0665,
      "step": 106520
    },
    {
      "epoch": 2.130344358676959,
      "grad_norm": 0.12451661378145218,
      "learning_rate": 1.4507925715580797e-05,
      "loss": 0.0691,
      "step": 106530
    },
    {
      "epoch": 2.1305443346798385,
      "grad_norm": 0.13796421885490417,
      "learning_rate": 1.450459278219947e-05,
      "loss": 0.0729,
      "step": 106540
    },
    {
      "epoch": 2.130744310682718,
      "grad_norm": 0.18789762258529663,
      "learning_rate": 1.4501259848818141e-05,
      "loss": 0.0986,
      "step": 106550
    },
    {
      "epoch": 2.130944286685598,
      "grad_norm": 0.18313580751419067,
      "learning_rate": 1.4497926915436816e-05,
      "loss": 0.0745,
      "step": 106560
    },
    {
      "epoch": 2.1311442626884776,
      "grad_norm": 0.07171612977981567,
      "learning_rate": 1.4494593982055487e-05,
      "loss": 0.0524,
      "step": 106570
    },
    {
      "epoch": 2.131344238691357,
      "grad_norm": 0.13131220638751984,
      "learning_rate": 1.449126104867416e-05,
      "loss": 0.0621,
      "step": 106580
    },
    {
      "epoch": 2.1315442146942365,
      "grad_norm": 0.09273575246334076,
      "learning_rate": 1.4487928115292831e-05,
      "loss": 0.0506,
      "step": 106590
    },
    {
      "epoch": 2.131744190697116,
      "grad_norm": 0.06323684751987457,
      "learning_rate": 1.4484595181911503e-05,
      "loss": 0.0436,
      "step": 106600
    },
    {
      "epoch": 2.131944166699996,
      "grad_norm": 0.17607936263084412,
      "learning_rate": 1.4481262248530177e-05,
      "loss": 0.0726,
      "step": 106610
    },
    {
      "epoch": 2.1321441427028756,
      "grad_norm": 0.14903931319713593,
      "learning_rate": 1.447792931514885e-05,
      "loss": 0.0575,
      "step": 106620
    },
    {
      "epoch": 2.1323441187057552,
      "grad_norm": 0.1614101678133011,
      "learning_rate": 1.4474596381767522e-05,
      "loss": 0.0699,
      "step": 106630
    },
    {
      "epoch": 2.132544094708635,
      "grad_norm": 0.09684319794178009,
      "learning_rate": 1.4471263448386193e-05,
      "loss": 0.0496,
      "step": 106640
    },
    {
      "epoch": 2.1327440707115146,
      "grad_norm": 0.16123799979686737,
      "learning_rate": 1.4467930515004866e-05,
      "loss": 0.0575,
      "step": 106650
    },
    {
      "epoch": 2.1329440467143943,
      "grad_norm": 0.1865123063325882,
      "learning_rate": 1.446459758162354e-05,
      "loss": 0.0532,
      "step": 106660
    },
    {
      "epoch": 2.133144022717274,
      "grad_norm": 0.16000191867351532,
      "learning_rate": 1.4461264648242212e-05,
      "loss": 0.0696,
      "step": 106670
    },
    {
      "epoch": 2.1333439987201537,
      "grad_norm": 0.16765107214450836,
      "learning_rate": 1.4457931714860883e-05,
      "loss": 0.0493,
      "step": 106680
    },
    {
      "epoch": 2.1335439747230334,
      "grad_norm": 0.1926116794347763,
      "learning_rate": 1.4454598781479556e-05,
      "loss": 0.0672,
      "step": 106690
    },
    {
      "epoch": 2.133743950725913,
      "grad_norm": 0.1960880160331726,
      "learning_rate": 1.4451265848098228e-05,
      "loss": 0.1062,
      "step": 106700
    },
    {
      "epoch": 2.1339439267287927,
      "grad_norm": 0.12280260771512985,
      "learning_rate": 1.4447932914716902e-05,
      "loss": 0.072,
      "step": 106710
    },
    {
      "epoch": 2.1341439027316724,
      "grad_norm": 0.0891050472855568,
      "learning_rate": 1.4444599981335574e-05,
      "loss": 0.0644,
      "step": 106720
    },
    {
      "epoch": 2.1343438787345517,
      "grad_norm": 0.21294927597045898,
      "learning_rate": 1.4441267047954247e-05,
      "loss": 0.0718,
      "step": 106730
    },
    {
      "epoch": 2.1345438547374314,
      "grad_norm": 0.1383773684501648,
      "learning_rate": 1.4437934114572918e-05,
      "loss": 0.0475,
      "step": 106740
    },
    {
      "epoch": 2.134743830740311,
      "grad_norm": 0.1950342357158661,
      "learning_rate": 1.443460118119159e-05,
      "loss": 0.0689,
      "step": 106750
    },
    {
      "epoch": 2.1349438067431907,
      "grad_norm": 0.15649107098579407,
      "learning_rate": 1.4431268247810264e-05,
      "loss": 0.09,
      "step": 106760
    },
    {
      "epoch": 2.1351437827460704,
      "grad_norm": 0.2232273817062378,
      "learning_rate": 1.4427935314428937e-05,
      "loss": 0.0934,
      "step": 106770
    },
    {
      "epoch": 2.13534375874895,
      "grad_norm": 0.11904149502515793,
      "learning_rate": 1.4424602381047608e-05,
      "loss": 0.062,
      "step": 106780
    },
    {
      "epoch": 2.13554373475183,
      "grad_norm": 0.10765189677476883,
      "learning_rate": 1.442126944766628e-05,
      "loss": 0.0367,
      "step": 106790
    },
    {
      "epoch": 2.1357437107547095,
      "grad_norm": 0.1664222776889801,
      "learning_rate": 1.4417936514284953e-05,
      "loss": 0.0703,
      "step": 106800
    },
    {
      "epoch": 2.135943686757589,
      "grad_norm": 0.0828801691532135,
      "learning_rate": 1.4414603580903627e-05,
      "loss": 0.0489,
      "step": 106810
    },
    {
      "epoch": 2.136143662760469,
      "grad_norm": 0.15730252861976624,
      "learning_rate": 1.4411270647522299e-05,
      "loss": 0.0894,
      "step": 106820
    },
    {
      "epoch": 2.1363436387633485,
      "grad_norm": 0.26621490716934204,
      "learning_rate": 1.440793771414097e-05,
      "loss": 0.0852,
      "step": 106830
    },
    {
      "epoch": 2.1365436147662282,
      "grad_norm": 0.1253119707107544,
      "learning_rate": 1.4404604780759643e-05,
      "loss": 0.058,
      "step": 106840
    },
    {
      "epoch": 2.136743590769108,
      "grad_norm": 0.061159711331129074,
      "learning_rate": 1.4401271847378314e-05,
      "loss": 0.0525,
      "step": 106850
    },
    {
      "epoch": 2.136943566771987,
      "grad_norm": 0.1624714583158493,
      "learning_rate": 1.4397938913996989e-05,
      "loss": 0.0979,
      "step": 106860
    },
    {
      "epoch": 2.137143542774867,
      "grad_norm": 0.14125192165374756,
      "learning_rate": 1.439460598061566e-05,
      "loss": 0.0668,
      "step": 106870
    },
    {
      "epoch": 2.1373435187777465,
      "grad_norm": 0.13819588720798492,
      "learning_rate": 1.4391273047234333e-05,
      "loss": 0.1298,
      "step": 106880
    },
    {
      "epoch": 2.137543494780626,
      "grad_norm": 0.15253251791000366,
      "learning_rate": 1.4387940113853005e-05,
      "loss": 0.044,
      "step": 106890
    },
    {
      "epoch": 2.137743470783506,
      "grad_norm": 0.14146751165390015,
      "learning_rate": 1.4384607180471676e-05,
      "loss": 0.0582,
      "step": 106900
    },
    {
      "epoch": 2.1379434467863856,
      "grad_norm": 0.08129150420427322,
      "learning_rate": 1.438127424709035e-05,
      "loss": 0.101,
      "step": 106910
    },
    {
      "epoch": 2.1381434227892653,
      "grad_norm": 0.10346055030822754,
      "learning_rate": 1.4377941313709024e-05,
      "loss": 0.2275,
      "step": 106920
    },
    {
      "epoch": 2.138343398792145,
      "grad_norm": 0.27201274037361145,
      "learning_rate": 1.4374608380327695e-05,
      "loss": 0.0887,
      "step": 106930
    },
    {
      "epoch": 2.1385433747950247,
      "grad_norm": 0.06105192005634308,
      "learning_rate": 1.4371275446946366e-05,
      "loss": 0.036,
      "step": 106940
    },
    {
      "epoch": 2.1387433507979043,
      "grad_norm": 0.267831027507782,
      "learning_rate": 1.436794251356504e-05,
      "loss": 0.2133,
      "step": 106950
    },
    {
      "epoch": 2.138943326800784,
      "grad_norm": 0.07779831439256668,
      "learning_rate": 1.4364609580183714e-05,
      "loss": 0.088,
      "step": 106960
    },
    {
      "epoch": 2.1391433028036637,
      "grad_norm": 0.10031698644161224,
      "learning_rate": 1.4361276646802385e-05,
      "loss": 0.0724,
      "step": 106970
    },
    {
      "epoch": 2.1393432788065434,
      "grad_norm": 0.20407070219516754,
      "learning_rate": 1.4357943713421057e-05,
      "loss": 0.0753,
      "step": 106980
    },
    {
      "epoch": 2.139543254809423,
      "grad_norm": 0.19827288389205933,
      "learning_rate": 1.435461078003973e-05,
      "loss": 0.0655,
      "step": 106990
    },
    {
      "epoch": 2.1397432308123023,
      "grad_norm": 0.05667121708393097,
      "learning_rate": 1.4351277846658401e-05,
      "loss": 0.0842,
      "step": 107000
    },
    {
      "epoch": 2.139943206815182,
      "grad_norm": 0.17034894227981567,
      "learning_rate": 1.4347944913277076e-05,
      "loss": 0.0847,
      "step": 107010
    },
    {
      "epoch": 2.1401431828180617,
      "grad_norm": 0.23961244523525238,
      "learning_rate": 1.4344611979895747e-05,
      "loss": 0.0758,
      "step": 107020
    },
    {
      "epoch": 2.1403431588209414,
      "grad_norm": 0.16301296651363373,
      "learning_rate": 1.434127904651442e-05,
      "loss": 0.0637,
      "step": 107030
    },
    {
      "epoch": 2.140543134823821,
      "grad_norm": 0.1890828162431717,
      "learning_rate": 1.4337946113133091e-05,
      "loss": 0.0768,
      "step": 107040
    },
    {
      "epoch": 2.1407431108267008,
      "grad_norm": 0.14600354433059692,
      "learning_rate": 1.4334613179751762e-05,
      "loss": 0.0975,
      "step": 107050
    },
    {
      "epoch": 2.1409430868295805,
      "grad_norm": 0.10514680296182632,
      "learning_rate": 1.4331280246370435e-05,
      "loss": 0.0813,
      "step": 107060
    },
    {
      "epoch": 2.14114306283246,
      "grad_norm": 0.14735907316207886,
      "learning_rate": 1.432794731298911e-05,
      "loss": 0.0602,
      "step": 107070
    },
    {
      "epoch": 2.14134303883534,
      "grad_norm": 0.0719103291630745,
      "learning_rate": 1.4324614379607782e-05,
      "loss": 0.0568,
      "step": 107080
    },
    {
      "epoch": 2.1415430148382195,
      "grad_norm": 0.10494694113731384,
      "learning_rate": 1.4321281446226453e-05,
      "loss": 0.0986,
      "step": 107090
    },
    {
      "epoch": 2.141742990841099,
      "grad_norm": 0.07597645372152328,
      "learning_rate": 1.4317948512845126e-05,
      "loss": 0.057,
      "step": 107100
    },
    {
      "epoch": 2.141942966843979,
      "grad_norm": 0.053890254348516464,
      "learning_rate": 1.4314615579463797e-05,
      "loss": 0.0416,
      "step": 107110
    },
    {
      "epoch": 2.1421429428468586,
      "grad_norm": 0.14366239309310913,
      "learning_rate": 1.4311282646082472e-05,
      "loss": 0.0726,
      "step": 107120
    },
    {
      "epoch": 2.142342918849738,
      "grad_norm": 0.16723574697971344,
      "learning_rate": 1.4307949712701143e-05,
      "loss": 0.065,
      "step": 107130
    },
    {
      "epoch": 2.1425428948526175,
      "grad_norm": 0.1513490378856659,
      "learning_rate": 1.4304616779319816e-05,
      "loss": 0.0645,
      "step": 107140
    },
    {
      "epoch": 2.142742870855497,
      "grad_norm": 0.07664820551872253,
      "learning_rate": 1.4301283845938487e-05,
      "loss": 0.0732,
      "step": 107150
    },
    {
      "epoch": 2.142942846858377,
      "grad_norm": 0.19643503427505493,
      "learning_rate": 1.4297950912557159e-05,
      "loss": 0.0685,
      "step": 107160
    },
    {
      "epoch": 2.1431428228612566,
      "grad_norm": 0.0796094760298729,
      "learning_rate": 1.4294617979175833e-05,
      "loss": 0.0638,
      "step": 107170
    },
    {
      "epoch": 2.1433427988641363,
      "grad_norm": 0.22011646628379822,
      "learning_rate": 1.4291285045794506e-05,
      "loss": 0.1005,
      "step": 107180
    },
    {
      "epoch": 2.143542774867016,
      "grad_norm": 0.16871009767055511,
      "learning_rate": 1.4287952112413178e-05,
      "loss": 0.0618,
      "step": 107190
    },
    {
      "epoch": 2.1437427508698956,
      "grad_norm": 0.08734486997127533,
      "learning_rate": 1.4284619179031849e-05,
      "loss": 0.0573,
      "step": 107200
    },
    {
      "epoch": 2.1439427268727753,
      "grad_norm": 0.22367726266384125,
      "learning_rate": 1.4281286245650522e-05,
      "loss": 0.0712,
      "step": 107210
    },
    {
      "epoch": 2.144142702875655,
      "grad_norm": 0.22723671793937683,
      "learning_rate": 1.4277953312269197e-05,
      "loss": 0.1042,
      "step": 107220
    },
    {
      "epoch": 2.1443426788785347,
      "grad_norm": 0.09106727689504623,
      "learning_rate": 1.4274620378887868e-05,
      "loss": 0.0405,
      "step": 107230
    },
    {
      "epoch": 2.1445426548814144,
      "grad_norm": 0.16035397350788116,
      "learning_rate": 1.427128744550654e-05,
      "loss": 0.0783,
      "step": 107240
    },
    {
      "epoch": 2.144742630884294,
      "grad_norm": 0.13699187338352203,
      "learning_rate": 1.4267954512125212e-05,
      "loss": 0.0681,
      "step": 107250
    },
    {
      "epoch": 2.1449426068871738,
      "grad_norm": 0.16931167244911194,
      "learning_rate": 1.4264621578743884e-05,
      "loss": 0.0676,
      "step": 107260
    },
    {
      "epoch": 2.145142582890053,
      "grad_norm": 0.11786897480487823,
      "learning_rate": 1.4261288645362558e-05,
      "loss": 0.0671,
      "step": 107270
    },
    {
      "epoch": 2.1453425588929327,
      "grad_norm": 0.09766684472560883,
      "learning_rate": 1.425795571198123e-05,
      "loss": 0.0503,
      "step": 107280
    },
    {
      "epoch": 2.1455425348958124,
      "grad_norm": 0.21166668832302094,
      "learning_rate": 1.4254622778599903e-05,
      "loss": 0.0868,
      "step": 107290
    },
    {
      "epoch": 2.145742510898692,
      "grad_norm": 0.2037079781293869,
      "learning_rate": 1.4251289845218574e-05,
      "loss": 0.1135,
      "step": 107300
    },
    {
      "epoch": 2.1459424869015717,
      "grad_norm": 0.08046804368495941,
      "learning_rate": 1.4247956911837245e-05,
      "loss": 0.089,
      "step": 107310
    },
    {
      "epoch": 2.1461424629044514,
      "grad_norm": 0.17234010994434357,
      "learning_rate": 1.424462397845592e-05,
      "loss": 0.1053,
      "step": 107320
    },
    {
      "epoch": 2.146342438907331,
      "grad_norm": 0.10503295063972473,
      "learning_rate": 1.4241291045074593e-05,
      "loss": 0.0496,
      "step": 107330
    },
    {
      "epoch": 2.146542414910211,
      "grad_norm": 0.1496254801750183,
      "learning_rate": 1.4237958111693264e-05,
      "loss": 0.0862,
      "step": 107340
    },
    {
      "epoch": 2.1467423909130905,
      "grad_norm": 0.12263981997966766,
      "learning_rate": 1.4234625178311936e-05,
      "loss": 0.0713,
      "step": 107350
    },
    {
      "epoch": 2.14694236691597,
      "grad_norm": 0.13902294635772705,
      "learning_rate": 1.4231292244930609e-05,
      "loss": 0.1002,
      "step": 107360
    },
    {
      "epoch": 2.14714234291885,
      "grad_norm": 0.08124467730522156,
      "learning_rate": 1.4227959311549283e-05,
      "loss": 0.0625,
      "step": 107370
    },
    {
      "epoch": 2.1473423189217296,
      "grad_norm": 0.32189086079597473,
      "learning_rate": 1.4224626378167955e-05,
      "loss": 0.0747,
      "step": 107380
    },
    {
      "epoch": 2.1475422949246092,
      "grad_norm": 0.11480564624071121,
      "learning_rate": 1.4221293444786626e-05,
      "loss": 0.0886,
      "step": 107390
    },
    {
      "epoch": 2.1477422709274885,
      "grad_norm": 0.21019546687602997,
      "learning_rate": 1.4217960511405299e-05,
      "loss": 0.0541,
      "step": 107400
    },
    {
      "epoch": 2.147942246930368,
      "grad_norm": 0.21456566452980042,
      "learning_rate": 1.421462757802397e-05,
      "loss": 0.0532,
      "step": 107410
    },
    {
      "epoch": 2.148142222933248,
      "grad_norm": 0.10003810375928879,
      "learning_rate": 1.4211294644642645e-05,
      "loss": 0.0785,
      "step": 107420
    },
    {
      "epoch": 2.1483421989361275,
      "grad_norm": 0.13530321419239044,
      "learning_rate": 1.4207961711261316e-05,
      "loss": 0.062,
      "step": 107430
    },
    {
      "epoch": 2.1485421749390072,
      "grad_norm": 0.07002612203359604,
      "learning_rate": 1.420462877787999e-05,
      "loss": 0.069,
      "step": 107440
    },
    {
      "epoch": 2.148742150941887,
      "grad_norm": 0.13870538771152496,
      "learning_rate": 1.420129584449866e-05,
      "loss": 0.0739,
      "step": 107450
    },
    {
      "epoch": 2.1489421269447666,
      "grad_norm": 0.07077614217996597,
      "learning_rate": 1.4197962911117332e-05,
      "loss": 0.08,
      "step": 107460
    },
    {
      "epoch": 2.1491421029476463,
      "grad_norm": 0.15585072338581085,
      "learning_rate": 1.4194629977736007e-05,
      "loss": 0.0907,
      "step": 107470
    },
    {
      "epoch": 2.149342078950526,
      "grad_norm": 0.13690811395645142,
      "learning_rate": 1.419129704435468e-05,
      "loss": 0.0604,
      "step": 107480
    },
    {
      "epoch": 2.1495420549534057,
      "grad_norm": 0.09245419502258301,
      "learning_rate": 1.4187964110973351e-05,
      "loss": 0.0468,
      "step": 107490
    },
    {
      "epoch": 2.1497420309562854,
      "grad_norm": 0.2131700962781906,
      "learning_rate": 1.4184631177592022e-05,
      "loss": 0.099,
      "step": 107500
    },
    {
      "epoch": 2.149942006959165,
      "grad_norm": 0.2772718369960785,
      "learning_rate": 1.4181298244210695e-05,
      "loss": 0.0962,
      "step": 107510
    },
    {
      "epoch": 2.1501419829620447,
      "grad_norm": 0.10182273387908936,
      "learning_rate": 1.417796531082937e-05,
      "loss": 0.0609,
      "step": 107520
    },
    {
      "epoch": 2.1503419589649244,
      "grad_norm": 0.20792044699192047,
      "learning_rate": 1.4174632377448041e-05,
      "loss": 0.077,
      "step": 107530
    },
    {
      "epoch": 2.1505419349678037,
      "grad_norm": 0.12041117995977402,
      "learning_rate": 1.4171299444066713e-05,
      "loss": 0.107,
      "step": 107540
    },
    {
      "epoch": 2.1507419109706833,
      "grad_norm": 0.10437455773353577,
      "learning_rate": 1.4167966510685386e-05,
      "loss": 0.0814,
      "step": 107550
    },
    {
      "epoch": 2.150941886973563,
      "grad_norm": 0.1273009032011032,
      "learning_rate": 1.4164633577304057e-05,
      "loss": 0.0542,
      "step": 107560
    },
    {
      "epoch": 2.1511418629764427,
      "grad_norm": 0.0823298841714859,
      "learning_rate": 1.4161300643922728e-05,
      "loss": 0.0716,
      "step": 107570
    },
    {
      "epoch": 2.1513418389793224,
      "grad_norm": 0.11473625153303146,
      "learning_rate": 1.4157967710541403e-05,
      "loss": 0.0981,
      "step": 107580
    },
    {
      "epoch": 2.151541814982202,
      "grad_norm": 0.1397622674703598,
      "learning_rate": 1.4154634777160076e-05,
      "loss": 0.1244,
      "step": 107590
    },
    {
      "epoch": 2.151741790985082,
      "grad_norm": 0.16972646117210388,
      "learning_rate": 1.4151301843778747e-05,
      "loss": 0.0675,
      "step": 107600
    },
    {
      "epoch": 2.1519417669879615,
      "grad_norm": 0.18906494975090027,
      "learning_rate": 1.4147968910397419e-05,
      "loss": 0.0799,
      "step": 107610
    },
    {
      "epoch": 2.152141742990841,
      "grad_norm": 0.14032408595085144,
      "learning_rate": 1.4144635977016092e-05,
      "loss": 0.0805,
      "step": 107620
    },
    {
      "epoch": 2.152341718993721,
      "grad_norm": 0.2712418735027313,
      "learning_rate": 1.4141303043634766e-05,
      "loss": 0.1031,
      "step": 107630
    },
    {
      "epoch": 2.1525416949966005,
      "grad_norm": 0.10147371143102646,
      "learning_rate": 1.4137970110253438e-05,
      "loss": 0.0668,
      "step": 107640
    },
    {
      "epoch": 2.15274167099948,
      "grad_norm": 0.18286262452602386,
      "learning_rate": 1.4134637176872109e-05,
      "loss": 0.1165,
      "step": 107650
    },
    {
      "epoch": 2.15294164700236,
      "grad_norm": 0.15572409331798553,
      "learning_rate": 1.4131304243490782e-05,
      "loss": 0.0699,
      "step": 107660
    },
    {
      "epoch": 2.153141623005239,
      "grad_norm": 0.10993539541959763,
      "learning_rate": 1.4127971310109453e-05,
      "loss": 0.075,
      "step": 107670
    },
    {
      "epoch": 2.153341599008119,
      "grad_norm": 0.09089096635580063,
      "learning_rate": 1.4124638376728128e-05,
      "loss": 0.0423,
      "step": 107680
    },
    {
      "epoch": 2.1535415750109985,
      "grad_norm": 0.11054258048534393,
      "learning_rate": 1.41213054433468e-05,
      "loss": 0.0728,
      "step": 107690
    },
    {
      "epoch": 2.153741551013878,
      "grad_norm": 0.203714981675148,
      "learning_rate": 1.4117972509965472e-05,
      "loss": 0.0557,
      "step": 107700
    },
    {
      "epoch": 2.153941527016758,
      "grad_norm": 0.1545039266347885,
      "learning_rate": 1.4114639576584143e-05,
      "loss": 0.0446,
      "step": 107710
    },
    {
      "epoch": 2.1541415030196376,
      "grad_norm": 0.1570090353488922,
      "learning_rate": 1.4111306643202815e-05,
      "loss": 0.0923,
      "step": 107720
    },
    {
      "epoch": 2.1543414790225173,
      "grad_norm": 0.19065983593463898,
      "learning_rate": 1.410797370982149e-05,
      "loss": 0.0928,
      "step": 107730
    },
    {
      "epoch": 2.154541455025397,
      "grad_norm": 0.06920528411865234,
      "learning_rate": 1.4104640776440162e-05,
      "loss": 0.0553,
      "step": 107740
    },
    {
      "epoch": 2.1547414310282766,
      "grad_norm": 0.0942852571606636,
      "learning_rate": 1.4101307843058834e-05,
      "loss": 0.0694,
      "step": 107750
    },
    {
      "epoch": 2.1549414070311563,
      "grad_norm": 0.18517865240573883,
      "learning_rate": 1.4097974909677505e-05,
      "loss": 0.1064,
      "step": 107760
    },
    {
      "epoch": 2.155141383034036,
      "grad_norm": 0.12015573680400848,
      "learning_rate": 1.4094641976296178e-05,
      "loss": 0.0626,
      "step": 107770
    },
    {
      "epoch": 2.1553413590369157,
      "grad_norm": 0.07127894461154938,
      "learning_rate": 1.4091309042914853e-05,
      "loss": 0.0559,
      "step": 107780
    },
    {
      "epoch": 2.1555413350397954,
      "grad_norm": 0.11148051917552948,
      "learning_rate": 1.4087976109533524e-05,
      "loss": 0.0834,
      "step": 107790
    },
    {
      "epoch": 2.155741311042675,
      "grad_norm": 0.08486482501029968,
      "learning_rate": 1.4084643176152195e-05,
      "loss": 0.0593,
      "step": 107800
    },
    {
      "epoch": 2.1559412870455548,
      "grad_norm": 0.215794175863266,
      "learning_rate": 1.4081310242770868e-05,
      "loss": 0.0788,
      "step": 107810
    },
    {
      "epoch": 2.156141263048434,
      "grad_norm": 0.060446493327617645,
      "learning_rate": 1.407797730938954e-05,
      "loss": 0.0382,
      "step": 107820
    },
    {
      "epoch": 2.1563412390513137,
      "grad_norm": 0.12352225184440613,
      "learning_rate": 1.4074644376008214e-05,
      "loss": 0.0864,
      "step": 107830
    },
    {
      "epoch": 2.1565412150541934,
      "grad_norm": 0.21137018501758575,
      "learning_rate": 1.4071311442626886e-05,
      "loss": 0.0958,
      "step": 107840
    },
    {
      "epoch": 2.156741191057073,
      "grad_norm": 0.16537395119667053,
      "learning_rate": 1.4067978509245559e-05,
      "loss": 0.0607,
      "step": 107850
    },
    {
      "epoch": 2.1569411670599528,
      "grad_norm": 0.21183112263679504,
      "learning_rate": 1.406464557586423e-05,
      "loss": 0.1106,
      "step": 107860
    },
    {
      "epoch": 2.1571411430628324,
      "grad_norm": 0.07383298128843307,
      "learning_rate": 1.4061312642482901e-05,
      "loss": 0.0573,
      "step": 107870
    },
    {
      "epoch": 2.157341119065712,
      "grad_norm": 0.1600029319524765,
      "learning_rate": 1.4057979709101576e-05,
      "loss": 0.0705,
      "step": 107880
    },
    {
      "epoch": 2.157541095068592,
      "grad_norm": 0.11678113788366318,
      "learning_rate": 1.4054646775720247e-05,
      "loss": 0.0681,
      "step": 107890
    },
    {
      "epoch": 2.1577410710714715,
      "grad_norm": 0.11153549700975418,
      "learning_rate": 1.405131384233892e-05,
      "loss": 0.0952,
      "step": 107900
    },
    {
      "epoch": 2.157941047074351,
      "grad_norm": 0.07495512068271637,
      "learning_rate": 1.4047980908957592e-05,
      "loss": 0.1304,
      "step": 107910
    },
    {
      "epoch": 2.158141023077231,
      "grad_norm": 0.1960696280002594,
      "learning_rate": 1.4044647975576265e-05,
      "loss": 0.0799,
      "step": 107920
    },
    {
      "epoch": 2.1583409990801106,
      "grad_norm": 0.11886086314916611,
      "learning_rate": 1.4041315042194938e-05,
      "loss": 0.0656,
      "step": 107930
    },
    {
      "epoch": 2.15854097508299,
      "grad_norm": 0.16872678697109222,
      "learning_rate": 1.403798210881361e-05,
      "loss": 0.0786,
      "step": 107940
    },
    {
      "epoch": 2.1587409510858695,
      "grad_norm": 0.2273649424314499,
      "learning_rate": 1.4034649175432282e-05,
      "loss": 0.0832,
      "step": 107950
    },
    {
      "epoch": 2.158940927088749,
      "grad_norm": 0.2014733999967575,
      "learning_rate": 1.4031316242050953e-05,
      "loss": 0.0516,
      "step": 107960
    },
    {
      "epoch": 2.159140903091629,
      "grad_norm": 0.16226741671562195,
      "learning_rate": 1.4027983308669626e-05,
      "loss": 0.0458,
      "step": 107970
    },
    {
      "epoch": 2.1593408790945086,
      "grad_norm": 0.23225700855255127,
      "learning_rate": 1.4024650375288301e-05,
      "loss": 0.1021,
      "step": 107980
    },
    {
      "epoch": 2.1595408550973882,
      "grad_norm": 0.18619361519813538,
      "learning_rate": 1.4021317441906972e-05,
      "loss": 0.0765,
      "step": 107990
    },
    {
      "epoch": 2.159740831100268,
      "grad_norm": 0.11076800525188446,
      "learning_rate": 1.4017984508525644e-05,
      "loss": 0.0894,
      "step": 108000
    },
    {
      "epoch": 2.1599408071031476,
      "grad_norm": 0.16193056106567383,
      "learning_rate": 1.4014651575144317e-05,
      "loss": 0.0512,
      "step": 108010
    },
    {
      "epoch": 2.1601407831060273,
      "grad_norm": 0.10966645926237106,
      "learning_rate": 1.4011318641762988e-05,
      "loss": 0.0658,
      "step": 108020
    },
    {
      "epoch": 2.160340759108907,
      "grad_norm": 0.0572148822247982,
      "learning_rate": 1.4007985708381663e-05,
      "loss": 0.0882,
      "step": 108030
    },
    {
      "epoch": 2.1605407351117867,
      "grad_norm": 0.10001032799482346,
      "learning_rate": 1.4004652775000334e-05,
      "loss": 0.0524,
      "step": 108040
    },
    {
      "epoch": 2.1607407111146664,
      "grad_norm": 0.0718432068824768,
      "learning_rate": 1.4001319841619007e-05,
      "loss": 0.0489,
      "step": 108050
    },
    {
      "epoch": 2.160940687117546,
      "grad_norm": 0.14887969195842743,
      "learning_rate": 1.3997986908237678e-05,
      "loss": 0.0645,
      "step": 108060
    },
    {
      "epoch": 2.1611406631204257,
      "grad_norm": 0.08636542409658432,
      "learning_rate": 1.399465397485635e-05,
      "loss": 0.0675,
      "step": 108070
    },
    {
      "epoch": 2.1613406391233054,
      "grad_norm": 0.12564371526241302,
      "learning_rate": 1.3991321041475023e-05,
      "loss": 0.067,
      "step": 108080
    },
    {
      "epoch": 2.1615406151261847,
      "grad_norm": 0.0891154333949089,
      "learning_rate": 1.3987988108093697e-05,
      "loss": 0.0808,
      "step": 108090
    },
    {
      "epoch": 2.1617405911290644,
      "grad_norm": 0.1732528805732727,
      "learning_rate": 1.3984655174712369e-05,
      "loss": 0.0484,
      "step": 108100
    },
    {
      "epoch": 2.161940567131944,
      "grad_norm": 0.06518014520406723,
      "learning_rate": 1.398132224133104e-05,
      "loss": 0.0622,
      "step": 108110
    },
    {
      "epoch": 2.1621405431348237,
      "grad_norm": 0.11629210412502289,
      "learning_rate": 1.3977989307949713e-05,
      "loss": 0.0492,
      "step": 108120
    },
    {
      "epoch": 2.1623405191377034,
      "grad_norm": 0.19079378247261047,
      "learning_rate": 1.3974656374568384e-05,
      "loss": 0.0746,
      "step": 108130
    },
    {
      "epoch": 2.162540495140583,
      "grad_norm": 0.07328157871961594,
      "learning_rate": 1.3971323441187059e-05,
      "loss": 0.046,
      "step": 108140
    },
    {
      "epoch": 2.162740471143463,
      "grad_norm": 0.16943958401679993,
      "learning_rate": 1.396799050780573e-05,
      "loss": 0.098,
      "step": 108150
    },
    {
      "epoch": 2.1629404471463425,
      "grad_norm": 0.2296234518289566,
      "learning_rate": 1.3964657574424403e-05,
      "loss": 0.0794,
      "step": 108160
    },
    {
      "epoch": 2.163140423149222,
      "grad_norm": 0.19698050618171692,
      "learning_rate": 1.3961324641043075e-05,
      "loss": 0.1102,
      "step": 108170
    },
    {
      "epoch": 2.163340399152102,
      "grad_norm": 0.15002715587615967,
      "learning_rate": 1.3957991707661746e-05,
      "loss": 0.0637,
      "step": 108180
    },
    {
      "epoch": 2.1635403751549815,
      "grad_norm": 0.17613719403743744,
      "learning_rate": 1.395465877428042e-05,
      "loss": 0.1195,
      "step": 108190
    },
    {
      "epoch": 2.1637403511578612,
      "grad_norm": 0.0449221171438694,
      "learning_rate": 1.3951325840899094e-05,
      "loss": 0.0795,
      "step": 108200
    },
    {
      "epoch": 2.163940327160741,
      "grad_norm": 0.18953192234039307,
      "learning_rate": 1.3947992907517765e-05,
      "loss": 0.0667,
      "step": 108210
    },
    {
      "epoch": 2.16414030316362,
      "grad_norm": 0.20097069442272186,
      "learning_rate": 1.3944659974136436e-05,
      "loss": 0.0606,
      "step": 108220
    },
    {
      "epoch": 2.1643402791665,
      "grad_norm": 0.12301290780305862,
      "learning_rate": 1.394132704075511e-05,
      "loss": 0.0717,
      "step": 108230
    },
    {
      "epoch": 2.1645402551693795,
      "grad_norm": 0.24054698646068573,
      "learning_rate": 1.3937994107373784e-05,
      "loss": 0.0658,
      "step": 108240
    },
    {
      "epoch": 2.164740231172259,
      "grad_norm": 0.1022891104221344,
      "learning_rate": 1.3934661173992455e-05,
      "loss": 0.0672,
      "step": 108250
    },
    {
      "epoch": 2.164940207175139,
      "grad_norm": 0.16332460939884186,
      "learning_rate": 1.3931328240611127e-05,
      "loss": 0.0477,
      "step": 108260
    },
    {
      "epoch": 2.1651401831780186,
      "grad_norm": 0.10753408819437027,
      "learning_rate": 1.39279953072298e-05,
      "loss": 0.0642,
      "step": 108270
    },
    {
      "epoch": 2.1653401591808983,
      "grad_norm": 0.24115218222141266,
      "learning_rate": 1.392466237384847e-05,
      "loss": 0.0605,
      "step": 108280
    },
    {
      "epoch": 2.165540135183778,
      "grad_norm": 0.07282833009958267,
      "learning_rate": 1.3921329440467146e-05,
      "loss": 0.095,
      "step": 108290
    },
    {
      "epoch": 2.1657401111866577,
      "grad_norm": 0.12447740137577057,
      "learning_rate": 1.391832980042395e-05,
      "loss": 0.0567,
      "step": 108300
    },
    {
      "epoch": 2.1659400871895373,
      "grad_norm": 0.1709732711315155,
      "learning_rate": 1.3914996867042624e-05,
      "loss": 0.0809,
      "step": 108310
    },
    {
      "epoch": 2.166140063192417,
      "grad_norm": 0.07080093026161194,
      "learning_rate": 1.3911663933661295e-05,
      "loss": 0.092,
      "step": 108320
    },
    {
      "epoch": 2.1663400391952967,
      "grad_norm": 0.10163071751594543,
      "learning_rate": 1.3908331000279967e-05,
      "loss": 0.0428,
      "step": 108330
    },
    {
      "epoch": 2.1665400151981764,
      "grad_norm": 0.20756329596042633,
      "learning_rate": 1.390499806689864e-05,
      "loss": 0.0636,
      "step": 108340
    },
    {
      "epoch": 2.166739991201056,
      "grad_norm": 0.14780768752098083,
      "learning_rate": 1.390166513351731e-05,
      "loss": 0.0869,
      "step": 108350
    },
    {
      "epoch": 2.1669399672039353,
      "grad_norm": 0.14439181983470917,
      "learning_rate": 1.3898332200135986e-05,
      "loss": 0.0535,
      "step": 108360
    },
    {
      "epoch": 2.167139943206815,
      "grad_norm": 0.11519800871610641,
      "learning_rate": 1.3894999266754657e-05,
      "loss": 0.0541,
      "step": 108370
    },
    {
      "epoch": 2.1673399192096947,
      "grad_norm": 0.20634496212005615,
      "learning_rate": 1.389166633337333e-05,
      "loss": 0.0497,
      "step": 108380
    },
    {
      "epoch": 2.1675398952125744,
      "grad_norm": 0.24468831717967987,
      "learning_rate": 1.3888333399992001e-05,
      "loss": 0.0794,
      "step": 108390
    },
    {
      "epoch": 2.167739871215454,
      "grad_norm": 0.14600326120853424,
      "learning_rate": 1.3885000466610672e-05,
      "loss": 0.0676,
      "step": 108400
    },
    {
      "epoch": 2.1679398472183338,
      "grad_norm": 0.16478416323661804,
      "learning_rate": 1.3881667533229347e-05,
      "loss": 0.0847,
      "step": 108410
    },
    {
      "epoch": 2.1681398232212135,
      "grad_norm": 0.14905555546283722,
      "learning_rate": 1.387833459984802e-05,
      "loss": 0.0861,
      "step": 108420
    },
    {
      "epoch": 2.168339799224093,
      "grad_norm": 0.06439295411109924,
      "learning_rate": 1.3875001666466691e-05,
      "loss": 0.0497,
      "step": 108430
    },
    {
      "epoch": 2.168539775226973,
      "grad_norm": 0.10942894965410233,
      "learning_rate": 1.3871668733085363e-05,
      "loss": 0.0588,
      "step": 108440
    },
    {
      "epoch": 2.1687397512298525,
      "grad_norm": 0.20646385848522186,
      "learning_rate": 1.3868335799704036e-05,
      "loss": 0.0607,
      "step": 108450
    },
    {
      "epoch": 2.168939727232732,
      "grad_norm": 0.09946474432945251,
      "learning_rate": 1.386500286632271e-05,
      "loss": 0.0763,
      "step": 108460
    },
    {
      "epoch": 2.169139703235612,
      "grad_norm": 0.10887432843446732,
      "learning_rate": 1.3861669932941382e-05,
      "loss": 0.0907,
      "step": 108470
    },
    {
      "epoch": 2.1693396792384916,
      "grad_norm": 0.11302480846643448,
      "learning_rate": 1.3858336999560053e-05,
      "loss": 0.0716,
      "step": 108480
    },
    {
      "epoch": 2.169539655241371,
      "grad_norm": 0.23528920114040375,
      "learning_rate": 1.3855004066178726e-05,
      "loss": 0.0917,
      "step": 108490
    },
    {
      "epoch": 2.1697396312442505,
      "grad_norm": 0.1323956847190857,
      "learning_rate": 1.3851671132797397e-05,
      "loss": 0.0439,
      "step": 108500
    },
    {
      "epoch": 2.16993960724713,
      "grad_norm": 0.16291260719299316,
      "learning_rate": 1.3848338199416069e-05,
      "loss": 0.0633,
      "step": 108510
    },
    {
      "epoch": 2.17013958325001,
      "grad_norm": 0.12120142579078674,
      "learning_rate": 1.3845005266034743e-05,
      "loss": 0.0581,
      "step": 108520
    },
    {
      "epoch": 2.1703395592528896,
      "grad_norm": 0.1708991527557373,
      "learning_rate": 1.3841672332653416e-05,
      "loss": 0.0569,
      "step": 108530
    },
    {
      "epoch": 2.1705395352557693,
      "grad_norm": 0.1178818792104721,
      "learning_rate": 1.3838339399272088e-05,
      "loss": 0.0599,
      "step": 108540
    },
    {
      "epoch": 2.170739511258649,
      "grad_norm": 0.24563370645046234,
      "learning_rate": 1.3835006465890759e-05,
      "loss": 0.0866,
      "step": 108550
    },
    {
      "epoch": 2.1709394872615286,
      "grad_norm": 0.12799665331840515,
      "learning_rate": 1.3831673532509432e-05,
      "loss": 0.0999,
      "step": 108560
    },
    {
      "epoch": 2.1711394632644083,
      "grad_norm": 0.09120532125234604,
      "learning_rate": 1.3828340599128107e-05,
      "loss": 0.0585,
      "step": 108570
    },
    {
      "epoch": 2.171339439267288,
      "grad_norm": 0.2771865129470825,
      "learning_rate": 1.3825007665746778e-05,
      "loss": 0.078,
      "step": 108580
    },
    {
      "epoch": 2.1715394152701677,
      "grad_norm": 0.05967763438820839,
      "learning_rate": 1.382167473236545e-05,
      "loss": 0.1021,
      "step": 108590
    },
    {
      "epoch": 2.1717393912730474,
      "grad_norm": 0.1972295641899109,
      "learning_rate": 1.3818341798984122e-05,
      "loss": 0.1513,
      "step": 108600
    },
    {
      "epoch": 2.171939367275927,
      "grad_norm": 0.07302030920982361,
      "learning_rate": 1.3815008865602794e-05,
      "loss": 0.0947,
      "step": 108610
    },
    {
      "epoch": 2.1721393432788068,
      "grad_norm": 0.12129130214452744,
      "learning_rate": 1.3811675932221468e-05,
      "loss": 0.066,
      "step": 108620
    },
    {
      "epoch": 2.172339319281686,
      "grad_norm": 0.08120410889387131,
      "learning_rate": 1.380834299884014e-05,
      "loss": 0.0705,
      "step": 108630
    },
    {
      "epoch": 2.1725392952845657,
      "grad_norm": 0.07215937227010727,
      "learning_rate": 1.3805010065458813e-05,
      "loss": 0.0643,
      "step": 108640
    },
    {
      "epoch": 2.1727392712874454,
      "grad_norm": 0.18223655223846436,
      "learning_rate": 1.3801677132077484e-05,
      "loss": 0.0766,
      "step": 108650
    },
    {
      "epoch": 2.172939247290325,
      "grad_norm": 0.08087364584207535,
      "learning_rate": 1.3798344198696155e-05,
      "loss": 0.0519,
      "step": 108660
    },
    {
      "epoch": 2.1731392232932047,
      "grad_norm": 0.08413975685834885,
      "learning_rate": 1.379501126531483e-05,
      "loss": 0.0648,
      "step": 108670
    },
    {
      "epoch": 2.1733391992960844,
      "grad_norm": 0.1216522604227066,
      "learning_rate": 1.3791678331933503e-05,
      "loss": 0.0842,
      "step": 108680
    },
    {
      "epoch": 2.173539175298964,
      "grad_norm": 0.19619864225387573,
      "learning_rate": 1.3788345398552174e-05,
      "loss": 0.0788,
      "step": 108690
    },
    {
      "epoch": 2.173739151301844,
      "grad_norm": 0.09787940233945847,
      "learning_rate": 1.3785012465170846e-05,
      "loss": 0.0778,
      "step": 108700
    },
    {
      "epoch": 2.1739391273047235,
      "grad_norm": 0.07354442030191422,
      "learning_rate": 1.3781679531789519e-05,
      "loss": 0.0633,
      "step": 108710
    },
    {
      "epoch": 2.174139103307603,
      "grad_norm": 0.21914826333522797,
      "learning_rate": 1.3778346598408193e-05,
      "loss": 0.0781,
      "step": 108720
    },
    {
      "epoch": 2.174339079310483,
      "grad_norm": 0.1517937332391739,
      "learning_rate": 1.3775013665026865e-05,
      "loss": 0.0509,
      "step": 108730
    },
    {
      "epoch": 2.1745390553133626,
      "grad_norm": 0.0884007066488266,
      "learning_rate": 1.3771680731645536e-05,
      "loss": 0.0826,
      "step": 108740
    },
    {
      "epoch": 2.1747390313162422,
      "grad_norm": 0.11345841735601425,
      "learning_rate": 1.3768347798264209e-05,
      "loss": 0.0558,
      "step": 108750
    },
    {
      "epoch": 2.1749390073191215,
      "grad_norm": 0.17026928067207336,
      "learning_rate": 1.376501486488288e-05,
      "loss": 0.0792,
      "step": 108760
    },
    {
      "epoch": 2.175138983322001,
      "grad_norm": 0.21031707525253296,
      "learning_rate": 1.3761681931501555e-05,
      "loss": 0.078,
      "step": 108770
    },
    {
      "epoch": 2.175338959324881,
      "grad_norm": 0.16856509447097778,
      "learning_rate": 1.3758348998120226e-05,
      "loss": 0.0546,
      "step": 108780
    },
    {
      "epoch": 2.1755389353277605,
      "grad_norm": 0.09717343747615814,
      "learning_rate": 1.37550160647389e-05,
      "loss": 0.0501,
      "step": 108790
    },
    {
      "epoch": 2.1757389113306402,
      "grad_norm": 0.1352897584438324,
      "learning_rate": 1.375168313135757e-05,
      "loss": 0.0876,
      "step": 108800
    },
    {
      "epoch": 2.17593888733352,
      "grad_norm": 0.16134382784366608,
      "learning_rate": 1.3748350197976242e-05,
      "loss": 0.0697,
      "step": 108810
    },
    {
      "epoch": 2.1761388633363996,
      "grad_norm": 0.15307489037513733,
      "learning_rate": 1.3745017264594917e-05,
      "loss": 0.076,
      "step": 108820
    },
    {
      "epoch": 2.1763388393392793,
      "grad_norm": 0.10577834397554398,
      "learning_rate": 1.374168433121359e-05,
      "loss": 0.0757,
      "step": 108830
    },
    {
      "epoch": 2.176538815342159,
      "grad_norm": 0.09596569836139679,
      "learning_rate": 1.3738351397832261e-05,
      "loss": 0.0578,
      "step": 108840
    },
    {
      "epoch": 2.1767387913450387,
      "grad_norm": 0.20652472972869873,
      "learning_rate": 1.3735018464450932e-05,
      "loss": 0.1036,
      "step": 108850
    },
    {
      "epoch": 2.1769387673479184,
      "grad_norm": 0.16793422400951385,
      "learning_rate": 1.3731685531069605e-05,
      "loss": 0.0698,
      "step": 108860
    },
    {
      "epoch": 2.177138743350798,
      "grad_norm": 0.11519374698400497,
      "learning_rate": 1.372835259768828e-05,
      "loss": 0.074,
      "step": 108870
    },
    {
      "epoch": 2.1773387193536777,
      "grad_norm": 0.277986079454422,
      "learning_rate": 1.3725019664306951e-05,
      "loss": 0.0815,
      "step": 108880
    },
    {
      "epoch": 2.1775386953565574,
      "grad_norm": 0.10763902962207794,
      "learning_rate": 1.3721686730925623e-05,
      "loss": 0.0667,
      "step": 108890
    },
    {
      "epoch": 2.1777386713594367,
      "grad_norm": 0.14897574484348297,
      "learning_rate": 1.3718353797544296e-05,
      "loss": 0.0663,
      "step": 108900
    },
    {
      "epoch": 2.1779386473623163,
      "grad_norm": 0.0688926950097084,
      "learning_rate": 1.3715020864162967e-05,
      "loss": 0.0363,
      "step": 108910
    },
    {
      "epoch": 2.178138623365196,
      "grad_norm": 0.1428872048854828,
      "learning_rate": 1.3711687930781642e-05,
      "loss": 0.0584,
      "step": 108920
    },
    {
      "epoch": 2.1783385993680757,
      "grad_norm": 0.15325927734375,
      "learning_rate": 1.3708354997400313e-05,
      "loss": 0.0522,
      "step": 108930
    },
    {
      "epoch": 2.1785385753709554,
      "grad_norm": 0.052335742861032486,
      "learning_rate": 1.3705022064018986e-05,
      "loss": 0.0834,
      "step": 108940
    },
    {
      "epoch": 2.178738551373835,
      "grad_norm": 0.17751160264015198,
      "learning_rate": 1.3701689130637657e-05,
      "loss": 0.0607,
      "step": 108950
    },
    {
      "epoch": 2.178938527376715,
      "grad_norm": 0.09100662916898727,
      "learning_rate": 1.3698356197256329e-05,
      "loss": 0.0709,
      "step": 108960
    },
    {
      "epoch": 2.1791385033795945,
      "grad_norm": 0.21384574472904205,
      "learning_rate": 1.3695023263875003e-05,
      "loss": 0.0794,
      "step": 108970
    },
    {
      "epoch": 2.179338479382474,
      "grad_norm": 0.100824274122715,
      "learning_rate": 1.3691690330493676e-05,
      "loss": 0.0873,
      "step": 108980
    },
    {
      "epoch": 2.179538455385354,
      "grad_norm": 0.06673936545848846,
      "learning_rate": 1.3688357397112348e-05,
      "loss": 0.0303,
      "step": 108990
    },
    {
      "epoch": 2.1797384313882335,
      "grad_norm": 0.11580238491296768,
      "learning_rate": 1.3685024463731019e-05,
      "loss": 0.059,
      "step": 109000
    },
    {
      "epoch": 2.179938407391113,
      "grad_norm": 0.11595044285058975,
      "learning_rate": 1.3681691530349692e-05,
      "loss": 0.0392,
      "step": 109010
    },
    {
      "epoch": 2.180138383393993,
      "grad_norm": 0.07501814514398575,
      "learning_rate": 1.3678358596968363e-05,
      "loss": 0.0661,
      "step": 109020
    },
    {
      "epoch": 2.180338359396872,
      "grad_norm": 0.2576424777507782,
      "learning_rate": 1.3675025663587038e-05,
      "loss": 0.0771,
      "step": 109030
    },
    {
      "epoch": 2.180538335399752,
      "grad_norm": 0.18635885417461395,
      "learning_rate": 1.3671692730205709e-05,
      "loss": 0.0692,
      "step": 109040
    },
    {
      "epoch": 2.1807383114026315,
      "grad_norm": 0.12253065407276154,
      "learning_rate": 1.3668359796824382e-05,
      "loss": 0.0748,
      "step": 109050
    },
    {
      "epoch": 2.180938287405511,
      "grad_norm": 0.12598799169063568,
      "learning_rate": 1.3665026863443053e-05,
      "loss": 0.1079,
      "step": 109060
    },
    {
      "epoch": 2.181138263408391,
      "grad_norm": 0.07151608169078827,
      "learning_rate": 1.3661693930061725e-05,
      "loss": 0.0773,
      "step": 109070
    },
    {
      "epoch": 2.1813382394112706,
      "grad_norm": 0.12946924567222595,
      "learning_rate": 1.36583609966804e-05,
      "loss": 0.0756,
      "step": 109080
    },
    {
      "epoch": 2.1815382154141503,
      "grad_norm": 0.13158610463142395,
      "learning_rate": 1.3655028063299072e-05,
      "loss": 0.1067,
      "step": 109090
    },
    {
      "epoch": 2.18173819141703,
      "grad_norm": 0.10441727936267853,
      "learning_rate": 1.3651695129917744e-05,
      "loss": 0.1123,
      "step": 109100
    },
    {
      "epoch": 2.1819381674199096,
      "grad_norm": 0.19548076391220093,
      "learning_rate": 1.3648362196536415e-05,
      "loss": 0.1778,
      "step": 109110
    },
    {
      "epoch": 2.1821381434227893,
      "grad_norm": 0.11228519678115845,
      "learning_rate": 1.3645029263155088e-05,
      "loss": 0.059,
      "step": 109120
    },
    {
      "epoch": 2.182338119425669,
      "grad_norm": 0.21768300235271454,
      "learning_rate": 1.3641696329773763e-05,
      "loss": 0.0893,
      "step": 109130
    },
    {
      "epoch": 2.1825380954285487,
      "grad_norm": 0.23414982855319977,
      "learning_rate": 1.3638363396392434e-05,
      "loss": 0.0605,
      "step": 109140
    },
    {
      "epoch": 2.1827380714314284,
      "grad_norm": 0.2152257114648819,
      "learning_rate": 1.3635030463011105e-05,
      "loss": 0.117,
      "step": 109150
    },
    {
      "epoch": 2.182938047434308,
      "grad_norm": 0.07323817908763885,
      "learning_rate": 1.3631697529629778e-05,
      "loss": 0.1189,
      "step": 109160
    },
    {
      "epoch": 2.1831380234371878,
      "grad_norm": 0.1995396614074707,
      "learning_rate": 1.362836459624845e-05,
      "loss": 0.071,
      "step": 109170
    },
    {
      "epoch": 2.183337999440067,
      "grad_norm": 0.11640553921461105,
      "learning_rate": 1.3625031662867124e-05,
      "loss": 0.0788,
      "step": 109180
    },
    {
      "epoch": 2.1835379754429467,
      "grad_norm": 0.06912899017333984,
      "learning_rate": 1.3621698729485796e-05,
      "loss": 0.0736,
      "step": 109190
    },
    {
      "epoch": 2.1837379514458264,
      "grad_norm": 0.16787633299827576,
      "learning_rate": 1.3618365796104469e-05,
      "loss": 0.0602,
      "step": 109200
    },
    {
      "epoch": 2.183937927448706,
      "grad_norm": 0.16421626508235931,
      "learning_rate": 1.361503286272314e-05,
      "loss": 0.0533,
      "step": 109210
    },
    {
      "epoch": 2.1841379034515858,
      "grad_norm": 0.11570660769939423,
      "learning_rate": 1.3611699929341811e-05,
      "loss": 0.0799,
      "step": 109220
    },
    {
      "epoch": 2.1843378794544654,
      "grad_norm": 0.1436130702495575,
      "learning_rate": 1.3608366995960486e-05,
      "loss": 0.0743,
      "step": 109230
    },
    {
      "epoch": 2.184537855457345,
      "grad_norm": 0.18186552822589874,
      "learning_rate": 1.3605034062579159e-05,
      "loss": 0.0578,
      "step": 109240
    },
    {
      "epoch": 2.184737831460225,
      "grad_norm": 0.12300579994916916,
      "learning_rate": 1.360170112919783e-05,
      "loss": 0.0594,
      "step": 109250
    },
    {
      "epoch": 2.1849378074631045,
      "grad_norm": 0.16332033276557922,
      "learning_rate": 1.3598368195816502e-05,
      "loss": 0.0866,
      "step": 109260
    },
    {
      "epoch": 2.185137783465984,
      "grad_norm": 0.24378009140491486,
      "learning_rate": 1.3595035262435175e-05,
      "loss": 0.0615,
      "step": 109270
    },
    {
      "epoch": 2.185337759468864,
      "grad_norm": 0.14504587650299072,
      "learning_rate": 1.359170232905385e-05,
      "loss": 0.0551,
      "step": 109280
    },
    {
      "epoch": 2.1855377354717436,
      "grad_norm": 0.12560737133026123,
      "learning_rate": 1.358836939567252e-05,
      "loss": 0.0551,
      "step": 109290
    },
    {
      "epoch": 2.185737711474623,
      "grad_norm": 0.09853062033653259,
      "learning_rate": 1.3585036462291192e-05,
      "loss": 0.0381,
      "step": 109300
    },
    {
      "epoch": 2.1859376874775025,
      "grad_norm": 0.15057402849197388,
      "learning_rate": 1.3581703528909865e-05,
      "loss": 0.0642,
      "step": 109310
    },
    {
      "epoch": 2.186137663480382,
      "grad_norm": 0.15864311158657074,
      "learning_rate": 1.3578370595528536e-05,
      "loss": 0.0428,
      "step": 109320
    },
    {
      "epoch": 2.186337639483262,
      "grad_norm": 0.15101391077041626,
      "learning_rate": 1.3575037662147211e-05,
      "loss": 0.0711,
      "step": 109330
    },
    {
      "epoch": 2.1865376154861416,
      "grad_norm": 0.12685735523700714,
      "learning_rate": 1.3571704728765882e-05,
      "loss": 0.0766,
      "step": 109340
    },
    {
      "epoch": 2.1867375914890212,
      "grad_norm": 0.09460074454545975,
      "learning_rate": 1.3568371795384555e-05,
      "loss": 0.0817,
      "step": 109350
    },
    {
      "epoch": 2.186937567491901,
      "grad_norm": 0.19530417025089264,
      "learning_rate": 1.3565038862003227e-05,
      "loss": 0.108,
      "step": 109360
    },
    {
      "epoch": 2.1871375434947806,
      "grad_norm": 0.15459144115447998,
      "learning_rate": 1.3561705928621898e-05,
      "loss": 0.0394,
      "step": 109370
    },
    {
      "epoch": 2.1873375194976603,
      "grad_norm": 0.13774123787879944,
      "learning_rate": 1.3558372995240573e-05,
      "loss": 0.0969,
      "step": 109380
    },
    {
      "epoch": 2.18753749550054,
      "grad_norm": 0.2332606464624405,
      "learning_rate": 1.3555040061859246e-05,
      "loss": 0.0724,
      "step": 109390
    },
    {
      "epoch": 2.1877374715034197,
      "grad_norm": 0.220876544713974,
      "learning_rate": 1.3551707128477917e-05,
      "loss": 0.0803,
      "step": 109400
    },
    {
      "epoch": 2.1879374475062994,
      "grad_norm": 0.07732130587100983,
      "learning_rate": 1.3548374195096588e-05,
      "loss": 0.0715,
      "step": 109410
    },
    {
      "epoch": 2.188137423509179,
      "grad_norm": 0.16860683262348175,
      "learning_rate": 1.3545041261715261e-05,
      "loss": 0.0801,
      "step": 109420
    },
    {
      "epoch": 2.1883373995120587,
      "grad_norm": 0.07094304263591766,
      "learning_rate": 1.3541708328333936e-05,
      "loss": 0.0404,
      "step": 109430
    },
    {
      "epoch": 2.1885373755149384,
      "grad_norm": 0.1221330389380455,
      "learning_rate": 1.3538375394952607e-05,
      "loss": 0.1096,
      "step": 109440
    },
    {
      "epoch": 2.1887373515178177,
      "grad_norm": 0.21383193135261536,
      "learning_rate": 1.3535042461571279e-05,
      "loss": 0.0441,
      "step": 109450
    },
    {
      "epoch": 2.1889373275206974,
      "grad_norm": 0.1431228518486023,
      "learning_rate": 1.3531709528189952e-05,
      "loss": 0.058,
      "step": 109460
    },
    {
      "epoch": 2.189137303523577,
      "grad_norm": 0.07253699004650116,
      "learning_rate": 1.3528376594808623e-05,
      "loss": 0.0682,
      "step": 109470
    },
    {
      "epoch": 2.1893372795264567,
      "grad_norm": 0.16055400669574738,
      "learning_rate": 1.3525043661427298e-05,
      "loss": 0.0873,
      "step": 109480
    },
    {
      "epoch": 2.1895372555293364,
      "grad_norm": 0.18458721041679382,
      "learning_rate": 1.3521710728045969e-05,
      "loss": 0.0731,
      "step": 109490
    },
    {
      "epoch": 2.189737231532216,
      "grad_norm": 0.13764196634292603,
      "learning_rate": 1.3518377794664642e-05,
      "loss": 0.0424,
      "step": 109500
    },
    {
      "epoch": 2.189937207535096,
      "grad_norm": 0.06293387711048126,
      "learning_rate": 1.3515044861283313e-05,
      "loss": 0.0539,
      "step": 109510
    },
    {
      "epoch": 2.1901371835379755,
      "grad_norm": 0.1684006303548813,
      "learning_rate": 1.3511711927901985e-05,
      "loss": 0.0489,
      "step": 109520
    },
    {
      "epoch": 2.190337159540855,
      "grad_norm": 0.07149313390254974,
      "learning_rate": 1.3508378994520658e-05,
      "loss": 0.0726,
      "step": 109530
    },
    {
      "epoch": 2.190537135543735,
      "grad_norm": 0.10523293912410736,
      "learning_rate": 1.3505046061139332e-05,
      "loss": 0.0582,
      "step": 109540
    },
    {
      "epoch": 2.1907371115466145,
      "grad_norm": 0.14997924864292145,
      "learning_rate": 1.3501713127758004e-05,
      "loss": 0.0662,
      "step": 109550
    },
    {
      "epoch": 2.1909370875494942,
      "grad_norm": 0.06781483441591263,
      "learning_rate": 1.3498380194376675e-05,
      "loss": 0.097,
      "step": 109560
    },
    {
      "epoch": 2.191137063552374,
      "grad_norm": 0.15824972093105316,
      "learning_rate": 1.3495047260995348e-05,
      "loss": 0.0632,
      "step": 109570
    },
    {
      "epoch": 2.191337039555253,
      "grad_norm": 0.16839087009429932,
      "learning_rate": 1.349171432761402e-05,
      "loss": 0.0614,
      "step": 109580
    },
    {
      "epoch": 2.191537015558133,
      "grad_norm": 0.18895743787288666,
      "learning_rate": 1.3488381394232694e-05,
      "loss": 0.076,
      "step": 109590
    },
    {
      "epoch": 2.1917369915610125,
      "grad_norm": 0.20535323023796082,
      "learning_rate": 1.3485048460851365e-05,
      "loss": 0.0567,
      "step": 109600
    },
    {
      "epoch": 2.1919369675638922,
      "grad_norm": 0.16686660051345825,
      "learning_rate": 1.3481715527470038e-05,
      "loss": 0.0767,
      "step": 109610
    },
    {
      "epoch": 2.192136943566772,
      "grad_norm": 0.18962186574935913,
      "learning_rate": 1.347838259408871e-05,
      "loss": 0.0688,
      "step": 109620
    },
    {
      "epoch": 2.1923369195696516,
      "grad_norm": 0.15617206692695618,
      "learning_rate": 1.347504966070738e-05,
      "loss": 0.0671,
      "step": 109630
    },
    {
      "epoch": 2.1925368955725313,
      "grad_norm": 0.19326917827129364,
      "learning_rate": 1.3471716727326056e-05,
      "loss": 0.4515,
      "step": 109640
    },
    {
      "epoch": 2.192736871575411,
      "grad_norm": 0.14068368077278137,
      "learning_rate": 1.3468383793944729e-05,
      "loss": 0.0665,
      "step": 109650
    },
    {
      "epoch": 2.1929368475782907,
      "grad_norm": 0.20735757052898407,
      "learning_rate": 1.34650508605634e-05,
      "loss": 0.1234,
      "step": 109660
    },
    {
      "epoch": 2.1931368235811703,
      "grad_norm": 0.14203746616840363,
      "learning_rate": 1.3461717927182071e-05,
      "loss": 0.0511,
      "step": 109670
    },
    {
      "epoch": 2.19333679958405,
      "grad_norm": 0.12406633794307709,
      "learning_rate": 1.3458384993800744e-05,
      "loss": 0.121,
      "step": 109680
    },
    {
      "epoch": 2.1935367755869297,
      "grad_norm": 0.13930286467075348,
      "learning_rate": 1.3455052060419419e-05,
      "loss": 0.0574,
      "step": 109690
    },
    {
      "epoch": 2.1937367515898094,
      "grad_norm": 0.14248161017894745,
      "learning_rate": 1.345171912703809e-05,
      "loss": 0.0503,
      "step": 109700
    },
    {
      "epoch": 2.193936727592689,
      "grad_norm": 0.07363516092300415,
      "learning_rate": 1.3448386193656761e-05,
      "loss": 0.0827,
      "step": 109710
    },
    {
      "epoch": 2.1941367035955683,
      "grad_norm": 0.13875718414783478,
      "learning_rate": 1.3445053260275434e-05,
      "loss": 0.0578,
      "step": 109720
    },
    {
      "epoch": 2.194336679598448,
      "grad_norm": 0.13284291326999664,
      "learning_rate": 1.3441720326894106e-05,
      "loss": 0.0611,
      "step": 109730
    },
    {
      "epoch": 2.1945366556013277,
      "grad_norm": 0.08805571496486664,
      "learning_rate": 1.343838739351278e-05,
      "loss": 0.0818,
      "step": 109740
    },
    {
      "epoch": 2.1947366316042074,
      "grad_norm": 0.14716698229312897,
      "learning_rate": 1.3435054460131452e-05,
      "loss": 0.0812,
      "step": 109750
    },
    {
      "epoch": 2.194936607607087,
      "grad_norm": 0.10068964213132858,
      "learning_rate": 1.3431721526750125e-05,
      "loss": 0.0857,
      "step": 109760
    },
    {
      "epoch": 2.1951365836099668,
      "grad_norm": 0.18906457722187042,
      "learning_rate": 1.3428388593368796e-05,
      "loss": 0.0475,
      "step": 109770
    },
    {
      "epoch": 2.1953365596128465,
      "grad_norm": 0.1293005347251892,
      "learning_rate": 1.3425055659987467e-05,
      "loss": 0.074,
      "step": 109780
    },
    {
      "epoch": 2.195536535615726,
      "grad_norm": 0.13497501611709595,
      "learning_rate": 1.3421722726606142e-05,
      "loss": 0.0775,
      "step": 109790
    },
    {
      "epoch": 2.195736511618606,
      "grad_norm": 0.13228127360343933,
      "learning_rate": 1.3418389793224815e-05,
      "loss": 0.054,
      "step": 109800
    },
    {
      "epoch": 2.1959364876214855,
      "grad_norm": 0.09693984687328339,
      "learning_rate": 1.3415056859843486e-05,
      "loss": 0.1085,
      "step": 109810
    },
    {
      "epoch": 2.196136463624365,
      "grad_norm": 0.18142053484916687,
      "learning_rate": 1.3411723926462158e-05,
      "loss": 0.093,
      "step": 109820
    },
    {
      "epoch": 2.196336439627245,
      "grad_norm": 0.20760731399059296,
      "learning_rate": 1.340839099308083e-05,
      "loss": 0.0636,
      "step": 109830
    },
    {
      "epoch": 2.1965364156301246,
      "grad_norm": 0.1809319257736206,
      "learning_rate": 1.3405058059699504e-05,
      "loss": 0.05,
      "step": 109840
    },
    {
      "epoch": 2.196736391633004,
      "grad_norm": 0.15787197649478912,
      "learning_rate": 1.3401725126318177e-05,
      "loss": 0.0586,
      "step": 109850
    },
    {
      "epoch": 2.1969363676358835,
      "grad_norm": 0.288718044757843,
      "learning_rate": 1.3398392192936848e-05,
      "loss": 0.2259,
      "step": 109860
    },
    {
      "epoch": 2.197136343638763,
      "grad_norm": 0.08726727217435837,
      "learning_rate": 1.3395059259555521e-05,
      "loss": 0.0479,
      "step": 109870
    },
    {
      "epoch": 2.197336319641643,
      "grad_norm": 0.18834730982780457,
      "learning_rate": 1.3391726326174192e-05,
      "loss": 0.0535,
      "step": 109880
    },
    {
      "epoch": 2.1975362956445226,
      "grad_norm": 0.07294346392154694,
      "learning_rate": 1.3388393392792867e-05,
      "loss": 0.0484,
      "step": 109890
    },
    {
      "epoch": 2.1977362716474023,
      "grad_norm": 0.12932522594928741,
      "learning_rate": 1.3385060459411538e-05,
      "loss": 0.0885,
      "step": 109900
    },
    {
      "epoch": 2.197936247650282,
      "grad_norm": 0.12801115214824677,
      "learning_rate": 1.338172752603021e-05,
      "loss": 0.0875,
      "step": 109910
    },
    {
      "epoch": 2.1981362236531616,
      "grad_norm": 0.13993999361991882,
      "learning_rate": 1.3378394592648883e-05,
      "loss": 0.0701,
      "step": 109920
    },
    {
      "epoch": 2.1983361996560413,
      "grad_norm": 0.15987935662269592,
      "learning_rate": 1.3375061659267554e-05,
      "loss": 0.0622,
      "step": 109930
    },
    {
      "epoch": 2.198536175658921,
      "grad_norm": 0.16410644352436066,
      "learning_rate": 1.3371728725886229e-05,
      "loss": 0.0903,
      "step": 109940
    },
    {
      "epoch": 2.1987361516618007,
      "grad_norm": 0.12316825985908508,
      "learning_rate": 1.33683957925049e-05,
      "loss": 0.0705,
      "step": 109950
    },
    {
      "epoch": 2.1989361276646804,
      "grad_norm": 0.10579310357570648,
      "learning_rate": 1.3365062859123573e-05,
      "loss": 0.0819,
      "step": 109960
    },
    {
      "epoch": 2.19913610366756,
      "grad_norm": 0.16474345326423645,
      "learning_rate": 1.3361729925742244e-05,
      "loss": 0.0572,
      "step": 109970
    },
    {
      "epoch": 2.1993360796704398,
      "grad_norm": 0.11255621165037155,
      "learning_rate": 1.3358396992360916e-05,
      "loss": 0.0811,
      "step": 109980
    },
    {
      "epoch": 2.199536055673319,
      "grad_norm": 0.16185931861400604,
      "learning_rate": 1.335506405897959e-05,
      "loss": 0.0644,
      "step": 109990
    },
    {
      "epoch": 2.1997360316761987,
      "grad_norm": 0.09884575754404068,
      "learning_rate": 1.3351731125598263e-05,
      "loss": 0.0563,
      "step": 110000
    },
    {
      "epoch": 2.1999360076790784,
      "grad_norm": 0.07573463767766953,
      "learning_rate": 1.3348398192216935e-05,
      "loss": 0.1195,
      "step": 110010
    },
    {
      "epoch": 2.200135983681958,
      "grad_norm": 0.1407782882452011,
      "learning_rate": 1.3345065258835606e-05,
      "loss": 0.0626,
      "step": 110020
    },
    {
      "epoch": 2.2003359596848377,
      "grad_norm": 0.16269654035568237,
      "learning_rate": 1.3341732325454279e-05,
      "loss": 0.0664,
      "step": 110030
    },
    {
      "epoch": 2.2005359356877174,
      "grad_norm": 0.10969530045986176,
      "learning_rate": 1.333839939207295e-05,
      "loss": 0.0739,
      "step": 110040
    },
    {
      "epoch": 2.200735911690597,
      "grad_norm": 0.14542949199676514,
      "learning_rate": 1.3335066458691625e-05,
      "loss": 0.0469,
      "step": 110050
    },
    {
      "epoch": 2.200935887693477,
      "grad_norm": 0.1285189539194107,
      "learning_rate": 1.3331733525310296e-05,
      "loss": 0.0587,
      "step": 110060
    },
    {
      "epoch": 2.2011358636963565,
      "grad_norm": 0.12665560841560364,
      "learning_rate": 1.332840059192897e-05,
      "loss": 0.0441,
      "step": 110070
    },
    {
      "epoch": 2.201335839699236,
      "grad_norm": 0.07429647445678711,
      "learning_rate": 1.332506765854764e-05,
      "loss": 0.0693,
      "step": 110080
    },
    {
      "epoch": 2.201535815702116,
      "grad_norm": 0.10433883219957352,
      "learning_rate": 1.3321734725166312e-05,
      "loss": 0.0811,
      "step": 110090
    },
    {
      "epoch": 2.2017357917049956,
      "grad_norm": 0.08604839444160461,
      "learning_rate": 1.3318401791784987e-05,
      "loss": 0.0565,
      "step": 110100
    },
    {
      "epoch": 2.2019357677078752,
      "grad_norm": 0.12631739675998688,
      "learning_rate": 1.331506885840366e-05,
      "loss": 0.0653,
      "step": 110110
    },
    {
      "epoch": 2.2021357437107545,
      "grad_norm": 0.07198209315538406,
      "learning_rate": 1.3311735925022331e-05,
      "loss": 0.0601,
      "step": 110120
    },
    {
      "epoch": 2.202335719713634,
      "grad_norm": 0.1297144740819931,
      "learning_rate": 1.3308402991641002e-05,
      "loss": 0.0599,
      "step": 110130
    },
    {
      "epoch": 2.202535695716514,
      "grad_norm": 0.10385479032993317,
      "learning_rate": 1.3305070058259675e-05,
      "loss": 0.0855,
      "step": 110140
    },
    {
      "epoch": 2.2027356717193936,
      "grad_norm": 0.07515077292919159,
      "learning_rate": 1.330173712487835e-05,
      "loss": 0.0718,
      "step": 110150
    },
    {
      "epoch": 2.2029356477222732,
      "grad_norm": 0.07641956955194473,
      "learning_rate": 1.3298404191497021e-05,
      "loss": 0.1328,
      "step": 110160
    },
    {
      "epoch": 2.203135623725153,
      "grad_norm": 0.23559552431106567,
      "learning_rate": 1.3295071258115693e-05,
      "loss": 0.0761,
      "step": 110170
    },
    {
      "epoch": 2.2033355997280326,
      "grad_norm": 0.05858178436756134,
      "learning_rate": 1.3291738324734366e-05,
      "loss": 0.0361,
      "step": 110180
    },
    {
      "epoch": 2.2035355757309123,
      "grad_norm": 0.10673058032989502,
      "learning_rate": 1.3288405391353037e-05,
      "loss": 0.0825,
      "step": 110190
    },
    {
      "epoch": 2.203735551733792,
      "grad_norm": 0.0817529708147049,
      "learning_rate": 1.3285072457971712e-05,
      "loss": 0.0665,
      "step": 110200
    },
    {
      "epoch": 2.2039355277366717,
      "grad_norm": 0.12773200869560242,
      "learning_rate": 1.3281739524590383e-05,
      "loss": 0.0758,
      "step": 110210
    },
    {
      "epoch": 2.2041355037395514,
      "grad_norm": 0.23963996767997742,
      "learning_rate": 1.3278406591209056e-05,
      "loss": 0.0707,
      "step": 110220
    },
    {
      "epoch": 2.204335479742431,
      "grad_norm": 0.2448873072862625,
      "learning_rate": 1.3275073657827727e-05,
      "loss": 0.0786,
      "step": 110230
    },
    {
      "epoch": 2.2045354557453107,
      "grad_norm": 0.24385187029838562,
      "learning_rate": 1.3271740724446398e-05,
      "loss": 0.0643,
      "step": 110240
    },
    {
      "epoch": 2.2047354317481904,
      "grad_norm": 0.19430583715438843,
      "learning_rate": 1.3268407791065073e-05,
      "loss": 0.0625,
      "step": 110250
    },
    {
      "epoch": 2.2049354077510697,
      "grad_norm": 0.1418931782245636,
      "learning_rate": 1.3265074857683746e-05,
      "loss": 0.0647,
      "step": 110260
    },
    {
      "epoch": 2.2051353837539494,
      "grad_norm": 0.1783086210489273,
      "learning_rate": 1.3261741924302417e-05,
      "loss": 0.0651,
      "step": 110270
    },
    {
      "epoch": 2.205335359756829,
      "grad_norm": 0.1090548038482666,
      "learning_rate": 1.3258408990921089e-05,
      "loss": 0.105,
      "step": 110280
    },
    {
      "epoch": 2.2055353357597087,
      "grad_norm": 0.19672970473766327,
      "learning_rate": 1.3255076057539762e-05,
      "loss": 0.0806,
      "step": 110290
    },
    {
      "epoch": 2.2057353117625884,
      "grad_norm": 0.07879166305065155,
      "learning_rate": 1.3251743124158437e-05,
      "loss": 0.0417,
      "step": 110300
    },
    {
      "epoch": 2.205935287765468,
      "grad_norm": 0.17866377532482147,
      "learning_rate": 1.3248410190777108e-05,
      "loss": 0.0877,
      "step": 110310
    },
    {
      "epoch": 2.206135263768348,
      "grad_norm": 0.22193361818790436,
      "learning_rate": 1.3245077257395779e-05,
      "loss": 0.0959,
      "step": 110320
    },
    {
      "epoch": 2.2063352397712275,
      "grad_norm": 0.09551508724689484,
      "learning_rate": 1.3241744324014452e-05,
      "loss": 0.0723,
      "step": 110330
    },
    {
      "epoch": 2.206535215774107,
      "grad_norm": 0.1439623385667801,
      "learning_rate": 1.3238411390633123e-05,
      "loss": 0.0635,
      "step": 110340
    },
    {
      "epoch": 2.206735191776987,
      "grad_norm": 0.11305457353591919,
      "learning_rate": 1.3235078457251798e-05,
      "loss": 0.0611,
      "step": 110350
    },
    {
      "epoch": 2.2069351677798665,
      "grad_norm": 0.17682069540023804,
      "learning_rate": 1.323174552387047e-05,
      "loss": 0.0815,
      "step": 110360
    },
    {
      "epoch": 2.2071351437827462,
      "grad_norm": 0.0903044193983078,
      "learning_rate": 1.3228412590489142e-05,
      "loss": 0.0382,
      "step": 110370
    },
    {
      "epoch": 2.207335119785626,
      "grad_norm": 0.07756531238555908,
      "learning_rate": 1.3225079657107814e-05,
      "loss": 0.0677,
      "step": 110380
    },
    {
      "epoch": 2.207535095788505,
      "grad_norm": 0.08975179493427277,
      "learning_rate": 1.3221746723726485e-05,
      "loss": 0.066,
      "step": 110390
    },
    {
      "epoch": 2.207735071791385,
      "grad_norm": 0.0883532166481018,
      "learning_rate": 1.321841379034516e-05,
      "loss": 0.0552,
      "step": 110400
    },
    {
      "epoch": 2.2079350477942645,
      "grad_norm": 0.17989401519298553,
      "learning_rate": 1.3215080856963833e-05,
      "loss": 0.0934,
      "step": 110410
    },
    {
      "epoch": 2.208135023797144,
      "grad_norm": 0.17621800303459167,
      "learning_rate": 1.3211747923582504e-05,
      "loss": 0.1051,
      "step": 110420
    },
    {
      "epoch": 2.208334999800024,
      "grad_norm": 0.12056472152471542,
      "learning_rate": 1.3208414990201175e-05,
      "loss": 0.082,
      "step": 110430
    },
    {
      "epoch": 2.2085349758029036,
      "grad_norm": 0.17555338144302368,
      "learning_rate": 1.3205082056819848e-05,
      "loss": 0.0956,
      "step": 110440
    },
    {
      "epoch": 2.2087349518057833,
      "grad_norm": 0.20905667543411255,
      "learning_rate": 1.3201749123438523e-05,
      "loss": 0.1045,
      "step": 110450
    },
    {
      "epoch": 2.208934927808663,
      "grad_norm": 0.18433398008346558,
      "learning_rate": 1.3198416190057194e-05,
      "loss": 0.0554,
      "step": 110460
    },
    {
      "epoch": 2.2091349038115426,
      "grad_norm": 0.07997434586286545,
      "learning_rate": 1.3195083256675866e-05,
      "loss": 0.0354,
      "step": 110470
    },
    {
      "epoch": 2.2093348798144223,
      "grad_norm": 0.21595369279384613,
      "learning_rate": 1.3191750323294539e-05,
      "loss": 0.073,
      "step": 110480
    },
    {
      "epoch": 2.209534855817302,
      "grad_norm": 0.10155404359102249,
      "learning_rate": 1.318841738991321e-05,
      "loss": 0.0871,
      "step": 110490
    },
    {
      "epoch": 2.2097348318201817,
      "grad_norm": 0.10642129182815552,
      "learning_rate": 1.3185084456531885e-05,
      "loss": 0.0569,
      "step": 110500
    },
    {
      "epoch": 2.2099348078230614,
      "grad_norm": 0.10324900597333908,
      "learning_rate": 1.3181751523150556e-05,
      "loss": 0.0493,
      "step": 110510
    },
    {
      "epoch": 2.210134783825941,
      "grad_norm": 0.20668543875217438,
      "learning_rate": 1.3178418589769229e-05,
      "loss": 0.0743,
      "step": 110520
    },
    {
      "epoch": 2.2103347598288208,
      "grad_norm": 0.1151464506983757,
      "learning_rate": 1.31750856563879e-05,
      "loss": 0.087,
      "step": 110530
    },
    {
      "epoch": 2.2105347358317,
      "grad_norm": 0.12234650552272797,
      "learning_rate": 1.3171752723006572e-05,
      "loss": 0.0781,
      "step": 110540
    },
    {
      "epoch": 2.2107347118345797,
      "grad_norm": 0.10542182624340057,
      "learning_rate": 1.3168419789625245e-05,
      "loss": 0.0692,
      "step": 110550
    },
    {
      "epoch": 2.2109346878374594,
      "grad_norm": 0.1399667114019394,
      "learning_rate": 1.316508685624392e-05,
      "loss": 0.0761,
      "step": 110560
    },
    {
      "epoch": 2.211134663840339,
      "grad_norm": 0.12521925568580627,
      "learning_rate": 1.316175392286259e-05,
      "loss": 0.052,
      "step": 110570
    },
    {
      "epoch": 2.2113346398432188,
      "grad_norm": 0.1091037169098854,
      "learning_rate": 1.3158420989481262e-05,
      "loss": 0.0813,
      "step": 110580
    },
    {
      "epoch": 2.2115346158460985,
      "grad_norm": 0.11897237598896027,
      "learning_rate": 1.3155088056099935e-05,
      "loss": 0.0786,
      "step": 110590
    },
    {
      "epoch": 2.211734591848978,
      "grad_norm": 0.259600967168808,
      "learning_rate": 1.3151755122718606e-05,
      "loss": 0.1176,
      "step": 110600
    },
    {
      "epoch": 2.211934567851858,
      "grad_norm": 0.19828367233276367,
      "learning_rate": 1.3148422189337281e-05,
      "loss": 0.0645,
      "step": 110610
    },
    {
      "epoch": 2.2121345438547375,
      "grad_norm": 0.19895805418491364,
      "learning_rate": 1.3145089255955952e-05,
      "loss": 0.0804,
      "step": 110620
    },
    {
      "epoch": 2.212334519857617,
      "grad_norm": 0.2150772511959076,
      "learning_rate": 1.3141756322574625e-05,
      "loss": 0.0849,
      "step": 110630
    },
    {
      "epoch": 2.212534495860497,
      "grad_norm": 0.24760113656520844,
      "learning_rate": 1.3138423389193297e-05,
      "loss": 0.0812,
      "step": 110640
    },
    {
      "epoch": 2.2127344718633766,
      "grad_norm": 0.1160450428724289,
      "learning_rate": 1.3135090455811968e-05,
      "loss": 0.0428,
      "step": 110650
    },
    {
      "epoch": 2.212934447866256,
      "grad_norm": 0.05691750347614288,
      "learning_rate": 1.3131757522430643e-05,
      "loss": 0.0413,
      "step": 110660
    },
    {
      "epoch": 2.2131344238691355,
      "grad_norm": 0.14018484950065613,
      "learning_rate": 1.3128424589049316e-05,
      "loss": 0.0384,
      "step": 110670
    },
    {
      "epoch": 2.213334399872015,
      "grad_norm": 0.42546409368515015,
      "learning_rate": 1.3125091655667987e-05,
      "loss": 0.1301,
      "step": 110680
    },
    {
      "epoch": 2.213534375874895,
      "grad_norm": 0.2125808298587799,
      "learning_rate": 1.3121758722286658e-05,
      "loss": 0.0677,
      "step": 110690
    },
    {
      "epoch": 2.2137343518777746,
      "grad_norm": 0.1704212874174118,
      "learning_rate": 1.3118425788905331e-05,
      "loss": 0.0624,
      "step": 110700
    },
    {
      "epoch": 2.2139343278806543,
      "grad_norm": 0.21374741196632385,
      "learning_rate": 1.3115092855524006e-05,
      "loss": 0.1114,
      "step": 110710
    },
    {
      "epoch": 2.214134303883534,
      "grad_norm": 0.09862697124481201,
      "learning_rate": 1.3111759922142677e-05,
      "loss": 0.0654,
      "step": 110720
    },
    {
      "epoch": 2.2143342798864136,
      "grad_norm": 0.2267858386039734,
      "learning_rate": 1.3108426988761349e-05,
      "loss": 0.0753,
      "step": 110730
    },
    {
      "epoch": 2.2145342558892933,
      "grad_norm": 0.09641270339488983,
      "learning_rate": 1.3105094055380022e-05,
      "loss": 0.1556,
      "step": 110740
    },
    {
      "epoch": 2.214734231892173,
      "grad_norm": 0.06550214439630508,
      "learning_rate": 1.3101761121998693e-05,
      "loss": 0.0711,
      "step": 110750
    },
    {
      "epoch": 2.2149342078950527,
      "grad_norm": 0.10228318721055984,
      "learning_rate": 1.3098428188617368e-05,
      "loss": 0.0964,
      "step": 110760
    },
    {
      "epoch": 2.2151341838979324,
      "grad_norm": 0.18872852623462677,
      "learning_rate": 1.3095095255236039e-05,
      "loss": 0.1374,
      "step": 110770
    },
    {
      "epoch": 2.215334159900812,
      "grad_norm": 0.11513352394104004,
      "learning_rate": 1.3091762321854712e-05,
      "loss": 0.2897,
      "step": 110780
    },
    {
      "epoch": 2.2155341359036917,
      "grad_norm": 0.08602310717105865,
      "learning_rate": 1.3088429388473383e-05,
      "loss": 0.0783,
      "step": 110790
    },
    {
      "epoch": 2.2157341119065714,
      "grad_norm": 0.06889472901821136,
      "learning_rate": 1.3085096455092055e-05,
      "loss": 0.0715,
      "step": 110800
    },
    {
      "epoch": 2.2159340879094507,
      "grad_norm": 0.08248559385538101,
      "learning_rate": 1.308176352171073e-05,
      "loss": 0.0898,
      "step": 110810
    },
    {
      "epoch": 2.2161340639123304,
      "grad_norm": 0.1656917780637741,
      "learning_rate": 1.3078430588329402e-05,
      "loss": 0.0626,
      "step": 110820
    },
    {
      "epoch": 2.21633403991521,
      "grad_norm": 0.10818322747945786,
      "learning_rate": 1.3075097654948074e-05,
      "loss": 0.0717,
      "step": 110830
    },
    {
      "epoch": 2.2165340159180897,
      "grad_norm": 0.15154503285884857,
      "learning_rate": 1.3071764721566745e-05,
      "loss": 0.0728,
      "step": 110840
    },
    {
      "epoch": 2.2167339919209694,
      "grad_norm": 0.09094753116369247,
      "learning_rate": 1.3068431788185418e-05,
      "loss": 0.0416,
      "step": 110850
    },
    {
      "epoch": 2.216933967923849,
      "grad_norm": 0.17232687771320343,
      "learning_rate": 1.3065098854804093e-05,
      "loss": 0.077,
      "step": 110860
    },
    {
      "epoch": 2.217133943926729,
      "grad_norm": 0.32766371965408325,
      "learning_rate": 1.3061765921422764e-05,
      "loss": 0.4319,
      "step": 110870
    },
    {
      "epoch": 2.2173339199296085,
      "grad_norm": 0.10605709254741669,
      "learning_rate": 1.3058432988041435e-05,
      "loss": 0.0651,
      "step": 110880
    },
    {
      "epoch": 2.217533895932488,
      "grad_norm": 0.2519070506095886,
      "learning_rate": 1.3055100054660108e-05,
      "loss": 0.1245,
      "step": 110890
    },
    {
      "epoch": 2.217733871935368,
      "grad_norm": 0.16196303069591522,
      "learning_rate": 1.305176712127878e-05,
      "loss": 0.0615,
      "step": 110900
    },
    {
      "epoch": 2.2179338479382475,
      "grad_norm": 0.0650031566619873,
      "learning_rate": 1.3048434187897454e-05,
      "loss": 0.0589,
      "step": 110910
    },
    {
      "epoch": 2.2181338239411272,
      "grad_norm": 0.10704764723777771,
      "learning_rate": 1.3045101254516125e-05,
      "loss": 0.0641,
      "step": 110920
    },
    {
      "epoch": 2.218333799944007,
      "grad_norm": 0.1161358579993248,
      "learning_rate": 1.3041768321134798e-05,
      "loss": 0.0572,
      "step": 110930
    },
    {
      "epoch": 2.218533775946886,
      "grad_norm": 0.16064459085464478,
      "learning_rate": 1.303843538775347e-05,
      "loss": 0.0526,
      "step": 110940
    },
    {
      "epoch": 2.218733751949766,
      "grad_norm": 0.08878261595964432,
      "learning_rate": 1.3035102454372141e-05,
      "loss": 0.0564,
      "step": 110950
    },
    {
      "epoch": 2.2189337279526455,
      "grad_norm": 0.2438504844903946,
      "learning_rate": 1.3031769520990816e-05,
      "loss": 0.085,
      "step": 110960
    },
    {
      "epoch": 2.2191337039555252,
      "grad_norm": 0.1536560356616974,
      "learning_rate": 1.3028436587609489e-05,
      "loss": 0.05,
      "step": 110970
    },
    {
      "epoch": 2.219333679958405,
      "grad_norm": 0.12499915808439255,
      "learning_rate": 1.302510365422816e-05,
      "loss": 0.0828,
      "step": 110980
    },
    {
      "epoch": 2.2195336559612846,
      "grad_norm": 0.1484261155128479,
      "learning_rate": 1.3021770720846831e-05,
      "loss": 0.0823,
      "step": 110990
    },
    {
      "epoch": 2.2197336319641643,
      "grad_norm": 0.22474640607833862,
      "learning_rate": 1.3018437787465504e-05,
      "loss": 0.0813,
      "step": 111000
    },
    {
      "epoch": 2.219933607967044,
      "grad_norm": 0.09834568947553635,
      "learning_rate": 1.3015104854084179e-05,
      "loss": 0.107,
      "step": 111010
    },
    {
      "epoch": 2.2201335839699237,
      "grad_norm": 0.1619187295436859,
      "learning_rate": 1.301177192070285e-05,
      "loss": 0.0898,
      "step": 111020
    },
    {
      "epoch": 2.2203335599728034,
      "grad_norm": 0.17214912176132202,
      "learning_rate": 1.3008438987321522e-05,
      "loss": 0.0603,
      "step": 111030
    },
    {
      "epoch": 2.220533535975683,
      "grad_norm": 0.21515794098377228,
      "learning_rate": 1.3005106053940195e-05,
      "loss": 0.1184,
      "step": 111040
    },
    {
      "epoch": 2.2207335119785627,
      "grad_norm": 0.09168694168329239,
      "learning_rate": 1.3001773120558866e-05,
      "loss": 0.0516,
      "step": 111050
    },
    {
      "epoch": 2.2209334879814424,
      "grad_norm": 0.16954351961612701,
      "learning_rate": 1.2998440187177537e-05,
      "loss": 0.0839,
      "step": 111060
    },
    {
      "epoch": 2.221133463984322,
      "grad_norm": 0.1082346960902214,
      "learning_rate": 1.2995107253796212e-05,
      "loss": 0.075,
      "step": 111070
    },
    {
      "epoch": 2.2213334399872013,
      "grad_norm": 0.12336715310811996,
      "learning_rate": 1.2991774320414885e-05,
      "loss": 0.0537,
      "step": 111080
    },
    {
      "epoch": 2.221533415990081,
      "grad_norm": 0.1307828575372696,
      "learning_rate": 1.2988441387033556e-05,
      "loss": 0.0489,
      "step": 111090
    },
    {
      "epoch": 2.2217333919929607,
      "grad_norm": 0.20935280621051788,
      "learning_rate": 1.2985108453652228e-05,
      "loss": 0.1001,
      "step": 111100
    },
    {
      "epoch": 2.2219333679958404,
      "grad_norm": 0.13308455049991608,
      "learning_rate": 1.29817755202709e-05,
      "loss": 0.0882,
      "step": 111110
    },
    {
      "epoch": 2.22213334399872,
      "grad_norm": 0.18969818949699402,
      "learning_rate": 1.2978442586889575e-05,
      "loss": 0.1161,
      "step": 111120
    },
    {
      "epoch": 2.2223333200015998,
      "grad_norm": 0.19160495698451996,
      "learning_rate": 1.2975109653508247e-05,
      "loss": 0.0833,
      "step": 111130
    },
    {
      "epoch": 2.2225332960044795,
      "grad_norm": 0.07699627429246902,
      "learning_rate": 1.2971776720126918e-05,
      "loss": 0.0995,
      "step": 111140
    },
    {
      "epoch": 2.222733272007359,
      "grad_norm": 0.2941316068172455,
      "learning_rate": 1.2968443786745591e-05,
      "loss": 0.1,
      "step": 111150
    },
    {
      "epoch": 2.222933248010239,
      "grad_norm": 0.2107519954442978,
      "learning_rate": 1.2965110853364262e-05,
      "loss": 0.0466,
      "step": 111160
    },
    {
      "epoch": 2.2231332240131185,
      "grad_norm": 0.047453008592128754,
      "learning_rate": 1.2961777919982937e-05,
      "loss": 0.0951,
      "step": 111170
    },
    {
      "epoch": 2.223333200015998,
      "grad_norm": 0.19024407863616943,
      "learning_rate": 1.2958444986601608e-05,
      "loss": 0.0748,
      "step": 111180
    },
    {
      "epoch": 2.223533176018878,
      "grad_norm": 0.10650612413883209,
      "learning_rate": 1.2955112053220281e-05,
      "loss": 0.0575,
      "step": 111190
    },
    {
      "epoch": 2.2237331520217576,
      "grad_norm": 0.1458115130662918,
      "learning_rate": 1.2951779119838953e-05,
      "loss": 0.098,
      "step": 111200
    },
    {
      "epoch": 2.223933128024637,
      "grad_norm": 0.22503328323364258,
      "learning_rate": 1.2948446186457624e-05,
      "loss": 0.0717,
      "step": 111210
    },
    {
      "epoch": 2.2241331040275165,
      "grad_norm": 0.1335761994123459,
      "learning_rate": 1.2945113253076299e-05,
      "loss": 0.0516,
      "step": 111220
    },
    {
      "epoch": 2.224333080030396,
      "grad_norm": 0.25262200832366943,
      "learning_rate": 1.2941780319694972e-05,
      "loss": 0.117,
      "step": 111230
    },
    {
      "epoch": 2.224533056033276,
      "grad_norm": 0.1698458194732666,
      "learning_rate": 1.2938447386313643e-05,
      "loss": 0.0726,
      "step": 111240
    },
    {
      "epoch": 2.2247330320361556,
      "grad_norm": 0.11827822774648666,
      "learning_rate": 1.2935114452932314e-05,
      "loss": 0.0663,
      "step": 111250
    },
    {
      "epoch": 2.2249330080390353,
      "grad_norm": 0.11111371219158173,
      "learning_rate": 1.2931781519550987e-05,
      "loss": 0.0797,
      "step": 111260
    },
    {
      "epoch": 2.225132984041915,
      "grad_norm": 0.07678049057722092,
      "learning_rate": 1.2928448586169662e-05,
      "loss": 0.06,
      "step": 111270
    },
    {
      "epoch": 2.2253329600447946,
      "grad_norm": 0.09201619029045105,
      "learning_rate": 1.2925115652788333e-05,
      "loss": 0.0392,
      "step": 111280
    },
    {
      "epoch": 2.2255329360476743,
      "grad_norm": 0.10742713510990143,
      "learning_rate": 1.2921782719407005e-05,
      "loss": 0.046,
      "step": 111290
    },
    {
      "epoch": 2.225732912050554,
      "grad_norm": 0.07434149086475372,
      "learning_rate": 1.2918449786025678e-05,
      "loss": 0.0586,
      "step": 111300
    },
    {
      "epoch": 2.2259328880534337,
      "grad_norm": 0.09142813831567764,
      "learning_rate": 1.2915116852644349e-05,
      "loss": 0.0558,
      "step": 111310
    },
    {
      "epoch": 2.2261328640563134,
      "grad_norm": 0.09637598693370819,
      "learning_rate": 1.2911783919263024e-05,
      "loss": 0.0886,
      "step": 111320
    },
    {
      "epoch": 2.226332840059193,
      "grad_norm": 0.08024220913648605,
      "learning_rate": 1.2908450985881695e-05,
      "loss": 0.0534,
      "step": 111330
    },
    {
      "epoch": 2.2265328160620728,
      "grad_norm": 0.11689906567335129,
      "learning_rate": 1.2905118052500368e-05,
      "loss": 0.0748,
      "step": 111340
    },
    {
      "epoch": 2.226732792064952,
      "grad_norm": 0.09803902357816696,
      "learning_rate": 1.290178511911904e-05,
      "loss": 0.0554,
      "step": 111350
    },
    {
      "epoch": 2.2269327680678317,
      "grad_norm": 0.10945256054401398,
      "learning_rate": 1.289845218573771e-05,
      "loss": 0.1026,
      "step": 111360
    },
    {
      "epoch": 2.2271327440707114,
      "grad_norm": 0.16442856192588806,
      "learning_rate": 1.2895119252356385e-05,
      "loss": 0.0911,
      "step": 111370
    },
    {
      "epoch": 2.227332720073591,
      "grad_norm": 0.17851677536964417,
      "learning_rate": 1.2891786318975058e-05,
      "loss": 0.0632,
      "step": 111380
    },
    {
      "epoch": 2.2275326960764708,
      "grad_norm": 0.24822908639907837,
      "learning_rate": 1.288845338559373e-05,
      "loss": 0.0885,
      "step": 111390
    },
    {
      "epoch": 2.2277326720793504,
      "grad_norm": 0.0973958671092987,
      "learning_rate": 1.2885120452212401e-05,
      "loss": 0.0894,
      "step": 111400
    },
    {
      "epoch": 2.22793264808223,
      "grad_norm": 0.10638692229986191,
      "learning_rate": 1.2881787518831074e-05,
      "loss": 0.0464,
      "step": 111410
    },
    {
      "epoch": 2.22813262408511,
      "grad_norm": 0.11170408129692078,
      "learning_rate": 1.2878454585449749e-05,
      "loss": 0.0972,
      "step": 111420
    },
    {
      "epoch": 2.2283326000879895,
      "grad_norm": 0.19200575351715088,
      "learning_rate": 1.287512165206842e-05,
      "loss": 0.09,
      "step": 111430
    },
    {
      "epoch": 2.228532576090869,
      "grad_norm": 0.1141166239976883,
      "learning_rate": 1.2871788718687091e-05,
      "loss": 0.1005,
      "step": 111440
    },
    {
      "epoch": 2.228732552093749,
      "grad_norm": 0.1464260071516037,
      "learning_rate": 1.2868455785305764e-05,
      "loss": 0.074,
      "step": 111450
    },
    {
      "epoch": 2.2289325280966286,
      "grad_norm": 0.15269356966018677,
      "learning_rate": 1.2865122851924436e-05,
      "loss": 0.0662,
      "step": 111460
    },
    {
      "epoch": 2.2291325040995082,
      "grad_norm": 0.2564782500267029,
      "learning_rate": 1.286178991854311e-05,
      "loss": 0.0982,
      "step": 111470
    },
    {
      "epoch": 2.2293324801023875,
      "grad_norm": 0.13243818283081055,
      "learning_rate": 1.2858456985161782e-05,
      "loss": 0.076,
      "step": 111480
    },
    {
      "epoch": 2.229532456105267,
      "grad_norm": 0.12361200153827667,
      "learning_rate": 1.2855124051780455e-05,
      "loss": 0.0656,
      "step": 111490
    },
    {
      "epoch": 2.229732432108147,
      "grad_norm": 0.06360547989606857,
      "learning_rate": 1.2851791118399126e-05,
      "loss": 0.0847,
      "step": 111500
    },
    {
      "epoch": 2.2299324081110266,
      "grad_norm": 0.12122222781181335,
      "learning_rate": 1.2848458185017797e-05,
      "loss": 0.0923,
      "step": 111510
    },
    {
      "epoch": 2.2301323841139062,
      "grad_norm": 0.17894190549850464,
      "learning_rate": 1.2845125251636472e-05,
      "loss": 0.0609,
      "step": 111520
    },
    {
      "epoch": 2.230332360116786,
      "grad_norm": 0.135630801320076,
      "learning_rate": 1.2841792318255145e-05,
      "loss": 0.0812,
      "step": 111530
    },
    {
      "epoch": 2.2305323361196656,
      "grad_norm": 0.05049635097384453,
      "learning_rate": 1.2838459384873816e-05,
      "loss": 0.0916,
      "step": 111540
    },
    {
      "epoch": 2.2307323121225453,
      "grad_norm": 0.0731082558631897,
      "learning_rate": 1.2835126451492487e-05,
      "loss": 0.037,
      "step": 111550
    },
    {
      "epoch": 2.230932288125425,
      "grad_norm": 0.10067808628082275,
      "learning_rate": 1.283179351811116e-05,
      "loss": 0.0768,
      "step": 111560
    },
    {
      "epoch": 2.2311322641283047,
      "grad_norm": 0.1359088122844696,
      "learning_rate": 1.2828460584729832e-05,
      "loss": 0.0351,
      "step": 111570
    },
    {
      "epoch": 2.2313322401311844,
      "grad_norm": 0.14976775646209717,
      "learning_rate": 1.2825127651348506e-05,
      "loss": 0.0674,
      "step": 111580
    },
    {
      "epoch": 2.231532216134064,
      "grad_norm": 0.06091750040650368,
      "learning_rate": 1.2821794717967178e-05,
      "loss": 0.0522,
      "step": 111590
    },
    {
      "epoch": 2.2317321921369437,
      "grad_norm": 0.15024563670158386,
      "learning_rate": 1.281846178458585e-05,
      "loss": 0.0685,
      "step": 111600
    },
    {
      "epoch": 2.2319321681398234,
      "grad_norm": 0.14502041041851044,
      "learning_rate": 1.2815128851204522e-05,
      "loss": 0.047,
      "step": 111610
    },
    {
      "epoch": 2.2321321441427027,
      "grad_norm": 0.2184436172246933,
      "learning_rate": 1.2811795917823193e-05,
      "loss": 0.0865,
      "step": 111620
    },
    {
      "epoch": 2.2323321201455824,
      "grad_norm": 0.09809950739145279,
      "learning_rate": 1.2808462984441868e-05,
      "loss": 0.052,
      "step": 111630
    },
    {
      "epoch": 2.232532096148462,
      "grad_norm": 0.15529608726501465,
      "learning_rate": 1.2805130051060541e-05,
      "loss": 0.0505,
      "step": 111640
    },
    {
      "epoch": 2.2327320721513417,
      "grad_norm": 0.21069614589214325,
      "learning_rate": 1.2801797117679212e-05,
      "loss": 0.0544,
      "step": 111650
    },
    {
      "epoch": 2.2329320481542214,
      "grad_norm": 0.16893039643764496,
      "learning_rate": 1.2798464184297884e-05,
      "loss": 0.123,
      "step": 111660
    },
    {
      "epoch": 2.233132024157101,
      "grad_norm": 0.2402254343032837,
      "learning_rate": 1.2795131250916557e-05,
      "loss": 0.0675,
      "step": 111670
    },
    {
      "epoch": 2.233332000159981,
      "grad_norm": 0.12790679931640625,
      "learning_rate": 1.2791798317535231e-05,
      "loss": 0.0621,
      "step": 111680
    },
    {
      "epoch": 2.2335319761628605,
      "grad_norm": 0.08291654288768768,
      "learning_rate": 1.2788465384153903e-05,
      "loss": 0.0612,
      "step": 111690
    },
    {
      "epoch": 2.23373195216574,
      "grad_norm": 0.08682149648666382,
      "learning_rate": 1.2785132450772574e-05,
      "loss": 0.0389,
      "step": 111700
    },
    {
      "epoch": 2.23393192816862,
      "grad_norm": 0.14690563082695007,
      "learning_rate": 1.2781799517391247e-05,
      "loss": 0.0895,
      "step": 111710
    },
    {
      "epoch": 2.2341319041714995,
      "grad_norm": 0.10350073873996735,
      "learning_rate": 1.2778466584009918e-05,
      "loss": 0.0731,
      "step": 111720
    },
    {
      "epoch": 2.2343318801743792,
      "grad_norm": 0.24380208551883698,
      "learning_rate": 1.2775133650628593e-05,
      "loss": 0.0842,
      "step": 111730
    },
    {
      "epoch": 2.234531856177259,
      "grad_norm": 0.12210164964199066,
      "learning_rate": 1.2771800717247264e-05,
      "loss": 0.0681,
      "step": 111740
    },
    {
      "epoch": 2.234731832180138,
      "grad_norm": 0.2907370626926422,
      "learning_rate": 1.2768467783865937e-05,
      "loss": 0.0783,
      "step": 111750
    },
    {
      "epoch": 2.234931808183018,
      "grad_norm": 0.15785032510757446,
      "learning_rate": 1.2765134850484609e-05,
      "loss": 0.0714,
      "step": 111760
    },
    {
      "epoch": 2.2351317841858975,
      "grad_norm": 0.2019035369157791,
      "learning_rate": 1.276180191710328e-05,
      "loss": 0.0657,
      "step": 111770
    },
    {
      "epoch": 2.235331760188777,
      "grad_norm": 0.17678555846214294,
      "learning_rate": 1.2758468983721955e-05,
      "loss": 0.0937,
      "step": 111780
    },
    {
      "epoch": 2.235531736191657,
      "grad_norm": 0.12804405391216278,
      "learning_rate": 1.2755136050340628e-05,
      "loss": 0.0679,
      "step": 111790
    },
    {
      "epoch": 2.2357317121945366,
      "grad_norm": 0.1603204905986786,
      "learning_rate": 1.2751803116959299e-05,
      "loss": 0.0699,
      "step": 111800
    },
    {
      "epoch": 2.2359316881974163,
      "grad_norm": 0.16197705268859863,
      "learning_rate": 1.274847018357797e-05,
      "loss": 0.0811,
      "step": 111810
    },
    {
      "epoch": 2.236131664200296,
      "grad_norm": 0.16708926856517792,
      "learning_rate": 1.2745137250196643e-05,
      "loss": 0.0445,
      "step": 111820
    },
    {
      "epoch": 2.2363316402031757,
      "grad_norm": 0.1294742226600647,
      "learning_rate": 1.2741804316815318e-05,
      "loss": 0.0544,
      "step": 111830
    },
    {
      "epoch": 2.2365316162060553,
      "grad_norm": 0.09860951453447342,
      "learning_rate": 1.273847138343399e-05,
      "loss": 0.0767,
      "step": 111840
    },
    {
      "epoch": 2.236731592208935,
      "grad_norm": 0.1811489313840866,
      "learning_rate": 1.273513845005266e-05,
      "loss": 0.0707,
      "step": 111850
    },
    {
      "epoch": 2.2369315682118147,
      "grad_norm": 0.17960874736309052,
      "learning_rate": 1.2731805516671334e-05,
      "loss": 0.0556,
      "step": 111860
    },
    {
      "epoch": 2.2371315442146944,
      "grad_norm": 0.09680423140525818,
      "learning_rate": 1.2728472583290005e-05,
      "loss": 0.1387,
      "step": 111870
    },
    {
      "epoch": 2.237331520217574,
      "grad_norm": 0.19124098122119904,
      "learning_rate": 1.272513964990868e-05,
      "loss": 0.0698,
      "step": 111880
    },
    {
      "epoch": 2.2375314962204538,
      "grad_norm": 0.12540596723556519,
      "learning_rate": 1.2721806716527351e-05,
      "loss": 0.0862,
      "step": 111890
    },
    {
      "epoch": 2.237731472223333,
      "grad_norm": 0.18964651226997375,
      "learning_rate": 1.2718473783146024e-05,
      "loss": 0.0847,
      "step": 111900
    },
    {
      "epoch": 2.2379314482262127,
      "grad_norm": 0.22058169543743134,
      "learning_rate": 1.2715140849764695e-05,
      "loss": 0.0854,
      "step": 111910
    },
    {
      "epoch": 2.2381314242290924,
      "grad_norm": 0.2412983626127243,
      "learning_rate": 1.2711807916383367e-05,
      "loss": 0.0706,
      "step": 111920
    },
    {
      "epoch": 2.238331400231972,
      "grad_norm": 0.12142866104841232,
      "learning_rate": 1.2708474983002041e-05,
      "loss": 0.0943,
      "step": 111930
    },
    {
      "epoch": 2.2385313762348518,
      "grad_norm": 0.10772408545017242,
      "learning_rate": 1.2705142049620714e-05,
      "loss": 0.1,
      "step": 111940
    },
    {
      "epoch": 2.2387313522377315,
      "grad_norm": 0.09831160306930542,
      "learning_rate": 1.2701809116239386e-05,
      "loss": 0.0898,
      "step": 111950
    },
    {
      "epoch": 2.238931328240611,
      "grad_norm": 0.08322208374738693,
      "learning_rate": 1.2698476182858057e-05,
      "loss": 0.0578,
      "step": 111960
    },
    {
      "epoch": 2.239131304243491,
      "grad_norm": 0.08641190826892853,
      "learning_rate": 1.269514324947673e-05,
      "loss": 0.0392,
      "step": 111970
    },
    {
      "epoch": 2.2393312802463705,
      "grad_norm": 0.15318289399147034,
      "learning_rate": 1.2691810316095405e-05,
      "loss": 0.0897,
      "step": 111980
    },
    {
      "epoch": 2.23953125624925,
      "grad_norm": 0.23808619379997253,
      "learning_rate": 1.2688477382714076e-05,
      "loss": 0.0822,
      "step": 111990
    },
    {
      "epoch": 2.23973123225213,
      "grad_norm": 0.10841318964958191,
      "learning_rate": 1.2685144449332747e-05,
      "loss": 0.0422,
      "step": 112000
    },
    {
      "epoch": 2.2399312082550096,
      "grad_norm": 0.1489141434431076,
      "learning_rate": 1.268181151595142e-05,
      "loss": 0.0904,
      "step": 112010
    },
    {
      "epoch": 2.240131184257889,
      "grad_norm": 0.15866510570049286,
      "learning_rate": 1.2678478582570092e-05,
      "loss": 0.0585,
      "step": 112020
    },
    {
      "epoch": 2.2403311602607685,
      "grad_norm": 0.18287327885627747,
      "learning_rate": 1.2675145649188763e-05,
      "loss": 0.071,
      "step": 112030
    },
    {
      "epoch": 2.240531136263648,
      "grad_norm": 0.09772051870822906,
      "learning_rate": 1.2671812715807438e-05,
      "loss": 0.0611,
      "step": 112040
    },
    {
      "epoch": 2.240731112266528,
      "grad_norm": 0.1461321860551834,
      "learning_rate": 1.266847978242611e-05,
      "loss": 0.0778,
      "step": 112050
    },
    {
      "epoch": 2.2409310882694076,
      "grad_norm": 0.2112559825181961,
      "learning_rate": 1.2665146849044782e-05,
      "loss": 0.078,
      "step": 112060
    },
    {
      "epoch": 2.2411310642722873,
      "grad_norm": 0.12612037360668182,
      "learning_rate": 1.2661813915663453e-05,
      "loss": 0.0642,
      "step": 112070
    },
    {
      "epoch": 2.241331040275167,
      "grad_norm": 0.20987603068351746,
      "learning_rate": 1.2658480982282126e-05,
      "loss": 0.0709,
      "step": 112080
    },
    {
      "epoch": 2.2415310162780466,
      "grad_norm": 0.19210971891880035,
      "learning_rate": 1.2655148048900801e-05,
      "loss": 0.0547,
      "step": 112090
    },
    {
      "epoch": 2.2417309922809263,
      "grad_norm": 0.12501473724842072,
      "learning_rate": 1.2651815115519472e-05,
      "loss": 0.0561,
      "step": 112100
    },
    {
      "epoch": 2.241930968283806,
      "grad_norm": 0.19733551144599915,
      "learning_rate": 1.2648482182138144e-05,
      "loss": 0.079,
      "step": 112110
    },
    {
      "epoch": 2.2421309442866857,
      "grad_norm": 0.1356051117181778,
      "learning_rate": 1.2645149248756817e-05,
      "loss": 0.0937,
      "step": 112120
    },
    {
      "epoch": 2.2423309202895654,
      "grad_norm": 0.14695119857788086,
      "learning_rate": 1.2641816315375488e-05,
      "loss": 0.0763,
      "step": 112130
    },
    {
      "epoch": 2.242530896292445,
      "grad_norm": 0.07308986783027649,
      "learning_rate": 1.2638483381994163e-05,
      "loss": 0.0558,
      "step": 112140
    },
    {
      "epoch": 2.2427308722953248,
      "grad_norm": 0.21657025814056396,
      "learning_rate": 1.2635150448612834e-05,
      "loss": 0.0912,
      "step": 112150
    },
    {
      "epoch": 2.2429308482982044,
      "grad_norm": 0.10726390033960342,
      "learning_rate": 1.2631817515231507e-05,
      "loss": 0.0839,
      "step": 112160
    },
    {
      "epoch": 2.2431308243010837,
      "grad_norm": 0.1028437688946724,
      "learning_rate": 1.2628484581850178e-05,
      "loss": 0.0433,
      "step": 112170
    },
    {
      "epoch": 2.2433308003039634,
      "grad_norm": 0.2075224071741104,
      "learning_rate": 1.262515164846885e-05,
      "loss": 0.1075,
      "step": 112180
    },
    {
      "epoch": 2.243530776306843,
      "grad_norm": 0.1380256861448288,
      "learning_rate": 1.2621818715087524e-05,
      "loss": 0.0625,
      "step": 112190
    },
    {
      "epoch": 2.2437307523097227,
      "grad_norm": 0.08680219948291779,
      "learning_rate": 1.2618485781706197e-05,
      "loss": 0.0659,
      "step": 112200
    },
    {
      "epoch": 2.2439307283126024,
      "grad_norm": 0.21696311235427856,
      "learning_rate": 1.2615152848324868e-05,
      "loss": 0.0872,
      "step": 112210
    },
    {
      "epoch": 2.244130704315482,
      "grad_norm": 0.21571098268032074,
      "learning_rate": 1.261181991494354e-05,
      "loss": 0.0568,
      "step": 112220
    },
    {
      "epoch": 2.244330680318362,
      "grad_norm": 0.10298407822847366,
      "learning_rate": 1.2608486981562213e-05,
      "loss": 0.0852,
      "step": 112230
    },
    {
      "epoch": 2.2445306563212415,
      "grad_norm": 0.2539936304092407,
      "learning_rate": 1.2605154048180886e-05,
      "loss": 0.124,
      "step": 112240
    },
    {
      "epoch": 2.244730632324121,
      "grad_norm": 0.23500098288059235,
      "learning_rate": 1.2601821114799559e-05,
      "loss": 0.0641,
      "step": 112250
    },
    {
      "epoch": 2.244930608327001,
      "grad_norm": 0.19887463748455048,
      "learning_rate": 1.259848818141823e-05,
      "loss": 0.0615,
      "step": 112260
    },
    {
      "epoch": 2.2451305843298806,
      "grad_norm": 0.20655931532382965,
      "learning_rate": 1.2595155248036903e-05,
      "loss": 0.1132,
      "step": 112270
    },
    {
      "epoch": 2.2453305603327602,
      "grad_norm": 0.113109290599823,
      "learning_rate": 1.2591822314655574e-05,
      "loss": 0.0582,
      "step": 112280
    },
    {
      "epoch": 2.24553053633564,
      "grad_norm": 0.13454797863960266,
      "learning_rate": 1.2588489381274249e-05,
      "loss": 0.0707,
      "step": 112290
    },
    {
      "epoch": 2.245730512338519,
      "grad_norm": 0.14447051286697388,
      "learning_rate": 1.258515644789292e-05,
      "loss": 0.057,
      "step": 112300
    },
    {
      "epoch": 2.245930488341399,
      "grad_norm": 0.22112403810024261,
      "learning_rate": 1.2582156807849726e-05,
      "loss": 0.0857,
      "step": 112310
    },
    {
      "epoch": 2.2461304643442785,
      "grad_norm": 0.10592465102672577,
      "learning_rate": 1.2578823874468399e-05,
      "loss": 0.0502,
      "step": 112320
    },
    {
      "epoch": 2.2463304403471582,
      "grad_norm": 0.1494528204202652,
      "learning_rate": 1.257549094108707e-05,
      "loss": 0.0754,
      "step": 112330
    },
    {
      "epoch": 2.246530416350038,
      "grad_norm": 0.21391741931438446,
      "learning_rate": 1.2572158007705741e-05,
      "loss": 0.0967,
      "step": 112340
    },
    {
      "epoch": 2.2467303923529176,
      "grad_norm": 0.1041259914636612,
      "learning_rate": 1.2568825074324414e-05,
      "loss": 0.0575,
      "step": 112350
    },
    {
      "epoch": 2.2469303683557973,
      "grad_norm": 0.20063182711601257,
      "learning_rate": 1.2565492140943089e-05,
      "loss": 0.1043,
      "step": 112360
    },
    {
      "epoch": 2.247130344358677,
      "grad_norm": 0.16806460916996002,
      "learning_rate": 1.256215920756176e-05,
      "loss": 0.0615,
      "step": 112370
    },
    {
      "epoch": 2.2473303203615567,
      "grad_norm": 0.09952929615974426,
      "learning_rate": 1.2558826274180432e-05,
      "loss": 0.1027,
      "step": 112380
    },
    {
      "epoch": 2.2475302963644364,
      "grad_norm": 0.2229134440422058,
      "learning_rate": 1.2555493340799105e-05,
      "loss": 0.0434,
      "step": 112390
    },
    {
      "epoch": 2.247730272367316,
      "grad_norm": 0.203672856092453,
      "learning_rate": 1.2552160407417776e-05,
      "loss": 0.0832,
      "step": 112400
    },
    {
      "epoch": 2.2479302483701957,
      "grad_norm": 0.08938411623239517,
      "learning_rate": 1.254882747403645e-05,
      "loss": 0.0507,
      "step": 112410
    },
    {
      "epoch": 2.2481302243730754,
      "grad_norm": 0.2066650092601776,
      "learning_rate": 1.2545494540655122e-05,
      "loss": 0.11,
      "step": 112420
    },
    {
      "epoch": 2.248330200375955,
      "grad_norm": 0.15541835129261017,
      "learning_rate": 1.2542161607273795e-05,
      "loss": 0.0439,
      "step": 112430
    },
    {
      "epoch": 2.2485301763788343,
      "grad_norm": 0.19555875658988953,
      "learning_rate": 1.2538828673892466e-05,
      "loss": 0.0812,
      "step": 112440
    },
    {
      "epoch": 2.248730152381714,
      "grad_norm": 0.1754184067249298,
      "learning_rate": 1.2535495740511138e-05,
      "loss": 0.0669,
      "step": 112450
    },
    {
      "epoch": 2.2489301283845937,
      "grad_norm": 0.23012478649616241,
      "learning_rate": 1.2532162807129812e-05,
      "loss": 0.0801,
      "step": 112460
    },
    {
      "epoch": 2.2491301043874734,
      "grad_norm": 0.13877873122692108,
      "learning_rate": 1.2528829873748485e-05,
      "loss": 0.1418,
      "step": 112470
    },
    {
      "epoch": 2.249330080390353,
      "grad_norm": 0.23415353894233704,
      "learning_rate": 1.2525496940367157e-05,
      "loss": 0.1038,
      "step": 112480
    },
    {
      "epoch": 2.249530056393233,
      "grad_norm": 0.12007779628038406,
      "learning_rate": 1.2522164006985828e-05,
      "loss": 0.0663,
      "step": 112490
    },
    {
      "epoch": 2.2497300323961125,
      "grad_norm": 0.09963371604681015,
      "learning_rate": 1.2518831073604501e-05,
      "loss": 0.0588,
      "step": 112500
    },
    {
      "epoch": 2.249930008398992,
      "grad_norm": 0.21954412758350372,
      "learning_rate": 1.2515498140223172e-05,
      "loss": 0.0656,
      "step": 112510
    },
    {
      "epoch": 2.250129984401872,
      "grad_norm": 0.054271895438432693,
      "learning_rate": 1.2512165206841847e-05,
      "loss": 0.0873,
      "step": 112520
    },
    {
      "epoch": 2.2503299604047515,
      "grad_norm": 0.20120225846767426,
      "learning_rate": 1.2508832273460518e-05,
      "loss": 0.0593,
      "step": 112530
    },
    {
      "epoch": 2.250529936407631,
      "grad_norm": 0.14287060499191284,
      "learning_rate": 1.2505499340079191e-05,
      "loss": 0.1025,
      "step": 112540
    },
    {
      "epoch": 2.250729912410511,
      "grad_norm": 0.13141797482967377,
      "learning_rate": 1.2502166406697863e-05,
      "loss": 0.078,
      "step": 112550
    },
    {
      "epoch": 2.25092988841339,
      "grad_norm": 0.11331352591514587,
      "learning_rate": 1.2498833473316536e-05,
      "loss": 0.0623,
      "step": 112560
    },
    {
      "epoch": 2.25112986441627,
      "grad_norm": 0.13037893176078796,
      "learning_rate": 1.2495500539935209e-05,
      "loss": 0.0417,
      "step": 112570
    },
    {
      "epoch": 2.2513298404191495,
      "grad_norm": 0.08121321350336075,
      "learning_rate": 1.2492167606553882e-05,
      "loss": 0.271,
      "step": 112580
    },
    {
      "epoch": 2.251529816422029,
      "grad_norm": 0.047643378376960754,
      "learning_rate": 1.2488834673172553e-05,
      "loss": 0.1438,
      "step": 112590
    },
    {
      "epoch": 2.251729792424909,
      "grad_norm": 0.12547756731510162,
      "learning_rate": 1.2485501739791226e-05,
      "loss": 0.0448,
      "step": 112600
    },
    {
      "epoch": 2.2519297684277886,
      "grad_norm": 0.09830030798912048,
      "learning_rate": 1.2482168806409899e-05,
      "loss": 0.0671,
      "step": 112610
    },
    {
      "epoch": 2.2521297444306683,
      "grad_norm": 0.15749813616275787,
      "learning_rate": 1.247883587302857e-05,
      "loss": 0.0577,
      "step": 112620
    },
    {
      "epoch": 2.252329720433548,
      "grad_norm": 0.2600342631340027,
      "learning_rate": 1.2475502939647243e-05,
      "loss": 0.0623,
      "step": 112630
    },
    {
      "epoch": 2.2525296964364276,
      "grad_norm": 0.0833636149764061,
      "learning_rate": 1.2472170006265915e-05,
      "loss": 0.0686,
      "step": 112640
    },
    {
      "epoch": 2.2527296724393073,
      "grad_norm": 0.11657857149839401,
      "learning_rate": 1.2468837072884588e-05,
      "loss": 0.0452,
      "step": 112650
    },
    {
      "epoch": 2.252929648442187,
      "grad_norm": 0.08225709199905396,
      "learning_rate": 1.246550413950326e-05,
      "loss": 0.0674,
      "step": 112660
    },
    {
      "epoch": 2.2531296244450667,
      "grad_norm": 0.2037941962480545,
      "learning_rate": 1.2462171206121932e-05,
      "loss": 0.0756,
      "step": 112670
    },
    {
      "epoch": 2.2533296004479464,
      "grad_norm": 0.15694159269332886,
      "learning_rate": 1.2458838272740605e-05,
      "loss": 0.0714,
      "step": 112680
    },
    {
      "epoch": 2.253529576450826,
      "grad_norm": 0.23041394352912903,
      "learning_rate": 1.2455505339359278e-05,
      "loss": 0.448,
      "step": 112690
    },
    {
      "epoch": 2.2537295524537058,
      "grad_norm": 0.2525011897087097,
      "learning_rate": 1.245217240597795e-05,
      "loss": 0.1015,
      "step": 112700
    },
    {
      "epoch": 2.2539295284565855,
      "grad_norm": 0.06732337921857834,
      "learning_rate": 1.2448839472596622e-05,
      "loss": 0.0661,
      "step": 112710
    },
    {
      "epoch": 2.2541295044594647,
      "grad_norm": 0.25596174597740173,
      "learning_rate": 1.2445506539215295e-05,
      "loss": 0.0659,
      "step": 112720
    },
    {
      "epoch": 2.2543294804623444,
      "grad_norm": 0.18555137515068054,
      "learning_rate": 1.2442173605833968e-05,
      "loss": 0.1128,
      "step": 112730
    },
    {
      "epoch": 2.254529456465224,
      "grad_norm": 0.09189071506261826,
      "learning_rate": 1.243884067245264e-05,
      "loss": 0.0583,
      "step": 112740
    },
    {
      "epoch": 2.2547294324681038,
      "grad_norm": 0.12478319555521011,
      "learning_rate": 1.2435507739071311e-05,
      "loss": 0.0584,
      "step": 112750
    },
    {
      "epoch": 2.2549294084709834,
      "grad_norm": 0.05972592532634735,
      "learning_rate": 1.2432174805689986e-05,
      "loss": 0.0514,
      "step": 112760
    },
    {
      "epoch": 2.255129384473863,
      "grad_norm": 0.15816619992256165,
      "learning_rate": 1.2428841872308657e-05,
      "loss": 0.117,
      "step": 112770
    },
    {
      "epoch": 2.255329360476743,
      "grad_norm": 0.09547844529151917,
      "learning_rate": 1.242550893892733e-05,
      "loss": 0.0378,
      "step": 112780
    },
    {
      "epoch": 2.2555293364796225,
      "grad_norm": 0.09909746795892715,
      "learning_rate": 1.2422176005546001e-05,
      "loss": 0.0892,
      "step": 112790
    },
    {
      "epoch": 2.255729312482502,
      "grad_norm": 0.15957383811473846,
      "learning_rate": 1.2418843072164674e-05,
      "loss": 0.0551,
      "step": 112800
    },
    {
      "epoch": 2.255929288485382,
      "grad_norm": 0.2245800644159317,
      "learning_rate": 1.2415510138783347e-05,
      "loss": 0.0622,
      "step": 112810
    },
    {
      "epoch": 2.2561292644882616,
      "grad_norm": 0.159487783908844,
      "learning_rate": 1.2412177205402019e-05,
      "loss": 0.0686,
      "step": 112820
    },
    {
      "epoch": 2.2563292404911413,
      "grad_norm": 0.08992110937833786,
      "learning_rate": 1.2408844272020692e-05,
      "loss": 0.0901,
      "step": 112830
    },
    {
      "epoch": 2.2565292164940205,
      "grad_norm": 0.09004835784435272,
      "learning_rate": 1.2405511338639365e-05,
      "loss": 0.0514,
      "step": 112840
    },
    {
      "epoch": 2.2567291924969,
      "grad_norm": 0.22089649736881256,
      "learning_rate": 1.2402178405258036e-05,
      "loss": 0.0843,
      "step": 112850
    },
    {
      "epoch": 2.25692916849978,
      "grad_norm": 0.08306797593832016,
      "learning_rate": 1.2398845471876709e-05,
      "loss": 0.059,
      "step": 112860
    },
    {
      "epoch": 2.2571291445026596,
      "grad_norm": 0.08160319924354553,
      "learning_rate": 1.2395512538495382e-05,
      "loss": 0.057,
      "step": 112870
    },
    {
      "epoch": 2.2573291205055392,
      "grad_norm": 0.1145295724272728,
      "learning_rate": 1.2392179605114053e-05,
      "loss": 0.0601,
      "step": 112880
    },
    {
      "epoch": 2.257529096508419,
      "grad_norm": 0.13406524062156677,
      "learning_rate": 1.2388846671732726e-05,
      "loss": 0.0742,
      "step": 112890
    },
    {
      "epoch": 2.2577290725112986,
      "grad_norm": 0.16838404536247253,
      "learning_rate": 1.2385513738351397e-05,
      "loss": 0.0711,
      "step": 112900
    },
    {
      "epoch": 2.2579290485141783,
      "grad_norm": 0.08902429789304733,
      "learning_rate": 1.2382180804970072e-05,
      "loss": 0.0849,
      "step": 112910
    },
    {
      "epoch": 2.258129024517058,
      "grad_norm": 0.09429238736629486,
      "learning_rate": 1.2378847871588743e-05,
      "loss": 0.0942,
      "step": 112920
    },
    {
      "epoch": 2.2583290005199377,
      "grad_norm": 0.20427215099334717,
      "learning_rate": 1.2375514938207415e-05,
      "loss": 0.0965,
      "step": 112930
    },
    {
      "epoch": 2.2585289765228174,
      "grad_norm": 0.16995465755462646,
      "learning_rate": 1.2372182004826088e-05,
      "loss": 0.0826,
      "step": 112940
    },
    {
      "epoch": 2.258728952525697,
      "grad_norm": 0.061510976403951645,
      "learning_rate": 1.236884907144476e-05,
      "loss": 0.036,
      "step": 112950
    },
    {
      "epoch": 2.2589289285285767,
      "grad_norm": 0.1696549504995346,
      "learning_rate": 1.2365516138063434e-05,
      "loss": 0.059,
      "step": 112960
    },
    {
      "epoch": 2.2591289045314564,
      "grad_norm": 0.1595868319272995,
      "learning_rate": 1.2362183204682105e-05,
      "loss": 0.0691,
      "step": 112970
    },
    {
      "epoch": 2.259328880534336,
      "grad_norm": 0.21331122517585754,
      "learning_rate": 1.2358850271300778e-05,
      "loss": 0.0821,
      "step": 112980
    },
    {
      "epoch": 2.2595288565372154,
      "grad_norm": 0.23522770404815674,
      "learning_rate": 1.2355517337919451e-05,
      "loss": 0.0769,
      "step": 112990
    },
    {
      "epoch": 2.259728832540095,
      "grad_norm": 0.20843610167503357,
      "learning_rate": 1.2352184404538122e-05,
      "loss": 0.0706,
      "step": 113000
    },
    {
      "epoch": 2.2599288085429747,
      "grad_norm": 0.22388406097888947,
      "learning_rate": 1.2348851471156795e-05,
      "loss": 0.083,
      "step": 113010
    },
    {
      "epoch": 2.2601287845458544,
      "grad_norm": 0.09589862078428268,
      "learning_rate": 1.2345518537775468e-05,
      "loss": 0.0544,
      "step": 113020
    },
    {
      "epoch": 2.260328760548734,
      "grad_norm": 0.1233375295996666,
      "learning_rate": 1.234218560439414e-05,
      "loss": 0.0874,
      "step": 113030
    },
    {
      "epoch": 2.260528736551614,
      "grad_norm": 0.17876628041267395,
      "learning_rate": 1.2338852671012813e-05,
      "loss": 0.0653,
      "step": 113040
    },
    {
      "epoch": 2.2607287125544935,
      "grad_norm": 0.11941848695278168,
      "learning_rate": 1.2335519737631484e-05,
      "loss": 0.1067,
      "step": 113050
    },
    {
      "epoch": 2.260928688557373,
      "grad_norm": 0.08602281659841537,
      "learning_rate": 1.2332186804250157e-05,
      "loss": 0.0683,
      "step": 113060
    },
    {
      "epoch": 2.261128664560253,
      "grad_norm": 0.0900803878903389,
      "learning_rate": 1.232885387086883e-05,
      "loss": 0.0714,
      "step": 113070
    },
    {
      "epoch": 2.2613286405631325,
      "grad_norm": 0.2602464258670807,
      "learning_rate": 1.2325520937487501e-05,
      "loss": 0.0584,
      "step": 113080
    },
    {
      "epoch": 2.2615286165660122,
      "grad_norm": 0.12153102457523346,
      "learning_rate": 1.2322188004106174e-05,
      "loss": 0.0567,
      "step": 113090
    },
    {
      "epoch": 2.261728592568892,
      "grad_norm": 0.1005459576845169,
      "learning_rate": 1.2318855070724847e-05,
      "loss": 0.0739,
      "step": 113100
    },
    {
      "epoch": 2.261928568571771,
      "grad_norm": 0.13141773641109467,
      "learning_rate": 1.231552213734352e-05,
      "loss": 0.0861,
      "step": 113110
    },
    {
      "epoch": 2.262128544574651,
      "grad_norm": 0.26896199584007263,
      "learning_rate": 1.2312189203962192e-05,
      "loss": 0.0853,
      "step": 113120
    },
    {
      "epoch": 2.2623285205775305,
      "grad_norm": 0.15409883856773376,
      "learning_rate": 1.2308856270580863e-05,
      "loss": 0.044,
      "step": 113130
    },
    {
      "epoch": 2.26252849658041,
      "grad_norm": 0.13818997144699097,
      "learning_rate": 1.2305523337199538e-05,
      "loss": 0.0716,
      "step": 113140
    },
    {
      "epoch": 2.26272847258329,
      "grad_norm": 0.19826874136924744,
      "learning_rate": 1.2302190403818209e-05,
      "loss": 0.1121,
      "step": 113150
    },
    {
      "epoch": 2.2629284485861696,
      "grad_norm": 0.0975767970085144,
      "learning_rate": 1.229885747043688e-05,
      "loss": 0.0752,
      "step": 113160
    },
    {
      "epoch": 2.2631284245890493,
      "grad_norm": 0.12431738525629044,
      "learning_rate": 1.2295524537055553e-05,
      "loss": 0.0583,
      "step": 113170
    },
    {
      "epoch": 2.263328400591929,
      "grad_norm": 0.09902834892272949,
      "learning_rate": 1.2292191603674226e-05,
      "loss": 0.1168,
      "step": 113180
    },
    {
      "epoch": 2.2635283765948087,
      "grad_norm": 0.21034683287143707,
      "learning_rate": 1.22888586702929e-05,
      "loss": 0.0827,
      "step": 113190
    },
    {
      "epoch": 2.2637283525976883,
      "grad_norm": 0.09195663779973984,
      "learning_rate": 1.228552573691157e-05,
      "loss": 0.0784,
      "step": 113200
    },
    {
      "epoch": 2.263928328600568,
      "grad_norm": 0.15507574379444122,
      "learning_rate": 1.2282192803530244e-05,
      "loss": 0.0699,
      "step": 113210
    },
    {
      "epoch": 2.2641283046034477,
      "grad_norm": 0.09070185571908951,
      "learning_rate": 1.2278859870148917e-05,
      "loss": 0.0866,
      "step": 113220
    },
    {
      "epoch": 2.2643282806063274,
      "grad_norm": 0.15696075558662415,
      "learning_rate": 1.2275526936767588e-05,
      "loss": 0.0922,
      "step": 113230
    },
    {
      "epoch": 2.264528256609207,
      "grad_norm": 0.1695306897163391,
      "learning_rate": 1.2272194003386261e-05,
      "loss": 0.0715,
      "step": 113240
    },
    {
      "epoch": 2.2647282326120868,
      "grad_norm": 0.074347585439682,
      "learning_rate": 1.2268861070004934e-05,
      "loss": 0.2149,
      "step": 113250
    },
    {
      "epoch": 2.264928208614966,
      "grad_norm": 0.1878308653831482,
      "learning_rate": 1.2265528136623605e-05,
      "loss": 0.0904,
      "step": 113260
    },
    {
      "epoch": 2.2651281846178457,
      "grad_norm": 0.0832509994506836,
      "learning_rate": 1.2262195203242278e-05,
      "loss": 0.0421,
      "step": 113270
    },
    {
      "epoch": 2.2653281606207254,
      "grad_norm": 0.1406315118074417,
      "learning_rate": 1.225886226986095e-05,
      "loss": 0.0563,
      "step": 113280
    },
    {
      "epoch": 2.265528136623605,
      "grad_norm": 0.1693946123123169,
      "learning_rate": 1.2255529336479624e-05,
      "loss": 0.0642,
      "step": 113290
    },
    {
      "epoch": 2.2657281126264848,
      "grad_norm": 0.1007685735821724,
      "learning_rate": 1.2252196403098296e-05,
      "loss": 0.0715,
      "step": 113300
    },
    {
      "epoch": 2.2659280886293645,
      "grad_norm": 0.16087879240512848,
      "learning_rate": 1.2248863469716967e-05,
      "loss": 0.059,
      "step": 113310
    },
    {
      "epoch": 2.266128064632244,
      "grad_norm": 0.1661417931318283,
      "learning_rate": 1.224553053633564e-05,
      "loss": 0.0734,
      "step": 113320
    },
    {
      "epoch": 2.266328040635124,
      "grad_norm": 0.13596127927303314,
      "learning_rate": 1.2242197602954313e-05,
      "loss": 0.1071,
      "step": 113330
    },
    {
      "epoch": 2.2665280166380035,
      "grad_norm": 0.07061927020549774,
      "learning_rate": 1.2238864669572986e-05,
      "loss": 0.0439,
      "step": 113340
    },
    {
      "epoch": 2.266727992640883,
      "grad_norm": 0.08698047697544098,
      "learning_rate": 1.2235531736191657e-05,
      "loss": 0.063,
      "step": 113350
    },
    {
      "epoch": 2.266927968643763,
      "grad_norm": 0.07418771088123322,
      "learning_rate": 1.223219880281033e-05,
      "loss": 0.1074,
      "step": 113360
    },
    {
      "epoch": 2.2671279446466426,
      "grad_norm": 0.07505159825086594,
      "learning_rate": 1.2228865869429003e-05,
      "loss": 0.0324,
      "step": 113370
    },
    {
      "epoch": 2.267327920649522,
      "grad_norm": 0.2132340669631958,
      "learning_rate": 1.2225532936047675e-05,
      "loss": 0.0751,
      "step": 113380
    },
    {
      "epoch": 2.2675278966524015,
      "grad_norm": 0.1247553676366806,
      "learning_rate": 1.2222200002666346e-05,
      "loss": 0.046,
      "step": 113390
    },
    {
      "epoch": 2.267727872655281,
      "grad_norm": 0.17356914281845093,
      "learning_rate": 1.221886706928502e-05,
      "loss": 0.0775,
      "step": 113400
    },
    {
      "epoch": 2.267927848658161,
      "grad_norm": 0.07120882719755173,
      "learning_rate": 1.2215534135903692e-05,
      "loss": 0.0738,
      "step": 113410
    },
    {
      "epoch": 2.2681278246610406,
      "grad_norm": 0.058059122413396835,
      "learning_rate": 1.2212201202522365e-05,
      "loss": 0.0846,
      "step": 113420
    },
    {
      "epoch": 2.2683278006639203,
      "grad_norm": 0.12858469784259796,
      "learning_rate": 1.2208868269141036e-05,
      "loss": 0.0495,
      "step": 113430
    },
    {
      "epoch": 2.2685277766668,
      "grad_norm": 0.133127823472023,
      "learning_rate": 1.220553533575971e-05,
      "loss": 0.0839,
      "step": 113440
    },
    {
      "epoch": 2.2687277526696796,
      "grad_norm": 0.12658348679542542,
      "learning_rate": 1.2202202402378382e-05,
      "loss": 0.1723,
      "step": 113450
    },
    {
      "epoch": 2.2689277286725593,
      "grad_norm": 0.13750618696212769,
      "learning_rate": 1.2198869468997053e-05,
      "loss": 0.0589,
      "step": 113460
    },
    {
      "epoch": 2.269127704675439,
      "grad_norm": 0.08899781107902527,
      "learning_rate": 1.2195536535615726e-05,
      "loss": 0.0375,
      "step": 113470
    },
    {
      "epoch": 2.2693276806783187,
      "grad_norm": 0.1912941187620163,
      "learning_rate": 1.21922036022344e-05,
      "loss": 0.3713,
      "step": 113480
    },
    {
      "epoch": 2.2695276566811984,
      "grad_norm": 0.061074502766132355,
      "learning_rate": 1.218887066885307e-05,
      "loss": 0.0658,
      "step": 113490
    },
    {
      "epoch": 2.269727632684078,
      "grad_norm": 0.19477839767932892,
      "learning_rate": 1.2185537735471744e-05,
      "loss": 0.0734,
      "step": 113500
    },
    {
      "epoch": 2.2699276086869578,
      "grad_norm": 0.07784529030323029,
      "learning_rate": 1.2182204802090417e-05,
      "loss": 0.0633,
      "step": 113510
    },
    {
      "epoch": 2.2701275846898374,
      "grad_norm": 0.07084386050701141,
      "learning_rate": 1.217887186870909e-05,
      "loss": 0.069,
      "step": 113520
    },
    {
      "epoch": 2.2703275606927167,
      "grad_norm": 0.1134004220366478,
      "learning_rate": 1.2175538935327761e-05,
      "loss": 0.0615,
      "step": 113530
    },
    {
      "epoch": 2.2705275366955964,
      "grad_norm": 0.060639891773462296,
      "learning_rate": 1.2172206001946432e-05,
      "loss": 0.072,
      "step": 113540
    },
    {
      "epoch": 2.270727512698476,
      "grad_norm": 0.08863455057144165,
      "learning_rate": 1.2168873068565107e-05,
      "loss": 0.1076,
      "step": 113550
    },
    {
      "epoch": 2.2709274887013557,
      "grad_norm": 0.17939575016498566,
      "learning_rate": 1.2165540135183778e-05,
      "loss": 0.0874,
      "step": 113560
    },
    {
      "epoch": 2.2711274647042354,
      "grad_norm": 0.15352454781532288,
      "learning_rate": 1.2162207201802451e-05,
      "loss": 0.0565,
      "step": 113570
    },
    {
      "epoch": 2.271327440707115,
      "grad_norm": 0.16624392569065094,
      "learning_rate": 1.2158874268421123e-05,
      "loss": 0.0659,
      "step": 113580
    },
    {
      "epoch": 2.271527416709995,
      "grad_norm": 0.07741938531398773,
      "learning_rate": 1.2155541335039796e-05,
      "loss": 0.0802,
      "step": 113590
    },
    {
      "epoch": 2.2717273927128745,
      "grad_norm": 0.12426535040140152,
      "learning_rate": 1.2152208401658469e-05,
      "loss": 0.0594,
      "step": 113600
    },
    {
      "epoch": 2.271927368715754,
      "grad_norm": 0.2843717038631439,
      "learning_rate": 1.214887546827714e-05,
      "loss": 0.0617,
      "step": 113610
    },
    {
      "epoch": 2.272127344718634,
      "grad_norm": 0.09674309939146042,
      "learning_rate": 1.2145542534895813e-05,
      "loss": 0.0639,
      "step": 113620
    },
    {
      "epoch": 2.2723273207215136,
      "grad_norm": 0.10573840886354446,
      "learning_rate": 1.2142209601514486e-05,
      "loss": 0.152,
      "step": 113630
    },
    {
      "epoch": 2.2725272967243932,
      "grad_norm": 0.12149381637573242,
      "learning_rate": 1.2138876668133157e-05,
      "loss": 0.0574,
      "step": 113640
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.06411729753017426,
      "learning_rate": 1.213554373475183e-05,
      "loss": 0.0788,
      "step": 113650
    },
    {
      "epoch": 2.272927248730152,
      "grad_norm": 0.15047776699066162,
      "learning_rate": 1.2132210801370503e-05,
      "loss": 0.0493,
      "step": 113660
    },
    {
      "epoch": 2.273127224733032,
      "grad_norm": 0.3181662857532501,
      "learning_rate": 1.2128877867989175e-05,
      "loss": 0.0838,
      "step": 113670
    },
    {
      "epoch": 2.2733272007359115,
      "grad_norm": 0.14072978496551514,
      "learning_rate": 1.2125544934607848e-05,
      "loss": 0.0439,
      "step": 113680
    },
    {
      "epoch": 2.2735271767387912,
      "grad_norm": 0.11856439709663391,
      "learning_rate": 1.2122212001226519e-05,
      "loss": 0.061,
      "step": 113690
    },
    {
      "epoch": 2.273727152741671,
      "grad_norm": 0.10906631499528885,
      "learning_rate": 1.2118879067845194e-05,
      "loss": 0.0932,
      "step": 113700
    },
    {
      "epoch": 2.2739271287445506,
      "grad_norm": 0.19279015064239502,
      "learning_rate": 1.2115546134463865e-05,
      "loss": 0.0546,
      "step": 113710
    },
    {
      "epoch": 2.2741271047474303,
      "grad_norm": 0.20095671713352203,
      "learning_rate": 1.2112213201082536e-05,
      "loss": 0.1022,
      "step": 113720
    },
    {
      "epoch": 2.27432708075031,
      "grad_norm": 0.19653448462486267,
      "learning_rate": 1.210888026770121e-05,
      "loss": 0.1097,
      "step": 113730
    },
    {
      "epoch": 2.2745270567531897,
      "grad_norm": 0.07395613938570023,
      "learning_rate": 1.2105547334319882e-05,
      "loss": 0.0798,
      "step": 113740
    },
    {
      "epoch": 2.2747270327560694,
      "grad_norm": 0.11281654238700867,
      "learning_rate": 1.2102214400938555e-05,
      "loss": 0.1088,
      "step": 113750
    },
    {
      "epoch": 2.274927008758949,
      "grad_norm": 0.12906210124492645,
      "learning_rate": 1.2098881467557227e-05,
      "loss": 0.0757,
      "step": 113760
    },
    {
      "epoch": 2.2751269847618287,
      "grad_norm": 0.15405608713626862,
      "learning_rate": 1.20955485341759e-05,
      "loss": 0.0605,
      "step": 113770
    },
    {
      "epoch": 2.2753269607647084,
      "grad_norm": 0.13202925026416779,
      "learning_rate": 1.2092215600794573e-05,
      "loss": 0.0832,
      "step": 113780
    },
    {
      "epoch": 2.275526936767588,
      "grad_norm": 0.14563138782978058,
      "learning_rate": 1.2088882667413244e-05,
      "loss": 0.0799,
      "step": 113790
    },
    {
      "epoch": 2.275726912770468,
      "grad_norm": 0.18151366710662842,
      "learning_rate": 1.2085549734031917e-05,
      "loss": 0.0535,
      "step": 113800
    },
    {
      "epoch": 2.275926888773347,
      "grad_norm": 0.0967223271727562,
      "learning_rate": 1.208221680065059e-05,
      "loss": 0.0747,
      "step": 113810
    },
    {
      "epoch": 2.2761268647762267,
      "grad_norm": 0.18303117156028748,
      "learning_rate": 1.2078883867269261e-05,
      "loss": 0.0585,
      "step": 113820
    },
    {
      "epoch": 2.2763268407791064,
      "grad_norm": 0.0982070341706276,
      "learning_rate": 1.2075550933887934e-05,
      "loss": 0.0531,
      "step": 113830
    },
    {
      "epoch": 2.276526816781986,
      "grad_norm": 0.1533864140510559,
      "learning_rate": 1.2072218000506606e-05,
      "loss": 0.069,
      "step": 113840
    },
    {
      "epoch": 2.276726792784866,
      "grad_norm": 0.18075761198997498,
      "learning_rate": 1.206888506712528e-05,
      "loss": 0.0504,
      "step": 113850
    },
    {
      "epoch": 2.2769267687877455,
      "grad_norm": 0.2619622051715851,
      "learning_rate": 1.2065552133743952e-05,
      "loss": 0.1159,
      "step": 113860
    },
    {
      "epoch": 2.277126744790625,
      "grad_norm": 0.20234894752502441,
      "learning_rate": 1.2062219200362623e-05,
      "loss": 0.0696,
      "step": 113870
    },
    {
      "epoch": 2.277326720793505,
      "grad_norm": 0.1996302306652069,
      "learning_rate": 1.2058886266981296e-05,
      "loss": 0.0989,
      "step": 113880
    },
    {
      "epoch": 2.2775266967963845,
      "grad_norm": 0.16227339208126068,
      "learning_rate": 1.2055553333599969e-05,
      "loss": 0.0658,
      "step": 113890
    },
    {
      "epoch": 2.277726672799264,
      "grad_norm": 0.20127715170383453,
      "learning_rate": 1.205222040021864e-05,
      "loss": 0.0733,
      "step": 113900
    },
    {
      "epoch": 2.277926648802144,
      "grad_norm": 0.09998225420713425,
      "learning_rate": 1.2048887466837313e-05,
      "loss": 0.0529,
      "step": 113910
    },
    {
      "epoch": 2.278126624805023,
      "grad_norm": 0.16405892372131348,
      "learning_rate": 1.2045554533455986e-05,
      "loss": 0.0621,
      "step": 113920
    },
    {
      "epoch": 2.278326600807903,
      "grad_norm": 0.12815497815608978,
      "learning_rate": 1.204222160007466e-05,
      "loss": 0.0637,
      "step": 113930
    },
    {
      "epoch": 2.2785265768107825,
      "grad_norm": 0.17898662388324738,
      "learning_rate": 1.203888866669333e-05,
      "loss": 0.0722,
      "step": 113940
    },
    {
      "epoch": 2.278726552813662,
      "grad_norm": 0.20240633189678192,
      "learning_rate": 1.2035555733312002e-05,
      "loss": 0.2336,
      "step": 113950
    },
    {
      "epoch": 2.278926528816542,
      "grad_norm": 0.15727810561656952,
      "learning_rate": 1.2032556093268809e-05,
      "loss": 0.0508,
      "step": 113960
    },
    {
      "epoch": 2.2791265048194216,
      "grad_norm": 0.04277527704834938,
      "learning_rate": 1.202922315988748e-05,
      "loss": 0.0681,
      "step": 113970
    },
    {
      "epoch": 2.2793264808223013,
      "grad_norm": 0.15189099311828613,
      "learning_rate": 1.2025890226506153e-05,
      "loss": 0.1045,
      "step": 113980
    },
    {
      "epoch": 2.279526456825181,
      "grad_norm": 0.211013525724411,
      "learning_rate": 1.2022557293124825e-05,
      "loss": 0.0691,
      "step": 113990
    },
    {
      "epoch": 2.2797264328280606,
      "grad_norm": 0.0801500678062439,
      "learning_rate": 1.20192243597435e-05,
      "loss": 0.079,
      "step": 114000
    },
    {
      "epoch": 2.2799264088309403,
      "grad_norm": 0.06869582831859589,
      "learning_rate": 1.201589142636217e-05,
      "loss": 0.0826,
      "step": 114010
    },
    {
      "epoch": 2.28012638483382,
      "grad_norm": 0.06220335513353348,
      "learning_rate": 1.2012558492980842e-05,
      "loss": 0.0832,
      "step": 114020
    },
    {
      "epoch": 2.2803263608366997,
      "grad_norm": 0.0909959152340889,
      "learning_rate": 1.2009225559599515e-05,
      "loss": 0.0711,
      "step": 114030
    },
    {
      "epoch": 2.2805263368395794,
      "grad_norm": 0.19471698999404907,
      "learning_rate": 1.2005892626218188e-05,
      "loss": 0.0949,
      "step": 114040
    },
    {
      "epoch": 2.280726312842459,
      "grad_norm": 0.17307820916175842,
      "learning_rate": 1.2002559692836861e-05,
      "loss": 0.0887,
      "step": 114050
    },
    {
      "epoch": 2.2809262888453388,
      "grad_norm": 0.1501656472682953,
      "learning_rate": 1.1999226759455532e-05,
      "loss": 0.0516,
      "step": 114060
    },
    {
      "epoch": 2.2811262648482185,
      "grad_norm": 0.2641550898551941,
      "learning_rate": 1.1995893826074205e-05,
      "loss": 0.0762,
      "step": 114070
    },
    {
      "epoch": 2.2813262408510977,
      "grad_norm": 0.2660956382751465,
      "learning_rate": 1.1992560892692878e-05,
      "loss": 0.127,
      "step": 114080
    },
    {
      "epoch": 2.2815262168539774,
      "grad_norm": 0.08359748870134354,
      "learning_rate": 1.198922795931155e-05,
      "loss": 0.0413,
      "step": 114090
    },
    {
      "epoch": 2.281726192856857,
      "grad_norm": 0.2111676186323166,
      "learning_rate": 1.198589502593022e-05,
      "loss": 0.0785,
      "step": 114100
    },
    {
      "epoch": 2.2819261688597368,
      "grad_norm": 0.1227993592619896,
      "learning_rate": 1.1982562092548896e-05,
      "loss": 0.0779,
      "step": 114110
    },
    {
      "epoch": 2.2821261448626164,
      "grad_norm": 0.17379029095172882,
      "learning_rate": 1.1979229159167567e-05,
      "loss": 0.0769,
      "step": 114120
    },
    {
      "epoch": 2.282326120865496,
      "grad_norm": 0.0912187397480011,
      "learning_rate": 1.197589622578624e-05,
      "loss": 0.0337,
      "step": 114130
    },
    {
      "epoch": 2.282526096868376,
      "grad_norm": 0.19878755509853363,
      "learning_rate": 1.1972563292404911e-05,
      "loss": 0.0728,
      "step": 114140
    },
    {
      "epoch": 2.2827260728712555,
      "grad_norm": 0.08185090124607086,
      "learning_rate": 1.1969230359023584e-05,
      "loss": 0.0673,
      "step": 114150
    },
    {
      "epoch": 2.282926048874135,
      "grad_norm": 0.12041658908128738,
      "learning_rate": 1.1965897425642257e-05,
      "loss": 0.1198,
      "step": 114160
    },
    {
      "epoch": 2.283126024877015,
      "grad_norm": 0.12203054130077362,
      "learning_rate": 1.1962564492260928e-05,
      "loss": 0.128,
      "step": 114170
    },
    {
      "epoch": 2.2833260008798946,
      "grad_norm": 0.14222835004329681,
      "learning_rate": 1.1959231558879601e-05,
      "loss": 0.0804,
      "step": 114180
    },
    {
      "epoch": 2.2835259768827743,
      "grad_norm": 0.13198283314704895,
      "learning_rate": 1.1955898625498274e-05,
      "loss": 0.0787,
      "step": 114190
    },
    {
      "epoch": 2.2837259528856535,
      "grad_norm": 0.0915723368525505,
      "learning_rate": 1.1952565692116946e-05,
      "loss": 0.042,
      "step": 114200
    },
    {
      "epoch": 2.283925928888533,
      "grad_norm": 0.1086663156747818,
      "learning_rate": 1.1949232758735619e-05,
      "loss": 0.0809,
      "step": 114210
    },
    {
      "epoch": 2.284125904891413,
      "grad_norm": 0.14491215348243713,
      "learning_rate": 1.1945899825354292e-05,
      "loss": 0.0919,
      "step": 114220
    },
    {
      "epoch": 2.2843258808942926,
      "grad_norm": 0.12590627372264862,
      "learning_rate": 1.1942566891972965e-05,
      "loss": 0.0558,
      "step": 114230
    },
    {
      "epoch": 2.2845258568971722,
      "grad_norm": 0.18671734631061554,
      "learning_rate": 1.1939233958591636e-05,
      "loss": 0.0985,
      "step": 114240
    },
    {
      "epoch": 2.284725832900052,
      "grad_norm": 0.11645352095365524,
      "learning_rate": 1.1935901025210307e-05,
      "loss": 0.0451,
      "step": 114250
    },
    {
      "epoch": 2.2849258089029316,
      "grad_norm": 0.11936759948730469,
      "learning_rate": 1.1932568091828982e-05,
      "loss": 0.0704,
      "step": 114260
    },
    {
      "epoch": 2.2851257849058113,
      "grad_norm": 0.11260831356048584,
      "learning_rate": 1.1929235158447653e-05,
      "loss": 0.0514,
      "step": 114270
    },
    {
      "epoch": 2.285325760908691,
      "grad_norm": 0.21858744323253632,
      "learning_rate": 1.1925902225066326e-05,
      "loss": 0.0633,
      "step": 114280
    },
    {
      "epoch": 2.2855257369115707,
      "grad_norm": 0.1447814255952835,
      "learning_rate": 1.1922569291684998e-05,
      "loss": 0.0774,
      "step": 114290
    },
    {
      "epoch": 2.2857257129144504,
      "grad_norm": 0.09814447164535522,
      "learning_rate": 1.191923635830367e-05,
      "loss": 0.1134,
      "step": 114300
    },
    {
      "epoch": 2.28592568891733,
      "grad_norm": 0.10940033197402954,
      "learning_rate": 1.1915903424922344e-05,
      "loss": 0.0534,
      "step": 114310
    },
    {
      "epoch": 2.2861256649202097,
      "grad_norm": 0.2095562368631363,
      "learning_rate": 1.1912570491541015e-05,
      "loss": 0.0733,
      "step": 114320
    },
    {
      "epoch": 2.2863256409230894,
      "grad_norm": 0.13011133670806885,
      "learning_rate": 1.1909237558159688e-05,
      "loss": 0.072,
      "step": 114330
    },
    {
      "epoch": 2.286525616925969,
      "grad_norm": 0.10883018374443054,
      "learning_rate": 1.1905904624778361e-05,
      "loss": 0.106,
      "step": 114340
    },
    {
      "epoch": 2.2867255929288484,
      "grad_norm": 0.07285428792238235,
      "learning_rate": 1.1902571691397032e-05,
      "loss": 0.038,
      "step": 114350
    },
    {
      "epoch": 2.286925568931728,
      "grad_norm": 0.06911155581474304,
      "learning_rate": 1.1899238758015705e-05,
      "loss": 0.1019,
      "step": 114360
    },
    {
      "epoch": 2.2871255449346077,
      "grad_norm": 0.13637767732143402,
      "learning_rate": 1.1895905824634378e-05,
      "loss": 0.0744,
      "step": 114370
    },
    {
      "epoch": 2.2873255209374874,
      "grad_norm": 0.1509721279144287,
      "learning_rate": 1.189257289125305e-05,
      "loss": 0.078,
      "step": 114380
    },
    {
      "epoch": 2.287525496940367,
      "grad_norm": 0.07793684303760529,
      "learning_rate": 1.1889239957871723e-05,
      "loss": 0.038,
      "step": 114390
    },
    {
      "epoch": 2.287725472943247,
      "grad_norm": 0.24685809016227722,
      "learning_rate": 1.1885907024490394e-05,
      "loss": 0.1098,
      "step": 114400
    },
    {
      "epoch": 2.2879254489461265,
      "grad_norm": 0.25196322798728943,
      "learning_rate": 1.1882574091109069e-05,
      "loss": 0.0861,
      "step": 114410
    },
    {
      "epoch": 2.288125424949006,
      "grad_norm": 0.07331622391939163,
      "learning_rate": 1.187924115772774e-05,
      "loss": 0.0803,
      "step": 114420
    },
    {
      "epoch": 2.288325400951886,
      "grad_norm": 0.1981322467327118,
      "learning_rate": 1.1875908224346411e-05,
      "loss": 0.0607,
      "step": 114430
    },
    {
      "epoch": 2.2885253769547655,
      "grad_norm": 0.08452843874692917,
      "learning_rate": 1.1872575290965084e-05,
      "loss": 0.0697,
      "step": 114440
    },
    {
      "epoch": 2.2887253529576452,
      "grad_norm": 0.10279680043458939,
      "learning_rate": 1.1869242357583757e-05,
      "loss": 0.0774,
      "step": 114450
    },
    {
      "epoch": 2.288925328960525,
      "grad_norm": 0.20371177792549133,
      "learning_rate": 1.186590942420243e-05,
      "loss": 0.0686,
      "step": 114460
    },
    {
      "epoch": 2.289125304963404,
      "grad_norm": 0.16051582992076874,
      "learning_rate": 1.1862576490821102e-05,
      "loss": 0.0591,
      "step": 114470
    },
    {
      "epoch": 2.289325280966284,
      "grad_norm": 0.12163278460502625,
      "learning_rate": 1.1859243557439775e-05,
      "loss": 0.057,
      "step": 114480
    },
    {
      "epoch": 2.2895252569691635,
      "grad_norm": 0.15081731975078583,
      "learning_rate": 1.1855910624058448e-05,
      "loss": 0.0648,
      "step": 114490
    },
    {
      "epoch": 2.2897252329720432,
      "grad_norm": 0.09039672464132309,
      "learning_rate": 1.1852577690677119e-05,
      "loss": 0.0374,
      "step": 114500
    },
    {
      "epoch": 2.289925208974923,
      "grad_norm": 0.18144384026527405,
      "learning_rate": 1.1849244757295792e-05,
      "loss": 0.0586,
      "step": 114510
    },
    {
      "epoch": 2.2901251849778026,
      "grad_norm": 0.18853013217449188,
      "learning_rate": 1.1845911823914465e-05,
      "loss": 0.0827,
      "step": 114520
    },
    {
      "epoch": 2.2903251609806823,
      "grad_norm": 0.16525357961654663,
      "learning_rate": 1.1842578890533136e-05,
      "loss": 0.0731,
      "step": 114530
    },
    {
      "epoch": 2.290525136983562,
      "grad_norm": 0.08875688165426254,
      "learning_rate": 1.183924595715181e-05,
      "loss": 0.0874,
      "step": 114540
    },
    {
      "epoch": 2.2907251129864417,
      "grad_norm": 0.078037790954113,
      "learning_rate": 1.183591302377048e-05,
      "loss": 0.0401,
      "step": 114550
    },
    {
      "epoch": 2.2909250889893213,
      "grad_norm": 0.17007292807102203,
      "learning_rate": 1.1832580090389155e-05,
      "loss": 0.0615,
      "step": 114560
    },
    {
      "epoch": 2.291125064992201,
      "grad_norm": 0.07122579962015152,
      "learning_rate": 1.1829247157007827e-05,
      "loss": 0.0775,
      "step": 114570
    },
    {
      "epoch": 2.2913250409950807,
      "grad_norm": 0.18961332738399506,
      "learning_rate": 1.1825914223626498e-05,
      "loss": 0.0856,
      "step": 114580
    },
    {
      "epoch": 2.2915250169979604,
      "grad_norm": 0.19832046329975128,
      "learning_rate": 1.1822581290245171e-05,
      "loss": 0.0746,
      "step": 114590
    },
    {
      "epoch": 2.29172499300084,
      "grad_norm": 0.08139195293188095,
      "learning_rate": 1.1819248356863844e-05,
      "loss": 0.0368,
      "step": 114600
    },
    {
      "epoch": 2.29192496900372,
      "grad_norm": 0.07943977415561676,
      "learning_rate": 1.1815915423482515e-05,
      "loss": 0.0699,
      "step": 114610
    },
    {
      "epoch": 2.292124945006599,
      "grad_norm": 0.08839839696884155,
      "learning_rate": 1.1812582490101188e-05,
      "loss": 0.074,
      "step": 114620
    },
    {
      "epoch": 2.2923249210094787,
      "grad_norm": 0.1416458636522293,
      "learning_rate": 1.1809249556719861e-05,
      "loss": 0.085,
      "step": 114630
    },
    {
      "epoch": 2.2925248970123584,
      "grad_norm": 0.08647167682647705,
      "learning_rate": 1.1805916623338534e-05,
      "loss": 0.0625,
      "step": 114640
    },
    {
      "epoch": 2.292724873015238,
      "grad_norm": 0.12725532054901123,
      "learning_rate": 1.1802583689957206e-05,
      "loss": 0.0764,
      "step": 114650
    },
    {
      "epoch": 2.2929248490181178,
      "grad_norm": 0.15966293215751648,
      "learning_rate": 1.1799250756575877e-05,
      "loss": 0.0775,
      "step": 114660
    },
    {
      "epoch": 2.2931248250209975,
      "grad_norm": 0.1449369639158249,
      "learning_rate": 1.1795917823194552e-05,
      "loss": 0.0608,
      "step": 114670
    },
    {
      "epoch": 2.293324801023877,
      "grad_norm": 0.1290515661239624,
      "learning_rate": 1.1792584889813223e-05,
      "loss": 0.0542,
      "step": 114680
    },
    {
      "epoch": 2.293524777026757,
      "grad_norm": 0.14878645539283752,
      "learning_rate": 1.1789251956431896e-05,
      "loss": 0.0615,
      "step": 114690
    },
    {
      "epoch": 2.2937247530296365,
      "grad_norm": 0.13047845661640167,
      "learning_rate": 1.1785919023050567e-05,
      "loss": 0.0684,
      "step": 114700
    },
    {
      "epoch": 2.293924729032516,
      "grad_norm": 0.07631993293762207,
      "learning_rate": 1.178258608966924e-05,
      "loss": 0.0522,
      "step": 114710
    },
    {
      "epoch": 2.294124705035396,
      "grad_norm": 0.18966634571552277,
      "learning_rate": 1.1779253156287913e-05,
      "loss": 0.0513,
      "step": 114720
    },
    {
      "epoch": 2.2943246810382756,
      "grad_norm": 0.18935047090053558,
      "learning_rate": 1.1775920222906585e-05,
      "loss": 0.0727,
      "step": 114730
    },
    {
      "epoch": 2.294524657041155,
      "grad_norm": 0.10355549305677414,
      "learning_rate": 1.1772587289525258e-05,
      "loss": 0.0564,
      "step": 114740
    },
    {
      "epoch": 2.2947246330440345,
      "grad_norm": 0.08676312863826752,
      "learning_rate": 1.176925435614393e-05,
      "loss": 0.0788,
      "step": 114750
    },
    {
      "epoch": 2.294924609046914,
      "grad_norm": 0.10687803477048874,
      "learning_rate": 1.1765921422762602e-05,
      "loss": 0.061,
      "step": 114760
    },
    {
      "epoch": 2.295124585049794,
      "grad_norm": 0.16266143321990967,
      "learning_rate": 1.1762588489381275e-05,
      "loss": 0.0639,
      "step": 114770
    },
    {
      "epoch": 2.2953245610526736,
      "grad_norm": 0.06273400783538818,
      "learning_rate": 1.1759255555999948e-05,
      "loss": 0.0466,
      "step": 114780
    },
    {
      "epoch": 2.2955245370555533,
      "grad_norm": 0.11688904464244843,
      "learning_rate": 1.1755922622618621e-05,
      "loss": 0.0653,
      "step": 114790
    },
    {
      "epoch": 2.295724513058433,
      "grad_norm": 0.07279876619577408,
      "learning_rate": 1.1752589689237292e-05,
      "loss": 0.0539,
      "step": 114800
    },
    {
      "epoch": 2.2959244890613126,
      "grad_norm": 0.2701761722564697,
      "learning_rate": 1.1749256755855963e-05,
      "loss": 0.0917,
      "step": 114810
    },
    {
      "epoch": 2.2961244650641923,
      "grad_norm": 0.09805691242218018,
      "learning_rate": 1.1745923822474638e-05,
      "loss": 0.0665,
      "step": 114820
    },
    {
      "epoch": 2.296324441067072,
      "grad_norm": 0.07218848913908005,
      "learning_rate": 1.174259088909331e-05,
      "loss": 0.0688,
      "step": 114830
    },
    {
      "epoch": 2.2965244170699517,
      "grad_norm": 0.2164497822523117,
      "learning_rate": 1.173925795571198e-05,
      "loss": 0.0673,
      "step": 114840
    },
    {
      "epoch": 2.2967243930728314,
      "grad_norm": 0.22993890941143036,
      "learning_rate": 1.1735925022330654e-05,
      "loss": 0.0606,
      "step": 114850
    },
    {
      "epoch": 2.296924369075711,
      "grad_norm": 0.09614790230989456,
      "learning_rate": 1.1732592088949327e-05,
      "loss": 0.1692,
      "step": 114860
    },
    {
      "epoch": 2.2971243450785908,
      "grad_norm": 0.12684686481952667,
      "learning_rate": 1.1729259155568e-05,
      "loss": 0.03,
      "step": 114870
    },
    {
      "epoch": 2.2973243210814704,
      "grad_norm": 0.20112742483615875,
      "learning_rate": 1.1725926222186671e-05,
      "loss": 0.0619,
      "step": 114880
    },
    {
      "epoch": 2.2975242970843497,
      "grad_norm": 0.20163725316524506,
      "learning_rate": 1.1722593288805344e-05,
      "loss": 0.0505,
      "step": 114890
    },
    {
      "epoch": 2.2977242730872294,
      "grad_norm": 0.1769767850637436,
      "learning_rate": 1.1719260355424017e-05,
      "loss": 0.0629,
      "step": 114900
    },
    {
      "epoch": 2.297924249090109,
      "grad_norm": 0.09938937425613403,
      "learning_rate": 1.1715927422042688e-05,
      "loss": 0.0623,
      "step": 114910
    },
    {
      "epoch": 2.2981242250929887,
      "grad_norm": 0.17500703036785126,
      "learning_rate": 1.1712594488661361e-05,
      "loss": 0.0697,
      "step": 114920
    },
    {
      "epoch": 2.2983242010958684,
      "grad_norm": 0.11055118590593338,
      "learning_rate": 1.1709261555280034e-05,
      "loss": 0.0878,
      "step": 114930
    },
    {
      "epoch": 2.298524177098748,
      "grad_norm": 0.09261738508939743,
      "learning_rate": 1.1705928621898706e-05,
      "loss": 0.0855,
      "step": 114940
    },
    {
      "epoch": 2.298724153101628,
      "grad_norm": 0.1782209277153015,
      "learning_rate": 1.1702595688517379e-05,
      "loss": 0.0651,
      "step": 114950
    },
    {
      "epoch": 2.2989241291045075,
      "grad_norm": 0.12778514623641968,
      "learning_rate": 1.169926275513605e-05,
      "loss": 0.038,
      "step": 114960
    },
    {
      "epoch": 2.299124105107387,
      "grad_norm": 0.2294626384973526,
      "learning_rate": 1.1695929821754723e-05,
      "loss": 0.0784,
      "step": 114970
    },
    {
      "epoch": 2.299324081110267,
      "grad_norm": 0.2576838731765747,
      "learning_rate": 1.1692596888373396e-05,
      "loss": 0.0927,
      "step": 114980
    },
    {
      "epoch": 2.2995240571131466,
      "grad_norm": 0.0954522117972374,
      "learning_rate": 1.1689263954992067e-05,
      "loss": 0.0845,
      "step": 114990
    },
    {
      "epoch": 2.2997240331160262,
      "grad_norm": 0.12402331829071045,
      "learning_rate": 1.168593102161074e-05,
      "loss": 0.0886,
      "step": 115000
    },
    {
      "epoch": 2.2999240091189055,
      "grad_norm": 0.1683586686849594,
      "learning_rate": 1.1682598088229413e-05,
      "loss": 0.0815,
      "step": 115010
    },
    {
      "epoch": 2.300123985121785,
      "grad_norm": 0.11756305396556854,
      "learning_rate": 1.1679265154848086e-05,
      "loss": 0.0805,
      "step": 115020
    },
    {
      "epoch": 2.300323961124665,
      "grad_norm": 0.1278032660484314,
      "learning_rate": 1.1675932221466758e-05,
      "loss": 0.0765,
      "step": 115030
    },
    {
      "epoch": 2.3005239371275445,
      "grad_norm": 0.15668407082557678,
      "learning_rate": 1.1672599288085429e-05,
      "loss": 0.0825,
      "step": 115040
    },
    {
      "epoch": 2.3007239131304242,
      "grad_norm": 0.13639187812805176,
      "learning_rate": 1.1669266354704104e-05,
      "loss": 0.0751,
      "step": 115050
    },
    {
      "epoch": 2.300923889133304,
      "grad_norm": 0.12270718067884445,
      "learning_rate": 1.1665933421322775e-05,
      "loss": 0.0977,
      "step": 115060
    },
    {
      "epoch": 2.3011238651361836,
      "grad_norm": 0.11028783768415451,
      "learning_rate": 1.1662600487941448e-05,
      "loss": 0.0407,
      "step": 115070
    },
    {
      "epoch": 2.3013238411390633,
      "grad_norm": 0.12183008342981339,
      "learning_rate": 1.165926755456012e-05,
      "loss": 0.0494,
      "step": 115080
    },
    {
      "epoch": 2.301523817141943,
      "grad_norm": 0.20056287944316864,
      "learning_rate": 1.1655934621178792e-05,
      "loss": 0.0512,
      "step": 115090
    },
    {
      "epoch": 2.3017237931448227,
      "grad_norm": 0.23862478137016296,
      "learning_rate": 1.1652601687797465e-05,
      "loss": 0.0731,
      "step": 115100
    },
    {
      "epoch": 2.3019237691477024,
      "grad_norm": 0.12234879285097122,
      "learning_rate": 1.1649268754416137e-05,
      "loss": 0.0807,
      "step": 115110
    },
    {
      "epoch": 2.302123745150582,
      "grad_norm": 0.1338588297367096,
      "learning_rate": 1.164593582103481e-05,
      "loss": 0.0665,
      "step": 115120
    },
    {
      "epoch": 2.3023237211534617,
      "grad_norm": 0.09343908727169037,
      "learning_rate": 1.1642602887653483e-05,
      "loss": 0.0507,
      "step": 115130
    },
    {
      "epoch": 2.3025236971563414,
      "grad_norm": 0.0894978791475296,
      "learning_rate": 1.1639269954272154e-05,
      "loss": 0.0593,
      "step": 115140
    },
    {
      "epoch": 2.302723673159221,
      "grad_norm": 0.11192008852958679,
      "learning_rate": 1.1635937020890827e-05,
      "loss": 0.0951,
      "step": 115150
    },
    {
      "epoch": 2.302923649162101,
      "grad_norm": 0.1487269103527069,
      "learning_rate": 1.16326040875095e-05,
      "loss": 0.0447,
      "step": 115160
    },
    {
      "epoch": 2.30312362516498,
      "grad_norm": 0.11955495178699493,
      "learning_rate": 1.1629271154128171e-05,
      "loss": 0.0759,
      "step": 115170
    },
    {
      "epoch": 2.3033236011678597,
      "grad_norm": 0.1433594673871994,
      "learning_rate": 1.1625938220746844e-05,
      "loss": 0.0591,
      "step": 115180
    },
    {
      "epoch": 2.3035235771707394,
      "grad_norm": 0.19077830016613007,
      "learning_rate": 1.1622605287365516e-05,
      "loss": 0.0806,
      "step": 115190
    },
    {
      "epoch": 2.303723553173619,
      "grad_norm": 0.17169882357120514,
      "learning_rate": 1.161927235398419e-05,
      "loss": 0.0619,
      "step": 115200
    },
    {
      "epoch": 2.303923529176499,
      "grad_norm": 0.18714815378189087,
      "learning_rate": 1.1615939420602862e-05,
      "loss": 0.4561,
      "step": 115210
    },
    {
      "epoch": 2.3041235051793785,
      "grad_norm": 0.11048858612775803,
      "learning_rate": 1.1612606487221533e-05,
      "loss": 0.0707,
      "step": 115220
    },
    {
      "epoch": 2.304323481182258,
      "grad_norm": 0.24359050393104553,
      "learning_rate": 1.1609273553840206e-05,
      "loss": 0.0718,
      "step": 115230
    },
    {
      "epoch": 2.304523457185138,
      "grad_norm": 0.06768247485160828,
      "learning_rate": 1.1605940620458879e-05,
      "loss": 0.0603,
      "step": 115240
    },
    {
      "epoch": 2.3047234331880175,
      "grad_norm": 0.13570231199264526,
      "learning_rate": 1.1602607687077552e-05,
      "loss": 0.086,
      "step": 115250
    },
    {
      "epoch": 2.304923409190897,
      "grad_norm": 0.21034246683120728,
      "learning_rate": 1.1599274753696223e-05,
      "loss": 0.0731,
      "step": 115260
    },
    {
      "epoch": 2.305123385193777,
      "grad_norm": 0.10278719663619995,
      "learning_rate": 1.1595941820314896e-05,
      "loss": 0.051,
      "step": 115270
    },
    {
      "epoch": 2.3053233611966566,
      "grad_norm": 0.13843241333961487,
      "learning_rate": 1.159260888693357e-05,
      "loss": 0.0526,
      "step": 115280
    },
    {
      "epoch": 2.305523337199536,
      "grad_norm": 0.18581421673297882,
      "learning_rate": 1.158927595355224e-05,
      "loss": 0.0905,
      "step": 115290
    },
    {
      "epoch": 2.3057233132024155,
      "grad_norm": 0.11276638507843018,
      "learning_rate": 1.1585943020170914e-05,
      "loss": 0.0635,
      "step": 115300
    },
    {
      "epoch": 2.305923289205295,
      "grad_norm": 0.24430373311042786,
      "learning_rate": 1.1582610086789587e-05,
      "loss": 0.0763,
      "step": 115310
    },
    {
      "epoch": 2.306123265208175,
      "grad_norm": 0.16096043586730957,
      "learning_rate": 1.1579277153408258e-05,
      "loss": 0.0647,
      "step": 115320
    },
    {
      "epoch": 2.3063232412110546,
      "grad_norm": 0.13315707445144653,
      "learning_rate": 1.1575944220026931e-05,
      "loss": 0.058,
      "step": 115330
    },
    {
      "epoch": 2.3065232172139343,
      "grad_norm": 0.09798348695039749,
      "learning_rate": 1.1572611286645602e-05,
      "loss": 0.1082,
      "step": 115340
    },
    {
      "epoch": 2.306723193216814,
      "grad_norm": 0.11202513426542282,
      "learning_rate": 1.1569278353264275e-05,
      "loss": 0.0785,
      "step": 115350
    },
    {
      "epoch": 2.3069231692196936,
      "grad_norm": 0.09781482070684433,
      "learning_rate": 1.1565945419882948e-05,
      "loss": 0.0378,
      "step": 115360
    },
    {
      "epoch": 2.3071231452225733,
      "grad_norm": 0.0638355240225792,
      "learning_rate": 1.156261248650162e-05,
      "loss": 0.0461,
      "step": 115370
    },
    {
      "epoch": 2.307323121225453,
      "grad_norm": 0.2090788632631302,
      "learning_rate": 1.1559279553120293e-05,
      "loss": 0.0352,
      "step": 115380
    },
    {
      "epoch": 2.3075230972283327,
      "grad_norm": 0.17994797229766846,
      "learning_rate": 1.1555946619738966e-05,
      "loss": 0.0883,
      "step": 115390
    },
    {
      "epoch": 2.3077230732312124,
      "grad_norm": 0.1792140156030655,
      "learning_rate": 1.1552613686357637e-05,
      "loss": 0.069,
      "step": 115400
    },
    {
      "epoch": 2.307923049234092,
      "grad_norm": 0.19749683141708374,
      "learning_rate": 1.154928075297631e-05,
      "loss": 0.1143,
      "step": 115410
    },
    {
      "epoch": 2.3081230252369718,
      "grad_norm": 0.11698129028081894,
      "learning_rate": 1.1545947819594983e-05,
      "loss": 0.048,
      "step": 115420
    },
    {
      "epoch": 2.3083230012398515,
      "grad_norm": 0.09287445992231369,
      "learning_rate": 1.1542614886213656e-05,
      "loss": 0.0605,
      "step": 115430
    },
    {
      "epoch": 2.3085229772427307,
      "grad_norm": 0.1704295426607132,
      "learning_rate": 1.1539281952832327e-05,
      "loss": 0.0729,
      "step": 115440
    },
    {
      "epoch": 2.3087229532456104,
      "grad_norm": 0.07484585791826248,
      "learning_rate": 1.1535949019450998e-05,
      "loss": 0.0528,
      "step": 115450
    },
    {
      "epoch": 2.30892292924849,
      "grad_norm": 0.07865225523710251,
      "learning_rate": 1.1532616086069673e-05,
      "loss": 0.054,
      "step": 115460
    },
    {
      "epoch": 2.3091229052513698,
      "grad_norm": 0.1020951122045517,
      "learning_rate": 1.1529283152688344e-05,
      "loss": 0.0453,
      "step": 115470
    },
    {
      "epoch": 2.3093228812542494,
      "grad_norm": 0.08445809781551361,
      "learning_rate": 1.1525950219307017e-05,
      "loss": 0.0494,
      "step": 115480
    },
    {
      "epoch": 2.309522857257129,
      "grad_norm": 0.08256512880325317,
      "learning_rate": 1.1522617285925689e-05,
      "loss": 0.1151,
      "step": 115490
    },
    {
      "epoch": 2.309722833260009,
      "grad_norm": 0.13459204137325287,
      "learning_rate": 1.1519284352544362e-05,
      "loss": 0.0845,
      "step": 115500
    },
    {
      "epoch": 2.3099228092628885,
      "grad_norm": 0.14070925116539001,
      "learning_rate": 1.1515951419163035e-05,
      "loss": 0.093,
      "step": 115510
    },
    {
      "epoch": 2.310122785265768,
      "grad_norm": 0.1121973767876625,
      "learning_rate": 1.1512618485781706e-05,
      "loss": 0.0646,
      "step": 115520
    },
    {
      "epoch": 2.310322761268648,
      "grad_norm": 0.06806715577840805,
      "learning_rate": 1.1509285552400379e-05,
      "loss": 0.0616,
      "step": 115530
    },
    {
      "epoch": 2.3105227372715276,
      "grad_norm": 0.12614545226097107,
      "learning_rate": 1.1505952619019052e-05,
      "loss": 0.0707,
      "step": 115540
    },
    {
      "epoch": 2.3107227132744073,
      "grad_norm": 0.1482909470796585,
      "learning_rate": 1.1502619685637723e-05,
      "loss": 0.0665,
      "step": 115550
    },
    {
      "epoch": 2.3109226892772865,
      "grad_norm": 0.13970468938350677,
      "learning_rate": 1.1499286752256396e-05,
      "loss": 0.0795,
      "step": 115560
    },
    {
      "epoch": 2.311122665280166,
      "grad_norm": 0.04783570393919945,
      "learning_rate": 1.149595381887507e-05,
      "loss": 0.0926,
      "step": 115570
    },
    {
      "epoch": 2.311322641283046,
      "grad_norm": 0.18078501522541046,
      "learning_rate": 1.1492620885493742e-05,
      "loss": 0.1003,
      "step": 115580
    },
    {
      "epoch": 2.3115226172859256,
      "grad_norm": 0.23607945442199707,
      "learning_rate": 1.1489287952112414e-05,
      "loss": 0.0928,
      "step": 115590
    },
    {
      "epoch": 2.3117225932888052,
      "grad_norm": 0.12289441376924515,
      "learning_rate": 1.1485955018731085e-05,
      "loss": 0.0551,
      "step": 115600
    },
    {
      "epoch": 2.311922569291685,
      "grad_norm": 0.12257245182991028,
      "learning_rate": 1.148262208534976e-05,
      "loss": 0.065,
      "step": 115610
    },
    {
      "epoch": 2.3121225452945646,
      "grad_norm": 0.1711723506450653,
      "learning_rate": 1.1479289151968431e-05,
      "loss": 0.0808,
      "step": 115620
    },
    {
      "epoch": 2.3123225212974443,
      "grad_norm": 0.24058790504932404,
      "learning_rate": 1.1475956218587102e-05,
      "loss": 0.0835,
      "step": 115630
    },
    {
      "epoch": 2.312522497300324,
      "grad_norm": 0.12239842861890793,
      "learning_rate": 1.1472623285205775e-05,
      "loss": 0.0737,
      "step": 115640
    },
    {
      "epoch": 2.3127224733032037,
      "grad_norm": 0.278335303068161,
      "learning_rate": 1.1469290351824448e-05,
      "loss": 0.0914,
      "step": 115650
    },
    {
      "epoch": 2.3129224493060834,
      "grad_norm": 0.2001514732837677,
      "learning_rate": 1.1465957418443121e-05,
      "loss": 0.0831,
      "step": 115660
    },
    {
      "epoch": 2.313122425308963,
      "grad_norm": 0.1682518571615219,
      "learning_rate": 1.1462624485061793e-05,
      "loss": 0.0643,
      "step": 115670
    },
    {
      "epoch": 2.3133224013118427,
      "grad_norm": 0.20062261819839478,
      "learning_rate": 1.1459291551680466e-05,
      "loss": 0.0427,
      "step": 115680
    },
    {
      "epoch": 2.3135223773147224,
      "grad_norm": 0.2169983834028244,
      "learning_rate": 1.1455958618299139e-05,
      "loss": 0.0745,
      "step": 115690
    },
    {
      "epoch": 2.313722353317602,
      "grad_norm": 0.05515899509191513,
      "learning_rate": 1.145262568491781e-05,
      "loss": 0.0708,
      "step": 115700
    },
    {
      "epoch": 2.3139223293204814,
      "grad_norm": 0.1135149821639061,
      "learning_rate": 1.1449292751536483e-05,
      "loss": 0.0983,
      "step": 115710
    },
    {
      "epoch": 2.314122305323361,
      "grad_norm": 0.13832448422908783,
      "learning_rate": 1.1445959818155156e-05,
      "loss": 0.0486,
      "step": 115720
    },
    {
      "epoch": 2.3143222813262407,
      "grad_norm": 0.0879361554980278,
      "learning_rate": 1.1442626884773827e-05,
      "loss": 0.1546,
      "step": 115730
    },
    {
      "epoch": 2.3145222573291204,
      "grad_norm": 0.21342886984348297,
      "learning_rate": 1.14392939513925e-05,
      "loss": 0.0753,
      "step": 115740
    },
    {
      "epoch": 2.314722233332,
      "grad_norm": 0.09524533897638321,
      "learning_rate": 1.1435961018011172e-05,
      "loss": 0.0465,
      "step": 115750
    },
    {
      "epoch": 2.31492220933488,
      "grad_norm": 0.26614075899124146,
      "learning_rate": 1.1432628084629846e-05,
      "loss": 0.0967,
      "step": 115760
    },
    {
      "epoch": 2.3151221853377595,
      "grad_norm": 0.11190111190080643,
      "learning_rate": 1.1429295151248518e-05,
      "loss": 0.0628,
      "step": 115770
    },
    {
      "epoch": 2.315322161340639,
      "grad_norm": 0.07601957023143768,
      "learning_rate": 1.1425962217867189e-05,
      "loss": 0.036,
      "step": 115780
    },
    {
      "epoch": 2.315522137343519,
      "grad_norm": 0.09349358081817627,
      "learning_rate": 1.1422629284485862e-05,
      "loss": 0.0529,
      "step": 115790
    },
    {
      "epoch": 2.3157221133463985,
      "grad_norm": 0.09098731726408005,
      "learning_rate": 1.1419296351104535e-05,
      "loss": 0.0583,
      "step": 115800
    },
    {
      "epoch": 2.3159220893492782,
      "grad_norm": 0.12688195705413818,
      "learning_rate": 1.1415963417723208e-05,
      "loss": 0.0701,
      "step": 115810
    },
    {
      "epoch": 2.316122065352158,
      "grad_norm": 0.20798741281032562,
      "learning_rate": 1.141263048434188e-05,
      "loss": 0.087,
      "step": 115820
    },
    {
      "epoch": 2.316322041355037,
      "grad_norm": 0.08649741858243942,
      "learning_rate": 1.1409297550960552e-05,
      "loss": 0.0848,
      "step": 115830
    },
    {
      "epoch": 2.316522017357917,
      "grad_norm": 0.09214012324810028,
      "learning_rate": 1.1405964617579225e-05,
      "loss": 0.0502,
      "step": 115840
    },
    {
      "epoch": 2.3167219933607965,
      "grad_norm": 0.11359383165836334,
      "learning_rate": 1.1402631684197897e-05,
      "loss": 0.0426,
      "step": 115850
    },
    {
      "epoch": 2.3169219693636762,
      "grad_norm": 0.12453658878803253,
      "learning_rate": 1.1399298750816568e-05,
      "loss": 0.074,
      "step": 115860
    },
    {
      "epoch": 2.317121945366556,
      "grad_norm": 0.13066831231117249,
      "learning_rate": 1.1395965817435243e-05,
      "loss": 0.0628,
      "step": 115870
    },
    {
      "epoch": 2.3173219213694356,
      "grad_norm": 0.18222829699516296,
      "learning_rate": 1.1392632884053914e-05,
      "loss": 0.0597,
      "step": 115880
    },
    {
      "epoch": 2.3175218973723153,
      "grad_norm": 0.0916324034333229,
      "learning_rate": 1.1389299950672587e-05,
      "loss": 0.1621,
      "step": 115890
    },
    {
      "epoch": 2.317721873375195,
      "grad_norm": 0.07851257920265198,
      "learning_rate": 1.1385967017291258e-05,
      "loss": 0.081,
      "step": 115900
    },
    {
      "epoch": 2.3179218493780747,
      "grad_norm": 0.16698670387268066,
      "learning_rate": 1.1382634083909931e-05,
      "loss": 0.0872,
      "step": 115910
    },
    {
      "epoch": 2.3181218253809543,
      "grad_norm": 0.12974533438682556,
      "learning_rate": 1.1379301150528604e-05,
      "loss": 0.0699,
      "step": 115920
    },
    {
      "epoch": 2.318321801383834,
      "grad_norm": 0.22662754356861115,
      "learning_rate": 1.1375968217147276e-05,
      "loss": 0.0788,
      "step": 115930
    },
    {
      "epoch": 2.3185217773867137,
      "grad_norm": 0.19686444103717804,
      "learning_rate": 1.1372635283765949e-05,
      "loss": 0.1106,
      "step": 115940
    },
    {
      "epoch": 2.3187217533895934,
      "grad_norm": 0.15468382835388184,
      "learning_rate": 1.1369302350384622e-05,
      "loss": 0.0774,
      "step": 115950
    },
    {
      "epoch": 2.318921729392473,
      "grad_norm": 0.08154985308647156,
      "learning_rate": 1.1365969417003293e-05,
      "loss": 0.0617,
      "step": 115960
    },
    {
      "epoch": 2.319121705395353,
      "grad_norm": 0.06910327076911926,
      "learning_rate": 1.1362636483621966e-05,
      "loss": 0.0933,
      "step": 115970
    },
    {
      "epoch": 2.319321681398232,
      "grad_norm": 0.18836578726768494,
      "learning_rate": 1.1359303550240639e-05,
      "loss": 0.0705,
      "step": 115980
    },
    {
      "epoch": 2.3195216574011117,
      "grad_norm": 0.1318168193101883,
      "learning_rate": 1.1355970616859312e-05,
      "loss": 0.0932,
      "step": 115990
    },
    {
      "epoch": 2.3197216334039914,
      "grad_norm": 0.07400965690612793,
      "learning_rate": 1.1352637683477983e-05,
      "loss": 0.0578,
      "step": 116000
    },
    {
      "epoch": 2.319921609406871,
      "grad_norm": 0.094667948782444,
      "learning_rate": 1.1349304750096654e-05,
      "loss": 0.0823,
      "step": 116010
    },
    {
      "epoch": 2.3201215854097508,
      "grad_norm": 0.13056112825870514,
      "learning_rate": 1.134597181671533e-05,
      "loss": 0.1216,
      "step": 116020
    },
    {
      "epoch": 2.3203215614126305,
      "grad_norm": 0.0989542230963707,
      "learning_rate": 1.1342638883334e-05,
      "loss": 0.0666,
      "step": 116030
    },
    {
      "epoch": 2.32052153741551,
      "grad_norm": 0.15798184275627136,
      "learning_rate": 1.1339305949952674e-05,
      "loss": 0.0685,
      "step": 116040
    },
    {
      "epoch": 2.32072151341839,
      "grad_norm": 0.05887638032436371,
      "learning_rate": 1.1335973016571345e-05,
      "loss": 0.0452,
      "step": 116050
    },
    {
      "epoch": 2.3209214894212695,
      "grad_norm": 0.1702273190021515,
      "learning_rate": 1.1332640083190018e-05,
      "loss": 0.0967,
      "step": 116060
    },
    {
      "epoch": 2.321121465424149,
      "grad_norm": 0.20319882035255432,
      "learning_rate": 1.132930714980869e-05,
      "loss": 0.0723,
      "step": 116070
    },
    {
      "epoch": 2.321321441427029,
      "grad_norm": 0.24123899638652802,
      "learning_rate": 1.1325974216427362e-05,
      "loss": 0.0342,
      "step": 116080
    },
    {
      "epoch": 2.3215214174299086,
      "grad_norm": 0.11317314952611923,
      "learning_rate": 1.1322641283046035e-05,
      "loss": 0.0544,
      "step": 116090
    },
    {
      "epoch": 2.321721393432788,
      "grad_norm": 0.18364882469177246,
      "learning_rate": 1.1319308349664708e-05,
      "loss": 0.0693,
      "step": 116100
    },
    {
      "epoch": 2.3219213694356675,
      "grad_norm": 0.11062896996736526,
      "learning_rate": 1.131597541628338e-05,
      "loss": 0.1286,
      "step": 116110
    },
    {
      "epoch": 2.322121345438547,
      "grad_norm": 0.18715471029281616,
      "learning_rate": 1.1312642482902052e-05,
      "loss": 0.0657,
      "step": 116120
    },
    {
      "epoch": 2.322321321441427,
      "grad_norm": 0.1418476402759552,
      "learning_rate": 1.1309309549520725e-05,
      "loss": 0.0749,
      "step": 116130
    },
    {
      "epoch": 2.3225212974443066,
      "grad_norm": 0.18336084485054016,
      "learning_rate": 1.1305976616139397e-05,
      "loss": 0.0563,
      "step": 116140
    },
    {
      "epoch": 2.3227212734471863,
      "grad_norm": 0.14848588407039642,
      "learning_rate": 1.130264368275807e-05,
      "loss": 0.1214,
      "step": 116150
    },
    {
      "epoch": 2.322921249450066,
      "grad_norm": 0.13264140486717224,
      "learning_rate": 1.1299310749376741e-05,
      "loss": 0.0569,
      "step": 116160
    },
    {
      "epoch": 2.3231212254529456,
      "grad_norm": 0.19654032588005066,
      "learning_rate": 1.1295977815995416e-05,
      "loss": 0.1211,
      "step": 116170
    },
    {
      "epoch": 2.3233212014558253,
      "grad_norm": 0.18279682099819183,
      "learning_rate": 1.1292644882614087e-05,
      "loss": 0.049,
      "step": 116180
    },
    {
      "epoch": 2.323521177458705,
      "grad_norm": 0.25304967164993286,
      "learning_rate": 1.1289311949232758e-05,
      "loss": 0.0962,
      "step": 116190
    },
    {
      "epoch": 2.3237211534615847,
      "grad_norm": 0.2219184786081314,
      "learning_rate": 1.1285979015851431e-05,
      "loss": 0.0659,
      "step": 116200
    },
    {
      "epoch": 2.3239211294644644,
      "grad_norm": 0.06805143505334854,
      "learning_rate": 1.1282646082470104e-05,
      "loss": 0.0477,
      "step": 116210
    },
    {
      "epoch": 2.324121105467344,
      "grad_norm": 0.10631696879863739,
      "learning_rate": 1.1279313149088777e-05,
      "loss": 0.0786,
      "step": 116220
    },
    {
      "epoch": 2.3243210814702238,
      "grad_norm": 0.11561018973588943,
      "learning_rate": 1.1275980215707449e-05,
      "loss": 0.0483,
      "step": 116230
    },
    {
      "epoch": 2.3245210574731034,
      "grad_norm": 0.09585019946098328,
      "learning_rate": 1.1272647282326122e-05,
      "loss": 0.091,
      "step": 116240
    },
    {
      "epoch": 2.3247210334759827,
      "grad_norm": 0.06107436120510101,
      "learning_rate": 1.1269314348944795e-05,
      "loss": 0.0827,
      "step": 116250
    },
    {
      "epoch": 2.3249210094788624,
      "grad_norm": 0.16343331336975098,
      "learning_rate": 1.1265981415563466e-05,
      "loss": 0.1403,
      "step": 116260
    },
    {
      "epoch": 2.325120985481742,
      "grad_norm": 0.11768148094415665,
      "learning_rate": 1.1262648482182139e-05,
      "loss": 0.0687,
      "step": 116270
    },
    {
      "epoch": 2.3253209614846218,
      "grad_norm": 0.1871218979358673,
      "learning_rate": 1.125931554880081e-05,
      "loss": 0.0661,
      "step": 116280
    },
    {
      "epoch": 2.3255209374875014,
      "grad_norm": 0.17089401185512543,
      "learning_rate": 1.1255982615419483e-05,
      "loss": 0.0562,
      "step": 116290
    },
    {
      "epoch": 2.325720913490381,
      "grad_norm": 0.23841796815395355,
      "learning_rate": 1.1252649682038156e-05,
      "loss": 0.0725,
      "step": 116300
    },
    {
      "epoch": 2.325920889493261,
      "grad_norm": 0.14827388525009155,
      "learning_rate": 1.1249316748656828e-05,
      "loss": 0.0895,
      "step": 116310
    },
    {
      "epoch": 2.3261208654961405,
      "grad_norm": 0.2483004778623581,
      "learning_rate": 1.12459838152755e-05,
      "loss": 0.0811,
      "step": 116320
    },
    {
      "epoch": 2.32632084149902,
      "grad_norm": 0.2184232473373413,
      "learning_rate": 1.1242650881894174e-05,
      "loss": 0.0784,
      "step": 116330
    },
    {
      "epoch": 2.3265208175019,
      "grad_norm": 0.17497098445892334,
      "learning_rate": 1.1239317948512845e-05,
      "loss": 0.0662,
      "step": 116340
    },
    {
      "epoch": 2.3267207935047796,
      "grad_norm": 0.2265380620956421,
      "learning_rate": 1.1235985015131518e-05,
      "loss": 0.0594,
      "step": 116350
    },
    {
      "epoch": 2.3269207695076592,
      "grad_norm": 0.19694849848747253,
      "learning_rate": 1.1232652081750191e-05,
      "loss": 0.0654,
      "step": 116360
    },
    {
      "epoch": 2.3271207455105385,
      "grad_norm": 0.2058658003807068,
      "learning_rate": 1.1229319148368862e-05,
      "loss": 0.0742,
      "step": 116370
    },
    {
      "epoch": 2.327320721513418,
      "grad_norm": 0.08899811655282974,
      "learning_rate": 1.1225986214987535e-05,
      "loss": 0.0656,
      "step": 116380
    },
    {
      "epoch": 2.327520697516298,
      "grad_norm": 0.1308484971523285,
      "learning_rate": 1.1222653281606207e-05,
      "loss": 0.0965,
      "step": 116390
    },
    {
      "epoch": 2.3277206735191776,
      "grad_norm": 0.13262303173542023,
      "learning_rate": 1.1219320348224881e-05,
      "loss": 0.0761,
      "step": 116400
    },
    {
      "epoch": 2.3279206495220572,
      "grad_norm": 0.17280815541744232,
      "learning_rate": 1.1215987414843553e-05,
      "loss": 0.0604,
      "step": 116410
    },
    {
      "epoch": 2.328120625524937,
      "grad_norm": 0.09115767478942871,
      "learning_rate": 1.1212654481462224e-05,
      "loss": 0.0595,
      "step": 116420
    },
    {
      "epoch": 2.3283206015278166,
      "grad_norm": 0.20280982553958893,
      "learning_rate": 1.1209321548080897e-05,
      "loss": 0.0718,
      "step": 116430
    },
    {
      "epoch": 2.3285205775306963,
      "grad_norm": 0.20342190563678741,
      "learning_rate": 1.120598861469957e-05,
      "loss": 0.0452,
      "step": 116440
    },
    {
      "epoch": 2.328720553533576,
      "grad_norm": 0.08683689683675766,
      "learning_rate": 1.1202655681318243e-05,
      "loss": 0.0716,
      "step": 116450
    },
    {
      "epoch": 2.3289205295364557,
      "grad_norm": 0.1262127012014389,
      "learning_rate": 1.1199322747936914e-05,
      "loss": 0.0836,
      "step": 116460
    },
    {
      "epoch": 2.3291205055393354,
      "grad_norm": 0.11604912579059601,
      "learning_rate": 1.1195989814555587e-05,
      "loss": 0.1066,
      "step": 116470
    },
    {
      "epoch": 2.329320481542215,
      "grad_norm": 0.11484707146883011,
      "learning_rate": 1.119265688117426e-05,
      "loss": 0.0743,
      "step": 116480
    },
    {
      "epoch": 2.3295204575450947,
      "grad_norm": 0.12526348233222961,
      "learning_rate": 1.1189323947792932e-05,
      "loss": 0.0939,
      "step": 116490
    },
    {
      "epoch": 2.3297204335479744,
      "grad_norm": 0.08345385640859604,
      "learning_rate": 1.1185991014411605e-05,
      "loss": 0.0764,
      "step": 116500
    },
    {
      "epoch": 2.329920409550854,
      "grad_norm": 0.18488585948944092,
      "learning_rate": 1.1182658081030278e-05,
      "loss": 0.0576,
      "step": 116510
    },
    {
      "epoch": 2.330120385553734,
      "grad_norm": 0.06216033920645714,
      "learning_rate": 1.1179325147648949e-05,
      "loss": 0.0574,
      "step": 116520
    },
    {
      "epoch": 2.330320361556613,
      "grad_norm": 0.1208852231502533,
      "learning_rate": 1.1175992214267622e-05,
      "loss": 0.056,
      "step": 116530
    },
    {
      "epoch": 2.3305203375594927,
      "grad_norm": 0.07407032698392868,
      "learning_rate": 1.1172659280886293e-05,
      "loss": 0.0663,
      "step": 116540
    },
    {
      "epoch": 2.3307203135623724,
      "grad_norm": 0.11701593548059464,
      "learning_rate": 1.1169326347504968e-05,
      "loss": 0.4324,
      "step": 116550
    },
    {
      "epoch": 2.330920289565252,
      "grad_norm": 0.070912204682827,
      "learning_rate": 1.116599341412364e-05,
      "loss": 0.0765,
      "step": 116560
    },
    {
      "epoch": 2.331120265568132,
      "grad_norm": 0.2236415594816208,
      "learning_rate": 1.116266048074231e-05,
      "loss": 0.0896,
      "step": 116570
    },
    {
      "epoch": 2.3313202415710115,
      "grad_norm": 0.1729671210050583,
      "learning_rate": 1.1159327547360984e-05,
      "loss": 0.0789,
      "step": 116580
    },
    {
      "epoch": 2.331520217573891,
      "grad_norm": 0.23058639466762543,
      "learning_rate": 1.1155994613979657e-05,
      "loss": 0.0691,
      "step": 116590
    },
    {
      "epoch": 2.331720193576771,
      "grad_norm": 0.15578699111938477,
      "learning_rate": 1.1152661680598328e-05,
      "loss": 0.0928,
      "step": 116600
    },
    {
      "epoch": 2.3319201695796505,
      "grad_norm": 0.08445817232131958,
      "learning_rate": 1.1149328747217001e-05,
      "loss": 0.0409,
      "step": 116610
    },
    {
      "epoch": 2.3321201455825302,
      "grad_norm": 0.19949060678482056,
      "learning_rate": 1.1145995813835674e-05,
      "loss": 0.0612,
      "step": 116620
    },
    {
      "epoch": 2.33232012158541,
      "grad_norm": 0.22456249594688416,
      "learning_rate": 1.1142662880454347e-05,
      "loss": 0.1349,
      "step": 116630
    },
    {
      "epoch": 2.3325200975882896,
      "grad_norm": 0.1205708235502243,
      "learning_rate": 1.1139329947073018e-05,
      "loss": 0.053,
      "step": 116640
    },
    {
      "epoch": 2.332720073591169,
      "grad_norm": 0.21157073974609375,
      "learning_rate": 1.113599701369169e-05,
      "loss": 0.0789,
      "step": 116650
    },
    {
      "epoch": 2.3329200495940485,
      "grad_norm": 0.11197959631681442,
      "learning_rate": 1.1132664080310364e-05,
      "loss": 0.0724,
      "step": 116660
    },
    {
      "epoch": 2.333120025596928,
      "grad_norm": 0.1727563440799713,
      "learning_rate": 1.1129331146929035e-05,
      "loss": 0.0627,
      "step": 116670
    },
    {
      "epoch": 2.333320001599808,
      "grad_norm": 0.11101003736257553,
      "learning_rate": 1.1125998213547708e-05,
      "loss": 0.1118,
      "step": 116680
    },
    {
      "epoch": 2.3335199776026876,
      "grad_norm": 0.05844533443450928,
      "learning_rate": 1.112266528016638e-05,
      "loss": 0.0693,
      "step": 116690
    },
    {
      "epoch": 2.3337199536055673,
      "grad_norm": 0.22110621631145477,
      "learning_rate": 1.1119332346785053e-05,
      "loss": 0.0978,
      "step": 116700
    },
    {
      "epoch": 2.333919929608447,
      "grad_norm": 0.09146488457918167,
      "learning_rate": 1.1115999413403726e-05,
      "loss": 0.0499,
      "step": 116710
    },
    {
      "epoch": 2.3341199056113267,
      "grad_norm": 0.07527390122413635,
      "learning_rate": 1.1112666480022397e-05,
      "loss": 0.071,
      "step": 116720
    },
    {
      "epoch": 2.3343198816142063,
      "grad_norm": 0.06962402909994125,
      "learning_rate": 1.110933354664107e-05,
      "loss": 0.0779,
      "step": 116730
    },
    {
      "epoch": 2.334519857617086,
      "grad_norm": 0.06043093651533127,
      "learning_rate": 1.1106000613259743e-05,
      "loss": 0.0823,
      "step": 116740
    },
    {
      "epoch": 2.3347198336199657,
      "grad_norm": 0.06021466478705406,
      "learning_rate": 1.1102667679878414e-05,
      "loss": 0.0443,
      "step": 116750
    },
    {
      "epoch": 2.3349198096228454,
      "grad_norm": 0.08689363300800323,
      "learning_rate": 1.1099334746497087e-05,
      "loss": 0.1069,
      "step": 116760
    },
    {
      "epoch": 2.335119785625725,
      "grad_norm": 0.10599765926599503,
      "learning_rate": 1.109600181311576e-05,
      "loss": 0.0672,
      "step": 116770
    },
    {
      "epoch": 2.3353197616286048,
      "grad_norm": 0.2580857276916504,
      "learning_rate": 1.1092668879734433e-05,
      "loss": 0.0582,
      "step": 116780
    },
    {
      "epoch": 2.3355197376314845,
      "grad_norm": 0.09948144108057022,
      "learning_rate": 1.1089335946353105e-05,
      "loss": 0.0654,
      "step": 116790
    },
    {
      "epoch": 2.3357197136343637,
      "grad_norm": 0.1023976057767868,
      "learning_rate": 1.1086003012971776e-05,
      "loss": 0.0445,
      "step": 116800
    },
    {
      "epoch": 2.3359196896372434,
      "grad_norm": 0.19865137338638306,
      "learning_rate": 1.108267007959045e-05,
      "loss": 0.062,
      "step": 116810
    },
    {
      "epoch": 2.336119665640123,
      "grad_norm": 0.14568471908569336,
      "learning_rate": 1.1079337146209122e-05,
      "loss": 0.0911,
      "step": 116820
    },
    {
      "epoch": 2.3363196416430028,
      "grad_norm": 0.05585351958870888,
      "learning_rate": 1.1076004212827795e-05,
      "loss": 0.0571,
      "step": 116830
    },
    {
      "epoch": 2.3365196176458825,
      "grad_norm": 0.11673074215650558,
      "learning_rate": 1.1072671279446466e-05,
      "loss": 0.0851,
      "step": 116840
    },
    {
      "epoch": 2.336719593648762,
      "grad_norm": 0.20702317357063293,
      "learning_rate": 1.106933834606514e-05,
      "loss": 0.1704,
      "step": 116850
    },
    {
      "epoch": 2.336919569651642,
      "grad_norm": 0.13628552854061127,
      "learning_rate": 1.1066005412683812e-05,
      "loss": 0.0776,
      "step": 116860
    },
    {
      "epoch": 2.3371195456545215,
      "grad_norm": 0.20925207436084747,
      "learning_rate": 1.1062672479302484e-05,
      "loss": 0.1146,
      "step": 116870
    },
    {
      "epoch": 2.337319521657401,
      "grad_norm": 0.22493289411067963,
      "learning_rate": 1.1059339545921157e-05,
      "loss": 0.0811,
      "step": 116880
    },
    {
      "epoch": 2.337519497660281,
      "grad_norm": 0.1055571660399437,
      "learning_rate": 1.105600661253983e-05,
      "loss": 0.0948,
      "step": 116890
    },
    {
      "epoch": 2.3377194736631606,
      "grad_norm": 0.05984579771757126,
      "learning_rate": 1.1052673679158501e-05,
      "loss": 0.0691,
      "step": 116900
    },
    {
      "epoch": 2.3379194496660403,
      "grad_norm": 0.17958860099315643,
      "learning_rate": 1.1049340745777174e-05,
      "loss": 0.1306,
      "step": 116910
    },
    {
      "epoch": 2.3381194256689195,
      "grad_norm": 0.20441626012325287,
      "learning_rate": 1.1046007812395847e-05,
      "loss": 0.0763,
      "step": 116920
    },
    {
      "epoch": 2.338319401671799,
      "grad_norm": 0.12058234959840775,
      "learning_rate": 1.1042674879014518e-05,
      "loss": 0.0637,
      "step": 116930
    },
    {
      "epoch": 2.338519377674679,
      "grad_norm": 0.12496367841959,
      "learning_rate": 1.1039341945633191e-05,
      "loss": 0.0563,
      "step": 116940
    },
    {
      "epoch": 2.3387193536775586,
      "grad_norm": 0.16913168132305145,
      "learning_rate": 1.1036009012251863e-05,
      "loss": 0.0441,
      "step": 116950
    },
    {
      "epoch": 2.3389193296804383,
      "grad_norm": 0.13067325949668884,
      "learning_rate": 1.1032676078870537e-05,
      "loss": 0.0625,
      "step": 116960
    },
    {
      "epoch": 2.339119305683318,
      "grad_norm": 0.10250239074230194,
      "learning_rate": 1.1029343145489209e-05,
      "loss": 0.0684,
      "step": 116970
    },
    {
      "epoch": 2.3393192816861976,
      "grad_norm": 0.04883041977882385,
      "learning_rate": 1.102601021210788e-05,
      "loss": 0.1013,
      "step": 116980
    },
    {
      "epoch": 2.3395192576890773,
      "grad_norm": 0.12452370673418045,
      "learning_rate": 1.1022677278726553e-05,
      "loss": 0.0718,
      "step": 116990
    },
    {
      "epoch": 2.339719233691957,
      "grad_norm": 0.0887271910905838,
      "learning_rate": 1.1019344345345226e-05,
      "loss": 0.097,
      "step": 117000
    },
    {
      "epoch": 2.3399192096948367,
      "grad_norm": 0.1259845495223999,
      "learning_rate": 1.1016011411963899e-05,
      "loss": 0.0804,
      "step": 117010
    },
    {
      "epoch": 2.3401191856977164,
      "grad_norm": 0.29062312841415405,
      "learning_rate": 1.101267847858257e-05,
      "loss": 0.0766,
      "step": 117020
    },
    {
      "epoch": 2.340319161700596,
      "grad_norm": 0.1991061121225357,
      "learning_rate": 1.1009345545201243e-05,
      "loss": 0.0741,
      "step": 117030
    },
    {
      "epoch": 2.3405191377034757,
      "grad_norm": 0.17464835941791534,
      "learning_rate": 1.1006012611819916e-05,
      "loss": 0.0746,
      "step": 117040
    },
    {
      "epoch": 2.3407191137063554,
      "grad_norm": 0.2587316632270813,
      "learning_rate": 1.1002679678438588e-05,
      "loss": 0.0875,
      "step": 117050
    },
    {
      "epoch": 2.340919089709235,
      "grad_norm": 0.22098904848098755,
      "learning_rate": 1.099934674505726e-05,
      "loss": 0.0542,
      "step": 117060
    },
    {
      "epoch": 2.3411190657121144,
      "grad_norm": 0.10887745767831802,
      "learning_rate": 1.0996013811675934e-05,
      "loss": 0.064,
      "step": 117070
    },
    {
      "epoch": 2.341319041714994,
      "grad_norm": 0.18462902307510376,
      "learning_rate": 1.0992680878294605e-05,
      "loss": 0.0975,
      "step": 117080
    },
    {
      "epoch": 2.3415190177178737,
      "grad_norm": 0.15103106200695038,
      "learning_rate": 1.0989347944913278e-05,
      "loss": 0.0781,
      "step": 117090
    },
    {
      "epoch": 2.3417189937207534,
      "grad_norm": 0.1493556797504425,
      "learning_rate": 1.098601501153195e-05,
      "loss": 0.0656,
      "step": 117100
    },
    {
      "epoch": 2.341918969723633,
      "grad_norm": 0.0881066843867302,
      "learning_rate": 1.0982682078150622e-05,
      "loss": 0.0358,
      "step": 117110
    },
    {
      "epoch": 2.342118945726513,
      "grad_norm": 0.19500131905078888,
      "learning_rate": 1.0979349144769295e-05,
      "loss": 0.082,
      "step": 117120
    },
    {
      "epoch": 2.3423189217293925,
      "grad_norm": 0.12064753472805023,
      "learning_rate": 1.0976016211387967e-05,
      "loss": 0.0427,
      "step": 117130
    },
    {
      "epoch": 2.342518897732272,
      "grad_norm": 0.10537873208522797,
      "learning_rate": 1.097268327800664e-05,
      "loss": 0.0841,
      "step": 117140
    },
    {
      "epoch": 2.342718873735152,
      "grad_norm": 0.1769454926252365,
      "learning_rate": 1.0969350344625313e-05,
      "loss": 0.073,
      "step": 117150
    },
    {
      "epoch": 2.3429188497380316,
      "grad_norm": 0.11925821006298065,
      "learning_rate": 1.0966017411243984e-05,
      "loss": 0.0819,
      "step": 117160
    },
    {
      "epoch": 2.3431188257409112,
      "grad_norm": NaN,
      "learning_rate": 1.0962684477862657e-05,
      "loss": 0.099,
      "step": 117170
    },
    {
      "epoch": 2.343318801743791,
      "grad_norm": 0.1275603473186493,
      "learning_rate": 1.0959684837819462e-05,
      "loss": 0.0588,
      "step": 117180
    },
    {
      "epoch": 2.34351877774667,
      "grad_norm": 0.10905148088932037,
      "learning_rate": 1.0956351904438135e-05,
      "loss": 0.0721,
      "step": 117190
    },
    {
      "epoch": 2.34371875374955,
      "grad_norm": 0.08537527918815613,
      "learning_rate": 1.0953018971056807e-05,
      "loss": 0.0796,
      "step": 117200
    },
    {
      "epoch": 2.3439187297524295,
      "grad_norm": 0.06962732970714569,
      "learning_rate": 1.094968603767548e-05,
      "loss": 0.0767,
      "step": 117210
    },
    {
      "epoch": 2.3441187057553092,
      "grad_norm": 0.10162592679262161,
      "learning_rate": 1.0946353104294153e-05,
      "loss": 0.0689,
      "step": 117220
    },
    {
      "epoch": 2.344318681758189,
      "grad_norm": 0.08354426920413971,
      "learning_rate": 1.0943020170912824e-05,
      "loss": 0.0701,
      "step": 117230
    },
    {
      "epoch": 2.3445186577610686,
      "grad_norm": 0.17512446641921997,
      "learning_rate": 1.0939687237531497e-05,
      "loss": 0.07,
      "step": 117240
    },
    {
      "epoch": 2.3447186337639483,
      "grad_norm": 0.14447927474975586,
      "learning_rate": 1.0936354304150168e-05,
      "loss": 0.064,
      "step": 117250
    },
    {
      "epoch": 2.344918609766828,
      "grad_norm": 0.1408359408378601,
      "learning_rate": 1.0933021370768843e-05,
      "loss": 0.0748,
      "step": 117260
    },
    {
      "epoch": 2.3451185857697077,
      "grad_norm": 0.15268276631832123,
      "learning_rate": 1.0929688437387514e-05,
      "loss": 0.067,
      "step": 117270
    },
    {
      "epoch": 2.3453185617725874,
      "grad_norm": 0.12480808794498444,
      "learning_rate": 1.0926355504006186e-05,
      "loss": 0.0553,
      "step": 117280
    },
    {
      "epoch": 2.345518537775467,
      "grad_norm": 0.22159801423549652,
      "learning_rate": 1.0923022570624859e-05,
      "loss": 0.0758,
      "step": 117290
    },
    {
      "epoch": 2.3457185137783467,
      "grad_norm": 0.1065511554479599,
      "learning_rate": 1.0919689637243532e-05,
      "loss": 0.0589,
      "step": 117300
    },
    {
      "epoch": 2.3459184897812264,
      "grad_norm": 0.1663036197423935,
      "learning_rate": 1.0916356703862203e-05,
      "loss": 0.0969,
      "step": 117310
    },
    {
      "epoch": 2.346118465784106,
      "grad_norm": 0.1555299013853073,
      "learning_rate": 1.0913023770480876e-05,
      "loss": 0.0646,
      "step": 117320
    },
    {
      "epoch": 2.346318441786986,
      "grad_norm": 0.10418210923671722,
      "learning_rate": 1.0909690837099549e-05,
      "loss": 0.0378,
      "step": 117330
    },
    {
      "epoch": 2.346518417789865,
      "grad_norm": 0.0852169319987297,
      "learning_rate": 1.0906357903718222e-05,
      "loss": 0.0624,
      "step": 117340
    },
    {
      "epoch": 2.3467183937927447,
      "grad_norm": 0.11670710891485214,
      "learning_rate": 1.0903024970336893e-05,
      "loss": 0.0678,
      "step": 117350
    },
    {
      "epoch": 2.3469183697956244,
      "grad_norm": 0.10900978744029999,
      "learning_rate": 1.0899692036955564e-05,
      "loss": 0.0896,
      "step": 117360
    },
    {
      "epoch": 2.347118345798504,
      "grad_norm": 0.09216133505105972,
      "learning_rate": 1.089635910357424e-05,
      "loss": 0.0486,
      "step": 117370
    },
    {
      "epoch": 2.347318321801384,
      "grad_norm": 0.1339532881975174,
      "learning_rate": 1.089302617019291e-05,
      "loss": 0.0911,
      "step": 117380
    },
    {
      "epoch": 2.3475182978042635,
      "grad_norm": 0.08203937113285065,
      "learning_rate": 1.0889693236811583e-05,
      "loss": 0.0782,
      "step": 117390
    },
    {
      "epoch": 2.347718273807143,
      "grad_norm": 0.14992566406726837,
      "learning_rate": 1.0886360303430255e-05,
      "loss": 0.0934,
      "step": 117400
    },
    {
      "epoch": 2.347918249810023,
      "grad_norm": 0.09050163626670837,
      "learning_rate": 1.0883027370048928e-05,
      "loss": 0.1057,
      "step": 117410
    },
    {
      "epoch": 2.3481182258129025,
      "grad_norm": 0.07530557364225388,
      "learning_rate": 1.08796944366676e-05,
      "loss": 0.0446,
      "step": 117420
    },
    {
      "epoch": 2.348318201815782,
      "grad_norm": 0.2166469395160675,
      "learning_rate": 1.0876361503286272e-05,
      "loss": 0.0605,
      "step": 117430
    },
    {
      "epoch": 2.348518177818662,
      "grad_norm": 0.11169221997261047,
      "learning_rate": 1.0873028569904945e-05,
      "loss": 0.0556,
      "step": 117440
    },
    {
      "epoch": 2.3487181538215416,
      "grad_norm": 0.20172441005706787,
      "learning_rate": 1.0869695636523618e-05,
      "loss": 0.0895,
      "step": 117450
    },
    {
      "epoch": 2.348918129824421,
      "grad_norm": 0.06507328152656555,
      "learning_rate": 1.086636270314229e-05,
      "loss": 0.0636,
      "step": 117460
    },
    {
      "epoch": 2.3491181058273005,
      "grad_norm": 0.08874029666185379,
      "learning_rate": 1.0863029769760962e-05,
      "loss": 0.0565,
      "step": 117470
    },
    {
      "epoch": 2.34931808183018,
      "grad_norm": 0.19490663707256317,
      "learning_rate": 1.0859696836379635e-05,
      "loss": 0.0653,
      "step": 117480
    },
    {
      "epoch": 2.34951805783306,
      "grad_norm": 0.07865002751350403,
      "learning_rate": 1.0856363902998308e-05,
      "loss": 0.0883,
      "step": 117490
    },
    {
      "epoch": 2.3497180338359396,
      "grad_norm": 0.11827948689460754,
      "learning_rate": 1.085303096961698e-05,
      "loss": 0.0801,
      "step": 117500
    },
    {
      "epoch": 2.3499180098388193,
      "grad_norm": 0.11411450058221817,
      "learning_rate": 1.0849698036235651e-05,
      "loss": 0.0632,
      "step": 117510
    },
    {
      "epoch": 2.350117985841699,
      "grad_norm": 0.1631888747215271,
      "learning_rate": 1.0846365102854326e-05,
      "loss": 0.0565,
      "step": 117520
    },
    {
      "epoch": 2.3503179618445786,
      "grad_norm": 0.13381068408489227,
      "learning_rate": 1.0843032169472997e-05,
      "loss": 0.0618,
      "step": 117530
    },
    {
      "epoch": 2.3505179378474583,
      "grad_norm": 0.26018789410591125,
      "learning_rate": 1.083969923609167e-05,
      "loss": 0.0655,
      "step": 117540
    },
    {
      "epoch": 2.350717913850338,
      "grad_norm": 0.1753423660993576,
      "learning_rate": 1.0836366302710341e-05,
      "loss": 0.0591,
      "step": 117550
    },
    {
      "epoch": 2.3509178898532177,
      "grad_norm": 0.140558123588562,
      "learning_rate": 1.0833033369329014e-05,
      "loss": 0.1048,
      "step": 117560
    },
    {
      "epoch": 2.3511178658560974,
      "grad_norm": 0.16861245036125183,
      "learning_rate": 1.0829700435947687e-05,
      "loss": 0.0719,
      "step": 117570
    },
    {
      "epoch": 2.351317841858977,
      "grad_norm": 0.06339184194803238,
      "learning_rate": 1.0826367502566359e-05,
      "loss": 0.0768,
      "step": 117580
    },
    {
      "epoch": 2.3515178178618568,
      "grad_norm": 0.15670698881149292,
      "learning_rate": 1.0823034569185032e-05,
      "loss": 0.0966,
      "step": 117590
    },
    {
      "epoch": 2.3517177938647364,
      "grad_norm": 0.18044094741344452,
      "learning_rate": 1.0819701635803705e-05,
      "loss": 0.2485,
      "step": 117600
    },
    {
      "epoch": 2.3519177698676157,
      "grad_norm": 0.11153823137283325,
      "learning_rate": 1.0816368702422376e-05,
      "loss": 0.0969,
      "step": 117610
    },
    {
      "epoch": 2.3521177458704954,
      "grad_norm": 0.12191999703645706,
      "learning_rate": 1.0813035769041049e-05,
      "loss": 0.0631,
      "step": 117620
    },
    {
      "epoch": 2.352317721873375,
      "grad_norm": 0.07328706979751587,
      "learning_rate": 1.0809702835659722e-05,
      "loss": 0.09,
      "step": 117630
    },
    {
      "epoch": 2.3525176978762548,
      "grad_norm": 0.12588435411453247,
      "learning_rate": 1.0806369902278393e-05,
      "loss": 0.0725,
      "step": 117640
    },
    {
      "epoch": 2.3527176738791344,
      "grad_norm": 0.16103649139404297,
      "learning_rate": 1.0803036968897066e-05,
      "loss": 0.0758,
      "step": 117650
    },
    {
      "epoch": 2.352917649882014,
      "grad_norm": 0.13367502391338348,
      "learning_rate": 1.0799704035515738e-05,
      "loss": 0.0559,
      "step": 117660
    },
    {
      "epoch": 2.353117625884894,
      "grad_norm": 0.05345862731337547,
      "learning_rate": 1.0796371102134412e-05,
      "loss": 0.0567,
      "step": 117670
    },
    {
      "epoch": 2.3533176018877735,
      "grad_norm": 0.17110106348991394,
      "learning_rate": 1.0793038168753084e-05,
      "loss": 0.0601,
      "step": 117680
    },
    {
      "epoch": 2.353517577890653,
      "grad_norm": 0.23049816489219666,
      "learning_rate": 1.0789705235371755e-05,
      "loss": 0.0751,
      "step": 117690
    },
    {
      "epoch": 2.353717553893533,
      "grad_norm": 0.25042524933815,
      "learning_rate": 1.0786372301990428e-05,
      "loss": 0.0792,
      "step": 117700
    },
    {
      "epoch": 2.3539175298964126,
      "grad_norm": 0.2628571391105652,
      "learning_rate": 1.0783039368609101e-05,
      "loss": 0.0526,
      "step": 117710
    },
    {
      "epoch": 2.3541175058992923,
      "grad_norm": 0.23624984920024872,
      "learning_rate": 1.0779706435227774e-05,
      "loss": 0.0667,
      "step": 117720
    },
    {
      "epoch": 2.3543174819021715,
      "grad_norm": 0.2087124139070511,
      "learning_rate": 1.0776373501846445e-05,
      "loss": 0.0681,
      "step": 117730
    },
    {
      "epoch": 2.354517457905051,
      "grad_norm": 0.22705677151679993,
      "learning_rate": 1.0773040568465118e-05,
      "loss": 0.0542,
      "step": 117740
    },
    {
      "epoch": 2.354717433907931,
      "grad_norm": 0.13066086173057556,
      "learning_rate": 1.0769707635083791e-05,
      "loss": 0.0862,
      "step": 117750
    },
    {
      "epoch": 2.3549174099108106,
      "grad_norm": 0.15842927992343903,
      "learning_rate": 1.0766374701702463e-05,
      "loss": 0.0842,
      "step": 117760
    },
    {
      "epoch": 2.3551173859136902,
      "grad_norm": 0.15210896730422974,
      "learning_rate": 1.0763041768321136e-05,
      "loss": 0.0547,
      "step": 117770
    },
    {
      "epoch": 2.35531736191657,
      "grad_norm": 0.17108003795146942,
      "learning_rate": 1.0759708834939809e-05,
      "loss": 0.082,
      "step": 117780
    },
    {
      "epoch": 2.3555173379194496,
      "grad_norm": 0.06850627064704895,
      "learning_rate": 1.075637590155848e-05,
      "loss": 0.0538,
      "step": 117790
    },
    {
      "epoch": 2.3557173139223293,
      "grad_norm": 0.0977182611823082,
      "learning_rate": 1.0753042968177153e-05,
      "loss": 0.0765,
      "step": 117800
    },
    {
      "epoch": 2.355917289925209,
      "grad_norm": 0.17693370580673218,
      "learning_rate": 1.0749710034795824e-05,
      "loss": 0.0741,
      "step": 117810
    },
    {
      "epoch": 2.3561172659280887,
      "grad_norm": 0.04947732016444206,
      "learning_rate": 1.0746377101414497e-05,
      "loss": 0.0532,
      "step": 117820
    },
    {
      "epoch": 2.3563172419309684,
      "grad_norm": 0.07695083320140839,
      "learning_rate": 1.074304416803317e-05,
      "loss": 0.0678,
      "step": 117830
    },
    {
      "epoch": 2.356517217933848,
      "grad_norm": 0.06901830434799194,
      "learning_rate": 1.0739711234651842e-05,
      "loss": 0.088,
      "step": 117840
    },
    {
      "epoch": 2.3567171939367277,
      "grad_norm": 0.18292944133281708,
      "learning_rate": 1.0736378301270515e-05,
      "loss": 0.0836,
      "step": 117850
    },
    {
      "epoch": 2.3569171699396074,
      "grad_norm": 0.17149224877357483,
      "learning_rate": 1.0733045367889188e-05,
      "loss": 0.0981,
      "step": 117860
    },
    {
      "epoch": 2.357117145942487,
      "grad_norm": 0.08873173594474792,
      "learning_rate": 1.0729712434507859e-05,
      "loss": 0.0425,
      "step": 117870
    },
    {
      "epoch": 2.357317121945367,
      "grad_norm": 0.08009649813175201,
      "learning_rate": 1.0726379501126532e-05,
      "loss": 0.0876,
      "step": 117880
    },
    {
      "epoch": 2.357517097948246,
      "grad_norm": 0.11668428033590317,
      "learning_rate": 1.0723046567745205e-05,
      "loss": 0.1107,
      "step": 117890
    },
    {
      "epoch": 2.3577170739511257,
      "grad_norm": 0.1426457017660141,
      "learning_rate": 1.0719713634363878e-05,
      "loss": 0.0464,
      "step": 117900
    },
    {
      "epoch": 2.3579170499540054,
      "grad_norm": 0.1102212443947792,
      "learning_rate": 1.071638070098255e-05,
      "loss": 0.0977,
      "step": 117910
    },
    {
      "epoch": 2.358117025956885,
      "grad_norm": 0.14496862888336182,
      "learning_rate": 1.071304776760122e-05,
      "loss": 0.0805,
      "step": 117920
    },
    {
      "epoch": 2.358317001959765,
      "grad_norm": 0.13669022917747498,
      "learning_rate": 1.0709714834219895e-05,
      "loss": 0.0817,
      "step": 117930
    },
    {
      "epoch": 2.3585169779626445,
      "grad_norm": 0.18201954662799835,
      "learning_rate": 1.0706381900838567e-05,
      "loss": 0.0634,
      "step": 117940
    },
    {
      "epoch": 2.358716953965524,
      "grad_norm": 0.0956050306558609,
      "learning_rate": 1.070304896745724e-05,
      "loss": 0.0668,
      "step": 117950
    },
    {
      "epoch": 2.358916929968404,
      "grad_norm": 0.09859302639961243,
      "learning_rate": 1.069971603407591e-05,
      "loss": 0.1093,
      "step": 117960
    },
    {
      "epoch": 2.3591169059712835,
      "grad_norm": 0.0844360962510109,
      "learning_rate": 1.0696383100694584e-05,
      "loss": 0.0784,
      "step": 117970
    },
    {
      "epoch": 2.3593168819741632,
      "grad_norm": 0.07943637669086456,
      "learning_rate": 1.0693050167313257e-05,
      "loss": 0.0641,
      "step": 117980
    },
    {
      "epoch": 2.359516857977043,
      "grad_norm": 0.1325300633907318,
      "learning_rate": 1.0689717233931928e-05,
      "loss": 0.0584,
      "step": 117990
    },
    {
      "epoch": 2.3597168339799226,
      "grad_norm": 0.430277943611145,
      "learning_rate": 1.0686384300550601e-05,
      "loss": 0.5932,
      "step": 118000
    },
    {
      "epoch": 2.359916809982802,
      "grad_norm": 0.11094215512275696,
      "learning_rate": 1.0683051367169274e-05,
      "loss": 0.0731,
      "step": 118010
    },
    {
      "epoch": 2.3601167859856815,
      "grad_norm": 0.11876433342695236,
      "learning_rate": 1.0679718433787945e-05,
      "loss": 0.1046,
      "step": 118020
    },
    {
      "epoch": 2.360316761988561,
      "grad_norm": 0.17562268674373627,
      "learning_rate": 1.0676385500406618e-05,
      "loss": 0.1024,
      "step": 118030
    },
    {
      "epoch": 2.360516737991441,
      "grad_norm": 0.22493956983089447,
      "learning_rate": 1.0673052567025291e-05,
      "loss": 0.0571,
      "step": 118040
    },
    {
      "epoch": 2.3607167139943206,
      "grad_norm": 0.08454661071300507,
      "learning_rate": 1.0669719633643963e-05,
      "loss": 0.0727,
      "step": 118050
    },
    {
      "epoch": 2.3609166899972003,
      "grad_norm": 0.24756377935409546,
      "learning_rate": 1.0666386700262636e-05,
      "loss": 0.0628,
      "step": 118060
    },
    {
      "epoch": 2.36111666600008,
      "grad_norm": 0.18406881392002106,
      "learning_rate": 1.0663053766881307e-05,
      "loss": 0.0536,
      "step": 118070
    },
    {
      "epoch": 2.3613166420029597,
      "grad_norm": 0.21724195778369904,
      "learning_rate": 1.0659720833499982e-05,
      "loss": 0.0943,
      "step": 118080
    },
    {
      "epoch": 2.3615166180058393,
      "grad_norm": 0.06857004016637802,
      "learning_rate": 1.0656387900118653e-05,
      "loss": 0.1081,
      "step": 118090
    },
    {
      "epoch": 2.361716594008719,
      "grad_norm": 0.12771755456924438,
      "learning_rate": 1.0653054966737324e-05,
      "loss": 0.0646,
      "step": 118100
    },
    {
      "epoch": 2.3619165700115987,
      "grad_norm": 0.14460858702659607,
      "learning_rate": 1.0649722033355997e-05,
      "loss": 0.0448,
      "step": 118110
    },
    {
      "epoch": 2.3621165460144784,
      "grad_norm": 0.21917250752449036,
      "learning_rate": 1.064638909997467e-05,
      "loss": 0.061,
      "step": 118120
    },
    {
      "epoch": 2.362316522017358,
      "grad_norm": 0.22968769073486328,
      "learning_rate": 1.0643056166593343e-05,
      "loss": 0.1189,
      "step": 118130
    },
    {
      "epoch": 2.3625164980202378,
      "grad_norm": 0.1865878850221634,
      "learning_rate": 1.0639723233212015e-05,
      "loss": 0.0817,
      "step": 118140
    },
    {
      "epoch": 2.3627164740231175,
      "grad_norm": 0.1598668098449707,
      "learning_rate": 1.0636390299830688e-05,
      "loss": 0.0682,
      "step": 118150
    },
    {
      "epoch": 2.3629164500259967,
      "grad_norm": 0.057462427765131,
      "learning_rate": 1.063305736644936e-05,
      "loss": 0.0638,
      "step": 118160
    },
    {
      "epoch": 2.3631164260288764,
      "grad_norm": 0.05751496180891991,
      "learning_rate": 1.0629724433068032e-05,
      "loss": 0.0876,
      "step": 118170
    },
    {
      "epoch": 2.363316402031756,
      "grad_norm": 0.19963359832763672,
      "learning_rate": 1.0626391499686705e-05,
      "loss": 0.1066,
      "step": 118180
    },
    {
      "epoch": 2.3635163780346358,
      "grad_norm": 0.27158331871032715,
      "learning_rate": 1.0623058566305376e-05,
      "loss": 0.0963,
      "step": 118190
    },
    {
      "epoch": 2.3637163540375155,
      "grad_norm": 0.08279784023761749,
      "learning_rate": 1.061972563292405e-05,
      "loss": 0.0747,
      "step": 118200
    },
    {
      "epoch": 2.363916330040395,
      "grad_norm": 0.1074516773223877,
      "learning_rate": 1.0616392699542722e-05,
      "loss": 0.0784,
      "step": 118210
    },
    {
      "epoch": 2.364116306043275,
      "grad_norm": 0.06297503411769867,
      "learning_rate": 1.0613059766161394e-05,
      "loss": 0.0795,
      "step": 118220
    },
    {
      "epoch": 2.3643162820461545,
      "grad_norm": 0.11423385888338089,
      "learning_rate": 1.0609726832780067e-05,
      "loss": 0.077,
      "step": 118230
    },
    {
      "epoch": 2.364516258049034,
      "grad_norm": 0.0673976019024849,
      "learning_rate": 1.060639389939874e-05,
      "loss": 0.0867,
      "step": 118240
    },
    {
      "epoch": 2.364716234051914,
      "grad_norm": 0.10092665255069733,
      "learning_rate": 1.0603060966017411e-05,
      "loss": 0.1279,
      "step": 118250
    },
    {
      "epoch": 2.3649162100547936,
      "grad_norm": 0.16448213160037994,
      "learning_rate": 1.0599728032636084e-05,
      "loss": 0.074,
      "step": 118260
    },
    {
      "epoch": 2.3651161860576733,
      "grad_norm": 0.14031921327114105,
      "learning_rate": 1.0596395099254757e-05,
      "loss": 0.0794,
      "step": 118270
    },
    {
      "epoch": 2.3653161620605525,
      "grad_norm": 0.23954714834690094,
      "learning_rate": 1.059306216587343e-05,
      "loss": 0.0675,
      "step": 118280
    },
    {
      "epoch": 2.365516138063432,
      "grad_norm": 0.1808970719575882,
      "learning_rate": 1.0589729232492101e-05,
      "loss": 0.0803,
      "step": 118290
    },
    {
      "epoch": 2.365716114066312,
      "grad_norm": 0.06951210647821426,
      "learning_rate": 1.0586396299110773e-05,
      "loss": 0.0573,
      "step": 118300
    },
    {
      "epoch": 2.3659160900691916,
      "grad_norm": 0.11785036325454712,
      "learning_rate": 1.0583063365729447e-05,
      "loss": 0.0555,
      "step": 118310
    },
    {
      "epoch": 2.3661160660720713,
      "grad_norm": 0.09510672092437744,
      "learning_rate": 1.0579730432348119e-05,
      "loss": 0.0656,
      "step": 118320
    },
    {
      "epoch": 2.366316042074951,
      "grad_norm": 0.11483344435691833,
      "learning_rate": 1.057639749896679e-05,
      "loss": 0.0517,
      "step": 118330
    },
    {
      "epoch": 2.3665160180778306,
      "grad_norm": 0.10191593319177628,
      "learning_rate": 1.0573064565585463e-05,
      "loss": 0.0897,
      "step": 118340
    },
    {
      "epoch": 2.3667159940807103,
      "grad_norm": 0.08806073665618896,
      "learning_rate": 1.0569731632204136e-05,
      "loss": 0.0942,
      "step": 118350
    },
    {
      "epoch": 2.36691597008359,
      "grad_norm": 0.19872404634952545,
      "learning_rate": 1.0566398698822809e-05,
      "loss": 0.1037,
      "step": 118360
    },
    {
      "epoch": 2.3671159460864697,
      "grad_norm": 0.11002576351165771,
      "learning_rate": 1.056306576544148e-05,
      "loss": 0.0647,
      "step": 118370
    },
    {
      "epoch": 2.3673159220893494,
      "grad_norm": 0.08096203953027725,
      "learning_rate": 1.0559732832060153e-05,
      "loss": 0.0676,
      "step": 118380
    },
    {
      "epoch": 2.367515898092229,
      "grad_norm": 0.15912500023841858,
      "learning_rate": 1.0556399898678826e-05,
      "loss": 0.1001,
      "step": 118390
    },
    {
      "epoch": 2.3677158740951088,
      "grad_norm": 0.17362864315509796,
      "learning_rate": 1.0553066965297498e-05,
      "loss": 0.0786,
      "step": 118400
    },
    {
      "epoch": 2.3679158500979884,
      "grad_norm": 0.10189994424581528,
      "learning_rate": 1.054973403191617e-05,
      "loss": 0.0582,
      "step": 118410
    },
    {
      "epoch": 2.368115826100868,
      "grad_norm": 0.08024049550294876,
      "learning_rate": 1.0546401098534844e-05,
      "loss": 0.0813,
      "step": 118420
    },
    {
      "epoch": 2.3683158021037474,
      "grad_norm": 0.1960563361644745,
      "learning_rate": 1.0543068165153515e-05,
      "loss": 0.0628,
      "step": 118430
    },
    {
      "epoch": 2.368515778106627,
      "grad_norm": 0.12171690165996552,
      "learning_rate": 1.0539735231772188e-05,
      "loss": 0.0475,
      "step": 118440
    },
    {
      "epoch": 2.3687157541095067,
      "grad_norm": 0.1328127086162567,
      "learning_rate": 1.053640229839086e-05,
      "loss": 0.1021,
      "step": 118450
    },
    {
      "epoch": 2.3689157301123864,
      "grad_norm": 0.16945260763168335,
      "learning_rate": 1.0533069365009534e-05,
      "loss": 0.1079,
      "step": 118460
    },
    {
      "epoch": 2.369115706115266,
      "grad_norm": 0.17779260873794556,
      "learning_rate": 1.0529736431628205e-05,
      "loss": 0.0452,
      "step": 118470
    },
    {
      "epoch": 2.369315682118146,
      "grad_norm": 0.09725449234247208,
      "learning_rate": 1.0526403498246877e-05,
      "loss": 0.0844,
      "step": 118480
    },
    {
      "epoch": 2.3695156581210255,
      "grad_norm": 0.08993183821439743,
      "learning_rate": 1.052307056486555e-05,
      "loss": 0.0472,
      "step": 118490
    },
    {
      "epoch": 2.369715634123905,
      "grad_norm": 0.12360526621341705,
      "learning_rate": 1.0519737631484223e-05,
      "loss": 0.0568,
      "step": 118500
    },
    {
      "epoch": 2.369915610126785,
      "grad_norm": 0.14020180702209473,
      "learning_rate": 1.0516404698102896e-05,
      "loss": 0.059,
      "step": 118510
    },
    {
      "epoch": 2.3701155861296646,
      "grad_norm": 0.15609660744667053,
      "learning_rate": 1.0513071764721567e-05,
      "loss": 0.0595,
      "step": 118520
    },
    {
      "epoch": 2.3703155621325442,
      "grad_norm": 0.11767111718654633,
      "learning_rate": 1.050973883134024e-05,
      "loss": 0.0884,
      "step": 118530
    },
    {
      "epoch": 2.370515538135424,
      "grad_norm": 0.19023063778877258,
      "learning_rate": 1.0506405897958913e-05,
      "loss": 0.0699,
      "step": 118540
    },
    {
      "epoch": 2.370715514138303,
      "grad_norm": 0.254142701625824,
      "learning_rate": 1.0503072964577584e-05,
      "loss": 0.0551,
      "step": 118550
    },
    {
      "epoch": 2.370915490141183,
      "grad_norm": 0.13760091364383698,
      "learning_rate": 1.0499740031196255e-05,
      "loss": 0.0387,
      "step": 118560
    },
    {
      "epoch": 2.3711154661440625,
      "grad_norm": 0.18478178977966309,
      "learning_rate": 1.049640709781493e-05,
      "loss": 0.0662,
      "step": 118570
    },
    {
      "epoch": 2.3713154421469422,
      "grad_norm": 0.11561621725559235,
      "learning_rate": 1.0493074164433602e-05,
      "loss": 0.0561,
      "step": 118580
    },
    {
      "epoch": 2.371515418149822,
      "grad_norm": 0.08922270685434341,
      "learning_rate": 1.0489741231052275e-05,
      "loss": 0.0698,
      "step": 118590
    },
    {
      "epoch": 2.3717153941527016,
      "grad_norm": 0.23353976011276245,
      "learning_rate": 1.0486408297670946e-05,
      "loss": 0.083,
      "step": 118600
    },
    {
      "epoch": 2.3719153701555813,
      "grad_norm": 0.15011221170425415,
      "learning_rate": 1.0483075364289619e-05,
      "loss": 0.0832,
      "step": 118610
    },
    {
      "epoch": 2.372115346158461,
      "grad_norm": 0.07067267596721649,
      "learning_rate": 1.0479742430908292e-05,
      "loss": 0.0656,
      "step": 118620
    },
    {
      "epoch": 2.3723153221613407,
      "grad_norm": 0.07951042801141739,
      "learning_rate": 1.0476409497526963e-05,
      "loss": 0.0717,
      "step": 118630
    },
    {
      "epoch": 2.3725152981642204,
      "grad_norm": 0.14603661000728607,
      "learning_rate": 1.0473076564145636e-05,
      "loss": 0.0353,
      "step": 118640
    },
    {
      "epoch": 2.3727152741671,
      "grad_norm": 0.1176103726029396,
      "learning_rate": 1.0469743630764309e-05,
      "loss": 0.0898,
      "step": 118650
    },
    {
      "epoch": 2.3729152501699797,
      "grad_norm": 0.19483815133571625,
      "learning_rate": 1.046641069738298e-05,
      "loss": 0.0541,
      "step": 118660
    },
    {
      "epoch": 2.3731152261728594,
      "grad_norm": 0.1762487292289734,
      "learning_rate": 1.0463077764001653e-05,
      "loss": 0.0615,
      "step": 118670
    },
    {
      "epoch": 2.373315202175739,
      "grad_norm": 0.2954276502132416,
      "learning_rate": 1.0459744830620326e-05,
      "loss": 0.0604,
      "step": 118680
    },
    {
      "epoch": 2.373515178178619,
      "grad_norm": 0.07997728139162064,
      "learning_rate": 1.0456411897239e-05,
      "loss": 0.0643,
      "step": 118690
    },
    {
      "epoch": 2.373715154181498,
      "grad_norm": 0.08487503230571747,
      "learning_rate": 1.045307896385767e-05,
      "loss": 0.0693,
      "step": 118700
    },
    {
      "epoch": 2.3739151301843777,
      "grad_norm": 0.16858623921871185,
      "learning_rate": 1.0449746030476342e-05,
      "loss": 0.1202,
      "step": 118710
    },
    {
      "epoch": 2.3741151061872574,
      "grad_norm": 0.08999397605657578,
      "learning_rate": 1.0446413097095017e-05,
      "loss": 0.0673,
      "step": 118720
    },
    {
      "epoch": 2.374315082190137,
      "grad_norm": 0.14639624953269958,
      "learning_rate": 1.0443080163713688e-05,
      "loss": 0.0697,
      "step": 118730
    },
    {
      "epoch": 2.374515058193017,
      "grad_norm": 0.19146806001663208,
      "learning_rate": 1.0439747230332361e-05,
      "loss": 0.0566,
      "step": 118740
    },
    {
      "epoch": 2.3747150341958965,
      "grad_norm": 0.09570317715406418,
      "learning_rate": 1.0436414296951032e-05,
      "loss": 0.0663,
      "step": 118750
    },
    {
      "epoch": 2.374915010198776,
      "grad_norm": 0.09320425242185593,
      "learning_rate": 1.0433081363569705e-05,
      "loss": 0.0484,
      "step": 118760
    },
    {
      "epoch": 2.375114986201656,
      "grad_norm": 0.1257721334695816,
      "learning_rate": 1.0429748430188378e-05,
      "loss": 0.0898,
      "step": 118770
    },
    {
      "epoch": 2.3753149622045355,
      "grad_norm": 0.16995298862457275,
      "learning_rate": 1.042641549680705e-05,
      "loss": 0.064,
      "step": 118780
    },
    {
      "epoch": 2.375514938207415,
      "grad_norm": 0.10797671228647232,
      "learning_rate": 1.0423082563425723e-05,
      "loss": 0.059,
      "step": 118790
    },
    {
      "epoch": 2.375714914210295,
      "grad_norm": 0.10915154963731766,
      "learning_rate": 1.0419749630044396e-05,
      "loss": 0.0534,
      "step": 118800
    },
    {
      "epoch": 2.3759148902131746,
      "grad_norm": 0.059261713176965714,
      "learning_rate": 1.0416416696663067e-05,
      "loss": 0.1235,
      "step": 118810
    },
    {
      "epoch": 2.376114866216054,
      "grad_norm": 0.1308101862668991,
      "learning_rate": 1.041308376328174e-05,
      "loss": 0.0578,
      "step": 118820
    },
    {
      "epoch": 2.3763148422189335,
      "grad_norm": 0.1028217300772667,
      "learning_rate": 1.0409750829900413e-05,
      "loss": 0.0583,
      "step": 118830
    },
    {
      "epoch": 2.376514818221813,
      "grad_norm": 0.17921116948127747,
      "learning_rate": 1.0406417896519084e-05,
      "loss": 0.0795,
      "step": 118840
    },
    {
      "epoch": 2.376714794224693,
      "grad_norm": 0.11649417877197266,
      "learning_rate": 1.0403084963137757e-05,
      "loss": 0.086,
      "step": 118850
    },
    {
      "epoch": 2.3769147702275726,
      "grad_norm": 0.2524507939815521,
      "learning_rate": 1.0399752029756429e-05,
      "loss": 0.0685,
      "step": 118860
    },
    {
      "epoch": 2.3771147462304523,
      "grad_norm": 0.15135683119297028,
      "learning_rate": 1.0396419096375103e-05,
      "loss": 0.0819,
      "step": 118870
    },
    {
      "epoch": 2.377314722233332,
      "grad_norm": 0.10154270380735397,
      "learning_rate": 1.0393086162993775e-05,
      "loss": 0.1126,
      "step": 118880
    },
    {
      "epoch": 2.3775146982362116,
      "grad_norm": 0.20344847440719604,
      "learning_rate": 1.0389753229612446e-05,
      "loss": 0.0588,
      "step": 118890
    },
    {
      "epoch": 2.3777146742390913,
      "grad_norm": 0.0926683098077774,
      "learning_rate": 1.0386420296231119e-05,
      "loss": 0.0673,
      "step": 118900
    },
    {
      "epoch": 2.377914650241971,
      "grad_norm": 0.08666931837797165,
      "learning_rate": 1.0383087362849792e-05,
      "loss": 0.0767,
      "step": 118910
    },
    {
      "epoch": 2.3781146262448507,
      "grad_norm": 0.2132205367088318,
      "learning_rate": 1.0379754429468465e-05,
      "loss": 0.0689,
      "step": 118920
    },
    {
      "epoch": 2.3783146022477304,
      "grad_norm": 0.10536739230155945,
      "learning_rate": 1.0376421496087136e-05,
      "loss": 0.0802,
      "step": 118930
    },
    {
      "epoch": 2.37851457825061,
      "grad_norm": 0.19965028762817383,
      "learning_rate": 1.037308856270581e-05,
      "loss": 0.1016,
      "step": 118940
    },
    {
      "epoch": 2.3787145542534898,
      "grad_norm": 0.07283039391040802,
      "learning_rate": 1.0369755629324482e-05,
      "loss": 0.0836,
      "step": 118950
    },
    {
      "epoch": 2.3789145302563695,
      "grad_norm": 0.06950431317090988,
      "learning_rate": 1.0366422695943154e-05,
      "loss": 0.0651,
      "step": 118960
    },
    {
      "epoch": 2.379114506259249,
      "grad_norm": 0.15878283977508545,
      "learning_rate": 1.0363089762561827e-05,
      "loss": 0.0791,
      "step": 118970
    },
    {
      "epoch": 2.3793144822621284,
      "grad_norm": 0.0783153623342514,
      "learning_rate": 1.03597568291805e-05,
      "loss": 0.0779,
      "step": 118980
    },
    {
      "epoch": 2.379514458265008,
      "grad_norm": 0.05964477360248566,
      "learning_rate": 1.0356423895799171e-05,
      "loss": 0.0898,
      "step": 118990
    },
    {
      "epoch": 2.3797144342678878,
      "grad_norm": 0.10033106058835983,
      "learning_rate": 1.0353090962417844e-05,
      "loss": 0.0557,
      "step": 119000
    },
    {
      "epoch": 2.3799144102707674,
      "grad_norm": 0.26149898767471313,
      "learning_rate": 1.0349758029036515e-05,
      "loss": 0.1221,
      "step": 119010
    },
    {
      "epoch": 2.380114386273647,
      "grad_norm": 0.07135294377803802,
      "learning_rate": 1.034642509565519e-05,
      "loss": 0.0925,
      "step": 119020
    },
    {
      "epoch": 2.380314362276527,
      "grad_norm": 0.15799468755722046,
      "learning_rate": 1.0343092162273861e-05,
      "loss": 0.0582,
      "step": 119030
    },
    {
      "epoch": 2.3805143382794065,
      "grad_norm": 0.08600940555334091,
      "learning_rate": 1.0339759228892533e-05,
      "loss": 0.0615,
      "step": 119040
    },
    {
      "epoch": 2.380714314282286,
      "grad_norm": 0.07462042570114136,
      "learning_rate": 1.0336426295511206e-05,
      "loss": 0.0499,
      "step": 119050
    },
    {
      "epoch": 2.380914290285166,
      "grad_norm": 0.37660083174705505,
      "learning_rate": 1.0333093362129879e-05,
      "loss": 0.1217,
      "step": 119060
    },
    {
      "epoch": 2.3811142662880456,
      "grad_norm": 0.20503894984722137,
      "learning_rate": 1.032976042874855e-05,
      "loss": 0.0955,
      "step": 119070
    },
    {
      "epoch": 2.3813142422909253,
      "grad_norm": 0.09163463860750198,
      "learning_rate": 1.0326427495367223e-05,
      "loss": 0.0624,
      "step": 119080
    },
    {
      "epoch": 2.3815142182938045,
      "grad_norm": 0.12226835638284683,
      "learning_rate": 1.0323094561985896e-05,
      "loss": 0.0807,
      "step": 119090
    },
    {
      "epoch": 2.381714194296684,
      "grad_norm": 0.1725611835718155,
      "learning_rate": 1.0319761628604569e-05,
      "loss": 0.0898,
      "step": 119100
    },
    {
      "epoch": 2.381914170299564,
      "grad_norm": 0.17058758437633514,
      "learning_rate": 1.031642869522324e-05,
      "loss": 0.0919,
      "step": 119110
    },
    {
      "epoch": 2.3821141463024436,
      "grad_norm": 0.21695995330810547,
      "learning_rate": 1.0313095761841912e-05,
      "loss": 0.0867,
      "step": 119120
    },
    {
      "epoch": 2.3823141223053232,
      "grad_norm": 0.11859054863452911,
      "learning_rate": 1.0309762828460586e-05,
      "loss": 0.0512,
      "step": 119130
    },
    {
      "epoch": 2.382514098308203,
      "grad_norm": 0.19683288037776947,
      "learning_rate": 1.0306429895079258e-05,
      "loss": 0.0751,
      "step": 119140
    },
    {
      "epoch": 2.3827140743110826,
      "grad_norm": 0.09093446284532547,
      "learning_rate": 1.030309696169793e-05,
      "loss": 0.0516,
      "step": 119150
    },
    {
      "epoch": 2.3829140503139623,
      "grad_norm": 0.11562316119670868,
      "learning_rate": 1.0299764028316602e-05,
      "loss": 0.0989,
      "step": 119160
    },
    {
      "epoch": 2.383114026316842,
      "grad_norm": 0.07442327588796616,
      "learning_rate": 1.0296431094935275e-05,
      "loss": 0.0747,
      "step": 119170
    },
    {
      "epoch": 2.3833140023197217,
      "grad_norm": 0.17880412936210632,
      "learning_rate": 1.0293098161553948e-05,
      "loss": 0.0726,
      "step": 119180
    },
    {
      "epoch": 2.3835139783226014,
      "grad_norm": 0.1367730051279068,
      "learning_rate": 1.028976522817262e-05,
      "loss": 0.0699,
      "step": 119190
    },
    {
      "epoch": 2.383713954325481,
      "grad_norm": 0.09940771758556366,
      "learning_rate": 1.0286432294791292e-05,
      "loss": 0.1093,
      "step": 119200
    },
    {
      "epoch": 2.3839139303283607,
      "grad_norm": 0.12160252779722214,
      "learning_rate": 1.0283099361409965e-05,
      "loss": 0.0552,
      "step": 119210
    },
    {
      "epoch": 2.3841139063312404,
      "grad_norm": 0.07841388136148453,
      "learning_rate": 1.0279766428028636e-05,
      "loss": 0.0626,
      "step": 119220
    },
    {
      "epoch": 2.38431388233412,
      "grad_norm": 0.13966825604438782,
      "learning_rate": 1.027643349464731e-05,
      "loss": 0.0728,
      "step": 119230
    },
    {
      "epoch": 2.384513858337,
      "grad_norm": 0.09069519490003586,
      "learning_rate": 1.0273100561265983e-05,
      "loss": 0.0592,
      "step": 119240
    },
    {
      "epoch": 2.384713834339879,
      "grad_norm": 0.06315261125564575,
      "learning_rate": 1.0269767627884656e-05,
      "loss": 0.0553,
      "step": 119250
    },
    {
      "epoch": 2.3849138103427587,
      "grad_norm": 0.11463124305009842,
      "learning_rate": 1.0266434694503327e-05,
      "loss": 0.0822,
      "step": 119260
    },
    {
      "epoch": 2.3851137863456384,
      "grad_norm": 0.2759351134300232,
      "learning_rate": 1.0263101761121998e-05,
      "loss": 0.0855,
      "step": 119270
    },
    {
      "epoch": 2.385313762348518,
      "grad_norm": 0.09725195169448853,
      "learning_rate": 1.0259768827740673e-05,
      "loss": 0.0546,
      "step": 119280
    },
    {
      "epoch": 2.385513738351398,
      "grad_norm": 0.07606766372919083,
      "learning_rate": 1.0256435894359344e-05,
      "loss": 0.0304,
      "step": 119290
    },
    {
      "epoch": 2.3857137143542775,
      "grad_norm": 0.07382048666477203,
      "learning_rate": 1.0253102960978017e-05,
      "loss": 0.0495,
      "step": 119300
    },
    {
      "epoch": 2.385913690357157,
      "grad_norm": 0.08901528269052505,
      "learning_rate": 1.0249770027596688e-05,
      "loss": 0.0799,
      "step": 119310
    },
    {
      "epoch": 2.386113666360037,
      "grad_norm": 0.1919805109500885,
      "learning_rate": 1.0246437094215361e-05,
      "loss": 0.1093,
      "step": 119320
    },
    {
      "epoch": 2.3863136423629165,
      "grad_norm": 0.08879990130662918,
      "learning_rate": 1.0243104160834034e-05,
      "loss": 0.1069,
      "step": 119330
    },
    {
      "epoch": 2.3865136183657962,
      "grad_norm": 0.08409573137760162,
      "learning_rate": 1.0239771227452706e-05,
      "loss": 0.1201,
      "step": 119340
    },
    {
      "epoch": 2.386713594368676,
      "grad_norm": 0.17712613940238953,
      "learning_rate": 1.0236438294071379e-05,
      "loss": 0.0547,
      "step": 119350
    },
    {
      "epoch": 2.3869135703715556,
      "grad_norm": 0.0692010149359703,
      "learning_rate": 1.0233105360690052e-05,
      "loss": 0.0751,
      "step": 119360
    },
    {
      "epoch": 2.387113546374435,
      "grad_norm": 0.07911752909421921,
      "learning_rate": 1.0229772427308723e-05,
      "loss": 0.0734,
      "step": 119370
    },
    {
      "epoch": 2.3873135223773145,
      "grad_norm": 0.12343558669090271,
      "learning_rate": 1.0226439493927396e-05,
      "loss": 0.0572,
      "step": 119380
    },
    {
      "epoch": 2.387513498380194,
      "grad_norm": 0.09162235260009766,
      "learning_rate": 1.0223106560546067e-05,
      "loss": 0.0659,
      "step": 119390
    },
    {
      "epoch": 2.387713474383074,
      "grad_norm": 0.11241453886032104,
      "learning_rate": 1.021977362716474e-05,
      "loss": 0.0571,
      "step": 119400
    },
    {
      "epoch": 2.3879134503859536,
      "grad_norm": 0.11414586007595062,
      "learning_rate": 1.0216440693783413e-05,
      "loss": 0.0555,
      "step": 119410
    },
    {
      "epoch": 2.3881134263888333,
      "grad_norm": 0.2558666169643402,
      "learning_rate": 1.0213107760402085e-05,
      "loss": 0.073,
      "step": 119420
    },
    {
      "epoch": 2.388313402391713,
      "grad_norm": 0.1540246158838272,
      "learning_rate": 1.0209774827020758e-05,
      "loss": 0.0528,
      "step": 119430
    },
    {
      "epoch": 2.3885133783945927,
      "grad_norm": 0.1047726571559906,
      "learning_rate": 1.020644189363943e-05,
      "loss": 0.0605,
      "step": 119440
    },
    {
      "epoch": 2.3887133543974723,
      "grad_norm": 0.12668421864509583,
      "learning_rate": 1.0203108960258102e-05,
      "loss": 0.0829,
      "step": 119450
    },
    {
      "epoch": 2.388913330400352,
      "grad_norm": 0.10824272781610489,
      "learning_rate": 1.0199776026876775e-05,
      "loss": 0.0441,
      "step": 119460
    },
    {
      "epoch": 2.3891133064032317,
      "grad_norm": 0.08481437712907791,
      "learning_rate": 1.0196443093495448e-05,
      "loss": 0.0587,
      "step": 119470
    },
    {
      "epoch": 2.3893132824061114,
      "grad_norm": 0.15570741891860962,
      "learning_rate": 1.0193110160114121e-05,
      "loss": 0.0589,
      "step": 119480
    },
    {
      "epoch": 2.389513258408991,
      "grad_norm": 0.1353413611650467,
      "learning_rate": 1.0189777226732792e-05,
      "loss": 0.0917,
      "step": 119490
    },
    {
      "epoch": 2.389713234411871,
      "grad_norm": 0.16338960826396942,
      "learning_rate": 1.0186444293351464e-05,
      "loss": 0.0697,
      "step": 119500
    },
    {
      "epoch": 2.3899132104147505,
      "grad_norm": 0.059434451162815094,
      "learning_rate": 1.0183111359970138e-05,
      "loss": 0.0569,
      "step": 119510
    },
    {
      "epoch": 2.3901131864176297,
      "grad_norm": 0.318119078874588,
      "learning_rate": 1.017977842658881e-05,
      "loss": 0.0995,
      "step": 119520
    },
    {
      "epoch": 2.3903131624205094,
      "grad_norm": 0.215775266289711,
      "learning_rate": 1.0176445493207483e-05,
      "loss": 0.0792,
      "step": 119530
    },
    {
      "epoch": 2.390513138423389,
      "grad_norm": 0.15195558965206146,
      "learning_rate": 1.0173112559826154e-05,
      "loss": 0.0683,
      "step": 119540
    },
    {
      "epoch": 2.3907131144262688,
      "grad_norm": 0.2681654095649719,
      "learning_rate": 1.0169779626444827e-05,
      "loss": 0.0737,
      "step": 119550
    },
    {
      "epoch": 2.3909130904291485,
      "grad_norm": 0.1397058218717575,
      "learning_rate": 1.01664466930635e-05,
      "loss": 0.0469,
      "step": 119560
    },
    {
      "epoch": 2.391113066432028,
      "grad_norm": 0.060297559946775436,
      "learning_rate": 1.0163113759682171e-05,
      "loss": 0.0384,
      "step": 119570
    },
    {
      "epoch": 2.391313042434908,
      "grad_norm": 0.09033461660146713,
      "learning_rate": 1.0159780826300844e-05,
      "loss": 0.0746,
      "step": 119580
    },
    {
      "epoch": 2.3915130184377875,
      "grad_norm": 0.11836811155080795,
      "learning_rate": 1.0156447892919517e-05,
      "loss": 0.074,
      "step": 119590
    },
    {
      "epoch": 2.391712994440667,
      "grad_norm": 0.20751075446605682,
      "learning_rate": 1.0153114959538189e-05,
      "loss": 0.0748,
      "step": 119600
    },
    {
      "epoch": 2.391912970443547,
      "grad_norm": 0.2124132663011551,
      "learning_rate": 1.0149782026156862e-05,
      "loss": 0.0744,
      "step": 119610
    },
    {
      "epoch": 2.3921129464464266,
      "grad_norm": 0.10612685233354568,
      "learning_rate": 1.0146449092775535e-05,
      "loss": 0.0514,
      "step": 119620
    },
    {
      "epoch": 2.3923129224493063,
      "grad_norm": 0.09168484061956406,
      "learning_rate": 1.0143116159394206e-05,
      "loss": 0.2264,
      "step": 119630
    },
    {
      "epoch": 2.3925128984521855,
      "grad_norm": 0.08497938513755798,
      "learning_rate": 1.0139783226012879e-05,
      "loss": 0.0656,
      "step": 119640
    },
    {
      "epoch": 2.392712874455065,
      "grad_norm": 0.1433122158050537,
      "learning_rate": 1.013645029263155e-05,
      "loss": 0.0322,
      "step": 119650
    },
    {
      "epoch": 2.392912850457945,
      "grad_norm": 0.23131495714187622,
      "learning_rate": 1.0133117359250225e-05,
      "loss": 0.0636,
      "step": 119660
    },
    {
      "epoch": 2.3931128264608246,
      "grad_norm": 0.21738240122795105,
      "learning_rate": 1.0129784425868896e-05,
      "loss": 0.06,
      "step": 119670
    },
    {
      "epoch": 2.3933128024637043,
      "grad_norm": 0.2506214380264282,
      "learning_rate": 1.0126451492487568e-05,
      "loss": 0.1012,
      "step": 119680
    },
    {
      "epoch": 2.393512778466584,
      "grad_norm": 0.09438242018222809,
      "learning_rate": 1.012311855910624e-05,
      "loss": 0.0509,
      "step": 119690
    },
    {
      "epoch": 2.3937127544694636,
      "grad_norm": 0.1471538543701172,
      "learning_rate": 1.0119785625724914e-05,
      "loss": 0.0775,
      "step": 119700
    },
    {
      "epoch": 2.3939127304723433,
      "grad_norm": 0.20204925537109375,
      "learning_rate": 1.0116452692343587e-05,
      "loss": 0.1029,
      "step": 119710
    },
    {
      "epoch": 2.394112706475223,
      "grad_norm": 0.11111590266227722,
      "learning_rate": 1.0113119758962258e-05,
      "loss": 0.0879,
      "step": 119720
    },
    {
      "epoch": 2.3943126824781027,
      "grad_norm": 0.06443935632705688,
      "learning_rate": 1.0109786825580931e-05,
      "loss": 0.0759,
      "step": 119730
    },
    {
      "epoch": 2.3945126584809824,
      "grad_norm": 0.19892652332782745,
      "learning_rate": 1.0106453892199604e-05,
      "loss": 0.1042,
      "step": 119740
    },
    {
      "epoch": 2.394712634483862,
      "grad_norm": 0.15998029708862305,
      "learning_rate": 1.0103120958818275e-05,
      "loss": 0.1035,
      "step": 119750
    },
    {
      "epoch": 2.3949126104867418,
      "grad_norm": 0.05158788710832596,
      "learning_rate": 1.0099788025436948e-05,
      "loss": 0.093,
      "step": 119760
    },
    {
      "epoch": 2.3951125864896214,
      "grad_norm": 0.20842546224594116,
      "learning_rate": 1.0096455092055621e-05,
      "loss": 0.1009,
      "step": 119770
    },
    {
      "epoch": 2.395312562492501,
      "grad_norm": 0.11241740733385086,
      "learning_rate": 1.0093122158674293e-05,
      "loss": 0.0718,
      "step": 119780
    },
    {
      "epoch": 2.3955125384953804,
      "grad_norm": 0.3972475826740265,
      "learning_rate": 1.0089789225292966e-05,
      "loss": 0.129,
      "step": 119790
    },
    {
      "epoch": 2.39571251449826,
      "grad_norm": 0.14722348749637604,
      "learning_rate": 1.0086456291911637e-05,
      "loss": 0.0895,
      "step": 119800
    },
    {
      "epoch": 2.3959124905011397,
      "grad_norm": 0.1890878528356552,
      "learning_rate": 1.0083123358530312e-05,
      "loss": 0.0724,
      "step": 119810
    },
    {
      "epoch": 2.3961124665040194,
      "grad_norm": 0.11946194618940353,
      "learning_rate": 1.0079790425148983e-05,
      "loss": 0.0647,
      "step": 119820
    },
    {
      "epoch": 2.396312442506899,
      "grad_norm": 0.1867634356021881,
      "learning_rate": 1.0076457491767654e-05,
      "loss": 0.0875,
      "step": 119830
    },
    {
      "epoch": 2.396512418509779,
      "grad_norm": 0.1915528029203415,
      "learning_rate": 1.0073124558386327e-05,
      "loss": 0.0836,
      "step": 119840
    },
    {
      "epoch": 2.3967123945126585,
      "grad_norm": 0.06614739447832108,
      "learning_rate": 1.0069791625005e-05,
      "loss": 0.0538,
      "step": 119850
    },
    {
      "epoch": 2.396912370515538,
      "grad_norm": 0.0877295508980751,
      "learning_rate": 1.0066458691623671e-05,
      "loss": 0.0698,
      "step": 119860
    },
    {
      "epoch": 2.397112346518418,
      "grad_norm": 0.18341979384422302,
      "learning_rate": 1.0063125758242344e-05,
      "loss": 0.057,
      "step": 119870
    },
    {
      "epoch": 2.3973123225212976,
      "grad_norm": 0.1998077780008316,
      "learning_rate": 1.0059792824861017e-05,
      "loss": 0.0914,
      "step": 119880
    },
    {
      "epoch": 2.3975122985241772,
      "grad_norm": 0.25025010108947754,
      "learning_rate": 1.005645989147969e-05,
      "loss": 0.0476,
      "step": 119890
    },
    {
      "epoch": 2.397712274527057,
      "grad_norm": 0.19422180950641632,
      "learning_rate": 1.0053126958098362e-05,
      "loss": 0.0775,
      "step": 119900
    },
    {
      "epoch": 2.397912250529936,
      "grad_norm": 0.10652735084295273,
      "learning_rate": 1.0049794024717033e-05,
      "loss": 0.0752,
      "step": 119910
    },
    {
      "epoch": 2.398112226532816,
      "grad_norm": 0.14105042815208435,
      "learning_rate": 1.0046461091335708e-05,
      "loss": 0.0624,
      "step": 119920
    },
    {
      "epoch": 2.3983122025356955,
      "grad_norm": 0.09365486353635788,
      "learning_rate": 1.0043128157954379e-05,
      "loss": 0.086,
      "step": 119930
    },
    {
      "epoch": 2.3985121785385752,
      "grad_norm": 0.12397295981645584,
      "learning_rate": 1.0039795224573052e-05,
      "loss": 0.1294,
      "step": 119940
    },
    {
      "epoch": 2.398712154541455,
      "grad_norm": 0.15649138391017914,
      "learning_rate": 1.0036462291191723e-05,
      "loss": 0.0932,
      "step": 119950
    },
    {
      "epoch": 2.3989121305443346,
      "grad_norm": 0.23110562562942505,
      "learning_rate": 1.0033129357810396e-05,
      "loss": 0.1153,
      "step": 119960
    },
    {
      "epoch": 2.3991121065472143,
      "grad_norm": 0.07092665880918503,
      "learning_rate": 1.002979642442907e-05,
      "loss": 0.0485,
      "step": 119970
    },
    {
      "epoch": 2.399312082550094,
      "grad_norm": 0.07673909515142441,
      "learning_rate": 1.002646349104774e-05,
      "loss": 0.0702,
      "step": 119980
    },
    {
      "epoch": 2.3995120585529737,
      "grad_norm": 0.15747733414173126,
      "learning_rate": 1.0023130557666414e-05,
      "loss": 0.0715,
      "step": 119990
    },
    {
      "epoch": 2.3997120345558534,
      "grad_norm": 0.10149489343166351,
      "learning_rate": 1.0019797624285087e-05,
      "loss": 0.0501,
      "step": 120000
    },
    {
      "epoch": 2.399912010558733,
      "grad_norm": 0.17116090655326843,
      "learning_rate": 1.0016464690903758e-05,
      "loss": 0.0583,
      "step": 120010
    },
    {
      "epoch": 2.4001119865616127,
      "grad_norm": 0.20037785172462463,
      "learning_rate": 1.0013131757522431e-05,
      "loss": 0.0629,
      "step": 120020
    },
    {
      "epoch": 2.4003119625644924,
      "grad_norm": 0.11729210615158081,
      "learning_rate": 1.0009798824141104e-05,
      "loss": 0.0666,
      "step": 120030
    },
    {
      "epoch": 2.400511938567372,
      "grad_norm": 0.08493577688932419,
      "learning_rate": 1.0006465890759777e-05,
      "loss": 0.0548,
      "step": 120040
    },
    {
      "epoch": 2.400711914570252,
      "grad_norm": 0.10247498005628586,
      "learning_rate": 1.0003132957378448e-05,
      "loss": 0.0719,
      "step": 120050
    },
    {
      "epoch": 2.400911890573131,
      "grad_norm": 0.21567122638225555,
      "learning_rate": 9.99980002399712e-06,
      "loss": 0.1438,
      "step": 120060
    },
    {
      "epoch": 2.4011118665760107,
      "grad_norm": 0.16488023102283478,
      "learning_rate": 9.996467090615794e-06,
      "loss": 0.1118,
      "step": 120070
    },
    {
      "epoch": 2.4013118425788904,
      "grad_norm": 0.126543790102005,
      "learning_rate": 9.993134157234466e-06,
      "loss": 0.0641,
      "step": 120080
    },
    {
      "epoch": 2.40151181858177,
      "grad_norm": 0.09856507927179337,
      "learning_rate": 9.989801223853137e-06,
      "loss": 0.0738,
      "step": 120090
    },
    {
      "epoch": 2.40171179458465,
      "grad_norm": 0.20386028289794922,
      "learning_rate": 9.98646829047181e-06,
      "loss": 0.0468,
      "step": 120100
    },
    {
      "epoch": 2.4019117705875295,
      "grad_norm": 0.11976253986358643,
      "learning_rate": 9.983135357090483e-06,
      "loss": 0.0643,
      "step": 120110
    },
    {
      "epoch": 2.402111746590409,
      "grad_norm": 0.06177535653114319,
      "learning_rate": 9.979802423709156e-06,
      "loss": 0.0479,
      "step": 120120
    },
    {
      "epoch": 2.402311722593289,
      "grad_norm": 0.10527001321315765,
      "learning_rate": 9.976469490327827e-06,
      "loss": 0.0986,
      "step": 120130
    },
    {
      "epoch": 2.4025116985961685,
      "grad_norm": 0.19274483621120453,
      "learning_rate": 9.9731365569465e-06,
      "loss": 0.0706,
      "step": 120140
    },
    {
      "epoch": 2.402711674599048,
      "grad_norm": 0.11369261890649796,
      "learning_rate": 9.969803623565173e-06,
      "loss": 0.072,
      "step": 120150
    },
    {
      "epoch": 2.402911650601928,
      "grad_norm": 0.059726737439632416,
      "learning_rate": 9.966470690183845e-06,
      "loss": 0.063,
      "step": 120160
    },
    {
      "epoch": 2.4031116266048076,
      "grad_norm": 0.12140829861164093,
      "learning_rate": 9.963137756802518e-06,
      "loss": 0.0705,
      "step": 120170
    },
    {
      "epoch": 2.403311602607687,
      "grad_norm": 0.06808708608150482,
      "learning_rate": 9.95980482342119e-06,
      "loss": 0.0645,
      "step": 120180
    },
    {
      "epoch": 2.4035115786105665,
      "grad_norm": 0.06559915095567703,
      "learning_rate": 9.956471890039862e-06,
      "loss": 0.0523,
      "step": 120190
    },
    {
      "epoch": 2.403711554613446,
      "grad_norm": 0.27509793639183044,
      "learning_rate": 9.953138956658535e-06,
      "loss": 0.0663,
      "step": 120200
    },
    {
      "epoch": 2.403911530616326,
      "grad_norm": 0.2679852843284607,
      "learning_rate": 9.949806023277206e-06,
      "loss": 0.0817,
      "step": 120210
    },
    {
      "epoch": 2.4041115066192056,
      "grad_norm": 0.19836623966693878,
      "learning_rate": 9.946473089895881e-06,
      "loss": 0.0713,
      "step": 120220
    },
    {
      "epoch": 2.4043114826220853,
      "grad_norm": 0.15364333987236023,
      "learning_rate": 9.943140156514552e-06,
      "loss": 0.0464,
      "step": 120230
    },
    {
      "epoch": 2.404511458624965,
      "grad_norm": 0.12081363052129745,
      "learning_rate": 9.939807223133224e-06,
      "loss": 0.0564,
      "step": 120240
    },
    {
      "epoch": 2.4047114346278446,
      "grad_norm": 0.10747922211885452,
      "learning_rate": 9.936474289751897e-06,
      "loss": 0.069,
      "step": 120250
    },
    {
      "epoch": 2.4049114106307243,
      "grad_norm": 0.21217940747737885,
      "learning_rate": 9.93314135637057e-06,
      "loss": 0.1035,
      "step": 120260
    },
    {
      "epoch": 2.405111386633604,
      "grad_norm": 0.24905817210674286,
      "learning_rate": 9.929808422989243e-06,
      "loss": 0.0898,
      "step": 120270
    },
    {
      "epoch": 2.4053113626364837,
      "grad_norm": 0.14637072384357452,
      "learning_rate": 9.926475489607914e-06,
      "loss": 0.0656,
      "step": 120280
    },
    {
      "epoch": 2.4055113386393634,
      "grad_norm": 0.12539081275463104,
      "learning_rate": 9.923142556226587e-06,
      "loss": 0.0898,
      "step": 120290
    },
    {
      "epoch": 2.405711314642243,
      "grad_norm": 0.26894158124923706,
      "learning_rate": 9.91980962284526e-06,
      "loss": 0.085,
      "step": 120300
    },
    {
      "epoch": 2.4059112906451228,
      "grad_norm": 0.0789092481136322,
      "learning_rate": 9.916476689463931e-06,
      "loss": 0.0594,
      "step": 120310
    },
    {
      "epoch": 2.4061112666480025,
      "grad_norm": 0.08626630902290344,
      "learning_rate": 9.913143756082603e-06,
      "loss": 0.0756,
      "step": 120320
    },
    {
      "epoch": 2.406311242650882,
      "grad_norm": 0.05928327515721321,
      "learning_rate": 9.909810822701277e-06,
      "loss": 0.0712,
      "step": 120330
    },
    {
      "epoch": 2.4065112186537614,
      "grad_norm": 0.07208411395549774,
      "learning_rate": 9.906477889319949e-06,
      "loss": 0.0505,
      "step": 120340
    },
    {
      "epoch": 2.406711194656641,
      "grad_norm": 0.06831659376621246,
      "learning_rate": 9.903144955938622e-06,
      "loss": 0.0828,
      "step": 120350
    },
    {
      "epoch": 2.4069111706595208,
      "grad_norm": 0.09486070275306702,
      "learning_rate": 9.899812022557293e-06,
      "loss": 0.0646,
      "step": 120360
    },
    {
      "epoch": 2.4071111466624004,
      "grad_norm": 0.08898819983005524,
      "learning_rate": 9.896479089175966e-06,
      "loss": 0.1036,
      "step": 120370
    },
    {
      "epoch": 2.40731112266528,
      "grad_norm": 0.1546182930469513,
      "learning_rate": 9.893146155794639e-06,
      "loss": 0.0541,
      "step": 120380
    },
    {
      "epoch": 2.40751109866816,
      "grad_norm": 0.18513797223567963,
      "learning_rate": 9.88981322241331e-06,
      "loss": 0.067,
      "step": 120390
    },
    {
      "epoch": 2.4077110746710395,
      "grad_norm": 0.1466643363237381,
      "learning_rate": 9.886480289031983e-06,
      "loss": 0.0641,
      "step": 120400
    },
    {
      "epoch": 2.407911050673919,
      "grad_norm": 0.2518708109855652,
      "learning_rate": 9.883147355650656e-06,
      "loss": 0.0701,
      "step": 120410
    },
    {
      "epoch": 2.408111026676799,
      "grad_norm": 0.11517895013093948,
      "learning_rate": 9.879814422269328e-06,
      "loss": 0.0586,
      "step": 120420
    },
    {
      "epoch": 2.4083110026796786,
      "grad_norm": 0.1172872930765152,
      "learning_rate": 9.876481488888e-06,
      "loss": 0.0577,
      "step": 120430
    },
    {
      "epoch": 2.4085109786825583,
      "grad_norm": 0.2551302909851074,
      "learning_rate": 9.873148555506674e-06,
      "loss": 0.0659,
      "step": 120440
    },
    {
      "epoch": 2.4087109546854375,
      "grad_norm": 0.18062183260917664,
      "learning_rate": 9.869815622125347e-06,
      "loss": 0.077,
      "step": 120450
    },
    {
      "epoch": 2.408910930688317,
      "grad_norm": 0.22894242405891418,
      "learning_rate": 9.866482688744018e-06,
      "loss": 0.0769,
      "step": 120460
    },
    {
      "epoch": 2.409110906691197,
      "grad_norm": 0.1652405709028244,
      "learning_rate": 9.86314975536269e-06,
      "loss": 0.0505,
      "step": 120470
    },
    {
      "epoch": 2.4093108826940766,
      "grad_norm": 0.19037990272045135,
      "learning_rate": 9.859816821981364e-06,
      "loss": 0.0922,
      "step": 120480
    },
    {
      "epoch": 2.4095108586969562,
      "grad_norm": 0.10682611912488937,
      "learning_rate": 9.856483888600035e-06,
      "loss": 0.048,
      "step": 120490
    },
    {
      "epoch": 2.409710834699836,
      "grad_norm": 0.1859898716211319,
      "learning_rate": 9.853150955218708e-06,
      "loss": 0.0954,
      "step": 120500
    },
    {
      "epoch": 2.4099108107027156,
      "grad_norm": 0.12651774287223816,
      "learning_rate": 9.84981802183738e-06,
      "loss": 0.1833,
      "step": 120510
    },
    {
      "epoch": 2.4101107867055953,
      "grad_norm": 0.05971677228808403,
      "learning_rate": 9.846485088456052e-06,
      "loss": 0.29,
      "step": 120520
    },
    {
      "epoch": 2.410310762708475,
      "grad_norm": 0.06213568523526192,
      "learning_rate": 9.843152155074725e-06,
      "loss": 0.091,
      "step": 120530
    },
    {
      "epoch": 2.4105107387113547,
      "grad_norm": 0.17306113243103027,
      "learning_rate": 9.839819221693397e-06,
      "loss": 0.0583,
      "step": 120540
    },
    {
      "epoch": 2.4107107147142344,
      "grad_norm": 0.10743916034698486,
      "learning_rate": 9.83648628831207e-06,
      "loss": 0.0758,
      "step": 120550
    },
    {
      "epoch": 2.410910690717114,
      "grad_norm": 0.1185242086648941,
      "learning_rate": 9.833153354930743e-06,
      "loss": 0.0906,
      "step": 120560
    },
    {
      "epoch": 2.4111106667199937,
      "grad_norm": 0.07158117741346359,
      "learning_rate": 9.829820421549414e-06,
      "loss": 0.0776,
      "step": 120570
    },
    {
      "epoch": 2.4113106427228734,
      "grad_norm": 0.20159994065761566,
      "learning_rate": 9.826487488168087e-06,
      "loss": 0.0717,
      "step": 120580
    },
    {
      "epoch": 2.411510618725753,
      "grad_norm": 0.06001421436667442,
      "learning_rate": 9.82315455478676e-06,
      "loss": 0.073,
      "step": 120590
    },
    {
      "epoch": 2.411710594728633,
      "grad_norm": 0.2352185696363449,
      "learning_rate": 9.819821621405431e-06,
      "loss": 0.089,
      "step": 120600
    },
    {
      "epoch": 2.411910570731512,
      "grad_norm": 0.1911262720823288,
      "learning_rate": 9.816488688024104e-06,
      "loss": 0.0883,
      "step": 120610
    },
    {
      "epoch": 2.4121105467343917,
      "grad_norm": 0.0660574734210968,
      "learning_rate": 9.813155754642776e-06,
      "loss": 0.1188,
      "step": 120620
    },
    {
      "epoch": 2.4123105227372714,
      "grad_norm": 0.17274782061576843,
      "learning_rate": 9.809822821261449e-06,
      "loss": 0.0809,
      "step": 120630
    },
    {
      "epoch": 2.412510498740151,
      "grad_norm": 0.2423929125070572,
      "learning_rate": 9.806489887880122e-06,
      "loss": 0.1185,
      "step": 120640
    },
    {
      "epoch": 2.412710474743031,
      "grad_norm": 0.11533895134925842,
      "learning_rate": 9.803156954498793e-06,
      "loss": 0.0932,
      "step": 120650
    },
    {
      "epoch": 2.4129104507459105,
      "grad_norm": 0.25773972272872925,
      "learning_rate": 9.799824021117466e-06,
      "loss": 0.0872,
      "step": 120660
    },
    {
      "epoch": 2.41311042674879,
      "grad_norm": 0.22162827849388123,
      "learning_rate": 9.796491087736139e-06,
      "loss": 0.066,
      "step": 120670
    },
    {
      "epoch": 2.41331040275167,
      "grad_norm": 0.09260919690132141,
      "learning_rate": 9.793158154354812e-06,
      "loss": 0.0895,
      "step": 120680
    },
    {
      "epoch": 2.4135103787545495,
      "grad_norm": 0.06691577285528183,
      "learning_rate": 9.789825220973483e-06,
      "loss": 0.0692,
      "step": 120690
    },
    {
      "epoch": 2.4137103547574292,
      "grad_norm": 0.1419076919555664,
      "learning_rate": 9.786492287592155e-06,
      "loss": 0.0581,
      "step": 120700
    },
    {
      "epoch": 2.413910330760309,
      "grad_norm": 0.14226335287094116,
      "learning_rate": 9.78315935421083e-06,
      "loss": 0.0569,
      "step": 120710
    },
    {
      "epoch": 2.4141103067631886,
      "grad_norm": 0.13897855579853058,
      "learning_rate": 9.7798264208295e-06,
      "loss": 0.0546,
      "step": 120720
    },
    {
      "epoch": 2.414310282766068,
      "grad_norm": 0.13039816915988922,
      "learning_rate": 9.776493487448174e-06,
      "loss": 0.0492,
      "step": 120730
    },
    {
      "epoch": 2.4145102587689475,
      "grad_norm": 0.15570613741874695,
      "learning_rate": 9.773160554066845e-06,
      "loss": 0.0822,
      "step": 120740
    },
    {
      "epoch": 2.4147102347718272,
      "grad_norm": 0.21688057482242584,
      "learning_rate": 9.769827620685518e-06,
      "loss": 0.0896,
      "step": 120750
    },
    {
      "epoch": 2.414910210774707,
      "grad_norm": 0.13252557814121246,
      "learning_rate": 9.766494687304191e-06,
      "loss": 0.0563,
      "step": 120760
    },
    {
      "epoch": 2.4151101867775866,
      "grad_norm": 0.0724339410662651,
      "learning_rate": 9.763161753922862e-06,
      "loss": 0.0521,
      "step": 120770
    },
    {
      "epoch": 2.4153101627804663,
      "grad_norm": 0.2905735671520233,
      "learning_rate": 9.759828820541535e-06,
      "loss": 0.0569,
      "step": 120780
    },
    {
      "epoch": 2.415510138783346,
      "grad_norm": 0.20576347410678864,
      "learning_rate": 9.756495887160208e-06,
      "loss": 0.0683,
      "step": 120790
    },
    {
      "epoch": 2.4157101147862257,
      "grad_norm": 0.19315633177757263,
      "learning_rate": 9.75316295377888e-06,
      "loss": 0.0902,
      "step": 120800
    },
    {
      "epoch": 2.4159100907891053,
      "grad_norm": 0.2446826845407486,
      "learning_rate": 9.749830020397553e-06,
      "loss": 0.0786,
      "step": 120810
    },
    {
      "epoch": 2.416110066791985,
      "grad_norm": 0.16875037550926208,
      "learning_rate": 9.746497087016226e-06,
      "loss": 0.0653,
      "step": 120820
    },
    {
      "epoch": 2.4163100427948647,
      "grad_norm": 0.12177561968564987,
      "learning_rate": 9.743164153634897e-06,
      "loss": 0.0862,
      "step": 120830
    },
    {
      "epoch": 2.4165100187977444,
      "grad_norm": 0.24612675607204437,
      "learning_rate": 9.73983122025357e-06,
      "loss": 0.0951,
      "step": 120840
    },
    {
      "epoch": 2.416709994800624,
      "grad_norm": 0.0932409018278122,
      "learning_rate": 9.736498286872241e-06,
      "loss": 0.0813,
      "step": 120850
    },
    {
      "epoch": 2.416909970803504,
      "grad_norm": 0.15293914079666138,
      "learning_rate": 9.733165353490916e-06,
      "loss": 0.0469,
      "step": 120860
    },
    {
      "epoch": 2.4171099468063835,
      "grad_norm": 0.1874479353427887,
      "learning_rate": 9.729832420109587e-06,
      "loss": 0.0928,
      "step": 120870
    },
    {
      "epoch": 2.4173099228092627,
      "grad_norm": 0.13988512754440308,
      "learning_rate": 9.726499486728259e-06,
      "loss": 0.0405,
      "step": 120880
    },
    {
      "epoch": 2.4175098988121424,
      "grad_norm": 0.11752472072839737,
      "learning_rate": 9.723166553346932e-06,
      "loss": 0.0474,
      "step": 120890
    },
    {
      "epoch": 2.417709874815022,
      "grad_norm": 0.11932452023029327,
      "learning_rate": 9.719833619965605e-06,
      "loss": 0.0831,
      "step": 120900
    },
    {
      "epoch": 2.4179098508179018,
      "grad_norm": 0.08761364221572876,
      "learning_rate": 9.716500686584278e-06,
      "loss": 0.0508,
      "step": 120910
    },
    {
      "epoch": 2.4181098268207815,
      "grad_norm": 0.19145922362804413,
      "learning_rate": 9.713167753202949e-06,
      "loss": 0.0584,
      "step": 120920
    },
    {
      "epoch": 2.418309802823661,
      "grad_norm": 0.14978492259979248,
      "learning_rate": 9.709834819821622e-06,
      "loss": 0.0703,
      "step": 120930
    },
    {
      "epoch": 2.418509778826541,
      "grad_norm": 0.05397630110383034,
      "learning_rate": 9.706501886440295e-06,
      "loss": 0.073,
      "step": 120940
    },
    {
      "epoch": 2.4187097548294205,
      "grad_norm": 0.21708709001541138,
      "learning_rate": 9.703168953058966e-06,
      "loss": 0.0633,
      "step": 120950
    },
    {
      "epoch": 2.4189097308323,
      "grad_norm": 0.1807544082403183,
      "learning_rate": 9.69983601967764e-06,
      "loss": 0.1692,
      "step": 120960
    },
    {
      "epoch": 2.41910970683518,
      "grad_norm": 0.18830126523971558,
      "learning_rate": 9.696503086296312e-06,
      "loss": 0.0716,
      "step": 120970
    },
    {
      "epoch": 2.4193096828380596,
      "grad_norm": 0.1560036689043045,
      "learning_rate": 9.693170152914984e-06,
      "loss": 0.0547,
      "step": 120980
    },
    {
      "epoch": 2.4195096588409393,
      "grad_norm": 0.3241613507270813,
      "learning_rate": 9.689837219533657e-06,
      "loss": 0.1184,
      "step": 120990
    },
    {
      "epoch": 2.4197096348438185,
      "grad_norm": 0.12938867509365082,
      "learning_rate": 9.686504286152328e-06,
      "loss": 0.0542,
      "step": 121000
    },
    {
      "epoch": 2.419909610846698,
      "grad_norm": 0.2181103229522705,
      "learning_rate": 9.683171352771003e-06,
      "loss": 0.0585,
      "step": 121010
    },
    {
      "epoch": 2.420109586849578,
      "grad_norm": 0.08109850436449051,
      "learning_rate": 9.679838419389674e-06,
      "loss": 0.0702,
      "step": 121020
    },
    {
      "epoch": 2.4203095628524576,
      "grad_norm": 0.1505826711654663,
      "learning_rate": 9.676505486008345e-06,
      "loss": 0.0645,
      "step": 121030
    },
    {
      "epoch": 2.4205095388553373,
      "grad_norm": 0.12705810368061066,
      "learning_rate": 9.673172552627018e-06,
      "loss": 0.0904,
      "step": 121040
    },
    {
      "epoch": 2.420709514858217,
      "grad_norm": 0.11429094523191452,
      "learning_rate": 9.669839619245691e-06,
      "loss": 0.076,
      "step": 121050
    },
    {
      "epoch": 2.4209094908610966,
      "grad_norm": 0.10990357398986816,
      "learning_rate": 9.666506685864364e-06,
      "loss": 0.0342,
      "step": 121060
    },
    {
      "epoch": 2.4211094668639763,
      "grad_norm": 0.32492727041244507,
      "learning_rate": 9.663173752483036e-06,
      "loss": 0.092,
      "step": 121070
    },
    {
      "epoch": 2.421309442866856,
      "grad_norm": 0.23715662956237793,
      "learning_rate": 9.659840819101709e-06,
      "loss": 0.0608,
      "step": 121080
    },
    {
      "epoch": 2.4215094188697357,
      "grad_norm": 0.08593472093343735,
      "learning_rate": 9.656507885720382e-06,
      "loss": 0.0723,
      "step": 121090
    },
    {
      "epoch": 2.4217093948726154,
      "grad_norm": 0.21028245985507965,
      "learning_rate": 9.653174952339053e-06,
      "loss": 0.0786,
      "step": 121100
    },
    {
      "epoch": 2.421909370875495,
      "grad_norm": 0.1375889629125595,
      "learning_rate": 9.649842018957724e-06,
      "loss": 0.0735,
      "step": 121110
    },
    {
      "epoch": 2.4221093468783748,
      "grad_norm": 0.13838396966457367,
      "learning_rate": 9.646509085576399e-06,
      "loss": 0.0592,
      "step": 121120
    },
    {
      "epoch": 2.4223093228812544,
      "grad_norm": 0.19030269980430603,
      "learning_rate": 9.64317615219507e-06,
      "loss": 0.0685,
      "step": 121130
    },
    {
      "epoch": 2.422509298884134,
      "grad_norm": 0.1659109741449356,
      "learning_rate": 9.639843218813743e-06,
      "loss": 0.0822,
      "step": 121140
    },
    {
      "epoch": 2.4227092748870134,
      "grad_norm": 0.1510760337114334,
      "learning_rate": 9.636510285432414e-06,
      "loss": 0.0277,
      "step": 121150
    },
    {
      "epoch": 2.422909250889893,
      "grad_norm": 0.10266570746898651,
      "learning_rate": 9.633177352051087e-06,
      "loss": 0.0693,
      "step": 121160
    },
    {
      "epoch": 2.4231092268927727,
      "grad_norm": 0.2882586121559143,
      "learning_rate": 9.62984441866976e-06,
      "loss": 0.1046,
      "step": 121170
    },
    {
      "epoch": 2.4233092028956524,
      "grad_norm": 0.0639238953590393,
      "learning_rate": 9.626511485288432e-06,
      "loss": 0.0648,
      "step": 121180
    },
    {
      "epoch": 2.423509178898532,
      "grad_norm": 0.09364533424377441,
      "learning_rate": 9.623178551907105e-06,
      "loss": 0.0497,
      "step": 121190
    },
    {
      "epoch": 2.423709154901412,
      "grad_norm": 0.22139158844947815,
      "learning_rate": 9.62017891186391e-06,
      "loss": 0.083,
      "step": 121200
    },
    {
      "epoch": 2.4239091309042915,
      "grad_norm": 0.13843640685081482,
      "learning_rate": 9.616845978482583e-06,
      "loss": 0.0532,
      "step": 121210
    },
    {
      "epoch": 2.424109106907171,
      "grad_norm": 0.07405245304107666,
      "learning_rate": 9.613513045101254e-06,
      "loss": 0.0662,
      "step": 121220
    },
    {
      "epoch": 2.424309082910051,
      "grad_norm": 0.08862873911857605,
      "learning_rate": 9.610180111719927e-06,
      "loss": 0.081,
      "step": 121230
    },
    {
      "epoch": 2.4245090589129306,
      "grad_norm": 0.12661738693714142,
      "learning_rate": 9.6068471783386e-06,
      "loss": 0.067,
      "step": 121240
    },
    {
      "epoch": 2.4247090349158102,
      "grad_norm": 0.14436298608779907,
      "learning_rate": 9.603514244957272e-06,
      "loss": 0.0785,
      "step": 121250
    },
    {
      "epoch": 2.42490901091869,
      "grad_norm": 0.12353356927633286,
      "learning_rate": 9.600181311575945e-06,
      "loss": 0.0386,
      "step": 121260
    },
    {
      "epoch": 2.425108986921569,
      "grad_norm": 0.14562258124351501,
      "learning_rate": 9.596848378194618e-06,
      "loss": 0.0669,
      "step": 121270
    },
    {
      "epoch": 2.425308962924449,
      "grad_norm": 0.15902920067310333,
      "learning_rate": 9.593515444813289e-06,
      "loss": 0.1071,
      "step": 121280
    },
    {
      "epoch": 2.4255089389273286,
      "grad_norm": 0.1411118358373642,
      "learning_rate": 9.590182511431962e-06,
      "loss": 0.0782,
      "step": 121290
    },
    {
      "epoch": 2.4257089149302082,
      "grad_norm": 0.09644686430692673,
      "learning_rate": 9.586849578050635e-06,
      "loss": 0.0648,
      "step": 121300
    },
    {
      "epoch": 2.425908890933088,
      "grad_norm": 0.08504743874073029,
      "learning_rate": 9.583516644669306e-06,
      "loss": 0.0611,
      "step": 121310
    },
    {
      "epoch": 2.4261088669359676,
      "grad_norm": 0.09496304392814636,
      "learning_rate": 9.58018371128798e-06,
      "loss": 0.0793,
      "step": 121320
    },
    {
      "epoch": 2.4263088429388473,
      "grad_norm": 0.11068391799926758,
      "learning_rate": 9.57685077790665e-06,
      "loss": 0.0901,
      "step": 121330
    },
    {
      "epoch": 2.426508818941727,
      "grad_norm": 0.09947112202644348,
      "learning_rate": 9.573517844525324e-06,
      "loss": 0.0604,
      "step": 121340
    },
    {
      "epoch": 2.4267087949446067,
      "grad_norm": 0.05853557959198952,
      "learning_rate": 9.570184911143997e-06,
      "loss": 0.0583,
      "step": 121350
    },
    {
      "epoch": 2.4269087709474864,
      "grad_norm": 0.1787528246641159,
      "learning_rate": 9.566851977762668e-06,
      "loss": 0.1018,
      "step": 121360
    },
    {
      "epoch": 2.427108746950366,
      "grad_norm": 0.20563775300979614,
      "learning_rate": 9.563519044381341e-06,
      "loss": 0.1019,
      "step": 121370
    },
    {
      "epoch": 2.4273087229532457,
      "grad_norm": 0.2828686237335205,
      "learning_rate": 9.560186111000014e-06,
      "loss": 0.0768,
      "step": 121380
    },
    {
      "epoch": 2.4275086989561254,
      "grad_norm": 0.19029539823532104,
      "learning_rate": 9.556853177618687e-06,
      "loss": 0.0774,
      "step": 121390
    },
    {
      "epoch": 2.427708674959005,
      "grad_norm": 0.08243324607610703,
      "learning_rate": 9.553520244237358e-06,
      "loss": 0.0509,
      "step": 121400
    },
    {
      "epoch": 2.427908650961885,
      "grad_norm": 0.0847030058503151,
      "learning_rate": 9.55018731085603e-06,
      "loss": 0.0511,
      "step": 121410
    },
    {
      "epoch": 2.428108626964764,
      "grad_norm": 0.13963837921619415,
      "learning_rate": 9.546854377474704e-06,
      "loss": 0.0728,
      "step": 121420
    },
    {
      "epoch": 2.4283086029676437,
      "grad_norm": 0.08339783549308777,
      "learning_rate": 9.543521444093376e-06,
      "loss": 0.0623,
      "step": 121430
    },
    {
      "epoch": 2.4285085789705234,
      "grad_norm": 0.10740821808576584,
      "learning_rate": 9.540188510712049e-06,
      "loss": 0.0596,
      "step": 121440
    },
    {
      "epoch": 2.428708554973403,
      "grad_norm": 0.14439164102077484,
      "learning_rate": 9.53685557733072e-06,
      "loss": 0.0759,
      "step": 121450
    },
    {
      "epoch": 2.428908530976283,
      "grad_norm": 0.18012794852256775,
      "learning_rate": 9.533522643949393e-06,
      "loss": 0.0611,
      "step": 121460
    },
    {
      "epoch": 2.4291085069791625,
      "grad_norm": 0.09850236773490906,
      "learning_rate": 9.530189710568066e-06,
      "loss": 0.0496,
      "step": 121470
    },
    {
      "epoch": 2.429308482982042,
      "grad_norm": 0.07489072531461716,
      "learning_rate": 9.526856777186737e-06,
      "loss": 0.0548,
      "step": 121480
    },
    {
      "epoch": 2.429508458984922,
      "grad_norm": 0.25909221172332764,
      "learning_rate": 9.52352384380541e-06,
      "loss": 0.0862,
      "step": 121490
    },
    {
      "epoch": 2.4297084349878015,
      "grad_norm": 0.11630450934171677,
      "learning_rate": 9.520190910424083e-06,
      "loss": 0.0871,
      "step": 121500
    },
    {
      "epoch": 2.4299084109906812,
      "grad_norm": 0.21411579847335815,
      "learning_rate": 9.516857977042755e-06,
      "loss": 0.0699,
      "step": 121510
    },
    {
      "epoch": 2.430108386993561,
      "grad_norm": 0.213815838098526,
      "learning_rate": 9.513525043661428e-06,
      "loss": 0.1013,
      "step": 121520
    },
    {
      "epoch": 2.4303083629964406,
      "grad_norm": 0.17330996692180634,
      "learning_rate": 9.5101921102801e-06,
      "loss": 0.0641,
      "step": 121530
    },
    {
      "epoch": 2.43050833899932,
      "grad_norm": 0.11048507690429688,
      "learning_rate": 9.506859176898772e-06,
      "loss": 0.0984,
      "step": 121540
    },
    {
      "epoch": 2.4307083150021995,
      "grad_norm": 0.19293420016765594,
      "learning_rate": 9.503526243517445e-06,
      "loss": 0.0675,
      "step": 121550
    },
    {
      "epoch": 2.430908291005079,
      "grad_norm": 0.12241017818450928,
      "learning_rate": 9.500193310136116e-06,
      "loss": 0.0915,
      "step": 121560
    },
    {
      "epoch": 2.431108267007959,
      "grad_norm": 0.09870514273643494,
      "learning_rate": 9.496860376754791e-06,
      "loss": 0.0796,
      "step": 121570
    },
    {
      "epoch": 2.4313082430108386,
      "grad_norm": 0.11254362016916275,
      "learning_rate": 9.493527443373462e-06,
      "loss": 0.0541,
      "step": 121580
    },
    {
      "epoch": 2.4315082190137183,
      "grad_norm": 0.23827946186065674,
      "learning_rate": 9.490194509992134e-06,
      "loss": 0.1211,
      "step": 121590
    },
    {
      "epoch": 2.431708195016598,
      "grad_norm": 0.1655343919992447,
      "learning_rate": 9.486861576610807e-06,
      "loss": 0.0772,
      "step": 121600
    },
    {
      "epoch": 2.4319081710194776,
      "grad_norm": 0.1307835727930069,
      "learning_rate": 9.48352864322948e-06,
      "loss": 0.0683,
      "step": 121610
    },
    {
      "epoch": 2.4321081470223573,
      "grad_norm": 0.18988335132598877,
      "learning_rate": 9.480195709848153e-06,
      "loss": 0.0762,
      "step": 121620
    },
    {
      "epoch": 2.432308123025237,
      "grad_norm": 0.1010245680809021,
      "learning_rate": 9.476862776466824e-06,
      "loss": 0.0606,
      "step": 121630
    },
    {
      "epoch": 2.4325080990281167,
      "grad_norm": 0.21103009581565857,
      "learning_rate": 9.473529843085497e-06,
      "loss": 0.0598,
      "step": 121640
    },
    {
      "epoch": 2.4327080750309964,
      "grad_norm": 0.14049653708934784,
      "learning_rate": 9.47019690970417e-06,
      "loss": 0.0942,
      "step": 121650
    },
    {
      "epoch": 2.432908051033876,
      "grad_norm": 0.18025346100330353,
      "learning_rate": 9.466863976322841e-06,
      "loss": 0.0854,
      "step": 121660
    },
    {
      "epoch": 2.4331080270367558,
      "grad_norm": 0.07927899807691574,
      "learning_rate": 9.463531042941514e-06,
      "loss": 0.0589,
      "step": 121670
    },
    {
      "epoch": 2.4333080030396355,
      "grad_norm": 0.07927227765321732,
      "learning_rate": 9.460198109560187e-06,
      "loss": 0.0441,
      "step": 121680
    },
    {
      "epoch": 2.433507979042515,
      "grad_norm": 0.055662427097558975,
      "learning_rate": 9.456865176178859e-06,
      "loss": 0.0419,
      "step": 121690
    },
    {
      "epoch": 2.4337079550453944,
      "grad_norm": 0.15429626405239105,
      "learning_rate": 9.453532242797532e-06,
      "loss": 0.0638,
      "step": 121700
    },
    {
      "epoch": 2.433907931048274,
      "grad_norm": 0.10982160270214081,
      "learning_rate": 9.450199309416203e-06,
      "loss": 0.0591,
      "step": 121710
    },
    {
      "epoch": 2.4341079070511538,
      "grad_norm": 0.17679542303085327,
      "learning_rate": 9.446866376034878e-06,
      "loss": 0.1057,
      "step": 121720
    },
    {
      "epoch": 2.4343078830540335,
      "grad_norm": 0.15366621315479279,
      "learning_rate": 9.443533442653549e-06,
      "loss": 0.067,
      "step": 121730
    },
    {
      "epoch": 2.434507859056913,
      "grad_norm": 0.20759670436382294,
      "learning_rate": 9.44020050927222e-06,
      "loss": 0.0746,
      "step": 121740
    },
    {
      "epoch": 2.434707835059793,
      "grad_norm": 0.2524361312389374,
      "learning_rate": 9.436867575890893e-06,
      "loss": 0.081,
      "step": 121750
    },
    {
      "epoch": 2.4349078110626725,
      "grad_norm": 0.09086420387029648,
      "learning_rate": 9.433867935847699e-06,
      "loss": 0.1051,
      "step": 121760
    },
    {
      "epoch": 2.435107787065552,
      "grad_norm": 0.17799878120422363,
      "learning_rate": 9.430535002466372e-06,
      "loss": 0.1412,
      "step": 121770
    },
    {
      "epoch": 2.435307763068432,
      "grad_norm": 0.14620502293109894,
      "learning_rate": 9.427202069085043e-06,
      "loss": 0.0726,
      "step": 121780
    },
    {
      "epoch": 2.4355077390713116,
      "grad_norm": 0.1737367957830429,
      "learning_rate": 9.423869135703716e-06,
      "loss": 0.0775,
      "step": 121790
    },
    {
      "epoch": 2.4357077150741913,
      "grad_norm": 0.09283769130706787,
      "learning_rate": 9.420536202322389e-06,
      "loss": 0.0952,
      "step": 121800
    },
    {
      "epoch": 2.4359076910770705,
      "grad_norm": 0.09114988148212433,
      "learning_rate": 9.41720326894106e-06,
      "loss": 0.0454,
      "step": 121810
    },
    {
      "epoch": 2.43610766707995,
      "grad_norm": 0.10206014662981033,
      "learning_rate": 9.413870335559733e-06,
      "loss": 0.0647,
      "step": 121820
    },
    {
      "epoch": 2.43630764308283,
      "grad_norm": 0.1873684823513031,
      "learning_rate": 9.410537402178406e-06,
      "loss": 0.0726,
      "step": 121830
    },
    {
      "epoch": 2.4365076190857096,
      "grad_norm": 0.13257980346679688,
      "learning_rate": 9.407204468797078e-06,
      "loss": 0.0531,
      "step": 121840
    },
    {
      "epoch": 2.4367075950885893,
      "grad_norm": 0.09160587936639786,
      "learning_rate": 9.40387153541575e-06,
      "loss": 0.0738,
      "step": 121850
    },
    {
      "epoch": 2.436907571091469,
      "grad_norm": 0.19421175122261047,
      "learning_rate": 9.400538602034424e-06,
      "loss": 0.198,
      "step": 121860
    },
    {
      "epoch": 2.4371075470943486,
      "grad_norm": 0.12067276984453201,
      "learning_rate": 9.397205668653097e-06,
      "loss": 0.0844,
      "step": 121870
    },
    {
      "epoch": 2.4373075230972283,
      "grad_norm": 0.08363530039787292,
      "learning_rate": 9.393872735271768e-06,
      "loss": 0.053,
      "step": 121880
    },
    {
      "epoch": 2.437507499100108,
      "grad_norm": 0.05170680582523346,
      "learning_rate": 9.390539801890439e-06,
      "loss": 0.0404,
      "step": 121890
    },
    {
      "epoch": 2.4377074751029877,
      "grad_norm": 0.11133011430501938,
      "learning_rate": 9.387206868509114e-06,
      "loss": 0.1132,
      "step": 121900
    },
    {
      "epoch": 2.4379074511058674,
      "grad_norm": 0.07997419685125351,
      "learning_rate": 9.383873935127785e-06,
      "loss": 0.0633,
      "step": 121910
    },
    {
      "epoch": 2.438107427108747,
      "grad_norm": 0.22201867401599884,
      "learning_rate": 9.380541001746458e-06,
      "loss": 0.0907,
      "step": 121920
    },
    {
      "epoch": 2.4383074031116267,
      "grad_norm": 0.07086622714996338,
      "learning_rate": 9.37720806836513e-06,
      "loss": 0.0686,
      "step": 121930
    },
    {
      "epoch": 2.4385073791145064,
      "grad_norm": 0.1337718814611435,
      "learning_rate": 9.373875134983802e-06,
      "loss": 0.0624,
      "step": 121940
    },
    {
      "epoch": 2.438707355117386,
      "grad_norm": 0.19563184678554535,
      "learning_rate": 9.370542201602475e-06,
      "loss": 0.0833,
      "step": 121950
    },
    {
      "epoch": 2.438907331120266,
      "grad_norm": 0.08150501549243927,
      "learning_rate": 9.367209268221147e-06,
      "loss": 0.0291,
      "step": 121960
    },
    {
      "epoch": 2.439107307123145,
      "grad_norm": 0.14758996665477753,
      "learning_rate": 9.36387633483982e-06,
      "loss": 0.0787,
      "step": 121970
    },
    {
      "epoch": 2.4393072831260247,
      "grad_norm": 0.08288594335317612,
      "learning_rate": 9.360543401458493e-06,
      "loss": 0.0738,
      "step": 121980
    },
    {
      "epoch": 2.4395072591289044,
      "grad_norm": 0.07976651191711426,
      "learning_rate": 9.357210468077164e-06,
      "loss": 0.0744,
      "step": 121990
    },
    {
      "epoch": 2.439707235131784,
      "grad_norm": 0.19553238153457642,
      "learning_rate": 9.353877534695837e-06,
      "loss": 0.0831,
      "step": 122000
    },
    {
      "epoch": 2.439907211134664,
      "grad_norm": 0.08901581913232803,
      "learning_rate": 9.35054460131451e-06,
      "loss": 0.0715,
      "step": 122010
    },
    {
      "epoch": 2.4401071871375435,
      "grad_norm": 0.1667078733444214,
      "learning_rate": 9.347211667933181e-06,
      "loss": 0.0767,
      "step": 122020
    },
    {
      "epoch": 2.440307163140423,
      "grad_norm": 0.08843134343624115,
      "learning_rate": 9.343878734551854e-06,
      "loss": 0.0601,
      "step": 122030
    },
    {
      "epoch": 2.440507139143303,
      "grad_norm": 0.13274970650672913,
      "learning_rate": 9.340545801170526e-06,
      "loss": 0.0605,
      "step": 122040
    },
    {
      "epoch": 2.4407071151461825,
      "grad_norm": 0.184939444065094,
      "learning_rate": 9.337212867789199e-06,
      "loss": 0.0955,
      "step": 122050
    },
    {
      "epoch": 2.4409070911490622,
      "grad_norm": 0.1785813421010971,
      "learning_rate": 9.333879934407872e-06,
      "loss": 0.0787,
      "step": 122060
    },
    {
      "epoch": 2.441107067151942,
      "grad_norm": 0.12308037281036377,
      "learning_rate": 9.330547001026543e-06,
      "loss": 0.0579,
      "step": 122070
    },
    {
      "epoch": 2.4413070431548216,
      "grad_norm": 0.08024723082780838,
      "learning_rate": 9.327214067645216e-06,
      "loss": 0.0605,
      "step": 122080
    },
    {
      "epoch": 2.441507019157701,
      "grad_norm": 0.095369353890419,
      "learning_rate": 9.323881134263889e-06,
      "loss": 0.0891,
      "step": 122090
    },
    {
      "epoch": 2.4417069951605805,
      "grad_norm": 0.18720963597297668,
      "learning_rate": 9.320548200882562e-06,
      "loss": 0.1113,
      "step": 122100
    },
    {
      "epoch": 2.4419069711634602,
      "grad_norm": 0.16017118096351624,
      "learning_rate": 9.317215267501233e-06,
      "loss": 0.0765,
      "step": 122110
    },
    {
      "epoch": 2.44210694716634,
      "grad_norm": 0.12126148492097855,
      "learning_rate": 9.313882334119905e-06,
      "loss": 0.0452,
      "step": 122120
    },
    {
      "epoch": 2.4423069231692196,
      "grad_norm": 0.18706870079040527,
      "learning_rate": 9.31054940073858e-06,
      "loss": 0.0576,
      "step": 122130
    },
    {
      "epoch": 2.4425068991720993,
      "grad_norm": 0.1448533833026886,
      "learning_rate": 9.30721646735725e-06,
      "loss": 0.0587,
      "step": 122140
    },
    {
      "epoch": 2.442706875174979,
      "grad_norm": 0.15983426570892334,
      "learning_rate": 9.303883533975924e-06,
      "loss": 0.0603,
      "step": 122150
    },
    {
      "epoch": 2.4429068511778587,
      "grad_norm": 0.10072237998247147,
      "learning_rate": 9.300550600594595e-06,
      "loss": 0.117,
      "step": 122160
    },
    {
      "epoch": 2.4431068271807383,
      "grad_norm": 0.11661900579929352,
      "learning_rate": 9.297217667213268e-06,
      "loss": 0.0568,
      "step": 122170
    },
    {
      "epoch": 2.443306803183618,
      "grad_norm": 0.07529173791408539,
      "learning_rate": 9.293884733831941e-06,
      "loss": 0.0687,
      "step": 122180
    },
    {
      "epoch": 2.4435067791864977,
      "grad_norm": 0.11297573894262314,
      "learning_rate": 9.290551800450612e-06,
      "loss": 0.0589,
      "step": 122190
    },
    {
      "epoch": 2.4437067551893774,
      "grad_norm": 0.13058212399482727,
      "learning_rate": 9.287218867069285e-06,
      "loss": 0.0698,
      "step": 122200
    },
    {
      "epoch": 2.443906731192257,
      "grad_norm": 0.16338160634040833,
      "learning_rate": 9.283885933687958e-06,
      "loss": 0.0621,
      "step": 122210
    },
    {
      "epoch": 2.444106707195137,
      "grad_norm": 0.11596401780843735,
      "learning_rate": 9.28055300030663e-06,
      "loss": 0.0613,
      "step": 122220
    },
    {
      "epoch": 2.4443066831980165,
      "grad_norm": 0.14110493659973145,
      "learning_rate": 9.277220066925303e-06,
      "loss": 0.0658,
      "step": 122230
    },
    {
      "epoch": 2.4445066592008957,
      "grad_norm": 0.15036843717098236,
      "learning_rate": 9.273887133543976e-06,
      "loss": 0.0676,
      "step": 122240
    },
    {
      "epoch": 2.4447066352037754,
      "grad_norm": 0.08903400599956512,
      "learning_rate": 9.270554200162647e-06,
      "loss": 0.0658,
      "step": 122250
    },
    {
      "epoch": 2.444906611206655,
      "grad_norm": 0.11461640149354935,
      "learning_rate": 9.26722126678132e-06,
      "loss": 0.0623,
      "step": 122260
    },
    {
      "epoch": 2.4451065872095348,
      "grad_norm": 0.06914962828159332,
      "learning_rate": 9.263888333399991e-06,
      "loss": 0.0603,
      "step": 122270
    },
    {
      "epoch": 2.4453065632124145,
      "grad_norm": 0.074924536049366,
      "learning_rate": 9.260555400018666e-06,
      "loss": 0.0824,
      "step": 122280
    },
    {
      "epoch": 2.445506539215294,
      "grad_norm": 0.09390048682689667,
      "learning_rate": 9.257222466637337e-06,
      "loss": 0.064,
      "step": 122290
    },
    {
      "epoch": 2.445706515218174,
      "grad_norm": 0.07576312124729156,
      "learning_rate": 9.253889533256009e-06,
      "loss": 0.0531,
      "step": 122300
    },
    {
      "epoch": 2.4459064912210535,
      "grad_norm": 0.13720548152923584,
      "learning_rate": 9.250556599874682e-06,
      "loss": 0.0877,
      "step": 122310
    },
    {
      "epoch": 2.446106467223933,
      "grad_norm": 0.0881146490573883,
      "learning_rate": 9.247223666493355e-06,
      "loss": 0.0522,
      "step": 122320
    },
    {
      "epoch": 2.446306443226813,
      "grad_norm": 0.16731373965740204,
      "learning_rate": 9.243890733112028e-06,
      "loss": 0.0667,
      "step": 122330
    },
    {
      "epoch": 2.4465064192296926,
      "grad_norm": 0.07884159684181213,
      "learning_rate": 9.240557799730699e-06,
      "loss": 0.1021,
      "step": 122340
    },
    {
      "epoch": 2.4467063952325723,
      "grad_norm": 0.08633343130350113,
      "learning_rate": 9.237224866349372e-06,
      "loss": 0.0554,
      "step": 122350
    },
    {
      "epoch": 2.4469063712354515,
      "grad_norm": 0.06571689993143082,
      "learning_rate": 9.233891932968045e-06,
      "loss": 0.0929,
      "step": 122360
    },
    {
      "epoch": 2.447106347238331,
      "grad_norm": 0.1728793978691101,
      "learning_rate": 9.230558999586716e-06,
      "loss": 0.0532,
      "step": 122370
    },
    {
      "epoch": 2.447306323241211,
      "grad_norm": 0.12518897652626038,
      "learning_rate": 9.22722606620539e-06,
      "loss": 0.0793,
      "step": 122380
    },
    {
      "epoch": 2.4475062992440906,
      "grad_norm": 0.12438724935054779,
      "learning_rate": 9.223893132824062e-06,
      "loss": 0.0631,
      "step": 122390
    },
    {
      "epoch": 2.4477062752469703,
      "grad_norm": 0.22715313732624054,
      "learning_rate": 9.220560199442734e-06,
      "loss": 0.0565,
      "step": 122400
    },
    {
      "epoch": 2.44790625124985,
      "grad_norm": 0.1494407057762146,
      "learning_rate": 9.217227266061407e-06,
      "loss": 0.0992,
      "step": 122410
    },
    {
      "epoch": 2.4481062272527296,
      "grad_norm": 0.15315212309360504,
      "learning_rate": 9.213894332680078e-06,
      "loss": 0.101,
      "step": 122420
    },
    {
      "epoch": 2.4483062032556093,
      "grad_norm": 0.23021672666072845,
      "learning_rate": 9.210561399298753e-06,
      "loss": 0.0692,
      "step": 122430
    },
    {
      "epoch": 2.448506179258489,
      "grad_norm": 0.21528784930706024,
      "learning_rate": 9.207228465917424e-06,
      "loss": 0.1432,
      "step": 122440
    },
    {
      "epoch": 2.4487061552613687,
      "grad_norm": 0.2529706358909607,
      "learning_rate": 9.203895532536095e-06,
      "loss": 0.055,
      "step": 122450
    },
    {
      "epoch": 2.4489061312642484,
      "grad_norm": 0.1970648318529129,
      "learning_rate": 9.200562599154768e-06,
      "loss": 0.1084,
      "step": 122460
    },
    {
      "epoch": 2.449106107267128,
      "grad_norm": 0.2521025836467743,
      "learning_rate": 9.197229665773441e-06,
      "loss": 0.0631,
      "step": 122470
    },
    {
      "epoch": 2.4493060832700078,
      "grad_norm": 0.24179095029830933,
      "learning_rate": 9.193896732392114e-06,
      "loss": 0.0747,
      "step": 122480
    },
    {
      "epoch": 2.4495060592728874,
      "grad_norm": 0.11102908849716187,
      "learning_rate": 9.190563799010785e-06,
      "loss": 0.0839,
      "step": 122490
    },
    {
      "epoch": 2.449706035275767,
      "grad_norm": 0.1694338023662567,
      "learning_rate": 9.187230865629458e-06,
      "loss": 0.0569,
      "step": 122500
    },
    {
      "epoch": 2.4499060112786464,
      "grad_norm": 0.1251702904701233,
      "learning_rate": 9.183897932248132e-06,
      "loss": 0.0993,
      "step": 122510
    },
    {
      "epoch": 2.450105987281526,
      "grad_norm": 0.1349736899137497,
      "learning_rate": 9.180564998866803e-06,
      "loss": 0.0742,
      "step": 122520
    },
    {
      "epoch": 2.4503059632844058,
      "grad_norm": 0.22430600225925446,
      "learning_rate": 9.177232065485474e-06,
      "loss": 0.0708,
      "step": 122530
    },
    {
      "epoch": 2.4505059392872854,
      "grad_norm": 0.09118199348449707,
      "learning_rate": 9.173899132104149e-06,
      "loss": 0.0617,
      "step": 122540
    },
    {
      "epoch": 2.450705915290165,
      "grad_norm": 0.07018955051898956,
      "learning_rate": 9.17056619872282e-06,
      "loss": 0.0608,
      "step": 122550
    },
    {
      "epoch": 2.450905891293045,
      "grad_norm": 0.15599964559078217,
      "learning_rate": 9.167233265341493e-06,
      "loss": 0.0617,
      "step": 122560
    },
    {
      "epoch": 2.4511058672959245,
      "grad_norm": 0.09120360016822815,
      "learning_rate": 9.163900331960164e-06,
      "loss": 0.059,
      "step": 122570
    },
    {
      "epoch": 2.451305843298804,
      "grad_norm": 0.11386757344007492,
      "learning_rate": 9.160567398578837e-06,
      "loss": 0.0643,
      "step": 122580
    },
    {
      "epoch": 2.451505819301684,
      "grad_norm": 0.21607606112957,
      "learning_rate": 9.15723446519751e-06,
      "loss": 0.1022,
      "step": 122590
    },
    {
      "epoch": 2.4517057953045636,
      "grad_norm": 0.20516817271709442,
      "learning_rate": 9.153901531816182e-06,
      "loss": 0.1129,
      "step": 122600
    },
    {
      "epoch": 2.4519057713074432,
      "grad_norm": 0.05889241397380829,
      "learning_rate": 9.150568598434855e-06,
      "loss": 0.0905,
      "step": 122610
    },
    {
      "epoch": 2.452105747310323,
      "grad_norm": 0.12192796915769577,
      "learning_rate": 9.147235665053528e-06,
      "loss": 0.0784,
      "step": 122620
    },
    {
      "epoch": 2.452305723313202,
      "grad_norm": 0.1634903997182846,
      "learning_rate": 9.143902731672199e-06,
      "loss": 0.0619,
      "step": 122630
    },
    {
      "epoch": 2.452505699316082,
      "grad_norm": 0.09771929681301117,
      "learning_rate": 9.140569798290872e-06,
      "loss": 0.0284,
      "step": 122640
    },
    {
      "epoch": 2.4527056753189616,
      "grad_norm": 0.14356693625450134,
      "learning_rate": 9.137236864909545e-06,
      "loss": 0.0564,
      "step": 122650
    },
    {
      "epoch": 2.4529056513218412,
      "grad_norm": 0.17251193523406982,
      "learning_rate": 9.133903931528218e-06,
      "loss": 0.0951,
      "step": 122660
    },
    {
      "epoch": 2.453105627324721,
      "grad_norm": 0.16778594255447388,
      "learning_rate": 9.13057099814689e-06,
      "loss": 0.0719,
      "step": 122670
    },
    {
      "epoch": 2.4533056033276006,
      "grad_norm": 0.11683545261621475,
      "learning_rate": 9.12723806476556e-06,
      "loss": 0.0588,
      "step": 122680
    },
    {
      "epoch": 2.4535055793304803,
      "grad_norm": 0.11666535586118698,
      "learning_rate": 9.123905131384235e-06,
      "loss": 0.0757,
      "step": 122690
    },
    {
      "epoch": 2.45370555533336,
      "grad_norm": 0.11173112690448761,
      "learning_rate": 9.120572198002907e-06,
      "loss": 0.0637,
      "step": 122700
    },
    {
      "epoch": 2.4539055313362397,
      "grad_norm": 0.07413602620363235,
      "learning_rate": 9.11723926462158e-06,
      "loss": 0.0872,
      "step": 122710
    },
    {
      "epoch": 2.4541055073391194,
      "grad_norm": 0.06034954637289047,
      "learning_rate": 9.113906331240251e-06,
      "loss": 0.0764,
      "step": 122720
    },
    {
      "epoch": 2.454305483341999,
      "grad_norm": 0.06538695096969604,
      "learning_rate": 9.110573397858924e-06,
      "loss": 0.0741,
      "step": 122730
    },
    {
      "epoch": 2.4545054593448787,
      "grad_norm": 0.17313197255134583,
      "learning_rate": 9.107240464477597e-06,
      "loss": 0.0935,
      "step": 122740
    },
    {
      "epoch": 2.4547054353477584,
      "grad_norm": 0.1521587073802948,
      "learning_rate": 9.103907531096268e-06,
      "loss": 0.0539,
      "step": 122750
    },
    {
      "epoch": 2.454905411350638,
      "grad_norm": 0.15650674700737,
      "learning_rate": 9.100574597714941e-06,
      "loss": 0.0862,
      "step": 122760
    },
    {
      "epoch": 2.455105387353518,
      "grad_norm": 0.12591859698295593,
      "learning_rate": 9.097241664333614e-06,
      "loss": 0.077,
      "step": 122770
    },
    {
      "epoch": 2.455305363356397,
      "grad_norm": 0.0857309103012085,
      "learning_rate": 9.093908730952286e-06,
      "loss": 0.069,
      "step": 122780
    },
    {
      "epoch": 2.4555053393592767,
      "grad_norm": 0.08109650760889053,
      "learning_rate": 9.090575797570959e-06,
      "loss": 0.0573,
      "step": 122790
    },
    {
      "epoch": 2.4557053153621564,
      "grad_norm": 0.12014121562242508,
      "learning_rate": 9.087242864189632e-06,
      "loss": 0.0784,
      "step": 122800
    },
    {
      "epoch": 2.455905291365036,
      "grad_norm": 0.17697890102863312,
      "learning_rate": 9.083909930808303e-06,
      "loss": 0.0604,
      "step": 122810
    },
    {
      "epoch": 2.456105267367916,
      "grad_norm": 0.07238077372312546,
      "learning_rate": 9.080576997426976e-06,
      "loss": 0.0679,
      "step": 122820
    },
    {
      "epoch": 2.4563052433707955,
      "grad_norm": 0.16168135404586792,
      "learning_rate": 9.077244064045647e-06,
      "loss": 0.0874,
      "step": 122830
    },
    {
      "epoch": 2.456505219373675,
      "grad_norm": 0.2228696644306183,
      "learning_rate": 9.073911130664322e-06,
      "loss": 0.0689,
      "step": 122840
    },
    {
      "epoch": 2.456705195376555,
      "grad_norm": 0.18931369483470917,
      "learning_rate": 9.070578197282993e-06,
      "loss": 0.0726,
      "step": 122850
    },
    {
      "epoch": 2.4569051713794345,
      "grad_norm": 0.15212935209274292,
      "learning_rate": 9.067245263901665e-06,
      "loss": 0.0811,
      "step": 122860
    },
    {
      "epoch": 2.4571051473823142,
      "grad_norm": 0.19668444991111755,
      "learning_rate": 9.063912330520338e-06,
      "loss": 0.0676,
      "step": 122870
    },
    {
      "epoch": 2.457305123385194,
      "grad_norm": 0.07904405891895294,
      "learning_rate": 9.06057939713901e-06,
      "loss": 0.0635,
      "step": 122880
    },
    {
      "epoch": 2.4575050993880736,
      "grad_norm": 0.230613112449646,
      "learning_rate": 9.057579757095816e-06,
      "loss": 0.0885,
      "step": 122890
    },
    {
      "epoch": 2.457705075390953,
      "grad_norm": 0.08540333062410355,
      "learning_rate": 9.054246823714487e-06,
      "loss": 0.0757,
      "step": 122900
    },
    {
      "epoch": 2.4579050513938325,
      "grad_norm": 0.1081504225730896,
      "learning_rate": 9.05091389033316e-06,
      "loss": 0.0497,
      "step": 122910
    },
    {
      "epoch": 2.458105027396712,
      "grad_norm": 0.12187240272760391,
      "learning_rate": 9.047580956951833e-06,
      "loss": 0.059,
      "step": 122920
    },
    {
      "epoch": 2.458305003399592,
      "grad_norm": 0.2911246418952942,
      "learning_rate": 9.044248023570505e-06,
      "loss": 0.0689,
      "step": 122930
    },
    {
      "epoch": 2.4585049794024716,
      "grad_norm": 0.05367852747440338,
      "learning_rate": 9.040915090189178e-06,
      "loss": 0.0501,
      "step": 122940
    },
    {
      "epoch": 2.4587049554053513,
      "grad_norm": 0.07728447020053864,
      "learning_rate": 9.03758215680785e-06,
      "loss": 0.0668,
      "step": 122950
    },
    {
      "epoch": 2.458904931408231,
      "grad_norm": 0.09172238409519196,
      "learning_rate": 9.034249223426522e-06,
      "loss": 0.0725,
      "step": 122960
    },
    {
      "epoch": 2.4591049074111107,
      "grad_norm": 0.14489124715328217,
      "learning_rate": 9.030916290045195e-06,
      "loss": 0.04,
      "step": 122970
    },
    {
      "epoch": 2.4593048834139903,
      "grad_norm": 0.07343951612710953,
      "learning_rate": 9.027583356663866e-06,
      "loss": 0.044,
      "step": 122980
    },
    {
      "epoch": 2.45950485941687,
      "grad_norm": 0.19977687299251556,
      "learning_rate": 9.024250423282541e-06,
      "loss": 0.0814,
      "step": 122990
    },
    {
      "epoch": 2.4597048354197497,
      "grad_norm": 0.11606930196285248,
      "learning_rate": 9.020917489901212e-06,
      "loss": 0.0827,
      "step": 123000
    },
    {
      "epoch": 2.4599048114226294,
      "grad_norm": 0.11391182988882065,
      "learning_rate": 9.017584556519884e-06,
      "loss": 0.0754,
      "step": 123010
    },
    {
      "epoch": 2.460104787425509,
      "grad_norm": 0.13095565140247345,
      "learning_rate": 9.014251623138557e-06,
      "loss": 0.0577,
      "step": 123020
    },
    {
      "epoch": 2.4603047634283888,
      "grad_norm": 0.15509700775146484,
      "learning_rate": 9.01091868975723e-06,
      "loss": 0.0685,
      "step": 123030
    },
    {
      "epoch": 2.4605047394312685,
      "grad_norm": 0.13114294409751892,
      "learning_rate": 9.007585756375903e-06,
      "loss": 0.0423,
      "step": 123040
    },
    {
      "epoch": 2.460704715434148,
      "grad_norm": 0.19057731330394745,
      "learning_rate": 9.004252822994574e-06,
      "loss": 0.1019,
      "step": 123050
    },
    {
      "epoch": 2.4609046914370274,
      "grad_norm": 0.13297846913337708,
      "learning_rate": 9.000919889613247e-06,
      "loss": 0.1809,
      "step": 123060
    },
    {
      "epoch": 2.461104667439907,
      "grad_norm": 0.08657766878604889,
      "learning_rate": 8.99758695623192e-06,
      "loss": 0.0708,
      "step": 123070
    },
    {
      "epoch": 2.4613046434427868,
      "grad_norm": 0.16130749881267548,
      "learning_rate": 8.994254022850591e-06,
      "loss": 0.1024,
      "step": 123080
    },
    {
      "epoch": 2.4615046194456665,
      "grad_norm": 0.236862450838089,
      "learning_rate": 8.990921089469264e-06,
      "loss": 0.0533,
      "step": 123090
    },
    {
      "epoch": 2.461704595448546,
      "grad_norm": 0.12577509880065918,
      "learning_rate": 8.987588156087937e-06,
      "loss": 0.0669,
      "step": 123100
    },
    {
      "epoch": 2.461904571451426,
      "grad_norm": 0.06003526970744133,
      "learning_rate": 8.984255222706609e-06,
      "loss": 0.0836,
      "step": 123110
    },
    {
      "epoch": 2.4621045474543055,
      "grad_norm": 0.28279751539230347,
      "learning_rate": 8.980922289325282e-06,
      "loss": 0.0963,
      "step": 123120
    },
    {
      "epoch": 2.462304523457185,
      "grad_norm": 0.20681574940681458,
      "learning_rate": 8.977589355943953e-06,
      "loss": 0.0902,
      "step": 123130
    },
    {
      "epoch": 2.462504499460065,
      "grad_norm": 0.12167943269014359,
      "learning_rate": 8.974256422562628e-06,
      "loss": 0.0652,
      "step": 123140
    },
    {
      "epoch": 2.4627044754629446,
      "grad_norm": 0.19686131179332733,
      "learning_rate": 8.970923489181299e-06,
      "loss": 0.0815,
      "step": 123150
    },
    {
      "epoch": 2.4629044514658243,
      "grad_norm": 0.29720205068588257,
      "learning_rate": 8.96759055579997e-06,
      "loss": 0.122,
      "step": 123160
    },
    {
      "epoch": 2.463104427468704,
      "grad_norm": 0.1592073142528534,
      "learning_rate": 8.964257622418643e-06,
      "loss": 0.0586,
      "step": 123170
    },
    {
      "epoch": 2.463304403471583,
      "grad_norm": 0.13115642964839935,
      "learning_rate": 8.960924689037316e-06,
      "loss": 0.0732,
      "step": 123180
    },
    {
      "epoch": 2.463504379474463,
      "grad_norm": 0.1937849223613739,
      "learning_rate": 8.95759175565599e-06,
      "loss": 0.082,
      "step": 123190
    },
    {
      "epoch": 2.4637043554773426,
      "grad_norm": 0.10461146384477615,
      "learning_rate": 8.95425882227466e-06,
      "loss": 0.0724,
      "step": 123200
    },
    {
      "epoch": 2.4639043314802223,
      "grad_norm": 0.2312944084405899,
      "learning_rate": 8.950925888893333e-06,
      "loss": 0.0815,
      "step": 123210
    },
    {
      "epoch": 2.464104307483102,
      "grad_norm": 0.17438949644565582,
      "learning_rate": 8.947592955512006e-06,
      "loss": 0.0588,
      "step": 123220
    },
    {
      "epoch": 2.4643042834859816,
      "grad_norm": 0.1416631042957306,
      "learning_rate": 8.944260022130678e-06,
      "loss": 0.0405,
      "step": 123230
    },
    {
      "epoch": 2.4645042594888613,
      "grad_norm": 0.13222777843475342,
      "learning_rate": 8.940927088749349e-06,
      "loss": 0.049,
      "step": 123240
    },
    {
      "epoch": 2.464704235491741,
      "grad_norm": 0.22771304845809937,
      "learning_rate": 8.937594155368024e-06,
      "loss": 0.0486,
      "step": 123250
    },
    {
      "epoch": 2.4649042114946207,
      "grad_norm": 0.15848146378993988,
      "learning_rate": 8.934261221986695e-06,
      "loss": 0.0747,
      "step": 123260
    },
    {
      "epoch": 2.4651041874975004,
      "grad_norm": 0.21643811464309692,
      "learning_rate": 8.930928288605368e-06,
      "loss": 0.0662,
      "step": 123270
    },
    {
      "epoch": 2.46530416350038,
      "grad_norm": 0.11470696330070496,
      "learning_rate": 8.92759535522404e-06,
      "loss": 0.0866,
      "step": 123280
    },
    {
      "epoch": 2.4655041395032598,
      "grad_norm": 0.17775394022464752,
      "learning_rate": 8.924262421842712e-06,
      "loss": 0.0658,
      "step": 123290
    },
    {
      "epoch": 2.4657041155061394,
      "grad_norm": 0.09094421565532684,
      "learning_rate": 8.920929488461385e-06,
      "loss": 0.0621,
      "step": 123300
    },
    {
      "epoch": 2.465904091509019,
      "grad_norm": 0.15758784115314484,
      "learning_rate": 8.917596555080057e-06,
      "loss": 0.08,
      "step": 123310
    },
    {
      "epoch": 2.466104067511899,
      "grad_norm": 0.0899849683046341,
      "learning_rate": 8.91426362169873e-06,
      "loss": 0.0449,
      "step": 123320
    },
    {
      "epoch": 2.466304043514778,
      "grad_norm": 0.10847675055265427,
      "learning_rate": 8.910930688317403e-06,
      "loss": 0.0537,
      "step": 123330
    },
    {
      "epoch": 2.4665040195176577,
      "grad_norm": 0.12878212332725525,
      "learning_rate": 8.907597754936074e-06,
      "loss": 0.0654,
      "step": 123340
    },
    {
      "epoch": 2.4667039955205374,
      "grad_norm": 0.1500099003314972,
      "learning_rate": 8.904264821554747e-06,
      "loss": 0.0598,
      "step": 123350
    },
    {
      "epoch": 2.466903971523417,
      "grad_norm": 0.12867975234985352,
      "learning_rate": 8.90093188817342e-06,
      "loss": 0.0489,
      "step": 123360
    },
    {
      "epoch": 2.467103947526297,
      "grad_norm": 0.13154208660125732,
      "learning_rate": 8.897598954792093e-06,
      "loss": 0.0951,
      "step": 123370
    },
    {
      "epoch": 2.4673039235291765,
      "grad_norm": 0.14647310972213745,
      "learning_rate": 8.894266021410764e-06,
      "loss": 0.0682,
      "step": 123380
    },
    {
      "epoch": 2.467503899532056,
      "grad_norm": 0.09720819443464279,
      "learning_rate": 8.890933088029436e-06,
      "loss": 0.0658,
      "step": 123390
    },
    {
      "epoch": 2.467703875534936,
      "grad_norm": 0.08431941270828247,
      "learning_rate": 8.88760015464811e-06,
      "loss": 0.063,
      "step": 123400
    },
    {
      "epoch": 2.4679038515378156,
      "grad_norm": 0.20178578794002533,
      "learning_rate": 8.884267221266782e-06,
      "loss": 0.0559,
      "step": 123410
    },
    {
      "epoch": 2.4681038275406952,
      "grad_norm": 0.19730599224567413,
      "learning_rate": 8.880934287885455e-06,
      "loss": 0.0856,
      "step": 123420
    },
    {
      "epoch": 2.468303803543575,
      "grad_norm": 0.1414649337530136,
      "learning_rate": 8.877601354504126e-06,
      "loss": 0.0969,
      "step": 123430
    },
    {
      "epoch": 2.4685037795464546,
      "grad_norm": 0.2275206446647644,
      "learning_rate": 8.874268421122799e-06,
      "loss": 0.102,
      "step": 123440
    },
    {
      "epoch": 2.468703755549334,
      "grad_norm": 0.24477435648441315,
      "learning_rate": 8.870935487741472e-06,
      "loss": 0.0676,
      "step": 123450
    },
    {
      "epoch": 2.4689037315522135,
      "grad_norm": 0.1322966068983078,
      "learning_rate": 8.867602554360143e-06,
      "loss": 0.0736,
      "step": 123460
    },
    {
      "epoch": 2.4691037075550932,
      "grad_norm": 0.1801535189151764,
      "learning_rate": 8.864269620978816e-06,
      "loss": 0.0967,
      "step": 123470
    },
    {
      "epoch": 2.469303683557973,
      "grad_norm": 0.0934765636920929,
      "learning_rate": 8.86093668759749e-06,
      "loss": 0.0542,
      "step": 123480
    },
    {
      "epoch": 2.4695036595608526,
      "grad_norm": 0.1583404242992401,
      "learning_rate": 8.85760375421616e-06,
      "loss": 0.0972,
      "step": 123490
    },
    {
      "epoch": 2.4697036355637323,
      "grad_norm": 0.10825721174478531,
      "learning_rate": 8.854270820834834e-06,
      "loss": 0.1362,
      "step": 123500
    },
    {
      "epoch": 2.469903611566612,
      "grad_norm": 0.24336566030979156,
      "learning_rate": 8.850937887453507e-06,
      "loss": 0.1158,
      "step": 123510
    },
    {
      "epoch": 2.4701035875694917,
      "grad_norm": 0.18023811280727386,
      "learning_rate": 8.847604954072178e-06,
      "loss": 0.063,
      "step": 123520
    },
    {
      "epoch": 2.4703035635723714,
      "grad_norm": 0.07263802736997604,
      "learning_rate": 8.844272020690851e-06,
      "loss": 0.0605,
      "step": 123530
    },
    {
      "epoch": 2.470503539575251,
      "grad_norm": 0.11474563926458359,
      "learning_rate": 8.840939087309522e-06,
      "loss": 0.0902,
      "step": 123540
    },
    {
      "epoch": 2.4707035155781307,
      "grad_norm": 0.12488352507352829,
      "learning_rate": 8.837606153928197e-06,
      "loss": 0.0541,
      "step": 123550
    },
    {
      "epoch": 2.4709034915810104,
      "grad_norm": 0.2338596135377884,
      "learning_rate": 8.834273220546868e-06,
      "loss": 0.0804,
      "step": 123560
    },
    {
      "epoch": 2.47110346758389,
      "grad_norm": 0.11356663703918457,
      "learning_rate": 8.83094028716554e-06,
      "loss": 0.0517,
      "step": 123570
    },
    {
      "epoch": 2.47130344358677,
      "grad_norm": 0.12119640409946442,
      "learning_rate": 8.827607353784213e-06,
      "loss": 0.0887,
      "step": 123580
    },
    {
      "epoch": 2.4715034195896495,
      "grad_norm": 0.12677153944969177,
      "learning_rate": 8.824274420402886e-06,
      "loss": 0.0747,
      "step": 123590
    },
    {
      "epoch": 2.4717033955925287,
      "grad_norm": 0.10330503433942795,
      "learning_rate": 8.820941487021559e-06,
      "loss": 0.0607,
      "step": 123600
    },
    {
      "epoch": 2.4719033715954084,
      "grad_norm": 0.1647876501083374,
      "learning_rate": 8.81760855364023e-06,
      "loss": 0.0744,
      "step": 123610
    },
    {
      "epoch": 2.472103347598288,
      "grad_norm": 0.2035195529460907,
      "learning_rate": 8.814275620258903e-06,
      "loss": 0.0533,
      "step": 123620
    },
    {
      "epoch": 2.472303323601168,
      "grad_norm": 0.15979331731796265,
      "learning_rate": 8.810942686877576e-06,
      "loss": 0.0889,
      "step": 123630
    },
    {
      "epoch": 2.4725032996040475,
      "grad_norm": 0.12462443113327026,
      "learning_rate": 8.807609753496247e-06,
      "loss": 0.0671,
      "step": 123640
    },
    {
      "epoch": 2.472703275606927,
      "grad_norm": 0.12001343071460724,
      "learning_rate": 8.80427682011492e-06,
      "loss": 0.0959,
      "step": 123650
    },
    {
      "epoch": 2.472903251609807,
      "grad_norm": 0.0602383129298687,
      "learning_rate": 8.800943886733593e-06,
      "loss": 0.0752,
      "step": 123660
    },
    {
      "epoch": 2.4731032276126865,
      "grad_norm": 0.21787670254707336,
      "learning_rate": 8.797610953352265e-06,
      "loss": 0.0733,
      "step": 123670
    },
    {
      "epoch": 2.473303203615566,
      "grad_norm": 0.11656305193901062,
      "learning_rate": 8.794278019970938e-06,
      "loss": 0.0481,
      "step": 123680
    },
    {
      "epoch": 2.473503179618446,
      "grad_norm": 0.1885869950056076,
      "learning_rate": 8.790945086589609e-06,
      "loss": 0.0682,
      "step": 123690
    },
    {
      "epoch": 2.4737031556213256,
      "grad_norm": 0.2428772747516632,
      "learning_rate": 8.787612153208282e-06,
      "loss": 0.0619,
      "step": 123700
    },
    {
      "epoch": 2.4739031316242053,
      "grad_norm": 0.20701546967029572,
      "learning_rate": 8.784279219826955e-06,
      "loss": 0.0692,
      "step": 123710
    },
    {
      "epoch": 2.4741031076270845,
      "grad_norm": 0.10674486309289932,
      "learning_rate": 8.780946286445626e-06,
      "loss": 0.0673,
      "step": 123720
    },
    {
      "epoch": 2.474303083629964,
      "grad_norm": 0.17142394185066223,
      "learning_rate": 8.7776133530643e-06,
      "loss": 0.0584,
      "step": 123730
    },
    {
      "epoch": 2.474503059632844,
      "grad_norm": 0.19970114529132843,
      "learning_rate": 8.774280419682972e-06,
      "loss": 0.0904,
      "step": 123740
    },
    {
      "epoch": 2.4747030356357236,
      "grad_norm": 0.10387997329235077,
      "learning_rate": 8.770947486301644e-06,
      "loss": 0.0493,
      "step": 123750
    },
    {
      "epoch": 2.4749030116386033,
      "grad_norm": 0.16408893465995789,
      "learning_rate": 8.767614552920317e-06,
      "loss": 0.0584,
      "step": 123760
    },
    {
      "epoch": 2.475102987641483,
      "grad_norm": 0.21824190020561218,
      "learning_rate": 8.76428161953899e-06,
      "loss": 0.1132,
      "step": 123770
    },
    {
      "epoch": 2.4753029636443626,
      "grad_norm": 0.24131879210472107,
      "learning_rate": 8.760948686157663e-06,
      "loss": 0.073,
      "step": 123780
    },
    {
      "epoch": 2.4755029396472423,
      "grad_norm": 0.10642324388027191,
      "learning_rate": 8.757615752776334e-06,
      "loss": 0.0348,
      "step": 123790
    },
    {
      "epoch": 2.475702915650122,
      "grad_norm": 0.13970635831356049,
      "learning_rate": 8.754282819395005e-06,
      "loss": 0.0729,
      "step": 123800
    },
    {
      "epoch": 2.4759028916530017,
      "grad_norm": 0.25961124897003174,
      "learning_rate": 8.75094988601368e-06,
      "loss": 0.0759,
      "step": 123810
    },
    {
      "epoch": 2.4761028676558814,
      "grad_norm": 0.06687669456005096,
      "learning_rate": 8.747616952632351e-06,
      "loss": 0.0565,
      "step": 123820
    },
    {
      "epoch": 2.476302843658761,
      "grad_norm": 0.16860739886760712,
      "learning_rate": 8.744284019251024e-06,
      "loss": 0.0644,
      "step": 123830
    },
    {
      "epoch": 2.4765028196616408,
      "grad_norm": 0.1498539000749588,
      "learning_rate": 8.740951085869695e-06,
      "loss": 0.0508,
      "step": 123840
    },
    {
      "epoch": 2.4767027956645205,
      "grad_norm": 0.12621432542800903,
      "learning_rate": 8.737618152488368e-06,
      "loss": 0.0655,
      "step": 123850
    },
    {
      "epoch": 2.4769027716674,
      "grad_norm": 0.10097729414701462,
      "learning_rate": 8.734285219107041e-06,
      "loss": 0.0593,
      "step": 123860
    },
    {
      "epoch": 2.4771027476702794,
      "grad_norm": 0.2070266604423523,
      "learning_rate": 8.730952285725713e-06,
      "loss": 0.0918,
      "step": 123870
    },
    {
      "epoch": 2.477302723673159,
      "grad_norm": 0.1080280989408493,
      "learning_rate": 8.727619352344386e-06,
      "loss": 0.0877,
      "step": 123880
    },
    {
      "epoch": 2.4775026996760388,
      "grad_norm": 0.08618947863578796,
      "learning_rate": 8.724286418963059e-06,
      "loss": 0.0755,
      "step": 123890
    },
    {
      "epoch": 2.4777026756789184,
      "grad_norm": 0.12927480041980743,
      "learning_rate": 8.72095348558173e-06,
      "loss": 0.0685,
      "step": 123900
    },
    {
      "epoch": 2.477902651681798,
      "grad_norm": 0.08088231086730957,
      "learning_rate": 8.717620552200403e-06,
      "loss": 0.0906,
      "step": 123910
    },
    {
      "epoch": 2.478102627684678,
      "grad_norm": 0.07939933240413666,
      "learning_rate": 8.714287618819076e-06,
      "loss": 0.061,
      "step": 123920
    },
    {
      "epoch": 2.4783026036875575,
      "grad_norm": 0.11242566257715225,
      "learning_rate": 8.710954685437749e-06,
      "loss": 0.052,
      "step": 123930
    },
    {
      "epoch": 2.478502579690437,
      "grad_norm": 0.18301905691623688,
      "learning_rate": 8.70762175205642e-06,
      "loss": 0.0667,
      "step": 123940
    },
    {
      "epoch": 2.478702555693317,
      "grad_norm": 0.06591110676527023,
      "learning_rate": 8.704288818675092e-06,
      "loss": 0.0538,
      "step": 123950
    },
    {
      "epoch": 2.4789025316961966,
      "grad_norm": 0.1996055543422699,
      "learning_rate": 8.700955885293766e-06,
      "loss": 0.048,
      "step": 123960
    },
    {
      "epoch": 2.4791025076990763,
      "grad_norm": 0.06631268560886383,
      "learning_rate": 8.697622951912438e-06,
      "loss": 0.0783,
      "step": 123970
    },
    {
      "epoch": 2.479302483701956,
      "grad_norm": 0.1496749222278595,
      "learning_rate": 8.694290018531109e-06,
      "loss": 0.057,
      "step": 123980
    },
    {
      "epoch": 2.479502459704835,
      "grad_norm": 0.14483840763568878,
      "learning_rate": 8.690957085149782e-06,
      "loss": 0.0796,
      "step": 123990
    },
    {
      "epoch": 2.479702435707715,
      "grad_norm": 0.11892974376678467,
      "learning_rate": 8.687624151768455e-06,
      "loss": 0.0853,
      "step": 124000
    },
    {
      "epoch": 2.4799024117105946,
      "grad_norm": 0.25043556094169617,
      "learning_rate": 8.684291218387128e-06,
      "loss": 0.097,
      "step": 124010
    },
    {
      "epoch": 2.4801023877134742,
      "grad_norm": 0.13998524844646454,
      "learning_rate": 8.6809582850058e-06,
      "loss": 0.0809,
      "step": 124020
    },
    {
      "epoch": 2.480302363716354,
      "grad_norm": 0.08463308215141296,
      "learning_rate": 8.677625351624472e-06,
      "loss": 0.0695,
      "step": 124030
    },
    {
      "epoch": 2.4805023397192336,
      "grad_norm": 0.12133841216564178,
      "learning_rate": 8.674292418243145e-06,
      "loss": 0.0908,
      "step": 124040
    },
    {
      "epoch": 2.4807023157221133,
      "grad_norm": 0.0946500226855278,
      "learning_rate": 8.670959484861817e-06,
      "loss": 0.0506,
      "step": 124050
    },
    {
      "epoch": 2.480902291724993,
      "grad_norm": 0.22508090734481812,
      "learning_rate": 8.66762655148049e-06,
      "loss": 0.0726,
      "step": 124060
    },
    {
      "epoch": 2.4811022677278727,
      "grad_norm": 0.1777942031621933,
      "learning_rate": 8.664293618099161e-06,
      "loss": 0.0995,
      "step": 124070
    },
    {
      "epoch": 2.4813022437307524,
      "grad_norm": 0.08530459553003311,
      "learning_rate": 8.660960684717834e-06,
      "loss": 0.0677,
      "step": 124080
    },
    {
      "epoch": 2.481502219733632,
      "grad_norm": 0.19343124330043793,
      "learning_rate": 8.657627751336507e-06,
      "loss": 0.0794,
      "step": 124090
    },
    {
      "epoch": 2.4817021957365117,
      "grad_norm": 0.10257504135370255,
      "learning_rate": 8.654294817955178e-06,
      "loss": 0.0999,
      "step": 124100
    },
    {
      "epoch": 2.4819021717393914,
      "grad_norm": 0.19215907156467438,
      "learning_rate": 8.650961884573851e-06,
      "loss": 0.0562,
      "step": 124110
    },
    {
      "epoch": 2.482102147742271,
      "grad_norm": 0.1270686686038971,
      "learning_rate": 8.647628951192524e-06,
      "loss": 0.091,
      "step": 124120
    },
    {
      "epoch": 2.482302123745151,
      "grad_norm": 0.11361344158649445,
      "learning_rate": 8.644296017811196e-06,
      "loss": 0.0694,
      "step": 124130
    },
    {
      "epoch": 2.48250209974803,
      "grad_norm": 0.14552028477191925,
      "learning_rate": 8.640963084429869e-06,
      "loss": 0.0419,
      "step": 124140
    },
    {
      "epoch": 2.4827020757509097,
      "grad_norm": 0.19763456284999847,
      "learning_rate": 8.637630151048542e-06,
      "loss": 0.0858,
      "step": 124150
    },
    {
      "epoch": 2.4829020517537894,
      "grad_norm": 0.11440768837928772,
      "learning_rate": 8.634297217667215e-06,
      "loss": 0.0562,
      "step": 124160
    },
    {
      "epoch": 2.483102027756669,
      "grad_norm": 0.1013462170958519,
      "learning_rate": 8.630964284285886e-06,
      "loss": 0.0536,
      "step": 124170
    },
    {
      "epoch": 2.483302003759549,
      "grad_norm": 0.18145526945590973,
      "learning_rate": 8.627631350904557e-06,
      "loss": 0.0705,
      "step": 124180
    },
    {
      "epoch": 2.4835019797624285,
      "grad_norm": 0.10303705930709839,
      "learning_rate": 8.624298417523232e-06,
      "loss": 0.0643,
      "step": 124190
    },
    {
      "epoch": 2.483701955765308,
      "grad_norm": 0.19359320402145386,
      "learning_rate": 8.620965484141903e-06,
      "loss": 0.0756,
      "step": 124200
    },
    {
      "epoch": 2.483901931768188,
      "grad_norm": 0.24313172698020935,
      "learning_rate": 8.617632550760575e-06,
      "loss": 0.1211,
      "step": 124210
    },
    {
      "epoch": 2.4841019077710675,
      "grad_norm": 0.0731295496225357,
      "learning_rate": 8.614299617379248e-06,
      "loss": 0.0646,
      "step": 124220
    },
    {
      "epoch": 2.4843018837739472,
      "grad_norm": 0.11576303094625473,
      "learning_rate": 8.61096668399792e-06,
      "loss": 0.0722,
      "step": 124230
    },
    {
      "epoch": 2.484501859776827,
      "grad_norm": 0.14514340460300446,
      "learning_rate": 8.607633750616594e-06,
      "loss": 0.0833,
      "step": 124240
    },
    {
      "epoch": 2.4847018357797066,
      "grad_norm": 0.07178434729576111,
      "learning_rate": 8.604300817235265e-06,
      "loss": 0.0545,
      "step": 124250
    },
    {
      "epoch": 2.484901811782586,
      "grad_norm": 0.21756590902805328,
      "learning_rate": 8.600967883853938e-06,
      "loss": 0.0764,
      "step": 124260
    },
    {
      "epoch": 2.4851017877854655,
      "grad_norm": 0.14528967440128326,
      "learning_rate": 8.597634950472611e-06,
      "loss": 0.0696,
      "step": 124270
    },
    {
      "epoch": 2.485301763788345,
      "grad_norm": 0.1564793586730957,
      "learning_rate": 8.594302017091282e-06,
      "loss": 0.0859,
      "step": 124280
    },
    {
      "epoch": 2.485501739791225,
      "grad_norm": 0.19091670215129852,
      "learning_rate": 8.590969083709955e-06,
      "loss": 0.053,
      "step": 124290
    },
    {
      "epoch": 2.4857017157941046,
      "grad_norm": 0.17693185806274414,
      "learning_rate": 8.587636150328628e-06,
      "loss": 0.0683,
      "step": 124300
    },
    {
      "epoch": 2.4859016917969843,
      "grad_norm": 0.14456485211849213,
      "learning_rate": 8.5843032169473e-06,
      "loss": 0.0607,
      "step": 124310
    },
    {
      "epoch": 2.486101667799864,
      "grad_norm": 0.10435174405574799,
      "learning_rate": 8.580970283565973e-06,
      "loss": 0.057,
      "step": 124320
    },
    {
      "epoch": 2.4863016438027437,
      "grad_norm": 0.18936076760292053,
      "learning_rate": 8.577637350184644e-06,
      "loss": 0.0914,
      "step": 124330
    },
    {
      "epoch": 2.4865016198056233,
      "grad_norm": 0.23435910046100616,
      "learning_rate": 8.574304416803319e-06,
      "loss": 0.0892,
      "step": 124340
    },
    {
      "epoch": 2.486701595808503,
      "grad_norm": 0.19769132137298584,
      "learning_rate": 8.57097148342199e-06,
      "loss": 0.0502,
      "step": 124350
    },
    {
      "epoch": 2.4869015718113827,
      "grad_norm": 0.13153748214244843,
      "learning_rate": 8.567638550040661e-06,
      "loss": 0.0635,
      "step": 124360
    },
    {
      "epoch": 2.4871015478142624,
      "grad_norm": 0.1883263736963272,
      "learning_rate": 8.564305616659334e-06,
      "loss": 0.0738,
      "step": 124370
    },
    {
      "epoch": 2.487301523817142,
      "grad_norm": 0.15980716049671173,
      "learning_rate": 8.560972683278007e-06,
      "loss": 0.0608,
      "step": 124380
    },
    {
      "epoch": 2.4875014998200218,
      "grad_norm": 0.06906413286924362,
      "learning_rate": 8.55763974989668e-06,
      "loss": 0.0434,
      "step": 124390
    },
    {
      "epoch": 2.4877014758229015,
      "grad_norm": 0.16432705521583557,
      "learning_rate": 8.554306816515352e-06,
      "loss": 0.1243,
      "step": 124400
    },
    {
      "epoch": 2.487901451825781,
      "grad_norm": 0.16011449694633484,
      "learning_rate": 8.550973883134025e-06,
      "loss": 0.058,
      "step": 124410
    },
    {
      "epoch": 2.4881014278286604,
      "grad_norm": 0.16825081408023834,
      "learning_rate": 8.547640949752698e-06,
      "loss": 0.0814,
      "step": 124420
    },
    {
      "epoch": 2.48830140383154,
      "grad_norm": 0.16071026027202606,
      "learning_rate": 8.544308016371369e-06,
      "loss": 0.0523,
      "step": 124430
    },
    {
      "epoch": 2.4885013798344198,
      "grad_norm": 0.2705618739128113,
      "learning_rate": 8.540975082990042e-06,
      "loss": 0.0886,
      "step": 124440
    },
    {
      "epoch": 2.4887013558372995,
      "grad_norm": 0.07447436451911926,
      "learning_rate": 8.537642149608715e-06,
      "loss": 0.0563,
      "step": 124450
    },
    {
      "epoch": 2.488901331840179,
      "grad_norm": 0.1373874545097351,
      "learning_rate": 8.534309216227386e-06,
      "loss": 0.0722,
      "step": 124460
    },
    {
      "epoch": 2.489101307843059,
      "grad_norm": 0.2533266842365265,
      "learning_rate": 8.530976282846059e-06,
      "loss": 0.0713,
      "step": 124470
    },
    {
      "epoch": 2.4893012838459385,
      "grad_norm": 0.2074500322341919,
      "learning_rate": 8.52764334946473e-06,
      "loss": 0.1146,
      "step": 124480
    },
    {
      "epoch": 2.489501259848818,
      "grad_norm": 0.14744426310062408,
      "learning_rate": 8.524310416083403e-06,
      "loss": 0.0965,
      "step": 124490
    },
    {
      "epoch": 2.489701235851698,
      "grad_norm": 0.09913653135299683,
      "learning_rate": 8.520977482702076e-06,
      "loss": 0.0634,
      "step": 124500
    },
    {
      "epoch": 2.4899012118545776,
      "grad_norm": 0.08860361576080322,
      "learning_rate": 8.517644549320748e-06,
      "loss": 0.0721,
      "step": 124510
    },
    {
      "epoch": 2.4901011878574573,
      "grad_norm": 0.10397281497716904,
      "learning_rate": 8.51431161593942e-06,
      "loss": 0.0782,
      "step": 124520
    },
    {
      "epoch": 2.490301163860337,
      "grad_norm": 0.07020615041255951,
      "learning_rate": 8.510978682558094e-06,
      "loss": 0.0653,
      "step": 124530
    },
    {
      "epoch": 2.490501139863216,
      "grad_norm": 0.154519721865654,
      "learning_rate": 8.507645749176765e-06,
      "loss": 0.0638,
      "step": 124540
    },
    {
      "epoch": 2.490701115866096,
      "grad_norm": 0.10074178874492645,
      "learning_rate": 8.504312815795438e-06,
      "loss": 0.0673,
      "step": 124550
    },
    {
      "epoch": 2.4909010918689756,
      "grad_norm": 0.16780033707618713,
      "learning_rate": 8.500979882414111e-06,
      "loss": 0.0918,
      "step": 124560
    },
    {
      "epoch": 2.4911010678718553,
      "grad_norm": 0.0908103957772255,
      "learning_rate": 8.497646949032784e-06,
      "loss": 0.0664,
      "step": 124570
    },
    {
      "epoch": 2.491301043874735,
      "grad_norm": 0.2508600056171417,
      "learning_rate": 8.494314015651455e-06,
      "loss": 0.0859,
      "step": 124580
    },
    {
      "epoch": 2.4915010198776146,
      "grad_norm": 0.06066340580582619,
      "learning_rate": 8.490981082270127e-06,
      "loss": 0.0646,
      "step": 124590
    },
    {
      "epoch": 2.4917009958804943,
      "grad_norm": 0.12772466242313385,
      "learning_rate": 8.487648148888801e-06,
      "loss": 0.0551,
      "step": 124600
    },
    {
      "epoch": 2.491900971883374,
      "grad_norm": 0.19783824682235718,
      "learning_rate": 8.484315215507473e-06,
      "loss": 0.0954,
      "step": 124610
    },
    {
      "epoch": 2.4921009478862537,
      "grad_norm": 0.06343573331832886,
      "learning_rate": 8.480982282126146e-06,
      "loss": 0.0565,
      "step": 124620
    },
    {
      "epoch": 2.4923009238891334,
      "grad_norm": 0.1981578916311264,
      "learning_rate": 8.477649348744817e-06,
      "loss": 0.0578,
      "step": 124630
    },
    {
      "epoch": 2.492500899892013,
      "grad_norm": 0.13766655325889587,
      "learning_rate": 8.47431641536349e-06,
      "loss": 0.0543,
      "step": 124640
    },
    {
      "epoch": 2.4927008758948928,
      "grad_norm": 0.18555550277233124,
      "learning_rate": 8.470983481982163e-06,
      "loss": 0.0863,
      "step": 124650
    },
    {
      "epoch": 2.4929008518977724,
      "grad_norm": 0.11437729001045227,
      "learning_rate": 8.467650548600834e-06,
      "loss": 0.0748,
      "step": 124660
    },
    {
      "epoch": 2.493100827900652,
      "grad_norm": 0.06584130227565765,
      "learning_rate": 8.464317615219507e-06,
      "loss": 0.0618,
      "step": 124670
    },
    {
      "epoch": 2.493300803903532,
      "grad_norm": 0.2383929342031479,
      "learning_rate": 8.46098468183818e-06,
      "loss": 0.0669,
      "step": 124680
    },
    {
      "epoch": 2.493500779906411,
      "grad_norm": 0.07644389569759369,
      "learning_rate": 8.457651748456852e-06,
      "loss": 0.0691,
      "step": 124690
    },
    {
      "epoch": 2.4937007559092907,
      "grad_norm": 0.21392343938350677,
      "learning_rate": 8.454318815075525e-06,
      "loss": 0.0822,
      "step": 124700
    },
    {
      "epoch": 2.4939007319121704,
      "grad_norm": 0.1673506647348404,
      "learning_rate": 8.450985881694198e-06,
      "loss": 0.1052,
      "step": 124710
    },
    {
      "epoch": 2.49410070791505,
      "grad_norm": 0.19122318923473358,
      "learning_rate": 8.447652948312869e-06,
      "loss": 0.0723,
      "step": 124720
    },
    {
      "epoch": 2.49430068391793,
      "grad_norm": 0.12707480788230896,
      "learning_rate": 8.444320014931542e-06,
      "loss": 0.0589,
      "step": 124730
    },
    {
      "epoch": 2.4945006599208095,
      "grad_norm": 0.1852714717388153,
      "learning_rate": 8.440987081550213e-06,
      "loss": 0.0983,
      "step": 124740
    },
    {
      "epoch": 2.494700635923689,
      "grad_norm": 0.12904983758926392,
      "learning_rate": 8.437654148168888e-06,
      "loss": 0.0771,
      "step": 124750
    },
    {
      "epoch": 2.494900611926569,
      "grad_norm": 0.13207487761974335,
      "learning_rate": 8.43432121478756e-06,
      "loss": 0.0526,
      "step": 124760
    },
    {
      "epoch": 2.4951005879294486,
      "grad_norm": 0.10046537965536118,
      "learning_rate": 8.43098828140623e-06,
      "loss": 0.0426,
      "step": 124770
    },
    {
      "epoch": 2.4953005639323282,
      "grad_norm": 0.19281621277332306,
      "learning_rate": 8.427655348024904e-06,
      "loss": 0.077,
      "step": 124780
    },
    {
      "epoch": 2.495500539935208,
      "grad_norm": 0.08375844359397888,
      "learning_rate": 8.424322414643577e-06,
      "loss": 0.0542,
      "step": 124790
    },
    {
      "epoch": 2.4957005159380876,
      "grad_norm": 0.18153467774391174,
      "learning_rate": 8.42098948126225e-06,
      "loss": 0.0563,
      "step": 124800
    },
    {
      "epoch": 2.495900491940967,
      "grad_norm": 0.11797797679901123,
      "learning_rate": 8.417656547880921e-06,
      "loss": 0.0851,
      "step": 124810
    },
    {
      "epoch": 2.4961004679438465,
      "grad_norm": 0.11297646909952164,
      "learning_rate": 8.414323614499594e-06,
      "loss": 0.0701,
      "step": 124820
    },
    {
      "epoch": 2.4963004439467262,
      "grad_norm": 0.12403864413499832,
      "learning_rate": 8.410990681118267e-06,
      "loss": 0.0867,
      "step": 124830
    },
    {
      "epoch": 2.496500419949606,
      "grad_norm": 0.20983868837356567,
      "learning_rate": 8.407657747736938e-06,
      "loss": 0.0989,
      "step": 124840
    },
    {
      "epoch": 2.4967003959524856,
      "grad_norm": 0.1486293226480484,
      "learning_rate": 8.404324814355611e-06,
      "loss": 0.11,
      "step": 124850
    },
    {
      "epoch": 2.4969003719553653,
      "grad_norm": 0.0881364569067955,
      "learning_rate": 8.400991880974284e-06,
      "loss": 0.0435,
      "step": 124860
    },
    {
      "epoch": 2.497100347958245,
      "grad_norm": 0.11493396759033203,
      "learning_rate": 8.397658947592956e-06,
      "loss": 0.069,
      "step": 124870
    },
    {
      "epoch": 2.4973003239611247,
      "grad_norm": 0.2418574094772339,
      "learning_rate": 8.394326014211629e-06,
      "loss": 0.0709,
      "step": 124880
    },
    {
      "epoch": 2.4975002999640044,
      "grad_norm": 0.18391326069831848,
      "learning_rate": 8.3909930808303e-06,
      "loss": 0.0688,
      "step": 124890
    },
    {
      "epoch": 2.497700275966884,
      "grad_norm": 0.11147695034742355,
      "learning_rate": 8.387660147448975e-06,
      "loss": 0.0638,
      "step": 124900
    },
    {
      "epoch": 2.4979002519697637,
      "grad_norm": 0.08071081340312958,
      "learning_rate": 8.384327214067646e-06,
      "loss": 0.0788,
      "step": 124910
    },
    {
      "epoch": 2.4981002279726434,
      "grad_norm": 0.11357609182596207,
      "learning_rate": 8.380994280686317e-06,
      "loss": 0.0603,
      "step": 124920
    },
    {
      "epoch": 2.498300203975523,
      "grad_norm": 0.15955206751823425,
      "learning_rate": 8.37766134730499e-06,
      "loss": 0.1253,
      "step": 124930
    },
    {
      "epoch": 2.498500179978403,
      "grad_norm": 0.11527442932128906,
      "learning_rate": 8.374328413923663e-06,
      "loss": 0.0446,
      "step": 124940
    },
    {
      "epoch": 2.4987001559812825,
      "grad_norm": 0.24989551305770874,
      "learning_rate": 8.370995480542336e-06,
      "loss": 0.0926,
      "step": 124950
    },
    {
      "epoch": 2.4989001319841617,
      "grad_norm": 0.18996977806091309,
      "learning_rate": 8.367662547161008e-06,
      "loss": 0.2985,
      "step": 124960
    },
    {
      "epoch": 2.4991001079870414,
      "grad_norm": 0.11185060441493988,
      "learning_rate": 8.36432961377968e-06,
      "loss": 0.0878,
      "step": 124970
    },
    {
      "epoch": 2.499300083989921,
      "grad_norm": 0.11115993559360504,
      "learning_rate": 8.360996680398354e-06,
      "loss": 0.0523,
      "step": 124980
    },
    {
      "epoch": 2.499500059992801,
      "grad_norm": 0.263313889503479,
      "learning_rate": 8.357663747017025e-06,
      "loss": 0.0891,
      "step": 124990
    },
    {
      "epoch": 2.4997000359956805,
      "grad_norm": 0.10926294326782227,
      "learning_rate": 8.354330813635696e-06,
      "loss": 0.078,
      "step": 125000
    },
    {
      "epoch": 2.49990001199856,
      "grad_norm": 0.21880629658699036,
      "learning_rate": 8.350997880254371e-06,
      "loss": 0.0554,
      "step": 125010
    },
    {
      "epoch": 2.50009998800144,
      "grad_norm": 0.15513363480567932,
      "learning_rate": 8.347664946873042e-06,
      "loss": 0.0868,
      "step": 125020
    },
    {
      "epoch": 2.5002999640043195,
      "grad_norm": 0.18846310675144196,
      "learning_rate": 8.344332013491715e-06,
      "loss": 0.0741,
      "step": 125030
    },
    {
      "epoch": 2.500499940007199,
      "grad_norm": 0.11563048511743546,
      "learning_rate": 8.340999080110387e-06,
      "loss": 0.0718,
      "step": 125040
    },
    {
      "epoch": 2.500699916010079,
      "grad_norm": 0.20396046340465546,
      "learning_rate": 8.33766614672906e-06,
      "loss": 0.0956,
      "step": 125050
    },
    {
      "epoch": 2.5008998920129586,
      "grad_norm": 0.13749462366104126,
      "learning_rate": 8.334333213347733e-06,
      "loss": 0.0655,
      "step": 125060
    },
    {
      "epoch": 2.501099868015838,
      "grad_norm": 0.10888861119747162,
      "learning_rate": 8.331000279966404e-06,
      "loss": 0.0672,
      "step": 125070
    },
    {
      "epoch": 2.5012998440187175,
      "grad_norm": 0.31848838925361633,
      "learning_rate": 8.327667346585077e-06,
      "loss": 0.1575,
      "step": 125080
    },
    {
      "epoch": 2.501499820021597,
      "grad_norm": 0.18654818832874298,
      "learning_rate": 8.32433441320375e-06,
      "loss": 0.063,
      "step": 125090
    },
    {
      "epoch": 2.501699796024477,
      "grad_norm": 0.2593456208705902,
      "learning_rate": 8.321001479822421e-06,
      "loss": 0.0696,
      "step": 125100
    },
    {
      "epoch": 2.5018997720273566,
      "grad_norm": 0.19978947937488556,
      "learning_rate": 8.317668546441094e-06,
      "loss": 0.1035,
      "step": 125110
    },
    {
      "epoch": 2.5020997480302363,
      "grad_norm": 0.16209639608860016,
      "learning_rate": 8.314335613059767e-06,
      "loss": 0.0547,
      "step": 125120
    },
    {
      "epoch": 2.502299724033116,
      "grad_norm": 0.19228249788284302,
      "learning_rate": 8.31100267967844e-06,
      "loss": 0.1128,
      "step": 125130
    },
    {
      "epoch": 2.5024997000359956,
      "grad_norm": 0.10354144126176834,
      "learning_rate": 8.307669746297111e-06,
      "loss": 0.0509,
      "step": 125140
    },
    {
      "epoch": 2.5026996760388753,
      "grad_norm": 0.21097718179225922,
      "learning_rate": 8.304336812915783e-06,
      "loss": 0.0514,
      "step": 125150
    },
    {
      "epoch": 2.502899652041755,
      "grad_norm": 0.14890137314796448,
      "learning_rate": 8.301003879534457e-06,
      "loss": 0.0722,
      "step": 125160
    },
    {
      "epoch": 2.5030996280446347,
      "grad_norm": 0.0657023936510086,
      "learning_rate": 8.297670946153129e-06,
      "loss": 0.0431,
      "step": 125170
    },
    {
      "epoch": 2.5032996040475144,
      "grad_norm": 0.1297122985124588,
      "learning_rate": 8.294338012771802e-06,
      "loss": 0.0703,
      "step": 125180
    },
    {
      "epoch": 2.503499580050394,
      "grad_norm": 0.2594870626926422,
      "learning_rate": 8.291005079390473e-06,
      "loss": 0.1065,
      "step": 125190
    },
    {
      "epoch": 2.5036995560532738,
      "grad_norm": 0.07751857489347458,
      "learning_rate": 8.287672146009146e-06,
      "loss": 0.0814,
      "step": 125200
    },
    {
      "epoch": 2.5038995320561535,
      "grad_norm": 0.0705447793006897,
      "learning_rate": 8.284339212627819e-06,
      "loss": 0.0563,
      "step": 125210
    },
    {
      "epoch": 2.504099508059033,
      "grad_norm": 0.09733781963586807,
      "learning_rate": 8.28100627924649e-06,
      "loss": 0.0732,
      "step": 125220
    },
    {
      "epoch": 2.504299484061913,
      "grad_norm": 0.058948103338479996,
      "learning_rate": 8.277673345865163e-06,
      "loss": 0.052,
      "step": 125230
    },
    {
      "epoch": 2.504499460064792,
      "grad_norm": 0.14981402456760406,
      "learning_rate": 8.274340412483836e-06,
      "loss": 0.0577,
      "step": 125240
    },
    {
      "epoch": 2.5046994360676718,
      "grad_norm": 0.23829488456249237,
      "learning_rate": 8.271007479102508e-06,
      "loss": 0.1447,
      "step": 125250
    },
    {
      "epoch": 2.5048994120705514,
      "grad_norm": 0.20735758543014526,
      "learning_rate": 8.26767454572118e-06,
      "loss": 0.0671,
      "step": 125260
    },
    {
      "epoch": 2.505099388073431,
      "grad_norm": 0.11134139448404312,
      "learning_rate": 8.264341612339852e-06,
      "loss": 0.1304,
      "step": 125270
    },
    {
      "epoch": 2.505299364076311,
      "grad_norm": 0.18132542073726654,
      "learning_rate": 8.261008678958525e-06,
      "loss": 0.0947,
      "step": 125280
    },
    {
      "epoch": 2.5054993400791905,
      "grad_norm": 0.21623755991458893,
      "learning_rate": 8.257675745577198e-06,
      "loss": 0.0683,
      "step": 125290
    },
    {
      "epoch": 2.50569931608207,
      "grad_norm": 0.06586955487728119,
      "learning_rate": 8.25434281219587e-06,
      "loss": 0.0732,
      "step": 125300
    },
    {
      "epoch": 2.50589929208495,
      "grad_norm": 0.12085973471403122,
      "learning_rate": 8.251009878814542e-06,
      "loss": 0.074,
      "step": 125310
    },
    {
      "epoch": 2.5060992680878296,
      "grad_norm": 0.20750433206558228,
      "learning_rate": 8.247676945433215e-06,
      "loss": 0.0675,
      "step": 125320
    },
    {
      "epoch": 2.5062992440907093,
      "grad_norm": 0.14387522637844086,
      "learning_rate": 8.244344012051887e-06,
      "loss": 0.103,
      "step": 125330
    },
    {
      "epoch": 2.5064992200935885,
      "grad_norm": 0.08943289518356323,
      "learning_rate": 8.24101107867056e-06,
      "loss": 0.061,
      "step": 125340
    },
    {
      "epoch": 2.506699196096468,
      "grad_norm": 0.13616950809955597,
      "learning_rate": 8.237678145289233e-06,
      "loss": 0.0478,
      "step": 125350
    },
    {
      "epoch": 2.506899172099348,
      "grad_norm": 0.0930556207895279,
      "learning_rate": 8.234345211907906e-06,
      "loss": 0.077,
      "step": 125360
    },
    {
      "epoch": 2.5070991481022276,
      "grad_norm": 0.2109675407409668,
      "learning_rate": 8.231012278526577e-06,
      "loss": 0.0798,
      "step": 125370
    },
    {
      "epoch": 2.5072991241051072,
      "grad_norm": 0.13857056200504303,
      "learning_rate": 8.227679345145248e-06,
      "loss": 0.0394,
      "step": 125380
    },
    {
      "epoch": 2.507499100107987,
      "grad_norm": 0.17928193509578705,
      "learning_rate": 8.224346411763923e-06,
      "loss": 0.1112,
      "step": 125390
    },
    {
      "epoch": 2.5076990761108666,
      "grad_norm": 0.057670459151268005,
      "learning_rate": 8.221013478382594e-06,
      "loss": 0.0447,
      "step": 125400
    },
    {
      "epoch": 2.5078990521137463,
      "grad_norm": 0.10057726502418518,
      "learning_rate": 8.217680545001267e-06,
      "loss": 0.0695,
      "step": 125410
    },
    {
      "epoch": 2.508099028116626,
      "grad_norm": 0.16088268160820007,
      "learning_rate": 8.214347611619939e-06,
      "loss": 0.0763,
      "step": 125420
    },
    {
      "epoch": 2.5082990041195057,
      "grad_norm": 0.10935639590024948,
      "learning_rate": 8.211014678238612e-06,
      "loss": 0.047,
      "step": 125430
    },
    {
      "epoch": 2.5084989801223854,
      "grad_norm": 0.22067859768867493,
      "learning_rate": 8.207681744857285e-06,
      "loss": 0.0789,
      "step": 125440
    },
    {
      "epoch": 2.508698956125265,
      "grad_norm": 0.10099998861551285,
      "learning_rate": 8.204348811475956e-06,
      "loss": 0.0715,
      "step": 125450
    },
    {
      "epoch": 2.5088989321281447,
      "grad_norm": 0.09042097628116608,
      "learning_rate": 8.201015878094629e-06,
      "loss": 0.0608,
      "step": 125460
    },
    {
      "epoch": 2.5090989081310244,
      "grad_norm": 0.11984946578741074,
      "learning_rate": 8.197682944713302e-06,
      "loss": 0.0732,
      "step": 125470
    },
    {
      "epoch": 2.509298884133904,
      "grad_norm": 0.18719176948070526,
      "learning_rate": 8.194350011331973e-06,
      "loss": 0.0717,
      "step": 125480
    },
    {
      "epoch": 2.509498860136784,
      "grad_norm": 0.09393474459648132,
      "learning_rate": 8.191017077950646e-06,
      "loss": 0.0612,
      "step": 125490
    },
    {
      "epoch": 2.5096988361396635,
      "grad_norm": 0.1723342090845108,
      "learning_rate": 8.18768414456932e-06,
      "loss": 0.0833,
      "step": 125500
    },
    {
      "epoch": 2.5098988121425427,
      "grad_norm": 0.08071738481521606,
      "learning_rate": 8.18435121118799e-06,
      "loss": 0.0551,
      "step": 125510
    },
    {
      "epoch": 2.5100987881454224,
      "grad_norm": 0.09420180320739746,
      "learning_rate": 8.181018277806664e-06,
      "loss": 0.0585,
      "step": 125520
    },
    {
      "epoch": 2.510298764148302,
      "grad_norm": 0.09878798574209213,
      "learning_rate": 8.177685344425335e-06,
      "loss": 0.0604,
      "step": 125530
    },
    {
      "epoch": 2.510498740151182,
      "grad_norm": 0.1432066410779953,
      "learning_rate": 8.17435241104401e-06,
      "loss": 0.0892,
      "step": 125540
    },
    {
      "epoch": 2.5106987161540615,
      "grad_norm": 0.15023386478424072,
      "learning_rate": 8.171019477662681e-06,
      "loss": 0.0756,
      "step": 125550
    },
    {
      "epoch": 2.510898692156941,
      "grad_norm": 0.12181326001882553,
      "learning_rate": 8.167686544281352e-06,
      "loss": 0.1086,
      "step": 125560
    },
    {
      "epoch": 2.511098668159821,
      "grad_norm": 0.17840522527694702,
      "learning_rate": 8.164353610900025e-06,
      "loss": 0.0678,
      "step": 125570
    },
    {
      "epoch": 2.5112986441627005,
      "grad_norm": 0.10370352864265442,
      "learning_rate": 8.161020677518698e-06,
      "loss": 0.0804,
      "step": 125580
    },
    {
      "epoch": 2.5114986201655802,
      "grad_norm": 0.07457663863897324,
      "learning_rate": 8.157687744137371e-06,
      "loss": 0.0942,
      "step": 125590
    },
    {
      "epoch": 2.51169859616846,
      "grad_norm": 0.30679187178611755,
      "learning_rate": 8.154354810756043e-06,
      "loss": 0.0918,
      "step": 125600
    },
    {
      "epoch": 2.5118985721713396,
      "grad_norm": 0.18827681243419647,
      "learning_rate": 8.151021877374716e-06,
      "loss": 0.0614,
      "step": 125610
    },
    {
      "epoch": 2.512098548174219,
      "grad_norm": 0.11568236351013184,
      "learning_rate": 8.147688943993389e-06,
      "loss": 0.1101,
      "step": 125620
    },
    {
      "epoch": 2.5122985241770985,
      "grad_norm": 0.15050889551639557,
      "learning_rate": 8.14435601061206e-06,
      "loss": 0.0548,
      "step": 125630
    },
    {
      "epoch": 2.5124985001799782,
      "grad_norm": 0.10922033339738846,
      "learning_rate": 8.141023077230733e-06,
      "loss": 0.0562,
      "step": 125640
    },
    {
      "epoch": 2.512698476182858,
      "grad_norm": 0.07008088380098343,
      "learning_rate": 8.137690143849406e-06,
      "loss": 0.0463,
      "step": 125650
    },
    {
      "epoch": 2.5128984521857376,
      "grad_norm": 0.048936422914266586,
      "learning_rate": 8.134357210468077e-06,
      "loss": 0.0521,
      "step": 125660
    },
    {
      "epoch": 2.5130984281886173,
      "grad_norm": 0.1272275298833847,
      "learning_rate": 8.13102427708675e-06,
      "loss": 0.0884,
      "step": 125670
    },
    {
      "epoch": 2.513298404191497,
      "grad_norm": 0.12732718884944916,
      "learning_rate": 8.127691343705421e-06,
      "loss": 0.0491,
      "step": 125680
    },
    {
      "epoch": 2.5134983801943767,
      "grad_norm": 0.199164479970932,
      "learning_rate": 8.124358410324096e-06,
      "loss": 0.1099,
      "step": 125690
    },
    {
      "epoch": 2.5136983561972563,
      "grad_norm": 0.09614479541778564,
      "learning_rate": 8.121025476942767e-06,
      "loss": 0.0744,
      "step": 125700
    },
    {
      "epoch": 2.513898332200136,
      "grad_norm": 0.23737186193466187,
      "learning_rate": 8.117692543561439e-06,
      "loss": 0.0762,
      "step": 125710
    },
    {
      "epoch": 2.5140983082030157,
      "grad_norm": 0.09755656123161316,
      "learning_rate": 8.114359610180112e-06,
      "loss": 0.0479,
      "step": 125720
    },
    {
      "epoch": 2.5142982842058954,
      "grad_norm": 0.110007643699646,
      "learning_rate": 8.111026676798785e-06,
      "loss": 0.0991,
      "step": 125730
    },
    {
      "epoch": 2.514498260208775,
      "grad_norm": 0.05852973088622093,
      "learning_rate": 8.107693743417456e-06,
      "loss": 0.0614,
      "step": 125740
    },
    {
      "epoch": 2.514698236211655,
      "grad_norm": 0.15562549233436584,
      "learning_rate": 8.104360810036129e-06,
      "loss": 0.0842,
      "step": 125750
    },
    {
      "epoch": 2.5148982122145345,
      "grad_norm": 0.2487562596797943,
      "learning_rate": 8.101027876654802e-06,
      "loss": 0.1169,
      "step": 125760
    },
    {
      "epoch": 2.515098188217414,
      "grad_norm": 0.1954527497291565,
      "learning_rate": 8.097694943273475e-06,
      "loss": 0.0713,
      "step": 125770
    },
    {
      "epoch": 2.515298164220294,
      "grad_norm": 0.16904686391353607,
      "learning_rate": 8.094362009892146e-06,
      "loss": 0.0839,
      "step": 125780
    },
    {
      "epoch": 2.515498140223173,
      "grad_norm": 0.10810071229934692,
      "learning_rate": 8.091029076510818e-06,
      "loss": 0.0797,
      "step": 125790
    },
    {
      "epoch": 2.5156981162260528,
      "grad_norm": 0.13047008216381073,
      "learning_rate": 8.087696143129492e-06,
      "loss": 0.0835,
      "step": 125800
    },
    {
      "epoch": 2.5158980922289325,
      "grad_norm": 0.14060167968273163,
      "learning_rate": 8.084363209748164e-06,
      "loss": 0.0701,
      "step": 125810
    },
    {
      "epoch": 2.516098068231812,
      "grad_norm": 0.0959438756108284,
      "learning_rate": 8.081030276366837e-06,
      "loss": 0.049,
      "step": 125820
    },
    {
      "epoch": 2.516298044234692,
      "grad_norm": 0.09497274458408356,
      "learning_rate": 8.077697342985508e-06,
      "loss": 0.0726,
      "step": 125830
    },
    {
      "epoch": 2.5164980202375715,
      "grad_norm": 0.1291128396987915,
      "learning_rate": 8.074364409604181e-06,
      "loss": 0.072,
      "step": 125840
    },
    {
      "epoch": 2.516697996240451,
      "grad_norm": 0.10026788711547852,
      "learning_rate": 8.071031476222854e-06,
      "loss": 0.0847,
      "step": 125850
    },
    {
      "epoch": 2.516897972243331,
      "grad_norm": 0.10596919804811478,
      "learning_rate": 8.067698542841525e-06,
      "loss": 0.0824,
      "step": 125860
    },
    {
      "epoch": 2.5170979482462106,
      "grad_norm": 0.22186289727687836,
      "learning_rate": 8.064365609460198e-06,
      "loss": 0.0822,
      "step": 125870
    },
    {
      "epoch": 2.5172979242490903,
      "grad_norm": 0.10322151333093643,
      "learning_rate": 8.061032676078871e-06,
      "loss": 0.0561,
      "step": 125880
    },
    {
      "epoch": 2.5174979002519695,
      "grad_norm": 0.14363250136375427,
      "learning_rate": 8.057699742697543e-06,
      "loss": 0.058,
      "step": 125890
    },
    {
      "epoch": 2.517697876254849,
      "grad_norm": 0.0999736338853836,
      "learning_rate": 8.054366809316216e-06,
      "loss": 0.0801,
      "step": 125900
    },
    {
      "epoch": 2.517897852257729,
      "grad_norm": 0.08599007874727249,
      "learning_rate": 8.051033875934889e-06,
      "loss": 0.5257,
      "step": 125910
    },
    {
      "epoch": 2.5180978282606086,
      "grad_norm": 0.2024002969264984,
      "learning_rate": 8.047700942553562e-06,
      "loss": 0.0507,
      "step": 125920
    },
    {
      "epoch": 2.5182978042634883,
      "grad_norm": 0.23688454926013947,
      "learning_rate": 8.044368009172233e-06,
      "loss": 0.0901,
      "step": 125930
    },
    {
      "epoch": 2.518497780266368,
      "grad_norm": 0.23110370337963104,
      "learning_rate": 8.041035075790904e-06,
      "loss": 0.0895,
      "step": 125940
    },
    {
      "epoch": 2.5186977562692476,
      "grad_norm": 0.11801470816135406,
      "learning_rate": 8.037702142409579e-06,
      "loss": 0.0872,
      "step": 125950
    },
    {
      "epoch": 2.5188977322721273,
      "grad_norm": 0.2265283465385437,
      "learning_rate": 8.03436920902825e-06,
      "loss": 0.0801,
      "step": 125960
    },
    {
      "epoch": 2.519097708275007,
      "grad_norm": 0.08521698415279388,
      "learning_rate": 8.031036275646922e-06,
      "loss": 0.0536,
      "step": 125970
    },
    {
      "epoch": 2.5192976842778867,
      "grad_norm": 0.0731395035982132,
      "learning_rate": 8.027703342265595e-06,
      "loss": 0.0865,
      "step": 125980
    },
    {
      "epoch": 2.5194976602807664,
      "grad_norm": 0.12525607645511627,
      "learning_rate": 8.024370408884268e-06,
      "loss": 0.0896,
      "step": 125990
    },
    {
      "epoch": 2.519697636283646,
      "grad_norm": 0.11162122339010239,
      "learning_rate": 8.02103747550294e-06,
      "loss": 0.0654,
      "step": 126000
    },
    {
      "epoch": 2.5198976122865258,
      "grad_norm": 0.1611795276403427,
      "learning_rate": 8.017704542121612e-06,
      "loss": 0.0384,
      "step": 126010
    },
    {
      "epoch": 2.5200975882894054,
      "grad_norm": 0.10693108290433884,
      "learning_rate": 8.014371608740285e-06,
      "loss": 0.0517,
      "step": 126020
    },
    {
      "epoch": 2.520297564292285,
      "grad_norm": 0.17640510201454163,
      "learning_rate": 8.011038675358958e-06,
      "loss": 0.1894,
      "step": 126030
    },
    {
      "epoch": 2.520497540295165,
      "grad_norm": 0.190530464053154,
      "learning_rate": 8.00770574197763e-06,
      "loss": 0.0798,
      "step": 126040
    },
    {
      "epoch": 2.5206975162980445,
      "grad_norm": 0.16151419281959534,
      "learning_rate": 8.004372808596302e-06,
      "loss": 0.0504,
      "step": 126050
    },
    {
      "epoch": 2.5208974923009237,
      "grad_norm": 0.10592539608478546,
      "learning_rate": 8.001039875214975e-06,
      "loss": 0.0581,
      "step": 126060
    },
    {
      "epoch": 2.5210974683038034,
      "grad_norm": 0.07079893350601196,
      "learning_rate": 7.997706941833647e-06,
      "loss": 0.0744,
      "step": 126070
    },
    {
      "epoch": 2.521297444306683,
      "grad_norm": 0.25479254126548767,
      "learning_rate": 7.99437400845232e-06,
      "loss": 0.0716,
      "step": 126080
    },
    {
      "epoch": 2.521497420309563,
      "grad_norm": 0.18434187769889832,
      "learning_rate": 7.991041075070991e-06,
      "loss": 0.047,
      "step": 126090
    },
    {
      "epoch": 2.5216973963124425,
      "grad_norm": 0.26172786951065063,
      "learning_rate": 7.987708141689666e-06,
      "loss": 0.0789,
      "step": 126100
    },
    {
      "epoch": 2.521897372315322,
      "grad_norm": 0.12969431281089783,
      "learning_rate": 7.984375208308337e-06,
      "loss": 0.0695,
      "step": 126110
    },
    {
      "epoch": 2.522097348318202,
      "grad_norm": 0.0711297020316124,
      "learning_rate": 7.981042274927008e-06,
      "loss": 0.0522,
      "step": 126120
    },
    {
      "epoch": 2.5222973243210816,
      "grad_norm": 0.12132327258586884,
      "learning_rate": 7.977709341545681e-06,
      "loss": 0.0817,
      "step": 126130
    },
    {
      "epoch": 2.5224973003239612,
      "grad_norm": 0.1185082271695137,
      "learning_rate": 7.974376408164354e-06,
      "loss": 0.0765,
      "step": 126140
    },
    {
      "epoch": 2.522697276326841,
      "grad_norm": 0.21207520365715027,
      "learning_rate": 7.971043474783027e-06,
      "loss": 0.0872,
      "step": 126150
    },
    {
      "epoch": 2.52289725232972,
      "grad_norm": 0.12710043787956238,
      "learning_rate": 7.967710541401699e-06,
      "loss": 0.0887,
      "step": 126160
    },
    {
      "epoch": 2.5230972283326,
      "grad_norm": 0.24713444709777832,
      "learning_rate": 7.964377608020372e-06,
      "loss": 0.0616,
      "step": 126170
    },
    {
      "epoch": 2.5232972043354795,
      "grad_norm": 0.23687799274921417,
      "learning_rate": 7.961044674639045e-06,
      "loss": 0.1172,
      "step": 126180
    },
    {
      "epoch": 2.5234971803383592,
      "grad_norm": 0.06075451150536537,
      "learning_rate": 7.957711741257716e-06,
      "loss": 0.0524,
      "step": 126190
    },
    {
      "epoch": 2.523697156341239,
      "grad_norm": 0.1260833442211151,
      "learning_rate": 7.954378807876389e-06,
      "loss": 0.1017,
      "step": 126200
    },
    {
      "epoch": 2.5238971323441186,
      "grad_norm": 0.08294759690761566,
      "learning_rate": 7.951045874495062e-06,
      "loss": 0.0637,
      "step": 126210
    },
    {
      "epoch": 2.5240971083469983,
      "grad_norm": 0.06785472482442856,
      "learning_rate": 7.947712941113733e-06,
      "loss": 0.085,
      "step": 126220
    },
    {
      "epoch": 2.524297084349878,
      "grad_norm": 0.17884986102581024,
      "learning_rate": 7.944380007732406e-06,
      "loss": 0.082,
      "step": 126230
    },
    {
      "epoch": 2.5244970603527577,
      "grad_norm": 0.1875467598438263,
      "learning_rate": 7.941047074351078e-06,
      "loss": 0.0628,
      "step": 126240
    },
    {
      "epoch": 2.5246970363556374,
      "grad_norm": 0.15352386236190796,
      "learning_rate": 7.93771414096975e-06,
      "loss": 0.0746,
      "step": 126250
    },
    {
      "epoch": 2.524897012358517,
      "grad_norm": 0.14751632511615753,
      "learning_rate": 7.934381207588424e-06,
      "loss": 0.0403,
      "step": 126260
    },
    {
      "epoch": 2.5250969883613967,
      "grad_norm": 0.07541237771511078,
      "learning_rate": 7.931048274207095e-06,
      "loss": 0.0663,
      "step": 126270
    },
    {
      "epoch": 2.5252969643642764,
      "grad_norm": 0.24130438268184662,
      "learning_rate": 7.927715340825768e-06,
      "loss": 0.0684,
      "step": 126280
    },
    {
      "epoch": 2.525496940367156,
      "grad_norm": 0.06232547014951706,
      "learning_rate": 7.924382407444441e-06,
      "loss": 0.0879,
      "step": 126290
    },
    {
      "epoch": 2.525696916370036,
      "grad_norm": 0.13419954478740692,
      "learning_rate": 7.921049474063112e-06,
      "loss": 0.0814,
      "step": 126300
    },
    {
      "epoch": 2.5258968923729155,
      "grad_norm": 0.05388946458697319,
      "learning_rate": 7.917716540681785e-06,
      "loss": 0.0782,
      "step": 126310
    },
    {
      "epoch": 2.526096868375795,
      "grad_norm": 0.20207339525222778,
      "learning_rate": 7.914383607300458e-06,
      "loss": 0.0585,
      "step": 126320
    },
    {
      "epoch": 2.5262968443786744,
      "grad_norm": 0.09717642515897751,
      "learning_rate": 7.911050673919131e-06,
      "loss": 0.0762,
      "step": 126330
    },
    {
      "epoch": 2.526496820381554,
      "grad_norm": 0.06046152859926224,
      "learning_rate": 7.907717740537802e-06,
      "loss": 0.0536,
      "step": 126340
    },
    {
      "epoch": 2.526696796384434,
      "grad_norm": 0.20330604910850525,
      "learning_rate": 7.904384807156474e-06,
      "loss": 0.0818,
      "step": 126350
    },
    {
      "epoch": 2.5268967723873135,
      "grad_norm": 0.07534507662057877,
      "learning_rate": 7.901051873775148e-06,
      "loss": 0.0386,
      "step": 126360
    },
    {
      "epoch": 2.527096748390193,
      "grad_norm": 0.1602163016796112,
      "learning_rate": 7.89771894039382e-06,
      "loss": 0.1022,
      "step": 126370
    },
    {
      "epoch": 2.527296724393073,
      "grad_norm": 0.20738498866558075,
      "learning_rate": 7.894386007012493e-06,
      "loss": 0.0592,
      "step": 126380
    },
    {
      "epoch": 2.5274967003959525,
      "grad_norm": 0.08679833263158798,
      "learning_rate": 7.891053073631164e-06,
      "loss": 0.08,
      "step": 126390
    },
    {
      "epoch": 2.527696676398832,
      "grad_norm": 0.06655538082122803,
      "learning_rate": 7.887720140249837e-06,
      "loss": 0.0378,
      "step": 126400
    },
    {
      "epoch": 2.527896652401712,
      "grad_norm": 0.10073218494653702,
      "learning_rate": 7.88438720686851e-06,
      "loss": 0.0886,
      "step": 126410
    },
    {
      "epoch": 2.5280966284045916,
      "grad_norm": 0.08015068620443344,
      "learning_rate": 7.881054273487181e-06,
      "loss": 0.1214,
      "step": 126420
    },
    {
      "epoch": 2.528296604407471,
      "grad_norm": 0.1861138939857483,
      "learning_rate": 7.877721340105854e-06,
      "loss": 0.099,
      "step": 126430
    },
    {
      "epoch": 2.5284965804103505,
      "grad_norm": 0.1550968438386917,
      "learning_rate": 7.874388406724527e-06,
      "loss": 0.0626,
      "step": 126440
    },
    {
      "epoch": 2.52869655641323,
      "grad_norm": 0.06779074668884277,
      "learning_rate": 7.871055473343199e-06,
      "loss": 0.0668,
      "step": 126450
    },
    {
      "epoch": 2.52889653241611,
      "grad_norm": 0.15760573744773865,
      "learning_rate": 7.867722539961872e-06,
      "loss": 0.0774,
      "step": 126460
    },
    {
      "epoch": 2.5290965084189896,
      "grad_norm": 0.21925224363803864,
      "learning_rate": 7.864389606580543e-06,
      "loss": 0.054,
      "step": 126470
    },
    {
      "epoch": 2.5292964844218693,
      "grad_norm": 0.2607448697090149,
      "learning_rate": 7.861056673199216e-06,
      "loss": 0.0985,
      "step": 126480
    },
    {
      "epoch": 2.529496460424749,
      "grad_norm": 0.1837386041879654,
      "learning_rate": 7.857723739817889e-06,
      "loss": 0.0667,
      "step": 126490
    },
    {
      "epoch": 2.5296964364276286,
      "grad_norm": 0.12937523424625397,
      "learning_rate": 7.85439080643656e-06,
      "loss": 0.0724,
      "step": 126500
    },
    {
      "epoch": 2.5298964124305083,
      "grad_norm": 0.057934604585170746,
      "learning_rate": 7.851057873055233e-06,
      "loss": 0.0542,
      "step": 126510
    },
    {
      "epoch": 2.530096388433388,
      "grad_norm": 0.08198881149291992,
      "learning_rate": 7.847724939673906e-06,
      "loss": 0.0497,
      "step": 126520
    },
    {
      "epoch": 2.5302963644362677,
      "grad_norm": 0.07347632199525833,
      "learning_rate": 7.844392006292578e-06,
      "loss": 0.0752,
      "step": 126530
    },
    {
      "epoch": 2.5304963404391474,
      "grad_norm": 0.1584426611661911,
      "learning_rate": 7.84105907291125e-06,
      "loss": 0.0625,
      "step": 126540
    },
    {
      "epoch": 2.530696316442027,
      "grad_norm": 0.16000497341156006,
      "learning_rate": 7.837726139529924e-06,
      "loss": 0.0897,
      "step": 126550
    },
    {
      "epoch": 2.5308962924449068,
      "grad_norm": 0.17650699615478516,
      "learning_rate": 7.834393206148597e-06,
      "loss": 0.0747,
      "step": 126560
    },
    {
      "epoch": 2.5310962684477865,
      "grad_norm": 0.10220570117235184,
      "learning_rate": 7.831060272767268e-06,
      "loss": 0.0546,
      "step": 126570
    },
    {
      "epoch": 2.531296244450666,
      "grad_norm": 0.1105998307466507,
      "learning_rate": 7.82772733938594e-06,
      "loss": 0.0635,
      "step": 126580
    },
    {
      "epoch": 2.531496220453546,
      "grad_norm": 0.2341422736644745,
      "learning_rate": 7.824394406004614e-06,
      "loss": 0.0874,
      "step": 126590
    },
    {
      "epoch": 2.531696196456425,
      "grad_norm": 0.07326474785804749,
      "learning_rate": 7.821061472623285e-06,
      "loss": 0.1227,
      "step": 126600
    },
    {
      "epoch": 2.5318961724593048,
      "grad_norm": 0.2090757191181183,
      "learning_rate": 7.817728539241958e-06,
      "loss": 0.1141,
      "step": 126610
    },
    {
      "epoch": 2.5320961484621844,
      "grad_norm": 0.13098189234733582,
      "learning_rate": 7.81439560586063e-06,
      "loss": 0.0546,
      "step": 126620
    },
    {
      "epoch": 2.532296124465064,
      "grad_norm": 0.26569512486457825,
      "learning_rate": 7.811062672479303e-06,
      "loss": 0.0816,
      "step": 126630
    },
    {
      "epoch": 2.532496100467944,
      "grad_norm": 0.2631731331348419,
      "learning_rate": 7.807729739097976e-06,
      "loss": 0.0934,
      "step": 126640
    },
    {
      "epoch": 2.5326960764708235,
      "grad_norm": 0.15339595079421997,
      "learning_rate": 7.804396805716647e-06,
      "loss": 0.0886,
      "step": 126650
    },
    {
      "epoch": 2.532896052473703,
      "grad_norm": 0.23870418965816498,
      "learning_rate": 7.80106387233532e-06,
      "loss": 0.0728,
      "step": 126660
    },
    {
      "epoch": 2.533096028476583,
      "grad_norm": 0.09553811699151993,
      "learning_rate": 7.797730938953993e-06,
      "loss": 0.0666,
      "step": 126670
    },
    {
      "epoch": 2.5332960044794626,
      "grad_norm": 0.16113154590129852,
      "learning_rate": 7.794398005572664e-06,
      "loss": 0.0929,
      "step": 126680
    },
    {
      "epoch": 2.5334959804823423,
      "grad_norm": 0.16573701798915863,
      "learning_rate": 7.791065072191337e-06,
      "loss": 0.0693,
      "step": 126690
    },
    {
      "epoch": 2.5336959564852215,
      "grad_norm": 0.06729511171579361,
      "learning_rate": 7.78773213881001e-06,
      "loss": 0.0743,
      "step": 126700
    },
    {
      "epoch": 2.533895932488101,
      "grad_norm": 0.1424282342195511,
      "learning_rate": 7.784399205428683e-06,
      "loss": 0.0879,
      "step": 126710
    },
    {
      "epoch": 2.534095908490981,
      "grad_norm": 0.2572692930698395,
      "learning_rate": 7.781066272047355e-06,
      "loss": 0.062,
      "step": 126720
    },
    {
      "epoch": 2.5342958844938606,
      "grad_norm": 0.13422967493534088,
      "learning_rate": 7.777733338666026e-06,
      "loss": 0.1083,
      "step": 126730
    },
    {
      "epoch": 2.5344958604967402,
      "grad_norm": 0.09754928201436996,
      "learning_rate": 7.7744004052847e-06,
      "loss": 0.076,
      "step": 126740
    },
    {
      "epoch": 2.53469583649962,
      "grad_norm": 0.08595412969589233,
      "learning_rate": 7.771067471903372e-06,
      "loss": 0.0689,
      "step": 126750
    },
    {
      "epoch": 2.5348958125024996,
      "grad_norm": 0.12033355981111526,
      "learning_rate": 7.767734538522043e-06,
      "loss": 0.0879,
      "step": 126760
    },
    {
      "epoch": 2.5350957885053793,
      "grad_norm": 0.11593669652938843,
      "learning_rate": 7.764401605140716e-06,
      "loss": 0.0937,
      "step": 126770
    },
    {
      "epoch": 2.535295764508259,
      "grad_norm": 0.20259873569011688,
      "learning_rate": 7.76106867175939e-06,
      "loss": 0.0885,
      "step": 126780
    },
    {
      "epoch": 2.5354957405111387,
      "grad_norm": 0.11826901137828827,
      "learning_rate": 7.757735738378062e-06,
      "loss": 0.0628,
      "step": 126790
    },
    {
      "epoch": 2.5356957165140184,
      "grad_norm": 0.0885206088423729,
      "learning_rate": 7.754402804996734e-06,
      "loss": 0.0337,
      "step": 126800
    },
    {
      "epoch": 2.535895692516898,
      "grad_norm": 0.1187109425663948,
      "learning_rate": 7.751069871615407e-06,
      "loss": 0.0662,
      "step": 126810
    },
    {
      "epoch": 2.5360956685197777,
      "grad_norm": 0.06045647710561752,
      "learning_rate": 7.74773693823408e-06,
      "loss": 0.0359,
      "step": 126820
    },
    {
      "epoch": 2.5362956445226574,
      "grad_norm": 0.08507293462753296,
      "learning_rate": 7.744404004852751e-06,
      "loss": 0.0414,
      "step": 126830
    },
    {
      "epoch": 2.536495620525537,
      "grad_norm": 0.24890977144241333,
      "learning_rate": 7.741071071471424e-06,
      "loss": 0.0632,
      "step": 126840
    },
    {
      "epoch": 2.536695596528417,
      "grad_norm": 0.14475636184215546,
      "learning_rate": 7.737738138090097e-06,
      "loss": 0.0913,
      "step": 126850
    },
    {
      "epoch": 2.5368955725312965,
      "grad_norm": 0.16782155632972717,
      "learning_rate": 7.734405204708768e-06,
      "loss": 0.0632,
      "step": 126860
    },
    {
      "epoch": 2.5370955485341757,
      "grad_norm": 0.2918132543563843,
      "learning_rate": 7.731072271327441e-06,
      "loss": 0.1589,
      "step": 126870
    },
    {
      "epoch": 2.5372955245370554,
      "grad_norm": 0.07739892601966858,
      "learning_rate": 7.727739337946113e-06,
      "loss": 0.0668,
      "step": 126880
    },
    {
      "epoch": 2.537495500539935,
      "grad_norm": 0.1070784330368042,
      "learning_rate": 7.724406404564787e-06,
      "loss": 0.0561,
      "step": 126890
    },
    {
      "epoch": 2.537695476542815,
      "grad_norm": 0.09467839449644089,
      "learning_rate": 7.721406764521591e-06,
      "loss": 0.1022,
      "step": 126900
    },
    {
      "epoch": 2.5378954525456945,
      "grad_norm": 0.20918653905391693,
      "learning_rate": 7.718073831140264e-06,
      "loss": 0.0363,
      "step": 126910
    },
    {
      "epoch": 2.538095428548574,
      "grad_norm": 0.1866326481103897,
      "learning_rate": 7.714740897758937e-06,
      "loss": 0.0633,
      "step": 126920
    },
    {
      "epoch": 2.538295404551454,
      "grad_norm": 0.10336438566446304,
      "learning_rate": 7.711407964377608e-06,
      "loss": 0.0524,
      "step": 126930
    },
    {
      "epoch": 2.5384953805543335,
      "grad_norm": 0.15526911616325378,
      "learning_rate": 7.708075030996281e-06,
      "loss": 0.0692,
      "step": 126940
    },
    {
      "epoch": 2.5386953565572132,
      "grad_norm": 0.2463497519493103,
      "learning_rate": 7.704742097614953e-06,
      "loss": 0.066,
      "step": 126950
    },
    {
      "epoch": 2.538895332560093,
      "grad_norm": 0.20597371459007263,
      "learning_rate": 7.701409164233626e-06,
      "loss": 0.0764,
      "step": 126960
    },
    {
      "epoch": 2.5390953085629726,
      "grad_norm": 0.07747559249401093,
      "learning_rate": 7.698076230852299e-06,
      "loss": 0.0342,
      "step": 126970
    },
    {
      "epoch": 2.539295284565852,
      "grad_norm": 0.15080302953720093,
      "learning_rate": 7.69474329747097e-06,
      "loss": 0.0581,
      "step": 126980
    },
    {
      "epoch": 2.5394952605687315,
      "grad_norm": 0.06937988102436066,
      "learning_rate": 7.691410364089643e-06,
      "loss": 0.0562,
      "step": 126990
    },
    {
      "epoch": 2.5396952365716112,
      "grad_norm": 0.06876514106988907,
      "learning_rate": 7.688077430708316e-06,
      "loss": 0.06,
      "step": 127000
    },
    {
      "epoch": 2.539895212574491,
      "grad_norm": 0.1875220388174057,
      "learning_rate": 7.684744497326987e-06,
      "loss": 0.0436,
      "step": 127010
    },
    {
      "epoch": 2.5400951885773706,
      "grad_norm": 0.11603933572769165,
      "learning_rate": 7.68141156394566e-06,
      "loss": 0.051,
      "step": 127020
    },
    {
      "epoch": 2.5402951645802503,
      "grad_norm": 0.22353747487068176,
      "learning_rate": 7.678078630564333e-06,
      "loss": 0.0989,
      "step": 127030
    },
    {
      "epoch": 2.54049514058313,
      "grad_norm": 0.20789796113967896,
      "learning_rate": 7.674745697183006e-06,
      "loss": 0.0562,
      "step": 127040
    },
    {
      "epoch": 2.5406951165860097,
      "grad_norm": 0.0721660628914833,
      "learning_rate": 7.671412763801677e-06,
      "loss": 0.0784,
      "step": 127050
    },
    {
      "epoch": 2.5408950925888893,
      "grad_norm": 0.06473024189472198,
      "learning_rate": 7.668079830420349e-06,
      "loss": 0.0706,
      "step": 127060
    },
    {
      "epoch": 2.541095068591769,
      "grad_norm": 0.14757898449897766,
      "learning_rate": 7.664746897039023e-06,
      "loss": 0.0268,
      "step": 127070
    },
    {
      "epoch": 2.5412950445946487,
      "grad_norm": 0.22604940831661224,
      "learning_rate": 7.661413963657695e-06,
      "loss": 0.0598,
      "step": 127080
    },
    {
      "epoch": 2.5414950205975284,
      "grad_norm": 0.12041493505239487,
      "learning_rate": 7.658081030276368e-06,
      "loss": 0.07,
      "step": 127090
    },
    {
      "epoch": 2.541694996600408,
      "grad_norm": 0.1447766274213791,
      "learning_rate": 7.654748096895039e-06,
      "loss": 0.3478,
      "step": 127100
    },
    {
      "epoch": 2.541894972603288,
      "grad_norm": 0.2621917426586151,
      "learning_rate": 7.651415163513712e-06,
      "loss": 0.0612,
      "step": 127110
    },
    {
      "epoch": 2.5420949486061675,
      "grad_norm": 0.1881483793258667,
      "learning_rate": 7.648082230132385e-06,
      "loss": 0.0859,
      "step": 127120
    },
    {
      "epoch": 2.542294924609047,
      "grad_norm": 0.10059043020009995,
      "learning_rate": 7.644749296751056e-06,
      "loss": 0.071,
      "step": 127130
    },
    {
      "epoch": 2.542494900611927,
      "grad_norm": 0.13990437984466553,
      "learning_rate": 7.64141636336973e-06,
      "loss": 0.042,
      "step": 127140
    },
    {
      "epoch": 2.542694876614806,
      "grad_norm": 0.15728983283042908,
      "learning_rate": 7.638083429988402e-06,
      "loss": 0.0744,
      "step": 127150
    },
    {
      "epoch": 2.5428948526176858,
      "grad_norm": 0.19247283041477203,
      "learning_rate": 7.634750496607074e-06,
      "loss": 0.0658,
      "step": 127160
    },
    {
      "epoch": 2.5430948286205655,
      "grad_norm": 0.1860618144273758,
      "learning_rate": 7.631417563225747e-06,
      "loss": 0.0971,
      "step": 127170
    },
    {
      "epoch": 2.543294804623445,
      "grad_norm": 0.17230211198329926,
      "learning_rate": 7.628084629844419e-06,
      "loss": 0.0572,
      "step": 127180
    },
    {
      "epoch": 2.543494780626325,
      "grad_norm": 0.08786459267139435,
      "learning_rate": 7.624751696463091e-06,
      "loss": 0.0851,
      "step": 127190
    },
    {
      "epoch": 2.5436947566292045,
      "grad_norm": 0.1659904569387436,
      "learning_rate": 7.621418763081764e-06,
      "loss": 0.0763,
      "step": 127200
    },
    {
      "epoch": 2.543894732632084,
      "grad_norm": 0.13621129095554352,
      "learning_rate": 7.618085829700436e-06,
      "loss": 0.074,
      "step": 127210
    },
    {
      "epoch": 2.544094708634964,
      "grad_norm": 0.2915342152118683,
      "learning_rate": 7.614752896319109e-06,
      "loss": 0.1969,
      "step": 127220
    },
    {
      "epoch": 2.5442946846378436,
      "grad_norm": 0.09908484667539597,
      "learning_rate": 7.611419962937781e-06,
      "loss": 0.0752,
      "step": 127230
    },
    {
      "epoch": 2.5444946606407233,
      "grad_norm": 0.20566503703594208,
      "learning_rate": 7.608087029556453e-06,
      "loss": 0.0683,
      "step": 127240
    },
    {
      "epoch": 2.5446946366436025,
      "grad_norm": 0.07534334808588028,
      "learning_rate": 7.6047540961751265e-06,
      "loss": 0.0644,
      "step": 127250
    },
    {
      "epoch": 2.544894612646482,
      "grad_norm": 0.13844087719917297,
      "learning_rate": 7.601421162793798e-06,
      "loss": 0.0586,
      "step": 127260
    },
    {
      "epoch": 2.545094588649362,
      "grad_norm": 0.2564483880996704,
      "learning_rate": 7.598088229412472e-06,
      "loss": 0.1031,
      "step": 127270
    },
    {
      "epoch": 2.5452945646522416,
      "grad_norm": 0.19129572808742523,
      "learning_rate": 7.594755296031143e-06,
      "loss": 0.0737,
      "step": 127280
    },
    {
      "epoch": 2.5454945406551213,
      "grad_norm": 0.14128339290618896,
      "learning_rate": 7.591422362649815e-06,
      "loss": 0.0676,
      "step": 127290
    },
    {
      "epoch": 2.545694516658001,
      "grad_norm": 0.10578276216983795,
      "learning_rate": 7.588089429268488e-06,
      "loss": 0.0541,
      "step": 127300
    },
    {
      "epoch": 2.5458944926608806,
      "grad_norm": 0.16204588115215302,
      "learning_rate": 7.58475649588716e-06,
      "loss": 0.0779,
      "step": 127310
    },
    {
      "epoch": 2.5460944686637603,
      "grad_norm": 0.2573390007019043,
      "learning_rate": 7.581423562505833e-06,
      "loss": 0.1077,
      "step": 127320
    },
    {
      "epoch": 2.54629444466664,
      "grad_norm": 0.13401935994625092,
      "learning_rate": 7.5780906291245055e-06,
      "loss": 0.0677,
      "step": 127330
    },
    {
      "epoch": 2.5464944206695197,
      "grad_norm": 0.13164794445037842,
      "learning_rate": 7.574757695743178e-06,
      "loss": 0.0943,
      "step": 127340
    },
    {
      "epoch": 2.5466943966723994,
      "grad_norm": 0.10668031871318817,
      "learning_rate": 7.571424762361851e-06,
      "loss": 0.1022,
      "step": 127350
    },
    {
      "epoch": 2.546894372675279,
      "grad_norm": 0.07284374535083771,
      "learning_rate": 7.568091828980523e-06,
      "loss": 0.0639,
      "step": 127360
    },
    {
      "epoch": 2.5470943486781588,
      "grad_norm": 0.25350961089134216,
      "learning_rate": 7.564758895599196e-06,
      "loss": 0.0893,
      "step": 127370
    },
    {
      "epoch": 2.5472943246810384,
      "grad_norm": 0.08180423080921173,
      "learning_rate": 7.561425962217868e-06,
      "loss": 0.0973,
      "step": 127380
    },
    {
      "epoch": 2.547494300683918,
      "grad_norm": 0.2455613911151886,
      "learning_rate": 7.558093028836539e-06,
      "loss": 0.1064,
      "step": 127390
    },
    {
      "epoch": 2.547694276686798,
      "grad_norm": 0.07023664563894272,
      "learning_rate": 7.554760095455213e-06,
      "loss": 0.0722,
      "step": 127400
    },
    {
      "epoch": 2.5478942526896775,
      "grad_norm": 0.10856887698173523,
      "learning_rate": 7.5514271620738844e-06,
      "loss": 0.0493,
      "step": 127410
    },
    {
      "epoch": 2.5480942286925568,
      "grad_norm": 0.17517489194869995,
      "learning_rate": 7.548094228692558e-06,
      "loss": 0.0767,
      "step": 127420
    },
    {
      "epoch": 2.5482942046954364,
      "grad_norm": 0.10872919112443924,
      "learning_rate": 7.54476129531123e-06,
      "loss": 0.0704,
      "step": 127430
    },
    {
      "epoch": 2.548494180698316,
      "grad_norm": 0.1251147836446762,
      "learning_rate": 7.541428361929902e-06,
      "loss": 0.0407,
      "step": 127440
    },
    {
      "epoch": 2.548694156701196,
      "grad_norm": 0.13212531805038452,
      "learning_rate": 7.538095428548575e-06,
      "loss": 0.0952,
      "step": 127450
    },
    {
      "epoch": 2.5488941327040755,
      "grad_norm": 0.09431822597980499,
      "learning_rate": 7.534762495167247e-06,
      "loss": 0.0868,
      "step": 127460
    },
    {
      "epoch": 2.549094108706955,
      "grad_norm": 0.1597917675971985,
      "learning_rate": 7.531429561785919e-06,
      "loss": 0.0783,
      "step": 127470
    },
    {
      "epoch": 2.549294084709835,
      "grad_norm": 0.17574253678321838,
      "learning_rate": 7.528096628404592e-06,
      "loss": 0.0736,
      "step": 127480
    },
    {
      "epoch": 2.5494940607127146,
      "grad_norm": 0.1443430334329605,
      "learning_rate": 7.524763695023264e-06,
      "loss": 0.0559,
      "step": 127490
    },
    {
      "epoch": 2.5496940367155942,
      "grad_norm": 0.11721598356962204,
      "learning_rate": 7.521430761641937e-06,
      "loss": 0.0757,
      "step": 127500
    },
    {
      "epoch": 2.549894012718474,
      "grad_norm": 0.12161751091480255,
      "learning_rate": 7.518097828260609e-06,
      "loss": 0.0616,
      "step": 127510
    },
    {
      "epoch": 2.550093988721353,
      "grad_norm": 0.10950694978237152,
      "learning_rate": 7.514764894879281e-06,
      "loss": 0.0688,
      "step": 127520
    },
    {
      "epoch": 2.550293964724233,
      "grad_norm": 0.23315024375915527,
      "learning_rate": 7.5114319614979546e-06,
      "loss": 0.0637,
      "step": 127530
    },
    {
      "epoch": 2.5504939407271126,
      "grad_norm": 0.0673445388674736,
      "learning_rate": 7.508099028116626e-06,
      "loss": 0.0666,
      "step": 127540
    },
    {
      "epoch": 2.5506939167299922,
      "grad_norm": 0.07259780168533325,
      "learning_rate": 7.5047660947353e-06,
      "loss": 0.0566,
      "step": 127550
    },
    {
      "epoch": 2.550893892732872,
      "grad_norm": 0.2018190175294876,
      "learning_rate": 7.501433161353971e-06,
      "loss": 0.1542,
      "step": 127560
    },
    {
      "epoch": 2.5510938687357516,
      "grad_norm": 0.12139884382486343,
      "learning_rate": 7.498100227972643e-06,
      "loss": 0.0832,
      "step": 127570
    },
    {
      "epoch": 2.5512938447386313,
      "grad_norm": 0.10605226457118988,
      "learning_rate": 7.494767294591316e-06,
      "loss": 0.0586,
      "step": 127580
    },
    {
      "epoch": 2.551493820741511,
      "grad_norm": 0.19298167526721954,
      "learning_rate": 7.491434361209988e-06,
      "loss": 0.0737,
      "step": 127590
    },
    {
      "epoch": 2.5516937967443907,
      "grad_norm": 0.18327370285987854,
      "learning_rate": 7.488101427828661e-06,
      "loss": 0.0464,
      "step": 127600
    },
    {
      "epoch": 2.5518937727472704,
      "grad_norm": 0.11014913022518158,
      "learning_rate": 7.4847684944473335e-06,
      "loss": 0.0912,
      "step": 127610
    },
    {
      "epoch": 2.55209374875015,
      "grad_norm": 0.19565065205097198,
      "learning_rate": 7.481435561066006e-06,
      "loss": 0.0647,
      "step": 127620
    },
    {
      "epoch": 2.5522937247530297,
      "grad_norm": 0.15042147040367126,
      "learning_rate": 7.478102627684679e-06,
      "loss": 0.0642,
      "step": 127630
    },
    {
      "epoch": 2.5524937007559094,
      "grad_norm": 0.1813187301158905,
      "learning_rate": 7.474769694303351e-06,
      "loss": 0.0616,
      "step": 127640
    },
    {
      "epoch": 2.552693676758789,
      "grad_norm": 0.08369006961584091,
      "learning_rate": 7.471436760922024e-06,
      "loss": 0.0542,
      "step": 127650
    },
    {
      "epoch": 2.552893652761669,
      "grad_norm": 0.10706862807273865,
      "learning_rate": 7.468103827540696e-06,
      "loss": 0.0555,
      "step": 127660
    },
    {
      "epoch": 2.5530936287645485,
      "grad_norm": 0.19999386370182037,
      "learning_rate": 7.464770894159367e-06,
      "loss": 0.0765,
      "step": 127670
    },
    {
      "epoch": 2.553293604767428,
      "grad_norm": 0.10042630881071091,
      "learning_rate": 7.461437960778041e-06,
      "loss": 0.0575,
      "step": 127680
    },
    {
      "epoch": 2.5534935807703074,
      "grad_norm": 0.1911158412694931,
      "learning_rate": 7.4581050273967125e-06,
      "loss": 0.0904,
      "step": 127690
    },
    {
      "epoch": 2.553693556773187,
      "grad_norm": 0.16316476464271545,
      "learning_rate": 7.454772094015385e-06,
      "loss": 0.0708,
      "step": 127700
    },
    {
      "epoch": 2.553893532776067,
      "grad_norm": 0.1280355006456375,
      "learning_rate": 7.451439160634058e-06,
      "loss": 0.0864,
      "step": 127710
    },
    {
      "epoch": 2.5540935087789465,
      "grad_norm": 0.1308317631483078,
      "learning_rate": 7.44810622725273e-06,
      "loss": 0.0461,
      "step": 127720
    },
    {
      "epoch": 2.554293484781826,
      "grad_norm": 0.174615278840065,
      "learning_rate": 7.444773293871403e-06,
      "loss": 0.0787,
      "step": 127730
    },
    {
      "epoch": 2.554493460784706,
      "grad_norm": 0.19486436247825623,
      "learning_rate": 7.441440360490075e-06,
      "loss": 0.0813,
      "step": 127740
    },
    {
      "epoch": 2.5546934367875855,
      "grad_norm": 0.25487220287323,
      "learning_rate": 7.438107427108747e-06,
      "loss": 0.0863,
      "step": 127750
    },
    {
      "epoch": 2.5548934127904652,
      "grad_norm": 0.18540558218955994,
      "learning_rate": 7.43477449372742e-06,
      "loss": 0.1126,
      "step": 127760
    },
    {
      "epoch": 2.555093388793345,
      "grad_norm": 0.16706155240535736,
      "learning_rate": 7.431441560346092e-06,
      "loss": 0.0774,
      "step": 127770
    },
    {
      "epoch": 2.5552933647962246,
      "grad_norm": 0.06759608536958694,
      "learning_rate": 7.428108626964765e-06,
      "loss": 0.0589,
      "step": 127780
    },
    {
      "epoch": 2.555493340799104,
      "grad_norm": 0.1576552838087082,
      "learning_rate": 7.4247756935834366e-06,
      "loss": 0.083,
      "step": 127790
    },
    {
      "epoch": 2.5556933168019835,
      "grad_norm": 0.23532375693321228,
      "learning_rate": 7.421442760202109e-06,
      "loss": 0.0753,
      "step": 127800
    },
    {
      "epoch": 2.555893292804863,
      "grad_norm": 0.14517807960510254,
      "learning_rate": 7.418109826820782e-06,
      "loss": 0.0946,
      "step": 127810
    },
    {
      "epoch": 2.556093268807743,
      "grad_norm": 0.10377437621355057,
      "learning_rate": 7.414776893439454e-06,
      "loss": 0.1041,
      "step": 127820
    },
    {
      "epoch": 2.5562932448106226,
      "grad_norm": 0.1915520578622818,
      "learning_rate": 7.411443960058127e-06,
      "loss": 0.0655,
      "step": 127830
    },
    {
      "epoch": 2.5564932208135023,
      "grad_norm": 0.19576376676559448,
      "learning_rate": 7.408111026676799e-06,
      "loss": 0.0659,
      "step": 127840
    },
    {
      "epoch": 2.556693196816382,
      "grad_norm": 0.058878108859062195,
      "learning_rate": 7.404778093295471e-06,
      "loss": 0.0342,
      "step": 127850
    },
    {
      "epoch": 2.5568931728192617,
      "grad_norm": 0.09551717340946198,
      "learning_rate": 7.401445159914144e-06,
      "loss": 0.075,
      "step": 127860
    },
    {
      "epoch": 2.5570931488221413,
      "grad_norm": 0.12295506149530411,
      "learning_rate": 7.398112226532816e-06,
      "loss": 0.0568,
      "step": 127870
    },
    {
      "epoch": 2.557293124825021,
      "grad_norm": 0.1515958160161972,
      "learning_rate": 7.394779293151489e-06,
      "loss": 0.0948,
      "step": 127880
    },
    {
      "epoch": 2.5574931008279007,
      "grad_norm": 0.08824780583381653,
      "learning_rate": 7.3914463597701615e-06,
      "loss": 0.0377,
      "step": 127890
    },
    {
      "epoch": 2.5576930768307804,
      "grad_norm": 0.06405068188905716,
      "learning_rate": 7.388113426388833e-06,
      "loss": 0.0654,
      "step": 127900
    },
    {
      "epoch": 2.55789305283366,
      "grad_norm": 0.12304849922657013,
      "learning_rate": 7.384780493007507e-06,
      "loss": 0.045,
      "step": 127910
    },
    {
      "epoch": 2.5580930288365398,
      "grad_norm": 0.11272617429494858,
      "learning_rate": 7.381447559626178e-06,
      "loss": 0.0892,
      "step": 127920
    },
    {
      "epoch": 2.5582930048394195,
      "grad_norm": 0.19970259070396423,
      "learning_rate": 7.37811462624485e-06,
      "loss": 0.1094,
      "step": 127930
    },
    {
      "epoch": 2.558492980842299,
      "grad_norm": 0.13568413257598877,
      "learning_rate": 7.374781692863523e-06,
      "loss": 0.0773,
      "step": 127940
    },
    {
      "epoch": 2.558692956845179,
      "grad_norm": 0.19995559751987457,
      "learning_rate": 7.371448759482195e-06,
      "loss": 0.0506,
      "step": 127950
    },
    {
      "epoch": 2.558892932848058,
      "grad_norm": 0.14186620712280273,
      "learning_rate": 7.368115826100868e-06,
      "loss": 0.11,
      "step": 127960
    },
    {
      "epoch": 2.5590929088509378,
      "grad_norm": 0.07319774478673935,
      "learning_rate": 7.3647828927195405e-06,
      "loss": 0.0538,
      "step": 127970
    },
    {
      "epoch": 2.5592928848538175,
      "grad_norm": 0.1359306126832962,
      "learning_rate": 7.361449959338213e-06,
      "loss": 0.0509,
      "step": 127980
    },
    {
      "epoch": 2.559492860856697,
      "grad_norm": 0.1589171290397644,
      "learning_rate": 7.358117025956886e-06,
      "loss": 0.0637,
      "step": 127990
    },
    {
      "epoch": 2.559692836859577,
      "grad_norm": 0.1931782066822052,
      "learning_rate": 7.354784092575558e-06,
      "loss": 0.0923,
      "step": 128000
    },
    {
      "epoch": 2.5598928128624565,
      "grad_norm": 0.21231603622436523,
      "learning_rate": 7.351451159194231e-06,
      "loss": 0.0648,
      "step": 128010
    },
    {
      "epoch": 2.560092788865336,
      "grad_norm": 0.13260141015052795,
      "learning_rate": 7.348118225812903e-06,
      "loss": 0.0999,
      "step": 128020
    },
    {
      "epoch": 2.560292764868216,
      "grad_norm": 0.156056746840477,
      "learning_rate": 7.344785292431574e-06,
      "loss": 0.0882,
      "step": 128030
    },
    {
      "epoch": 2.5604927408710956,
      "grad_norm": 0.21651802957057953,
      "learning_rate": 7.341452359050248e-06,
      "loss": 0.0754,
      "step": 128040
    },
    {
      "epoch": 2.5606927168739753,
      "grad_norm": 0.08510186523199081,
      "learning_rate": 7.3381194256689194e-06,
      "loss": 0.0975,
      "step": 128050
    },
    {
      "epoch": 2.5608926928768545,
      "grad_norm": 0.10585033893585205,
      "learning_rate": 7.334786492287593e-06,
      "loss": 0.0446,
      "step": 128060
    },
    {
      "epoch": 2.561092668879734,
      "grad_norm": 0.16073638200759888,
      "learning_rate": 7.331453558906265e-06,
      "loss": 0.0924,
      "step": 128070
    },
    {
      "epoch": 2.561292644882614,
      "grad_norm": 0.16034632921218872,
      "learning_rate": 7.328120625524937e-06,
      "loss": 0.0557,
      "step": 128080
    },
    {
      "epoch": 2.5614926208854936,
      "grad_norm": 0.17069999873638153,
      "learning_rate": 7.32478769214361e-06,
      "loss": 0.0748,
      "step": 128090
    },
    {
      "epoch": 2.5616925968883733,
      "grad_norm": 0.08092330396175385,
      "learning_rate": 7.321454758762282e-06,
      "loss": 0.0589,
      "step": 128100
    },
    {
      "epoch": 2.561892572891253,
      "grad_norm": 0.2257183939218521,
      "learning_rate": 7.318121825380955e-06,
      "loss": 0.0763,
      "step": 128110
    },
    {
      "epoch": 2.5620925488941326,
      "grad_norm": 0.15146416425704956,
      "learning_rate": 7.314788891999627e-06,
      "loss": 0.0704,
      "step": 128120
    },
    {
      "epoch": 2.5622925248970123,
      "grad_norm": 0.10986848920583725,
      "learning_rate": 7.311455958618299e-06,
      "loss": 0.094,
      "step": 128130
    },
    {
      "epoch": 2.562492500899892,
      "grad_norm": 0.22986480593681335,
      "learning_rate": 7.308123025236972e-06,
      "loss": 0.0561,
      "step": 128140
    },
    {
      "epoch": 2.5626924769027717,
      "grad_norm": 0.14993739128112793,
      "learning_rate": 7.304790091855644e-06,
      "loss": 0.0641,
      "step": 128150
    },
    {
      "epoch": 2.5628924529056514,
      "grad_norm": 0.19451844692230225,
      "learning_rate": 7.301457158474317e-06,
      "loss": 0.0612,
      "step": 128160
    },
    {
      "epoch": 2.563092428908531,
      "grad_norm": 0.18326929211616516,
      "learning_rate": 7.2981242250929896e-06,
      "loss": 0.0935,
      "step": 128170
    },
    {
      "epoch": 2.5632924049114107,
      "grad_norm": 0.08497373014688492,
      "learning_rate": 7.294791291711661e-06,
      "loss": 0.06,
      "step": 128180
    },
    {
      "epoch": 2.5634923809142904,
      "grad_norm": 0.15314747393131256,
      "learning_rate": 7.291458358330335e-06,
      "loss": 0.0446,
      "step": 128190
    },
    {
      "epoch": 2.56369235691717,
      "grad_norm": 0.11200036108493805,
      "learning_rate": 7.288125424949006e-06,
      "loss": 0.0688,
      "step": 128200
    },
    {
      "epoch": 2.56389233292005,
      "grad_norm": 0.0693061575293541,
      "learning_rate": 7.284792491567678e-06,
      "loss": 0.0382,
      "step": 128210
    },
    {
      "epoch": 2.5640923089229295,
      "grad_norm": 0.17569181323051453,
      "learning_rate": 7.281459558186351e-06,
      "loss": 0.0736,
      "step": 128220
    },
    {
      "epoch": 2.5642922849258087,
      "grad_norm": 0.13605955243110657,
      "learning_rate": 7.278459918143156e-06,
      "loss": 0.1266,
      "step": 128230
    },
    {
      "epoch": 2.5644922609286884,
      "grad_norm": 0.12881259620189667,
      "learning_rate": 7.2751269847618296e-06,
      "loss": 0.0617,
      "step": 128240
    },
    {
      "epoch": 2.564692236931568,
      "grad_norm": 0.11986847221851349,
      "learning_rate": 7.271794051380501e-06,
      "loss": 0.0757,
      "step": 128250
    },
    {
      "epoch": 2.564892212934448,
      "grad_norm": 0.09846606850624084,
      "learning_rate": 7.268461117999175e-06,
      "loss": 0.0764,
      "step": 128260
    },
    {
      "epoch": 2.5650921889373275,
      "grad_norm": 0.22842499613761902,
      "learning_rate": 7.265128184617846e-06,
      "loss": 0.0895,
      "step": 128270
    },
    {
      "epoch": 2.565292164940207,
      "grad_norm": 0.19572846591472626,
      "learning_rate": 7.261795251236518e-06,
      "loss": 0.0978,
      "step": 128280
    },
    {
      "epoch": 2.565492140943087,
      "grad_norm": 0.08946316689252853,
      "learning_rate": 7.258462317855191e-06,
      "loss": 0.0565,
      "step": 128290
    },
    {
      "epoch": 2.5656921169459665,
      "grad_norm": 0.2718137502670288,
      "learning_rate": 7.255129384473863e-06,
      "loss": 0.0836,
      "step": 128300
    },
    {
      "epoch": 2.5658920929488462,
      "grad_norm": 0.1958295851945877,
      "learning_rate": 7.251796451092536e-06,
      "loss": 0.0941,
      "step": 128310
    },
    {
      "epoch": 2.566092068951726,
      "grad_norm": 0.11359022557735443,
      "learning_rate": 7.2484635177112085e-06,
      "loss": 0.0654,
      "step": 128320
    },
    {
      "epoch": 2.5662920449546056,
      "grad_norm": 0.10986260324716568,
      "learning_rate": 7.245130584329881e-06,
      "loss": 0.0999,
      "step": 128330
    },
    {
      "epoch": 2.566492020957485,
      "grad_norm": 0.05436622351408005,
      "learning_rate": 7.241797650948554e-06,
      "loss": 0.0286,
      "step": 128340
    },
    {
      "epoch": 2.5666919969603645,
      "grad_norm": 0.14383089542388916,
      "learning_rate": 7.238464717567226e-06,
      "loss": 0.1951,
      "step": 128350
    },
    {
      "epoch": 2.5668919729632442,
      "grad_norm": 0.19091303646564484,
      "learning_rate": 7.235131784185899e-06,
      "loss": 0.0491,
      "step": 128360
    },
    {
      "epoch": 2.567091948966124,
      "grad_norm": 0.13446500897407532,
      "learning_rate": 7.231798850804571e-06,
      "loss": 0.0505,
      "step": 128370
    },
    {
      "epoch": 2.5672919249690036,
      "grad_norm": 0.16360844671726227,
      "learning_rate": 7.228465917423242e-06,
      "loss": 0.0449,
      "step": 128380
    },
    {
      "epoch": 2.5674919009718833,
      "grad_norm": 0.18614089488983154,
      "learning_rate": 7.225132984041916e-06,
      "loss": 0.1011,
      "step": 128390
    },
    {
      "epoch": 2.567691876974763,
      "grad_norm": 0.07804294675588608,
      "learning_rate": 7.2218000506605875e-06,
      "loss": 0.0385,
      "step": 128400
    },
    {
      "epoch": 2.5678918529776427,
      "grad_norm": 0.07875125110149384,
      "learning_rate": 7.21846711727926e-06,
      "loss": 0.0544,
      "step": 128410
    },
    {
      "epoch": 2.5680918289805224,
      "grad_norm": 0.0870889201760292,
      "learning_rate": 7.215134183897933e-06,
      "loss": 0.0528,
      "step": 128420
    },
    {
      "epoch": 2.568291804983402,
      "grad_norm": 0.14998023211956024,
      "learning_rate": 7.211801250516605e-06,
      "loss": 0.0731,
      "step": 128430
    },
    {
      "epoch": 2.5684917809862817,
      "grad_norm": 0.1237691342830658,
      "learning_rate": 7.208468317135278e-06,
      "loss": 0.0674,
      "step": 128440
    },
    {
      "epoch": 2.5686917569891614,
      "grad_norm": 0.17427919805049896,
      "learning_rate": 7.20513538375395e-06,
      "loss": 0.0596,
      "step": 128450
    },
    {
      "epoch": 2.568891732992041,
      "grad_norm": 0.14626659452915192,
      "learning_rate": 7.201802450372622e-06,
      "loss": 0.0699,
      "step": 128460
    },
    {
      "epoch": 2.569091708994921,
      "grad_norm": 0.08880201727151871,
      "learning_rate": 7.198469516991295e-06,
      "loss": 0.0783,
      "step": 128470
    },
    {
      "epoch": 2.5692916849978005,
      "grad_norm": 0.09080399572849274,
      "learning_rate": 7.195136583609967e-06,
      "loss": 0.0572,
      "step": 128480
    },
    {
      "epoch": 2.56949166100068,
      "grad_norm": 0.08091572672128677,
      "learning_rate": 7.19180365022864e-06,
      "loss": 0.0388,
      "step": 128490
    },
    {
      "epoch": 2.56969163700356,
      "grad_norm": 0.08089231699705124,
      "learning_rate": 7.188470716847312e-06,
      "loss": 0.0841,
      "step": 128500
    },
    {
      "epoch": 2.569891613006439,
      "grad_norm": 0.07586118578910828,
      "learning_rate": 7.185137783465984e-06,
      "loss": 0.0534,
      "step": 128510
    },
    {
      "epoch": 2.5700915890093188,
      "grad_norm": 0.11235839873552322,
      "learning_rate": 7.181804850084657e-06,
      "loss": 0.0529,
      "step": 128520
    },
    {
      "epoch": 2.5702915650121985,
      "grad_norm": 0.15304268896579742,
      "learning_rate": 7.178471916703329e-06,
      "loss": 0.081,
      "step": 128530
    },
    {
      "epoch": 2.570491541015078,
      "grad_norm": 0.09253183007240295,
      "learning_rate": 7.175138983322002e-06,
      "loss": 0.0699,
      "step": 128540
    },
    {
      "epoch": 2.570691517017958,
      "grad_norm": 0.09520226716995239,
      "learning_rate": 7.171806049940674e-06,
      "loss": 0.0629,
      "step": 128550
    },
    {
      "epoch": 2.5708914930208375,
      "grad_norm": 0.16156910359859467,
      "learning_rate": 7.168473116559346e-06,
      "loss": 0.06,
      "step": 128560
    },
    {
      "epoch": 2.571091469023717,
      "grad_norm": 0.27068328857421875,
      "learning_rate": 7.165140183178019e-06,
      "loss": 0.0694,
      "step": 128570
    },
    {
      "epoch": 2.571291445026597,
      "grad_norm": 0.10763023793697357,
      "learning_rate": 7.161807249796691e-06,
      "loss": 0.0828,
      "step": 128580
    },
    {
      "epoch": 2.5714914210294766,
      "grad_norm": 0.1842702478170395,
      "learning_rate": 7.158474316415364e-06,
      "loss": 0.0775,
      "step": 128590
    },
    {
      "epoch": 2.5716913970323563,
      "grad_norm": 0.21672140061855316,
      "learning_rate": 7.1551413830340365e-06,
      "loss": 0.0691,
      "step": 128600
    },
    {
      "epoch": 2.5718913730352355,
      "grad_norm": 0.06693403422832489,
      "learning_rate": 7.151808449652708e-06,
      "loss": 0.0801,
      "step": 128610
    },
    {
      "epoch": 2.572091349038115,
      "grad_norm": 0.10458426177501678,
      "learning_rate": 7.148475516271382e-06,
      "loss": 0.0862,
      "step": 128620
    },
    {
      "epoch": 2.572291325040995,
      "grad_norm": 0.11251865327358246,
      "learning_rate": 7.145142582890053e-06,
      "loss": 0.1018,
      "step": 128630
    },
    {
      "epoch": 2.5724913010438746,
      "grad_norm": 0.08614912629127502,
      "learning_rate": 7.141809649508725e-06,
      "loss": 0.067,
      "step": 128640
    },
    {
      "epoch": 2.5726912770467543,
      "grad_norm": 0.0850200206041336,
      "learning_rate": 7.138476716127398e-06,
      "loss": 0.0588,
      "step": 128650
    },
    {
      "epoch": 2.572891253049634,
      "grad_norm": 0.15776924788951874,
      "learning_rate": 7.13514378274607e-06,
      "loss": 0.0632,
      "step": 128660
    },
    {
      "epoch": 2.5730912290525136,
      "grad_norm": 0.22246314585208893,
      "learning_rate": 7.131810849364743e-06,
      "loss": 0.0817,
      "step": 128670
    },
    {
      "epoch": 2.5732912050553933,
      "grad_norm": 0.17157632112503052,
      "learning_rate": 7.1284779159834155e-06,
      "loss": 0.5226,
      "step": 128680
    },
    {
      "epoch": 2.573491181058273,
      "grad_norm": 0.12646706402301788,
      "learning_rate": 7.125144982602088e-06,
      "loss": 0.1059,
      "step": 128690
    },
    {
      "epoch": 2.5736911570611527,
      "grad_norm": 0.10217326879501343,
      "learning_rate": 7.121812049220761e-06,
      "loss": 0.0744,
      "step": 128700
    },
    {
      "epoch": 2.5738911330640324,
      "grad_norm": 0.21130409836769104,
      "learning_rate": 7.118479115839433e-06,
      "loss": 0.086,
      "step": 128710
    },
    {
      "epoch": 2.574091109066912,
      "grad_norm": 0.23553872108459473,
      "learning_rate": 7.115146182458106e-06,
      "loss": 0.0794,
      "step": 128720
    },
    {
      "epoch": 2.5742910850697918,
      "grad_norm": 0.12461245805025101,
      "learning_rate": 7.111813249076778e-06,
      "loss": 0.0641,
      "step": 128730
    },
    {
      "epoch": 2.5744910610726714,
      "grad_norm": 0.2654428780078888,
      "learning_rate": 7.108480315695449e-06,
      "loss": 0.0663,
      "step": 128740
    },
    {
      "epoch": 2.574691037075551,
      "grad_norm": 0.0950414389371872,
      "learning_rate": 7.105147382314123e-06,
      "loss": 0.0931,
      "step": 128750
    },
    {
      "epoch": 2.574891013078431,
      "grad_norm": 0.10195405036211014,
      "learning_rate": 7.101814448932794e-06,
      "loss": 0.0444,
      "step": 128760
    },
    {
      "epoch": 2.5750909890813105,
      "grad_norm": 0.07351783663034439,
      "learning_rate": 7.098481515551468e-06,
      "loss": 0.0756,
      "step": 128770
    },
    {
      "epoch": 2.5752909650841898,
      "grad_norm": 0.16252100467681885,
      "learning_rate": 7.09514858217014e-06,
      "loss": 0.0552,
      "step": 128780
    },
    {
      "epoch": 2.5754909410870694,
      "grad_norm": 0.12571556866168976,
      "learning_rate": 7.091815648788812e-06,
      "loss": 0.0848,
      "step": 128790
    },
    {
      "epoch": 2.575690917089949,
      "grad_norm": 0.09436248987913132,
      "learning_rate": 7.088482715407485e-06,
      "loss": 0.0585,
      "step": 128800
    },
    {
      "epoch": 2.575890893092829,
      "grad_norm": 0.06001955643296242,
      "learning_rate": 7.085149782026157e-06,
      "loss": 0.0509,
      "step": 128810
    },
    {
      "epoch": 2.5760908690957085,
      "grad_norm": 0.12630672752857208,
      "learning_rate": 7.08181684864483e-06,
      "loss": 0.0967,
      "step": 128820
    },
    {
      "epoch": 2.576290845098588,
      "grad_norm": 0.053121697157621384,
      "learning_rate": 7.078483915263502e-06,
      "loss": 0.0495,
      "step": 128830
    },
    {
      "epoch": 2.576490821101468,
      "grad_norm": 0.13468174636363983,
      "learning_rate": 7.075150981882174e-06,
      "loss": 0.064,
      "step": 128840
    },
    {
      "epoch": 2.5766907971043476,
      "grad_norm": 0.11870128661394119,
      "learning_rate": 7.071818048500847e-06,
      "loss": 0.0643,
      "step": 128850
    },
    {
      "epoch": 2.5768907731072273,
      "grad_norm": 0.10965412110090256,
      "learning_rate": 7.068485115119519e-06,
      "loss": 0.0568,
      "step": 128860
    },
    {
      "epoch": 2.577090749110107,
      "grad_norm": 0.17260678112506866,
      "learning_rate": 7.065152181738192e-06,
      "loss": 0.0956,
      "step": 128870
    },
    {
      "epoch": 2.577290725112986,
      "grad_norm": 0.1310565173625946,
      "learning_rate": 7.0618192483568645e-06,
      "loss": 0.0688,
      "step": 128880
    },
    {
      "epoch": 2.577490701115866,
      "grad_norm": 0.19397778809070587,
      "learning_rate": 7.058486314975536e-06,
      "loss": 0.087,
      "step": 128890
    },
    {
      "epoch": 2.5776906771187456,
      "grad_norm": 0.07205284386873245,
      "learning_rate": 7.05515338159421e-06,
      "loss": 0.0703,
      "step": 128900
    },
    {
      "epoch": 2.5778906531216252,
      "grad_norm": 0.10821601748466492,
      "learning_rate": 7.051820448212881e-06,
      "loss": 0.0609,
      "step": 128910
    },
    {
      "epoch": 2.578090629124505,
      "grad_norm": 0.2607574462890625,
      "learning_rate": 7.048487514831553e-06,
      "loss": 0.0603,
      "step": 128920
    },
    {
      "epoch": 2.5782906051273846,
      "grad_norm": 0.2461688071489334,
      "learning_rate": 7.045154581450226e-06,
      "loss": 0.0974,
      "step": 128930
    },
    {
      "epoch": 2.5784905811302643,
      "grad_norm": 0.1402583122253418,
      "learning_rate": 7.041821648068898e-06,
      "loss": 0.0881,
      "step": 128940
    },
    {
      "epoch": 2.578690557133144,
      "grad_norm": 0.1115327998995781,
      "learning_rate": 7.038488714687571e-06,
      "loss": 0.0779,
      "step": 128950
    },
    {
      "epoch": 2.5788905331360237,
      "grad_norm": 0.15879391133785248,
      "learning_rate": 7.0351557813062435e-06,
      "loss": 0.0769,
      "step": 128960
    },
    {
      "epoch": 2.5790905091389034,
      "grad_norm": 0.12873287498950958,
      "learning_rate": 7.031822847924916e-06,
      "loss": 0.086,
      "step": 128970
    },
    {
      "epoch": 2.579290485141783,
      "grad_norm": 0.11104056239128113,
      "learning_rate": 7.028489914543589e-06,
      "loss": 0.0649,
      "step": 128980
    },
    {
      "epoch": 2.5794904611446627,
      "grad_norm": 0.0879504457116127,
      "learning_rate": 7.025156981162261e-06,
      "loss": 0.2244,
      "step": 128990
    },
    {
      "epoch": 2.5796904371475424,
      "grad_norm": 0.09529612213373184,
      "learning_rate": 7.021824047780934e-06,
      "loss": 0.0469,
      "step": 129000
    },
    {
      "epoch": 2.579890413150422,
      "grad_norm": 0.27639931440353394,
      "learning_rate": 7.018491114399606e-06,
      "loss": 0.0748,
      "step": 129010
    },
    {
      "epoch": 2.580090389153302,
      "grad_norm": 0.09079104661941528,
      "learning_rate": 7.015158181018277e-06,
      "loss": 0.0817,
      "step": 129020
    },
    {
      "epoch": 2.5802903651561815,
      "grad_norm": 0.10600077360868454,
      "learning_rate": 7.011825247636951e-06,
      "loss": 0.1024,
      "step": 129030
    },
    {
      "epoch": 2.580490341159061,
      "grad_norm": 0.09154845029115677,
      "learning_rate": 7.0084923142556224e-06,
      "loss": 0.055,
      "step": 129040
    },
    {
      "epoch": 2.5806903171619404,
      "grad_norm": 0.12793301045894623,
      "learning_rate": 7.005159380874296e-06,
      "loss": 0.0796,
      "step": 129050
    },
    {
      "epoch": 2.58089029316482,
      "grad_norm": 0.21695968508720398,
      "learning_rate": 7.001826447492968e-06,
      "loss": 0.0768,
      "step": 129060
    },
    {
      "epoch": 2.5810902691677,
      "grad_norm": 0.14954501390457153,
      "learning_rate": 6.99849351411164e-06,
      "loss": 0.0922,
      "step": 129070
    },
    {
      "epoch": 2.5812902451705795,
      "grad_norm": 0.13175185024738312,
      "learning_rate": 6.995160580730313e-06,
      "loss": 0.0557,
      "step": 129080
    },
    {
      "epoch": 2.581490221173459,
      "grad_norm": 0.18257340788841248,
      "learning_rate": 6.991827647348985e-06,
      "loss": 0.0846,
      "step": 129090
    },
    {
      "epoch": 2.581690197176339,
      "grad_norm": 0.15490487217903137,
      "learning_rate": 6.988494713967658e-06,
      "loss": 0.0821,
      "step": 129100
    },
    {
      "epoch": 2.5818901731792185,
      "grad_norm": 0.08878888934850693,
      "learning_rate": 6.98516178058633e-06,
      "loss": 0.0572,
      "step": 129110
    },
    {
      "epoch": 2.5820901491820982,
      "grad_norm": 0.20416343212127686,
      "learning_rate": 6.981828847205002e-06,
      "loss": 0.0666,
      "step": 129120
    },
    {
      "epoch": 2.582290125184978,
      "grad_norm": 0.06834076344966888,
      "learning_rate": 6.978495913823675e-06,
      "loss": 0.0659,
      "step": 129130
    },
    {
      "epoch": 2.5824901011878576,
      "grad_norm": 0.2744631767272949,
      "learning_rate": 6.975162980442347e-06,
      "loss": 0.1004,
      "step": 129140
    },
    {
      "epoch": 2.582690077190737,
      "grad_norm": 0.09020913392305374,
      "learning_rate": 6.971830047061019e-06,
      "loss": 0.0506,
      "step": 129150
    },
    {
      "epoch": 2.5828900531936165,
      "grad_norm": 0.1993343085050583,
      "learning_rate": 6.9684971136796926e-06,
      "loss": 0.0941,
      "step": 129160
    },
    {
      "epoch": 2.583090029196496,
      "grad_norm": 0.1544279158115387,
      "learning_rate": 6.965164180298364e-06,
      "loss": 0.0474,
      "step": 129170
    },
    {
      "epoch": 2.583290005199376,
      "grad_norm": 0.09713474661111832,
      "learning_rate": 6.961831246917038e-06,
      "loss": 0.0557,
      "step": 129180
    },
    {
      "epoch": 2.5834899812022556,
      "grad_norm": 0.15405170619487762,
      "learning_rate": 6.958498313535709e-06,
      "loss": 0.069,
      "step": 129190
    },
    {
      "epoch": 2.5836899572051353,
      "grad_norm": 0.19197972118854523,
      "learning_rate": 6.955165380154381e-06,
      "loss": 0.0738,
      "step": 129200
    },
    {
      "epoch": 2.583889933208015,
      "grad_norm": 0.1728007197380066,
      "learning_rate": 6.951832446773054e-06,
      "loss": 0.0786,
      "step": 129210
    },
    {
      "epoch": 2.5840899092108947,
      "grad_norm": 0.14984281361103058,
      "learning_rate": 6.948499513391726e-06,
      "loss": 0.0493,
      "step": 129220
    },
    {
      "epoch": 2.5842898852137743,
      "grad_norm": 0.10217940807342529,
      "learning_rate": 6.945166580010399e-06,
      "loss": 0.0883,
      "step": 129230
    },
    {
      "epoch": 2.584489861216654,
      "grad_norm": 0.18676374852657318,
      "learning_rate": 6.9418336466290715e-06,
      "loss": 0.0667,
      "step": 129240
    },
    {
      "epoch": 2.5846898372195337,
      "grad_norm": 0.10006045550107956,
      "learning_rate": 6.938500713247744e-06,
      "loss": 0.0814,
      "step": 129250
    },
    {
      "epoch": 2.5848898132224134,
      "grad_norm": 0.1343042403459549,
      "learning_rate": 6.935167779866417e-06,
      "loss": 0.0851,
      "step": 129260
    },
    {
      "epoch": 2.585089789225293,
      "grad_norm": 0.15531285107135773,
      "learning_rate": 6.931834846485089e-06,
      "loss": 0.2908,
      "step": 129270
    },
    {
      "epoch": 2.5852897652281728,
      "grad_norm": 0.1234038844704628,
      "learning_rate": 6.928501913103762e-06,
      "loss": 0.0497,
      "step": 129280
    },
    {
      "epoch": 2.5854897412310525,
      "grad_norm": 0.3047374188899994,
      "learning_rate": 6.925168979722434e-06,
      "loss": 0.0953,
      "step": 129290
    },
    {
      "epoch": 2.585689717233932,
      "grad_norm": 0.1967521458864212,
      "learning_rate": 6.921836046341105e-06,
      "loss": 0.0808,
      "step": 129300
    },
    {
      "epoch": 2.585889693236812,
      "grad_norm": 0.17599201202392578,
      "learning_rate": 6.918503112959779e-06,
      "loss": 0.0539,
      "step": 129310
    },
    {
      "epoch": 2.586089669239691,
      "grad_norm": 0.15386584401130676,
      "learning_rate": 6.9151701795784505e-06,
      "loss": 0.1245,
      "step": 129320
    },
    {
      "epoch": 2.5862896452425708,
      "grad_norm": 0.20463673770427704,
      "learning_rate": 6.911837246197124e-06,
      "loss": 0.1231,
      "step": 129330
    },
    {
      "epoch": 2.5864896212454505,
      "grad_norm": 0.09749896079301834,
      "learning_rate": 6.908504312815796e-06,
      "loss": 0.0655,
      "step": 129340
    },
    {
      "epoch": 2.58668959724833,
      "grad_norm": 0.1411014199256897,
      "learning_rate": 6.905171379434468e-06,
      "loss": 0.0799,
      "step": 129350
    },
    {
      "epoch": 2.58688957325121,
      "grad_norm": 0.1964688003063202,
      "learning_rate": 6.901838446053141e-06,
      "loss": 0.0271,
      "step": 129360
    },
    {
      "epoch": 2.5870895492540895,
      "grad_norm": 0.06770532578229904,
      "learning_rate": 6.898505512671813e-06,
      "loss": 0.0502,
      "step": 129370
    },
    {
      "epoch": 2.587289525256969,
      "grad_norm": 0.15265999734401703,
      "learning_rate": 6.895172579290486e-06,
      "loss": 0.0756,
      "step": 129380
    },
    {
      "epoch": 2.587489501259849,
      "grad_norm": 0.09333053976297379,
      "learning_rate": 6.891839645909158e-06,
      "loss": 0.0648,
      "step": 129390
    },
    {
      "epoch": 2.5876894772627286,
      "grad_norm": 0.06786957383155823,
      "learning_rate": 6.88850671252783e-06,
      "loss": 0.0668,
      "step": 129400
    },
    {
      "epoch": 2.5878894532656083,
      "grad_norm": 0.1712304800748825,
      "learning_rate": 6.885173779146503e-06,
      "loss": 0.0881,
      "step": 129410
    },
    {
      "epoch": 2.5880894292684875,
      "grad_norm": 0.17608319222927094,
      "learning_rate": 6.881840845765175e-06,
      "loss": 0.0953,
      "step": 129420
    },
    {
      "epoch": 2.588289405271367,
      "grad_norm": 0.1353687047958374,
      "learning_rate": 6.878507912383847e-06,
      "loss": 0.0441,
      "step": 129430
    },
    {
      "epoch": 2.588489381274247,
      "grad_norm": 0.1061306968331337,
      "learning_rate": 6.875174979002521e-06,
      "loss": 0.0506,
      "step": 129440
    },
    {
      "epoch": 2.5886893572771266,
      "grad_norm": 0.06832361221313477,
      "learning_rate": 6.871842045621192e-06,
      "loss": 0.0606,
      "step": 129450
    },
    {
      "epoch": 2.5888893332800063,
      "grad_norm": 0.22396667301654816,
      "learning_rate": 6.868509112239866e-06,
      "loss": 0.0824,
      "step": 129460
    },
    {
      "epoch": 2.589089309282886,
      "grad_norm": 0.1967494934797287,
      "learning_rate": 6.865176178858537e-06,
      "loss": 0.0743,
      "step": 129470
    },
    {
      "epoch": 2.5892892852857656,
      "grad_norm": 0.20654979348182678,
      "learning_rate": 6.861843245477209e-06,
      "loss": 0.1068,
      "step": 129480
    },
    {
      "epoch": 2.5894892612886453,
      "grad_norm": 0.17320990562438965,
      "learning_rate": 6.858510312095882e-06,
      "loss": 0.0782,
      "step": 129490
    },
    {
      "epoch": 2.589689237291525,
      "grad_norm": 0.13228845596313477,
      "learning_rate": 6.855177378714554e-06,
      "loss": 0.1197,
      "step": 129500
    },
    {
      "epoch": 2.5898892132944047,
      "grad_norm": 0.13192352652549744,
      "learning_rate": 6.851844445333227e-06,
      "loss": 0.0695,
      "step": 129510
    },
    {
      "epoch": 2.5900891892972844,
      "grad_norm": 0.13050265610218048,
      "learning_rate": 6.8485115119518995e-06,
      "loss": 0.0343,
      "step": 129520
    },
    {
      "epoch": 2.590289165300164,
      "grad_norm": 0.21324238181114197,
      "learning_rate": 6.845178578570572e-06,
      "loss": 0.0922,
      "step": 129530
    },
    {
      "epoch": 2.5904891413030438,
      "grad_norm": 0.24546551704406738,
      "learning_rate": 6.841845645189245e-06,
      "loss": 0.0652,
      "step": 129540
    },
    {
      "epoch": 2.5906891173059234,
      "grad_norm": 0.15473271906375885,
      "learning_rate": 6.838512711807917e-06,
      "loss": 0.1134,
      "step": 129550
    },
    {
      "epoch": 2.590889093308803,
      "grad_norm": 0.16127081215381622,
      "learning_rate": 6.83517977842659e-06,
      "loss": 0.0798,
      "step": 129560
    },
    {
      "epoch": 2.591089069311683,
      "grad_norm": 0.1623203158378601,
      "learning_rate": 6.831846845045262e-06,
      "loss": 0.0667,
      "step": 129570
    },
    {
      "epoch": 2.5912890453145625,
      "grad_norm": 0.12245624512434006,
      "learning_rate": 6.828513911663933e-06,
      "loss": 0.0735,
      "step": 129580
    },
    {
      "epoch": 2.5914890213174417,
      "grad_norm": 0.19948513805866241,
      "learning_rate": 6.825180978282607e-06,
      "loss": 0.0689,
      "step": 129590
    },
    {
      "epoch": 2.5916889973203214,
      "grad_norm": 0.18133234977722168,
      "learning_rate": 6.8218480449012785e-06,
      "loss": 0.0863,
      "step": 129600
    },
    {
      "epoch": 2.591888973323201,
      "grad_norm": 0.09227339178323746,
      "learning_rate": 6.818515111519952e-06,
      "loss": 0.0521,
      "step": 129610
    },
    {
      "epoch": 2.592088949326081,
      "grad_norm": 0.10521828383207321,
      "learning_rate": 6.815182178138624e-06,
      "loss": 0.0642,
      "step": 129620
    },
    {
      "epoch": 2.5922889253289605,
      "grad_norm": 0.1999446004629135,
      "learning_rate": 6.811849244757296e-06,
      "loss": 0.0577,
      "step": 129630
    },
    {
      "epoch": 2.59248890133184,
      "grad_norm": 0.12534229457378387,
      "learning_rate": 6.808516311375969e-06,
      "loss": 0.0838,
      "step": 129640
    },
    {
      "epoch": 2.59268887733472,
      "grad_norm": 0.08758597820997238,
      "learning_rate": 6.805183377994641e-06,
      "loss": 0.0743,
      "step": 129650
    },
    {
      "epoch": 2.5928888533375996,
      "grad_norm": 0.14485076069831848,
      "learning_rate": 6.801850444613313e-06,
      "loss": 0.0517,
      "step": 129660
    },
    {
      "epoch": 2.5930888293404792,
      "grad_norm": 0.05936228483915329,
      "learning_rate": 6.798517511231986e-06,
      "loss": 0.0738,
      "step": 129670
    },
    {
      "epoch": 2.593288805343359,
      "grad_norm": 0.11615568399429321,
      "learning_rate": 6.795184577850658e-06,
      "loss": 0.08,
      "step": 129680
    },
    {
      "epoch": 2.5934887813462386,
      "grad_norm": 0.20957982540130615,
      "learning_rate": 6.791851644469331e-06,
      "loss": 0.0774,
      "step": 129690
    },
    {
      "epoch": 2.593688757349118,
      "grad_norm": 0.2128688544034958,
      "learning_rate": 6.7885187110880034e-06,
      "loss": 0.076,
      "step": 129700
    },
    {
      "epoch": 2.5938887333519975,
      "grad_norm": 0.07269910722970963,
      "learning_rate": 6.785185777706675e-06,
      "loss": 0.0488,
      "step": 129710
    },
    {
      "epoch": 2.5940887093548772,
      "grad_norm": 0.19036997854709625,
      "learning_rate": 6.781852844325348e-06,
      "loss": 0.0644,
      "step": 129720
    },
    {
      "epoch": 2.594288685357757,
      "grad_norm": 0.17782288789749146,
      "learning_rate": 6.77851991094402e-06,
      "loss": 0.0879,
      "step": 129730
    },
    {
      "epoch": 2.5944886613606366,
      "grad_norm": 0.07608726620674133,
      "learning_rate": 6.775186977562693e-06,
      "loss": 0.1061,
      "step": 129740
    },
    {
      "epoch": 2.5946886373635163,
      "grad_norm": 0.17668040096759796,
      "learning_rate": 6.771854044181365e-06,
      "loss": 0.1345,
      "step": 129750
    },
    {
      "epoch": 2.594888613366396,
      "grad_norm": 0.22469565272331238,
      "learning_rate": 6.768521110800037e-06,
      "loss": 0.0918,
      "step": 129760
    },
    {
      "epoch": 2.5950885893692757,
      "grad_norm": 0.08315262198448181,
      "learning_rate": 6.76518817741871e-06,
      "loss": 0.0645,
      "step": 129770
    },
    {
      "epoch": 2.5952885653721554,
      "grad_norm": 0.11720836907625198,
      "learning_rate": 6.761855244037382e-06,
      "loss": 0.0819,
      "step": 129780
    },
    {
      "epoch": 2.595488541375035,
      "grad_norm": 0.23737776279449463,
      "learning_rate": 6.758522310656055e-06,
      "loss": 0.0817,
      "step": 129790
    },
    {
      "epoch": 2.5956885173779147,
      "grad_norm": 0.07068927586078644,
      "learning_rate": 6.7551893772747276e-06,
      "loss": 0.0651,
      "step": 129800
    },
    {
      "epoch": 2.5958884933807944,
      "grad_norm": 0.06901766359806061,
      "learning_rate": 6.751856443893399e-06,
      "loss": 0.0711,
      "step": 129810
    },
    {
      "epoch": 2.596088469383674,
      "grad_norm": 0.17062067985534668,
      "learning_rate": 6.748523510512073e-06,
      "loss": 0.0674,
      "step": 129820
    },
    {
      "epoch": 2.596288445386554,
      "grad_norm": 0.11433427035808563,
      "learning_rate": 6.745190577130744e-06,
      "loss": 0.0985,
      "step": 129830
    },
    {
      "epoch": 2.5964884213894335,
      "grad_norm": 0.21605364978313446,
      "learning_rate": 6.741857643749418e-06,
      "loss": 0.0724,
      "step": 129840
    },
    {
      "epoch": 2.596688397392313,
      "grad_norm": 0.1019057035446167,
      "learning_rate": 6.738524710368089e-06,
      "loss": 0.0849,
      "step": 129850
    },
    {
      "epoch": 2.596888373395193,
      "grad_norm": 0.1561165750026703,
      "learning_rate": 6.735191776986761e-06,
      "loss": 0.0714,
      "step": 129860
    },
    {
      "epoch": 2.597088349398072,
      "grad_norm": 0.0806073322892189,
      "learning_rate": 6.731858843605434e-06,
      "loss": 0.0731,
      "step": 129870
    },
    {
      "epoch": 2.597288325400952,
      "grad_norm": 0.1059039905667305,
      "learning_rate": 6.7285259102241065e-06,
      "loss": 0.0836,
      "step": 129880
    },
    {
      "epoch": 2.5974883014038315,
      "grad_norm": 0.2078217715024948,
      "learning_rate": 6.7251929768427795e-06,
      "loss": 0.0716,
      "step": 129890
    },
    {
      "epoch": 2.597688277406711,
      "grad_norm": 0.17424629628658295,
      "learning_rate": 6.721860043461452e-06,
      "loss": 0.0908,
      "step": 129900
    },
    {
      "epoch": 2.597888253409591,
      "grad_norm": 0.058764975517988205,
      "learning_rate": 6.718527110080124e-06,
      "loss": 0.0771,
      "step": 129910
    },
    {
      "epoch": 2.5980882294124705,
      "grad_norm": 0.2575186491012573,
      "learning_rate": 6.715194176698797e-06,
      "loss": 0.0593,
      "step": 129920
    },
    {
      "epoch": 2.59828820541535,
      "grad_norm": 0.21374186873435974,
      "learning_rate": 6.711861243317469e-06,
      "loss": 0.0627,
      "step": 129930
    },
    {
      "epoch": 2.59848818141823,
      "grad_norm": 0.07382863014936447,
      "learning_rate": 6.70852830993614e-06,
      "loss": 0.0578,
      "step": 129940
    },
    {
      "epoch": 2.5986881574211096,
      "grad_norm": 0.07180791348218918,
      "learning_rate": 6.705195376554814e-06,
      "loss": 0.053,
      "step": 129950
    },
    {
      "epoch": 2.5988881334239893,
      "grad_norm": 0.2392728179693222,
      "learning_rate": 6.7018624431734855e-06,
      "loss": 0.0998,
      "step": 129960
    },
    {
      "epoch": 2.5990881094268685,
      "grad_norm": 0.12426119297742844,
      "learning_rate": 6.698529509792159e-06,
      "loss": 0.0913,
      "step": 129970
    },
    {
      "epoch": 2.599288085429748,
      "grad_norm": 0.21876898407936096,
      "learning_rate": 6.695196576410831e-06,
      "loss": 0.0636,
      "step": 129980
    },
    {
      "epoch": 2.599488061432628,
      "grad_norm": 0.09943392127752304,
      "learning_rate": 6.691863643029503e-06,
      "loss": 0.0445,
      "step": 129990
    },
    {
      "epoch": 2.5996880374355076,
      "grad_norm": 0.08785894513130188,
      "learning_rate": 6.688530709648176e-06,
      "loss": 0.0779,
      "step": 130000
    },
    {
      "epoch": 2.5998880134383873,
      "grad_norm": 0.1853717565536499,
      "learning_rate": 6.685197776266848e-06,
      "loss": 0.1069,
      "step": 130010
    },
    {
      "epoch": 2.600087989441267,
      "grad_norm": 0.12122129648923874,
      "learning_rate": 6.681864842885521e-06,
      "loss": 0.0817,
      "step": 130020
    },
    {
      "epoch": 2.6002879654441466,
      "grad_norm": 0.116686150431633,
      "learning_rate": 6.678531909504193e-06,
      "loss": 0.0499,
      "step": 130030
    },
    {
      "epoch": 2.6004879414470263,
      "grad_norm": 0.09166058897972107,
      "learning_rate": 6.675198976122865e-06,
      "loss": 0.0646,
      "step": 130040
    },
    {
      "epoch": 2.600687917449906,
      "grad_norm": 0.19075819849967957,
      "learning_rate": 6.671866042741538e-06,
      "loss": 0.0574,
      "step": 130050
    },
    {
      "epoch": 2.6008878934527857,
      "grad_norm": 0.0924731194972992,
      "learning_rate": 6.66853310936021e-06,
      "loss": 0.0826,
      "step": 130060
    },
    {
      "epoch": 2.6010878694556654,
      "grad_norm": 0.1551944613456726,
      "learning_rate": 6.665200175978883e-06,
      "loss": 0.0396,
      "step": 130070
    },
    {
      "epoch": 2.601287845458545,
      "grad_norm": 0.1483982801437378,
      "learning_rate": 6.6618672425975556e-06,
      "loss": 0.0355,
      "step": 130080
    },
    {
      "epoch": 2.6014878214614248,
      "grad_norm": 0.10953901708126068,
      "learning_rate": 6.658534309216227e-06,
      "loss": 0.065,
      "step": 130090
    },
    {
      "epoch": 2.6016877974643045,
      "grad_norm": 0.09034517407417297,
      "learning_rate": 6.655201375834901e-06,
      "loss": 0.0788,
      "step": 130100
    },
    {
      "epoch": 2.601887773467184,
      "grad_norm": 0.10404334962368011,
      "learning_rate": 6.651868442453572e-06,
      "loss": 0.0521,
      "step": 130110
    },
    {
      "epoch": 2.602087749470064,
      "grad_norm": 0.11120035499334335,
      "learning_rate": 6.648535509072246e-06,
      "loss": 0.0683,
      "step": 130120
    },
    {
      "epoch": 2.6022877254729435,
      "grad_norm": 0.1680900603532791,
      "learning_rate": 6.645202575690917e-06,
      "loss": 0.0894,
      "step": 130130
    },
    {
      "epoch": 2.6024877014758228,
      "grad_norm": 0.12857262790203094,
      "learning_rate": 6.641869642309589e-06,
      "loss": 0.0744,
      "step": 130140
    },
    {
      "epoch": 2.6026876774787024,
      "grad_norm": 0.13213030993938446,
      "learning_rate": 6.638536708928262e-06,
      "loss": 0.0601,
      "step": 130150
    },
    {
      "epoch": 2.602887653481582,
      "grad_norm": 0.19735558331012726,
      "learning_rate": 6.6352037755469345e-06,
      "loss": 0.0535,
      "step": 130160
    },
    {
      "epoch": 2.603087629484462,
      "grad_norm": 0.11555567383766174,
      "learning_rate": 6.631870842165607e-06,
      "loss": 0.0701,
      "step": 130170
    },
    {
      "epoch": 2.6032876054873415,
      "grad_norm": 0.08384008705615997,
      "learning_rate": 6.62853790878428e-06,
      "loss": 0.0487,
      "step": 130180
    },
    {
      "epoch": 2.603487581490221,
      "grad_norm": 0.10595975816249847,
      "learning_rate": 6.625204975402952e-06,
      "loss": 0.0733,
      "step": 130190
    },
    {
      "epoch": 2.603687557493101,
      "grad_norm": 0.14871178567409515,
      "learning_rate": 6.621872042021625e-06,
      "loss": 0.0675,
      "step": 130200
    },
    {
      "epoch": 2.6038875334959806,
      "grad_norm": 0.16009625792503357,
      "learning_rate": 6.618539108640297e-06,
      "loss": 0.0514,
      "step": 130210
    },
    {
      "epoch": 2.6040875094988603,
      "grad_norm": 0.1857369840145111,
      "learning_rate": 6.615206175258968e-06,
      "loss": 0.0686,
      "step": 130220
    },
    {
      "epoch": 2.60428748550174,
      "grad_norm": 0.12341617047786713,
      "learning_rate": 6.611873241877642e-06,
      "loss": 0.0441,
      "step": 130230
    },
    {
      "epoch": 2.604487461504619,
      "grad_norm": 0.1642017364501953,
      "learning_rate": 6.6085403084963135e-06,
      "loss": 0.0622,
      "step": 130240
    },
    {
      "epoch": 2.604687437507499,
      "grad_norm": 0.22638332843780518,
      "learning_rate": 6.605207375114987e-06,
      "loss": 0.0934,
      "step": 130250
    },
    {
      "epoch": 2.6048874135103786,
      "grad_norm": 0.07976876944303513,
      "learning_rate": 6.601874441733659e-06,
      "loss": 0.0995,
      "step": 130260
    },
    {
      "epoch": 2.6050873895132582,
      "grad_norm": 0.2670077383518219,
      "learning_rate": 6.598541508352331e-06,
      "loss": 0.1037,
      "step": 130270
    },
    {
      "epoch": 2.605287365516138,
      "grad_norm": 0.08864803612232208,
      "learning_rate": 6.595208574971004e-06,
      "loss": 0.0378,
      "step": 130280
    },
    {
      "epoch": 2.6054873415190176,
      "grad_norm": 0.146622434258461,
      "learning_rate": 6.591875641589676e-06,
      "loss": 0.081,
      "step": 130290
    },
    {
      "epoch": 2.6056873175218973,
      "grad_norm": 0.1754021942615509,
      "learning_rate": 6.588542708208349e-06,
      "loss": 0.0605,
      "step": 130300
    },
    {
      "epoch": 2.605887293524777,
      "grad_norm": 0.14881157875061035,
      "learning_rate": 6.585209774827021e-06,
      "loss": 0.0781,
      "step": 130310
    },
    {
      "epoch": 2.6060872695276567,
      "grad_norm": 0.16753865778446198,
      "learning_rate": 6.581876841445693e-06,
      "loss": 0.0741,
      "step": 130320
    },
    {
      "epoch": 2.6062872455305364,
      "grad_norm": 0.17014111578464508,
      "learning_rate": 6.578543908064366e-06,
      "loss": 0.0954,
      "step": 130330
    },
    {
      "epoch": 2.606487221533416,
      "grad_norm": 0.06793365627527237,
      "learning_rate": 6.5752109746830384e-06,
      "loss": 0.0742,
      "step": 130340
    },
    {
      "epoch": 2.6066871975362957,
      "grad_norm": 0.25422757863998413,
      "learning_rate": 6.5718780413017114e-06,
      "loss": 0.0894,
      "step": 130350
    },
    {
      "epoch": 2.6068871735391754,
      "grad_norm": 0.19764478504657745,
      "learning_rate": 6.568545107920384e-06,
      "loss": 0.0784,
      "step": 130360
    },
    {
      "epoch": 2.607087149542055,
      "grad_norm": 0.15378369390964508,
      "learning_rate": 6.565212174539055e-06,
      "loss": 0.0803,
      "step": 130370
    },
    {
      "epoch": 2.607287125544935,
      "grad_norm": 0.1959114670753479,
      "learning_rate": 6.561879241157729e-06,
      "loss": 0.0966,
      "step": 130380
    },
    {
      "epoch": 2.6074871015478145,
      "grad_norm": 0.12722130119800568,
      "learning_rate": 6.5585463077764e-06,
      "loss": 0.0801,
      "step": 130390
    },
    {
      "epoch": 2.607687077550694,
      "grad_norm": 0.18917541205883026,
      "learning_rate": 6.555213374395072e-06,
      "loss": 0.0827,
      "step": 130400
    },
    {
      "epoch": 2.6078870535535734,
      "grad_norm": 0.13665124773979187,
      "learning_rate": 6.551880441013745e-06,
      "loss": 0.0636,
      "step": 130410
    },
    {
      "epoch": 2.608087029556453,
      "grad_norm": 0.10360804200172424,
      "learning_rate": 6.548547507632417e-06,
      "loss": 0.1203,
      "step": 130420
    },
    {
      "epoch": 2.608287005559333,
      "grad_norm": 0.09610278159379959,
      "learning_rate": 6.54521457425109e-06,
      "loss": 0.0442,
      "step": 130430
    },
    {
      "epoch": 2.6084869815622125,
      "grad_norm": 0.18102101981639862,
      "learning_rate": 6.5418816408697625e-06,
      "loss": 0.0759,
      "step": 130440
    },
    {
      "epoch": 2.608686957565092,
      "grad_norm": 0.11792965978384018,
      "learning_rate": 6.538548707488435e-06,
      "loss": 0.0889,
      "step": 130450
    },
    {
      "epoch": 2.608886933567972,
      "grad_norm": 0.06617238372564316,
      "learning_rate": 6.535215774107108e-06,
      "loss": 0.0728,
      "step": 130460
    },
    {
      "epoch": 2.6090869095708515,
      "grad_norm": 0.08221019804477692,
      "learning_rate": 6.53188284072578e-06,
      "loss": 0.0719,
      "step": 130470
    },
    {
      "epoch": 2.6092868855737312,
      "grad_norm": 0.37864601612091064,
      "learning_rate": 6.528549907344453e-06,
      "loss": 0.2122,
      "step": 130480
    },
    {
      "epoch": 2.609486861576611,
      "grad_norm": 0.111213319003582,
      "learning_rate": 6.525216973963125e-06,
      "loss": 0.0596,
      "step": 130490
    },
    {
      "epoch": 2.6096868375794906,
      "grad_norm": 0.19953273236751556,
      "learning_rate": 6.521884040581796e-06,
      "loss": 0.0964,
      "step": 130500
    },
    {
      "epoch": 2.60988681358237,
      "grad_norm": 0.0813586413860321,
      "learning_rate": 6.51855110720047e-06,
      "loss": 0.0774,
      "step": 130510
    },
    {
      "epoch": 2.6100867895852495,
      "grad_norm": 0.2279803603887558,
      "learning_rate": 6.5152181738191415e-06,
      "loss": 0.0653,
      "step": 130520
    },
    {
      "epoch": 2.610286765588129,
      "grad_norm": 0.17150115966796875,
      "learning_rate": 6.511885240437815e-06,
      "loss": 0.0821,
      "step": 130530
    },
    {
      "epoch": 2.610486741591009,
      "grad_norm": 0.09035040438175201,
      "learning_rate": 6.508552307056487e-06,
      "loss": 0.0544,
      "step": 130540
    },
    {
      "epoch": 2.6106867175938886,
      "grad_norm": 0.1396917700767517,
      "learning_rate": 6.505219373675159e-06,
      "loss": 0.0912,
      "step": 130550
    },
    {
      "epoch": 2.6108866935967683,
      "grad_norm": 0.1030326709151268,
      "learning_rate": 6.501886440293832e-06,
      "loss": 0.0603,
      "step": 130560
    },
    {
      "epoch": 2.611086669599648,
      "grad_norm": 0.07984034717082977,
      "learning_rate": 6.498553506912504e-06,
      "loss": 0.0633,
      "step": 130570
    },
    {
      "epoch": 2.6112866456025277,
      "grad_norm": 0.12170162796974182,
      "learning_rate": 6.495220573531177e-06,
      "loss": 0.0782,
      "step": 130580
    },
    {
      "epoch": 2.6114866216054073,
      "grad_norm": 0.1833251416683197,
      "learning_rate": 6.491887640149849e-06,
      "loss": 0.0615,
      "step": 130590
    },
    {
      "epoch": 2.611686597608287,
      "grad_norm": 0.21462243795394897,
      "learning_rate": 6.488554706768521e-06,
      "loss": 0.1071,
      "step": 130600
    },
    {
      "epoch": 2.6118865736111667,
      "grad_norm": 0.18799149990081787,
      "learning_rate": 6.485221773387194e-06,
      "loss": 0.0536,
      "step": 130610
    },
    {
      "epoch": 2.6120865496140464,
      "grad_norm": 0.10193697363138199,
      "learning_rate": 6.4818888400058664e-06,
      "loss": 0.0917,
      "step": 130620
    },
    {
      "epoch": 2.612286525616926,
      "grad_norm": 0.09205836802721024,
      "learning_rate": 6.4785559066245395e-06,
      "loss": 0.0775,
      "step": 130630
    },
    {
      "epoch": 2.612486501619806,
      "grad_norm": 0.1158745214343071,
      "learning_rate": 6.475222973243212e-06,
      "loss": 0.0539,
      "step": 130640
    },
    {
      "epoch": 2.6126864776226855,
      "grad_norm": 0.11884379386901855,
      "learning_rate": 6.471890039861883e-06,
      "loss": 0.0847,
      "step": 130650
    },
    {
      "epoch": 2.612886453625565,
      "grad_norm": 0.2216922640800476,
      "learning_rate": 6.468557106480557e-06,
      "loss": 0.0905,
      "step": 130660
    },
    {
      "epoch": 2.613086429628445,
      "grad_norm": 0.12741383910179138,
      "learning_rate": 6.465224173099228e-06,
      "loss": 0.0654,
      "step": 130670
    },
    {
      "epoch": 2.613286405631324,
      "grad_norm": 0.1602121889591217,
      "learning_rate": 6.4618912397179e-06,
      "loss": 0.0692,
      "step": 130680
    },
    {
      "epoch": 2.6134863816342038,
      "grad_norm": 0.08533424884080887,
      "learning_rate": 6.458558306336573e-06,
      "loss": 0.0529,
      "step": 130690
    },
    {
      "epoch": 2.6136863576370835,
      "grad_norm": 0.14562807977199554,
      "learning_rate": 6.455225372955245e-06,
      "loss": 0.0737,
      "step": 130700
    },
    {
      "epoch": 2.613886333639963,
      "grad_norm": 0.18868562579154968,
      "learning_rate": 6.451892439573918e-06,
      "loss": 0.0869,
      "step": 130710
    },
    {
      "epoch": 2.614086309642843,
      "grad_norm": 0.26020219922065735,
      "learning_rate": 6.4485595061925906e-06,
      "loss": 0.1096,
      "step": 130720
    },
    {
      "epoch": 2.6142862856457225,
      "grad_norm": 0.17495235800743103,
      "learning_rate": 6.445226572811263e-06,
      "loss": 0.0561,
      "step": 130730
    },
    {
      "epoch": 2.614486261648602,
      "grad_norm": 0.16423800587654114,
      "learning_rate": 6.441893639429936e-06,
      "loss": 0.0732,
      "step": 130740
    },
    {
      "epoch": 2.614686237651482,
      "grad_norm": 0.1674126237630844,
      "learning_rate": 6.438560706048608e-06,
      "loss": 0.0582,
      "step": 130750
    },
    {
      "epoch": 2.6148862136543616,
      "grad_norm": 0.05897751450538635,
      "learning_rate": 6.435227772667281e-06,
      "loss": 0.0724,
      "step": 130760
    },
    {
      "epoch": 2.6150861896572413,
      "grad_norm": 0.17648550868034363,
      "learning_rate": 6.431894839285953e-06,
      "loss": 0.076,
      "step": 130770
    },
    {
      "epoch": 2.6152861656601205,
      "grad_norm": 0.12352681905031204,
      "learning_rate": 6.428561905904624e-06,
      "loss": 0.0854,
      "step": 130780
    },
    {
      "epoch": 2.615486141663,
      "grad_norm": 0.12449266761541367,
      "learning_rate": 6.425228972523298e-06,
      "loss": 0.0637,
      "step": 130790
    },
    {
      "epoch": 2.61568611766588,
      "grad_norm": 0.06601885706186295,
      "learning_rate": 6.4218960391419695e-06,
      "loss": 0.075,
      "step": 130800
    },
    {
      "epoch": 2.6158860936687596,
      "grad_norm": 0.07971259951591492,
      "learning_rate": 6.418563105760643e-06,
      "loss": 0.0849,
      "step": 130810
    },
    {
      "epoch": 2.6160860696716393,
      "grad_norm": 0.24983879923820496,
      "learning_rate": 6.415230172379315e-06,
      "loss": 0.0921,
      "step": 130820
    },
    {
      "epoch": 2.616286045674519,
      "grad_norm": 0.2262379229068756,
      "learning_rate": 6.411897238997987e-06,
      "loss": 0.0775,
      "step": 130830
    },
    {
      "epoch": 2.6164860216773986,
      "grad_norm": 0.06599260121583939,
      "learning_rate": 6.40856430561666e-06,
      "loss": 0.0478,
      "step": 130840
    },
    {
      "epoch": 2.6166859976802783,
      "grad_norm": 0.21047192811965942,
      "learning_rate": 6.405231372235332e-06,
      "loss": 0.074,
      "step": 130850
    },
    {
      "epoch": 2.616885973683158,
      "grad_norm": 0.19627901911735535,
      "learning_rate": 6.401898438854005e-06,
      "loss": 0.0591,
      "step": 130860
    },
    {
      "epoch": 2.6170859496860377,
      "grad_norm": 0.10029973089694977,
      "learning_rate": 6.398565505472677e-06,
      "loss": 0.077,
      "step": 130870
    },
    {
      "epoch": 2.6172859256889174,
      "grad_norm": 0.15382984280586243,
      "learning_rate": 6.395232572091349e-06,
      "loss": 0.0944,
      "step": 130880
    },
    {
      "epoch": 2.617485901691797,
      "grad_norm": 0.12461310625076294,
      "learning_rate": 6.391899638710022e-06,
      "loss": 0.0507,
      "step": 130890
    },
    {
      "epoch": 2.6176858776946768,
      "grad_norm": 0.11809064447879791,
      "learning_rate": 6.3885667053286945e-06,
      "loss": 0.086,
      "step": 130900
    },
    {
      "epoch": 2.6178858536975564,
      "grad_norm": 0.11392399668693542,
      "learning_rate": 6.385233771947366e-06,
      "loss": 0.0804,
      "step": 130910
    },
    {
      "epoch": 2.618085829700436,
      "grad_norm": 0.1061173528432846,
      "learning_rate": 6.38190083856604e-06,
      "loss": 0.0841,
      "step": 130920
    },
    {
      "epoch": 2.618285805703316,
      "grad_norm": 0.12588809430599213,
      "learning_rate": 6.378567905184711e-06,
      "loss": 0.0471,
      "step": 130930
    },
    {
      "epoch": 2.6184857817061955,
      "grad_norm": 0.20079845190048218,
      "learning_rate": 6.375234971803384e-06,
      "loss": 0.0858,
      "step": 130940
    },
    {
      "epoch": 2.6186857577090747,
      "grad_norm": 0.1210736632347107,
      "learning_rate": 6.371902038422056e-06,
      "loss": 0.1467,
      "step": 130950
    },
    {
      "epoch": 2.6188857337119544,
      "grad_norm": 0.1505669206380844,
      "learning_rate": 6.368569105040728e-06,
      "loss": 0.0961,
      "step": 130960
    },
    {
      "epoch": 2.619085709714834,
      "grad_norm": 0.1399141252040863,
      "learning_rate": 6.365236171659401e-06,
      "loss": 0.09,
      "step": 130970
    },
    {
      "epoch": 2.619285685717714,
      "grad_norm": 0.15542036294937134,
      "learning_rate": 6.361903238278073e-06,
      "loss": 0.0551,
      "step": 130980
    },
    {
      "epoch": 2.6194856617205935,
      "grad_norm": 0.19990818202495575,
      "learning_rate": 6.358570304896746e-06,
      "loss": 0.0557,
      "step": 130990
    },
    {
      "epoch": 2.619685637723473,
      "grad_norm": 0.09089705348014832,
      "learning_rate": 6.355237371515419e-06,
      "loss": 0.0697,
      "step": 131000
    },
    {
      "epoch": 2.619885613726353,
      "grad_norm": 0.1658056229352951,
      "learning_rate": 6.35190443813409e-06,
      "loss": 0.0559,
      "step": 131010
    },
    {
      "epoch": 2.6200855897292326,
      "grad_norm": 0.03904525935649872,
      "learning_rate": 6.348571504752764e-06,
      "loss": 0.0461,
      "step": 131020
    },
    {
      "epoch": 2.6202855657321122,
      "grad_norm": 0.10423456132411957,
      "learning_rate": 6.345238571371435e-06,
      "loss": 0.0521,
      "step": 131030
    },
    {
      "epoch": 2.620485541734992,
      "grad_norm": 0.13270972669124603,
      "learning_rate": 6.341905637990109e-06,
      "loss": 0.0393,
      "step": 131040
    },
    {
      "epoch": 2.6206855177378716,
      "grad_norm": 0.08283344656229019,
      "learning_rate": 6.33857270460878e-06,
      "loss": 0.0849,
      "step": 131050
    },
    {
      "epoch": 2.620885493740751,
      "grad_norm": 0.08499860018491745,
      "learning_rate": 6.335239771227452e-06,
      "loss": 0.0506,
      "step": 131060
    },
    {
      "epoch": 2.6210854697436305,
      "grad_norm": 0.17341840267181396,
      "learning_rate": 6.331906837846125e-06,
      "loss": 0.0445,
      "step": 131070
    },
    {
      "epoch": 2.6212854457465102,
      "grad_norm": 0.14925527572631836,
      "learning_rate": 6.3285739044647975e-06,
      "loss": 0.0664,
      "step": 131080
    },
    {
      "epoch": 2.62148542174939,
      "grad_norm": 0.20388825237751007,
      "learning_rate": 6.3252409710834705e-06,
      "loss": 0.0883,
      "step": 131090
    },
    {
      "epoch": 2.6216853977522696,
      "grad_norm": 0.08234251290559769,
      "learning_rate": 6.321908037702143e-06,
      "loss": 0.0982,
      "step": 131100
    },
    {
      "epoch": 2.6218853737551493,
      "grad_norm": 0.13868458569049835,
      "learning_rate": 6.318575104320815e-06,
      "loss": 0.0568,
      "step": 131110
    },
    {
      "epoch": 2.622085349758029,
      "grad_norm": 0.08046074211597443,
      "learning_rate": 6.315242170939488e-06,
      "loss": 0.0797,
      "step": 131120
    },
    {
      "epoch": 2.6222853257609087,
      "grad_norm": 0.20270732045173645,
      "learning_rate": 6.31190923755816e-06,
      "loss": 0.0831,
      "step": 131130
    },
    {
      "epoch": 2.6224853017637884,
      "grad_norm": 0.37074559926986694,
      "learning_rate": 6.308576304176833e-06,
      "loss": 0.0736,
      "step": 131140
    },
    {
      "epoch": 2.622685277766668,
      "grad_norm": 0.11150964349508286,
      "learning_rate": 6.305243370795505e-06,
      "loss": 0.0854,
      "step": 131150
    },
    {
      "epoch": 2.6228852537695477,
      "grad_norm": 0.22491036355495453,
      "learning_rate": 6.3019104374141765e-06,
      "loss": 0.1208,
      "step": 131160
    },
    {
      "epoch": 2.6230852297724274,
      "grad_norm": 0.10023592412471771,
      "learning_rate": 6.29857750403285e-06,
      "loss": 0.0723,
      "step": 131170
    },
    {
      "epoch": 2.623285205775307,
      "grad_norm": 0.10003042966127396,
      "learning_rate": 6.295244570651522e-06,
      "loss": 0.0916,
      "step": 131180
    },
    {
      "epoch": 2.623485181778187,
      "grad_norm": 0.12224582582712173,
      "learning_rate": 6.291911637270194e-06,
      "loss": 0.0716,
      "step": 131190
    },
    {
      "epoch": 2.6236851577810665,
      "grad_norm": 0.14940837025642395,
      "learning_rate": 6.288578703888867e-06,
      "loss": 0.0564,
      "step": 131200
    },
    {
      "epoch": 2.623885133783946,
      "grad_norm": 0.2923034429550171,
      "learning_rate": 6.285245770507539e-06,
      "loss": 0.0813,
      "step": 131210
    },
    {
      "epoch": 2.624085109786826,
      "grad_norm": 0.21596308052539825,
      "learning_rate": 6.281912837126212e-06,
      "loss": 0.0659,
      "step": 131220
    },
    {
      "epoch": 2.624285085789705,
      "grad_norm": 0.15151388943195343,
      "learning_rate": 6.278579903744884e-06,
      "loss": 0.0894,
      "step": 131230
    },
    {
      "epoch": 2.624485061792585,
      "grad_norm": 0.17871583998203278,
      "learning_rate": 6.275246970363556e-06,
      "loss": 0.0502,
      "step": 131240
    },
    {
      "epoch": 2.6246850377954645,
      "grad_norm": 0.04281251132488251,
      "learning_rate": 6.271914036982229e-06,
      "loss": 0.0636,
      "step": 131250
    },
    {
      "epoch": 2.624885013798344,
      "grad_norm": 0.1781248301267624,
      "learning_rate": 6.2685811036009014e-06,
      "loss": 0.0642,
      "step": 131260
    },
    {
      "epoch": 2.625084989801224,
      "grad_norm": 0.12614385783672333,
      "learning_rate": 6.2652481702195744e-06,
      "loss": 0.0771,
      "step": 131270
    },
    {
      "epoch": 2.6252849658041035,
      "grad_norm": 0.1785341203212738,
      "learning_rate": 6.261915236838247e-06,
      "loss": 0.0774,
      "step": 131280
    },
    {
      "epoch": 2.625484941806983,
      "grad_norm": 0.1320708841085434,
      "learning_rate": 6.258582303456918e-06,
      "loss": 0.0905,
      "step": 131290
    },
    {
      "epoch": 2.625684917809863,
      "grad_norm": 0.2135864943265915,
      "learning_rate": 6.255249370075592e-06,
      "loss": 0.0718,
      "step": 131300
    },
    {
      "epoch": 2.6258848938127426,
      "grad_norm": 0.08899490535259247,
      "learning_rate": 6.251916436694263e-06,
      "loss": 0.0474,
      "step": 131310
    },
    {
      "epoch": 2.6260848698156223,
      "grad_norm": 0.24874404072761536,
      "learning_rate": 6.248583503312936e-06,
      "loss": 0.0523,
      "step": 131320
    },
    {
      "epoch": 2.6262848458185015,
      "grad_norm": 0.13923275470733643,
      "learning_rate": 6.245250569931608e-06,
      "loss": 0.0822,
      "step": 131330
    },
    {
      "epoch": 2.626484821821381,
      "grad_norm": 0.18351615965366364,
      "learning_rate": 6.241917636550281e-06,
      "loss": 0.0958,
      "step": 131340
    },
    {
      "epoch": 2.626684797824261,
      "grad_norm": 0.17132721841335297,
      "learning_rate": 6.238584703168953e-06,
      "loss": 0.0796,
      "step": 131350
    },
    {
      "epoch": 2.6268847738271406,
      "grad_norm": 0.1458667814731598,
      "learning_rate": 6.2352517697876255e-06,
      "loss": 0.1224,
      "step": 131360
    },
    {
      "epoch": 2.6270847498300203,
      "grad_norm": 0.19267718493938446,
      "learning_rate": 6.2319188364062986e-06,
      "loss": 0.0887,
      "step": 131370
    },
    {
      "epoch": 2.6272847258329,
      "grad_norm": 0.11232348531484604,
      "learning_rate": 6.228585903024971e-06,
      "loss": 0.0571,
      "step": 131380
    },
    {
      "epoch": 2.6274847018357796,
      "grad_norm": 0.07024507969617844,
      "learning_rate": 6.225252969643644e-06,
      "loss": 0.0498,
      "step": 131390
    },
    {
      "epoch": 2.6276846778386593,
      "grad_norm": 0.1344892382621765,
      "learning_rate": 6.221920036262315e-06,
      "loss": 0.0669,
      "step": 131400
    },
    {
      "epoch": 2.627884653841539,
      "grad_norm": 0.22150032222270966,
      "learning_rate": 6.218587102880988e-06,
      "loss": 0.0658,
      "step": 131410
    },
    {
      "epoch": 2.6280846298444187,
      "grad_norm": 0.05559033527970314,
      "learning_rate": 6.21525416949966e-06,
      "loss": 0.0574,
      "step": 131420
    },
    {
      "epoch": 2.6282846058472984,
      "grad_norm": 0.04553057625889778,
      "learning_rate": 6.211921236118333e-06,
      "loss": 0.0566,
      "step": 131430
    },
    {
      "epoch": 2.628484581850178,
      "grad_norm": 0.224683478474617,
      "learning_rate": 6.208588302737005e-06,
      "loss": 0.0848,
      "step": 131440
    },
    {
      "epoch": 2.6286845578530578,
      "grad_norm": 0.22990041971206665,
      "learning_rate": 6.2052553693556775e-06,
      "loss": 0.0799,
      "step": 131450
    },
    {
      "epoch": 2.6288845338559375,
      "grad_norm": 0.09137624502182007,
      "learning_rate": 6.20192243597435e-06,
      "loss": 0.0468,
      "step": 131460
    },
    {
      "epoch": 2.629084509858817,
      "grad_norm": 0.14125008881092072,
      "learning_rate": 6.198589502593023e-06,
      "loss": 0.0605,
      "step": 131470
    },
    {
      "epoch": 2.629284485861697,
      "grad_norm": 0.1071699857711792,
      "learning_rate": 6.195256569211695e-06,
      "loss": 0.043,
      "step": 131480
    },
    {
      "epoch": 2.6294844618645765,
      "grad_norm": 0.09828831255435944,
      "learning_rate": 6.191923635830367e-06,
      "loss": 0.1335,
      "step": 131490
    },
    {
      "epoch": 2.6296844378674558,
      "grad_norm": 0.1653786152601242,
      "learning_rate": 6.18859070244904e-06,
      "loss": 0.0614,
      "step": 131500
    },
    {
      "epoch": 2.6298844138703354,
      "grad_norm": 0.225820854306221,
      "learning_rate": 6.185257769067712e-06,
      "loss": 0.0738,
      "step": 131510
    },
    {
      "epoch": 2.630084389873215,
      "grad_norm": 0.1466509848833084,
      "learning_rate": 6.181924835686385e-06,
      "loss": 0.0691,
      "step": 131520
    },
    {
      "epoch": 2.630284365876095,
      "grad_norm": 0.0782579854130745,
      "learning_rate": 6.178591902305057e-06,
      "loss": 0.0727,
      "step": 131530
    },
    {
      "epoch": 2.6304843418789745,
      "grad_norm": 0.12011964619159698,
      "learning_rate": 6.1752589689237295e-06,
      "loss": 0.0657,
      "step": 131540
    },
    {
      "epoch": 2.630684317881854,
      "grad_norm": 0.23989678919315338,
      "learning_rate": 6.171926035542402e-06,
      "loss": 0.0745,
      "step": 131550
    },
    {
      "epoch": 2.630884293884734,
      "grad_norm": 0.21986520290374756,
      "learning_rate": 6.168593102161075e-06,
      "loss": 0.0711,
      "step": 131560
    },
    {
      "epoch": 2.6310842698876136,
      "grad_norm": 0.13753429055213928,
      "learning_rate": 6.165260168779747e-06,
      "loss": 0.0556,
      "step": 131570
    },
    {
      "epoch": 2.6312842458904933,
      "grad_norm": 0.1834540069103241,
      "learning_rate": 6.16192723539842e-06,
      "loss": 0.0705,
      "step": 131580
    },
    {
      "epoch": 2.631484221893373,
      "grad_norm": 0.24634753167629242,
      "learning_rate": 6.158594302017091e-06,
      "loss": 0.0895,
      "step": 131590
    },
    {
      "epoch": 2.631684197896252,
      "grad_norm": 0.07512833178043365,
      "learning_rate": 6.155261368635764e-06,
      "loss": 0.0761,
      "step": 131600
    },
    {
      "epoch": 2.631884173899132,
      "grad_norm": 0.18505200743675232,
      "learning_rate": 6.151928435254436e-06,
      "loss": 0.0702,
      "step": 131610
    },
    {
      "epoch": 2.6320841499020116,
      "grad_norm": 0.13808786869049072,
      "learning_rate": 6.148595501873109e-06,
      "loss": 0.0751,
      "step": 131620
    },
    {
      "epoch": 2.6322841259048912,
      "grad_norm": 0.18792879581451416,
      "learning_rate": 6.1452625684917806e-06,
      "loss": 0.0864,
      "step": 131630
    },
    {
      "epoch": 2.632484101907771,
      "grad_norm": 0.2374764382839203,
      "learning_rate": 6.1419296351104536e-06,
      "loss": 0.0857,
      "step": 131640
    },
    {
      "epoch": 2.6326840779106506,
      "grad_norm": 0.10786605626344681,
      "learning_rate": 6.138596701729126e-06,
      "loss": 0.0697,
      "step": 131650
    },
    {
      "epoch": 2.6328840539135303,
      "grad_norm": 0.2074602246284485,
      "learning_rate": 6.135263768347799e-06,
      "loss": 0.0972,
      "step": 131660
    },
    {
      "epoch": 2.63308402991641,
      "grad_norm": 0.15271635353565216,
      "learning_rate": 6.131930834966471e-06,
      "loss": 0.0892,
      "step": 131670
    },
    {
      "epoch": 2.6332840059192897,
      "grad_norm": 0.10218217223882675,
      "learning_rate": 6.128597901585143e-06,
      "loss": 0.0836,
      "step": 131680
    },
    {
      "epoch": 2.6334839819221694,
      "grad_norm": 0.11020270735025406,
      "learning_rate": 6.125264968203816e-06,
      "loss": 0.0524,
      "step": 131690
    },
    {
      "epoch": 2.633683957925049,
      "grad_norm": 0.06479749828577042,
      "learning_rate": 6.121932034822488e-06,
      "loss": 0.0569,
      "step": 131700
    },
    {
      "epoch": 2.6338839339279287,
      "grad_norm": 0.12318026274442673,
      "learning_rate": 6.118599101441161e-06,
      "loss": 0.0724,
      "step": 131710
    },
    {
      "epoch": 2.6340839099308084,
      "grad_norm": 0.2036663144826889,
      "learning_rate": 6.1152661680598325e-06,
      "loss": 0.0641,
      "step": 131720
    },
    {
      "epoch": 2.634283885933688,
      "grad_norm": 0.09509611129760742,
      "learning_rate": 6.1119332346785055e-06,
      "loss": 0.0578,
      "step": 131730
    },
    {
      "epoch": 2.634483861936568,
      "grad_norm": 0.04575658589601517,
      "learning_rate": 6.108600301297178e-06,
      "loss": 0.0619,
      "step": 131740
    },
    {
      "epoch": 2.6346838379394475,
      "grad_norm": 0.08034153282642365,
      "learning_rate": 6.105267367915851e-06,
      "loss": 0.0533,
      "step": 131750
    },
    {
      "epoch": 2.634883813942327,
      "grad_norm": 0.09172898530960083,
      "learning_rate": 6.101934434534523e-06,
      "loss": 0.0575,
      "step": 131760
    },
    {
      "epoch": 2.6350837899452064,
      "grad_norm": 0.31276288628578186,
      "learning_rate": 6.098601501153195e-06,
      "loss": 0.1147,
      "step": 131770
    },
    {
      "epoch": 2.635283765948086,
      "grad_norm": 0.1501791924238205,
      "learning_rate": 6.095268567771867e-06,
      "loss": 0.0624,
      "step": 131780
    },
    {
      "epoch": 2.635483741950966,
      "grad_norm": 0.1451275646686554,
      "learning_rate": 6.09193563439054e-06,
      "loss": 0.0515,
      "step": 131790
    },
    {
      "epoch": 2.6356837179538455,
      "grad_norm": 0.17347633838653564,
      "learning_rate": 6.088602701009212e-06,
      "loss": 0.0969,
      "step": 131800
    },
    {
      "epoch": 2.635883693956725,
      "grad_norm": 0.09817536920309067,
      "learning_rate": 6.085269767627885e-06,
      "loss": 0.0945,
      "step": 131810
    },
    {
      "epoch": 2.636083669959605,
      "grad_norm": 0.07262839376926422,
      "learning_rate": 6.0819368342465575e-06,
      "loss": 0.1162,
      "step": 131820
    },
    {
      "epoch": 2.6362836459624845,
      "grad_norm": 0.09500076621770859,
      "learning_rate": 6.07860390086523e-06,
      "loss": 0.059,
      "step": 131830
    },
    {
      "epoch": 2.6364836219653642,
      "grad_norm": 0.07166513055562973,
      "learning_rate": 6.075270967483903e-06,
      "loss": 0.0412,
      "step": 131840
    },
    {
      "epoch": 2.636683597968244,
      "grad_norm": 0.10715165734291077,
      "learning_rate": 6.071938034102575e-06,
      "loss": 0.0683,
      "step": 131850
    },
    {
      "epoch": 2.6368835739711236,
      "grad_norm": 0.08962295949459076,
      "learning_rate": 6.068605100721247e-06,
      "loss": 0.0698,
      "step": 131860
    },
    {
      "epoch": 2.637083549974003,
      "grad_norm": 0.08573588728904724,
      "learning_rate": 6.065272167339919e-06,
      "loss": 0.1355,
      "step": 131870
    },
    {
      "epoch": 2.6372835259768825,
      "grad_norm": 0.13384027779102325,
      "learning_rate": 6.061939233958592e-06,
      "loss": 0.094,
      "step": 131880
    },
    {
      "epoch": 2.6374835019797622,
      "grad_norm": 0.25149282813072205,
      "learning_rate": 6.058606300577264e-06,
      "loss": 0.0671,
      "step": 131890
    },
    {
      "epoch": 2.637683477982642,
      "grad_norm": 0.15905889868736267,
      "learning_rate": 6.055273367195937e-06,
      "loss": 0.09,
      "step": 131900
    },
    {
      "epoch": 2.6378834539855216,
      "grad_norm": 0.23676703870296478,
      "learning_rate": 6.051940433814609e-06,
      "loss": 0.0821,
      "step": 131910
    },
    {
      "epoch": 2.6380834299884013,
      "grad_norm": 0.15382014214992523,
      "learning_rate": 6.048607500433282e-06,
      "loss": 0.0559,
      "step": 131920
    },
    {
      "epoch": 2.638283405991281,
      "grad_norm": 0.1749369353055954,
      "learning_rate": 6.045274567051954e-06,
      "loss": 0.101,
      "step": 131930
    },
    {
      "epoch": 2.6384833819941607,
      "grad_norm": 0.07377620786428452,
      "learning_rate": 6.041941633670627e-06,
      "loss": 0.0419,
      "step": 131940
    },
    {
      "epoch": 2.6386833579970403,
      "grad_norm": 0.10125119239091873,
      "learning_rate": 6.038608700289299e-06,
      "loss": 0.0541,
      "step": 131950
    },
    {
      "epoch": 2.63888333399992,
      "grad_norm": 0.18240699172019958,
      "learning_rate": 6.035275766907971e-06,
      "loss": 0.0641,
      "step": 131960
    },
    {
      "epoch": 2.6390833100027997,
      "grad_norm": 0.20725829899311066,
      "learning_rate": 6.031942833526644e-06,
      "loss": 0.0962,
      "step": 131970
    },
    {
      "epoch": 2.6392832860056794,
      "grad_norm": 0.08851947635412216,
      "learning_rate": 6.028609900145316e-06,
      "loss": 0.0718,
      "step": 131980
    },
    {
      "epoch": 2.639483262008559,
      "grad_norm": 0.2074790596961975,
      "learning_rate": 6.025276966763989e-06,
      "loss": 0.052,
      "step": 131990
    },
    {
      "epoch": 2.639683238011439,
      "grad_norm": 0.09515709429979324,
      "learning_rate": 6.0219440333826605e-06,
      "loss": 0.066,
      "step": 132000
    },
    {
      "epoch": 2.6398832140143185,
      "grad_norm": 0.14167293906211853,
      "learning_rate": 6.0186111000013335e-06,
      "loss": 0.0596,
      "step": 132010
    },
    {
      "epoch": 2.640083190017198,
      "grad_norm": 0.09156382828950882,
      "learning_rate": 6.015278166620006e-06,
      "loss": 0.0705,
      "step": 132020
    },
    {
      "epoch": 2.640283166020078,
      "grad_norm": 0.12903691828250885,
      "learning_rate": 6.011945233238679e-06,
      "loss": 0.0667,
      "step": 132030
    },
    {
      "epoch": 2.640483142022957,
      "grad_norm": 0.1893656849861145,
      "learning_rate": 6.008612299857351e-06,
      "loss": 0.1206,
      "step": 132040
    },
    {
      "epoch": 2.6406831180258368,
      "grad_norm": 0.27496328949928284,
      "learning_rate": 6.005279366476023e-06,
      "loss": 0.075,
      "step": 132050
    },
    {
      "epoch": 2.6408830940287165,
      "grad_norm": 0.12673227488994598,
      "learning_rate": 6.001946433094695e-06,
      "loss": 0.0879,
      "step": 132060
    },
    {
      "epoch": 2.641083070031596,
      "grad_norm": 0.1377517133951187,
      "learning_rate": 5.998613499713368e-06,
      "loss": 0.079,
      "step": 132070
    },
    {
      "epoch": 2.641283046034476,
      "grad_norm": 0.10724303871393204,
      "learning_rate": 5.99528056633204e-06,
      "loss": 0.0732,
      "step": 132080
    },
    {
      "epoch": 2.6414830220373555,
      "grad_norm": 0.16716057062149048,
      "learning_rate": 5.991947632950713e-06,
      "loss": 0.0881,
      "step": 132090
    },
    {
      "epoch": 2.641682998040235,
      "grad_norm": 0.14800326526165009,
      "learning_rate": 5.9886146995693855e-06,
      "loss": 0.0792,
      "step": 132100
    },
    {
      "epoch": 2.641882974043115,
      "grad_norm": 0.14047789573669434,
      "learning_rate": 5.985281766188058e-06,
      "loss": 0.0437,
      "step": 132110
    },
    {
      "epoch": 2.6420829500459946,
      "grad_norm": 0.10573796927928925,
      "learning_rate": 5.981948832806731e-06,
      "loss": 0.0892,
      "step": 132120
    },
    {
      "epoch": 2.6422829260488743,
      "grad_norm": 0.2505371868610382,
      "learning_rate": 5.978615899425403e-06,
      "loss": 0.1362,
      "step": 132130
    },
    {
      "epoch": 2.6424829020517535,
      "grad_norm": 0.0983850508928299,
      "learning_rate": 5.975282966044075e-06,
      "loss": 0.0396,
      "step": 132140
    },
    {
      "epoch": 2.642682878054633,
      "grad_norm": 0.14058144390583038,
      "learning_rate": 5.971950032662747e-06,
      "loss": 0.0792,
      "step": 132150
    },
    {
      "epoch": 2.642882854057513,
      "grad_norm": 0.10922764241695404,
      "learning_rate": 5.96861709928142e-06,
      "loss": 0.0771,
      "step": 132160
    },
    {
      "epoch": 2.6430828300603926,
      "grad_norm": 0.15673355758190155,
      "learning_rate": 5.965284165900092e-06,
      "loss": 0.0742,
      "step": 132170
    },
    {
      "epoch": 2.6432828060632723,
      "grad_norm": 0.1308918595314026,
      "learning_rate": 5.961951232518765e-06,
      "loss": 0.1064,
      "step": 132180
    },
    {
      "epoch": 2.643482782066152,
      "grad_norm": 0.2059861421585083,
      "learning_rate": 5.958618299137437e-06,
      "loss": 0.0416,
      "step": 132190
    },
    {
      "epoch": 2.6436827580690316,
      "grad_norm": 0.1780492663383484,
      "learning_rate": 5.95528536575611e-06,
      "loss": 0.1149,
      "step": 132200
    },
    {
      "epoch": 2.6438827340719113,
      "grad_norm": 0.13562923669815063,
      "learning_rate": 5.951952432374782e-06,
      "loss": 0.0874,
      "step": 132210
    },
    {
      "epoch": 2.644082710074791,
      "grad_norm": 0.12552078068256378,
      "learning_rate": 5.948619498993455e-06,
      "loss": 0.0957,
      "step": 132220
    },
    {
      "epoch": 2.6442826860776707,
      "grad_norm": 0.10660170763731003,
      "learning_rate": 5.945286565612126e-06,
      "loss": 0.1006,
      "step": 132230
    },
    {
      "epoch": 2.6444826620805504,
      "grad_norm": 0.18357150256633759,
      "learning_rate": 5.941953632230799e-06,
      "loss": 0.0732,
      "step": 132240
    },
    {
      "epoch": 2.64468263808343,
      "grad_norm": 0.06783372163772583,
      "learning_rate": 5.938620698849471e-06,
      "loss": 0.0744,
      "step": 132250
    },
    {
      "epoch": 2.6448826140863098,
      "grad_norm": 0.25009268522262573,
      "learning_rate": 5.935287765468144e-06,
      "loss": 0.0874,
      "step": 132260
    },
    {
      "epoch": 2.6450825900891894,
      "grad_norm": 0.08098772168159485,
      "learning_rate": 5.931954832086816e-06,
      "loss": 0.0784,
      "step": 132270
    },
    {
      "epoch": 2.645282566092069,
      "grad_norm": 0.20475618541240692,
      "learning_rate": 5.9286218987054886e-06,
      "loss": 0.0831,
      "step": 132280
    },
    {
      "epoch": 2.645482542094949,
      "grad_norm": 0.2624930143356323,
      "learning_rate": 5.9252889653241616e-06,
      "loss": 0.0791,
      "step": 132290
    },
    {
      "epoch": 2.6456825180978285,
      "grad_norm": 0.24053116142749786,
      "learning_rate": 5.921956031942834e-06,
      "loss": 0.09,
      "step": 132300
    },
    {
      "epoch": 2.6458824941007077,
      "grad_norm": 0.14573374390602112,
      "learning_rate": 5.918623098561507e-06,
      "loss": 0.0629,
      "step": 132310
    },
    {
      "epoch": 2.6460824701035874,
      "grad_norm": 0.27067670226097107,
      "learning_rate": 5.915290165180179e-06,
      "loss": 0.1157,
      "step": 132320
    },
    {
      "epoch": 2.646282446106467,
      "grad_norm": 0.15038268268108368,
      "learning_rate": 5.911957231798851e-06,
      "loss": 0.0734,
      "step": 132330
    },
    {
      "epoch": 2.646482422109347,
      "grad_norm": 0.16761350631713867,
      "learning_rate": 5.908624298417523e-06,
      "loss": 0.1222,
      "step": 132340
    },
    {
      "epoch": 2.6466823981122265,
      "grad_norm": 0.07791955769062042,
      "learning_rate": 5.905291365036196e-06,
      "loss": 0.0456,
      "step": 132350
    },
    {
      "epoch": 2.646882374115106,
      "grad_norm": 0.14989542961120605,
      "learning_rate": 5.901958431654868e-06,
      "loss": 0.1245,
      "step": 132360
    },
    {
      "epoch": 2.647082350117986,
      "grad_norm": 0.10767537355422974,
      "learning_rate": 5.8986254982735405e-06,
      "loss": 0.0866,
      "step": 132370
    },
    {
      "epoch": 2.6472823261208656,
      "grad_norm": 0.10723026096820831,
      "learning_rate": 5.895292564892213e-06,
      "loss": 0.0555,
      "step": 132380
    },
    {
      "epoch": 2.6474823021237452,
      "grad_norm": 0.06212442368268967,
      "learning_rate": 5.891959631510886e-06,
      "loss": 0.0804,
      "step": 132390
    },
    {
      "epoch": 2.647682278126625,
      "grad_norm": 0.0799749568104744,
      "learning_rate": 5.888626698129558e-06,
      "loss": 0.0704,
      "step": 132400
    },
    {
      "epoch": 2.6478822541295046,
      "grad_norm": 0.12276068329811096,
      "learning_rate": 5.885293764748231e-06,
      "loss": 0.0443,
      "step": 132410
    },
    {
      "epoch": 2.648082230132384,
      "grad_norm": 0.143474742770195,
      "learning_rate": 5.881960831366903e-06,
      "loss": 0.0506,
      "step": 132420
    },
    {
      "epoch": 2.6482822061352636,
      "grad_norm": 0.04356127977371216,
      "learning_rate": 5.878627897985575e-06,
      "loss": 0.0775,
      "step": 132430
    },
    {
      "epoch": 2.6484821821381432,
      "grad_norm": 0.1110183522105217,
      "learning_rate": 5.875294964604248e-06,
      "loss": 0.0586,
      "step": 132440
    },
    {
      "epoch": 2.648682158141023,
      "grad_norm": 0.0741298571228981,
      "learning_rate": 5.87196203122292e-06,
      "loss": 0.0854,
      "step": 132450
    },
    {
      "epoch": 2.6488821341439026,
      "grad_norm": 0.16180787980556488,
      "learning_rate": 5.868629097841593e-06,
      "loss": 0.0743,
      "step": 132460
    },
    {
      "epoch": 2.6490821101467823,
      "grad_norm": 0.08942753076553345,
      "learning_rate": 5.865296164460265e-06,
      "loss": 0.0611,
      "step": 132470
    },
    {
      "epoch": 2.649282086149662,
      "grad_norm": 0.09064298868179321,
      "learning_rate": 5.861963231078938e-06,
      "loss": 0.0655,
      "step": 132480
    },
    {
      "epoch": 2.6494820621525417,
      "grad_norm": 0.08582712709903717,
      "learning_rate": 5.85863029769761e-06,
      "loss": 0.0684,
      "step": 132490
    },
    {
      "epoch": 2.6496820381554214,
      "grad_norm": 0.234699547290802,
      "learning_rate": 5.855297364316283e-06,
      "loss": 0.1459,
      "step": 132500
    },
    {
      "epoch": 2.649882014158301,
      "grad_norm": 0.1071997880935669,
      "learning_rate": 5.851964430934954e-06,
      "loss": 0.0839,
      "step": 132510
    },
    {
      "epoch": 2.6500819901611807,
      "grad_norm": 0.18323855102062225,
      "learning_rate": 5.848631497553627e-06,
      "loss": 0.0873,
      "step": 132520
    },
    {
      "epoch": 2.6502819661640604,
      "grad_norm": 0.2103779911994934,
      "learning_rate": 5.845298564172299e-06,
      "loss": 0.0999,
      "step": 132530
    },
    {
      "epoch": 2.65048194216694,
      "grad_norm": 0.126111701130867,
      "learning_rate": 5.841965630790972e-06,
      "loss": 0.0683,
      "step": 132540
    },
    {
      "epoch": 2.65068191816982,
      "grad_norm": 0.11502651870250702,
      "learning_rate": 5.838632697409644e-06,
      "loss": 0.0738,
      "step": 132550
    },
    {
      "epoch": 2.6508818941726995,
      "grad_norm": 0.14207279682159424,
      "learning_rate": 5.8352997640283166e-06,
      "loss": 0.04,
      "step": 132560
    },
    {
      "epoch": 2.651081870175579,
      "grad_norm": 0.12061411887407303,
      "learning_rate": 5.83196683064699e-06,
      "loss": 0.0686,
      "step": 132570
    },
    {
      "epoch": 2.651281846178459,
      "grad_norm": 0.20109698176383972,
      "learning_rate": 5.828633897265662e-06,
      "loss": 0.0676,
      "step": 132580
    },
    {
      "epoch": 2.651481822181338,
      "grad_norm": 0.2213461697101593,
      "learning_rate": 5.825300963884335e-06,
      "loss": 0.0821,
      "step": 132590
    },
    {
      "epoch": 2.651681798184218,
      "grad_norm": 0.09108331799507141,
      "learning_rate": 5.821968030503007e-06,
      "loss": 0.069,
      "step": 132600
    },
    {
      "epoch": 2.6518817741870975,
      "grad_norm": 0.05507807806134224,
      "learning_rate": 5.818635097121679e-06,
      "loss": 0.0745,
      "step": 132610
    },
    {
      "epoch": 2.652081750189977,
      "grad_norm": 0.11822719871997833,
      "learning_rate": 5.815302163740351e-06,
      "loss": 0.1061,
      "step": 132620
    },
    {
      "epoch": 2.652281726192857,
      "grad_norm": 0.1099824532866478,
      "learning_rate": 5.811969230359024e-06,
      "loss": 0.0567,
      "step": 132630
    },
    {
      "epoch": 2.6524817021957365,
      "grad_norm": 0.06485725939273834,
      "learning_rate": 5.808636296977696e-06,
      "loss": 0.0568,
      "step": 132640
    },
    {
      "epoch": 2.652681678198616,
      "grad_norm": 0.20320241153240204,
      "learning_rate": 5.8053033635963685e-06,
      "loss": 0.07,
      "step": 132650
    },
    {
      "epoch": 2.652881654201496,
      "grad_norm": 0.1794908344745636,
      "learning_rate": 5.801970430215041e-06,
      "loss": 0.064,
      "step": 132660
    },
    {
      "epoch": 2.6530816302043756,
      "grad_norm": 0.1994112879037857,
      "learning_rate": 5.798637496833714e-06,
      "loss": 0.0731,
      "step": 132670
    },
    {
      "epoch": 2.6532816062072553,
      "grad_norm": 0.10575251281261444,
      "learning_rate": 5.795304563452386e-06,
      "loss": 0.0951,
      "step": 132680
    },
    {
      "epoch": 2.6534815822101345,
      "grad_norm": 0.15949803590774536,
      "learning_rate": 5.791971630071059e-06,
      "loss": 0.092,
      "step": 132690
    },
    {
      "epoch": 2.653681558213014,
      "grad_norm": 0.1423685997724533,
      "learning_rate": 5.788638696689731e-06,
      "loss": 0.0762,
      "step": 132700
    },
    {
      "epoch": 2.653881534215894,
      "grad_norm": 0.09591787308454514,
      "learning_rate": 5.785305763308403e-06,
      "loss": 0.1047,
      "step": 132710
    },
    {
      "epoch": 2.6540815102187736,
      "grad_norm": 0.21895213425159454,
      "learning_rate": 5.781972829927076e-06,
      "loss": 0.0825,
      "step": 132720
    },
    {
      "epoch": 2.6542814862216533,
      "grad_norm": 0.13765496015548706,
      "learning_rate": 5.778639896545748e-06,
      "loss": 0.0783,
      "step": 132730
    },
    {
      "epoch": 2.654481462224533,
      "grad_norm": 0.10823569446802139,
      "learning_rate": 5.7753069631644205e-06,
      "loss": 0.0419,
      "step": 132740
    },
    {
      "epoch": 2.6546814382274126,
      "grad_norm": 0.0999261662364006,
      "learning_rate": 5.771974029783093e-06,
      "loss": 0.0894,
      "step": 132750
    },
    {
      "epoch": 2.6548814142302923,
      "grad_norm": 0.20510618388652802,
      "learning_rate": 5.768641096401766e-06,
      "loss": 0.0888,
      "step": 132760
    },
    {
      "epoch": 2.655081390233172,
      "grad_norm": 0.250808447599411,
      "learning_rate": 5.765308163020438e-06,
      "loss": 0.0695,
      "step": 132770
    },
    {
      "epoch": 2.6552813662360517,
      "grad_norm": 0.1300712674856186,
      "learning_rate": 5.761975229639111e-06,
      "loss": 0.0571,
      "step": 132780
    },
    {
      "epoch": 2.6554813422389314,
      "grad_norm": 0.19325925409793854,
      "learning_rate": 5.758642296257782e-06,
      "loss": 0.067,
      "step": 132790
    },
    {
      "epoch": 2.655681318241811,
      "grad_norm": 0.19367846846580505,
      "learning_rate": 5.755642656214588e-06,
      "loss": 0.0856,
      "step": 132800
    },
    {
      "epoch": 2.6558812942446908,
      "grad_norm": 0.07704195380210876,
      "learning_rate": 5.7523097228332605e-06,
      "loss": 0.0784,
      "step": 132810
    },
    {
      "epoch": 2.6560812702475705,
      "grad_norm": 0.11774928867816925,
      "learning_rate": 5.748976789451933e-06,
      "loss": 0.0488,
      "step": 132820
    },
    {
      "epoch": 2.65628124625045,
      "grad_norm": 0.12812146544456482,
      "learning_rate": 5.745643856070606e-06,
      "loss": 0.0692,
      "step": 132830
    },
    {
      "epoch": 2.65648122225333,
      "grad_norm": 0.133442223072052,
      "learning_rate": 5.742310922689278e-06,
      "loss": 0.1069,
      "step": 132840
    },
    {
      "epoch": 2.6566811982562095,
      "grad_norm": 0.14177894592285156,
      "learning_rate": 5.73897798930795e-06,
      "loss": 0.065,
      "step": 132850
    },
    {
      "epoch": 2.6568811742590888,
      "grad_norm": 0.19410456717014313,
      "learning_rate": 5.735645055926622e-06,
      "loss": 0.0683,
      "step": 132860
    },
    {
      "epoch": 2.6570811502619684,
      "grad_norm": 0.19069962203502655,
      "learning_rate": 5.732312122545295e-06,
      "loss": 0.0811,
      "step": 132870
    },
    {
      "epoch": 2.657281126264848,
      "grad_norm": 0.1072801873087883,
      "learning_rate": 5.728979189163967e-06,
      "loss": 0.0651,
      "step": 132880
    },
    {
      "epoch": 2.657481102267728,
      "grad_norm": 0.10828638076782227,
      "learning_rate": 5.72564625578264e-06,
      "loss": 0.0776,
      "step": 132890
    },
    {
      "epoch": 2.6576810782706075,
      "grad_norm": 0.1903119683265686,
      "learning_rate": 5.722313322401312e-06,
      "loss": 0.0665,
      "step": 132900
    },
    {
      "epoch": 2.657881054273487,
      "grad_norm": 0.07839754968881607,
      "learning_rate": 5.718980389019985e-06,
      "loss": 0.0481,
      "step": 132910
    },
    {
      "epoch": 2.658081030276367,
      "grad_norm": 0.2925278842449188,
      "learning_rate": 5.715647455638657e-06,
      "loss": 0.0927,
      "step": 132920
    },
    {
      "epoch": 2.6582810062792466,
      "grad_norm": 0.1736549735069275,
      "learning_rate": 5.71231452225733e-06,
      "loss": 0.0838,
      "step": 132930
    },
    {
      "epoch": 2.6584809822821263,
      "grad_norm": 0.15018682181835175,
      "learning_rate": 5.708981588876001e-06,
      "loss": 0.0647,
      "step": 132940
    },
    {
      "epoch": 2.658680958285006,
      "grad_norm": 0.10117646306753159,
      "learning_rate": 5.705648655494674e-06,
      "loss": 0.0689,
      "step": 132950
    },
    {
      "epoch": 2.658880934287885,
      "grad_norm": 0.117415651679039,
      "learning_rate": 5.702315722113346e-06,
      "loss": 0.059,
      "step": 132960
    },
    {
      "epoch": 2.659080910290765,
      "grad_norm": 0.2220759242773056,
      "learning_rate": 5.698982788732019e-06,
      "loss": 0.0915,
      "step": 132970
    },
    {
      "epoch": 2.6592808862936446,
      "grad_norm": 0.0757933035492897,
      "learning_rate": 5.695649855350691e-06,
      "loss": 0.08,
      "step": 132980
    },
    {
      "epoch": 2.6594808622965243,
      "grad_norm": 0.23163141310214996,
      "learning_rate": 5.6923169219693635e-06,
      "loss": 0.0723,
      "step": 132990
    },
    {
      "epoch": 2.659680838299404,
      "grad_norm": 0.25659191608428955,
      "learning_rate": 5.6889839885880365e-06,
      "loss": 0.091,
      "step": 133000
    },
    {
      "epoch": 2.6598808143022836,
      "grad_norm": 0.08060715347528458,
      "learning_rate": 5.685651055206709e-06,
      "loss": 0.081,
      "step": 133010
    },
    {
      "epoch": 2.6600807903051633,
      "grad_norm": 0.08931515365839005,
      "learning_rate": 5.682318121825382e-06,
      "loss": 0.0917,
      "step": 133020
    },
    {
      "epoch": 2.660280766308043,
      "grad_norm": 0.09788325428962708,
      "learning_rate": 5.678985188444054e-06,
      "loss": 0.0681,
      "step": 133030
    },
    {
      "epoch": 2.6604807423109227,
      "grad_norm": 0.167459174990654,
      "learning_rate": 5.675652255062726e-06,
      "loss": 0.0774,
      "step": 133040
    },
    {
      "epoch": 2.6606807183138024,
      "grad_norm": 0.0619603730738163,
      "learning_rate": 5.672319321681398e-06,
      "loss": 0.0623,
      "step": 133050
    },
    {
      "epoch": 2.660880694316682,
      "grad_norm": 0.09462420642375946,
      "learning_rate": 5.668986388300071e-06,
      "loss": 0.0547,
      "step": 133060
    },
    {
      "epoch": 2.6610806703195617,
      "grad_norm": 0.14514729380607605,
      "learning_rate": 5.665653454918743e-06,
      "loss": 0.0828,
      "step": 133070
    },
    {
      "epoch": 2.6612806463224414,
      "grad_norm": 0.18152357637882233,
      "learning_rate": 5.6623205215374155e-06,
      "loss": 0.0738,
      "step": 133080
    },
    {
      "epoch": 2.661480622325321,
      "grad_norm": 0.12906616926193237,
      "learning_rate": 5.658987588156088e-06,
      "loss": 0.0863,
      "step": 133090
    },
    {
      "epoch": 2.661680598328201,
      "grad_norm": 0.13410840928554535,
      "learning_rate": 5.655654654774761e-06,
      "loss": 0.0661,
      "step": 133100
    },
    {
      "epoch": 2.6618805743310805,
      "grad_norm": 0.2268390953540802,
      "learning_rate": 5.652321721393433e-06,
      "loss": 0.0833,
      "step": 133110
    },
    {
      "epoch": 2.66208055033396,
      "grad_norm": 0.13163580000400543,
      "learning_rate": 5.648988788012106e-06,
      "loss": 0.0944,
      "step": 133120
    },
    {
      "epoch": 2.6622805263368394,
      "grad_norm": 0.09023065119981766,
      "learning_rate": 5.645655854630778e-06,
      "loss": 0.091,
      "step": 133130
    },
    {
      "epoch": 2.662480502339719,
      "grad_norm": 0.09864117205142975,
      "learning_rate": 5.64232292124945e-06,
      "loss": 0.0626,
      "step": 133140
    },
    {
      "epoch": 2.662680478342599,
      "grad_norm": 0.1266176402568817,
      "learning_rate": 5.638989987868123e-06,
      "loss": 0.0915,
      "step": 133150
    },
    {
      "epoch": 2.6628804543454785,
      "grad_norm": 0.14562951028347015,
      "learning_rate": 5.635657054486795e-06,
      "loss": 0.0597,
      "step": 133160
    },
    {
      "epoch": 2.663080430348358,
      "grad_norm": 0.06989231705665588,
      "learning_rate": 5.632324121105468e-06,
      "loss": 0.0984,
      "step": 133170
    },
    {
      "epoch": 2.663280406351238,
      "grad_norm": 0.2149369716644287,
      "learning_rate": 5.62899118772414e-06,
      "loss": 0.0815,
      "step": 133180
    },
    {
      "epoch": 2.6634803823541175,
      "grad_norm": 0.18720246851444244,
      "learning_rate": 5.625658254342813e-06,
      "loss": 0.1863,
      "step": 133190
    },
    {
      "epoch": 2.6636803583569972,
      "grad_norm": 0.13311393558979034,
      "learning_rate": 5.622325320961485e-06,
      "loss": 0.0877,
      "step": 133200
    },
    {
      "epoch": 2.663880334359877,
      "grad_norm": 0.1646595299243927,
      "learning_rate": 5.61932568091829e-06,
      "loss": 0.0876,
      "step": 133210
    },
    {
      "epoch": 2.6640803103627566,
      "grad_norm": 0.12071798741817474,
      "learning_rate": 5.615992747536962e-06,
      "loss": 0.0645,
      "step": 133220
    },
    {
      "epoch": 2.664280286365636,
      "grad_norm": 0.10759098082780838,
      "learning_rate": 5.612659814155635e-06,
      "loss": 0.0432,
      "step": 133230
    },
    {
      "epoch": 2.6644802623685155,
      "grad_norm": 0.11610633879899979,
      "learning_rate": 5.6093268807743075e-06,
      "loss": 0.0683,
      "step": 133240
    },
    {
      "epoch": 2.6646802383713952,
      "grad_norm": 0.09976080805063248,
      "learning_rate": 5.60599394739298e-06,
      "loss": 0.0708,
      "step": 133250
    },
    {
      "epoch": 2.664880214374275,
      "grad_norm": 0.24931617081165314,
      "learning_rate": 5.602661014011653e-06,
      "loss": 0.0988,
      "step": 133260
    },
    {
      "epoch": 2.6650801903771546,
      "grad_norm": 0.09672952443361282,
      "learning_rate": 5.599328080630325e-06,
      "loss": 0.0851,
      "step": 133270
    },
    {
      "epoch": 2.6652801663800343,
      "grad_norm": 0.1469080001115799,
      "learning_rate": 5.595995147248997e-06,
      "loss": 0.4321,
      "step": 133280
    },
    {
      "epoch": 2.665480142382914,
      "grad_norm": 0.11703149974346161,
      "learning_rate": 5.592662213867669e-06,
      "loss": 0.0898,
      "step": 133290
    },
    {
      "epoch": 2.6656801183857937,
      "grad_norm": 0.14561359584331512,
      "learning_rate": 5.589329280486342e-06,
      "loss": 0.1073,
      "step": 133300
    },
    {
      "epoch": 2.6658800943886733,
      "grad_norm": 0.08923394232988358,
      "learning_rate": 5.585996347105014e-06,
      "loss": 0.0463,
      "step": 133310
    },
    {
      "epoch": 2.666080070391553,
      "grad_norm": 0.11097180843353271,
      "learning_rate": 5.582663413723687e-06,
      "loss": 0.0317,
      "step": 133320
    },
    {
      "epoch": 2.6662800463944327,
      "grad_norm": 0.21286533772945404,
      "learning_rate": 5.5793304803423586e-06,
      "loss": 0.0793,
      "step": 133330
    },
    {
      "epoch": 2.6664800223973124,
      "grad_norm": 0.07196345180273056,
      "learning_rate": 5.5759975469610316e-06,
      "loss": 0.073,
      "step": 133340
    },
    {
      "epoch": 2.666679998400192,
      "grad_norm": 0.0923733338713646,
      "learning_rate": 5.572664613579704e-06,
      "loss": 0.0698,
      "step": 133350
    },
    {
      "epoch": 2.666879974403072,
      "grad_norm": 0.16924814879894257,
      "learning_rate": 5.569331680198377e-06,
      "loss": 0.0512,
      "step": 133360
    },
    {
      "epoch": 2.6670799504059515,
      "grad_norm": 0.17526262998580933,
      "learning_rate": 5.565998746817049e-06,
      "loss": 0.0781,
      "step": 133370
    },
    {
      "epoch": 2.667279926408831,
      "grad_norm": 0.13973501324653625,
      "learning_rate": 5.562665813435721e-06,
      "loss": 0.0713,
      "step": 133380
    },
    {
      "epoch": 2.667479902411711,
      "grad_norm": 0.18502075970172882,
      "learning_rate": 5.559332880054394e-06,
      "loss": 0.1133,
      "step": 133390
    },
    {
      "epoch": 2.66767987841459,
      "grad_norm": 0.07684945315122604,
      "learning_rate": 5.555999946673066e-06,
      "loss": 0.057,
      "step": 133400
    },
    {
      "epoch": 2.6678798544174698,
      "grad_norm": 0.13346794247627258,
      "learning_rate": 5.552667013291739e-06,
      "loss": 0.0596,
      "step": 133410
    },
    {
      "epoch": 2.6680798304203495,
      "grad_norm": 0.21739260852336884,
      "learning_rate": 5.5493340799104105e-06,
      "loss": 0.0568,
      "step": 133420
    },
    {
      "epoch": 2.668279806423229,
      "grad_norm": 0.17875711619853973,
      "learning_rate": 5.5460011465290835e-06,
      "loss": 0.072,
      "step": 133430
    },
    {
      "epoch": 2.668479782426109,
      "grad_norm": 0.09062178432941437,
      "learning_rate": 5.542668213147756e-06,
      "loss": 0.0811,
      "step": 133440
    },
    {
      "epoch": 2.6686797584289885,
      "grad_norm": 0.1432798206806183,
      "learning_rate": 5.539335279766429e-06,
      "loss": 0.0395,
      "step": 133450
    },
    {
      "epoch": 2.668879734431868,
      "grad_norm": 0.09317504614591599,
      "learning_rate": 5.536002346385101e-06,
      "loss": 0.0624,
      "step": 133460
    },
    {
      "epoch": 2.669079710434748,
      "grad_norm": 0.1312374472618103,
      "learning_rate": 5.532669413003773e-06,
      "loss": 0.1124,
      "step": 133470
    },
    {
      "epoch": 2.6692796864376276,
      "grad_norm": 0.14243869483470917,
      "learning_rate": 5.529336479622445e-06,
      "loss": 0.0643,
      "step": 133480
    },
    {
      "epoch": 2.6694796624405073,
      "grad_norm": 0.08432324975728989,
      "learning_rate": 5.526003546241118e-06,
      "loss": 0.0757,
      "step": 133490
    },
    {
      "epoch": 2.669679638443387,
      "grad_norm": 0.18177586793899536,
      "learning_rate": 5.52267061285979e-06,
      "loss": 0.0573,
      "step": 133500
    },
    {
      "epoch": 2.669879614446266,
      "grad_norm": 0.08519794046878815,
      "learning_rate": 5.5193376794784625e-06,
      "loss": 0.0579,
      "step": 133510
    },
    {
      "epoch": 2.670079590449146,
      "grad_norm": 0.19348543882369995,
      "learning_rate": 5.5160047460971355e-06,
      "loss": 0.0781,
      "step": 133520
    },
    {
      "epoch": 2.6702795664520256,
      "grad_norm": 0.24126572906970978,
      "learning_rate": 5.512671812715808e-06,
      "loss": 0.0674,
      "step": 133530
    },
    {
      "epoch": 2.6704795424549053,
      "grad_norm": 0.15226779878139496,
      "learning_rate": 5.509338879334481e-06,
      "loss": 0.0446,
      "step": 133540
    },
    {
      "epoch": 2.670679518457785,
      "grad_norm": 0.055462151765823364,
      "learning_rate": 5.506005945953153e-06,
      "loss": 0.0711,
      "step": 133550
    },
    {
      "epoch": 2.6708794944606646,
      "grad_norm": 0.10827912390232086,
      "learning_rate": 5.502673012571825e-06,
      "loss": 0.064,
      "step": 133560
    },
    {
      "epoch": 2.6710794704635443,
      "grad_norm": 0.1834208071231842,
      "learning_rate": 5.499340079190497e-06,
      "loss": 0.0527,
      "step": 133570
    },
    {
      "epoch": 2.671279446466424,
      "grad_norm": 0.12530557811260223,
      "learning_rate": 5.49600714580917e-06,
      "loss": 0.0577,
      "step": 133580
    },
    {
      "epoch": 2.6714794224693037,
      "grad_norm": 0.12098145484924316,
      "learning_rate": 5.492674212427842e-06,
      "loss": 0.0717,
      "step": 133590
    },
    {
      "epoch": 2.6716793984721834,
      "grad_norm": 0.14326132833957672,
      "learning_rate": 5.489341279046515e-06,
      "loss": 0.0793,
      "step": 133600
    },
    {
      "epoch": 2.671879374475063,
      "grad_norm": 0.2542399764060974,
      "learning_rate": 5.486008345665187e-06,
      "loss": 0.0661,
      "step": 133610
    },
    {
      "epoch": 2.6720793504779428,
      "grad_norm": 0.10111965984106064,
      "learning_rate": 5.48267541228386e-06,
      "loss": 0.0566,
      "step": 133620
    },
    {
      "epoch": 2.6722793264808224,
      "grad_norm": 0.1894943118095398,
      "learning_rate": 5.479342478902532e-06,
      "loss": 0.0586,
      "step": 133630
    },
    {
      "epoch": 2.672479302483702,
      "grad_norm": 0.17066863179206848,
      "learning_rate": 5.476009545521205e-06,
      "loss": 0.0748,
      "step": 133640
    },
    {
      "epoch": 2.672679278486582,
      "grad_norm": 0.10915130376815796,
      "learning_rate": 5.472676612139877e-06,
      "loss": 0.0384,
      "step": 133650
    },
    {
      "epoch": 2.6728792544894615,
      "grad_norm": 0.2375209629535675,
      "learning_rate": 5.469343678758549e-06,
      "loss": 0.1062,
      "step": 133660
    },
    {
      "epoch": 2.673079230492341,
      "grad_norm": 0.25414347648620605,
      "learning_rate": 5.466010745377221e-06,
      "loss": 0.0532,
      "step": 133670
    },
    {
      "epoch": 2.6732792064952204,
      "grad_norm": 0.16378775238990784,
      "learning_rate": 5.462677811995894e-06,
      "loss": 0.0437,
      "step": 133680
    },
    {
      "epoch": 2.6734791824981,
      "grad_norm": 0.14090818166732788,
      "learning_rate": 5.459344878614566e-06,
      "loss": 0.0707,
      "step": 133690
    },
    {
      "epoch": 2.67367915850098,
      "grad_norm": 0.12829962372779846,
      "learning_rate": 5.4560119452332385e-06,
      "loss": 0.0723,
      "step": 133700
    },
    {
      "epoch": 2.6738791345038595,
      "grad_norm": 0.22693440318107605,
      "learning_rate": 5.4526790118519115e-06,
      "loss": 0.0916,
      "step": 133710
    },
    {
      "epoch": 2.674079110506739,
      "grad_norm": 0.08153358101844788,
      "learning_rate": 5.449346078470584e-06,
      "loss": 0.2002,
      "step": 133720
    },
    {
      "epoch": 2.674279086509619,
      "grad_norm": 0.16733916103839874,
      "learning_rate": 5.446013145089257e-06,
      "loss": 0.0921,
      "step": 133730
    },
    {
      "epoch": 2.6744790625124986,
      "grad_norm": 0.18717719614505768,
      "learning_rate": 5.442680211707929e-06,
      "loss": 0.104,
      "step": 133740
    },
    {
      "epoch": 2.6746790385153782,
      "grad_norm": 0.11398152261972427,
      "learning_rate": 5.439347278326601e-06,
      "loss": 0.0604,
      "step": 133750
    },
    {
      "epoch": 2.674879014518258,
      "grad_norm": 0.1939105987548828,
      "learning_rate": 5.436014344945273e-06,
      "loss": 0.1065,
      "step": 133760
    },
    {
      "epoch": 2.6750789905211376,
      "grad_norm": 0.06461595743894577,
      "learning_rate": 5.432681411563946e-06,
      "loss": 0.0456,
      "step": 133770
    },
    {
      "epoch": 2.675278966524017,
      "grad_norm": 0.07071010023355484,
      "learning_rate": 5.429348478182618e-06,
      "loss": 0.0699,
      "step": 133780
    },
    {
      "epoch": 2.6754789425268966,
      "grad_norm": 0.06808412820100784,
      "learning_rate": 5.4260155448012905e-06,
      "loss": 0.0485,
      "step": 133790
    },
    {
      "epoch": 2.6756789185297762,
      "grad_norm": 0.10715805739164352,
      "learning_rate": 5.422682611419963e-06,
      "loss": 0.0774,
      "step": 133800
    },
    {
      "epoch": 2.675878894532656,
      "grad_norm": 0.08554701507091522,
      "learning_rate": 5.419349678038636e-06,
      "loss": 0.0704,
      "step": 133810
    },
    {
      "epoch": 2.6760788705355356,
      "grad_norm": 0.26261669397354126,
      "learning_rate": 5.416016744657308e-06,
      "loss": 0.4417,
      "step": 133820
    },
    {
      "epoch": 2.6762788465384153,
      "grad_norm": 0.17569227516651154,
      "learning_rate": 5.412683811275981e-06,
      "loss": 0.0772,
      "step": 133830
    },
    {
      "epoch": 2.676478822541295,
      "grad_norm": 0.08465593308210373,
      "learning_rate": 5.409350877894653e-06,
      "loss": 0.0673,
      "step": 133840
    },
    {
      "epoch": 2.6766787985441747,
      "grad_norm": 0.12540890276432037,
      "learning_rate": 5.406017944513325e-06,
      "loss": 0.0807,
      "step": 133850
    },
    {
      "epoch": 2.6768787745470544,
      "grad_norm": 0.25591209530830383,
      "learning_rate": 5.402685011131998e-06,
      "loss": 0.0982,
      "step": 133860
    },
    {
      "epoch": 2.677078750549934,
      "grad_norm": 0.12897354364395142,
      "learning_rate": 5.39935207775067e-06,
      "loss": 0.1019,
      "step": 133870
    },
    {
      "epoch": 2.6772787265528137,
      "grad_norm": 0.22434450685977936,
      "learning_rate": 5.396019144369343e-06,
      "loss": 0.0779,
      "step": 133880
    },
    {
      "epoch": 2.6774787025556934,
      "grad_norm": 0.11622054874897003,
      "learning_rate": 5.392686210988015e-06,
      "loss": 0.0697,
      "step": 133890
    },
    {
      "epoch": 2.677678678558573,
      "grad_norm": 0.15561127662658691,
      "learning_rate": 5.389353277606688e-06,
      "loss": 0.0648,
      "step": 133900
    },
    {
      "epoch": 2.677878654561453,
      "grad_norm": 0.23594968020915985,
      "learning_rate": 5.38602034422536e-06,
      "loss": 0.0832,
      "step": 133910
    },
    {
      "epoch": 2.6780786305643325,
      "grad_norm": 0.08213301748037338,
      "learning_rate": 5.382687410844033e-06,
      "loss": 0.0835,
      "step": 133920
    },
    {
      "epoch": 2.678278606567212,
      "grad_norm": 0.062454503029584885,
      "learning_rate": 5.379354477462704e-06,
      "loss": 0.1116,
      "step": 133930
    },
    {
      "epoch": 2.678478582570092,
      "grad_norm": 0.1355273425579071,
      "learning_rate": 5.376021544081377e-06,
      "loss": 0.0826,
      "step": 133940
    },
    {
      "epoch": 2.678678558572971,
      "grad_norm": 0.09760274738073349,
      "learning_rate": 5.372688610700049e-06,
      "loss": 0.0726,
      "step": 133950
    },
    {
      "epoch": 2.678878534575851,
      "grad_norm": 0.20049335062503815,
      "learning_rate": 5.369355677318722e-06,
      "loss": 0.0698,
      "step": 133960
    },
    {
      "epoch": 2.6790785105787305,
      "grad_norm": 0.08713359385728836,
      "learning_rate": 5.366022743937394e-06,
      "loss": 0.0707,
      "step": 133970
    },
    {
      "epoch": 2.67927848658161,
      "grad_norm": 0.06801397353410721,
      "learning_rate": 5.3626898105560666e-06,
      "loss": 0.065,
      "step": 133980
    },
    {
      "epoch": 2.67947846258449,
      "grad_norm": 0.1306878626346588,
      "learning_rate": 5.3593568771747396e-06,
      "loss": 0.0873,
      "step": 133990
    },
    {
      "epoch": 2.6796784385873695,
      "grad_norm": 0.10710678994655609,
      "learning_rate": 5.356023943793412e-06,
      "loss": 0.0749,
      "step": 134000
    },
    {
      "epoch": 2.6798784145902492,
      "grad_norm": 0.13470563292503357,
      "learning_rate": 5.352691010412085e-06,
      "loss": 0.0579,
      "step": 134010
    },
    {
      "epoch": 2.680078390593129,
      "grad_norm": 0.17608748376369476,
      "learning_rate": 5.349358077030756e-06,
      "loss": 0.0648,
      "step": 134020
    },
    {
      "epoch": 2.6802783665960086,
      "grad_norm": 0.11566364020109177,
      "learning_rate": 5.346025143649429e-06,
      "loss": 0.0601,
      "step": 134030
    },
    {
      "epoch": 2.6804783425988883,
      "grad_norm": 0.0907728299498558,
      "learning_rate": 5.342692210268101e-06,
      "loss": 0.0515,
      "step": 134040
    },
    {
      "epoch": 2.6806783186017675,
      "grad_norm": 0.19548536837100983,
      "learning_rate": 5.339359276886774e-06,
      "loss": 0.0677,
      "step": 134050
    },
    {
      "epoch": 2.680878294604647,
      "grad_norm": 0.24238567054271698,
      "learning_rate": 5.336026343505446e-06,
      "loss": 0.0905,
      "step": 134060
    },
    {
      "epoch": 2.681078270607527,
      "grad_norm": 0.1685609370470047,
      "learning_rate": 5.3326934101241185e-06,
      "loss": 0.0674,
      "step": 134070
    },
    {
      "epoch": 2.6812782466104066,
      "grad_norm": 0.23777994513511658,
      "learning_rate": 5.329360476742791e-06,
      "loss": 0.07,
      "step": 134080
    },
    {
      "epoch": 2.6814782226132863,
      "grad_norm": 0.17350850999355316,
      "learning_rate": 5.326027543361464e-06,
      "loss": 0.0421,
      "step": 134090
    },
    {
      "epoch": 2.681678198616166,
      "grad_norm": 0.2698793113231659,
      "learning_rate": 5.322694609980136e-06,
      "loss": 0.0932,
      "step": 134100
    },
    {
      "epoch": 2.6818781746190457,
      "grad_norm": 0.10575290024280548,
      "learning_rate": 5.319361676598809e-06,
      "loss": 0.05,
      "step": 134110
    },
    {
      "epoch": 2.6820781506219253,
      "grad_norm": 0.14305509626865387,
      "learning_rate": 5.316028743217481e-06,
      "loss": 0.0867,
      "step": 134120
    },
    {
      "epoch": 2.682278126624805,
      "grad_norm": 0.24057738482952118,
      "learning_rate": 5.312695809836153e-06,
      "loss": 0.0923,
      "step": 134130
    },
    {
      "epoch": 2.6824781026276847,
      "grad_norm": 0.09257721155881882,
      "learning_rate": 5.309362876454826e-06,
      "loss": 0.0371,
      "step": 134140
    },
    {
      "epoch": 2.6826780786305644,
      "grad_norm": 0.10981995612382889,
      "learning_rate": 5.306029943073498e-06,
      "loss": 0.0431,
      "step": 134150
    },
    {
      "epoch": 2.682878054633444,
      "grad_norm": 0.10931190848350525,
      "learning_rate": 5.3026970096921705e-06,
      "loss": 0.0957,
      "step": 134160
    },
    {
      "epoch": 2.6830780306363238,
      "grad_norm": 0.13895286619663239,
      "learning_rate": 5.299364076310843e-06,
      "loss": 0.0686,
      "step": 134170
    },
    {
      "epoch": 2.6832780066392035,
      "grad_norm": 0.13986271619796753,
      "learning_rate": 5.296031142929516e-06,
      "loss": 0.0589,
      "step": 134180
    },
    {
      "epoch": 2.683477982642083,
      "grad_norm": 0.10732156038284302,
      "learning_rate": 5.292698209548188e-06,
      "loss": 0.1075,
      "step": 134190
    },
    {
      "epoch": 2.683677958644963,
      "grad_norm": 0.09860751032829285,
      "learning_rate": 5.289365276166861e-06,
      "loss": 0.0563,
      "step": 134200
    },
    {
      "epoch": 2.6838779346478425,
      "grad_norm": 0.12589019536972046,
      "learning_rate": 5.286032342785532e-06,
      "loss": 0.0699,
      "step": 134210
    },
    {
      "epoch": 2.6840779106507218,
      "grad_norm": 0.09415806084871292,
      "learning_rate": 5.282699409404205e-06,
      "loss": 0.0383,
      "step": 134220
    },
    {
      "epoch": 2.6842778866536015,
      "grad_norm": 0.28197187185287476,
      "learning_rate": 5.279366476022877e-06,
      "loss": 0.0962,
      "step": 134230
    },
    {
      "epoch": 2.684477862656481,
      "grad_norm": 0.17950452864170074,
      "learning_rate": 5.27603354264155e-06,
      "loss": 0.0795,
      "step": 134240
    },
    {
      "epoch": 2.684677838659361,
      "grad_norm": 0.13395734131336212,
      "learning_rate": 5.272700609260222e-06,
      "loss": 0.0836,
      "step": 134250
    },
    {
      "epoch": 2.6848778146622405,
      "grad_norm": 0.18385589122772217,
      "learning_rate": 5.2693676758788946e-06,
      "loss": 0.0615,
      "step": 134260
    },
    {
      "epoch": 2.68507779066512,
      "grad_norm": 0.12817099690437317,
      "learning_rate": 5.266034742497567e-06,
      "loss": 0.0514,
      "step": 134270
    },
    {
      "epoch": 2.685277766668,
      "grad_norm": 0.1424999088048935,
      "learning_rate": 5.26270180911624e-06,
      "loss": 0.0689,
      "step": 134280
    },
    {
      "epoch": 2.6854777426708796,
      "grad_norm": 0.12643922865390778,
      "learning_rate": 5.259368875734912e-06,
      "loss": 0.0845,
      "step": 134290
    },
    {
      "epoch": 2.6856777186737593,
      "grad_norm": 0.20818091928958893,
      "learning_rate": 5.256035942353584e-06,
      "loss": 0.0876,
      "step": 134300
    },
    {
      "epoch": 2.685877694676639,
      "grad_norm": 0.10421447455883026,
      "learning_rate": 5.252703008972257e-06,
      "loss": 0.0524,
      "step": 134310
    },
    {
      "epoch": 2.686077670679518,
      "grad_norm": 0.11580831557512283,
      "learning_rate": 5.249370075590929e-06,
      "loss": 0.0442,
      "step": 134320
    },
    {
      "epoch": 2.686277646682398,
      "grad_norm": 0.12745460867881775,
      "learning_rate": 5.246037142209602e-06,
      "loss": 0.1095,
      "step": 134330
    },
    {
      "epoch": 2.6864776226852776,
      "grad_norm": 0.2851676046848297,
      "learning_rate": 5.242704208828274e-06,
      "loss": 0.1187,
      "step": 134340
    },
    {
      "epoch": 2.6866775986881573,
      "grad_norm": 0.13242609798908234,
      "learning_rate": 5.2393712754469465e-06,
      "loss": 0.0534,
      "step": 134350
    },
    {
      "epoch": 2.686877574691037,
      "grad_norm": 0.21315480768680573,
      "learning_rate": 5.236038342065619e-06,
      "loss": 0.0548,
      "step": 134360
    },
    {
      "epoch": 2.6870775506939166,
      "grad_norm": 0.11502711474895477,
      "learning_rate": 5.232705408684292e-06,
      "loss": 0.0439,
      "step": 134370
    },
    {
      "epoch": 2.6872775266967963,
      "grad_norm": 0.17170579731464386,
      "learning_rate": 5.229372475302964e-06,
      "loss": 0.0723,
      "step": 134380
    },
    {
      "epoch": 2.687477502699676,
      "grad_norm": 0.09634757786989212,
      "learning_rate": 5.226039541921637e-06,
      "loss": 0.0696,
      "step": 134390
    },
    {
      "epoch": 2.6876774787025557,
      "grad_norm": 0.12758958339691162,
      "learning_rate": 5.222706608540308e-06,
      "loss": 0.1008,
      "step": 134400
    },
    {
      "epoch": 2.6878774547054354,
      "grad_norm": 0.06854606419801712,
      "learning_rate": 5.219373675158981e-06,
      "loss": 0.0883,
      "step": 134410
    },
    {
      "epoch": 2.688077430708315,
      "grad_norm": 0.27665144205093384,
      "learning_rate": 5.216040741777653e-06,
      "loss": 0.1023,
      "step": 134420
    },
    {
      "epoch": 2.6882774067111948,
      "grad_norm": 0.2662392556667328,
      "learning_rate": 5.212707808396326e-06,
      "loss": 0.096,
      "step": 134430
    },
    {
      "epoch": 2.6884773827140744,
      "grad_norm": 0.08251950889825821,
      "learning_rate": 5.2093748750149985e-06,
      "loss": 0.067,
      "step": 134440
    },
    {
      "epoch": 2.688677358716954,
      "grad_norm": 0.09219292551279068,
      "learning_rate": 5.206041941633671e-06,
      "loss": 0.0673,
      "step": 134450
    },
    {
      "epoch": 2.688877334719834,
      "grad_norm": 0.1796780824661255,
      "learning_rate": 5.202709008252344e-06,
      "loss": 0.1058,
      "step": 134460
    },
    {
      "epoch": 2.6890773107227135,
      "grad_norm": 0.14103440940380096,
      "learning_rate": 5.199376074871016e-06,
      "loss": 0.0613,
      "step": 134470
    },
    {
      "epoch": 2.689277286725593,
      "grad_norm": 0.13133226335048676,
      "learning_rate": 5.196043141489689e-06,
      "loss": 0.0954,
      "step": 134480
    },
    {
      "epoch": 2.6894772627284724,
      "grad_norm": 0.12481239438056946,
      "learning_rate": 5.19271020810836e-06,
      "loss": 0.0935,
      "step": 134490
    },
    {
      "epoch": 2.689677238731352,
      "grad_norm": 0.12733180820941925,
      "learning_rate": 5.189377274727033e-06,
      "loss": 0.0478,
      "step": 134500
    },
    {
      "epoch": 2.689877214734232,
      "grad_norm": 0.1816093921661377,
      "learning_rate": 5.186044341345705e-06,
      "loss": 0.0767,
      "step": 134510
    },
    {
      "epoch": 2.6900771907371115,
      "grad_norm": 0.11031284183263779,
      "learning_rate": 5.182711407964378e-06,
      "loss": 0.0817,
      "step": 134520
    },
    {
      "epoch": 2.690277166739991,
      "grad_norm": 0.12915070354938507,
      "learning_rate": 5.17937847458305e-06,
      "loss": 0.0649,
      "step": 134530
    },
    {
      "epoch": 2.690477142742871,
      "grad_norm": 0.1304517537355423,
      "learning_rate": 5.176045541201723e-06,
      "loss": 0.0623,
      "step": 134540
    },
    {
      "epoch": 2.6906771187457506,
      "grad_norm": 0.0691634863615036,
      "learning_rate": 5.172712607820395e-06,
      "loss": 0.0461,
      "step": 134550
    },
    {
      "epoch": 2.6908770947486302,
      "grad_norm": 0.10918722301721573,
      "learning_rate": 5.169379674439068e-06,
      "loss": 0.0799,
      "step": 134560
    },
    {
      "epoch": 2.69107707075151,
      "grad_norm": 0.1685694456100464,
      "learning_rate": 5.16604674105774e-06,
      "loss": 0.0826,
      "step": 134570
    },
    {
      "epoch": 2.6912770467543896,
      "grad_norm": 0.1762247085571289,
      "learning_rate": 5.162713807676412e-06,
      "loss": 0.0624,
      "step": 134580
    },
    {
      "epoch": 2.691477022757269,
      "grad_norm": 0.11901379376649857,
      "learning_rate": 5.159380874295085e-06,
      "loss": 0.1096,
      "step": 134590
    },
    {
      "epoch": 2.6916769987601485,
      "grad_norm": 0.12368140369653702,
      "learning_rate": 5.156047940913757e-06,
      "loss": 0.0712,
      "step": 134600
    },
    {
      "epoch": 2.6918769747630282,
      "grad_norm": 0.11134588718414307,
      "learning_rate": 5.15271500753243e-06,
      "loss": 0.0713,
      "step": 134610
    },
    {
      "epoch": 2.692076950765908,
      "grad_norm": 0.13319049775600433,
      "learning_rate": 5.149382074151102e-06,
      "loss": 0.0824,
      "step": 134620
    },
    {
      "epoch": 2.6922769267687876,
      "grad_norm": 0.14436684548854828,
      "learning_rate": 5.1460491407697745e-06,
      "loss": 0.0487,
      "step": 134630
    },
    {
      "epoch": 2.6924769027716673,
      "grad_norm": 0.20223796367645264,
      "learning_rate": 5.142716207388447e-06,
      "loss": 0.0725,
      "step": 134640
    },
    {
      "epoch": 2.692676878774547,
      "grad_norm": 0.1516837775707245,
      "learning_rate": 5.13938327400712e-06,
      "loss": 0.061,
      "step": 134650
    },
    {
      "epoch": 2.6928768547774267,
      "grad_norm": 0.060795076191425323,
      "learning_rate": 5.136050340625792e-06,
      "loss": 0.0733,
      "step": 134660
    },
    {
      "epoch": 2.6930768307803064,
      "grad_norm": 0.17203541100025177,
      "learning_rate": 5.132717407244464e-06,
      "loss": 0.0506,
      "step": 134670
    },
    {
      "epoch": 2.693276806783186,
      "grad_norm": 0.18427152931690216,
      "learning_rate": 5.129384473863136e-06,
      "loss": 0.0687,
      "step": 134680
    },
    {
      "epoch": 2.6934767827860657,
      "grad_norm": 0.2001509815454483,
      "learning_rate": 5.126051540481809e-06,
      "loss": 0.099,
      "step": 134690
    },
    {
      "epoch": 2.6936767587889454,
      "grad_norm": 0.264726847410202,
      "learning_rate": 5.122718607100481e-06,
      "loss": 0.0595,
      "step": 134700
    },
    {
      "epoch": 2.693876734791825,
      "grad_norm": 0.16802413761615753,
      "learning_rate": 5.119385673719154e-06,
      "loss": 0.0831,
      "step": 134710
    },
    {
      "epoch": 2.694076710794705,
      "grad_norm": 0.1144583597779274,
      "learning_rate": 5.1160527403378265e-06,
      "loss": 0.0664,
      "step": 134720
    },
    {
      "epoch": 2.6942766867975845,
      "grad_norm": 0.10363412648439407,
      "learning_rate": 5.112719806956499e-06,
      "loss": 0.0783,
      "step": 134730
    },
    {
      "epoch": 2.694476662800464,
      "grad_norm": 0.23101596534252167,
      "learning_rate": 5.109386873575172e-06,
      "loss": 0.1252,
      "step": 134740
    },
    {
      "epoch": 2.694676638803344,
      "grad_norm": 0.2139655351638794,
      "learning_rate": 5.106053940193844e-06,
      "loss": 0.1166,
      "step": 134750
    },
    {
      "epoch": 2.694876614806223,
      "grad_norm": 0.11733172088861465,
      "learning_rate": 5.102721006812517e-06,
      "loss": 0.0556,
      "step": 134760
    },
    {
      "epoch": 2.695076590809103,
      "grad_norm": 0.18411751091480255,
      "learning_rate": 5.099388073431188e-06,
      "loss": 0.0748,
      "step": 134770
    },
    {
      "epoch": 2.6952765668119825,
      "grad_norm": 0.22550064325332642,
      "learning_rate": 5.096055140049861e-06,
      "loss": 0.0852,
      "step": 134780
    },
    {
      "epoch": 2.695476542814862,
      "grad_norm": 0.1523156315088272,
      "learning_rate": 5.092722206668533e-06,
      "loss": 0.0715,
      "step": 134790
    },
    {
      "epoch": 2.695676518817742,
      "grad_norm": 0.21266579627990723,
      "learning_rate": 5.089389273287206e-06,
      "loss": 0.0716,
      "step": 134800
    },
    {
      "epoch": 2.6958764948206215,
      "grad_norm": 0.21839500963687897,
      "learning_rate": 5.086056339905878e-06,
      "loss": 0.0605,
      "step": 134810
    },
    {
      "epoch": 2.696076470823501,
      "grad_norm": 0.09752288460731506,
      "learning_rate": 5.082723406524551e-06,
      "loss": 0.0556,
      "step": 134820
    },
    {
      "epoch": 2.696276446826381,
      "grad_norm": 0.12036947906017303,
      "learning_rate": 5.079390473143223e-06,
      "loss": 0.0471,
      "step": 134830
    },
    {
      "epoch": 2.6964764228292606,
      "grad_norm": 0.11458338797092438,
      "learning_rate": 5.076057539761896e-06,
      "loss": 0.0794,
      "step": 134840
    },
    {
      "epoch": 2.6966763988321403,
      "grad_norm": 0.16496983170509338,
      "learning_rate": 5.072724606380568e-06,
      "loss": 0.0851,
      "step": 134850
    },
    {
      "epoch": 2.69687637483502,
      "grad_norm": 0.1728741079568863,
      "learning_rate": 5.06939167299924e-06,
      "loss": 0.0866,
      "step": 134860
    },
    {
      "epoch": 2.697076350837899,
      "grad_norm": 0.05804198235273361,
      "learning_rate": 5.066058739617912e-06,
      "loss": 0.0812,
      "step": 134870
    },
    {
      "epoch": 2.697276326840779,
      "grad_norm": 0.08500910550355911,
      "learning_rate": 5.062725806236585e-06,
      "loss": 0.0677,
      "step": 134880
    },
    {
      "epoch": 2.6974763028436586,
      "grad_norm": 0.16191785037517548,
      "learning_rate": 5.059392872855257e-06,
      "loss": 0.0682,
      "step": 134890
    },
    {
      "epoch": 2.6976762788465383,
      "grad_norm": 0.06041707471013069,
      "learning_rate": 5.0560599394739296e-06,
      "loss": 0.0438,
      "step": 134900
    },
    {
      "epoch": 2.697876254849418,
      "grad_norm": 0.12178240716457367,
      "learning_rate": 5.0527270060926026e-06,
      "loss": 0.0844,
      "step": 134910
    },
    {
      "epoch": 2.6980762308522976,
      "grad_norm": 0.11368770152330399,
      "learning_rate": 5.049394072711275e-06,
      "loss": 0.0531,
      "step": 134920
    },
    {
      "epoch": 2.6982762068551773,
      "grad_norm": 0.07622811943292618,
      "learning_rate": 5.046061139329948e-06,
      "loss": 0.0829,
      "step": 134930
    },
    {
      "epoch": 2.698476182858057,
      "grad_norm": 0.1656351536512375,
      "learning_rate": 5.04272820594862e-06,
      "loss": 0.0735,
      "step": 134940
    },
    {
      "epoch": 2.6986761588609367,
      "grad_norm": 0.07807611674070358,
      "learning_rate": 5.039395272567292e-06,
      "loss": 0.129,
      "step": 134950
    },
    {
      "epoch": 2.6988761348638164,
      "grad_norm": 0.2370767891407013,
      "learning_rate": 5.036062339185964e-06,
      "loss": 0.3379,
      "step": 134960
    },
    {
      "epoch": 2.699076110866696,
      "grad_norm": 0.17611190676689148,
      "learning_rate": 5.032729405804637e-06,
      "loss": 0.072,
      "step": 134970
    },
    {
      "epoch": 2.6992760868695758,
      "grad_norm": 0.20468023419380188,
      "learning_rate": 5.029396472423309e-06,
      "loss": 0.0584,
      "step": 134980
    },
    {
      "epoch": 2.6994760628724555,
      "grad_norm": 0.20414453744888306,
      "learning_rate": 5.026063539041982e-06,
      "loss": 0.084,
      "step": 134990
    },
    {
      "epoch": 2.699676038875335,
      "grad_norm": 0.17064815759658813,
      "learning_rate": 5.022730605660654e-06,
      "loss": 0.0426,
      "step": 135000
    },
    {
      "epoch": 2.699876014878215,
      "grad_norm": 0.19493478536605835,
      "learning_rate": 5.019397672279327e-06,
      "loss": 0.0639,
      "step": 135010
    },
    {
      "epoch": 2.7000759908810945,
      "grad_norm": 0.16074974834918976,
      "learning_rate": 5.016064738897999e-06,
      "loss": 0.0845,
      "step": 135020
    },
    {
      "epoch": 2.700275966883974,
      "grad_norm": 0.08345387876033783,
      "learning_rate": 5.012731805516672e-06,
      "loss": 0.0849,
      "step": 135030
    },
    {
      "epoch": 2.7004759428868534,
      "grad_norm": 0.18119186162948608,
      "learning_rate": 5.009398872135344e-06,
      "loss": 0.0627,
      "step": 135040
    },
    {
      "epoch": 2.700675918889733,
      "grad_norm": 0.1625869870185852,
      "learning_rate": 5.006065938754016e-06,
      "loss": 0.0629,
      "step": 135050
    },
    {
      "epoch": 2.700875894892613,
      "grad_norm": 0.0684807151556015,
      "learning_rate": 5.002733005372689e-06,
      "loss": 0.0527,
      "step": 135060
    },
    {
      "epoch": 2.7010758708954925,
      "grad_norm": 0.10617531836032867,
      "learning_rate": 4.999400071991361e-06,
      "loss": 0.0585,
      "step": 135070
    },
    {
      "epoch": 2.701275846898372,
      "grad_norm": 0.17430947721004486,
      "learning_rate": 4.996067138610034e-06,
      "loss": 0.0819,
      "step": 135080
    },
    {
      "epoch": 2.701475822901252,
      "grad_norm": 0.10077252238988876,
      "learning_rate": 4.992734205228706e-06,
      "loss": 0.0449,
      "step": 135090
    },
    {
      "epoch": 2.7016757989041316,
      "grad_norm": 0.12139284610748291,
      "learning_rate": 4.989401271847379e-06,
      "loss": 0.0781,
      "step": 135100
    },
    {
      "epoch": 2.7018757749070113,
      "grad_norm": 0.26266124844551086,
      "learning_rate": 4.986068338466051e-06,
      "loss": 0.0752,
      "step": 135110
    },
    {
      "epoch": 2.702075750909891,
      "grad_norm": 0.10194705426692963,
      "learning_rate": 4.982735405084724e-06,
      "loss": 0.1301,
      "step": 135120
    },
    {
      "epoch": 2.7022757269127706,
      "grad_norm": 0.07981730997562408,
      "learning_rate": 4.979402471703396e-06,
      "loss": 0.0475,
      "step": 135130
    },
    {
      "epoch": 2.70247570291565,
      "grad_norm": 0.07627525925636292,
      "learning_rate": 4.976069538322068e-06,
      "loss": 0.0996,
      "step": 135140
    },
    {
      "epoch": 2.7026756789185296,
      "grad_norm": 0.13420090079307556,
      "learning_rate": 4.97273660494074e-06,
      "loss": 0.0821,
      "step": 135150
    },
    {
      "epoch": 2.7028756549214092,
      "grad_norm": 0.1046033576130867,
      "learning_rate": 4.969403671559413e-06,
      "loss": 0.0909,
      "step": 135160
    },
    {
      "epoch": 2.703075630924289,
      "grad_norm": 0.1338798552751541,
      "learning_rate": 4.9660707381780854e-06,
      "loss": 0.0535,
      "step": 135170
    },
    {
      "epoch": 2.7032756069271686,
      "grad_norm": 0.1083834245800972,
      "learning_rate": 4.962737804796758e-06,
      "loss": 0.1021,
      "step": 135180
    },
    {
      "epoch": 2.7034755829300483,
      "grad_norm": 0.19428032636642456,
      "learning_rate": 4.959404871415431e-06,
      "loss": 0.0852,
      "step": 135190
    },
    {
      "epoch": 2.703675558932928,
      "grad_norm": 0.1212378591299057,
      "learning_rate": 4.956071938034103e-06,
      "loss": 0.058,
      "step": 135200
    },
    {
      "epoch": 2.7038755349358077,
      "grad_norm": 0.09756889939308167,
      "learning_rate": 4.952739004652776e-06,
      "loss": 0.0651,
      "step": 135210
    },
    {
      "epoch": 2.7040755109386874,
      "grad_norm": 0.14789921045303345,
      "learning_rate": 4.949406071271448e-06,
      "loss": 0.0566,
      "step": 135220
    },
    {
      "epoch": 2.704275486941567,
      "grad_norm": 0.22104908525943756,
      "learning_rate": 4.94607313789012e-06,
      "loss": 0.1004,
      "step": 135230
    },
    {
      "epoch": 2.7044754629444467,
      "grad_norm": 0.16753025352954865,
      "learning_rate": 4.942740204508792e-06,
      "loss": 0.0733,
      "step": 135240
    },
    {
      "epoch": 2.7046754389473264,
      "grad_norm": 0.20459911227226257,
      "learning_rate": 4.939407271127465e-06,
      "loss": 0.1426,
      "step": 135250
    },
    {
      "epoch": 2.704875414950206,
      "grad_norm": 0.0656237006187439,
      "learning_rate": 4.936074337746137e-06,
      "loss": 0.0455,
      "step": 135260
    },
    {
      "epoch": 2.705075390953086,
      "grad_norm": 0.05305727198719978,
      "learning_rate": 4.93274140436481e-06,
      "loss": 0.0804,
      "step": 135270
    },
    {
      "epoch": 2.7052753669559655,
      "grad_norm": 0.08494066447019577,
      "learning_rate": 4.929408470983482e-06,
      "loss": 0.0575,
      "step": 135280
    },
    {
      "epoch": 2.705475342958845,
      "grad_norm": 0.07395070046186447,
      "learning_rate": 4.926075537602155e-06,
      "loss": 0.0803,
      "step": 135290
    },
    {
      "epoch": 2.705675318961725,
      "grad_norm": 0.16058982908725739,
      "learning_rate": 4.922742604220827e-06,
      "loss": 0.0648,
      "step": 135300
    },
    {
      "epoch": 2.705875294964604,
      "grad_norm": 0.17212794721126556,
      "learning_rate": 4.9194096708395e-06,
      "loss": 0.4453,
      "step": 135310
    },
    {
      "epoch": 2.706075270967484,
      "grad_norm": 0.21519608795642853,
      "learning_rate": 4.916076737458172e-06,
      "loss": 0.085,
      "step": 135320
    },
    {
      "epoch": 2.7062752469703635,
      "grad_norm": 0.06038010120391846,
      "learning_rate": 4.912743804076844e-06,
      "loss": 0.0542,
      "step": 135330
    },
    {
      "epoch": 2.706475222973243,
      "grad_norm": 0.09064242988824844,
      "learning_rate": 4.909410870695517e-06,
      "loss": 0.0472,
      "step": 135340
    },
    {
      "epoch": 2.706675198976123,
      "grad_norm": 0.24810151755809784,
      "learning_rate": 4.906077937314189e-06,
      "loss": 0.0972,
      "step": 135350
    },
    {
      "epoch": 2.7068751749790025,
      "grad_norm": 0.2708427608013153,
      "learning_rate": 4.902745003932862e-06,
      "loss": 0.1051,
      "step": 135360
    },
    {
      "epoch": 2.7070751509818822,
      "grad_norm": 0.1616591215133667,
      "learning_rate": 4.899412070551534e-06,
      "loss": 0.0842,
      "step": 135370
    },
    {
      "epoch": 2.707275126984762,
      "grad_norm": 0.06995894014835358,
      "learning_rate": 4.896079137170207e-06,
      "loss": 0.0844,
      "step": 135380
    },
    {
      "epoch": 2.7074751029876416,
      "grad_norm": 0.19528213143348694,
      "learning_rate": 4.892746203788879e-06,
      "loss": 0.087,
      "step": 135390
    },
    {
      "epoch": 2.7076750789905213,
      "grad_norm": 0.1994069367647171,
      "learning_rate": 4.889413270407552e-06,
      "loss": 0.0911,
      "step": 135400
    },
    {
      "epoch": 2.7078750549934005,
      "grad_norm": 0.24148797988891602,
      "learning_rate": 4.886080337026223e-06,
      "loss": 0.0919,
      "step": 135410
    },
    {
      "epoch": 2.70807503099628,
      "grad_norm": 0.24593615531921387,
      "learning_rate": 4.882747403644896e-06,
      "loss": 0.0881,
      "step": 135420
    },
    {
      "epoch": 2.70827500699916,
      "grad_norm": 0.20844534039497375,
      "learning_rate": 4.879414470263568e-06,
      "loss": 0.0578,
      "step": 135430
    },
    {
      "epoch": 2.7084749830020396,
      "grad_norm": 0.12408009171485901,
      "learning_rate": 4.876081536882241e-06,
      "loss": 0.084,
      "step": 135440
    },
    {
      "epoch": 2.7086749590049193,
      "grad_norm": 0.2692137062549591,
      "learning_rate": 4.8727486035009134e-06,
      "loss": 0.0966,
      "step": 135450
    },
    {
      "epoch": 2.708874935007799,
      "grad_norm": 0.14609205722808838,
      "learning_rate": 4.869415670119586e-06,
      "loss": 0.0562,
      "step": 135460
    },
    {
      "epoch": 2.7090749110106787,
      "grad_norm": 0.1774352788925171,
      "learning_rate": 4.866082736738258e-06,
      "loss": 0.0837,
      "step": 135470
    },
    {
      "epoch": 2.7092748870135583,
      "grad_norm": 0.2552923262119293,
      "learning_rate": 4.862749803356931e-06,
      "loss": 0.0761,
      "step": 135480
    },
    {
      "epoch": 2.709474863016438,
      "grad_norm": 0.10388989746570587,
      "learning_rate": 4.859416869975603e-06,
      "loss": 0.0638,
      "step": 135490
    },
    {
      "epoch": 2.7096748390193177,
      "grad_norm": 0.09654294699430466,
      "learning_rate": 4.856083936594276e-06,
      "loss": 0.037,
      "step": 135500
    },
    {
      "epoch": 2.7098748150221974,
      "grad_norm": 0.0849844366312027,
      "learning_rate": 4.852751003212948e-06,
      "loss": 0.0702,
      "step": 135510
    },
    {
      "epoch": 2.710074791025077,
      "grad_norm": 0.24352003633975983,
      "learning_rate": 4.84941806983162e-06,
      "loss": 0.0646,
      "step": 135520
    },
    {
      "epoch": 2.7102747670279568,
      "grad_norm": 0.13820242881774902,
      "learning_rate": 4.846085136450293e-06,
      "loss": 0.0429,
      "step": 135530
    },
    {
      "epoch": 2.7104747430308365,
      "grad_norm": 0.186920166015625,
      "learning_rate": 4.842752203068965e-06,
      "loss": 0.0648,
      "step": 135540
    },
    {
      "epoch": 2.710674719033716,
      "grad_norm": 0.12327183783054352,
      "learning_rate": 4.8394192696876376e-06,
      "loss": 0.0497,
      "step": 135550
    },
    {
      "epoch": 2.710874695036596,
      "grad_norm": 0.09566342085599899,
      "learning_rate": 4.83608633630631e-06,
      "loss": 0.0601,
      "step": 135560
    },
    {
      "epoch": 2.7110746710394755,
      "grad_norm": 0.09457704424858093,
      "learning_rate": 4.832753402924983e-06,
      "loss": 0.0621,
      "step": 135570
    },
    {
      "epoch": 2.7112746470423548,
      "grad_norm": 0.21324922144412994,
      "learning_rate": 4.829420469543655e-06,
      "loss": 0.0592,
      "step": 135580
    },
    {
      "epoch": 2.7114746230452345,
      "grad_norm": 0.12649130821228027,
      "learning_rate": 4.826087536162328e-06,
      "loss": 0.0442,
      "step": 135590
    },
    {
      "epoch": 2.711674599048114,
      "grad_norm": 0.06430214643478394,
      "learning_rate": 4.822754602780999e-06,
      "loss": 0.0696,
      "step": 135600
    },
    {
      "epoch": 2.711874575050994,
      "grad_norm": 0.12128044664859772,
      "learning_rate": 4.819421669399672e-06,
      "loss": 0.0784,
      "step": 135610
    },
    {
      "epoch": 2.7120745510538735,
      "grad_norm": 0.07435937225818634,
      "learning_rate": 4.816088736018344e-06,
      "loss": 0.0382,
      "step": 135620
    },
    {
      "epoch": 2.712274527056753,
      "grad_norm": 0.1845090389251709,
      "learning_rate": 4.812755802637017e-06,
      "loss": 0.054,
      "step": 135630
    },
    {
      "epoch": 2.712474503059633,
      "grad_norm": 0.08161712437868118,
      "learning_rate": 4.8094228692556895e-06,
      "loss": 0.05,
      "step": 135640
    },
    {
      "epoch": 2.7126744790625126,
      "grad_norm": 0.11096522957086563,
      "learning_rate": 4.806089935874362e-06,
      "loss": 0.1032,
      "step": 135650
    },
    {
      "epoch": 2.7128744550653923,
      "grad_norm": 0.11326565593481064,
      "learning_rate": 4.802757002493035e-06,
      "loss": 0.0434,
      "step": 135660
    },
    {
      "epoch": 2.713074431068272,
      "grad_norm": 0.06073356047272682,
      "learning_rate": 4.799424069111707e-06,
      "loss": 0.0518,
      "step": 135670
    },
    {
      "epoch": 2.713274407071151,
      "grad_norm": 0.04911009594798088,
      "learning_rate": 4.79609113573038e-06,
      "loss": 0.0718,
      "step": 135680
    },
    {
      "epoch": 2.713474383074031,
      "grad_norm": 0.19071662425994873,
      "learning_rate": 4.792758202349051e-06,
      "loss": 0.0507,
      "step": 135690
    },
    {
      "epoch": 2.7136743590769106,
      "grad_norm": 0.10789850354194641,
      "learning_rate": 4.789425268967724e-06,
      "loss": 0.0284,
      "step": 135700
    },
    {
      "epoch": 2.7138743350797903,
      "grad_norm": 0.10476405173540115,
      "learning_rate": 4.786092335586396e-06,
      "loss": 0.0864,
      "step": 135710
    },
    {
      "epoch": 2.71407431108267,
      "grad_norm": 0.10810845345258713,
      "learning_rate": 4.782759402205069e-06,
      "loss": 0.0509,
      "step": 135720
    },
    {
      "epoch": 2.7142742870855496,
      "grad_norm": 0.08616474270820618,
      "learning_rate": 4.7794264688237415e-06,
      "loss": 0.0785,
      "step": 135730
    },
    {
      "epoch": 2.7144742630884293,
      "grad_norm": 0.1060665100812912,
      "learning_rate": 4.776093535442414e-06,
      "loss": 0.0625,
      "step": 135740
    },
    {
      "epoch": 2.714674239091309,
      "grad_norm": 0.08012862503528595,
      "learning_rate": 4.772760602061086e-06,
      "loss": 0.0567,
      "step": 135750
    },
    {
      "epoch": 2.7148742150941887,
      "grad_norm": 0.1702517867088318,
      "learning_rate": 4.769427668679759e-06,
      "loss": 0.068,
      "step": 135760
    },
    {
      "epoch": 2.7150741910970684,
      "grad_norm": 0.1323527842760086,
      "learning_rate": 4.766094735298431e-06,
      "loss": 0.0639,
      "step": 135770
    },
    {
      "epoch": 2.715274167099948,
      "grad_norm": 0.17826251685619354,
      "learning_rate": 4.762761801917103e-06,
      "loss": 0.072,
      "step": 135780
    },
    {
      "epoch": 2.7154741431028278,
      "grad_norm": 0.07754480838775635,
      "learning_rate": 4.759428868535776e-06,
      "loss": 0.0617,
      "step": 135790
    },
    {
      "epoch": 2.7156741191057074,
      "grad_norm": 0.12236552685499191,
      "learning_rate": 4.756095935154448e-06,
      "loss": 0.0817,
      "step": 135800
    },
    {
      "epoch": 2.715874095108587,
      "grad_norm": 0.1732383817434311,
      "learning_rate": 4.752763001773121e-06,
      "loss": 0.3173,
      "step": 135810
    },
    {
      "epoch": 2.716074071111467,
      "grad_norm": 0.17859072983264923,
      "learning_rate": 4.749430068391793e-06,
      "loss": 0.043,
      "step": 135820
    },
    {
      "epoch": 2.7162740471143465,
      "grad_norm": 0.09887968748807907,
      "learning_rate": 4.7460971350104656e-06,
      "loss": 0.07,
      "step": 135830
    },
    {
      "epoch": 2.716474023117226,
      "grad_norm": 0.09874311089515686,
      "learning_rate": 4.742764201629138e-06,
      "loss": 0.085,
      "step": 135840
    },
    {
      "epoch": 2.7166739991201054,
      "grad_norm": 0.2550368905067444,
      "learning_rate": 4.739431268247811e-06,
      "loss": 0.104,
      "step": 135850
    },
    {
      "epoch": 2.716873975122985,
      "grad_norm": 0.06549438089132309,
      "learning_rate": 4.736098334866483e-06,
      "loss": 0.0609,
      "step": 135860
    },
    {
      "epoch": 2.717073951125865,
      "grad_norm": 0.21265169978141785,
      "learning_rate": 4.732765401485156e-06,
      "loss": 0.0666,
      "step": 135870
    },
    {
      "epoch": 2.7172739271287445,
      "grad_norm": 0.23664569854736328,
      "learning_rate": 4.729432468103827e-06,
      "loss": 0.0725,
      "step": 135880
    },
    {
      "epoch": 2.717473903131624,
      "grad_norm": 0.10704760253429413,
      "learning_rate": 4.7260995347225e-06,
      "loss": 0.0558,
      "step": 135890
    },
    {
      "epoch": 2.717673879134504,
      "grad_norm": 0.2011263370513916,
      "learning_rate": 4.722766601341172e-06,
      "loss": 0.0922,
      "step": 135900
    },
    {
      "epoch": 2.7178738551373836,
      "grad_norm": 0.12980782985687256,
      "learning_rate": 4.719433667959845e-06,
      "loss": 0.0789,
      "step": 135910
    },
    {
      "epoch": 2.7180738311402632,
      "grad_norm": 0.12046261131763458,
      "learning_rate": 4.7161007345785175e-06,
      "loss": 0.0496,
      "step": 135920
    },
    {
      "epoch": 2.718273807143143,
      "grad_norm": 0.0940760150551796,
      "learning_rate": 4.71276780119719e-06,
      "loss": 0.0815,
      "step": 135930
    },
    {
      "epoch": 2.7184737831460226,
      "grad_norm": 0.13271600008010864,
      "learning_rate": 4.709434867815863e-06,
      "loss": 0.1039,
      "step": 135940
    },
    {
      "epoch": 2.718673759148902,
      "grad_norm": 0.10337645560503006,
      "learning_rate": 4.706101934434535e-06,
      "loss": 0.0805,
      "step": 135950
    },
    {
      "epoch": 2.7188737351517815,
      "grad_norm": 0.22045263648033142,
      "learning_rate": 4.702769001053208e-06,
      "loss": 0.0828,
      "step": 135960
    },
    {
      "epoch": 2.7190737111546612,
      "grad_norm": 0.09418413788080215,
      "learning_rate": 4.699436067671879e-06,
      "loss": 0.0521,
      "step": 135970
    },
    {
      "epoch": 2.719273687157541,
      "grad_norm": 0.21721316874027252,
      "learning_rate": 4.696103134290552e-06,
      "loss": 0.0717,
      "step": 135980
    },
    {
      "epoch": 2.7194736631604206,
      "grad_norm": 0.2236548364162445,
      "learning_rate": 4.692770200909224e-06,
      "loss": 0.0844,
      "step": 135990
    },
    {
      "epoch": 2.7196736391633003,
      "grad_norm": 0.09968449175357819,
      "learning_rate": 4.689437267527897e-06,
      "loss": 0.0509,
      "step": 136000
    },
    {
      "epoch": 2.71987361516618,
      "grad_norm": 0.1838584840297699,
      "learning_rate": 4.6861043341465695e-06,
      "loss": 0.0588,
      "step": 136010
    },
    {
      "epoch": 2.7200735911690597,
      "grad_norm": 0.18861955404281616,
      "learning_rate": 4.682771400765242e-06,
      "loss": 0.0433,
      "step": 136020
    },
    {
      "epoch": 2.7202735671719394,
      "grad_norm": 0.21654778718948364,
      "learning_rate": 4.679438467383914e-06,
      "loss": 0.0859,
      "step": 136030
    },
    {
      "epoch": 2.720473543174819,
      "grad_norm": 0.20926854014396667,
      "learning_rate": 4.676105534002587e-06,
      "loss": 0.0441,
      "step": 136040
    },
    {
      "epoch": 2.7206735191776987,
      "grad_norm": 0.08771651238203049,
      "learning_rate": 4.672772600621259e-06,
      "loss": 0.0893,
      "step": 136050
    },
    {
      "epoch": 2.7208734951805784,
      "grad_norm": 0.16191446781158447,
      "learning_rate": 4.669439667239931e-06,
      "loss": 0.0798,
      "step": 136060
    },
    {
      "epoch": 2.721073471183458,
      "grad_norm": 0.13430823385715485,
      "learning_rate": 4.666106733858604e-06,
      "loss": 0.0658,
      "step": 136070
    },
    {
      "epoch": 2.721273447186338,
      "grad_norm": 0.14576241374015808,
      "learning_rate": 4.662773800477276e-06,
      "loss": 0.0522,
      "step": 136080
    },
    {
      "epoch": 2.7214734231892175,
      "grad_norm": 0.15565800666809082,
      "learning_rate": 4.6594408670959484e-06,
      "loss": 0.0363,
      "step": 136090
    },
    {
      "epoch": 2.721673399192097,
      "grad_norm": 0.07684087753295898,
      "learning_rate": 4.6561079337146214e-06,
      "loss": 0.0604,
      "step": 136100
    },
    {
      "epoch": 2.721873375194977,
      "grad_norm": 0.14051812887191772,
      "learning_rate": 4.652775000333294e-06,
      "loss": 0.1187,
      "step": 136110
    },
    {
      "epoch": 2.722073351197856,
      "grad_norm": 0.08752719312906265,
      "learning_rate": 4.649442066951966e-06,
      "loss": 0.0596,
      "step": 136120
    },
    {
      "epoch": 2.722273327200736,
      "grad_norm": 0.11014450341463089,
      "learning_rate": 4.646109133570639e-06,
      "loss": 0.0967,
      "step": 136130
    },
    {
      "epoch": 2.7224733032036155,
      "grad_norm": 0.08798689395189285,
      "learning_rate": 4.642776200189311e-06,
      "loss": 0.0668,
      "step": 136140
    },
    {
      "epoch": 2.722673279206495,
      "grad_norm": 0.12279387563467026,
      "learning_rate": 4.639443266807984e-06,
      "loss": 0.0595,
      "step": 136150
    },
    {
      "epoch": 2.722873255209375,
      "grad_norm": 0.1278405785560608,
      "learning_rate": 4.636110333426655e-06,
      "loss": 0.0821,
      "step": 136160
    },
    {
      "epoch": 2.7230732312122545,
      "grad_norm": 0.13639989495277405,
      "learning_rate": 4.632777400045328e-06,
      "loss": 0.0543,
      "step": 136170
    },
    {
      "epoch": 2.723273207215134,
      "grad_norm": 0.1734822690486908,
      "learning_rate": 4.629444466664e-06,
      "loss": 0.0671,
      "step": 136180
    },
    {
      "epoch": 2.723473183218014,
      "grad_norm": 0.23882582783699036,
      "learning_rate": 4.626111533282673e-06,
      "loss": 0.068,
      "step": 136190
    },
    {
      "epoch": 2.7236731592208936,
      "grad_norm": 0.08102572709321976,
      "learning_rate": 4.622778599901345e-06,
      "loss": 0.0595,
      "step": 136200
    },
    {
      "epoch": 2.7238731352237733,
      "grad_norm": 0.08004967123270035,
      "learning_rate": 4.619445666520018e-06,
      "loss": 0.0829,
      "step": 136210
    },
    {
      "epoch": 2.724073111226653,
      "grad_norm": 0.11445178836584091,
      "learning_rate": 4.61611273313869e-06,
      "loss": 0.0691,
      "step": 136220
    },
    {
      "epoch": 2.724273087229532,
      "grad_norm": 0.12841424345970154,
      "learning_rate": 4.612779799757363e-06,
      "loss": 0.0599,
      "step": 136230
    },
    {
      "epoch": 2.724473063232412,
      "grad_norm": 0.1084832027554512,
      "learning_rate": 4.609446866376035e-06,
      "loss": 0.0874,
      "step": 136240
    },
    {
      "epoch": 2.7246730392352916,
      "grad_norm": 0.14303413033485413,
      "learning_rate": 4.606113932994707e-06,
      "loss": 0.0854,
      "step": 136250
    },
    {
      "epoch": 2.7248730152381713,
      "grad_norm": 0.22641977667808533,
      "learning_rate": 4.60278099961338e-06,
      "loss": 0.0724,
      "step": 136260
    },
    {
      "epoch": 2.725072991241051,
      "grad_norm": 0.12896192073822021,
      "learning_rate": 4.599448066232052e-06,
      "loss": 0.0533,
      "step": 136270
    },
    {
      "epoch": 2.7252729672439306,
      "grad_norm": 0.09356801211833954,
      "learning_rate": 4.596115132850725e-06,
      "loss": 0.0616,
      "step": 136280
    },
    {
      "epoch": 2.7254729432468103,
      "grad_norm": 0.21217116713523865,
      "learning_rate": 4.592782199469397e-06,
      "loss": 0.1036,
      "step": 136290
    },
    {
      "epoch": 2.72567291924969,
      "grad_norm": 0.14510497450828552,
      "learning_rate": 4.58944926608807e-06,
      "loss": 0.0482,
      "step": 136300
    },
    {
      "epoch": 2.7258728952525697,
      "grad_norm": 0.10679363459348679,
      "learning_rate": 4.586116332706742e-06,
      "loss": 0.0596,
      "step": 136310
    },
    {
      "epoch": 2.7260728712554494,
      "grad_norm": 0.08522651344537735,
      "learning_rate": 4.582783399325415e-06,
      "loss": 0.069,
      "step": 136320
    },
    {
      "epoch": 2.726272847258329,
      "grad_norm": 0.2291041761636734,
      "learning_rate": 4.579450465944087e-06,
      "loss": 0.1059,
      "step": 136330
    },
    {
      "epoch": 2.7264728232612088,
      "grad_norm": 0.21475175023078918,
      "learning_rate": 4.576117532562759e-06,
      "loss": 0.0624,
      "step": 136340
    },
    {
      "epoch": 2.7266727992640885,
      "grad_norm": 0.1764983832836151,
      "learning_rate": 4.572784599181431e-06,
      "loss": 0.0706,
      "step": 136350
    },
    {
      "epoch": 2.726872775266968,
      "grad_norm": 0.1653754711151123,
      "learning_rate": 4.569451665800104e-06,
      "loss": 0.0555,
      "step": 136360
    },
    {
      "epoch": 2.727072751269848,
      "grad_norm": 0.13619345426559448,
      "learning_rate": 4.5661187324187765e-06,
      "loss": 0.0727,
      "step": 136370
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.21986381709575653,
      "learning_rate": 4.5627857990374495e-06,
      "loss": 0.0583,
      "step": 136380
    },
    {
      "epoch": 2.727472703275607,
      "grad_norm": 0.13671670854091644,
      "learning_rate": 4.559452865656122e-06,
      "loss": 0.0615,
      "step": 136390
    },
    {
      "epoch": 2.7276726792784864,
      "grad_norm": 0.09833160042762756,
      "learning_rate": 4.556119932274794e-06,
      "loss": 0.1061,
      "step": 136400
    },
    {
      "epoch": 2.727872655281366,
      "grad_norm": 0.08648377656936646,
      "learning_rate": 4.552786998893467e-06,
      "loss": 0.0782,
      "step": 136410
    },
    {
      "epoch": 2.728072631284246,
      "grad_norm": 0.07338184863328934,
      "learning_rate": 4.549454065512139e-06,
      "loss": 0.0819,
      "step": 136420
    },
    {
      "epoch": 2.7282726072871255,
      "grad_norm": 0.25515687465667725,
      "learning_rate": 4.546121132130811e-06,
      "loss": 0.0625,
      "step": 136430
    },
    {
      "epoch": 2.728472583290005,
      "grad_norm": 0.08262241631746292,
      "learning_rate": 4.542788198749483e-06,
      "loss": 0.053,
      "step": 136440
    },
    {
      "epoch": 2.728672559292885,
      "grad_norm": 0.10137320309877396,
      "learning_rate": 4.539455265368156e-06,
      "loss": 0.0693,
      "step": 136450
    },
    {
      "epoch": 2.7288725352957646,
      "grad_norm": 0.11476657539606094,
      "learning_rate": 4.536122331986828e-06,
      "loss": 0.1113,
      "step": 136460
    },
    {
      "epoch": 2.7290725112986443,
      "grad_norm": 0.11026699095964432,
      "learning_rate": 4.532789398605501e-06,
      "loss": 0.076,
      "step": 136470
    },
    {
      "epoch": 2.729272487301524,
      "grad_norm": 0.22061793506145477,
      "learning_rate": 4.529456465224173e-06,
      "loss": 0.0587,
      "step": 136480
    },
    {
      "epoch": 2.7294724633044036,
      "grad_norm": 0.071009062230587,
      "learning_rate": 4.526123531842846e-06,
      "loss": 0.0657,
      "step": 136490
    },
    {
      "epoch": 2.729672439307283,
      "grad_norm": 0.1699218451976776,
      "learning_rate": 4.522790598461518e-06,
      "loss": 0.0576,
      "step": 136500
    },
    {
      "epoch": 2.7298724153101626,
      "grad_norm": 0.1086026206612587,
      "learning_rate": 4.519457665080191e-06,
      "loss": 0.0791,
      "step": 136510
    },
    {
      "epoch": 2.7300723913130422,
      "grad_norm": 0.14501507580280304,
      "learning_rate": 4.516124731698863e-06,
      "loss": 0.0821,
      "step": 136520
    },
    {
      "epoch": 2.730272367315922,
      "grad_norm": 0.10335078835487366,
      "learning_rate": 4.512791798317535e-06,
      "loss": 0.0719,
      "step": 136530
    },
    {
      "epoch": 2.7304723433188016,
      "grad_norm": 0.23931095004081726,
      "learning_rate": 4.509458864936208e-06,
      "loss": 0.0855,
      "step": 136540
    },
    {
      "epoch": 2.7306723193216813,
      "grad_norm": 0.19782370328903198,
      "learning_rate": 4.50612593155488e-06,
      "loss": 0.0616,
      "step": 136550
    },
    {
      "epoch": 2.730872295324561,
      "grad_norm": 0.1216641440987587,
      "learning_rate": 4.502792998173553e-06,
      "loss": 0.0667,
      "step": 136560
    },
    {
      "epoch": 2.7310722713274407,
      "grad_norm": 0.0583043210208416,
      "learning_rate": 4.499460064792225e-06,
      "loss": 0.0641,
      "step": 136570
    },
    {
      "epoch": 2.7312722473303204,
      "grad_norm": 0.14300286769866943,
      "learning_rate": 4.496127131410898e-06,
      "loss": 0.0546,
      "step": 136580
    },
    {
      "epoch": 2.7314722233332,
      "grad_norm": 0.20683470368385315,
      "learning_rate": 4.49279419802957e-06,
      "loss": 0.0652,
      "step": 136590
    },
    {
      "epoch": 2.7316721993360797,
      "grad_norm": 0.08740737289190292,
      "learning_rate": 4.489461264648243e-06,
      "loss": 0.032,
      "step": 136600
    },
    {
      "epoch": 2.7318721753389594,
      "grad_norm": 0.25416672229766846,
      "learning_rate": 4.486128331266915e-06,
      "loss": 0.0643,
      "step": 136610
    },
    {
      "epoch": 2.732072151341839,
      "grad_norm": 0.21874096989631653,
      "learning_rate": 4.482795397885587e-06,
      "loss": 0.0837,
      "step": 136620
    },
    {
      "epoch": 2.732272127344719,
      "grad_norm": 0.2277923971414566,
      "learning_rate": 4.479462464504259e-06,
      "loss": 0.0776,
      "step": 136630
    },
    {
      "epoch": 2.7324721033475985,
      "grad_norm": 0.20602452754974365,
      "learning_rate": 4.476129531122932e-06,
      "loss": 0.0549,
      "step": 136640
    },
    {
      "epoch": 2.732672079350478,
      "grad_norm": 0.1301846206188202,
      "learning_rate": 4.4727965977416045e-06,
      "loss": 0.1013,
      "step": 136650
    },
    {
      "epoch": 2.732872055353358,
      "grad_norm": 0.1306537538766861,
      "learning_rate": 4.469463664360277e-06,
      "loss": 0.0872,
      "step": 136660
    },
    {
      "epoch": 2.733072031356237,
      "grad_norm": 0.17536234855651855,
      "learning_rate": 4.46613073097895e-06,
      "loss": 0.0623,
      "step": 136670
    },
    {
      "epoch": 2.733272007359117,
      "grad_norm": 0.24019698798656464,
      "learning_rate": 4.462797797597622e-06,
      "loss": 0.0765,
      "step": 136680
    },
    {
      "epoch": 2.7334719833619965,
      "grad_norm": 0.14473186433315277,
      "learning_rate": 4.459464864216294e-06,
      "loss": 0.0679,
      "step": 136690
    },
    {
      "epoch": 2.733671959364876,
      "grad_norm": 0.09416350722312927,
      "learning_rate": 4.456131930834967e-06,
      "loss": 0.0706,
      "step": 136700
    },
    {
      "epoch": 2.733871935367756,
      "grad_norm": 0.13341212272644043,
      "learning_rate": 4.452798997453639e-06,
      "loss": 0.1106,
      "step": 136710
    },
    {
      "epoch": 2.7340719113706355,
      "grad_norm": 0.16607815027236938,
      "learning_rate": 4.449466064072311e-06,
      "loss": 0.0716,
      "step": 136720
    },
    {
      "epoch": 2.7342718873735152,
      "grad_norm": 0.205155149102211,
      "learning_rate": 4.446133130690984e-06,
      "loss": 0.0672,
      "step": 136730
    },
    {
      "epoch": 2.734471863376395,
      "grad_norm": 0.24340702593326569,
      "learning_rate": 4.4428001973096564e-06,
      "loss": 0.0866,
      "step": 136740
    },
    {
      "epoch": 2.7346718393792746,
      "grad_norm": 0.2438403218984604,
      "learning_rate": 4.4394672639283294e-06,
      "loss": 0.0854,
      "step": 136750
    },
    {
      "epoch": 2.7348718153821543,
      "grad_norm": 0.1116936132311821,
      "learning_rate": 4.436134330547001e-06,
      "loss": 0.0858,
      "step": 136760
    },
    {
      "epoch": 2.7350717913850335,
      "grad_norm": 0.10328245162963867,
      "learning_rate": 4.432801397165674e-06,
      "loss": 0.0839,
      "step": 136770
    },
    {
      "epoch": 2.7352717673879132,
      "grad_norm": 0.13087789714336395,
      "learning_rate": 4.429468463784346e-06,
      "loss": 0.0594,
      "step": 136780
    },
    {
      "epoch": 2.735471743390793,
      "grad_norm": 0.08828701078891754,
      "learning_rate": 4.426135530403019e-06,
      "loss": 0.0521,
      "step": 136790
    },
    {
      "epoch": 2.7356717193936726,
      "grad_norm": 0.23552660644054413,
      "learning_rate": 4.42280259702169e-06,
      "loss": 0.0891,
      "step": 136800
    },
    {
      "epoch": 2.7358716953965523,
      "grad_norm": 0.15331876277923584,
      "learning_rate": 4.419469663640363e-06,
      "loss": 0.0673,
      "step": 136810
    },
    {
      "epoch": 2.736071671399432,
      "grad_norm": 0.21693043410778046,
      "learning_rate": 4.416136730259035e-06,
      "loss": 0.0947,
      "step": 136820
    },
    {
      "epoch": 2.7362716474023117,
      "grad_norm": 0.17240537703037262,
      "learning_rate": 4.412803796877708e-06,
      "loss": 0.0744,
      "step": 136830
    },
    {
      "epoch": 2.7364716234051913,
      "grad_norm": 0.09220671653747559,
      "learning_rate": 4.4094708634963805e-06,
      "loss": 0.0809,
      "step": 136840
    },
    {
      "epoch": 2.736671599408071,
      "grad_norm": 0.07864237576723099,
      "learning_rate": 4.406137930115053e-06,
      "loss": 0.0585,
      "step": 136850
    },
    {
      "epoch": 2.7368715754109507,
      "grad_norm": 0.10365234315395355,
      "learning_rate": 4.402804996733726e-06,
      "loss": 0.0508,
      "step": 136860
    },
    {
      "epoch": 2.7370715514138304,
      "grad_norm": 0.09294615685939789,
      "learning_rate": 4.399472063352398e-06,
      "loss": 0.0576,
      "step": 136870
    },
    {
      "epoch": 2.73727152741671,
      "grad_norm": 0.1981641799211502,
      "learning_rate": 4.396139129971071e-06,
      "loss": 0.0877,
      "step": 136880
    },
    {
      "epoch": 2.73747150341959,
      "grad_norm": 0.16137060523033142,
      "learning_rate": 4.392806196589743e-06,
      "loss": 0.0709,
      "step": 136890
    },
    {
      "epoch": 2.7376714794224695,
      "grad_norm": 0.21108393371105194,
      "learning_rate": 4.389473263208415e-06,
      "loss": 0.0965,
      "step": 136900
    },
    {
      "epoch": 2.737871455425349,
      "grad_norm": 0.22684668004512787,
      "learning_rate": 4.386140329827087e-06,
      "loss": 0.0687,
      "step": 136910
    },
    {
      "epoch": 2.738071431428229,
      "grad_norm": 0.06392298638820648,
      "learning_rate": 4.38280739644576e-06,
      "loss": 0.0674,
      "step": 136920
    },
    {
      "epoch": 2.7382714074311085,
      "grad_norm": 0.12105999886989594,
      "learning_rate": 4.3794744630644325e-06,
      "loss": 0.0358,
      "step": 136930
    },
    {
      "epoch": 2.7384713834339878,
      "grad_norm": 0.1965811401605606,
      "learning_rate": 4.376141529683105e-06,
      "loss": 0.1091,
      "step": 136940
    },
    {
      "epoch": 2.7386713594368675,
      "grad_norm": 0.19972841441631317,
      "learning_rate": 4.372808596301777e-06,
      "loss": 0.1249,
      "step": 136950
    },
    {
      "epoch": 2.738871335439747,
      "grad_norm": 0.07890182733535767,
      "learning_rate": 4.36947566292045e-06,
      "loss": 0.0918,
      "step": 136960
    },
    {
      "epoch": 2.739071311442627,
      "grad_norm": 0.14229419827461243,
      "learning_rate": 4.366142729539122e-06,
      "loss": 0.0631,
      "step": 136970
    },
    {
      "epoch": 2.7392712874455065,
      "grad_norm": 0.12335342913866043,
      "learning_rate": 4.362809796157795e-06,
      "loss": 0.1259,
      "step": 136980
    },
    {
      "epoch": 2.739471263448386,
      "grad_norm": 0.0890851765871048,
      "learning_rate": 4.359476862776467e-06,
      "loss": 0.0971,
      "step": 136990
    },
    {
      "epoch": 2.739671239451266,
      "grad_norm": 0.23340702056884766,
      "learning_rate": 4.356143929395139e-06,
      "loss": 0.0831,
      "step": 137000
    },
    {
      "epoch": 2.7398712154541456,
      "grad_norm": 0.17750702798366547,
      "learning_rate": 4.352810996013812e-06,
      "loss": 0.0551,
      "step": 137010
    },
    {
      "epoch": 2.7400711914570253,
      "grad_norm": 0.06992453336715698,
      "learning_rate": 4.3494780626324844e-06,
      "loss": 0.037,
      "step": 137020
    },
    {
      "epoch": 2.740271167459905,
      "grad_norm": 0.11702316254377365,
      "learning_rate": 4.3461451292511574e-06,
      "loss": 0.0698,
      "step": 137030
    },
    {
      "epoch": 2.740471143462784,
      "grad_norm": 0.15048299729824066,
      "learning_rate": 4.342812195869829e-06,
      "loss": 0.2406,
      "step": 137040
    },
    {
      "epoch": 2.740671119465664,
      "grad_norm": 0.14786027371883392,
      "learning_rate": 4.339479262488502e-06,
      "loss": 0.0561,
      "step": 137050
    },
    {
      "epoch": 2.7408710954685436,
      "grad_norm": 0.09192202985286713,
      "learning_rate": 4.336146329107174e-06,
      "loss": 0.0624,
      "step": 137060
    },
    {
      "epoch": 2.7410710714714233,
      "grad_norm": 0.19671042263507843,
      "learning_rate": 4.332813395725847e-06,
      "loss": 0.0733,
      "step": 137070
    },
    {
      "epoch": 2.741271047474303,
      "grad_norm": 0.05856100842356682,
      "learning_rate": 4.329480462344518e-06,
      "loss": 0.061,
      "step": 137080
    },
    {
      "epoch": 2.7414710234771826,
      "grad_norm": 0.1943328082561493,
      "learning_rate": 4.326147528963191e-06,
      "loss": 0.09,
      "step": 137090
    },
    {
      "epoch": 2.7416709994800623,
      "grad_norm": 0.10610885918140411,
      "learning_rate": 4.322814595581863e-06,
      "loss": 0.0263,
      "step": 137100
    },
    {
      "epoch": 2.741870975482942,
      "grad_norm": 0.0866333544254303,
      "learning_rate": 4.319481662200536e-06,
      "loss": 0.0787,
      "step": 137110
    },
    {
      "epoch": 2.7420709514858217,
      "grad_norm": 0.06602080166339874,
      "learning_rate": 4.3161487288192086e-06,
      "loss": 0.0785,
      "step": 137120
    },
    {
      "epoch": 2.7422709274887014,
      "grad_norm": 0.041118357330560684,
      "learning_rate": 4.312815795437881e-06,
      "loss": 0.091,
      "step": 137130
    },
    {
      "epoch": 2.742470903491581,
      "grad_norm": 0.058182667940855026,
      "learning_rate": 4.309482862056554e-06,
      "loss": 0.0632,
      "step": 137140
    },
    {
      "epoch": 2.7426708794944608,
      "grad_norm": 0.2012217938899994,
      "learning_rate": 4.306149928675226e-06,
      "loss": 0.0836,
      "step": 137150
    },
    {
      "epoch": 2.7428708554973404,
      "grad_norm": 0.1681012362241745,
      "learning_rate": 4.302816995293899e-06,
      "loss": 0.0691,
      "step": 137160
    },
    {
      "epoch": 2.74307083150022,
      "grad_norm": 0.11504388600587845,
      "learning_rate": 4.29948406191257e-06,
      "loss": 0.0744,
      "step": 137170
    },
    {
      "epoch": 2.7432708075031,
      "grad_norm": 0.1454738974571228,
      "learning_rate": 4.296151128531243e-06,
      "loss": 0.1247,
      "step": 137180
    },
    {
      "epoch": 2.7434707835059795,
      "grad_norm": 0.11940047889947891,
      "learning_rate": 4.292818195149915e-06,
      "loss": 0.0557,
      "step": 137190
    },
    {
      "epoch": 2.743670759508859,
      "grad_norm": 0.19580990076065063,
      "learning_rate": 4.289485261768588e-06,
      "loss": 0.0622,
      "step": 137200
    },
    {
      "epoch": 2.7438707355117384,
      "grad_norm": 0.23901937901973724,
      "learning_rate": 4.2861523283872605e-06,
      "loss": 0.075,
      "step": 137210
    },
    {
      "epoch": 2.744070711514618,
      "grad_norm": 0.1347445845603943,
      "learning_rate": 4.282819395005933e-06,
      "loss": 0.0785,
      "step": 137220
    },
    {
      "epoch": 2.744270687517498,
      "grad_norm": 0.07963202893733978,
      "learning_rate": 4.279486461624605e-06,
      "loss": 0.066,
      "step": 137230
    },
    {
      "epoch": 2.7444706635203775,
      "grad_norm": 0.13624413311481476,
      "learning_rate": 4.276153528243278e-06,
      "loss": 0.0929,
      "step": 137240
    },
    {
      "epoch": 2.744670639523257,
      "grad_norm": 0.07572799921035767,
      "learning_rate": 4.27282059486195e-06,
      "loss": 0.0322,
      "step": 137250
    },
    {
      "epoch": 2.744870615526137,
      "grad_norm": 0.22522768378257751,
      "learning_rate": 4.269487661480623e-06,
      "loss": 0.0553,
      "step": 137260
    },
    {
      "epoch": 2.7450705915290166,
      "grad_norm": 0.19804297387599945,
      "learning_rate": 4.266154728099295e-06,
      "loss": 0.0892,
      "step": 137270
    },
    {
      "epoch": 2.7452705675318962,
      "grad_norm": 0.07798420637845993,
      "learning_rate": 4.262821794717967e-06,
      "loss": 0.0875,
      "step": 137280
    },
    {
      "epoch": 2.745470543534776,
      "grad_norm": 0.18106284737586975,
      "learning_rate": 4.2594888613366395e-06,
      "loss": 0.0499,
      "step": 137290
    },
    {
      "epoch": 2.7456705195376556,
      "grad_norm": 0.09657052159309387,
      "learning_rate": 4.2561559279553125e-06,
      "loss": 0.092,
      "step": 137300
    },
    {
      "epoch": 2.745870495540535,
      "grad_norm": 0.12184835970401764,
      "learning_rate": 4.252822994573985e-06,
      "loss": 0.062,
      "step": 137310
    },
    {
      "epoch": 2.7460704715434145,
      "grad_norm": 0.16569648683071136,
      "learning_rate": 4.249490061192657e-06,
      "loss": 0.0886,
      "step": 137320
    },
    {
      "epoch": 2.7462704475462942,
      "grad_norm": 0.1515350192785263,
      "learning_rate": 4.24615712781133e-06,
      "loss": 0.1026,
      "step": 137330
    },
    {
      "epoch": 2.746470423549174,
      "grad_norm": 0.07604365795850754,
      "learning_rate": 4.242824194430002e-06,
      "loss": 0.0379,
      "step": 137340
    },
    {
      "epoch": 2.7466703995520536,
      "grad_norm": 0.10271605849266052,
      "learning_rate": 4.239491261048675e-06,
      "loss": 0.0566,
      "step": 137350
    },
    {
      "epoch": 2.7468703755549333,
      "grad_norm": 0.18778911232948303,
      "learning_rate": 4.236158327667346e-06,
      "loss": 0.0711,
      "step": 137360
    },
    {
      "epoch": 2.747070351557813,
      "grad_norm": 0.18574245274066925,
      "learning_rate": 4.232825394286019e-06,
      "loss": 0.0817,
      "step": 137370
    },
    {
      "epoch": 2.7472703275606927,
      "grad_norm": 0.10929141938686371,
      "learning_rate": 4.229492460904691e-06,
      "loss": 0.0769,
      "step": 137380
    },
    {
      "epoch": 2.7474703035635724,
      "grad_norm": 0.12754330039024353,
      "learning_rate": 4.226159527523364e-06,
      "loss": 0.0383,
      "step": 137390
    },
    {
      "epoch": 2.747670279566452,
      "grad_norm": 0.08950015157461166,
      "learning_rate": 4.2228265941420366e-06,
      "loss": 0.0703,
      "step": 137400
    },
    {
      "epoch": 2.7478702555693317,
      "grad_norm": 0.21102303266525269,
      "learning_rate": 4.219493660760709e-06,
      "loss": 0.0799,
      "step": 137410
    },
    {
      "epoch": 2.7480702315722114,
      "grad_norm": 0.12031591683626175,
      "learning_rate": 4.216160727379381e-06,
      "loss": 0.0878,
      "step": 137420
    },
    {
      "epoch": 2.748270207575091,
      "grad_norm": 0.1075320914387703,
      "learning_rate": 4.212827793998054e-06,
      "loss": 0.1129,
      "step": 137430
    },
    {
      "epoch": 2.748470183577971,
      "grad_norm": 0.07979048788547516,
      "learning_rate": 4.209494860616726e-06,
      "loss": 0.0637,
      "step": 137440
    },
    {
      "epoch": 2.7486701595808505,
      "grad_norm": 0.19766110181808472,
      "learning_rate": 4.206161927235398e-06,
      "loss": 0.0798,
      "step": 137450
    },
    {
      "epoch": 2.74887013558373,
      "grad_norm": 0.10614120960235596,
      "learning_rate": 4.202828993854071e-06,
      "loss": 0.0472,
      "step": 137460
    },
    {
      "epoch": 2.74907011158661,
      "grad_norm": 0.10745060443878174,
      "learning_rate": 4.199496060472743e-06,
      "loss": 0.0718,
      "step": 137470
    },
    {
      "epoch": 2.749270087589489,
      "grad_norm": 0.18353718519210815,
      "learning_rate": 4.196163127091416e-06,
      "loss": 0.0745,
      "step": 137480
    },
    {
      "epoch": 2.749470063592369,
      "grad_norm": 0.18084299564361572,
      "learning_rate": 4.1928301937100885e-06,
      "loss": 0.121,
      "step": 137490
    },
    {
      "epoch": 2.7496700395952485,
      "grad_norm": 0.0658915638923645,
      "learning_rate": 4.189497260328761e-06,
      "loss": 0.0498,
      "step": 137500
    },
    {
      "epoch": 2.749870015598128,
      "grad_norm": 0.11364701390266418,
      "learning_rate": 4.186164326947433e-06,
      "loss": 0.1063,
      "step": 137510
    },
    {
      "epoch": 2.750069991601008,
      "grad_norm": 0.11663953214883804,
      "learning_rate": 4.182831393566106e-06,
      "loss": 0.0869,
      "step": 137520
    },
    {
      "epoch": 2.7502699676038875,
      "grad_norm": 0.09566748142242432,
      "learning_rate": 4.179498460184778e-06,
      "loss": 0.0844,
      "step": 137530
    },
    {
      "epoch": 2.750469943606767,
      "grad_norm": 0.08523944765329361,
      "learning_rate": 4.17616552680345e-06,
      "loss": 0.0555,
      "step": 137540
    },
    {
      "epoch": 2.750669919609647,
      "grad_norm": 0.10626323521137238,
      "learning_rate": 4.172832593422122e-06,
      "loss": 0.0925,
      "step": 137550
    },
    {
      "epoch": 2.7508698956125266,
      "grad_norm": 0.09847765415906906,
      "learning_rate": 4.169499660040795e-06,
      "loss": 0.0649,
      "step": 137560
    },
    {
      "epoch": 2.7510698716154063,
      "grad_norm": 0.09650224447250366,
      "learning_rate": 4.1661667266594675e-06,
      "loss": 0.0529,
      "step": 137570
    },
    {
      "epoch": 2.751269847618286,
      "grad_norm": 0.14944897592067719,
      "learning_rate": 4.1628337932781405e-06,
      "loss": 0.0565,
      "step": 137580
    },
    {
      "epoch": 2.751469823621165,
      "grad_norm": 0.12981729209423065,
      "learning_rate": 4.159500859896813e-06,
      "loss": 0.0491,
      "step": 137590
    },
    {
      "epoch": 2.751669799624045,
      "grad_norm": 0.14423802495002747,
      "learning_rate": 4.156167926515485e-06,
      "loss": 0.0396,
      "step": 137600
    },
    {
      "epoch": 2.7518697756269246,
      "grad_norm": 0.0869208350777626,
      "learning_rate": 4.152834993134158e-06,
      "loss": 0.0874,
      "step": 137610
    },
    {
      "epoch": 2.7520697516298043,
      "grad_norm": 0.10444710403680801,
      "learning_rate": 4.14950205975283e-06,
      "loss": 0.0608,
      "step": 137620
    },
    {
      "epoch": 2.752269727632684,
      "grad_norm": 0.14482195675373077,
      "learning_rate": 4.146169126371503e-06,
      "loss": 0.0574,
      "step": 137630
    },
    {
      "epoch": 2.7524697036355636,
      "grad_norm": 0.19589686393737793,
      "learning_rate": 4.142836192990174e-06,
      "loss": 0.2778,
      "step": 137640
    },
    {
      "epoch": 2.7526696796384433,
      "grad_norm": 0.1587425023317337,
      "learning_rate": 4.139503259608847e-06,
      "loss": 0.0807,
      "step": 137650
    },
    {
      "epoch": 2.752869655641323,
      "grad_norm": 0.09301740676164627,
      "learning_rate": 4.1361703262275194e-06,
      "loss": 0.0462,
      "step": 137660
    },
    {
      "epoch": 2.7530696316442027,
      "grad_norm": 0.15506771206855774,
      "learning_rate": 4.1328373928461924e-06,
      "loss": 0.0756,
      "step": 137670
    },
    {
      "epoch": 2.7532696076470824,
      "grad_norm": 0.12976056337356567,
      "learning_rate": 4.129504459464864e-06,
      "loss": 0.058,
      "step": 137680
    },
    {
      "epoch": 2.753469583649962,
      "grad_norm": 0.22703397274017334,
      "learning_rate": 4.126171526083537e-06,
      "loss": 0.0472,
      "step": 137690
    },
    {
      "epoch": 2.7536695596528418,
      "grad_norm": 0.23092111945152283,
      "learning_rate": 4.122838592702209e-06,
      "loss": 0.0931,
      "step": 137700
    },
    {
      "epoch": 2.7538695356557215,
      "grad_norm": 0.17074011266231537,
      "learning_rate": 4.119505659320882e-06,
      "loss": 0.0735,
      "step": 137710
    },
    {
      "epoch": 2.754069511658601,
      "grad_norm": 0.25462809205055237,
      "learning_rate": 4.116172725939554e-06,
      "loss": 0.0643,
      "step": 137720
    },
    {
      "epoch": 2.754269487661481,
      "grad_norm": 0.22748731076717377,
      "learning_rate": 4.112839792558226e-06,
      "loss": 0.1023,
      "step": 137730
    },
    {
      "epoch": 2.7544694636643605,
      "grad_norm": 0.13614293932914734,
      "learning_rate": 4.109506859176899e-06,
      "loss": 0.0688,
      "step": 137740
    },
    {
      "epoch": 2.75466943966724,
      "grad_norm": 0.06954605132341385,
      "learning_rate": 4.106173925795571e-06,
      "loss": 0.0414,
      "step": 137750
    },
    {
      "epoch": 2.7548694156701194,
      "grad_norm": 0.11681170016527176,
      "learning_rate": 4.102840992414244e-06,
      "loss": 0.0664,
      "step": 137760
    },
    {
      "epoch": 2.755069391672999,
      "grad_norm": 0.16365091502666473,
      "learning_rate": 4.0995080590329165e-06,
      "loss": 0.084,
      "step": 137770
    },
    {
      "epoch": 2.755269367675879,
      "grad_norm": 0.0832497626543045,
      "learning_rate": 4.096175125651589e-06,
      "loss": 0.0543,
      "step": 137780
    },
    {
      "epoch": 2.7554693436787585,
      "grad_norm": 0.10621383786201477,
      "learning_rate": 4.092842192270261e-06,
      "loss": 0.0999,
      "step": 137790
    },
    {
      "epoch": 2.755669319681638,
      "grad_norm": 0.10364554077386856,
      "learning_rate": 4.089509258888934e-06,
      "loss": 0.066,
      "step": 137800
    },
    {
      "epoch": 2.755869295684518,
      "grad_norm": 0.2291927933692932,
      "learning_rate": 4.086176325507606e-06,
      "loss": 0.0636,
      "step": 137810
    },
    {
      "epoch": 2.7560692716873976,
      "grad_norm": 0.10776007175445557,
      "learning_rate": 4.082843392126278e-06,
      "loss": 0.0848,
      "step": 137820
    },
    {
      "epoch": 2.7562692476902773,
      "grad_norm": 0.09959463775157928,
      "learning_rate": 4.07951045874495e-06,
      "loss": 0.0569,
      "step": 137830
    },
    {
      "epoch": 2.756469223693157,
      "grad_norm": 0.13644559681415558,
      "learning_rate": 4.076177525363623e-06,
      "loss": 0.0533,
      "step": 137840
    },
    {
      "epoch": 2.7566691996960366,
      "grad_norm": 0.18307159841060638,
      "learning_rate": 4.0728445919822955e-06,
      "loss": 0.1392,
      "step": 137850
    },
    {
      "epoch": 2.756869175698916,
      "grad_norm": 0.2280212789773941,
      "learning_rate": 4.0695116586009685e-06,
      "loss": 0.1959,
      "step": 137860
    },
    {
      "epoch": 2.7570691517017956,
      "grad_norm": 0.12339620292186737,
      "learning_rate": 4.066178725219641e-06,
      "loss": 0.0604,
      "step": 137870
    },
    {
      "epoch": 2.7572691277046752,
      "grad_norm": 0.10216507315635681,
      "learning_rate": 4.062845791838313e-06,
      "loss": 0.0618,
      "step": 137880
    },
    {
      "epoch": 2.757469103707555,
      "grad_norm": 0.04671034589409828,
      "learning_rate": 4.059512858456986e-06,
      "loss": 0.0913,
      "step": 137890
    },
    {
      "epoch": 2.7576690797104346,
      "grad_norm": 0.11647780984640121,
      "learning_rate": 4.056179925075658e-06,
      "loss": 0.0633,
      "step": 137900
    },
    {
      "epoch": 2.7578690557133143,
      "grad_norm": 0.09405138343572617,
      "learning_rate": 4.05284699169433e-06,
      "loss": 0.3291,
      "step": 137910
    },
    {
      "epoch": 2.758069031716194,
      "grad_norm": 0.12845927476882935,
      "learning_rate": 4.049514058313002e-06,
      "loss": 0.0507,
      "step": 137920
    },
    {
      "epoch": 2.7582690077190737,
      "grad_norm": 0.06918058544397354,
      "learning_rate": 4.046181124931675e-06,
      "loss": 0.082,
      "step": 137930
    },
    {
      "epoch": 2.7584689837219534,
      "grad_norm": 0.08877567946910858,
      "learning_rate": 4.0428481915503475e-06,
      "loss": 0.0767,
      "step": 137940
    },
    {
      "epoch": 2.758668959724833,
      "grad_norm": 0.09651193767786026,
      "learning_rate": 4.0395152581690205e-06,
      "loss": 0.0503,
      "step": 137950
    },
    {
      "epoch": 2.7588689357277127,
      "grad_norm": 0.21341471374034882,
      "learning_rate": 4.036182324787692e-06,
      "loss": 0.1086,
      "step": 137960
    },
    {
      "epoch": 2.7590689117305924,
      "grad_norm": 0.25669369101524353,
      "learning_rate": 4.032849391406365e-06,
      "loss": 0.0726,
      "step": 137970
    },
    {
      "epoch": 2.759268887733472,
      "grad_norm": 0.0654725581407547,
      "learning_rate": 4.029516458025037e-06,
      "loss": 0.0582,
      "step": 137980
    },
    {
      "epoch": 2.759468863736352,
      "grad_norm": 0.14909681677818298,
      "learning_rate": 4.02618352464371e-06,
      "loss": 0.095,
      "step": 137990
    },
    {
      "epoch": 2.7596688397392315,
      "grad_norm": 0.17440563440322876,
      "learning_rate": 4.022850591262382e-06,
      "loss": 0.0757,
      "step": 138000
    },
    {
      "epoch": 2.759868815742111,
      "grad_norm": 0.097364641726017,
      "learning_rate": 4.019517657881054e-06,
      "loss": 0.0662,
      "step": 138010
    },
    {
      "epoch": 2.760068791744991,
      "grad_norm": 0.12619063258171082,
      "learning_rate": 4.016184724499726e-06,
      "loss": 0.0715,
      "step": 138020
    },
    {
      "epoch": 2.76026876774787,
      "grad_norm": 0.12748076021671295,
      "learning_rate": 4.012851791118399e-06,
      "loss": 0.1137,
      "step": 138030
    },
    {
      "epoch": 2.76046874375075,
      "grad_norm": 0.20726434886455536,
      "learning_rate": 4.0095188577370716e-06,
      "loss": 0.0522,
      "step": 138040
    },
    {
      "epoch": 2.7606687197536295,
      "grad_norm": 0.21343404054641724,
      "learning_rate": 4.006185924355744e-06,
      "loss": 0.0684,
      "step": 138050
    },
    {
      "epoch": 2.760868695756509,
      "grad_norm": 0.1140013188123703,
      "learning_rate": 4.002852990974417e-06,
      "loss": 0.0482,
      "step": 138060
    },
    {
      "epoch": 2.761068671759389,
      "grad_norm": 0.11165681481361389,
      "learning_rate": 3.999520057593089e-06,
      "loss": 0.0521,
      "step": 138070
    },
    {
      "epoch": 2.7612686477622685,
      "grad_norm": 0.12446724623441696,
      "learning_rate": 3.996187124211762e-06,
      "loss": 0.0882,
      "step": 138080
    },
    {
      "epoch": 2.7614686237651482,
      "grad_norm": 0.15764187276363373,
      "learning_rate": 3.992854190830434e-06,
      "loss": 0.0705,
      "step": 138090
    },
    {
      "epoch": 2.761668599768028,
      "grad_norm": 0.13871867954730988,
      "learning_rate": 3.989521257449106e-06,
      "loss": 0.062,
      "step": 138100
    },
    {
      "epoch": 2.7618685757709076,
      "grad_norm": 0.12418420612812042,
      "learning_rate": 3.986188324067778e-06,
      "loss": 0.0449,
      "step": 138110
    },
    {
      "epoch": 2.7620685517737873,
      "grad_norm": 0.07309748977422714,
      "learning_rate": 3.982855390686451e-06,
      "loss": 0.0889,
      "step": 138120
    },
    {
      "epoch": 2.7622685277766665,
      "grad_norm": 0.06921526044607162,
      "learning_rate": 3.9795224573051235e-06,
      "loss": 0.0476,
      "step": 138130
    },
    {
      "epoch": 2.7624685037795462,
      "grad_norm": 0.18089905381202698,
      "learning_rate": 3.9761895239237965e-06,
      "loss": 0.0545,
      "step": 138140
    },
    {
      "epoch": 2.762668479782426,
      "grad_norm": 0.11910958588123322,
      "learning_rate": 3.972856590542468e-06,
      "loss": 0.0977,
      "step": 138150
    },
    {
      "epoch": 2.7628684557853056,
      "grad_norm": 0.12734432518482208,
      "learning_rate": 3.969523657161141e-06,
      "loss": 0.0466,
      "step": 138160
    },
    {
      "epoch": 2.7630684317881853,
      "grad_norm": 0.06826020032167435,
      "learning_rate": 3.966190723779813e-06,
      "loss": 0.0579,
      "step": 138170
    },
    {
      "epoch": 2.763268407791065,
      "grad_norm": 0.151221364736557,
      "learning_rate": 3.962857790398486e-06,
      "loss": 0.0624,
      "step": 138180
    },
    {
      "epoch": 2.7634683837939447,
      "grad_norm": 0.18786373734474182,
      "learning_rate": 3.959524857017158e-06,
      "loss": 0.0813,
      "step": 138190
    },
    {
      "epoch": 2.7636683597968243,
      "grad_norm": 0.0819649025797844,
      "learning_rate": 3.95619192363583e-06,
      "loss": 0.0542,
      "step": 138200
    },
    {
      "epoch": 2.763868335799704,
      "grad_norm": 0.2224297821521759,
      "learning_rate": 3.952858990254503e-06,
      "loss": 0.0964,
      "step": 138210
    },
    {
      "epoch": 2.7640683118025837,
      "grad_norm": 0.16152139008045197,
      "learning_rate": 3.9495260568731755e-06,
      "loss": 0.0819,
      "step": 138220
    },
    {
      "epoch": 2.7642682878054634,
      "grad_norm": 0.06572356820106506,
      "learning_rate": 3.9461931234918485e-06,
      "loss": 0.0594,
      "step": 138230
    },
    {
      "epoch": 2.764468263808343,
      "grad_norm": 0.12017536163330078,
      "learning_rate": 3.94286019011052e-06,
      "loss": 0.057,
      "step": 138240
    },
    {
      "epoch": 2.764668239811223,
      "grad_norm": 0.11685410141944885,
      "learning_rate": 3.939527256729193e-06,
      "loss": 0.0702,
      "step": 138250
    },
    {
      "epoch": 2.7648682158141025,
      "grad_norm": 0.13851141929626465,
      "learning_rate": 3.936194323347865e-06,
      "loss": 0.0756,
      "step": 138260
    },
    {
      "epoch": 2.765068191816982,
      "grad_norm": 0.08049789816141129,
      "learning_rate": 3.932861389966538e-06,
      "loss": 0.1058,
      "step": 138270
    },
    {
      "epoch": 2.765268167819862,
      "grad_norm": 0.17792700231075287,
      "learning_rate": 3.92952845658521e-06,
      "loss": 0.0733,
      "step": 138280
    },
    {
      "epoch": 2.7654681438227415,
      "grad_norm": 0.11149062216281891,
      "learning_rate": 3.926195523203882e-06,
      "loss": 0.0667,
      "step": 138290
    },
    {
      "epoch": 2.7656681198256208,
      "grad_norm": 0.16772305965423584,
      "learning_rate": 3.922862589822554e-06,
      "loss": 0.0689,
      "step": 138300
    },
    {
      "epoch": 2.7658680958285005,
      "grad_norm": 0.12623518705368042,
      "learning_rate": 3.9195296564412274e-06,
      "loss": 0.0966,
      "step": 138310
    },
    {
      "epoch": 2.76606807183138,
      "grad_norm": 0.13210275769233704,
      "learning_rate": 3.9161967230599e-06,
      "loss": 0.0636,
      "step": 138320
    },
    {
      "epoch": 2.76626804783426,
      "grad_norm": 0.06672875583171844,
      "learning_rate": 3.912863789678572e-06,
      "loss": 0.0731,
      "step": 138330
    },
    {
      "epoch": 2.7664680238371395,
      "grad_norm": 0.2669616937637329,
      "learning_rate": 3.909530856297245e-06,
      "loss": 0.0849,
      "step": 138340
    },
    {
      "epoch": 2.766667999840019,
      "grad_norm": 0.13304035365581512,
      "learning_rate": 3.906197922915917e-06,
      "loss": 0.0774,
      "step": 138350
    },
    {
      "epoch": 2.766867975842899,
      "grad_norm": 0.1089736744761467,
      "learning_rate": 3.90286498953459e-06,
      "loss": 0.0552,
      "step": 138360
    },
    {
      "epoch": 2.7670679518457786,
      "grad_norm": 0.07686913013458252,
      "learning_rate": 3.899532056153262e-06,
      "loss": 0.0525,
      "step": 138370
    },
    {
      "epoch": 2.7672679278486583,
      "grad_norm": 0.09190921485424042,
      "learning_rate": 3.896199122771934e-06,
      "loss": 0.0401,
      "step": 138380
    },
    {
      "epoch": 2.767467903851538,
      "grad_norm": 0.13623079657554626,
      "learning_rate": 3.892866189390606e-06,
      "loss": 0.0724,
      "step": 138390
    },
    {
      "epoch": 2.767667879854417,
      "grad_norm": 0.06789667159318924,
      "learning_rate": 3.889533256009279e-06,
      "loss": 0.0715,
      "step": 138400
    },
    {
      "epoch": 2.767867855857297,
      "grad_norm": 0.15427404642105103,
      "learning_rate": 3.8862003226279515e-06,
      "loss": 0.0519,
      "step": 138410
    },
    {
      "epoch": 2.7680678318601766,
      "grad_norm": 0.08688611537218094,
      "learning_rate": 3.8828673892466245e-06,
      "loss": 0.0637,
      "step": 138420
    },
    {
      "epoch": 2.7682678078630563,
      "grad_norm": 0.16140003502368927,
      "learning_rate": 3.879534455865296e-06,
      "loss": 0.0757,
      "step": 138430
    },
    {
      "epoch": 2.768467783865936,
      "grad_norm": 0.17189569771289825,
      "learning_rate": 3.876201522483969e-06,
      "loss": 0.0645,
      "step": 138440
    },
    {
      "epoch": 2.7686677598688156,
      "grad_norm": 0.08188523352146149,
      "learning_rate": 3.872868589102641e-06,
      "loss": 0.071,
      "step": 138450
    },
    {
      "epoch": 2.7688677358716953,
      "grad_norm": 0.10338688641786575,
      "learning_rate": 3.869535655721314e-06,
      "loss": 0.078,
      "step": 138460
    },
    {
      "epoch": 2.769067711874575,
      "grad_norm": 0.18986715376377106,
      "learning_rate": 3.866202722339986e-06,
      "loss": 0.0924,
      "step": 138470
    },
    {
      "epoch": 2.7692676878774547,
      "grad_norm": 0.1869281679391861,
      "learning_rate": 3.862869788958658e-06,
      "loss": 0.0551,
      "step": 138480
    },
    {
      "epoch": 2.7694676638803344,
      "grad_norm": 0.14536331593990326,
      "learning_rate": 3.859536855577331e-06,
      "loss": 0.0733,
      "step": 138490
    },
    {
      "epoch": 2.769667639883214,
      "grad_norm": 0.10194340348243713,
      "learning_rate": 3.8562039221960035e-06,
      "loss": 0.0685,
      "step": 138500
    },
    {
      "epoch": 2.7698676158860938,
      "grad_norm": 0.16659562289714813,
      "learning_rate": 3.852870988814676e-06,
      "loss": 0.0545,
      "step": 138510
    },
    {
      "epoch": 2.7700675918889734,
      "grad_norm": 0.29527410864830017,
      "learning_rate": 3.849538055433348e-06,
      "loss": 0.0871,
      "step": 138520
    },
    {
      "epoch": 2.770267567891853,
      "grad_norm": 0.09504272043704987,
      "learning_rate": 3.846205122052021e-06,
      "loss": 0.0875,
      "step": 138530
    },
    {
      "epoch": 2.770467543894733,
      "grad_norm": 0.0908624604344368,
      "learning_rate": 3.842872188670693e-06,
      "loss": 0.0724,
      "step": 138540
    },
    {
      "epoch": 2.7706675198976125,
      "grad_norm": 0.26833102107048035,
      "learning_rate": 3.839539255289366e-06,
      "loss": 0.0726,
      "step": 138550
    },
    {
      "epoch": 2.770867495900492,
      "grad_norm": 0.25911322236061096,
      "learning_rate": 3.836206321908037e-06,
      "loss": 0.086,
      "step": 138560
    },
    {
      "epoch": 2.7710674719033714,
      "grad_norm": 0.17377357184886932,
      "learning_rate": 3.83287338852671e-06,
      "loss": 0.0732,
      "step": 138570
    },
    {
      "epoch": 2.771267447906251,
      "grad_norm": 0.19938647747039795,
      "learning_rate": 3.8295404551453824e-06,
      "loss": 0.0835,
      "step": 138580
    },
    {
      "epoch": 2.771467423909131,
      "grad_norm": 0.16728883981704712,
      "learning_rate": 3.8262075217640554e-06,
      "loss": 0.0813,
      "step": 138590
    },
    {
      "epoch": 2.7716673999120105,
      "grad_norm": 0.15868890285491943,
      "learning_rate": 3.822874588382728e-06,
      "loss": 0.035,
      "step": 138600
    },
    {
      "epoch": 2.77186737591489,
      "grad_norm": 0.08070649206638336,
      "learning_rate": 3.8195416550014e-06,
      "loss": 0.0877,
      "step": 138610
    },
    {
      "epoch": 2.77206735191777,
      "grad_norm": 0.2120613306760788,
      "learning_rate": 3.816208721620072e-06,
      "loss": 0.0738,
      "step": 138620
    },
    {
      "epoch": 2.7722673279206496,
      "grad_norm": 0.2540338635444641,
      "learning_rate": 3.812875788238745e-06,
      "loss": 0.0731,
      "step": 138630
    },
    {
      "epoch": 2.7724673039235292,
      "grad_norm": 0.0748080387711525,
      "learning_rate": 3.8095428548574175e-06,
      "loss": 0.0714,
      "step": 138640
    },
    {
      "epoch": 2.772667279926409,
      "grad_norm": 0.1660524159669876,
      "learning_rate": 3.80620992147609e-06,
      "loss": 0.094,
      "step": 138650
    },
    {
      "epoch": 2.7728672559292886,
      "grad_norm": 0.1635851114988327,
      "learning_rate": 3.802876988094762e-06,
      "loss": 0.0706,
      "step": 138660
    },
    {
      "epoch": 2.773067231932168,
      "grad_norm": 0.19247810542583466,
      "learning_rate": 3.7995440547134344e-06,
      "loss": 0.0999,
      "step": 138670
    },
    {
      "epoch": 2.7732672079350476,
      "grad_norm": 0.25955066084861755,
      "learning_rate": 3.796211121332107e-06,
      "loss": 0.0616,
      "step": 138680
    },
    {
      "epoch": 2.7734671839379272,
      "grad_norm": 0.1763935387134552,
      "learning_rate": 3.7928781879507796e-06,
      "loss": 0.0377,
      "step": 138690
    },
    {
      "epoch": 2.773667159940807,
      "grad_norm": 0.07675682753324509,
      "learning_rate": 3.7895452545694517e-06,
      "loss": 0.0668,
      "step": 138700
    },
    {
      "epoch": 2.7738671359436866,
      "grad_norm": 0.19669868052005768,
      "learning_rate": 3.7862123211881243e-06,
      "loss": 0.0451,
      "step": 138710
    },
    {
      "epoch": 2.7740671119465663,
      "grad_norm": 0.24297815561294556,
      "learning_rate": 3.782879387806797e-06,
      "loss": 0.058,
      "step": 138720
    },
    {
      "epoch": 2.774267087949446,
      "grad_norm": 0.19940941035747528,
      "learning_rate": 3.7795464544254695e-06,
      "loss": 0.0887,
      "step": 138730
    },
    {
      "epoch": 2.7744670639523257,
      "grad_norm": 0.1807936578989029,
      "learning_rate": 3.776213521044142e-06,
      "loss": 0.0553,
      "step": 138740
    },
    {
      "epoch": 2.7746670399552054,
      "grad_norm": 0.14895769953727722,
      "learning_rate": 3.7728805876628138e-06,
      "loss": 0.0593,
      "step": 138750
    },
    {
      "epoch": 2.774867015958085,
      "grad_norm": 0.2629728317260742,
      "learning_rate": 3.7695476542814863e-06,
      "loss": 0.0694,
      "step": 138760
    },
    {
      "epoch": 2.7750669919609647,
      "grad_norm": 0.18766531348228455,
      "learning_rate": 3.766214720900159e-06,
      "loss": 0.0787,
      "step": 138770
    },
    {
      "epoch": 2.7752669679638444,
      "grad_norm": 0.11492650210857391,
      "learning_rate": 3.7628817875188315e-06,
      "loss": 0.0916,
      "step": 138780
    },
    {
      "epoch": 2.775466943966724,
      "grad_norm": 0.197129487991333,
      "learning_rate": 3.759548854137504e-06,
      "loss": 0.1033,
      "step": 138790
    },
    {
      "epoch": 2.775666919969604,
      "grad_norm": 0.08107335865497589,
      "learning_rate": 3.756215920756176e-06,
      "loss": 0.0949,
      "step": 138800
    },
    {
      "epoch": 2.7758668959724835,
      "grad_norm": 0.14055387675762177,
      "learning_rate": 3.7528829873748484e-06,
      "loss": 0.0449,
      "step": 138810
    },
    {
      "epoch": 2.776066871975363,
      "grad_norm": 0.17235063016414642,
      "learning_rate": 3.749550053993521e-06,
      "loss": 0.066,
      "step": 138820
    },
    {
      "epoch": 2.776266847978243,
      "grad_norm": 0.08987342566251755,
      "learning_rate": 3.7462171206121936e-06,
      "loss": 0.0632,
      "step": 138830
    },
    {
      "epoch": 2.776466823981122,
      "grad_norm": 0.07946016639471054,
      "learning_rate": 3.7428841872308653e-06,
      "loss": 0.0709,
      "step": 138840
    },
    {
      "epoch": 2.776666799984002,
      "grad_norm": 0.056252263486385345,
      "learning_rate": 3.739551253849538e-06,
      "loss": 0.068,
      "step": 138850
    },
    {
      "epoch": 2.7768667759868815,
      "grad_norm": 0.06345123052597046,
      "learning_rate": 3.7362183204682105e-06,
      "loss": 0.1005,
      "step": 138860
    },
    {
      "epoch": 2.777066751989761,
      "grad_norm": 0.141421377658844,
      "learning_rate": 3.732885387086883e-06,
      "loss": 0.0866,
      "step": 138870
    },
    {
      "epoch": 2.777266727992641,
      "grad_norm": 0.23170572519302368,
      "learning_rate": 3.7295524537055556e-06,
      "loss": 0.0854,
      "step": 138880
    },
    {
      "epoch": 2.7774667039955205,
      "grad_norm": 0.14644913375377655,
      "learning_rate": 3.7262195203242278e-06,
      "loss": 0.067,
      "step": 138890
    },
    {
      "epoch": 2.7776666799984002,
      "grad_norm": 0.10342885553836823,
      "learning_rate": 3.7228865869429004e-06,
      "loss": 0.0522,
      "step": 138900
    },
    {
      "epoch": 2.77786665600128,
      "grad_norm": 0.07468763738870621,
      "learning_rate": 3.719553653561573e-06,
      "loss": 0.0748,
      "step": 138910
    },
    {
      "epoch": 2.7780666320041596,
      "grad_norm": 0.12133493274450302,
      "learning_rate": 3.7162207201802455e-06,
      "loss": 0.0858,
      "step": 138920
    },
    {
      "epoch": 2.7782666080070393,
      "grad_norm": 0.23838680982589722,
      "learning_rate": 3.7128877867989173e-06,
      "loss": 0.0677,
      "step": 138930
    },
    {
      "epoch": 2.778466584009919,
      "grad_norm": 0.07430951297283173,
      "learning_rate": 3.70955485341759e-06,
      "loss": 0.0391,
      "step": 138940
    },
    {
      "epoch": 2.778666560012798,
      "grad_norm": 0.09677053987979889,
      "learning_rate": 3.7062219200362624e-06,
      "loss": 0.055,
      "step": 138950
    },
    {
      "epoch": 2.778866536015678,
      "grad_norm": 0.047067176550626755,
      "learning_rate": 3.702888986654935e-06,
      "loss": 0.0726,
      "step": 138960
    },
    {
      "epoch": 2.7790665120185576,
      "grad_norm": 0.12567245960235596,
      "learning_rate": 3.6995560532736076e-06,
      "loss": 0.0844,
      "step": 138970
    },
    {
      "epoch": 2.7792664880214373,
      "grad_norm": 0.16363127529621124,
      "learning_rate": 3.6962231198922793e-06,
      "loss": 0.0631,
      "step": 138980
    },
    {
      "epoch": 2.779466464024317,
      "grad_norm": 0.10302957147359848,
      "learning_rate": 3.692890186510952e-06,
      "loss": 0.0834,
      "step": 138990
    },
    {
      "epoch": 2.7796664400271966,
      "grad_norm": 0.13978908956050873,
      "learning_rate": 3.6895572531296245e-06,
      "loss": 0.0721,
      "step": 139000
    },
    {
      "epoch": 2.7798664160300763,
      "grad_norm": 0.20339544117450714,
      "learning_rate": 3.686224319748297e-06,
      "loss": 0.0952,
      "step": 139010
    },
    {
      "epoch": 2.780066392032956,
      "grad_norm": 0.11386607587337494,
      "learning_rate": 3.6828913863669696e-06,
      "loss": 0.0506,
      "step": 139020
    },
    {
      "epoch": 2.7802663680358357,
      "grad_norm": 0.1706530898809433,
      "learning_rate": 3.6795584529856418e-06,
      "loss": 0.0889,
      "step": 139030
    },
    {
      "epoch": 2.7804663440387154,
      "grad_norm": 0.08365146815776825,
      "learning_rate": 3.6762255196043144e-06,
      "loss": 0.033,
      "step": 139040
    },
    {
      "epoch": 2.780666320041595,
      "grad_norm": 0.20199722051620483,
      "learning_rate": 3.672892586222987e-06,
      "loss": 0.0569,
      "step": 139050
    },
    {
      "epoch": 2.7808662960444748,
      "grad_norm": 0.09180391579866409,
      "learning_rate": 3.6695596528416595e-06,
      "loss": 0.0973,
      "step": 139060
    },
    {
      "epoch": 2.7810662720473545,
      "grad_norm": 0.07536058872938156,
      "learning_rate": 3.6662267194603313e-06,
      "loss": 0.057,
      "step": 139070
    },
    {
      "epoch": 2.781266248050234,
      "grad_norm": 0.28150370717048645,
      "learning_rate": 3.662893786079004e-06,
      "loss": 0.0717,
      "step": 139080
    },
    {
      "epoch": 2.781466224053114,
      "grad_norm": 0.20474107563495636,
      "learning_rate": 3.6595608526976764e-06,
      "loss": 0.0581,
      "step": 139090
    },
    {
      "epoch": 2.7816662000559935,
      "grad_norm": 0.09161974489688873,
      "learning_rate": 3.656227919316349e-06,
      "loss": 0.0658,
      "step": 139100
    },
    {
      "epoch": 2.781866176058873,
      "grad_norm": 0.11901067942380905,
      "learning_rate": 3.6528949859350216e-06,
      "loss": 0.1574,
      "step": 139110
    },
    {
      "epoch": 2.7820661520617525,
      "grad_norm": 0.10547889024019241,
      "learning_rate": 3.6495620525536933e-06,
      "loss": 0.0655,
      "step": 139120
    },
    {
      "epoch": 2.782266128064632,
      "grad_norm": 0.18761734664440155,
      "learning_rate": 3.646229119172366e-06,
      "loss": 0.0522,
      "step": 139130
    },
    {
      "epoch": 2.782466104067512,
      "grad_norm": 0.14988718926906586,
      "learning_rate": 3.6428961857910385e-06,
      "loss": 0.0737,
      "step": 139140
    },
    {
      "epoch": 2.7826660800703915,
      "grad_norm": 0.17887581884860992,
      "learning_rate": 3.639563252409711e-06,
      "loss": 0.0873,
      "step": 139150
    },
    {
      "epoch": 2.782866056073271,
      "grad_norm": 0.11082418262958527,
      "learning_rate": 3.6362303190283836e-06,
      "loss": 0.0865,
      "step": 139160
    },
    {
      "epoch": 2.783066032076151,
      "grad_norm": 0.1975577473640442,
      "learning_rate": 3.632897385647056e-06,
      "loss": 0.0644,
      "step": 139170
    },
    {
      "epoch": 2.7832660080790306,
      "grad_norm": 0.1779215782880783,
      "learning_rate": 3.6295644522657284e-06,
      "loss": 0.0896,
      "step": 139180
    },
    {
      "epoch": 2.7834659840819103,
      "grad_norm": 0.09874322265386581,
      "learning_rate": 3.626231518884401e-06,
      "loss": 0.0732,
      "step": 139190
    },
    {
      "epoch": 2.78366596008479,
      "grad_norm": 0.10840212553739548,
      "learning_rate": 3.6228985855030735e-06,
      "loss": 0.0569,
      "step": 139200
    },
    {
      "epoch": 2.7838659360876696,
      "grad_norm": 0.1914452463388443,
      "learning_rate": 3.6195656521217453e-06,
      "loss": 0.0711,
      "step": 139210
    },
    {
      "epoch": 2.784065912090549,
      "grad_norm": 0.06354806572198868,
      "learning_rate": 3.616232718740418e-06,
      "loss": 0.1308,
      "step": 139220
    },
    {
      "epoch": 2.7842658880934286,
      "grad_norm": 0.12664923071861267,
      "learning_rate": 3.6128997853590904e-06,
      "loss": 0.0706,
      "step": 139230
    },
    {
      "epoch": 2.7844658640963083,
      "grad_norm": 0.10750710964202881,
      "learning_rate": 3.609566851977763e-06,
      "loss": 0.0853,
      "step": 139240
    },
    {
      "epoch": 2.784665840099188,
      "grad_norm": 0.17929290235042572,
      "learning_rate": 3.6062339185964356e-06,
      "loss": 0.0691,
      "step": 139250
    },
    {
      "epoch": 2.7848658161020676,
      "grad_norm": 0.2407778799533844,
      "learning_rate": 3.6029009852151073e-06,
      "loss": 0.0674,
      "step": 139260
    },
    {
      "epoch": 2.7850657921049473,
      "grad_norm": 0.08013661205768585,
      "learning_rate": 3.59956805183378e-06,
      "loss": 0.0708,
      "step": 139270
    },
    {
      "epoch": 2.785265768107827,
      "grad_norm": 0.13223020732402802,
      "learning_rate": 3.5962351184524525e-06,
      "loss": 0.0748,
      "step": 139280
    },
    {
      "epoch": 2.7854657441107067,
      "grad_norm": 0.1813707947731018,
      "learning_rate": 3.592902185071125e-06,
      "loss": 0.0651,
      "step": 139290
    },
    {
      "epoch": 2.7856657201135864,
      "grad_norm": 0.21960143744945526,
      "learning_rate": 3.5899025450279304e-06,
      "loss": 0.0895,
      "step": 139300
    },
    {
      "epoch": 2.785865696116466,
      "grad_norm": 0.11619614064693451,
      "learning_rate": 3.586569611646603e-06,
      "loss": 0.0521,
      "step": 139310
    },
    {
      "epoch": 2.7860656721193457,
      "grad_norm": 0.21755142509937286,
      "learning_rate": 3.5832366782652747e-06,
      "loss": 0.1194,
      "step": 139320
    },
    {
      "epoch": 2.7862656481222254,
      "grad_norm": 0.12347833067178726,
      "learning_rate": 3.5799037448839473e-06,
      "loss": 0.0836,
      "step": 139330
    },
    {
      "epoch": 2.786465624125105,
      "grad_norm": 0.09184272587299347,
      "learning_rate": 3.57657081150262e-06,
      "loss": 0.0587,
      "step": 139340
    },
    {
      "epoch": 2.786665600127985,
      "grad_norm": 0.07767023146152496,
      "learning_rate": 3.5732378781212925e-06,
      "loss": 0.0719,
      "step": 139350
    },
    {
      "epoch": 2.7868655761308645,
      "grad_norm": 0.10549838840961456,
      "learning_rate": 3.569904944739965e-06,
      "loss": 0.0735,
      "step": 139360
    },
    {
      "epoch": 2.787065552133744,
      "grad_norm": 0.057819634675979614,
      "learning_rate": 3.566572011358637e-06,
      "loss": 0.0605,
      "step": 139370
    },
    {
      "epoch": 2.787265528136624,
      "grad_norm": 0.17772281169891357,
      "learning_rate": 3.5632390779773094e-06,
      "loss": 0.0806,
      "step": 139380
    },
    {
      "epoch": 2.787465504139503,
      "grad_norm": 0.2565913498401642,
      "learning_rate": 3.559906144595982e-06,
      "loss": 0.053,
      "step": 139390
    },
    {
      "epoch": 2.787665480142383,
      "grad_norm": 0.15553954243659973,
      "learning_rate": 3.5565732112146545e-06,
      "loss": 0.0546,
      "step": 139400
    },
    {
      "epoch": 2.7878654561452625,
      "grad_norm": 0.1620231717824936,
      "learning_rate": 3.5532402778333267e-06,
      "loss": 0.0551,
      "step": 139410
    },
    {
      "epoch": 2.788065432148142,
      "grad_norm": 0.18489068746566772,
      "learning_rate": 3.5499073444519993e-06,
      "loss": 0.0652,
      "step": 139420
    },
    {
      "epoch": 2.788265408151022,
      "grad_norm": 0.22755347192287445,
      "learning_rate": 3.5469077044088042e-06,
      "loss": 0.5319,
      "step": 139430
    },
    {
      "epoch": 2.7884653841539015,
      "grad_norm": 0.2189202457666397,
      "learning_rate": 3.543574771027477e-06,
      "loss": 0.0623,
      "step": 139440
    },
    {
      "epoch": 2.7886653601567812,
      "grad_norm": 0.1382775604724884,
      "learning_rate": 3.5402418376461494e-06,
      "loss": 0.0689,
      "step": 139450
    },
    {
      "epoch": 2.788865336159661,
      "grad_norm": 0.1416897475719452,
      "learning_rate": 3.536908904264822e-06,
      "loss": 0.0777,
      "step": 139460
    },
    {
      "epoch": 2.7890653121625406,
      "grad_norm": 0.13628193736076355,
      "learning_rate": 3.5335759708834937e-06,
      "loss": 0.0734,
      "step": 139470
    },
    {
      "epoch": 2.7892652881654203,
      "grad_norm": 0.1175684779882431,
      "learning_rate": 3.5302430375021663e-06,
      "loss": 0.1179,
      "step": 139480
    },
    {
      "epoch": 2.7894652641682995,
      "grad_norm": 0.19689908623695374,
      "learning_rate": 3.526910104120839e-06,
      "loss": 0.0764,
      "step": 139490
    },
    {
      "epoch": 2.7896652401711792,
      "grad_norm": 0.08782836049795151,
      "learning_rate": 3.5235771707395114e-06,
      "loss": 0.0712,
      "step": 139500
    },
    {
      "epoch": 2.789865216174059,
      "grad_norm": 0.10769607871770859,
      "learning_rate": 3.520244237358184e-06,
      "loss": 0.065,
      "step": 139510
    },
    {
      "epoch": 2.7900651921769386,
      "grad_norm": 0.14905117452144623,
      "learning_rate": 3.516911303976856e-06,
      "loss": 0.0768,
      "step": 139520
    },
    {
      "epoch": 2.7902651681798183,
      "grad_norm": 0.08855640888214111,
      "learning_rate": 3.5135783705955288e-06,
      "loss": 0.065,
      "step": 139530
    },
    {
      "epoch": 2.790465144182698,
      "grad_norm": 0.10958655923604965,
      "learning_rate": 3.5102454372142013e-06,
      "loss": 0.0959,
      "step": 139540
    },
    {
      "epoch": 2.7906651201855777,
      "grad_norm": 0.07154541462659836,
      "learning_rate": 3.506912503832874e-06,
      "loss": 0.0625,
      "step": 139550
    },
    {
      "epoch": 2.7908650961884574,
      "grad_norm": 0.293336421251297,
      "learning_rate": 3.5035795704515465e-06,
      "loss": 0.1543,
      "step": 139560
    },
    {
      "epoch": 2.791065072191337,
      "grad_norm": 0.10776697844266891,
      "learning_rate": 3.5002466370702182e-06,
      "loss": 0.0617,
      "step": 139570
    },
    {
      "epoch": 2.7912650481942167,
      "grad_norm": 0.243595153093338,
      "learning_rate": 3.496913703688891e-06,
      "loss": 0.0855,
      "step": 139580
    },
    {
      "epoch": 2.7914650241970964,
      "grad_norm": 0.10828444361686707,
      "learning_rate": 3.4935807703075634e-06,
      "loss": 0.111,
      "step": 139590
    },
    {
      "epoch": 2.791665000199976,
      "grad_norm": 0.20795924961566925,
      "learning_rate": 3.490247836926236e-06,
      "loss": 0.1131,
      "step": 139600
    },
    {
      "epoch": 2.791864976202856,
      "grad_norm": 0.07670212537050247,
      "learning_rate": 3.4869149035449077e-06,
      "loss": 0.0991,
      "step": 139610
    },
    {
      "epoch": 2.7920649522057355,
      "grad_norm": 0.15446139872074127,
      "learning_rate": 3.4835819701635803e-06,
      "loss": 0.0626,
      "step": 139620
    },
    {
      "epoch": 2.792264928208615,
      "grad_norm": 0.17218497395515442,
      "learning_rate": 3.480249036782253e-06,
      "loss": 0.1511,
      "step": 139630
    },
    {
      "epoch": 2.792464904211495,
      "grad_norm": 0.05931856110692024,
      "learning_rate": 3.4769161034009254e-06,
      "loss": 0.0994,
      "step": 139640
    },
    {
      "epoch": 2.7926648802143745,
      "grad_norm": 0.21891821920871735,
      "learning_rate": 3.473583170019598e-06,
      "loss": 0.056,
      "step": 139650
    },
    {
      "epoch": 2.7928648562172538,
      "grad_norm": 0.19621434807777405,
      "learning_rate": 3.47025023663827e-06,
      "loss": 0.0876,
      "step": 139660
    },
    {
      "epoch": 2.7930648322201335,
      "grad_norm": 0.22823593020439148,
      "learning_rate": 3.4669173032569423e-06,
      "loss": 0.0542,
      "step": 139670
    },
    {
      "epoch": 2.793264808223013,
      "grad_norm": 0.19791652262210846,
      "learning_rate": 3.463584369875615e-06,
      "loss": 0.0832,
      "step": 139680
    },
    {
      "epoch": 2.793464784225893,
      "grad_norm": 0.05701137334108353,
      "learning_rate": 3.4602514364942875e-06,
      "loss": 0.0789,
      "step": 139690
    },
    {
      "epoch": 2.7936647602287725,
      "grad_norm": 0.08814340084791183,
      "learning_rate": 3.45691850311296e-06,
      "loss": 0.0609,
      "step": 139700
    },
    {
      "epoch": 2.793864736231652,
      "grad_norm": 0.12187433242797852,
      "learning_rate": 3.4535855697316322e-06,
      "loss": 0.0721,
      "step": 139710
    },
    {
      "epoch": 2.794064712234532,
      "grad_norm": 0.2137337028980255,
      "learning_rate": 3.450252636350305e-06,
      "loss": 0.0937,
      "step": 139720
    },
    {
      "epoch": 2.7942646882374116,
      "grad_norm": 0.09278237819671631,
      "learning_rate": 3.4469197029689774e-06,
      "loss": 0.0789,
      "step": 139730
    },
    {
      "epoch": 2.7944646642402913,
      "grad_norm": 0.18427371978759766,
      "learning_rate": 3.44358676958765e-06,
      "loss": 0.08,
      "step": 139740
    },
    {
      "epoch": 2.794664640243171,
      "grad_norm": 0.19637525081634521,
      "learning_rate": 3.4402538362063217e-06,
      "loss": 0.0824,
      "step": 139750
    },
    {
      "epoch": 2.79486461624605,
      "grad_norm": 0.12500737607479095,
      "learning_rate": 3.4369209028249943e-06,
      "loss": 0.0765,
      "step": 139760
    },
    {
      "epoch": 2.79506459224893,
      "grad_norm": 0.07056620717048645,
      "learning_rate": 3.433587969443667e-06,
      "loss": 0.045,
      "step": 139770
    },
    {
      "epoch": 2.7952645682518096,
      "grad_norm": 0.08699066936969757,
      "learning_rate": 3.4302550360623395e-06,
      "loss": 0.0689,
      "step": 139780
    },
    {
      "epoch": 2.7954645442546893,
      "grad_norm": 0.1520991325378418,
      "learning_rate": 3.426922102681012e-06,
      "loss": 0.0733,
      "step": 139790
    },
    {
      "epoch": 2.795664520257569,
      "grad_norm": 0.22740475833415985,
      "learning_rate": 3.4235891692996838e-06,
      "loss": 0.0754,
      "step": 139800
    },
    {
      "epoch": 2.7958644962604486,
      "grad_norm": 0.20888672769069672,
      "learning_rate": 3.4202562359183564e-06,
      "loss": 0.0702,
      "step": 139810
    },
    {
      "epoch": 2.7960644722633283,
      "grad_norm": 0.08826789259910583,
      "learning_rate": 3.416923302537029e-06,
      "loss": 0.0623,
      "step": 139820
    },
    {
      "epoch": 2.796264448266208,
      "grad_norm": 0.15491439402103424,
      "learning_rate": 3.4135903691557015e-06,
      "loss": 0.0426,
      "step": 139830
    },
    {
      "epoch": 2.7964644242690877,
      "grad_norm": 0.11135178804397583,
      "learning_rate": 3.4102574357743737e-06,
      "loss": 0.0547,
      "step": 139840
    },
    {
      "epoch": 2.7966644002719674,
      "grad_norm": 0.11669446527957916,
      "learning_rate": 3.4069245023930463e-06,
      "loss": 0.4392,
      "step": 139850
    },
    {
      "epoch": 2.796864376274847,
      "grad_norm": 0.20043332874774933,
      "learning_rate": 3.403591569011719e-06,
      "loss": 0.085,
      "step": 139860
    },
    {
      "epoch": 2.7970643522777268,
      "grad_norm": 0.18719711899757385,
      "learning_rate": 3.4002586356303914e-06,
      "loss": 0.0593,
      "step": 139870
    },
    {
      "epoch": 2.7972643282806064,
      "grad_norm": 0.05660643056035042,
      "learning_rate": 3.396925702249064e-06,
      "loss": 0.0369,
      "step": 139880
    },
    {
      "epoch": 2.797464304283486,
      "grad_norm": 0.1431577205657959,
      "learning_rate": 3.3935927688677357e-06,
      "loss": 0.074,
      "step": 139890
    },
    {
      "epoch": 2.797664280286366,
      "grad_norm": 0.12746065855026245,
      "learning_rate": 3.3902598354864083e-06,
      "loss": 0.0959,
      "step": 139900
    },
    {
      "epoch": 2.7978642562892455,
      "grad_norm": 0.0969802513718605,
      "learning_rate": 3.386926902105081e-06,
      "loss": 0.0487,
      "step": 139910
    },
    {
      "epoch": 2.798064232292125,
      "grad_norm": 0.22579166293144226,
      "learning_rate": 3.3835939687237535e-06,
      "loss": 0.075,
      "step": 139920
    },
    {
      "epoch": 2.7982642082950044,
      "grad_norm": 0.20456640422344208,
      "learning_rate": 3.380261035342426e-06,
      "loss": 0.0733,
      "step": 139930
    },
    {
      "epoch": 2.798464184297884,
      "grad_norm": 0.07848678529262543,
      "learning_rate": 3.3769281019610978e-06,
      "loss": 0.0615,
      "step": 139940
    },
    {
      "epoch": 2.798664160300764,
      "grad_norm": 0.07891833037137985,
      "learning_rate": 3.3735951685797704e-06,
      "loss": 0.0634,
      "step": 139950
    },
    {
      "epoch": 2.7988641363036435,
      "grad_norm": 0.09622624516487122,
      "learning_rate": 3.370262235198443e-06,
      "loss": 0.0597,
      "step": 139960
    },
    {
      "epoch": 2.799064112306523,
      "grad_norm": 0.1314736157655716,
      "learning_rate": 3.3669293018171155e-06,
      "loss": 0.0697,
      "step": 139970
    },
    {
      "epoch": 2.799264088309403,
      "grad_norm": 0.13083969056606293,
      "learning_rate": 3.3635963684357877e-06,
      "loss": 0.1119,
      "step": 139980
    },
    {
      "epoch": 2.7994640643122826,
      "grad_norm": 0.13887611031532288,
      "learning_rate": 3.3602634350544603e-06,
      "loss": 0.0343,
      "step": 139990
    },
    {
      "epoch": 2.7996640403151623,
      "grad_norm": 0.08719378709793091,
      "learning_rate": 3.356930501673133e-06,
      "loss": 0.0506,
      "step": 140000
    },
    {
      "epoch": 2.799864016318042,
      "grad_norm": 0.058901842683553696,
      "learning_rate": 3.3535975682918054e-06,
      "loss": 0.0709,
      "step": 140010
    },
    {
      "epoch": 2.8000639923209216,
      "grad_norm": 0.07912375032901764,
      "learning_rate": 3.350264634910478e-06,
      "loss": 0.0633,
      "step": 140020
    },
    {
      "epoch": 2.800263968323801,
      "grad_norm": 0.15773944556713104,
      "learning_rate": 3.3469317015291497e-06,
      "loss": 0.0489,
      "step": 140030
    },
    {
      "epoch": 2.8004639443266806,
      "grad_norm": 0.1851770579814911,
      "learning_rate": 3.3435987681478223e-06,
      "loss": 0.081,
      "step": 140040
    },
    {
      "epoch": 2.8006639203295602,
      "grad_norm": 0.19501414895057678,
      "learning_rate": 3.340265834766495e-06,
      "loss": 0.0345,
      "step": 140050
    },
    {
      "epoch": 2.80086389633244,
      "grad_norm": 0.07478965073823929,
      "learning_rate": 3.3369329013851675e-06,
      "loss": 0.0775,
      "step": 140060
    },
    {
      "epoch": 2.8010638723353196,
      "grad_norm": 0.15852974355220795,
      "learning_rate": 3.33359996800384e-06,
      "loss": 0.0556,
      "step": 140070
    },
    {
      "epoch": 2.8012638483381993,
      "grad_norm": 0.13133341073989868,
      "learning_rate": 3.330267034622512e-06,
      "loss": 0.0715,
      "step": 140080
    },
    {
      "epoch": 2.801463824341079,
      "grad_norm": 0.1821725070476532,
      "learning_rate": 3.3269341012411844e-06,
      "loss": 0.0636,
      "step": 140090
    },
    {
      "epoch": 2.8016638003439587,
      "grad_norm": 0.34958142042160034,
      "learning_rate": 3.323601167859857e-06,
      "loss": 0.0822,
      "step": 140100
    },
    {
      "epoch": 2.8018637763468384,
      "grad_norm": 0.07063053548336029,
      "learning_rate": 3.3202682344785295e-06,
      "loss": 0.0639,
      "step": 140110
    },
    {
      "epoch": 2.802063752349718,
      "grad_norm": 0.09020083397626877,
      "learning_rate": 3.3169353010972017e-06,
      "loss": 0.0637,
      "step": 140120
    },
    {
      "epoch": 2.8022637283525977,
      "grad_norm": 0.28731945157051086,
      "learning_rate": 3.3136023677158743e-06,
      "loss": 0.128,
      "step": 140130
    },
    {
      "epoch": 2.8024637043554774,
      "grad_norm": 0.11870244145393372,
      "learning_rate": 3.310269434334547e-06,
      "loss": 0.0603,
      "step": 140140
    },
    {
      "epoch": 2.802663680358357,
      "grad_norm": 0.08194459229707718,
      "learning_rate": 3.3069365009532194e-06,
      "loss": 0.0444,
      "step": 140150
    },
    {
      "epoch": 2.802863656361237,
      "grad_norm": 0.2012321650981903,
      "learning_rate": 3.303603567571892e-06,
      "loss": 0.0817,
      "step": 140160
    },
    {
      "epoch": 2.8030636323641165,
      "grad_norm": 0.06405701488256454,
      "learning_rate": 3.3002706341905637e-06,
      "loss": 0.0682,
      "step": 140170
    },
    {
      "epoch": 2.803263608366996,
      "grad_norm": 0.08624470233917236,
      "learning_rate": 3.2969377008092363e-06,
      "loss": 0.0356,
      "step": 140180
    },
    {
      "epoch": 2.803463584369876,
      "grad_norm": 0.1108383759856224,
      "learning_rate": 3.293604767427909e-06,
      "loss": 0.0469,
      "step": 140190
    },
    {
      "epoch": 2.803663560372755,
      "grad_norm": 0.09427754580974579,
      "learning_rate": 3.2902718340465815e-06,
      "loss": 0.0685,
      "step": 140200
    },
    {
      "epoch": 2.803863536375635,
      "grad_norm": 0.15124955773353577,
      "learning_rate": 3.286938900665254e-06,
      "loss": 0.0762,
      "step": 140210
    },
    {
      "epoch": 2.8040635123785145,
      "grad_norm": 0.11812582612037659,
      "learning_rate": 3.283605967283926e-06,
      "loss": 0.0811,
      "step": 140220
    },
    {
      "epoch": 2.804263488381394,
      "grad_norm": 0.0992664247751236,
      "learning_rate": 3.2802730339025984e-06,
      "loss": 0.0486,
      "step": 140230
    },
    {
      "epoch": 2.804463464384274,
      "grad_norm": 0.07452378422021866,
      "learning_rate": 3.276940100521271e-06,
      "loss": 0.0778,
      "step": 140240
    },
    {
      "epoch": 2.8046634403871535,
      "grad_norm": 0.16451846063137054,
      "learning_rate": 3.2736071671399435e-06,
      "loss": 0.0718,
      "step": 140250
    },
    {
      "epoch": 2.8048634163900332,
      "grad_norm": 0.07703042030334473,
      "learning_rate": 3.2702742337586157e-06,
      "loss": 0.101,
      "step": 140260
    },
    {
      "epoch": 2.805063392392913,
      "grad_norm": 0.09845384210348129,
      "learning_rate": 3.2669413003772883e-06,
      "loss": 0.0694,
      "step": 140270
    },
    {
      "epoch": 2.8052633683957926,
      "grad_norm": 0.12878967821598053,
      "learning_rate": 3.2636083669959604e-06,
      "loss": 0.044,
      "step": 140280
    },
    {
      "epoch": 2.8054633443986723,
      "grad_norm": 0.07496191561222076,
      "learning_rate": 3.260275433614633e-06,
      "loss": 0.0243,
      "step": 140290
    },
    {
      "epoch": 2.805663320401552,
      "grad_norm": 0.11042828857898712,
      "learning_rate": 3.2569425002333056e-06,
      "loss": 0.0647,
      "step": 140300
    },
    {
      "epoch": 2.805863296404431,
      "grad_norm": 0.09930355101823807,
      "learning_rate": 3.2536095668519778e-06,
      "loss": 0.1114,
      "step": 140310
    },
    {
      "epoch": 2.806063272407311,
      "grad_norm": 0.1938246637582779,
      "learning_rate": 3.2502766334706503e-06,
      "loss": 0.0563,
      "step": 140320
    },
    {
      "epoch": 2.8062632484101906,
      "grad_norm": 0.28067171573638916,
      "learning_rate": 3.246943700089323e-06,
      "loss": 0.0744,
      "step": 140330
    },
    {
      "epoch": 2.8064632244130703,
      "grad_norm": 0.13196362555027008,
      "learning_rate": 3.2436107667079955e-06,
      "loss": 0.0812,
      "step": 140340
    },
    {
      "epoch": 2.80666320041595,
      "grad_norm": 0.16395042836666107,
      "learning_rate": 3.2402778333266672e-06,
      "loss": 0.0718,
      "step": 140350
    },
    {
      "epoch": 2.8068631764188297,
      "grad_norm": 0.12954354286193848,
      "learning_rate": 3.23694489994534e-06,
      "loss": 0.0807,
      "step": 140360
    },
    {
      "epoch": 2.8070631524217093,
      "grad_norm": 0.09201542288064957,
      "learning_rate": 3.2336119665640124e-06,
      "loss": 0.0793,
      "step": 140370
    },
    {
      "epoch": 2.807263128424589,
      "grad_norm": 0.1062585636973381,
      "learning_rate": 3.230279033182685e-06,
      "loss": 0.0758,
      "step": 140380
    },
    {
      "epoch": 2.8074631044274687,
      "grad_norm": 0.1471189558506012,
      "learning_rate": 3.2269460998013576e-06,
      "loss": 0.0975,
      "step": 140390
    },
    {
      "epoch": 2.8076630804303484,
      "grad_norm": 0.14755459129810333,
      "learning_rate": 3.2236131664200293e-06,
      "loss": 0.0475,
      "step": 140400
    },
    {
      "epoch": 2.807863056433228,
      "grad_norm": 0.12185798585414886,
      "learning_rate": 3.220280233038702e-06,
      "loss": 0.0693,
      "step": 140410
    },
    {
      "epoch": 2.8080630324361078,
      "grad_norm": 0.09221518039703369,
      "learning_rate": 3.2169472996573744e-06,
      "loss": 0.0908,
      "step": 140420
    },
    {
      "epoch": 2.8082630084389875,
      "grad_norm": 0.18350659310817719,
      "learning_rate": 3.213614366276047e-06,
      "loss": 0.0626,
      "step": 140430
    },
    {
      "epoch": 2.808462984441867,
      "grad_norm": 0.202411487698555,
      "learning_rate": 3.2102814328947196e-06,
      "loss": 0.0636,
      "step": 140440
    },
    {
      "epoch": 2.808662960444747,
      "grad_norm": 0.24682874977588654,
      "learning_rate": 3.2069484995133918e-06,
      "loss": 0.0869,
      "step": 140450
    },
    {
      "epoch": 2.8088629364476265,
      "grad_norm": 0.11865191161632538,
      "learning_rate": 3.2036155661320643e-06,
      "loss": 0.085,
      "step": 140460
    },
    {
      "epoch": 2.809062912450506,
      "grad_norm": 0.1998591274023056,
      "learning_rate": 3.200282632750737e-06,
      "loss": 0.0586,
      "step": 140470
    },
    {
      "epoch": 2.8092628884533855,
      "grad_norm": 0.12482885271310806,
      "learning_rate": 3.1969496993694095e-06,
      "loss": 0.0535,
      "step": 140480
    },
    {
      "epoch": 2.809462864456265,
      "grad_norm": 0.15202045440673828,
      "learning_rate": 3.1936167659880812e-06,
      "loss": 0.0967,
      "step": 140490
    },
    {
      "epoch": 2.809662840459145,
      "grad_norm": 0.19998523592948914,
      "learning_rate": 3.190283832606754e-06,
      "loss": 0.1103,
      "step": 140500
    },
    {
      "epoch": 2.8098628164620245,
      "grad_norm": 0.21696875989437103,
      "learning_rate": 3.1869508992254264e-06,
      "loss": 0.1033,
      "step": 140510
    },
    {
      "epoch": 2.810062792464904,
      "grad_norm": 0.2317621111869812,
      "learning_rate": 3.183617965844099e-06,
      "loss": 0.0784,
      "step": 140520
    },
    {
      "epoch": 2.810262768467784,
      "grad_norm": 0.09128867834806442,
      "learning_rate": 3.1802850324627716e-06,
      "loss": 0.0784,
      "step": 140530
    },
    {
      "epoch": 2.8104627444706636,
      "grad_norm": 0.18441976606845856,
      "learning_rate": 3.1769520990814433e-06,
      "loss": 0.0574,
      "step": 140540
    },
    {
      "epoch": 2.8106627204735433,
      "grad_norm": 0.08566983789205551,
      "learning_rate": 3.173619165700116e-06,
      "loss": 0.0552,
      "step": 140550
    },
    {
      "epoch": 2.810862696476423,
      "grad_norm": 0.22068479657173157,
      "learning_rate": 3.1702862323187885e-06,
      "loss": 0.059,
      "step": 140560
    },
    {
      "epoch": 2.8110626724793026,
      "grad_norm": 0.10682091861963272,
      "learning_rate": 3.166953298937461e-06,
      "loss": 0.0494,
      "step": 140570
    },
    {
      "epoch": 2.811262648482182,
      "grad_norm": 0.14213202893733978,
      "learning_rate": 3.1636203655561336e-06,
      "loss": 0.0606,
      "step": 140580
    },
    {
      "epoch": 2.8114626244850616,
      "grad_norm": 0.19200806319713593,
      "learning_rate": 3.1602874321748058e-06,
      "loss": 0.0671,
      "step": 140590
    },
    {
      "epoch": 2.8116626004879413,
      "grad_norm": 0.19402804970741272,
      "learning_rate": 3.1569544987934784e-06,
      "loss": 0.0865,
      "step": 140600
    },
    {
      "epoch": 2.811862576490821,
      "grad_norm": 0.22463493049144745,
      "learning_rate": 3.153621565412151e-06,
      "loss": 0.0944,
      "step": 140610
    },
    {
      "epoch": 2.8120625524937006,
      "grad_norm": 0.23358312249183655,
      "learning_rate": 3.1502886320308235e-06,
      "loss": 0.1043,
      "step": 140620
    },
    {
      "epoch": 2.8122625284965803,
      "grad_norm": 0.1534615159034729,
      "learning_rate": 3.1469556986494953e-06,
      "loss": 0.0895,
      "step": 140630
    },
    {
      "epoch": 2.81246250449946,
      "grad_norm": 0.11903110891580582,
      "learning_rate": 3.143622765268168e-06,
      "loss": 0.0502,
      "step": 140640
    },
    {
      "epoch": 2.8126624805023397,
      "grad_norm": 0.19095313549041748,
      "learning_rate": 3.1402898318868404e-06,
      "loss": 0.0867,
      "step": 140650
    },
    {
      "epoch": 2.8128624565052194,
      "grad_norm": 0.198279470205307,
      "learning_rate": 3.136956898505513e-06,
      "loss": 0.089,
      "step": 140660
    },
    {
      "epoch": 2.813062432508099,
      "grad_norm": 0.2603480815887451,
      "learning_rate": 3.1336239651241856e-06,
      "loss": 0.0973,
      "step": 140670
    },
    {
      "epoch": 2.8132624085109788,
      "grad_norm": 0.2095409482717514,
      "learning_rate": 3.1302910317428573e-06,
      "loss": 0.0906,
      "step": 140680
    },
    {
      "epoch": 2.8134623845138584,
      "grad_norm": 0.18911854922771454,
      "learning_rate": 3.12695809836153e-06,
      "loss": 0.0736,
      "step": 140690
    },
    {
      "epoch": 2.813662360516738,
      "grad_norm": 0.20029011368751526,
      "learning_rate": 3.1236251649802025e-06,
      "loss": 0.0399,
      "step": 140700
    },
    {
      "epoch": 2.813862336519618,
      "grad_norm": 0.22495320439338684,
      "learning_rate": 3.1202922315988746e-06,
      "loss": 0.064,
      "step": 140710
    },
    {
      "epoch": 2.8140623125224975,
      "grad_norm": 0.16592638194561005,
      "learning_rate": 3.116959298217547e-06,
      "loss": 0.0998,
      "step": 140720
    },
    {
      "epoch": 2.814262288525377,
      "grad_norm": 0.07523088902235031,
      "learning_rate": 3.1136263648362198e-06,
      "loss": 0.1123,
      "step": 140730
    },
    {
      "epoch": 2.814462264528257,
      "grad_norm": 0.162504181265831,
      "learning_rate": 3.1102934314548924e-06,
      "loss": 0.0986,
      "step": 140740
    },
    {
      "epoch": 2.814662240531136,
      "grad_norm": 0.24064771831035614,
      "learning_rate": 3.106960498073565e-06,
      "loss": 0.1124,
      "step": 140750
    },
    {
      "epoch": 2.814862216534016,
      "grad_norm": 0.2900647222995758,
      "learning_rate": 3.103627564692237e-06,
      "loss": 0.0683,
      "step": 140760
    },
    {
      "epoch": 2.8150621925368955,
      "grad_norm": 0.23337511718273163,
      "learning_rate": 3.1002946313109097e-06,
      "loss": 0.072,
      "step": 140770
    },
    {
      "epoch": 2.815262168539775,
      "grad_norm": 0.07271747291088104,
      "learning_rate": 3.096961697929582e-06,
      "loss": 0.046,
      "step": 140780
    },
    {
      "epoch": 2.815462144542655,
      "grad_norm": 0.1132257729768753,
      "learning_rate": 3.0936287645482544e-06,
      "loss": 0.0485,
      "step": 140790
    },
    {
      "epoch": 2.8156621205455346,
      "grad_norm": 0.28023242950439453,
      "learning_rate": 3.090295831166927e-06,
      "loss": 0.0757,
      "step": 140800
    },
    {
      "epoch": 2.8158620965484142,
      "grad_norm": 0.0833715870976448,
      "learning_rate": 3.086962897785599e-06,
      "loss": 0.098,
      "step": 140810
    },
    {
      "epoch": 2.816062072551294,
      "grad_norm": 0.2038845419883728,
      "learning_rate": 3.0836299644042717e-06,
      "loss": 0.0571,
      "step": 140820
    },
    {
      "epoch": 2.8162620485541736,
      "grad_norm": 0.18214505910873413,
      "learning_rate": 3.080297031022944e-06,
      "loss": 0.0741,
      "step": 140830
    },
    {
      "epoch": 2.8164620245570533,
      "grad_norm": 0.13181175291538239,
      "learning_rate": 3.0769640976416165e-06,
      "loss": 0.0669,
      "step": 140840
    },
    {
      "epoch": 2.8166620005599325,
      "grad_norm": 0.11486467719078064,
      "learning_rate": 3.0736311642602886e-06,
      "loss": 0.1023,
      "step": 140850
    },
    {
      "epoch": 2.8168619765628122,
      "grad_norm": 0.1040569394826889,
      "learning_rate": 3.0702982308789612e-06,
      "loss": 0.121,
      "step": 140860
    },
    {
      "epoch": 2.817061952565692,
      "grad_norm": 0.18001779913902283,
      "learning_rate": 3.066965297497634e-06,
      "loss": 0.0801,
      "step": 140870
    },
    {
      "epoch": 2.8172619285685716,
      "grad_norm": 0.1716560423374176,
      "learning_rate": 3.0636323641163064e-06,
      "loss": 0.0816,
      "step": 140880
    },
    {
      "epoch": 2.8174619045714513,
      "grad_norm": 0.1333315670490265,
      "learning_rate": 3.0602994307349785e-06,
      "loss": 0.0606,
      "step": 140890
    },
    {
      "epoch": 2.817661880574331,
      "grad_norm": 0.2323285937309265,
      "learning_rate": 3.056966497353651e-06,
      "loss": 0.1064,
      "step": 140900
    },
    {
      "epoch": 2.8178618565772107,
      "grad_norm": 0.1671871393918991,
      "learning_rate": 3.0536335639723237e-06,
      "loss": 0.0643,
      "step": 140910
    },
    {
      "epoch": 2.8180618325800904,
      "grad_norm": 0.3028728663921356,
      "learning_rate": 3.050300630590996e-06,
      "loss": 0.0868,
      "step": 140920
    },
    {
      "epoch": 2.81826180858297,
      "grad_norm": 0.19180312752723694,
      "learning_rate": 3.0469676972096684e-06,
      "loss": 0.0882,
      "step": 140930
    },
    {
      "epoch": 2.8184617845858497,
      "grad_norm": 0.1247980147600174,
      "learning_rate": 3.0436347638283406e-06,
      "loss": 0.0716,
      "step": 140940
    },
    {
      "epoch": 2.8186617605887294,
      "grad_norm": 0.19175389409065247,
      "learning_rate": 3.040301830447013e-06,
      "loss": 0.0644,
      "step": 140950
    },
    {
      "epoch": 2.818861736591609,
      "grad_norm": 0.22975365817546844,
      "learning_rate": 3.0369688970656857e-06,
      "loss": 0.0751,
      "step": 140960
    },
    {
      "epoch": 2.819061712594489,
      "grad_norm": 0.08563058823347092,
      "learning_rate": 3.033635963684358e-06,
      "loss": 0.0899,
      "step": 140970
    },
    {
      "epoch": 2.8192616885973685,
      "grad_norm": 0.1374487727880478,
      "learning_rate": 3.0303030303030305e-06,
      "loss": 0.066,
      "step": 140980
    },
    {
      "epoch": 2.819461664600248,
      "grad_norm": 0.11037329584360123,
      "learning_rate": 3.0269700969217026e-06,
      "loss": 0.0797,
      "step": 140990
    },
    {
      "epoch": 2.819661640603128,
      "grad_norm": 0.16273780167102814,
      "learning_rate": 3.0236371635403752e-06,
      "loss": 0.0543,
      "step": 141000
    },
    {
      "epoch": 2.8198616166060075,
      "grad_norm": 0.23172897100448608,
      "learning_rate": 3.0203042301590474e-06,
      "loss": 0.089,
      "step": 141010
    },
    {
      "epoch": 2.820061592608887,
      "grad_norm": 0.14554759860038757,
      "learning_rate": 3.01697129677772e-06,
      "loss": 0.1076,
      "step": 141020
    },
    {
      "epoch": 2.8202615686117665,
      "grad_norm": 0.07832877337932587,
      "learning_rate": 3.0136383633963925e-06,
      "loss": 0.0586,
      "step": 141030
    },
    {
      "epoch": 2.820461544614646,
      "grad_norm": 0.10339141637086868,
      "learning_rate": 3.010305430015065e-06,
      "loss": 0.0382,
      "step": 141040
    },
    {
      "epoch": 2.820661520617526,
      "grad_norm": 0.13528741896152496,
      "learning_rate": 3.0069724966337377e-06,
      "loss": 0.0582,
      "step": 141050
    },
    {
      "epoch": 2.8208614966204055,
      "grad_norm": 0.23449739813804626,
      "learning_rate": 3.00363956325241e-06,
      "loss": 0.0787,
      "step": 141060
    },
    {
      "epoch": 2.821061472623285,
      "grad_norm": 0.26673585176467896,
      "learning_rate": 3.0003066298710824e-06,
      "loss": 0.1212,
      "step": 141070
    },
    {
      "epoch": 2.821261448626165,
      "grad_norm": 0.054213907569646835,
      "learning_rate": 2.9969736964897546e-06,
      "loss": 0.0631,
      "step": 141080
    },
    {
      "epoch": 2.8214614246290446,
      "grad_norm": 0.16579151153564453,
      "learning_rate": 2.993640763108427e-06,
      "loss": 0.0709,
      "step": 141090
    },
    {
      "epoch": 2.8216614006319243,
      "grad_norm": 0.09493564814329147,
      "learning_rate": 2.9903078297270998e-06,
      "loss": 0.0836,
      "step": 141100
    },
    {
      "epoch": 2.821861376634804,
      "grad_norm": 0.1328084021806717,
      "learning_rate": 2.986974896345772e-06,
      "loss": 0.0759,
      "step": 141110
    },
    {
      "epoch": 2.822061352637683,
      "grad_norm": 0.15893639624118805,
      "learning_rate": 2.9836419629644445e-06,
      "loss": 0.0822,
      "step": 141120
    },
    {
      "epoch": 2.822261328640563,
      "grad_norm": 0.21822838485240936,
      "learning_rate": 2.9803090295831167e-06,
      "loss": 0.0724,
      "step": 141130
    },
    {
      "epoch": 2.8224613046434426,
      "grad_norm": 0.21896524727344513,
      "learning_rate": 2.9769760962017892e-06,
      "loss": 0.0482,
      "step": 141140
    },
    {
      "epoch": 2.8226612806463223,
      "grad_norm": 0.15221339464187622,
      "learning_rate": 2.9736431628204614e-06,
      "loss": 0.1176,
      "step": 141150
    },
    {
      "epoch": 2.822861256649202,
      "grad_norm": 0.2217225283384323,
      "learning_rate": 2.970310229439134e-06,
      "loss": 0.0853,
      "step": 141160
    },
    {
      "epoch": 2.8230612326520816,
      "grad_norm": 0.14123214781284332,
      "learning_rate": 2.9669772960578066e-06,
      "loss": 0.0821,
      "step": 141170
    },
    {
      "epoch": 2.8232612086549613,
      "grad_norm": 0.16365334391593933,
      "learning_rate": 2.963644362676479e-06,
      "loss": 0.0726,
      "step": 141180
    },
    {
      "epoch": 2.823461184657841,
      "grad_norm": 0.09141761809587479,
      "learning_rate": 2.9603114292951513e-06,
      "loss": 0.0574,
      "step": 141190
    },
    {
      "epoch": 2.8236611606607207,
      "grad_norm": 0.2225986272096634,
      "learning_rate": 2.956978495913824e-06,
      "loss": 0.1383,
      "step": 141200
    },
    {
      "epoch": 2.8238611366636004,
      "grad_norm": 0.12703843414783478,
      "learning_rate": 2.9536455625324965e-06,
      "loss": 0.0523,
      "step": 141210
    },
    {
      "epoch": 2.82406111266648,
      "grad_norm": 0.18710410594940186,
      "learning_rate": 2.9503126291511686e-06,
      "loss": 0.0829,
      "step": 141220
    },
    {
      "epoch": 2.8242610886693598,
      "grad_norm": 0.1796388179063797,
      "learning_rate": 2.946979695769841e-06,
      "loss": 0.0753,
      "step": 141230
    },
    {
      "epoch": 2.8244610646722395,
      "grad_norm": 0.09206628799438477,
      "learning_rate": 2.9436467623885138e-06,
      "loss": 0.056,
      "step": 141240
    },
    {
      "epoch": 2.824661040675119,
      "grad_norm": 0.08732803910970688,
      "learning_rate": 2.940313829007186e-06,
      "loss": 0.0783,
      "step": 141250
    },
    {
      "epoch": 2.824861016677999,
      "grad_norm": 0.1969468742609024,
      "learning_rate": 2.9369808956258585e-06,
      "loss": 0.0826,
      "step": 141260
    },
    {
      "epoch": 2.8250609926808785,
      "grad_norm": 0.1882135421037674,
      "learning_rate": 2.9336479622445307e-06,
      "loss": 0.0688,
      "step": 141270
    },
    {
      "epoch": 2.825260968683758,
      "grad_norm": 0.12828925251960754,
      "learning_rate": 2.9303150288632032e-06,
      "loss": 0.0539,
      "step": 141280
    },
    {
      "epoch": 2.8254609446866374,
      "grad_norm": 0.15057338774204254,
      "learning_rate": 2.9269820954818754e-06,
      "loss": 0.0698,
      "step": 141290
    },
    {
      "epoch": 2.825660920689517,
      "grad_norm": 0.15364216268062592,
      "learning_rate": 2.923649162100548e-06,
      "loss": 0.0506,
      "step": 141300
    },
    {
      "epoch": 2.825860896692397,
      "grad_norm": 0.14231018722057343,
      "learning_rate": 2.9203162287192206e-06,
      "loss": 0.0541,
      "step": 141310
    },
    {
      "epoch": 2.8260608726952765,
      "grad_norm": 0.1538112312555313,
      "learning_rate": 2.9169832953378927e-06,
      "loss": 0.0772,
      "step": 141320
    },
    {
      "epoch": 2.826260848698156,
      "grad_norm": 0.11313771456480026,
      "learning_rate": 2.9136503619565653e-06,
      "loss": 0.103,
      "step": 141330
    },
    {
      "epoch": 2.826460824701036,
      "grad_norm": 0.13464432954788208,
      "learning_rate": 2.910317428575238e-06,
      "loss": 0.0611,
      "step": 141340
    },
    {
      "epoch": 2.8266608007039156,
      "grad_norm": 0.09379731863737106,
      "learning_rate": 2.9069844951939105e-06,
      "loss": 0.04,
      "step": 141350
    },
    {
      "epoch": 2.8268607767067953,
      "grad_norm": 0.2353367954492569,
      "learning_rate": 2.9036515618125826e-06,
      "loss": 0.0779,
      "step": 141360
    },
    {
      "epoch": 2.827060752709675,
      "grad_norm": 0.17435409128665924,
      "learning_rate": 2.900318628431255e-06,
      "loss": 0.1071,
      "step": 141370
    },
    {
      "epoch": 2.8272607287125546,
      "grad_norm": 0.12136092036962509,
      "learning_rate": 2.8969856950499274e-06,
      "loss": 0.1537,
      "step": 141380
    },
    {
      "epoch": 2.8274607047154343,
      "grad_norm": 0.1882886439561844,
      "learning_rate": 2.8936527616686e-06,
      "loss": 0.2447,
      "step": 141390
    },
    {
      "epoch": 2.8276606807183136,
      "grad_norm": 0.20216034352779388,
      "learning_rate": 2.8903198282872725e-06,
      "loss": 0.0779,
      "step": 141400
    },
    {
      "epoch": 2.8278606567211932,
      "grad_norm": 0.22007957100868225,
      "learning_rate": 2.8869868949059447e-06,
      "loss": 0.1039,
      "step": 141410
    },
    {
      "epoch": 2.828060632724073,
      "grad_norm": 0.06834591180086136,
      "learning_rate": 2.8836539615246173e-06,
      "loss": 0.0736,
      "step": 141420
    },
    {
      "epoch": 2.8282606087269526,
      "grad_norm": 0.17354616522789001,
      "learning_rate": 2.8803210281432894e-06,
      "loss": 0.0794,
      "step": 141430
    },
    {
      "epoch": 2.8284605847298323,
      "grad_norm": 0.07955816388130188,
      "learning_rate": 2.876988094761962e-06,
      "loss": 0.0593,
      "step": 141440
    },
    {
      "epoch": 2.828660560732712,
      "grad_norm": 0.07371606677770615,
      "learning_rate": 2.873655161380634e-06,
      "loss": 0.0442,
      "step": 141450
    },
    {
      "epoch": 2.8288605367355917,
      "grad_norm": 0.19521020352840424,
      "learning_rate": 2.87065552133744e-06,
      "loss": 0.1017,
      "step": 141460
    },
    {
      "epoch": 2.8290605127384714,
      "grad_norm": 0.14757069945335388,
      "learning_rate": 2.867322587956112e-06,
      "loss": 0.0562,
      "step": 141470
    },
    {
      "epoch": 2.829260488741351,
      "grad_norm": 0.16969217360019684,
      "learning_rate": 2.8639896545747847e-06,
      "loss": 0.0713,
      "step": 141480
    },
    {
      "epoch": 2.8294604647442307,
      "grad_norm": 0.11114267259836197,
      "learning_rate": 2.860656721193457e-06,
      "loss": 0.0819,
      "step": 141490
    },
    {
      "epoch": 2.8296604407471104,
      "grad_norm": 0.16526049375534058,
      "learning_rate": 2.8573237878121294e-06,
      "loss": 0.0722,
      "step": 141500
    },
    {
      "epoch": 2.82986041674999,
      "grad_norm": 0.06202144920825958,
      "learning_rate": 2.853990854430802e-06,
      "loss": 0.066,
      "step": 141510
    },
    {
      "epoch": 2.83006039275287,
      "grad_norm": 0.222605362534523,
      "learning_rate": 2.850657921049474e-06,
      "loss": 0.105,
      "step": 141520
    },
    {
      "epoch": 2.8302603687557495,
      "grad_norm": 0.13278543949127197,
      "learning_rate": 2.8473249876681467e-06,
      "loss": 0.0587,
      "step": 141530
    },
    {
      "epoch": 2.830460344758629,
      "grad_norm": 0.09818882495164871,
      "learning_rate": 2.843992054286819e-06,
      "loss": 0.0785,
      "step": 141540
    },
    {
      "epoch": 2.830660320761509,
      "grad_norm": 0.09721846878528595,
      "learning_rate": 2.8406591209054915e-06,
      "loss": 0.065,
      "step": 141550
    },
    {
      "epoch": 2.8308602967643886,
      "grad_norm": 0.14781992137432098,
      "learning_rate": 2.8373261875241636e-06,
      "loss": 0.0779,
      "step": 141560
    },
    {
      "epoch": 2.831060272767268,
      "grad_norm": 0.18688559532165527,
      "learning_rate": 2.833993254142836e-06,
      "loss": 0.079,
      "step": 141570
    },
    {
      "epoch": 2.8312602487701475,
      "grad_norm": 0.05734303593635559,
      "learning_rate": 2.8306603207615088e-06,
      "loss": 0.0878,
      "step": 141580
    },
    {
      "epoch": 2.831460224773027,
      "grad_norm": 0.09406141191720963,
      "learning_rate": 2.8273273873801814e-06,
      "loss": 0.0591,
      "step": 141590
    },
    {
      "epoch": 2.831660200775907,
      "grad_norm": 0.20679761469364166,
      "learning_rate": 2.823994453998854e-06,
      "loss": 0.0734,
      "step": 141600
    },
    {
      "epoch": 2.8318601767787865,
      "grad_norm": 0.10888995230197906,
      "learning_rate": 2.820661520617526e-06,
      "loss": 0.0891,
      "step": 141610
    },
    {
      "epoch": 2.8320601527816662,
      "grad_norm": 0.12362243980169296,
      "learning_rate": 2.8173285872361987e-06,
      "loss": 0.0609,
      "step": 141620
    },
    {
      "epoch": 2.832260128784546,
      "grad_norm": 0.17110410332679749,
      "learning_rate": 2.813995653854871e-06,
      "loss": 0.0467,
      "step": 141630
    },
    {
      "epoch": 2.8324601047874256,
      "grad_norm": 0.1975223422050476,
      "learning_rate": 2.8106627204735434e-06,
      "loss": 0.0663,
      "step": 141640
    },
    {
      "epoch": 2.8326600807903053,
      "grad_norm": 0.09970443695783615,
      "learning_rate": 2.8073297870922156e-06,
      "loss": 0.0731,
      "step": 141650
    },
    {
      "epoch": 2.832860056793185,
      "grad_norm": 0.14175377786159515,
      "learning_rate": 2.803996853710888e-06,
      "loss": 0.0677,
      "step": 141660
    },
    {
      "epoch": 2.833060032796064,
      "grad_norm": 0.2657197415828705,
      "learning_rate": 2.8006639203295607e-06,
      "loss": 0.088,
      "step": 141670
    },
    {
      "epoch": 2.833260008798944,
      "grad_norm": 0.22742709517478943,
      "learning_rate": 2.797330986948233e-06,
      "loss": 0.0875,
      "step": 141680
    },
    {
      "epoch": 2.8334599848018236,
      "grad_norm": 0.19732117652893066,
      "learning_rate": 2.7939980535669055e-06,
      "loss": 0.0599,
      "step": 141690
    },
    {
      "epoch": 2.8336599608047033,
      "grad_norm": 0.17204277217388153,
      "learning_rate": 2.7906651201855776e-06,
      "loss": 0.0734,
      "step": 141700
    },
    {
      "epoch": 2.833859936807583,
      "grad_norm": 0.23027485609054565,
      "learning_rate": 2.7873321868042502e-06,
      "loss": 0.0927,
      "step": 141710
    },
    {
      "epoch": 2.8340599128104627,
      "grad_norm": 0.10381012409925461,
      "learning_rate": 2.7839992534229224e-06,
      "loss": 0.0583,
      "step": 141720
    },
    {
      "epoch": 2.8342598888133423,
      "grad_norm": 0.17824891209602356,
      "learning_rate": 2.780666320041595e-06,
      "loss": 0.1078,
      "step": 141730
    },
    {
      "epoch": 2.834459864816222,
      "grad_norm": 0.09460137784481049,
      "learning_rate": 2.7773333866602675e-06,
      "loss": 0.0399,
      "step": 141740
    },
    {
      "epoch": 2.8346598408191017,
      "grad_norm": 0.19243250787258148,
      "learning_rate": 2.77400045327894e-06,
      "loss": 0.0735,
      "step": 141750
    },
    {
      "epoch": 2.8348598168219814,
      "grad_norm": 0.154161274433136,
      "learning_rate": 2.7706675198976127e-06,
      "loss": 0.0589,
      "step": 141760
    },
    {
      "epoch": 2.835059792824861,
      "grad_norm": 0.20760737359523773,
      "learning_rate": 2.767334586516285e-06,
      "loss": 0.1048,
      "step": 141770
    },
    {
      "epoch": 2.835259768827741,
      "grad_norm": 0.2744365930557251,
      "learning_rate": 2.7640016531349574e-06,
      "loss": 0.0854,
      "step": 141780
    },
    {
      "epoch": 2.8354597448306205,
      "grad_norm": 0.09497998654842377,
      "learning_rate": 2.7606687197536296e-06,
      "loss": 0.083,
      "step": 141790
    },
    {
      "epoch": 2.8356597208335,
      "grad_norm": 0.1191384568810463,
      "learning_rate": 2.757335786372302e-06,
      "loss": 0.0583,
      "step": 141800
    },
    {
      "epoch": 2.83585969683638,
      "grad_norm": 0.2872332036495209,
      "learning_rate": 2.7540028529909747e-06,
      "loss": 0.0796,
      "step": 141810
    },
    {
      "epoch": 2.8360596728392595,
      "grad_norm": 0.15166670083999634,
      "learning_rate": 2.750669919609647e-06,
      "loss": 0.0762,
      "step": 141820
    },
    {
      "epoch": 2.836259648842139,
      "grad_norm": 0.24220122396945953,
      "learning_rate": 2.7473369862283195e-06,
      "loss": 0.0759,
      "step": 141830
    },
    {
      "epoch": 2.8364596248450185,
      "grad_norm": 0.09626708179712296,
      "learning_rate": 2.7440040528469916e-06,
      "loss": 0.0974,
      "step": 141840
    },
    {
      "epoch": 2.836659600847898,
      "grad_norm": 0.18544688820838928,
      "learning_rate": 2.7406711194656642e-06,
      "loss": 0.0481,
      "step": 141850
    },
    {
      "epoch": 2.836859576850778,
      "grad_norm": 0.1443621963262558,
      "learning_rate": 2.7373381860843364e-06,
      "loss": 0.0648,
      "step": 141860
    },
    {
      "epoch": 2.8370595528536575,
      "grad_norm": 0.09977556765079498,
      "learning_rate": 2.734005252703009e-06,
      "loss": 0.0701,
      "step": 141870
    },
    {
      "epoch": 2.837259528856537,
      "grad_norm": 0.07719429582357407,
      "learning_rate": 2.7306723193216815e-06,
      "loss": 0.0836,
      "step": 141880
    },
    {
      "epoch": 2.837459504859417,
      "grad_norm": 0.14416584372520447,
      "learning_rate": 2.727339385940354e-06,
      "loss": 0.0888,
      "step": 141890
    },
    {
      "epoch": 2.8376594808622966,
      "grad_norm": 0.13229043781757355,
      "learning_rate": 2.7240064525590267e-06,
      "loss": 0.0733,
      "step": 141900
    },
    {
      "epoch": 2.8378594568651763,
      "grad_norm": 0.19844107329845428,
      "learning_rate": 2.720673519177699e-06,
      "loss": 0.0859,
      "step": 141910
    },
    {
      "epoch": 2.838059432868056,
      "grad_norm": 0.10510075837373734,
      "learning_rate": 2.7173405857963714e-06,
      "loss": 0.0563,
      "step": 141920
    },
    {
      "epoch": 2.8382594088709356,
      "grad_norm": 0.13156123459339142,
      "learning_rate": 2.7140076524150436e-06,
      "loss": 0.0567,
      "step": 141930
    },
    {
      "epoch": 2.838459384873815,
      "grad_norm": 0.12982074916362762,
      "learning_rate": 2.710674719033716e-06,
      "loss": 0.1004,
      "step": 141940
    },
    {
      "epoch": 2.8386593608766946,
      "grad_norm": 0.08295482397079468,
      "learning_rate": 2.7073417856523888e-06,
      "loss": 0.0686,
      "step": 141950
    },
    {
      "epoch": 2.8388593368795743,
      "grad_norm": 0.08921640366315842,
      "learning_rate": 2.704008852271061e-06,
      "loss": 0.0582,
      "step": 141960
    },
    {
      "epoch": 2.839059312882454,
      "grad_norm": 0.17893552780151367,
      "learning_rate": 2.7006759188897335e-06,
      "loss": 0.0888,
      "step": 141970
    },
    {
      "epoch": 2.8392592888853336,
      "grad_norm": 0.2444477677345276,
      "learning_rate": 2.6973429855084057e-06,
      "loss": 0.0827,
      "step": 141980
    },
    {
      "epoch": 2.8394592648882133,
      "grad_norm": 0.08984293043613434,
      "learning_rate": 2.6940100521270782e-06,
      "loss": 0.0648,
      "step": 141990
    },
    {
      "epoch": 2.839659240891093,
      "grad_norm": 0.09502506256103516,
      "learning_rate": 2.6906771187457504e-06,
      "loss": 0.0707,
      "step": 142000
    },
    {
      "epoch": 2.8398592168939727,
      "grad_norm": 0.10898107290267944,
      "learning_rate": 2.687344185364423e-06,
      "loss": 0.0752,
      "step": 142010
    },
    {
      "epoch": 2.8400591928968524,
      "grad_norm": 0.19789153337478638,
      "learning_rate": 2.684011251983095e-06,
      "loss": 0.0648,
      "step": 142020
    },
    {
      "epoch": 2.840259168899732,
      "grad_norm": 0.1815236210823059,
      "learning_rate": 2.6806783186017677e-06,
      "loss": 0.0792,
      "step": 142030
    },
    {
      "epoch": 2.8404591449026118,
      "grad_norm": 0.1292404979467392,
      "learning_rate": 2.6773453852204403e-06,
      "loss": 0.0665,
      "step": 142040
    },
    {
      "epoch": 2.8406591209054914,
      "grad_norm": 0.15163274109363556,
      "learning_rate": 2.674012451839113e-06,
      "loss": 0.0503,
      "step": 142050
    },
    {
      "epoch": 2.840859096908371,
      "grad_norm": 0.08722682297229767,
      "learning_rate": 2.6706795184577854e-06,
      "loss": 0.0745,
      "step": 142060
    },
    {
      "epoch": 2.841059072911251,
      "grad_norm": 0.0980827659368515,
      "learning_rate": 2.6673465850764576e-06,
      "loss": 0.0781,
      "step": 142070
    },
    {
      "epoch": 2.8412590489141305,
      "grad_norm": 0.27432405948638916,
      "learning_rate": 2.66401365169513e-06,
      "loss": 0.0973,
      "step": 142080
    },
    {
      "epoch": 2.84145902491701,
      "grad_norm": 0.08084516227245331,
      "learning_rate": 2.6606807183138023e-06,
      "loss": 0.0399,
      "step": 142090
    },
    {
      "epoch": 2.84165900091989,
      "grad_norm": 0.2013419270515442,
      "learning_rate": 2.657347784932475e-06,
      "loss": 0.0869,
      "step": 142100
    },
    {
      "epoch": 2.841858976922769,
      "grad_norm": 0.19469863176345825,
      "learning_rate": 2.6540148515511475e-06,
      "loss": 0.0819,
      "step": 142110
    },
    {
      "epoch": 2.842058952925649,
      "grad_norm": 0.10943742841482162,
      "learning_rate": 2.6506819181698197e-06,
      "loss": 0.0877,
      "step": 142120
    },
    {
      "epoch": 2.8422589289285285,
      "grad_norm": 0.19061386585235596,
      "learning_rate": 2.6473489847884922e-06,
      "loss": 0.0668,
      "step": 142130
    },
    {
      "epoch": 2.842458904931408,
      "grad_norm": 0.07868596911430359,
      "learning_rate": 2.6440160514071644e-06,
      "loss": 0.0793,
      "step": 142140
    },
    {
      "epoch": 2.842658880934288,
      "grad_norm": 0.09213023632764816,
      "learning_rate": 2.640683118025837e-06,
      "loss": 0.0394,
      "step": 142150
    },
    {
      "epoch": 2.8428588569371676,
      "grad_norm": 0.08765725791454315,
      "learning_rate": 2.637350184644509e-06,
      "loss": 0.0801,
      "step": 142160
    },
    {
      "epoch": 2.8430588329400472,
      "grad_norm": 0.13353706896305084,
      "learning_rate": 2.6340172512631817e-06,
      "loss": 0.0596,
      "step": 142170
    },
    {
      "epoch": 2.843258808942927,
      "grad_norm": 0.18225827813148499,
      "learning_rate": 2.6306843178818543e-06,
      "loss": 0.1002,
      "step": 142180
    },
    {
      "epoch": 2.8434587849458066,
      "grad_norm": 0.20535224676132202,
      "learning_rate": 2.627351384500527e-06,
      "loss": 0.0818,
      "step": 142190
    },
    {
      "epoch": 2.8436587609486863,
      "grad_norm": 0.28288882970809937,
      "learning_rate": 2.6240184511191995e-06,
      "loss": 0.0737,
      "step": 142200
    },
    {
      "epoch": 2.8438587369515655,
      "grad_norm": 0.06927987188100815,
      "learning_rate": 2.6206855177378716e-06,
      "loss": 0.0805,
      "step": 142210
    },
    {
      "epoch": 2.8440587129544452,
      "grad_norm": 0.2785447835922241,
      "learning_rate": 2.617352584356544e-06,
      "loss": 0.0763,
      "step": 142220
    },
    {
      "epoch": 2.844258688957325,
      "grad_norm": 0.09946922957897186,
      "learning_rate": 2.6140196509752164e-06,
      "loss": 0.0673,
      "step": 142230
    },
    {
      "epoch": 2.8444586649602046,
      "grad_norm": 0.20868892967700958,
      "learning_rate": 2.610686717593889e-06,
      "loss": 0.0517,
      "step": 142240
    },
    {
      "epoch": 2.8446586409630843,
      "grad_norm": 0.23938758671283722,
      "learning_rate": 2.6073537842125615e-06,
      "loss": 0.0814,
      "step": 142250
    },
    {
      "epoch": 2.844858616965964,
      "grad_norm": 0.28433215618133545,
      "learning_rate": 2.6040208508312337e-06,
      "loss": 0.0946,
      "step": 142260
    },
    {
      "epoch": 2.8450585929688437,
      "grad_norm": 0.1873081475496292,
      "learning_rate": 2.6006879174499063e-06,
      "loss": 0.0697,
      "step": 142270
    },
    {
      "epoch": 2.8452585689717234,
      "grad_norm": 0.1191277727484703,
      "learning_rate": 2.5973549840685784e-06,
      "loss": 0.0663,
      "step": 142280
    },
    {
      "epoch": 2.845458544974603,
      "grad_norm": 0.1700008362531662,
      "learning_rate": 2.594022050687251e-06,
      "loss": 0.0779,
      "step": 142290
    },
    {
      "epoch": 2.8456585209774827,
      "grad_norm": 0.06055307760834694,
      "learning_rate": 2.590689117305923e-06,
      "loss": 0.0829,
      "step": 142300
    },
    {
      "epoch": 2.8458584969803624,
      "grad_norm": 0.2371840626001358,
      "learning_rate": 2.5873561839245957e-06,
      "loss": 0.0575,
      "step": 142310
    },
    {
      "epoch": 2.846058472983242,
      "grad_norm": 0.12686274945735931,
      "learning_rate": 2.5840232505432683e-06,
      "loss": 0.09,
      "step": 142320
    },
    {
      "epoch": 2.846258448986122,
      "grad_norm": 0.19025741517543793,
      "learning_rate": 2.5806903171619405e-06,
      "loss": 0.061,
      "step": 142330
    },
    {
      "epoch": 2.8464584249890015,
      "grad_norm": 0.16366173326969147,
      "learning_rate": 2.577357383780613e-06,
      "loss": 0.1298,
      "step": 142340
    },
    {
      "epoch": 2.846658400991881,
      "grad_norm": 0.09271709620952606,
      "learning_rate": 2.5740244503992856e-06,
      "loss": 0.0758,
      "step": 142350
    },
    {
      "epoch": 2.846858376994761,
      "grad_norm": 0.2048896849155426,
      "learning_rate": 2.570691517017958e-06,
      "loss": 0.1016,
      "step": 142360
    },
    {
      "epoch": 2.8470583529976405,
      "grad_norm": 0.13570094108581543,
      "learning_rate": 2.5673585836366304e-06,
      "loss": 0.0604,
      "step": 142370
    },
    {
      "epoch": 2.84725832900052,
      "grad_norm": 0.09854144603013992,
      "learning_rate": 2.564025650255303e-06,
      "loss": 0.0471,
      "step": 142380
    },
    {
      "epoch": 2.8474583050033995,
      "grad_norm": 0.09625247865915298,
      "learning_rate": 2.5606927168739755e-06,
      "loss": 0.0646,
      "step": 142390
    },
    {
      "epoch": 2.847658281006279,
      "grad_norm": 0.177826926112175,
      "learning_rate": 2.5573597834926477e-06,
      "loss": 0.1104,
      "step": 142400
    },
    {
      "epoch": 2.847858257009159,
      "grad_norm": 0.0875026062130928,
      "learning_rate": 2.5540268501113203e-06,
      "loss": 0.0731,
      "step": 142410
    },
    {
      "epoch": 2.8480582330120385,
      "grad_norm": 0.09673674404621124,
      "learning_rate": 2.5506939167299924e-06,
      "loss": 0.0529,
      "step": 142420
    },
    {
      "epoch": 2.848258209014918,
      "grad_norm": 0.1006433516740799,
      "learning_rate": 2.547360983348665e-06,
      "loss": 0.0835,
      "step": 142430
    },
    {
      "epoch": 2.848458185017798,
      "grad_norm": 0.09959202259778976,
      "learning_rate": 2.544028049967337e-06,
      "loss": 0.0806,
      "step": 142440
    },
    {
      "epoch": 2.8486581610206776,
      "grad_norm": 0.049978889524936676,
      "learning_rate": 2.5406951165860097e-06,
      "loss": 0.0739,
      "step": 142450
    },
    {
      "epoch": 2.8488581370235573,
      "grad_norm": 0.05553574487566948,
      "learning_rate": 2.5373621832046823e-06,
      "loss": 0.0836,
      "step": 142460
    },
    {
      "epoch": 2.849058113026437,
      "grad_norm": 0.10461857914924622,
      "learning_rate": 2.5340292498233545e-06,
      "loss": 0.0738,
      "step": 142470
    },
    {
      "epoch": 2.849258089029316,
      "grad_norm": 0.16669122874736786,
      "learning_rate": 2.530696316442027e-06,
      "loss": 0.0753,
      "step": 142480
    },
    {
      "epoch": 2.849458065032196,
      "grad_norm": 0.12693648040294647,
      "learning_rate": 2.5273633830606996e-06,
      "loss": 0.081,
      "step": 142490
    },
    {
      "epoch": 2.8496580410350756,
      "grad_norm": 0.11386849731206894,
      "learning_rate": 2.5240304496793722e-06,
      "loss": 0.0596,
      "step": 142500
    },
    {
      "epoch": 2.8498580170379553,
      "grad_norm": 0.08107289671897888,
      "learning_rate": 2.5206975162980444e-06,
      "loss": 0.0467,
      "step": 142510
    },
    {
      "epoch": 2.850057993040835,
      "grad_norm": 0.2082633525133133,
      "learning_rate": 2.517364582916717e-06,
      "loss": 0.0759,
      "step": 142520
    },
    {
      "epoch": 2.8502579690437146,
      "grad_norm": 0.1264829933643341,
      "learning_rate": 2.514031649535389e-06,
      "loss": 0.0855,
      "step": 142530
    },
    {
      "epoch": 2.8504579450465943,
      "grad_norm": 0.1986088752746582,
      "learning_rate": 2.5106987161540617e-06,
      "loss": 0.0903,
      "step": 142540
    },
    {
      "epoch": 2.850657921049474,
      "grad_norm": 0.0890921875834465,
      "learning_rate": 2.5073657827727343e-06,
      "loss": 0.0404,
      "step": 142550
    },
    {
      "epoch": 2.8508578970523537,
      "grad_norm": 0.2674840986728668,
      "learning_rate": 2.5040328493914064e-06,
      "loss": 0.0715,
      "step": 142560
    },
    {
      "epoch": 2.8510578730552334,
      "grad_norm": 0.11746948957443237,
      "learning_rate": 2.500699916010079e-06,
      "loss": 0.1133,
      "step": 142570
    },
    {
      "epoch": 2.851257849058113,
      "grad_norm": 0.2107754647731781,
      "learning_rate": 2.497366982628751e-06,
      "loss": 0.0752,
      "step": 142580
    },
    {
      "epoch": 2.8514578250609928,
      "grad_norm": 0.12934626638889313,
      "learning_rate": 2.4940340492474237e-06,
      "loss": 0.0775,
      "step": 142590
    },
    {
      "epoch": 2.8516578010638725,
      "grad_norm": 0.19864238798618317,
      "learning_rate": 2.490701115866096e-06,
      "loss": 0.2336,
      "step": 142600
    },
    {
      "epoch": 2.851857777066752,
      "grad_norm": 0.23968255519866943,
      "learning_rate": 2.4873681824847685e-06,
      "loss": 0.0918,
      "step": 142610
    },
    {
      "epoch": 2.852057753069632,
      "grad_norm": 0.07034163922071457,
      "learning_rate": 2.484035249103441e-06,
      "loss": 0.0574,
      "step": 142620
    },
    {
      "epoch": 2.8522577290725115,
      "grad_norm": 0.08436453342437744,
      "learning_rate": 2.4807023157221132e-06,
      "loss": 0.0644,
      "step": 142630
    },
    {
      "epoch": 2.852457705075391,
      "grad_norm": 0.1019786074757576,
      "learning_rate": 2.477369382340786e-06,
      "loss": 0.0684,
      "step": 142640
    },
    {
      "epoch": 2.8526576810782704,
      "grad_norm": 0.20861653983592987,
      "learning_rate": 2.4740364489594584e-06,
      "loss": 0.073,
      "step": 142650
    },
    {
      "epoch": 2.85285765708115,
      "grad_norm": 0.10220323503017426,
      "learning_rate": 2.470703515578131e-06,
      "loss": 0.0707,
      "step": 142660
    },
    {
      "epoch": 2.85305763308403,
      "grad_norm": 0.10150226950645447,
      "learning_rate": 2.467370582196803e-06,
      "loss": 0.0785,
      "step": 142670
    },
    {
      "epoch": 2.8532576090869095,
      "grad_norm": 0.12055229395627975,
      "learning_rate": 2.4640376488154757e-06,
      "loss": 0.0772,
      "step": 142680
    },
    {
      "epoch": 2.853457585089789,
      "grad_norm": 0.20042914152145386,
      "learning_rate": 2.4607047154341483e-06,
      "loss": 0.074,
      "step": 142690
    },
    {
      "epoch": 2.853657561092669,
      "grad_norm": 0.12873685359954834,
      "learning_rate": 2.4573717820528204e-06,
      "loss": 0.0897,
      "step": 142700
    },
    {
      "epoch": 2.8538575370955486,
      "grad_norm": 0.0844235047698021,
      "learning_rate": 2.454038848671493e-06,
      "loss": 0.0804,
      "step": 142710
    },
    {
      "epoch": 2.8540575130984283,
      "grad_norm": 0.2206805795431137,
      "learning_rate": 2.450705915290165e-06,
      "loss": 0.0907,
      "step": 142720
    },
    {
      "epoch": 2.854257489101308,
      "grad_norm": 0.13418914377689362,
      "learning_rate": 2.4473729819088378e-06,
      "loss": 0.0662,
      "step": 142730
    },
    {
      "epoch": 2.8544574651041876,
      "grad_norm": 0.24303025007247925,
      "learning_rate": 2.44404004852751e-06,
      "loss": 0.0785,
      "step": 142740
    },
    {
      "epoch": 2.8546574411070673,
      "grad_norm": 0.0890282541513443,
      "learning_rate": 2.4407071151461825e-06,
      "loss": 0.0389,
      "step": 142750
    },
    {
      "epoch": 2.8548574171099466,
      "grad_norm": 0.21288363635540009,
      "learning_rate": 2.437374181764855e-06,
      "loss": 0.0844,
      "step": 142760
    },
    {
      "epoch": 2.8550573931128262,
      "grad_norm": 0.25713029503822327,
      "learning_rate": 2.4340412483835272e-06,
      "loss": 0.0748,
      "step": 142770
    },
    {
      "epoch": 2.855257369115706,
      "grad_norm": 0.16395319998264313,
      "learning_rate": 2.4307083150022e-06,
      "loss": 0.0974,
      "step": 142780
    },
    {
      "epoch": 2.8554573451185856,
      "grad_norm": 0.1875004768371582,
      "learning_rate": 2.4273753816208724e-06,
      "loss": 0.0686,
      "step": 142790
    },
    {
      "epoch": 2.8556573211214653,
      "grad_norm": 0.23161914944648743,
      "learning_rate": 2.424042448239545e-06,
      "loss": 0.0785,
      "step": 142800
    },
    {
      "epoch": 2.855857297124345,
      "grad_norm": 0.21444036066532135,
      "learning_rate": 2.420709514858217e-06,
      "loss": 0.0713,
      "step": 142810
    },
    {
      "epoch": 2.8560572731272247,
      "grad_norm": 0.28290992975234985,
      "learning_rate": 2.4173765814768897e-06,
      "loss": 0.0885,
      "step": 142820
    },
    {
      "epoch": 2.8562572491301044,
      "grad_norm": 0.17507289350032806,
      "learning_rate": 2.4140436480955623e-06,
      "loss": 0.0932,
      "step": 142830
    },
    {
      "epoch": 2.856457225132984,
      "grad_norm": 0.35703322291374207,
      "learning_rate": 2.4107107147142344e-06,
      "loss": 0.1205,
      "step": 142840
    },
    {
      "epoch": 2.8566572011358637,
      "grad_norm": 0.09157489985227585,
      "learning_rate": 2.407377781332907e-06,
      "loss": 0.0665,
      "step": 142850
    },
    {
      "epoch": 2.8568571771387434,
      "grad_norm": 0.20356561243534088,
      "learning_rate": 2.404044847951579e-06,
      "loss": 0.0678,
      "step": 142860
    },
    {
      "epoch": 2.857057153141623,
      "grad_norm": 0.10806828737258911,
      "learning_rate": 2.4007119145702518e-06,
      "loss": 0.0526,
      "step": 142870
    },
    {
      "epoch": 2.857257129144503,
      "grad_norm": 0.20984332263469696,
      "learning_rate": 2.397378981188924e-06,
      "loss": 0.0481,
      "step": 142880
    },
    {
      "epoch": 2.8574571051473825,
      "grad_norm": 0.1860569417476654,
      "learning_rate": 2.3940460478075965e-06,
      "loss": 0.0783,
      "step": 142890
    },
    {
      "epoch": 2.857657081150262,
      "grad_norm": 0.1675170212984085,
      "learning_rate": 2.390713114426269e-06,
      "loss": 0.0703,
      "step": 142900
    },
    {
      "epoch": 2.857857057153142,
      "grad_norm": 0.10831034928560257,
      "learning_rate": 2.3873801810449412e-06,
      "loss": 0.081,
      "step": 142910
    },
    {
      "epoch": 2.8580570331560216,
      "grad_norm": 0.2000434249639511,
      "learning_rate": 2.384047247663614e-06,
      "loss": 0.0476,
      "step": 142920
    },
    {
      "epoch": 2.858257009158901,
      "grad_norm": 0.0752960592508316,
      "learning_rate": 2.380714314282286e-06,
      "loss": 0.0497,
      "step": 142930
    },
    {
      "epoch": 2.8584569851617805,
      "grad_norm": 0.10127873718738556,
      "learning_rate": 2.3773813809009586e-06,
      "loss": 0.0605,
      "step": 142940
    },
    {
      "epoch": 2.85865696116466,
      "grad_norm": 0.17028646171092987,
      "learning_rate": 2.374048447519631e-06,
      "loss": 0.0489,
      "step": 142950
    },
    {
      "epoch": 2.85885693716754,
      "grad_norm": 0.14669740200042725,
      "learning_rate": 2.3707155141383037e-06,
      "loss": 0.1031,
      "step": 142960
    },
    {
      "epoch": 2.8590569131704195,
      "grad_norm": 0.16945339739322662,
      "learning_rate": 2.367382580756976e-06,
      "loss": 0.0787,
      "step": 142970
    },
    {
      "epoch": 2.8592568891732992,
      "grad_norm": 0.24011217057704926,
      "learning_rate": 2.3640496473756485e-06,
      "loss": 0.0849,
      "step": 142980
    },
    {
      "epoch": 2.859456865176179,
      "grad_norm": 0.11002086102962494,
      "learning_rate": 2.360716713994321e-06,
      "loss": 0.0677,
      "step": 142990
    },
    {
      "epoch": 2.8596568411790586,
      "grad_norm": 0.0648699551820755,
      "learning_rate": 2.357383780612993e-06,
      "loss": 0.0579,
      "step": 143000
    },
    {
      "epoch": 2.8598568171819383,
      "grad_norm": 0.18980486690998077,
      "learning_rate": 2.3540508472316658e-06,
      "loss": 0.0841,
      "step": 143010
    },
    {
      "epoch": 2.860056793184818,
      "grad_norm": 0.19565439224243164,
      "learning_rate": 2.350717913850338e-06,
      "loss": 0.0607,
      "step": 143020
    },
    {
      "epoch": 2.8602567691876972,
      "grad_norm": 0.17108018696308136,
      "learning_rate": 2.3473849804690105e-06,
      "loss": 0.0657,
      "step": 143030
    },
    {
      "epoch": 2.860456745190577,
      "grad_norm": 0.19051067531108856,
      "learning_rate": 2.3440520470876827e-06,
      "loss": 0.081,
      "step": 143040
    },
    {
      "epoch": 2.8606567211934566,
      "grad_norm": 0.12026797235012054,
      "learning_rate": 2.3407191137063553e-06,
      "loss": 0.0559,
      "step": 143050
    },
    {
      "epoch": 2.8608566971963363,
      "grad_norm": 0.11738783866167068,
      "learning_rate": 2.337386180325028e-06,
      "loss": 0.0707,
      "step": 143060
    },
    {
      "epoch": 2.861056673199216,
      "grad_norm": 0.13874778151512146,
      "learning_rate": 2.3340532469437e-06,
      "loss": 0.057,
      "step": 143070
    },
    {
      "epoch": 2.8612566492020957,
      "grad_norm": 0.1507798731327057,
      "learning_rate": 2.3307203135623726e-06,
      "loss": 0.068,
      "step": 143080
    },
    {
      "epoch": 2.8614566252049753,
      "grad_norm": 0.07702891528606415,
      "learning_rate": 2.327387380181045e-06,
      "loss": 0.0472,
      "step": 143090
    },
    {
      "epoch": 2.861656601207855,
      "grad_norm": 0.07371187210083008,
      "learning_rate": 2.3240544467997177e-06,
      "loss": 0.057,
      "step": 143100
    },
    {
      "epoch": 2.8618565772107347,
      "grad_norm": 0.2840063273906708,
      "learning_rate": 2.32072151341839e-06,
      "loss": 0.0778,
      "step": 143110
    },
    {
      "epoch": 2.8620565532136144,
      "grad_norm": 0.10800888389348984,
      "learning_rate": 2.3173885800370625e-06,
      "loss": 0.0471,
      "step": 143120
    },
    {
      "epoch": 2.862256529216494,
      "grad_norm": 0.22027717530727386,
      "learning_rate": 2.314055646655735e-06,
      "loss": 0.0988,
      "step": 143130
    },
    {
      "epoch": 2.862456505219374,
      "grad_norm": 0.1559312492609024,
      "learning_rate": 2.310722713274407e-06,
      "loss": 0.0541,
      "step": 143140
    },
    {
      "epoch": 2.8626564812222535,
      "grad_norm": 0.13491274416446686,
      "learning_rate": 2.3073897798930798e-06,
      "loss": 0.0408,
      "step": 143150
    },
    {
      "epoch": 2.862856457225133,
      "grad_norm": 0.172907754778862,
      "learning_rate": 2.304056846511752e-06,
      "loss": 0.0874,
      "step": 143160
    },
    {
      "epoch": 2.863056433228013,
      "grad_norm": 0.0646301731467247,
      "learning_rate": 2.3007239131304245e-06,
      "loss": 0.1096,
      "step": 143170
    },
    {
      "epoch": 2.8632564092308925,
      "grad_norm": 0.14275504648685455,
      "learning_rate": 2.2973909797490967e-06,
      "loss": 0.0957,
      "step": 143180
    },
    {
      "epoch": 2.863456385233772,
      "grad_norm": 0.18163883686065674,
      "learning_rate": 2.2940580463677693e-06,
      "loss": 0.0891,
      "step": 143190
    },
    {
      "epoch": 2.8636563612366515,
      "grad_norm": 0.06193159893155098,
      "learning_rate": 2.290725112986442e-06,
      "loss": 0.0558,
      "step": 143200
    },
    {
      "epoch": 2.863856337239531,
      "grad_norm": 0.1410292536020279,
      "learning_rate": 2.287392179605114e-06,
      "loss": 0.0571,
      "step": 143210
    },
    {
      "epoch": 2.864056313242411,
      "grad_norm": 0.08526959270238876,
      "learning_rate": 2.2840592462237866e-06,
      "loss": 0.0851,
      "step": 143220
    },
    {
      "epoch": 2.8642562892452905,
      "grad_norm": 0.1703910082578659,
      "learning_rate": 2.2807263128424587e-06,
      "loss": 0.0689,
      "step": 143230
    },
    {
      "epoch": 2.86445626524817,
      "grad_norm": 0.08278532326221466,
      "learning_rate": 2.2773933794611313e-06,
      "loss": 0.0527,
      "step": 143240
    },
    {
      "epoch": 2.86465624125105,
      "grad_norm": 0.12307798862457275,
      "learning_rate": 2.274060446079804e-06,
      "loss": 0.0548,
      "step": 143250
    },
    {
      "epoch": 2.8648562172539296,
      "grad_norm": 0.07769429683685303,
      "learning_rate": 2.2707275126984765e-06,
      "loss": 0.0847,
      "step": 143260
    },
    {
      "epoch": 2.8650561932568093,
      "grad_norm": 0.18011237680912018,
      "learning_rate": 2.267394579317149e-06,
      "loss": 0.0411,
      "step": 143270
    },
    {
      "epoch": 2.865256169259689,
      "grad_norm": 0.10600020736455917,
      "learning_rate": 2.2640616459358212e-06,
      "loss": 0.0702,
      "step": 143280
    },
    {
      "epoch": 2.8654561452625686,
      "grad_norm": 0.12883003056049347,
      "learning_rate": 2.260728712554494e-06,
      "loss": 0.0657,
      "step": 143290
    },
    {
      "epoch": 2.865656121265448,
      "grad_norm": 0.1150108128786087,
      "learning_rate": 2.257395779173166e-06,
      "loss": 0.0569,
      "step": 143300
    },
    {
      "epoch": 2.8658560972683276,
      "grad_norm": 0.1558324694633484,
      "learning_rate": 2.2540628457918385e-06,
      "loss": 0.072,
      "step": 143310
    },
    {
      "epoch": 2.8660560732712073,
      "grad_norm": 0.11447590589523315,
      "learning_rate": 2.2507299124105107e-06,
      "loss": 0.0398,
      "step": 143320
    },
    {
      "epoch": 2.866256049274087,
      "grad_norm": 0.1770358681678772,
      "learning_rate": 2.2473969790291833e-06,
      "loss": 0.0626,
      "step": 143330
    },
    {
      "epoch": 2.8664560252769666,
      "grad_norm": 0.17282989621162415,
      "learning_rate": 2.244064045647856e-06,
      "loss": 0.0627,
      "step": 143340
    },
    {
      "epoch": 2.8666560012798463,
      "grad_norm": 0.10565075278282166,
      "learning_rate": 2.240731112266528e-06,
      "loss": 0.05,
      "step": 143350
    },
    {
      "epoch": 2.866855977282726,
      "grad_norm": 0.1417955905199051,
      "learning_rate": 2.2373981788852006e-06,
      "loss": 0.059,
      "step": 143360
    },
    {
      "epoch": 2.8670559532856057,
      "grad_norm": 0.27780625224113464,
      "learning_rate": 2.2340652455038727e-06,
      "loss": 0.0952,
      "step": 143370
    },
    {
      "epoch": 2.8672559292884854,
      "grad_norm": 0.16924211382865906,
      "learning_rate": 2.2307323121225453e-06,
      "loss": 0.1317,
      "step": 143380
    },
    {
      "epoch": 2.867455905291365,
      "grad_norm": 0.2116418033838272,
      "learning_rate": 2.227399378741218e-06,
      "loss": 0.0853,
      "step": 143390
    },
    {
      "epoch": 2.8676558812942448,
      "grad_norm": 0.20046202838420868,
      "learning_rate": 2.2240664453598905e-06,
      "loss": 0.0921,
      "step": 143400
    },
    {
      "epoch": 2.8678558572971244,
      "grad_norm": 0.17419378459453583,
      "learning_rate": 2.2207335119785626e-06,
      "loss": 0.075,
      "step": 143410
    },
    {
      "epoch": 2.868055833300004,
      "grad_norm": 0.14975950121879578,
      "learning_rate": 2.2174005785972352e-06,
      "loss": 0.2996,
      "step": 143420
    },
    {
      "epoch": 2.868255809302884,
      "grad_norm": 0.12019713222980499,
      "learning_rate": 2.214067645215908e-06,
      "loss": 0.0916,
      "step": 143430
    },
    {
      "epoch": 2.8684557853057635,
      "grad_norm": 0.11165322363376617,
      "learning_rate": 2.21073471183458e-06,
      "loss": 0.0502,
      "step": 143440
    },
    {
      "epoch": 2.868655761308643,
      "grad_norm": 0.06979411840438843,
      "learning_rate": 2.2074017784532525e-06,
      "loss": 0.0912,
      "step": 143450
    },
    {
      "epoch": 2.868855737311523,
      "grad_norm": 0.2015158087015152,
      "learning_rate": 2.2040688450719247e-06,
      "loss": 0.0675,
      "step": 143460
    },
    {
      "epoch": 2.869055713314402,
      "grad_norm": 0.275833398103714,
      "learning_rate": 2.2007359116905973e-06,
      "loss": 0.0596,
      "step": 143470
    },
    {
      "epoch": 2.869255689317282,
      "grad_norm": 0.2540273070335388,
      "learning_rate": 2.1974029783092694e-06,
      "loss": 0.0484,
      "step": 143480
    },
    {
      "epoch": 2.8694556653201615,
      "grad_norm": 0.15058107674121857,
      "learning_rate": 2.194070044927942e-06,
      "loss": 0.0712,
      "step": 143490
    },
    {
      "epoch": 2.869655641323041,
      "grad_norm": 0.18393823504447937,
      "learning_rate": 2.1907371115466146e-06,
      "loss": 0.0504,
      "step": 143500
    },
    {
      "epoch": 2.869855617325921,
      "grad_norm": 0.1475261151790619,
      "learning_rate": 2.1874041781652868e-06,
      "loss": 0.0637,
      "step": 143510
    },
    {
      "epoch": 2.8700555933288006,
      "grad_norm": 0.06519784778356552,
      "learning_rate": 2.1840712447839593e-06,
      "loss": 0.0521,
      "step": 143520
    },
    {
      "epoch": 2.8702555693316802,
      "grad_norm": 0.07391791045665741,
      "learning_rate": 2.1807383114026315e-06,
      "loss": 0.0559,
      "step": 143530
    },
    {
      "epoch": 2.87045554533456,
      "grad_norm": 0.08578044176101685,
      "learning_rate": 2.177405378021304e-06,
      "loss": 0.046,
      "step": 143540
    },
    {
      "epoch": 2.8706555213374396,
      "grad_norm": 0.0874147117137909,
      "learning_rate": 2.1740724446399767e-06,
      "loss": 0.045,
      "step": 143550
    },
    {
      "epoch": 2.8708554973403193,
      "grad_norm": 0.13046658039093018,
      "learning_rate": 2.1707395112586492e-06,
      "loss": 0.0762,
      "step": 143560
    },
    {
      "epoch": 2.8710554733431985,
      "grad_norm": 0.1742514818906784,
      "learning_rate": 2.167406577877322e-06,
      "loss": 0.0811,
      "step": 143570
    },
    {
      "epoch": 2.8712554493460782,
      "grad_norm": 0.10896646976470947,
      "learning_rate": 2.164073644495994e-06,
      "loss": 0.0526,
      "step": 143580
    },
    {
      "epoch": 2.871455425348958,
      "grad_norm": 0.20697526633739471,
      "learning_rate": 2.1607407111146666e-06,
      "loss": 0.0734,
      "step": 143590
    },
    {
      "epoch": 2.8716554013518376,
      "grad_norm": 0.1408422887325287,
      "learning_rate": 2.1574077777333387e-06,
      "loss": 0.0282,
      "step": 143600
    },
    {
      "epoch": 2.8718553773547173,
      "grad_norm": 0.09831628203392029,
      "learning_rate": 2.1540748443520113e-06,
      "loss": 0.0993,
      "step": 143610
    },
    {
      "epoch": 2.872055353357597,
      "grad_norm": 0.09009584784507751,
      "learning_rate": 2.1507419109706834e-06,
      "loss": 0.071,
      "step": 143620
    },
    {
      "epoch": 2.8722553293604767,
      "grad_norm": 0.2708292305469513,
      "learning_rate": 2.147408977589356e-06,
      "loss": 0.0959,
      "step": 143630
    },
    {
      "epoch": 2.8724553053633564,
      "grad_norm": 0.21382810175418854,
      "learning_rate": 2.1440760442080286e-06,
      "loss": 0.0858,
      "step": 143640
    },
    {
      "epoch": 2.872655281366236,
      "grad_norm": 0.08929500728845596,
      "learning_rate": 2.1407431108267008e-06,
      "loss": 0.084,
      "step": 143650
    },
    {
      "epoch": 2.8728552573691157,
      "grad_norm": 0.11251921206712723,
      "learning_rate": 2.1374101774453733e-06,
      "loss": 0.0688,
      "step": 143660
    },
    {
      "epoch": 2.8730552333719954,
      "grad_norm": 0.18843726813793182,
      "learning_rate": 2.1340772440640455e-06,
      "loss": 0.0809,
      "step": 143670
    },
    {
      "epoch": 2.873255209374875,
      "grad_norm": 0.2269257754087448,
      "learning_rate": 2.130744310682718e-06,
      "loss": 0.1004,
      "step": 143680
    },
    {
      "epoch": 2.873455185377755,
      "grad_norm": 0.17891669273376465,
      "learning_rate": 2.1274113773013907e-06,
      "loss": 0.0676,
      "step": 143690
    },
    {
      "epoch": 2.8736551613806345,
      "grad_norm": 0.06705883145332336,
      "learning_rate": 2.1240784439200632e-06,
      "loss": 0.0513,
      "step": 143700
    },
    {
      "epoch": 2.873855137383514,
      "grad_norm": 0.1304602175951004,
      "learning_rate": 2.120745510538736e-06,
      "loss": 0.0512,
      "step": 143710
    },
    {
      "epoch": 2.874055113386394,
      "grad_norm": 0.06695795804262161,
      "learning_rate": 2.117412577157408e-06,
      "loss": 0.0673,
      "step": 143720
    },
    {
      "epoch": 2.8742550893892735,
      "grad_norm": 0.19851535558700562,
      "learning_rate": 2.1140796437760806e-06,
      "loss": 0.0701,
      "step": 143730
    },
    {
      "epoch": 2.874455065392153,
      "grad_norm": 0.09174640476703644,
      "learning_rate": 2.1107467103947527e-06,
      "loss": 0.0926,
      "step": 143740
    },
    {
      "epoch": 2.8746550413950325,
      "grad_norm": 0.13723412156105042,
      "learning_rate": 2.1074137770134253e-06,
      "loss": 0.0347,
      "step": 143750
    },
    {
      "epoch": 2.874855017397912,
      "grad_norm": 0.08019988238811493,
      "learning_rate": 2.1040808436320975e-06,
      "loss": 0.0686,
      "step": 143760
    },
    {
      "epoch": 2.875054993400792,
      "grad_norm": 0.23037052154541016,
      "learning_rate": 2.10074791025077e-06,
      "loss": 0.0946,
      "step": 143770
    },
    {
      "epoch": 2.8752549694036715,
      "grad_norm": 0.08713032305240631,
      "learning_rate": 2.0974149768694426e-06,
      "loss": 0.0662,
      "step": 143780
    },
    {
      "epoch": 2.875454945406551,
      "grad_norm": 0.08613487333059311,
      "learning_rate": 2.0940820434881148e-06,
      "loss": 0.0741,
      "step": 143790
    },
    {
      "epoch": 2.875654921409431,
      "grad_norm": 0.1577751189470291,
      "learning_rate": 2.0907491101067874e-06,
      "loss": 0.091,
      "step": 143800
    },
    {
      "epoch": 2.8758548974123106,
      "grad_norm": 0.08545661717653275,
      "learning_rate": 2.0874161767254595e-06,
      "loss": 0.0686,
      "step": 143810
    },
    {
      "epoch": 2.8760548734151903,
      "grad_norm": 0.23845481872558594,
      "learning_rate": 2.084083243344132e-06,
      "loss": 0.0767,
      "step": 143820
    },
    {
      "epoch": 2.87625484941807,
      "grad_norm": 0.22002829611301422,
      "learning_rate": 2.0810836033009375e-06,
      "loss": 0.2378,
      "step": 143830
    },
    {
      "epoch": 2.876454825420949,
      "grad_norm": 0.22418496012687683,
      "learning_rate": 2.07775066991961e-06,
      "loss": 0.0717,
      "step": 143840
    },
    {
      "epoch": 2.876654801423829,
      "grad_norm": 0.10603143274784088,
      "learning_rate": 2.074417736538282e-06,
      "loss": 0.0741,
      "step": 143850
    },
    {
      "epoch": 2.8768547774267086,
      "grad_norm": 0.17717322707176208,
      "learning_rate": 2.0710848031569548e-06,
      "loss": 0.0657,
      "step": 143860
    },
    {
      "epoch": 2.8770547534295883,
      "grad_norm": 0.18074627220630646,
      "learning_rate": 2.067751869775627e-06,
      "loss": 0.0994,
      "step": 143870
    },
    {
      "epoch": 2.877254729432468,
      "grad_norm": 0.16800983250141144,
      "learning_rate": 2.0644189363942995e-06,
      "loss": 0.0512,
      "step": 143880
    },
    {
      "epoch": 2.8774547054353476,
      "grad_norm": 0.2546341121196747,
      "learning_rate": 2.0610860030129717e-06,
      "loss": 0.0725,
      "step": 143890
    },
    {
      "epoch": 2.8776546814382273,
      "grad_norm": 0.1525905430316925,
      "learning_rate": 2.0577530696316442e-06,
      "loss": 0.0875,
      "step": 143900
    },
    {
      "epoch": 2.877854657441107,
      "grad_norm": 0.11870186030864716,
      "learning_rate": 2.054420136250317e-06,
      "loss": 0.0443,
      "step": 143910
    },
    {
      "epoch": 2.8780546334439867,
      "grad_norm": 0.11187685281038284,
      "learning_rate": 2.051087202868989e-06,
      "loss": 0.0494,
      "step": 143920
    },
    {
      "epoch": 2.8782546094468664,
      "grad_norm": 0.1359865814447403,
      "learning_rate": 2.0477542694876616e-06,
      "loss": 0.0719,
      "step": 143930
    },
    {
      "epoch": 2.878454585449746,
      "grad_norm": 0.21130603551864624,
      "learning_rate": 2.0444213361063337e-06,
      "loss": 0.0874,
      "step": 143940
    },
    {
      "epoch": 2.8786545614526258,
      "grad_norm": 0.12731021642684937,
      "learning_rate": 2.0410884027250063e-06,
      "loss": 0.0774,
      "step": 143950
    },
    {
      "epoch": 2.8788545374555055,
      "grad_norm": 0.15027308464050293,
      "learning_rate": 2.037755469343679e-06,
      "loss": 0.0728,
      "step": 143960
    },
    {
      "epoch": 2.879054513458385,
      "grad_norm": 0.1014484390616417,
      "learning_rate": 2.0344225359623515e-06,
      "loss": 0.0521,
      "step": 143970
    },
    {
      "epoch": 2.879254489461265,
      "grad_norm": 0.1552208960056305,
      "learning_rate": 2.031089602581024e-06,
      "loss": 0.0682,
      "step": 143980
    },
    {
      "epoch": 2.8794544654641445,
      "grad_norm": 0.16332925856113434,
      "learning_rate": 2.027756669199696e-06,
      "loss": 0.0691,
      "step": 143990
    },
    {
      "epoch": 2.879654441467024,
      "grad_norm": 0.20061469078063965,
      "learning_rate": 2.0244237358183688e-06,
      "loss": 0.1692,
      "step": 144000
    },
    {
      "epoch": 2.8798544174699034,
      "grad_norm": 0.10136307030916214,
      "learning_rate": 2.021090802437041e-06,
      "loss": 0.1204,
      "step": 144010
    },
    {
      "epoch": 2.880054393472783,
      "grad_norm": 0.21555352210998535,
      "learning_rate": 2.0177578690557135e-06,
      "loss": 0.0758,
      "step": 144020
    },
    {
      "epoch": 2.880254369475663,
      "grad_norm": 0.13441449403762817,
      "learning_rate": 2.0144249356743857e-06,
      "loss": 0.0897,
      "step": 144030
    },
    {
      "epoch": 2.8804543454785425,
      "grad_norm": 0.20548374950885773,
      "learning_rate": 2.0110920022930583e-06,
      "loss": 0.0736,
      "step": 144040
    },
    {
      "epoch": 2.880654321481422,
      "grad_norm": 0.09238329529762268,
      "learning_rate": 2.0077590689117304e-06,
      "loss": 0.0781,
      "step": 144050
    },
    {
      "epoch": 2.880854297484302,
      "grad_norm": 0.2482992261648178,
      "learning_rate": 2.004426135530403e-06,
      "loss": 0.0905,
      "step": 144060
    },
    {
      "epoch": 2.8810542734871816,
      "grad_norm": 0.08799491822719574,
      "learning_rate": 2.0010932021490756e-06,
      "loss": 0.0525,
      "step": 144070
    },
    {
      "epoch": 2.8812542494900613,
      "grad_norm": 0.08849672228097916,
      "learning_rate": 1.9977602687677477e-06,
      "loss": 0.05,
      "step": 144080
    },
    {
      "epoch": 2.881454225492941,
      "grad_norm": 0.21988096833229065,
      "learning_rate": 1.9944273353864203e-06,
      "loss": 0.0579,
      "step": 144090
    },
    {
      "epoch": 2.8816542014958206,
      "grad_norm": 0.11043654382228851,
      "learning_rate": 1.991094402005093e-06,
      "loss": 0.0855,
      "step": 144100
    },
    {
      "epoch": 2.8818541774987003,
      "grad_norm": 0.07434916496276855,
      "learning_rate": 1.9877614686237655e-06,
      "loss": 0.0468,
      "step": 144110
    },
    {
      "epoch": 2.8820541535015796,
      "grad_norm": 0.13694016635417938,
      "learning_rate": 1.9844285352424376e-06,
      "loss": 0.0543,
      "step": 144120
    },
    {
      "epoch": 2.8822541295044593,
      "grad_norm": 0.27241554856300354,
      "learning_rate": 1.9810956018611102e-06,
      "loss": 0.0926,
      "step": 144130
    },
    {
      "epoch": 2.882454105507339,
      "grad_norm": 0.09203088283538818,
      "learning_rate": 1.977762668479783e-06,
      "loss": 0.0705,
      "step": 144140
    },
    {
      "epoch": 2.8826540815102186,
      "grad_norm": 0.1860848069190979,
      "learning_rate": 1.974429735098455e-06,
      "loss": 0.1005,
      "step": 144150
    },
    {
      "epoch": 2.8828540575130983,
      "grad_norm": 0.10916215926408768,
      "learning_rate": 1.9710968017171275e-06,
      "loss": 0.0569,
      "step": 144160
    },
    {
      "epoch": 2.883054033515978,
      "grad_norm": 0.18982666730880737,
      "learning_rate": 1.9677638683357997e-06,
      "loss": 0.0585,
      "step": 144170
    },
    {
      "epoch": 2.8832540095188577,
      "grad_norm": 0.26345863938331604,
      "learning_rate": 1.9644309349544723e-06,
      "loss": 0.0761,
      "step": 144180
    },
    {
      "epoch": 2.8834539855217374,
      "grad_norm": 0.22639764845371246,
      "learning_rate": 1.9610980015731444e-06,
      "loss": 0.0554,
      "step": 144190
    },
    {
      "epoch": 2.883653961524617,
      "grad_norm": 0.1430327594280243,
      "learning_rate": 1.957765068191817e-06,
      "loss": 0.0473,
      "step": 144200
    },
    {
      "epoch": 2.8838539375274967,
      "grad_norm": 0.08900827169418335,
      "learning_rate": 1.9544321348104896e-06,
      "loss": 0.0928,
      "step": 144210
    },
    {
      "epoch": 2.8840539135303764,
      "grad_norm": 0.08746406435966492,
      "learning_rate": 1.9510992014291617e-06,
      "loss": 0.0695,
      "step": 144220
    },
    {
      "epoch": 2.884253889533256,
      "grad_norm": 0.15215541422367096,
      "learning_rate": 1.9477662680478343e-06,
      "loss": 0.0963,
      "step": 144230
    },
    {
      "epoch": 2.884453865536136,
      "grad_norm": 0.16098341345787048,
      "learning_rate": 1.9444333346665065e-06,
      "loss": 0.061,
      "step": 144240
    },
    {
      "epoch": 2.8846538415390155,
      "grad_norm": 0.12941837310791016,
      "learning_rate": 1.941100401285179e-06,
      "loss": 0.0898,
      "step": 144250
    },
    {
      "epoch": 2.884853817541895,
      "grad_norm": 0.2138221561908722,
      "learning_rate": 1.9377674679038516e-06,
      "loss": 0.0843,
      "step": 144260
    },
    {
      "epoch": 2.885053793544775,
      "grad_norm": 0.13006043434143066,
      "learning_rate": 1.9344345345225242e-06,
      "loss": 0.0979,
      "step": 144270
    },
    {
      "epoch": 2.8852537695476546,
      "grad_norm": 0.1802382618188858,
      "learning_rate": 1.931101601141197e-06,
      "loss": 0.065,
      "step": 144280
    },
    {
      "epoch": 2.885453745550534,
      "grad_norm": 0.24080821871757507,
      "learning_rate": 1.927768667759869e-06,
      "loss": 0.0712,
      "step": 144290
    },
    {
      "epoch": 2.8856537215534135,
      "grad_norm": 0.038954298943281174,
      "learning_rate": 1.9244357343785415e-06,
      "loss": 0.0721,
      "step": 144300
    },
    {
      "epoch": 2.885853697556293,
      "grad_norm": 0.23450089991092682,
      "learning_rate": 1.9211028009972137e-06,
      "loss": 0.0686,
      "step": 144310
    },
    {
      "epoch": 2.886053673559173,
      "grad_norm": 0.21243689954280853,
      "learning_rate": 1.9177698676158863e-06,
      "loss": 0.0653,
      "step": 144320
    },
    {
      "epoch": 2.8862536495620525,
      "grad_norm": 0.14234252274036407,
      "learning_rate": 1.9144369342345584e-06,
      "loss": 0.0548,
      "step": 144330
    },
    {
      "epoch": 2.8864536255649322,
      "grad_norm": 0.1851615458726883,
      "learning_rate": 1.911104000853231e-06,
      "loss": 0.097,
      "step": 144340
    },
    {
      "epoch": 2.886653601567812,
      "grad_norm": 0.13024833798408508,
      "learning_rate": 1.9077710674719036e-06,
      "loss": 0.0774,
      "step": 144350
    },
    {
      "epoch": 2.8868535775706916,
      "grad_norm": 0.21007254719734192,
      "learning_rate": 1.9044381340905758e-06,
      "loss": 0.0841,
      "step": 144360
    },
    {
      "epoch": 2.8870535535735713,
      "grad_norm": 0.1517937034368515,
      "learning_rate": 1.9011052007092483e-06,
      "loss": 0.0892,
      "step": 144370
    },
    {
      "epoch": 2.887253529576451,
      "grad_norm": 0.23989298939704895,
      "learning_rate": 1.8977722673279207e-06,
      "loss": 0.1095,
      "step": 144380
    },
    {
      "epoch": 2.8874535055793302,
      "grad_norm": 0.11363846063613892,
      "learning_rate": 1.8944393339465933e-06,
      "loss": 0.0661,
      "step": 144390
    },
    {
      "epoch": 2.88765348158221,
      "grad_norm": 0.08258440345525742,
      "learning_rate": 1.8911064005652654e-06,
      "loss": 0.045,
      "step": 144400
    },
    {
      "epoch": 2.8878534575850896,
      "grad_norm": 0.2438589632511139,
      "learning_rate": 1.887773467183938e-06,
      "loss": 0.0948,
      "step": 144410
    },
    {
      "epoch": 2.8880534335879693,
      "grad_norm": 0.1610175520181656,
      "learning_rate": 1.8844405338026106e-06,
      "loss": 0.0422,
      "step": 144420
    },
    {
      "epoch": 2.888253409590849,
      "grad_norm": 0.113077811896801,
      "learning_rate": 1.8811076004212828e-06,
      "loss": 0.0636,
      "step": 144430
    },
    {
      "epoch": 2.8884533855937287,
      "grad_norm": 0.10540957748889923,
      "learning_rate": 1.8777746670399553e-06,
      "loss": 0.07,
      "step": 144440
    },
    {
      "epoch": 2.8886533615966083,
      "grad_norm": 0.10777630656957626,
      "learning_rate": 1.8744417336586277e-06,
      "loss": 0.0707,
      "step": 144450
    },
    {
      "epoch": 2.888853337599488,
      "grad_norm": 0.1246829405426979,
      "learning_rate": 1.8711088002773003e-06,
      "loss": 0.0724,
      "step": 144460
    },
    {
      "epoch": 2.8890533136023677,
      "grad_norm": 0.19346193969249725,
      "learning_rate": 1.8677758668959724e-06,
      "loss": 0.0881,
      "step": 144470
    },
    {
      "epoch": 2.8892532896052474,
      "grad_norm": 0.13405758142471313,
      "learning_rate": 1.864442933514645e-06,
      "loss": 0.0831,
      "step": 144480
    },
    {
      "epoch": 2.889453265608127,
      "grad_norm": 0.10320497304201126,
      "learning_rate": 1.8611100001333172e-06,
      "loss": 0.0619,
      "step": 144490
    },
    {
      "epoch": 2.889653241611007,
      "grad_norm": 0.09570793062448502,
      "learning_rate": 1.8577770667519898e-06,
      "loss": 0.064,
      "step": 144500
    },
    {
      "epoch": 2.8898532176138865,
      "grad_norm": 0.29893627762794495,
      "learning_rate": 1.8544441333706623e-06,
      "loss": 0.0568,
      "step": 144510
    },
    {
      "epoch": 2.890053193616766,
      "grad_norm": 0.06330113112926483,
      "learning_rate": 1.8511111999893347e-06,
      "loss": 0.0601,
      "step": 144520
    },
    {
      "epoch": 2.890253169619646,
      "grad_norm": 0.15739989280700684,
      "learning_rate": 1.8477782666080073e-06,
      "loss": 0.0722,
      "step": 144530
    },
    {
      "epoch": 2.8904531456225255,
      "grad_norm": 0.10933373123407364,
      "learning_rate": 1.8444453332266795e-06,
      "loss": 0.0762,
      "step": 144540
    },
    {
      "epoch": 2.890653121625405,
      "grad_norm": 0.09689368307590485,
      "learning_rate": 1.841112399845352e-06,
      "loss": 0.0552,
      "step": 144550
    },
    {
      "epoch": 2.8908530976282845,
      "grad_norm": 0.09731177985668182,
      "learning_rate": 1.8377794664640242e-06,
      "loss": 0.0873,
      "step": 144560
    },
    {
      "epoch": 2.891053073631164,
      "grad_norm": 0.12219271063804626,
      "learning_rate": 1.8344465330826968e-06,
      "loss": 0.0638,
      "step": 144570
    },
    {
      "epoch": 2.891253049634044,
      "grad_norm": 0.14710523188114166,
      "learning_rate": 1.8311135997013693e-06,
      "loss": 0.0784,
      "step": 144580
    },
    {
      "epoch": 2.8914530256369235,
      "grad_norm": 0.08649076521396637,
      "learning_rate": 1.8277806663200417e-06,
      "loss": 0.0809,
      "step": 144590
    },
    {
      "epoch": 2.891653001639803,
      "grad_norm": 0.15525387227535248,
      "learning_rate": 1.8244477329387143e-06,
      "loss": 0.0687,
      "step": 144600
    },
    {
      "epoch": 2.891852977642683,
      "grad_norm": 0.18434147536754608,
      "learning_rate": 1.8211147995573865e-06,
      "loss": 0.0642,
      "step": 144610
    },
    {
      "epoch": 2.8920529536455626,
      "grad_norm": 0.17887069284915924,
      "learning_rate": 1.817781866176059e-06,
      "loss": 0.082,
      "step": 144620
    },
    {
      "epoch": 2.8922529296484423,
      "grad_norm": 0.15394435822963715,
      "learning_rate": 1.8144489327947312e-06,
      "loss": 0.0608,
      "step": 144630
    },
    {
      "epoch": 2.892452905651322,
      "grad_norm": 0.21837379038333893,
      "learning_rate": 1.8111159994134038e-06,
      "loss": 0.0583,
      "step": 144640
    },
    {
      "epoch": 2.8926528816542016,
      "grad_norm": 0.07073765248060226,
      "learning_rate": 1.8077830660320764e-06,
      "loss": 0.0602,
      "step": 144650
    },
    {
      "epoch": 2.892852857657081,
      "grad_norm": 0.11529304087162018,
      "learning_rate": 1.8044501326507485e-06,
      "loss": 0.0526,
      "step": 144660
    },
    {
      "epoch": 2.8930528336599606,
      "grad_norm": 0.1462143361568451,
      "learning_rate": 1.801117199269421e-06,
      "loss": 0.0513,
      "step": 144670
    },
    {
      "epoch": 2.8932528096628403,
      "grad_norm": 0.12512950599193573,
      "learning_rate": 1.7977842658880935e-06,
      "loss": 0.0735,
      "step": 144680
    },
    {
      "epoch": 2.89345278566572,
      "grad_norm": 0.10131774097681046,
      "learning_rate": 1.794451332506766e-06,
      "loss": 0.0691,
      "step": 144690
    },
    {
      "epoch": 2.8936527616685996,
      "grad_norm": 0.20957140624523163,
      "learning_rate": 1.7911183991254382e-06,
      "loss": 0.0798,
      "step": 144700
    },
    {
      "epoch": 2.8938527376714793,
      "grad_norm": 0.18945065140724182,
      "learning_rate": 1.7877854657441108e-06,
      "loss": 0.0683,
      "step": 144710
    },
    {
      "epoch": 2.894052713674359,
      "grad_norm": 0.08997755497694016,
      "learning_rate": 1.7844525323627834e-06,
      "loss": 0.0518,
      "step": 144720
    },
    {
      "epoch": 2.8942526896772387,
      "grad_norm": 0.1291726529598236,
      "learning_rate": 1.7811195989814555e-06,
      "loss": 0.064,
      "step": 144730
    },
    {
      "epoch": 2.8944526656801184,
      "grad_norm": 0.12860649824142456,
      "learning_rate": 1.777786665600128e-06,
      "loss": 0.0429,
      "step": 144740
    },
    {
      "epoch": 2.894652641682998,
      "grad_norm": 0.14298047125339508,
      "learning_rate": 1.7744537322188005e-06,
      "loss": 0.0726,
      "step": 144750
    },
    {
      "epoch": 2.8948526176858778,
      "grad_norm": 0.1340051144361496,
      "learning_rate": 1.771120798837473e-06,
      "loss": 0.0581,
      "step": 144760
    },
    {
      "epoch": 2.8950525936887574,
      "grad_norm": 0.10877860337495804,
      "learning_rate": 1.7677878654561452e-06,
      "loss": 0.0411,
      "step": 144770
    },
    {
      "epoch": 2.895252569691637,
      "grad_norm": 0.19953948259353638,
      "learning_rate": 1.7644549320748178e-06,
      "loss": 0.0569,
      "step": 144780
    },
    {
      "epoch": 2.895452545694517,
      "grad_norm": 0.12704229354858398,
      "learning_rate": 1.7611219986934904e-06,
      "loss": 0.0741,
      "step": 144790
    },
    {
      "epoch": 2.8956525216973965,
      "grad_norm": 0.16079266369342804,
      "learning_rate": 1.7577890653121625e-06,
      "loss": 0.044,
      "step": 144800
    },
    {
      "epoch": 2.895852497700276,
      "grad_norm": 0.27842283248901367,
      "learning_rate": 1.754456131930835e-06,
      "loss": 0.0937,
      "step": 144810
    },
    {
      "epoch": 2.896052473703156,
      "grad_norm": 0.14218463003635406,
      "learning_rate": 1.7511231985495075e-06,
      "loss": 0.0538,
      "step": 144820
    },
    {
      "epoch": 2.896252449706035,
      "grad_norm": 0.13626214861869812,
      "learning_rate": 1.74779026516818e-06,
      "loss": 0.0845,
      "step": 144830
    },
    {
      "epoch": 2.896452425708915,
      "grad_norm": 0.10238576680421829,
      "learning_rate": 1.7444573317868522e-06,
      "loss": 0.0627,
      "step": 144840
    },
    {
      "epoch": 2.8966524017117945,
      "grad_norm": 0.18268153071403503,
      "learning_rate": 1.7411243984055248e-06,
      "loss": 0.0775,
      "step": 144850
    },
    {
      "epoch": 2.896852377714674,
      "grad_norm": 0.1870163232088089,
      "learning_rate": 1.7377914650241974e-06,
      "loss": 0.0493,
      "step": 144860
    },
    {
      "epoch": 2.897052353717554,
      "grad_norm": 0.05382423847913742,
      "learning_rate": 1.7344585316428695e-06,
      "loss": 0.042,
      "step": 144870
    },
    {
      "epoch": 2.8972523297204336,
      "grad_norm": 0.11883334815502167,
      "learning_rate": 1.731125598261542e-06,
      "loss": 0.0798,
      "step": 144880
    },
    {
      "epoch": 2.8974523057233132,
      "grad_norm": 0.17126259207725525,
      "learning_rate": 1.7277926648802145e-06,
      "loss": 0.3081,
      "step": 144890
    },
    {
      "epoch": 2.897652281726193,
      "grad_norm": 0.22086121141910553,
      "learning_rate": 1.724459731498887e-06,
      "loss": 0.0574,
      "step": 144900
    },
    {
      "epoch": 2.8978522577290726,
      "grad_norm": 0.05447573587298393,
      "learning_rate": 1.7211267981175592e-06,
      "loss": 0.0481,
      "step": 144910
    },
    {
      "epoch": 2.8980522337319523,
      "grad_norm": 0.18748588860034943,
      "learning_rate": 1.7177938647362318e-06,
      "loss": 0.0805,
      "step": 144920
    },
    {
      "epoch": 2.8982522097348316,
      "grad_norm": 0.16717234253883362,
      "learning_rate": 1.714460931354904e-06,
      "loss": 0.0974,
      "step": 144930
    },
    {
      "epoch": 2.8984521857377112,
      "grad_norm": 0.09381423145532608,
      "learning_rate": 1.7111279979735765e-06,
      "loss": 0.0862,
      "step": 144940
    },
    {
      "epoch": 2.898652161740591,
      "grad_norm": 0.1692502200603485,
      "learning_rate": 1.7077950645922491e-06,
      "loss": 0.0715,
      "step": 144950
    },
    {
      "epoch": 2.8988521377434706,
      "grad_norm": 0.18268302083015442,
      "learning_rate": 1.7044621312109213e-06,
      "loss": 0.0975,
      "step": 144960
    },
    {
      "epoch": 2.8990521137463503,
      "grad_norm": 0.08808795362710953,
      "learning_rate": 1.7011291978295938e-06,
      "loss": 0.0824,
      "step": 144970
    },
    {
      "epoch": 2.89925208974923,
      "grad_norm": 0.07782654464244843,
      "learning_rate": 1.6977962644482662e-06,
      "loss": 0.0787,
      "step": 144980
    },
    {
      "epoch": 2.8994520657521097,
      "grad_norm": 0.13578017055988312,
      "learning_rate": 1.6944633310669388e-06,
      "loss": 0.0672,
      "step": 144990
    },
    {
      "epoch": 2.8996520417549894,
      "grad_norm": 0.07714249193668365,
      "learning_rate": 1.691130397685611e-06,
      "loss": 0.0779,
      "step": 145000
    },
    {
      "epoch": 2.899852017757869,
      "grad_norm": 0.13049420714378357,
      "learning_rate": 1.6877974643042835e-06,
      "loss": 0.1673,
      "step": 145010
    },
    {
      "epoch": 2.9000519937607487,
      "grad_norm": 0.10739437490701675,
      "learning_rate": 1.6844645309229561e-06,
      "loss": 0.0838,
      "step": 145020
    },
    {
      "epoch": 2.9002519697636284,
      "grad_norm": 0.09933774173259735,
      "learning_rate": 1.6811315975416283e-06,
      "loss": 0.0631,
      "step": 145030
    },
    {
      "epoch": 2.900451945766508,
      "grad_norm": 0.06405787914991379,
      "learning_rate": 1.6777986641603009e-06,
      "loss": 0.0881,
      "step": 145040
    },
    {
      "epoch": 2.900651921769388,
      "grad_norm": 0.17744602262973785,
      "learning_rate": 1.6744657307789732e-06,
      "loss": 0.0836,
      "step": 145050
    },
    {
      "epoch": 2.9008518977722675,
      "grad_norm": 0.1858033835887909,
      "learning_rate": 1.6711327973976458e-06,
      "loss": 0.0588,
      "step": 145060
    },
    {
      "epoch": 2.901051873775147,
      "grad_norm": 0.09613937884569168,
      "learning_rate": 1.667799864016318e-06,
      "loss": 0.0719,
      "step": 145070
    },
    {
      "epoch": 2.901251849778027,
      "grad_norm": 0.0807526484131813,
      "learning_rate": 1.6644669306349905e-06,
      "loss": 0.0584,
      "step": 145080
    },
    {
      "epoch": 2.9014518257809065,
      "grad_norm": 0.2595653831958771,
      "learning_rate": 1.6611339972536631e-06,
      "loss": 0.0608,
      "step": 145090
    },
    {
      "epoch": 2.901651801783786,
      "grad_norm": 0.26391246914863586,
      "learning_rate": 1.6578010638723353e-06,
      "loss": 0.0991,
      "step": 145100
    },
    {
      "epoch": 2.9018517777866655,
      "grad_norm": 0.1153663694858551,
      "learning_rate": 1.6544681304910079e-06,
      "loss": 0.028,
      "step": 145110
    },
    {
      "epoch": 2.902051753789545,
      "grad_norm": 0.20768827199935913,
      "learning_rate": 1.6511351971096802e-06,
      "loss": 0.0933,
      "step": 145120
    },
    {
      "epoch": 2.902251729792425,
      "grad_norm": 0.20539724826812744,
      "learning_rate": 1.6478022637283528e-06,
      "loss": 0.0514,
      "step": 145130
    },
    {
      "epoch": 2.9024517057953045,
      "grad_norm": 0.1408626288175583,
      "learning_rate": 1.644469330347025e-06,
      "loss": 0.0607,
      "step": 145140
    },
    {
      "epoch": 2.9026516817981842,
      "grad_norm": 0.10315375030040741,
      "learning_rate": 1.6411363969656975e-06,
      "loss": 0.066,
      "step": 145150
    },
    {
      "epoch": 2.902851657801064,
      "grad_norm": 0.2439640909433365,
      "learning_rate": 1.6378034635843701e-06,
      "loss": 0.0696,
      "step": 145160
    },
    {
      "epoch": 2.9030516338039436,
      "grad_norm": 0.1916409432888031,
      "learning_rate": 1.6344705302030423e-06,
      "loss": 0.0741,
      "step": 145170
    },
    {
      "epoch": 2.9032516098068233,
      "grad_norm": 0.08964367210865021,
      "learning_rate": 1.6311375968217149e-06,
      "loss": 0.0511,
      "step": 145180
    },
    {
      "epoch": 2.903451585809703,
      "grad_norm": 0.15607568621635437,
      "learning_rate": 1.6278046634403872e-06,
      "loss": 0.089,
      "step": 145190
    },
    {
      "epoch": 2.903651561812582,
      "grad_norm": 0.10571777075529099,
      "learning_rate": 1.6244717300590598e-06,
      "loss": 0.0582,
      "step": 145200
    },
    {
      "epoch": 2.903851537815462,
      "grad_norm": 0.21248489618301392,
      "learning_rate": 1.621138796677732e-06,
      "loss": 0.0872,
      "step": 145210
    },
    {
      "epoch": 2.9040515138183416,
      "grad_norm": 0.13178858160972595,
      "learning_rate": 1.6178058632964045e-06,
      "loss": 0.064,
      "step": 145220
    },
    {
      "epoch": 2.9042514898212213,
      "grad_norm": 0.0841745063662529,
      "learning_rate": 1.6144729299150771e-06,
      "loss": 0.0645,
      "step": 145230
    },
    {
      "epoch": 2.904451465824101,
      "grad_norm": 0.2152162492275238,
      "learning_rate": 1.6111399965337493e-06,
      "loss": 0.0727,
      "step": 145240
    },
    {
      "epoch": 2.9046514418269807,
      "grad_norm": 0.2933187186717987,
      "learning_rate": 1.6078070631524219e-06,
      "loss": 0.1087,
      "step": 145250
    },
    {
      "epoch": 2.9048514178298603,
      "grad_norm": 0.10872071981430054,
      "learning_rate": 1.604474129771094e-06,
      "loss": 0.0802,
      "step": 145260
    },
    {
      "epoch": 2.90505139383274,
      "grad_norm": 0.13138709962368011,
      "learning_rate": 1.6011411963897666e-06,
      "loss": 0.0486,
      "step": 145270
    },
    {
      "epoch": 2.9052513698356197,
      "grad_norm": 0.22815193235874176,
      "learning_rate": 1.597808263008439e-06,
      "loss": 0.0688,
      "step": 145280
    },
    {
      "epoch": 2.9054513458384994,
      "grad_norm": 0.2425956279039383,
      "learning_rate": 1.5944753296271116e-06,
      "loss": 0.0577,
      "step": 145290
    },
    {
      "epoch": 2.905651321841379,
      "grad_norm": 0.1722920686006546,
      "learning_rate": 1.5911423962457841e-06,
      "loss": 0.0599,
      "step": 145300
    },
    {
      "epoch": 2.9058512978442588,
      "grad_norm": 0.2370356172323227,
      "learning_rate": 1.5878094628644563e-06,
      "loss": 0.1083,
      "step": 145310
    },
    {
      "epoch": 2.9060512738471385,
      "grad_norm": 0.11422955244779587,
      "learning_rate": 1.5844765294831289e-06,
      "loss": 0.098,
      "step": 145320
    },
    {
      "epoch": 2.906251249850018,
      "grad_norm": 0.15514348447322845,
      "learning_rate": 1.581143596101801e-06,
      "loss": 0.0492,
      "step": 145330
    },
    {
      "epoch": 2.906451225852898,
      "grad_norm": 0.2108221799135208,
      "learning_rate": 1.5778106627204736e-06,
      "loss": 0.0767,
      "step": 145340
    },
    {
      "epoch": 2.9066512018557775,
      "grad_norm": 0.15804919600486755,
      "learning_rate": 1.574477729339146e-06,
      "loss": 0.0873,
      "step": 145350
    },
    {
      "epoch": 2.906851177858657,
      "grad_norm": 0.3081665635108948,
      "learning_rate": 1.5711447959578186e-06,
      "loss": 0.0794,
      "step": 145360
    },
    {
      "epoch": 2.9070511538615365,
      "grad_norm": 0.09642332792282104,
      "learning_rate": 1.5678118625764911e-06,
      "loss": 0.0743,
      "step": 145370
    },
    {
      "epoch": 2.907251129864416,
      "grad_norm": 0.08791570365428925,
      "learning_rate": 1.5644789291951633e-06,
      "loss": 0.0634,
      "step": 145380
    },
    {
      "epoch": 2.907451105867296,
      "grad_norm": 0.14095506072044373,
      "learning_rate": 1.5611459958138357e-06,
      "loss": 0.0376,
      "step": 145390
    },
    {
      "epoch": 2.9076510818701755,
      "grad_norm": 0.11640579998493195,
      "learning_rate": 1.557813062432508e-06,
      "loss": 0.0548,
      "step": 145400
    },
    {
      "epoch": 2.907851057873055,
      "grad_norm": 0.21549005806446075,
      "learning_rate": 1.5544801290511806e-06,
      "loss": 0.1045,
      "step": 145410
    },
    {
      "epoch": 2.908051033875935,
      "grad_norm": 0.2963360548019409,
      "learning_rate": 1.551147195669853e-06,
      "loss": 0.1311,
      "step": 145420
    },
    {
      "epoch": 2.9082510098788146,
      "grad_norm": 0.11056602001190186,
      "learning_rate": 1.5478142622885256e-06,
      "loss": 0.0628,
      "step": 145430
    },
    {
      "epoch": 2.9084509858816943,
      "grad_norm": 0.07726503163576126,
      "learning_rate": 1.544481328907198e-06,
      "loss": 0.0712,
      "step": 145440
    },
    {
      "epoch": 2.908650961884574,
      "grad_norm": 0.15029114484786987,
      "learning_rate": 1.5411483955258703e-06,
      "loss": 0.07,
      "step": 145450
    },
    {
      "epoch": 2.9088509378874536,
      "grad_norm": 0.1464052051305771,
      "learning_rate": 1.5378154621445427e-06,
      "loss": 0.0577,
      "step": 145460
    },
    {
      "epoch": 2.9090509138903333,
      "grad_norm": 0.15354013442993164,
      "learning_rate": 1.534482528763215e-06,
      "loss": 0.0879,
      "step": 145470
    },
    {
      "epoch": 2.9092508898932126,
      "grad_norm": 0.1482800841331482,
      "learning_rate": 1.5311495953818876e-06,
      "loss": 0.043,
      "step": 145480
    },
    {
      "epoch": 2.9094508658960923,
      "grad_norm": 0.18836577236652374,
      "learning_rate": 1.52781666200056e-06,
      "loss": 0.0604,
      "step": 145490
    },
    {
      "epoch": 2.909650841898972,
      "grad_norm": 0.2784188985824585,
      "learning_rate": 1.5244837286192326e-06,
      "loss": 0.0643,
      "step": 145500
    },
    {
      "epoch": 2.9098508179018516,
      "grad_norm": 0.10617319494485855,
      "learning_rate": 1.521150795237905e-06,
      "loss": 0.0766,
      "step": 145510
    },
    {
      "epoch": 2.9100507939047313,
      "grad_norm": 0.20763960480690002,
      "learning_rate": 1.5178178618565773e-06,
      "loss": 0.0416,
      "step": 145520
    },
    {
      "epoch": 2.910250769907611,
      "grad_norm": 0.17400462925434113,
      "learning_rate": 1.5144849284752497e-06,
      "loss": 0.0548,
      "step": 145530
    },
    {
      "epoch": 2.9104507459104907,
      "grad_norm": 0.15495732426643372,
      "learning_rate": 1.511151995093922e-06,
      "loss": 0.0741,
      "step": 145540
    },
    {
      "epoch": 2.9106507219133704,
      "grad_norm": 0.07743518054485321,
      "learning_rate": 1.5078190617125944e-06,
      "loss": 0.0659,
      "step": 145550
    },
    {
      "epoch": 2.91085069791625,
      "grad_norm": 0.08745381236076355,
      "learning_rate": 1.504486128331267e-06,
      "loss": 0.064,
      "step": 145560
    },
    {
      "epoch": 2.9110506739191297,
      "grad_norm": 0.17810514569282532,
      "learning_rate": 1.5011531949499394e-06,
      "loss": 0.065,
      "step": 145570
    },
    {
      "epoch": 2.9112506499220094,
      "grad_norm": 0.1630447655916214,
      "learning_rate": 1.497820261568612e-06,
      "loss": 0.0505,
      "step": 145580
    },
    {
      "epoch": 2.911450625924889,
      "grad_norm": 0.24170778691768646,
      "learning_rate": 1.4944873281872843e-06,
      "loss": 0.0745,
      "step": 145590
    },
    {
      "epoch": 2.911650601927769,
      "grad_norm": 0.1449047178030014,
      "learning_rate": 1.4911543948059567e-06,
      "loss": 0.072,
      "step": 145600
    },
    {
      "epoch": 2.9118505779306485,
      "grad_norm": 0.1418355256319046,
      "learning_rate": 1.487821461424629e-06,
      "loss": 0.0841,
      "step": 145610
    },
    {
      "epoch": 2.912050553933528,
      "grad_norm": 0.12037154287099838,
      "learning_rate": 1.4844885280433014e-06,
      "loss": 0.118,
      "step": 145620
    },
    {
      "epoch": 2.912250529936408,
      "grad_norm": 0.12928397953510284,
      "learning_rate": 1.481155594661974e-06,
      "loss": 0.1174,
      "step": 145630
    },
    {
      "epoch": 2.9124505059392876,
      "grad_norm": 0.20148299634456635,
      "learning_rate": 1.4778226612806464e-06,
      "loss": 0.0823,
      "step": 145640
    },
    {
      "epoch": 2.912650481942167,
      "grad_norm": 0.15328049659729004,
      "learning_rate": 1.474489727899319e-06,
      "loss": 0.0998,
      "step": 145650
    },
    {
      "epoch": 2.9128504579450465,
      "grad_norm": 0.27980929613113403,
      "learning_rate": 1.4711567945179913e-06,
      "loss": 0.0813,
      "step": 145660
    },
    {
      "epoch": 2.913050433947926,
      "grad_norm": 0.18439267575740814,
      "learning_rate": 1.4678238611366637e-06,
      "loss": 0.0805,
      "step": 145670
    },
    {
      "epoch": 2.913250409950806,
      "grad_norm": 0.11037221550941467,
      "learning_rate": 1.464490927755336e-06,
      "loss": 0.0681,
      "step": 145680
    },
    {
      "epoch": 2.9134503859536856,
      "grad_norm": 0.19801805913448334,
      "learning_rate": 1.4611579943740084e-06,
      "loss": 0.0832,
      "step": 145690
    },
    {
      "epoch": 2.9136503619565652,
      "grad_norm": 0.1892455369234085,
      "learning_rate": 1.457825060992681e-06,
      "loss": 0.0754,
      "step": 145700
    },
    {
      "epoch": 2.913850337959445,
      "grad_norm": 0.18883246183395386,
      "learning_rate": 1.4544921276113534e-06,
      "loss": 0.0638,
      "step": 145710
    },
    {
      "epoch": 2.9140503139623246,
      "grad_norm": 0.16284798085689545,
      "learning_rate": 1.4511591942300257e-06,
      "loss": 0.0902,
      "step": 145720
    },
    {
      "epoch": 2.9142502899652043,
      "grad_norm": 0.1094689890742302,
      "learning_rate": 1.4478262608486983e-06,
      "loss": 0.0609,
      "step": 145730
    },
    {
      "epoch": 2.914450265968084,
      "grad_norm": 0.1219354197382927,
      "learning_rate": 1.4444933274673707e-06,
      "loss": 0.0892,
      "step": 145740
    },
    {
      "epoch": 2.9146502419709632,
      "grad_norm": 0.17772959172725677,
      "learning_rate": 1.441160394086043e-06,
      "loss": 0.0601,
      "step": 145750
    },
    {
      "epoch": 2.914850217973843,
      "grad_norm": 0.1420537829399109,
      "learning_rate": 1.4378274607047154e-06,
      "loss": 0.0774,
      "step": 145760
    },
    {
      "epoch": 2.9150501939767226,
      "grad_norm": 0.21862468123435974,
      "learning_rate": 1.4344945273233878e-06,
      "loss": 0.1014,
      "step": 145770
    },
    {
      "epoch": 2.9152501699796023,
      "grad_norm": 0.08972316235303879,
      "learning_rate": 1.4311615939420604e-06,
      "loss": 0.0623,
      "step": 145780
    },
    {
      "epoch": 2.915450145982482,
      "grad_norm": 0.15635529160499573,
      "learning_rate": 1.4278286605607327e-06,
      "loss": 0.0738,
      "step": 145790
    },
    {
      "epoch": 2.9156501219853617,
      "grad_norm": 0.1667441874742508,
      "learning_rate": 1.4244957271794053e-06,
      "loss": 0.0668,
      "step": 145800
    },
    {
      "epoch": 2.9158500979882414,
      "grad_norm": 0.23574931919574738,
      "learning_rate": 1.4211627937980777e-06,
      "loss": 0.0923,
      "step": 145810
    },
    {
      "epoch": 2.916050073991121,
      "grad_norm": 0.19777466356754303,
      "learning_rate": 1.41782986041675e-06,
      "loss": 0.0531,
      "step": 145820
    },
    {
      "epoch": 2.9162500499940007,
      "grad_norm": 0.13126406073570251,
      "learning_rate": 1.4144969270354224e-06,
      "loss": 0.0548,
      "step": 145830
    },
    {
      "epoch": 2.9164500259968804,
      "grad_norm": 0.08732316642999649,
      "learning_rate": 1.4111639936540948e-06,
      "loss": 0.0853,
      "step": 145840
    },
    {
      "epoch": 2.91665000199976,
      "grad_norm": 0.21590746939182281,
      "learning_rate": 1.4078310602727674e-06,
      "loss": 0.0627,
      "step": 145850
    },
    {
      "epoch": 2.91684997800264,
      "grad_norm": 0.2485020011663437,
      "learning_rate": 1.4044981268914397e-06,
      "loss": 0.0679,
      "step": 145860
    },
    {
      "epoch": 2.9170499540055195,
      "grad_norm": 0.19813399016857147,
      "learning_rate": 1.4011651935101121e-06,
      "loss": 0.0657,
      "step": 145870
    },
    {
      "epoch": 2.917249930008399,
      "grad_norm": 0.10399842262268066,
      "learning_rate": 1.3978322601287847e-06,
      "loss": 0.5584,
      "step": 145880
    },
    {
      "epoch": 2.917449906011279,
      "grad_norm": 0.20394952595233917,
      "learning_rate": 1.394499326747457e-06,
      "loss": 0.0848,
      "step": 145890
    },
    {
      "epoch": 2.9176498820141585,
      "grad_norm": 0.23084217309951782,
      "learning_rate": 1.3911663933661294e-06,
      "loss": 0.09,
      "step": 145900
    },
    {
      "epoch": 2.9178498580170382,
      "grad_norm": 0.21425317227840424,
      "learning_rate": 1.3878334599848018e-06,
      "loss": 0.0765,
      "step": 145910
    },
    {
      "epoch": 2.9180498340199175,
      "grad_norm": 0.21147111058235168,
      "learning_rate": 1.3845005266034744e-06,
      "loss": 0.063,
      "step": 145920
    },
    {
      "epoch": 2.918249810022797,
      "grad_norm": 0.2733774185180664,
      "learning_rate": 1.3811675932221468e-06,
      "loss": 0.1036,
      "step": 145930
    },
    {
      "epoch": 2.918449786025677,
      "grad_norm": 0.15094292163848877,
      "learning_rate": 1.3778346598408191e-06,
      "loss": 0.0694,
      "step": 145940
    },
    {
      "epoch": 2.9186497620285565,
      "grad_norm": 0.22280380129814148,
      "learning_rate": 1.3745017264594917e-06,
      "loss": 0.1061,
      "step": 145950
    },
    {
      "epoch": 2.918849738031436,
      "grad_norm": 0.09161164611577988,
      "learning_rate": 1.371168793078164e-06,
      "loss": 0.0539,
      "step": 145960
    },
    {
      "epoch": 2.919049714034316,
      "grad_norm": 0.16170860826969147,
      "learning_rate": 1.3678358596968364e-06,
      "loss": 0.0529,
      "step": 145970
    },
    {
      "epoch": 2.9192496900371956,
      "grad_norm": 0.15139268338680267,
      "learning_rate": 1.3645029263155088e-06,
      "loss": 0.063,
      "step": 145980
    },
    {
      "epoch": 2.9194496660400753,
      "grad_norm": 0.16377867758274078,
      "learning_rate": 1.3611699929341812e-06,
      "loss": 0.0669,
      "step": 145990
    },
    {
      "epoch": 2.919649642042955,
      "grad_norm": 0.23330336809158325,
      "learning_rate": 1.3578370595528538e-06,
      "loss": 0.0693,
      "step": 146000
    },
    {
      "epoch": 2.9198496180458346,
      "grad_norm": 0.10793299227952957,
      "learning_rate": 1.3545041261715261e-06,
      "loss": 0.0629,
      "step": 146010
    },
    {
      "epoch": 2.920049594048714,
      "grad_norm": 0.07356195896863937,
      "learning_rate": 1.3511711927901985e-06,
      "loss": 0.0885,
      "step": 146020
    },
    {
      "epoch": 2.9202495700515936,
      "grad_norm": 0.20375099778175354,
      "learning_rate": 1.347838259408871e-06,
      "loss": 0.0872,
      "step": 146030
    },
    {
      "epoch": 2.9204495460544733,
      "grad_norm": 0.20767126977443695,
      "learning_rate": 1.3445053260275434e-06,
      "loss": 0.0491,
      "step": 146040
    },
    {
      "epoch": 2.920649522057353,
      "grad_norm": 0.18779021501541138,
      "learning_rate": 1.3411723926462158e-06,
      "loss": 0.1106,
      "step": 146050
    },
    {
      "epoch": 2.9208494980602326,
      "grad_norm": 0.18459908664226532,
      "learning_rate": 1.3378394592648882e-06,
      "loss": 0.0617,
      "step": 146060
    },
    {
      "epoch": 2.9210494740631123,
      "grad_norm": 0.10980691760778427,
      "learning_rate": 1.3345065258835608e-06,
      "loss": 0.0692,
      "step": 146070
    },
    {
      "epoch": 2.921249450065992,
      "grad_norm": 0.14124839007854462,
      "learning_rate": 1.3311735925022331e-06,
      "loss": 0.1052,
      "step": 146080
    },
    {
      "epoch": 2.9214494260688717,
      "grad_norm": 0.04859526827931404,
      "learning_rate": 1.3278406591209055e-06,
      "loss": 0.0424,
      "step": 146090
    },
    {
      "epoch": 2.9216494020717514,
      "grad_norm": 0.16570569574832916,
      "learning_rate": 1.324507725739578e-06,
      "loss": 0.0731,
      "step": 146100
    },
    {
      "epoch": 2.921849378074631,
      "grad_norm": 0.16677676141262054,
      "learning_rate": 1.3211747923582505e-06,
      "loss": 0.0453,
      "step": 146110
    },
    {
      "epoch": 2.9220493540775108,
      "grad_norm": 0.11322399228811264,
      "learning_rate": 1.3178418589769228e-06,
      "loss": 0.0648,
      "step": 146120
    },
    {
      "epoch": 2.9222493300803905,
      "grad_norm": 0.2311026155948639,
      "learning_rate": 1.3145089255955952e-06,
      "loss": 0.1126,
      "step": 146130
    },
    {
      "epoch": 2.92244930608327,
      "grad_norm": 0.11378270387649536,
      "learning_rate": 1.3111759922142678e-06,
      "loss": 0.2396,
      "step": 146140
    },
    {
      "epoch": 2.92264928208615,
      "grad_norm": 0.20583102107048035,
      "learning_rate": 1.3078430588329401e-06,
      "loss": 0.0638,
      "step": 146150
    },
    {
      "epoch": 2.9228492580890295,
      "grad_norm": 0.16064666211605072,
      "learning_rate": 1.3045101254516125e-06,
      "loss": 0.0542,
      "step": 146160
    },
    {
      "epoch": 2.923049234091909,
      "grad_norm": 0.1530448943376541,
      "learning_rate": 1.3011771920702849e-06,
      "loss": 0.0838,
      "step": 146170
    },
    {
      "epoch": 2.923249210094789,
      "grad_norm": 0.141165629029274,
      "learning_rate": 1.2978442586889575e-06,
      "loss": 0.0558,
      "step": 146180
    },
    {
      "epoch": 2.923449186097668,
      "grad_norm": 0.1252647042274475,
      "learning_rate": 1.2945113253076298e-06,
      "loss": 0.0531,
      "step": 146190
    },
    {
      "epoch": 2.923649162100548,
      "grad_norm": 0.19322039186954498,
      "learning_rate": 1.2911783919263022e-06,
      "loss": 0.1105,
      "step": 146200
    },
    {
      "epoch": 2.9238491381034275,
      "grad_norm": 0.2190442830324173,
      "learning_rate": 1.2878454585449746e-06,
      "loss": 0.11,
      "step": 146210
    },
    {
      "epoch": 2.924049114106307,
      "grad_norm": 0.22641368210315704,
      "learning_rate": 1.2845125251636471e-06,
      "loss": 0.091,
      "step": 146220
    },
    {
      "epoch": 2.924249090109187,
      "grad_norm": 0.09546568989753723,
      "learning_rate": 1.2811795917823195e-06,
      "loss": 0.0776,
      "step": 146230
    },
    {
      "epoch": 2.9244490661120666,
      "grad_norm": 0.13395905494689941,
      "learning_rate": 1.2778466584009919e-06,
      "loss": 0.0699,
      "step": 146240
    },
    {
      "epoch": 2.9246490421149463,
      "grad_norm": 0.10575395822525024,
      "learning_rate": 1.2745137250196645e-06,
      "loss": 0.0736,
      "step": 146250
    },
    {
      "epoch": 2.924849018117826,
      "grad_norm": 0.09296015650033951,
      "learning_rate": 1.2711807916383368e-06,
      "loss": 0.0695,
      "step": 146260
    },
    {
      "epoch": 2.9250489941207056,
      "grad_norm": 0.1569330245256424,
      "learning_rate": 1.2678478582570092e-06,
      "loss": 0.0937,
      "step": 146270
    },
    {
      "epoch": 2.9252489701235853,
      "grad_norm": 0.16235429048538208,
      "learning_rate": 1.2645149248756816e-06,
      "loss": 0.0541,
      "step": 146280
    },
    {
      "epoch": 2.9254489461264646,
      "grad_norm": 0.13073919713497162,
      "learning_rate": 1.2611819914943541e-06,
      "loss": 0.078,
      "step": 146290
    },
    {
      "epoch": 2.9256489221293442,
      "grad_norm": 0.09009218961000443,
      "learning_rate": 1.2578490581130265e-06,
      "loss": 0.0732,
      "step": 146300
    },
    {
      "epoch": 2.925848898132224,
      "grad_norm": 0.0924326479434967,
      "learning_rate": 1.2545161247316989e-06,
      "loss": 0.0655,
      "step": 146310
    },
    {
      "epoch": 2.9260488741351036,
      "grad_norm": 0.2289203405380249,
      "learning_rate": 1.2511831913503713e-06,
      "loss": 0.0829,
      "step": 146320
    },
    {
      "epoch": 2.9262488501379833,
      "grad_norm": 0.2556496560573578,
      "learning_rate": 1.2478502579690438e-06,
      "loss": 0.0807,
      "step": 146330
    },
    {
      "epoch": 2.926448826140863,
      "grad_norm": 0.08646415919065475,
      "learning_rate": 1.2445173245877162e-06,
      "loss": 0.0563,
      "step": 146340
    },
    {
      "epoch": 2.9266488021437427,
      "grad_norm": 0.20323309302330017,
      "learning_rate": 1.2411843912063886e-06,
      "loss": 0.0955,
      "step": 146350
    },
    {
      "epoch": 2.9268487781466224,
      "grad_norm": 0.17633819580078125,
      "learning_rate": 1.2378514578250612e-06,
      "loss": 0.0639,
      "step": 146360
    },
    {
      "epoch": 2.927048754149502,
      "grad_norm": 0.1321912407875061,
      "learning_rate": 1.2345185244437335e-06,
      "loss": 0.0655,
      "step": 146370
    },
    {
      "epoch": 2.9272487301523817,
      "grad_norm": 0.1413654386997223,
      "learning_rate": 1.2311855910624059e-06,
      "loss": 0.0618,
      "step": 146380
    },
    {
      "epoch": 2.9274487061552614,
      "grad_norm": 0.27463510632514954,
      "learning_rate": 1.2278526576810783e-06,
      "loss": 0.0936,
      "step": 146390
    },
    {
      "epoch": 2.927648682158141,
      "grad_norm": 0.19775724411010742,
      "learning_rate": 1.2245197242997508e-06,
      "loss": 0.0675,
      "step": 146400
    },
    {
      "epoch": 2.927848658161021,
      "grad_norm": 0.13974787294864655,
      "learning_rate": 1.2211867909184232e-06,
      "loss": 0.0553,
      "step": 146410
    },
    {
      "epoch": 2.9280486341639005,
      "grad_norm": 0.16531166434288025,
      "learning_rate": 1.2178538575370956e-06,
      "loss": 0.1715,
      "step": 146420
    },
    {
      "epoch": 2.92824861016678,
      "grad_norm": 0.06814552843570709,
      "learning_rate": 1.214520924155768e-06,
      "loss": 0.065,
      "step": 146430
    },
    {
      "epoch": 2.92844858616966,
      "grad_norm": 0.20929433405399323,
      "learning_rate": 1.2111879907744405e-06,
      "loss": 0.1452,
      "step": 146440
    },
    {
      "epoch": 2.9286485621725395,
      "grad_norm": 0.1029074639081955,
      "learning_rate": 1.207855057393113e-06,
      "loss": 0.1115,
      "step": 146450
    },
    {
      "epoch": 2.928848538175419,
      "grad_norm": 0.1281863898038864,
      "learning_rate": 1.2045221240117853e-06,
      "loss": 0.0538,
      "step": 146460
    },
    {
      "epoch": 2.9290485141782985,
      "grad_norm": 0.15820421278476715,
      "learning_rate": 1.2011891906304576e-06,
      "loss": 0.0716,
      "step": 146470
    },
    {
      "epoch": 2.929248490181178,
      "grad_norm": 0.08776909857988358,
      "learning_rate": 1.1978562572491302e-06,
      "loss": 0.0656,
      "step": 146480
    },
    {
      "epoch": 2.929448466184058,
      "grad_norm": 0.07990124076604843,
      "learning_rate": 1.1945233238678026e-06,
      "loss": 0.0625,
      "step": 146490
    },
    {
      "epoch": 2.9296484421869375,
      "grad_norm": 0.2003069669008255,
      "learning_rate": 1.191190390486475e-06,
      "loss": 0.0903,
      "step": 146500
    },
    {
      "epoch": 2.9298484181898172,
      "grad_norm": 0.21885092556476593,
      "learning_rate": 1.1878574571051475e-06,
      "loss": 0.0728,
      "step": 146510
    },
    {
      "epoch": 2.930048394192697,
      "grad_norm": 0.1169651672244072,
      "learning_rate": 1.18452452372382e-06,
      "loss": 0.0845,
      "step": 146520
    },
    {
      "epoch": 2.9302483701955766,
      "grad_norm": 0.23417945206165314,
      "learning_rate": 1.1811915903424923e-06,
      "loss": 0.0772,
      "step": 146530
    },
    {
      "epoch": 2.9304483461984563,
      "grad_norm": 0.07407630980014801,
      "learning_rate": 1.1778586569611646e-06,
      "loss": 0.0679,
      "step": 146540
    },
    {
      "epoch": 2.930648322201336,
      "grad_norm": 0.24681544303894043,
      "learning_rate": 1.1745257235798372e-06,
      "loss": 0.1138,
      "step": 146550
    },
    {
      "epoch": 2.930848298204215,
      "grad_norm": 0.09681858122348785,
      "learning_rate": 1.1711927901985096e-06,
      "loss": 0.072,
      "step": 146560
    },
    {
      "epoch": 2.931048274207095,
      "grad_norm": 0.2012520283460617,
      "learning_rate": 1.167859856817182e-06,
      "loss": 0.0913,
      "step": 146570
    },
    {
      "epoch": 2.9312482502099746,
      "grad_norm": 0.2501518428325653,
      "learning_rate": 1.1645269234358545e-06,
      "loss": 0.0491,
      "step": 146580
    },
    {
      "epoch": 2.9314482262128543,
      "grad_norm": 0.07260077446699142,
      "learning_rate": 1.161193990054527e-06,
      "loss": 0.0786,
      "step": 146590
    },
    {
      "epoch": 2.931648202215734,
      "grad_norm": 0.10626804083585739,
      "learning_rate": 1.1578610566731993e-06,
      "loss": 0.0622,
      "step": 146600
    },
    {
      "epoch": 2.9318481782186137,
      "grad_norm": 0.217253640294075,
      "learning_rate": 1.1545281232918716e-06,
      "loss": 0.102,
      "step": 146610
    },
    {
      "epoch": 2.9320481542214933,
      "grad_norm": 0.09047365188598633,
      "learning_rate": 1.151195189910544e-06,
      "loss": 0.072,
      "step": 146620
    },
    {
      "epoch": 2.932248130224373,
      "grad_norm": 0.14229463040828705,
      "learning_rate": 1.1478622565292166e-06,
      "loss": 0.0704,
      "step": 146630
    },
    {
      "epoch": 2.9324481062272527,
      "grad_norm": 0.24741357564926147,
      "learning_rate": 1.144529323147889e-06,
      "loss": 0.0914,
      "step": 146640
    },
    {
      "epoch": 2.9326480822301324,
      "grad_norm": 0.1398540735244751,
      "learning_rate": 1.1411963897665613e-06,
      "loss": 0.0897,
      "step": 146650
    },
    {
      "epoch": 2.932848058233012,
      "grad_norm": 0.18011854588985443,
      "learning_rate": 1.137863456385234e-06,
      "loss": 0.0961,
      "step": 146660
    },
    {
      "epoch": 2.9330480342358918,
      "grad_norm": 0.14122909307479858,
      "learning_rate": 1.1345305230039063e-06,
      "loss": 0.0606,
      "step": 146670
    },
    {
      "epoch": 2.9332480102387715,
      "grad_norm": 0.14946550130844116,
      "learning_rate": 1.1311975896225786e-06,
      "loss": 0.0761,
      "step": 146680
    },
    {
      "epoch": 2.933447986241651,
      "grad_norm": 0.20982615649700165,
      "learning_rate": 1.127864656241251e-06,
      "loss": 0.074,
      "step": 146690
    },
    {
      "epoch": 2.933647962244531,
      "grad_norm": 0.2270670235157013,
      "learning_rate": 1.1245317228599236e-06,
      "loss": 0.0827,
      "step": 146700
    },
    {
      "epoch": 2.9338479382474105,
      "grad_norm": 0.10493514686822891,
      "learning_rate": 1.121198789478596e-06,
      "loss": 0.0544,
      "step": 146710
    },
    {
      "epoch": 2.93404791425029,
      "grad_norm": 0.1511610746383667,
      "learning_rate": 1.1178658560972683e-06,
      "loss": 0.0558,
      "step": 146720
    },
    {
      "epoch": 2.9342478902531695,
      "grad_norm": 0.12200713157653809,
      "learning_rate": 1.114532922715941e-06,
      "loss": 0.0866,
      "step": 146730
    },
    {
      "epoch": 2.934447866256049,
      "grad_norm": 0.11627842485904694,
      "learning_rate": 1.1111999893346133e-06,
      "loss": 0.0712,
      "step": 146740
    },
    {
      "epoch": 2.934647842258929,
      "grad_norm": 0.22141385078430176,
      "learning_rate": 1.1078670559532857e-06,
      "loss": 0.0757,
      "step": 146750
    },
    {
      "epoch": 2.9348478182618085,
      "grad_norm": 0.10980183631181717,
      "learning_rate": 1.104534122571958e-06,
      "loss": 0.0821,
      "step": 146760
    },
    {
      "epoch": 2.935047794264688,
      "grad_norm": 0.17428894340991974,
      "learning_rate": 1.1012011891906304e-06,
      "loss": 0.0613,
      "step": 146770
    },
    {
      "epoch": 2.935247770267568,
      "grad_norm": 0.11599965393543243,
      "learning_rate": 1.097868255809303e-06,
      "loss": 0.0502,
      "step": 146780
    },
    {
      "epoch": 2.9354477462704476,
      "grad_norm": 0.1874818056821823,
      "learning_rate": 1.0945353224279753e-06,
      "loss": 0.0617,
      "step": 146790
    },
    {
      "epoch": 2.9356477222733273,
      "grad_norm": 0.24091044068336487,
      "learning_rate": 1.091202389046648e-06,
      "loss": 0.0957,
      "step": 146800
    },
    {
      "epoch": 2.935847698276207,
      "grad_norm": 0.056448135524988174,
      "learning_rate": 1.0878694556653203e-06,
      "loss": 0.0735,
      "step": 146810
    },
    {
      "epoch": 2.9360476742790866,
      "grad_norm": 0.20240472257137299,
      "learning_rate": 1.0845365222839927e-06,
      "loss": 0.0864,
      "step": 146820
    },
    {
      "epoch": 2.9362476502819663,
      "grad_norm": 0.06904608011245728,
      "learning_rate": 1.081203588902665e-06,
      "loss": 0.0858,
      "step": 146830
    },
    {
      "epoch": 2.9364476262848456,
      "grad_norm": 0.21193434298038483,
      "learning_rate": 1.0778706555213374e-06,
      "loss": 0.0737,
      "step": 146840
    },
    {
      "epoch": 2.9366476022877253,
      "grad_norm": 0.11501874029636383,
      "learning_rate": 1.07453772214001e-06,
      "loss": 0.0535,
      "step": 146850
    },
    {
      "epoch": 2.936847578290605,
      "grad_norm": 0.256594717502594,
      "learning_rate": 1.0712047887586823e-06,
      "loss": 0.1034,
      "step": 146860
    },
    {
      "epoch": 2.9370475542934846,
      "grad_norm": 0.11583350598812103,
      "learning_rate": 1.0678718553773547e-06,
      "loss": 0.3049,
      "step": 146870
    },
    {
      "epoch": 2.9372475302963643,
      "grad_norm": 0.2475738525390625,
      "learning_rate": 1.0645389219960273e-06,
      "loss": 0.1135,
      "step": 146880
    },
    {
      "epoch": 2.937447506299244,
      "grad_norm": 0.1286308467388153,
      "learning_rate": 1.0612059886146997e-06,
      "loss": 0.0536,
      "step": 146890
    },
    {
      "epoch": 2.9376474823021237,
      "grad_norm": 0.09542480111122131,
      "learning_rate": 1.057873055233372e-06,
      "loss": 0.0712,
      "step": 146900
    },
    {
      "epoch": 2.9378474583050034,
      "grad_norm": 0.1267053335905075,
      "learning_rate": 1.0545401218520444e-06,
      "loss": 0.0506,
      "step": 146910
    },
    {
      "epoch": 2.938047434307883,
      "grad_norm": 0.1444176733493805,
      "learning_rate": 1.0512071884707168e-06,
      "loss": 0.0513,
      "step": 146920
    },
    {
      "epoch": 2.9382474103107628,
      "grad_norm": 0.2215052843093872,
      "learning_rate": 1.0478742550893893e-06,
      "loss": 0.0524,
      "step": 146930
    },
    {
      "epoch": 2.9384473863136424,
      "grad_norm": 0.10582146793603897,
      "learning_rate": 1.0445413217080617e-06,
      "loss": 0.0719,
      "step": 146940
    },
    {
      "epoch": 2.938647362316522,
      "grad_norm": 0.06001552939414978,
      "learning_rate": 1.0415416816648669e-06,
      "loss": 0.0998,
      "step": 146950
    },
    {
      "epoch": 2.938847338319402,
      "grad_norm": 0.13851621747016907,
      "learning_rate": 1.0382087482835395e-06,
      "loss": 0.0478,
      "step": 146960
    },
    {
      "epoch": 2.9390473143222815,
      "grad_norm": 0.2514220178127289,
      "learning_rate": 1.0348758149022118e-06,
      "loss": 0.0834,
      "step": 146970
    },
    {
      "epoch": 2.939247290325161,
      "grad_norm": 0.12072616815567017,
      "learning_rate": 1.0315428815208842e-06,
      "loss": 0.2154,
      "step": 146980
    },
    {
      "epoch": 2.939447266328041,
      "grad_norm": 0.16060902178287506,
      "learning_rate": 1.0282099481395566e-06,
      "loss": 0.066,
      "step": 146990
    },
    {
      "epoch": 2.9396472423309206,
      "grad_norm": 0.2129284143447876,
      "learning_rate": 1.0248770147582291e-06,
      "loss": 0.1148,
      "step": 147000
    },
    {
      "epoch": 2.9398472183338,
      "grad_norm": 0.2229769080877304,
      "learning_rate": 1.0215440813769015e-06,
      "loss": 0.057,
      "step": 147010
    },
    {
      "epoch": 2.9400471943366795,
      "grad_norm": 0.08805578947067261,
      "learning_rate": 1.0182111479955739e-06,
      "loss": 0.072,
      "step": 147020
    },
    {
      "epoch": 2.940247170339559,
      "grad_norm": 0.16544413566589355,
      "learning_rate": 1.0148782146142465e-06,
      "loss": 0.0911,
      "step": 147030
    },
    {
      "epoch": 2.940447146342439,
      "grad_norm": 0.2693873941898346,
      "learning_rate": 1.0115452812329188e-06,
      "loss": 0.0827,
      "step": 147040
    },
    {
      "epoch": 2.9406471223453186,
      "grad_norm": 0.21706020832061768,
      "learning_rate": 1.0082123478515912e-06,
      "loss": 0.0745,
      "step": 147050
    },
    {
      "epoch": 2.9408470983481982,
      "grad_norm": 0.2241685390472412,
      "learning_rate": 1.0048794144702636e-06,
      "loss": 0.1009,
      "step": 147060
    },
    {
      "epoch": 2.941047074351078,
      "grad_norm": 0.1729775369167328,
      "learning_rate": 1.001546481088936e-06,
      "loss": 0.0694,
      "step": 147070
    },
    {
      "epoch": 2.9412470503539576,
      "grad_norm": 0.16170001029968262,
      "learning_rate": 9.982135477076085e-07,
      "loss": 0.0584,
      "step": 147080
    },
    {
      "epoch": 2.9414470263568373,
      "grad_norm": 0.24524998664855957,
      "learning_rate": 9.948806143262809e-07,
      "loss": 0.0926,
      "step": 147090
    },
    {
      "epoch": 2.941647002359717,
      "grad_norm": 0.10854648798704147,
      "learning_rate": 9.915476809449532e-07,
      "loss": 0.0637,
      "step": 147100
    },
    {
      "epoch": 2.9418469783625962,
      "grad_norm": 0.13209596276283264,
      "learning_rate": 9.882147475636258e-07,
      "loss": 0.0764,
      "step": 147110
    },
    {
      "epoch": 2.942046954365476,
      "grad_norm": 0.24248091876506805,
      "learning_rate": 9.848818141822982e-07,
      "loss": 0.0703,
      "step": 147120
    },
    {
      "epoch": 2.9422469303683556,
      "grad_norm": 0.09969986230134964,
      "learning_rate": 9.815488808009706e-07,
      "loss": 0.0525,
      "step": 147130
    },
    {
      "epoch": 2.9424469063712353,
      "grad_norm": 0.08114870637655258,
      "learning_rate": 9.78215947419643e-07,
      "loss": 0.0531,
      "step": 147140
    },
    {
      "epoch": 2.942646882374115,
      "grad_norm": 0.08922283351421356,
      "learning_rate": 9.748830140383155e-07,
      "loss": 0.1138,
      "step": 147150
    },
    {
      "epoch": 2.9428468583769947,
      "grad_norm": 0.17655296623706818,
      "learning_rate": 9.715500806569879e-07,
      "loss": 0.073,
      "step": 147160
    },
    {
      "epoch": 2.9430468343798744,
      "grad_norm": 0.16530124843120575,
      "learning_rate": 9.682171472756603e-07,
      "loss": 0.087,
      "step": 147170
    },
    {
      "epoch": 2.943246810382754,
      "grad_norm": 0.1738879233598709,
      "learning_rate": 9.648842138943328e-07,
      "loss": 0.0465,
      "step": 147180
    },
    {
      "epoch": 2.9434467863856337,
      "grad_norm": 0.15153776109218597,
      "learning_rate": 9.615512805130052e-07,
      "loss": 0.0846,
      "step": 147190
    },
    {
      "epoch": 2.9436467623885134,
      "grad_norm": 0.08781096339225769,
      "learning_rate": 9.582183471316776e-07,
      "loss": 0.0863,
      "step": 147200
    },
    {
      "epoch": 2.943846738391393,
      "grad_norm": 0.19142168760299683,
      "learning_rate": 9.5488541375035e-07,
      "loss": 0.0607,
      "step": 147210
    },
    {
      "epoch": 2.944046714394273,
      "grad_norm": 0.08719499409198761,
      "learning_rate": 9.515524803690225e-07,
      "loss": 0.0516,
      "step": 147220
    },
    {
      "epoch": 2.9442466903971525,
      "grad_norm": 0.09468570351600647,
      "learning_rate": 9.482195469876949e-07,
      "loss": 0.0615,
      "step": 147230
    },
    {
      "epoch": 2.944446666400032,
      "grad_norm": 0.07052793353796005,
      "learning_rate": 9.448866136063674e-07,
      "loss": 0.0538,
      "step": 147240
    },
    {
      "epoch": 2.944646642402912,
      "grad_norm": 0.17511752247810364,
      "learning_rate": 9.415536802250397e-07,
      "loss": 0.05,
      "step": 147250
    },
    {
      "epoch": 2.9448466184057915,
      "grad_norm": 0.23283275961875916,
      "learning_rate": 9.382207468437121e-07,
      "loss": 0.0867,
      "step": 147260
    },
    {
      "epoch": 2.9450465944086712,
      "grad_norm": 0.08987658470869064,
      "learning_rate": 9.348878134623845e-07,
      "loss": 0.0693,
      "step": 147270
    },
    {
      "epoch": 2.9452465704115505,
      "grad_norm": 0.1570318192243576,
      "learning_rate": 9.315548800810569e-07,
      "loss": 0.09,
      "step": 147280
    },
    {
      "epoch": 2.94544654641443,
      "grad_norm": 0.11810481548309326,
      "learning_rate": 9.282219466997293e-07,
      "loss": 0.0666,
      "step": 147290
    },
    {
      "epoch": 2.94564652241731,
      "grad_norm": 0.05855638533830643,
      "learning_rate": 9.248890133184019e-07,
      "loss": 0.0498,
      "step": 147300
    },
    {
      "epoch": 2.9458464984201895,
      "grad_norm": 0.1640906184911728,
      "learning_rate": 9.215560799370743e-07,
      "loss": 0.0745,
      "step": 147310
    },
    {
      "epoch": 2.946046474423069,
      "grad_norm": 0.16980202496051788,
      "learning_rate": 9.182231465557467e-07,
      "loss": 0.0918,
      "step": 147320
    },
    {
      "epoch": 2.946246450425949,
      "grad_norm": 0.13176719844341278,
      "learning_rate": 9.148902131744191e-07,
      "loss": 0.0804,
      "step": 147330
    },
    {
      "epoch": 2.9464464264288286,
      "grad_norm": 0.1015375480055809,
      "learning_rate": 9.115572797930915e-07,
      "loss": 0.058,
      "step": 147340
    },
    {
      "epoch": 2.9466464024317083,
      "grad_norm": 0.17033430933952332,
      "learning_rate": 9.08224346411764e-07,
      "loss": 0.0531,
      "step": 147350
    },
    {
      "epoch": 2.946846378434588,
      "grad_norm": 0.10241662710905075,
      "learning_rate": 9.048914130304363e-07,
      "loss": 0.0922,
      "step": 147360
    },
    {
      "epoch": 2.9470463544374677,
      "grad_norm": 0.06193964183330536,
      "learning_rate": 9.015584796491089e-07,
      "loss": 0.0606,
      "step": 147370
    },
    {
      "epoch": 2.947246330440347,
      "grad_norm": 0.11620671302080154,
      "learning_rate": 8.982255462677813e-07,
      "loss": 0.0649,
      "step": 147380
    },
    {
      "epoch": 2.9474463064432266,
      "grad_norm": 0.22468474507331848,
      "learning_rate": 8.948926128864537e-07,
      "loss": 0.1203,
      "step": 147390
    },
    {
      "epoch": 2.9476462824461063,
      "grad_norm": 0.21382923424243927,
      "learning_rate": 8.915596795051261e-07,
      "loss": 0.0869,
      "step": 147400
    },
    {
      "epoch": 2.947846258448986,
      "grad_norm": 0.10133005678653717,
      "learning_rate": 8.882267461237985e-07,
      "loss": 0.0595,
      "step": 147410
    },
    {
      "epoch": 2.9480462344518656,
      "grad_norm": 0.11694692075252533,
      "learning_rate": 8.848938127424708e-07,
      "loss": 0.093,
      "step": 147420
    },
    {
      "epoch": 2.9482462104547453,
      "grad_norm": 0.23043984174728394,
      "learning_rate": 8.815608793611433e-07,
      "loss": 0.1179,
      "step": 147430
    },
    {
      "epoch": 2.948446186457625,
      "grad_norm": 0.24345651268959045,
      "learning_rate": 8.782279459798159e-07,
      "loss": 0.0659,
      "step": 147440
    },
    {
      "epoch": 2.9486461624605047,
      "grad_norm": 0.15609459578990936,
      "learning_rate": 8.748950125984883e-07,
      "loss": 0.0685,
      "step": 147450
    },
    {
      "epoch": 2.9488461384633844,
      "grad_norm": 0.14578981697559357,
      "learning_rate": 8.715620792171606e-07,
      "loss": 0.0547,
      "step": 147460
    },
    {
      "epoch": 2.949046114466264,
      "grad_norm": 0.18858669698238373,
      "learning_rate": 8.682291458358331e-07,
      "loss": 0.067,
      "step": 147470
    },
    {
      "epoch": 2.9492460904691438,
      "grad_norm": 0.27879562973976135,
      "learning_rate": 8.648962124545055e-07,
      "loss": 0.1092,
      "step": 147480
    },
    {
      "epoch": 2.9494460664720235,
      "grad_norm": 0.12752856314182281,
      "learning_rate": 8.615632790731779e-07,
      "loss": 0.0578,
      "step": 147490
    },
    {
      "epoch": 2.949646042474903,
      "grad_norm": 0.21975594758987427,
      "learning_rate": 8.582303456918503e-07,
      "loss": 0.0746,
      "step": 147500
    },
    {
      "epoch": 2.949846018477783,
      "grad_norm": 0.16526611149311066,
      "learning_rate": 8.548974123105227e-07,
      "loss": 0.0829,
      "step": 147510
    },
    {
      "epoch": 2.9500459944806625,
      "grad_norm": 0.26307588815689087,
      "learning_rate": 8.515644789291953e-07,
      "loss": 0.0859,
      "step": 147520
    },
    {
      "epoch": 2.950245970483542,
      "grad_norm": 0.09860925376415253,
      "learning_rate": 8.482315455478676e-07,
      "loss": 0.0905,
      "step": 147530
    },
    {
      "epoch": 2.950445946486422,
      "grad_norm": 0.10839960724115372,
      "learning_rate": 8.448986121665401e-07,
      "loss": 0.0789,
      "step": 147540
    },
    {
      "epoch": 2.950645922489301,
      "grad_norm": 0.22201353311538696,
      "learning_rate": 8.415656787852125e-07,
      "loss": 0.0932,
      "step": 147550
    },
    {
      "epoch": 2.950845898492181,
      "grad_norm": 0.10002251714468002,
      "learning_rate": 8.382327454038849e-07,
      "loss": 0.0325,
      "step": 147560
    },
    {
      "epoch": 2.9510458744950605,
      "grad_norm": 0.2645285427570343,
      "learning_rate": 8.348998120225572e-07,
      "loss": 0.0772,
      "step": 147570
    },
    {
      "epoch": 2.95124585049794,
      "grad_norm": 0.1364193856716156,
      "learning_rate": 8.315668786412297e-07,
      "loss": 0.0686,
      "step": 147580
    },
    {
      "epoch": 2.95144582650082,
      "grad_norm": 0.17025353014469147,
      "learning_rate": 8.282339452599023e-07,
      "loss": 0.1027,
      "step": 147590
    },
    {
      "epoch": 2.9516458025036996,
      "grad_norm": 0.04231952503323555,
      "learning_rate": 8.249010118785747e-07,
      "loss": 0.0735,
      "step": 147600
    },
    {
      "epoch": 2.9518457785065793,
      "grad_norm": 0.1473744511604309,
      "learning_rate": 8.21568078497247e-07,
      "loss": 0.1086,
      "step": 147610
    },
    {
      "epoch": 2.952045754509459,
      "grad_norm": 0.08994299173355103,
      "learning_rate": 8.182351451159195e-07,
      "loss": 0.0548,
      "step": 147620
    },
    {
      "epoch": 2.9522457305123386,
      "grad_norm": 0.24100445210933685,
      "learning_rate": 8.149022117345919e-07,
      "loss": 0.0606,
      "step": 147630
    },
    {
      "epoch": 2.9524457065152183,
      "grad_norm": 0.18774133920669556,
      "learning_rate": 8.115692783532642e-07,
      "loss": 0.0625,
      "step": 147640
    },
    {
      "epoch": 2.9526456825180976,
      "grad_norm": 0.17831194400787354,
      "learning_rate": 8.082363449719367e-07,
      "loss": 0.0852,
      "step": 147650
    },
    {
      "epoch": 2.9528456585209772,
      "grad_norm": 0.16875803470611572,
      "learning_rate": 8.049034115906093e-07,
      "loss": 0.058,
      "step": 147660
    },
    {
      "epoch": 2.953045634523857,
      "grad_norm": 0.136590376496315,
      "learning_rate": 8.015704782092817e-07,
      "loss": 0.0553,
      "step": 147670
    },
    {
      "epoch": 2.9532456105267366,
      "grad_norm": 0.07671450078487396,
      "learning_rate": 7.98237544827954e-07,
      "loss": 0.0725,
      "step": 147680
    },
    {
      "epoch": 2.9534455865296163,
      "grad_norm": 0.21167105436325073,
      "learning_rate": 7.949046114466265e-07,
      "loss": 0.0802,
      "step": 147690
    },
    {
      "epoch": 2.953645562532496,
      "grad_norm": 0.08753521740436554,
      "learning_rate": 7.915716780652989e-07,
      "loss": 0.045,
      "step": 147700
    },
    {
      "epoch": 2.9538455385353757,
      "grad_norm": 0.1342889964580536,
      "learning_rate": 7.882387446839712e-07,
      "loss": 0.2646,
      "step": 147710
    },
    {
      "epoch": 2.9540455145382554,
      "grad_norm": 0.09631440788507462,
      "learning_rate": 7.849058113026437e-07,
      "loss": 0.0633,
      "step": 147720
    },
    {
      "epoch": 2.954245490541135,
      "grad_norm": 0.0737311914563179,
      "learning_rate": 7.815728779213161e-07,
      "loss": 0.0653,
      "step": 147730
    },
    {
      "epoch": 2.9544454665440147,
      "grad_norm": 0.17727559804916382,
      "learning_rate": 7.782399445399886e-07,
      "loss": 0.0851,
      "step": 147740
    },
    {
      "epoch": 2.9546454425468944,
      "grad_norm": 0.09194660186767578,
      "learning_rate": 7.74907011158661e-07,
      "loss": 0.0698,
      "step": 147750
    },
    {
      "epoch": 2.954845418549774,
      "grad_norm": 0.08130043745040894,
      "learning_rate": 7.715740777773334e-07,
      "loss": 0.0604,
      "step": 147760
    },
    {
      "epoch": 2.955045394552654,
      "grad_norm": 0.12822400033473969,
      "learning_rate": 7.682411443960059e-07,
      "loss": 0.0625,
      "step": 147770
    },
    {
      "epoch": 2.9552453705555335,
      "grad_norm": 0.06366883218288422,
      "learning_rate": 7.649082110146782e-07,
      "loss": 0.0656,
      "step": 147780
    },
    {
      "epoch": 2.955445346558413,
      "grad_norm": 0.14994877576828003,
      "learning_rate": 7.615752776333507e-07,
      "loss": 0.0601,
      "step": 147790
    },
    {
      "epoch": 2.955645322561293,
      "grad_norm": 0.15913815796375275,
      "learning_rate": 7.582423442520231e-07,
      "loss": 0.072,
      "step": 147800
    },
    {
      "epoch": 2.9558452985641726,
      "grad_norm": 0.43827182054519653,
      "learning_rate": 7.549094108706956e-07,
      "loss": 0.1014,
      "step": 147810
    },
    {
      "epoch": 2.956045274567052,
      "grad_norm": 0.07381150871515274,
      "learning_rate": 7.515764774893679e-07,
      "loss": 0.0536,
      "step": 147820
    },
    {
      "epoch": 2.9562452505699315,
      "grad_norm": 0.21194490790367126,
      "learning_rate": 7.482435441080404e-07,
      "loss": 0.0617,
      "step": 147830
    },
    {
      "epoch": 2.956445226572811,
      "grad_norm": 0.1394137293100357,
      "learning_rate": 7.449106107267129e-07,
      "loss": 0.0634,
      "step": 147840
    },
    {
      "epoch": 2.956645202575691,
      "grad_norm": 0.1091850996017456,
      "learning_rate": 7.415776773453852e-07,
      "loss": 0.0918,
      "step": 147850
    },
    {
      "epoch": 2.9568451785785705,
      "grad_norm": 0.09197267144918442,
      "learning_rate": 7.382447439640577e-07,
      "loss": 0.0769,
      "step": 147860
    },
    {
      "epoch": 2.9570451545814502,
      "grad_norm": 0.21636222302913666,
      "learning_rate": 7.349118105827301e-07,
      "loss": 0.0741,
      "step": 147870
    },
    {
      "epoch": 2.95724513058433,
      "grad_norm": 0.12609046697616577,
      "learning_rate": 7.315788772014026e-07,
      "loss": 0.0612,
      "step": 147880
    },
    {
      "epoch": 2.9574451065872096,
      "grad_norm": 0.06195443496108055,
      "learning_rate": 7.282459438200749e-07,
      "loss": 0.0677,
      "step": 147890
    },
    {
      "epoch": 2.9576450825900893,
      "grad_norm": 0.122780442237854,
      "learning_rate": 7.249130104387474e-07,
      "loss": 0.0643,
      "step": 147900
    },
    {
      "epoch": 2.957845058592969,
      "grad_norm": 0.08486754447221756,
      "learning_rate": 7.215800770574198e-07,
      "loss": 0.0595,
      "step": 147910
    },
    {
      "epoch": 2.958045034595848,
      "grad_norm": 0.08242472261190414,
      "learning_rate": 7.182471436760923e-07,
      "loss": 0.0735,
      "step": 147920
    },
    {
      "epoch": 2.958245010598728,
      "grad_norm": 0.20063823461532593,
      "learning_rate": 7.149142102947646e-07,
      "loss": 0.0655,
      "step": 147930
    },
    {
      "epoch": 2.9584449866016076,
      "grad_norm": 0.16975714266300201,
      "learning_rate": 7.115812769134371e-07,
      "loss": 0.0622,
      "step": 147940
    },
    {
      "epoch": 2.9586449626044873,
      "grad_norm": 0.20791862905025482,
      "learning_rate": 7.082483435321095e-07,
      "loss": 0.0771,
      "step": 147950
    },
    {
      "epoch": 2.958844938607367,
      "grad_norm": 0.1084970235824585,
      "learning_rate": 7.049154101507819e-07,
      "loss": 0.0708,
      "step": 147960
    },
    {
      "epoch": 2.9590449146102467,
      "grad_norm": 0.1484578549861908,
      "learning_rate": 7.015824767694544e-07,
      "loss": 0.0846,
      "step": 147970
    },
    {
      "epoch": 2.9592448906131263,
      "grad_norm": 0.09352950006723404,
      "learning_rate": 6.982495433881268e-07,
      "loss": 0.077,
      "step": 147980
    },
    {
      "epoch": 2.959444866616006,
      "grad_norm": 0.2806096076965332,
      "learning_rate": 6.949166100067993e-07,
      "loss": 0.0777,
      "step": 147990
    },
    {
      "epoch": 2.9596448426188857,
      "grad_norm": 0.21391312777996063,
      "learning_rate": 6.915836766254716e-07,
      "loss": 0.1049,
      "step": 148000
    },
    {
      "epoch": 2.9598448186217654,
      "grad_norm": 0.040848128497600555,
      "learning_rate": 6.882507432441441e-07,
      "loss": 0.0793,
      "step": 148010
    },
    {
      "epoch": 2.960044794624645,
      "grad_norm": 0.13043223321437836,
      "learning_rate": 6.849178098628165e-07,
      "loss": 0.0447,
      "step": 148020
    },
    {
      "epoch": 2.960244770627525,
      "grad_norm": 0.09006806463003159,
      "learning_rate": 6.815848764814889e-07,
      "loss": 0.0693,
      "step": 148030
    },
    {
      "epoch": 2.9604447466304045,
      "grad_norm": 0.07764425128698349,
      "learning_rate": 6.782519431001613e-07,
      "loss": 0.0913,
      "step": 148040
    },
    {
      "epoch": 2.960644722633284,
      "grad_norm": 0.19302840530872345,
      "learning_rate": 6.749190097188338e-07,
      "loss": 0.0682,
      "step": 148050
    },
    {
      "epoch": 2.960844698636164,
      "grad_norm": 0.12957045435905457,
      "learning_rate": 6.715860763375062e-07,
      "loss": 0.1171,
      "step": 148060
    },
    {
      "epoch": 2.9610446746390435,
      "grad_norm": 0.14889775216579437,
      "learning_rate": 6.682531429561786e-07,
      "loss": 0.1041,
      "step": 148070
    },
    {
      "epoch": 2.961244650641923,
      "grad_norm": 0.1315438449382782,
      "learning_rate": 6.649202095748511e-07,
      "loss": 0.0887,
      "step": 148080
    },
    {
      "epoch": 2.9614446266448025,
      "grad_norm": 0.13034217059612274,
      "learning_rate": 6.615872761935235e-07,
      "loss": 0.0793,
      "step": 148090
    },
    {
      "epoch": 2.961644602647682,
      "grad_norm": 0.15052132308483124,
      "learning_rate": 6.582543428121958e-07,
      "loss": 0.0741,
      "step": 148100
    },
    {
      "epoch": 2.961844578650562,
      "grad_norm": 0.2212073653936386,
      "learning_rate": 6.549214094308683e-07,
      "loss": 0.0834,
      "step": 148110
    },
    {
      "epoch": 2.9620445546534415,
      "grad_norm": 0.09378907084465027,
      "learning_rate": 6.515884760495408e-07,
      "loss": 0.0426,
      "step": 148120
    },
    {
      "epoch": 2.962244530656321,
      "grad_norm": 0.10647977888584137,
      "learning_rate": 6.482555426682132e-07,
      "loss": 0.0879,
      "step": 148130
    },
    {
      "epoch": 2.962444506659201,
      "grad_norm": 0.17743365466594696,
      "learning_rate": 6.449226092868856e-07,
      "loss": 0.0715,
      "step": 148140
    },
    {
      "epoch": 2.9626444826620806,
      "grad_norm": 0.09370741248130798,
      "learning_rate": 6.41589675905558e-07,
      "loss": 0.0744,
      "step": 148150
    },
    {
      "epoch": 2.9628444586649603,
      "grad_norm": 0.19704319536685944,
      "learning_rate": 6.382567425242305e-07,
      "loss": 0.0697,
      "step": 148160
    },
    {
      "epoch": 2.96304443466784,
      "grad_norm": 0.24972039461135864,
      "learning_rate": 6.349238091429028e-07,
      "loss": 0.0729,
      "step": 148170
    },
    {
      "epoch": 2.9632444106707196,
      "grad_norm": 0.08165665715932846,
      "learning_rate": 6.315908757615753e-07,
      "loss": 0.0687,
      "step": 148180
    },
    {
      "epoch": 2.9634443866735993,
      "grad_norm": 0.1050548329949379,
      "learning_rate": 6.282579423802478e-07,
      "loss": 0.0643,
      "step": 148190
    },
    {
      "epoch": 2.9636443626764786,
      "grad_norm": 0.08901342749595642,
      "learning_rate": 6.249250089989202e-07,
      "loss": 0.0766,
      "step": 148200
    },
    {
      "epoch": 2.9638443386793583,
      "grad_norm": 0.19614256918430328,
      "learning_rate": 6.215920756175925e-07,
      "loss": 0.0643,
      "step": 148210
    },
    {
      "epoch": 2.964044314682238,
      "grad_norm": 0.16837823390960693,
      "learning_rate": 6.18259142236265e-07,
      "loss": 0.0824,
      "step": 148220
    },
    {
      "epoch": 2.9642442906851176,
      "grad_norm": 0.08483096957206726,
      "learning_rate": 6.149262088549375e-07,
      "loss": 0.0516,
      "step": 148230
    },
    {
      "epoch": 2.9644442666879973,
      "grad_norm": 0.23137891292572021,
      "learning_rate": 6.115932754736099e-07,
      "loss": 0.081,
      "step": 148240
    },
    {
      "epoch": 2.964644242690877,
      "grad_norm": 0.16689357161521912,
      "learning_rate": 6.082603420922822e-07,
      "loss": 0.0723,
      "step": 148250
    },
    {
      "epoch": 2.9648442186937567,
      "grad_norm": 0.20215393602848053,
      "learning_rate": 6.049274087109547e-07,
      "loss": 0.0493,
      "step": 148260
    },
    {
      "epoch": 2.9650441946966364,
      "grad_norm": 0.06743677705526352,
      "learning_rate": 6.015944753296272e-07,
      "loss": 0.049,
      "step": 148270
    },
    {
      "epoch": 2.965244170699516,
      "grad_norm": 0.21331991255283356,
      "learning_rate": 5.982615419482995e-07,
      "loss": 0.0803,
      "step": 148280
    },
    {
      "epoch": 2.9654441467023958,
      "grad_norm": 0.23184671998023987,
      "learning_rate": 5.94928608566972e-07,
      "loss": 0.0717,
      "step": 148290
    },
    {
      "epoch": 2.9656441227052754,
      "grad_norm": 0.06386545300483704,
      "learning_rate": 5.915956751856445e-07,
      "loss": 0.0539,
      "step": 148300
    },
    {
      "epoch": 2.965844098708155,
      "grad_norm": 0.1576821506023407,
      "learning_rate": 5.882627418043169e-07,
      "loss": 0.0912,
      "step": 148310
    },
    {
      "epoch": 2.966044074711035,
      "grad_norm": 0.1684824675321579,
      "learning_rate": 5.849298084229892e-07,
      "loss": 0.0702,
      "step": 148320
    },
    {
      "epoch": 2.9662440507139145,
      "grad_norm": 0.23501820862293243,
      "learning_rate": 5.815968750416617e-07,
      "loss": 0.0587,
      "step": 148330
    },
    {
      "epoch": 2.966444026716794,
      "grad_norm": 0.0651714876294136,
      "learning_rate": 5.782639416603342e-07,
      "loss": 0.061,
      "step": 148340
    },
    {
      "epoch": 2.966644002719674,
      "grad_norm": 0.12081661075353622,
      "learning_rate": 5.749310082790065e-07,
      "loss": 0.0586,
      "step": 148350
    },
    {
      "epoch": 2.9668439787225536,
      "grad_norm": 0.16667118668556213,
      "learning_rate": 5.715980748976789e-07,
      "loss": 0.0762,
      "step": 148360
    },
    {
      "epoch": 2.967043954725433,
      "grad_norm": 0.11413680762052536,
      "learning_rate": 5.682651415163514e-07,
      "loss": 0.0891,
      "step": 148370
    },
    {
      "epoch": 2.9672439307283125,
      "grad_norm": 0.24752214550971985,
      "learning_rate": 5.649322081350239e-07,
      "loss": 0.0722,
      "step": 148380
    },
    {
      "epoch": 2.967443906731192,
      "grad_norm": 0.23714680969715118,
      "learning_rate": 5.615992747536962e-07,
      "loss": 0.0733,
      "step": 148390
    },
    {
      "epoch": 2.967643882734072,
      "grad_norm": 0.2115982323884964,
      "learning_rate": 5.582663413723687e-07,
      "loss": 0.0678,
      "step": 148400
    },
    {
      "epoch": 2.9678438587369516,
      "grad_norm": 0.08521010726690292,
      "learning_rate": 5.549334079910412e-07,
      "loss": 0.0488,
      "step": 148410
    },
    {
      "epoch": 2.9680438347398312,
      "grad_norm": 0.15653103590011597,
      "learning_rate": 5.516004746097135e-07,
      "loss": 0.0736,
      "step": 148420
    },
    {
      "epoch": 2.968243810742711,
      "grad_norm": 0.09433245658874512,
      "learning_rate": 5.482675412283859e-07,
      "loss": 0.0582,
      "step": 148430
    },
    {
      "epoch": 2.9684437867455906,
      "grad_norm": 0.17016781866550446,
      "learning_rate": 5.449346078470584e-07,
      "loss": 0.0591,
      "step": 148440
    },
    {
      "epoch": 2.9686437627484703,
      "grad_norm": 0.22875690460205078,
      "learning_rate": 5.416016744657309e-07,
      "loss": 0.0512,
      "step": 148450
    },
    {
      "epoch": 2.96884373875135,
      "grad_norm": 0.15559767186641693,
      "learning_rate": 5.382687410844032e-07,
      "loss": 0.0745,
      "step": 148460
    },
    {
      "epoch": 2.9690437147542292,
      "grad_norm": 0.1385599970817566,
      "learning_rate": 5.349358077030756e-07,
      "loss": 0.086,
      "step": 148470
    },
    {
      "epoch": 2.969243690757109,
      "grad_norm": 0.09882638603448868,
      "learning_rate": 5.316028743217481e-07,
      "loss": 0.0621,
      "step": 148480
    },
    {
      "epoch": 2.9694436667599886,
      "grad_norm": 0.10950186103582382,
      "learning_rate": 5.282699409404206e-07,
      "loss": 0.0611,
      "step": 148490
    },
    {
      "epoch": 2.9696436427628683,
      "grad_norm": 0.0900702178478241,
      "learning_rate": 5.249370075590929e-07,
      "loss": 0.062,
      "step": 148500
    },
    {
      "epoch": 2.969843618765748,
      "grad_norm": 0.24768467247486115,
      "learning_rate": 5.216040741777653e-07,
      "loss": 0.1066,
      "step": 148510
    },
    {
      "epoch": 2.9700435947686277,
      "grad_norm": 0.06599007546901703,
      "learning_rate": 5.182711407964379e-07,
      "loss": 0.04,
      "step": 148520
    },
    {
      "epoch": 2.9702435707715074,
      "grad_norm": 0.21983405947685242,
      "learning_rate": 5.149382074151102e-07,
      "loss": 0.1059,
      "step": 148530
    },
    {
      "epoch": 2.970443546774387,
      "grad_norm": 0.1458541750907898,
      "learning_rate": 5.116052740337826e-07,
      "loss": 0.0768,
      "step": 148540
    },
    {
      "epoch": 2.9706435227772667,
      "grad_norm": 0.05343174934387207,
      "learning_rate": 5.082723406524551e-07,
      "loss": 0.0946,
      "step": 148550
    },
    {
      "epoch": 2.9708434987801464,
      "grad_norm": 0.23500455915927887,
      "learning_rate": 5.049394072711276e-07,
      "loss": 0.1071,
      "step": 148560
    },
    {
      "epoch": 2.971043474783026,
      "grad_norm": 0.09211663901805878,
      "learning_rate": 5.016064738897999e-07,
      "loss": 0.0389,
      "step": 148570
    },
    {
      "epoch": 2.971243450785906,
      "grad_norm": 0.18500399589538574,
      "learning_rate": 4.982735405084723e-07,
      "loss": 0.0752,
      "step": 148580
    },
    {
      "epoch": 2.9714434267887855,
      "grad_norm": 0.07669942826032639,
      "learning_rate": 4.949406071271448e-07,
      "loss": 0.0887,
      "step": 148590
    },
    {
      "epoch": 2.971643402791665,
      "grad_norm": 0.16384771466255188,
      "learning_rate": 4.916076737458172e-07,
      "loss": 0.082,
      "step": 148600
    },
    {
      "epoch": 2.971843378794545,
      "grad_norm": 0.09740167111158371,
      "learning_rate": 4.882747403644896e-07,
      "loss": 0.0599,
      "step": 148610
    },
    {
      "epoch": 2.9720433547974245,
      "grad_norm": 0.10925403237342834,
      "learning_rate": 4.84941806983162e-07,
      "loss": 0.0724,
      "step": 148620
    },
    {
      "epoch": 2.9722433308003042,
      "grad_norm": 0.11917615681886673,
      "learning_rate": 4.816088736018345e-07,
      "loss": 0.0703,
      "step": 148630
    },
    {
      "epoch": 2.9724433068031835,
      "grad_norm": 0.14865244925022125,
      "learning_rate": 4.782759402205069e-07,
      "loss": 0.0489,
      "step": 148640
    },
    {
      "epoch": 2.972643282806063,
      "grad_norm": 0.1704172044992447,
      "learning_rate": 4.749430068391793e-07,
      "loss": 0.0655,
      "step": 148650
    },
    {
      "epoch": 2.972843258808943,
      "grad_norm": 0.1270895004272461,
      "learning_rate": 4.716100734578517e-07,
      "loss": 0.0686,
      "step": 148660
    },
    {
      "epoch": 2.9730432348118225,
      "grad_norm": 0.19745582342147827,
      "learning_rate": 4.682771400765242e-07,
      "loss": 0.0467,
      "step": 148670
    },
    {
      "epoch": 2.973243210814702,
      "grad_norm": 0.0885908231139183,
      "learning_rate": 4.649442066951966e-07,
      "loss": 0.0501,
      "step": 148680
    },
    {
      "epoch": 2.973443186817582,
      "grad_norm": 0.1222653016448021,
      "learning_rate": 4.61611273313869e-07,
      "loss": 0.0645,
      "step": 148690
    },
    {
      "epoch": 2.9736431628204616,
      "grad_norm": 0.0738309845328331,
      "learning_rate": 4.582783399325414e-07,
      "loss": 0.0688,
      "step": 148700
    },
    {
      "epoch": 2.9738431388233413,
      "grad_norm": 0.14721260964870453,
      "learning_rate": 4.549454065512139e-07,
      "loss": 0.0655,
      "step": 148710
    },
    {
      "epoch": 2.974043114826221,
      "grad_norm": 0.16332294046878815,
      "learning_rate": 4.516124731698863e-07,
      "loss": 0.0927,
      "step": 148720
    },
    {
      "epoch": 2.9742430908291007,
      "grad_norm": 0.2399202138185501,
      "learning_rate": 4.482795397885587e-07,
      "loss": 0.0602,
      "step": 148730
    },
    {
      "epoch": 2.97444306683198,
      "grad_norm": 0.17592521011829376,
      "learning_rate": 4.449466064072312e-07,
      "loss": 0.0573,
      "step": 148740
    },
    {
      "epoch": 2.9746430428348596,
      "grad_norm": 0.22186316549777985,
      "learning_rate": 4.4161367302590357e-07,
      "loss": 0.0787,
      "step": 148750
    },
    {
      "epoch": 2.9748430188377393,
      "grad_norm": 0.08646002411842346,
      "learning_rate": 4.38280739644576e-07,
      "loss": 0.0655,
      "step": 148760
    },
    {
      "epoch": 2.975042994840619,
      "grad_norm": 0.09099073708057404,
      "learning_rate": 4.349478062632484e-07,
      "loss": 0.0593,
      "step": 148770
    },
    {
      "epoch": 2.9752429708434986,
      "grad_norm": 0.29985907673835754,
      "learning_rate": 4.316148728819209e-07,
      "loss": 0.0742,
      "step": 148780
    },
    {
      "epoch": 2.9754429468463783,
      "grad_norm": 0.17066757380962372,
      "learning_rate": 4.282819395005933e-07,
      "loss": 0.0785,
      "step": 148790
    },
    {
      "epoch": 2.975642922849258,
      "grad_norm": 0.12498466670513153,
      "learning_rate": 4.249490061192657e-07,
      "loss": 0.0699,
      "step": 148800
    },
    {
      "epoch": 2.9758428988521377,
      "grad_norm": 0.08607985079288483,
      "learning_rate": 4.216160727379381e-07,
      "loss": 0.0589,
      "step": 148810
    },
    {
      "epoch": 2.9760428748550174,
      "grad_norm": 0.1302599310874939,
      "learning_rate": 4.182831393566106e-07,
      "loss": 0.0579,
      "step": 148820
    },
    {
      "epoch": 2.976242850857897,
      "grad_norm": 0.11846055835485458,
      "learning_rate": 4.14950205975283e-07,
      "loss": 0.0556,
      "step": 148830
    },
    {
      "epoch": 2.9764428268607768,
      "grad_norm": 0.19749771058559418,
      "learning_rate": 4.1161727259395536e-07,
      "loss": 0.0844,
      "step": 148840
    },
    {
      "epoch": 2.9766428028636565,
      "grad_norm": 0.0986761748790741,
      "learning_rate": 4.082843392126279e-07,
      "loss": 0.0756,
      "step": 148850
    },
    {
      "epoch": 2.976842778866536,
      "grad_norm": 0.13762560486793518,
      "learning_rate": 4.0495140583130026e-07,
      "loss": 0.0535,
      "step": 148860
    },
    {
      "epoch": 2.977042754869416,
      "grad_norm": 0.16791817545890808,
      "learning_rate": 4.016184724499727e-07,
      "loss": 0.0455,
      "step": 148870
    },
    {
      "epoch": 2.9772427308722955,
      "grad_norm": 0.12531810998916626,
      "learning_rate": 3.982855390686451e-07,
      "loss": 0.127,
      "step": 148880
    },
    {
      "epoch": 2.977442706875175,
      "grad_norm": 0.0651308000087738,
      "learning_rate": 3.949526056873176e-07,
      "loss": 0.0668,
      "step": 148890
    },
    {
      "epoch": 2.977642682878055,
      "grad_norm": 0.1341654509305954,
      "learning_rate": 3.9161967230598995e-07,
      "loss": 0.0482,
      "step": 148900
    },
    {
      "epoch": 2.977842658880934,
      "grad_norm": 0.13543909788131714,
      "learning_rate": 3.8828673892466237e-07,
      "loss": 0.0682,
      "step": 148910
    },
    {
      "epoch": 2.978042634883814,
      "grad_norm": 0.1325812190771103,
      "learning_rate": 3.8495380554333484e-07,
      "loss": 0.0908,
      "step": 148920
    },
    {
      "epoch": 2.9782426108866935,
      "grad_norm": 0.08483584970235825,
      "learning_rate": 3.816208721620072e-07,
      "loss": 0.0605,
      "step": 148930
    },
    {
      "epoch": 2.978442586889573,
      "grad_norm": 0.18445461988449097,
      "learning_rate": 3.782879387806797e-07,
      "loss": 0.0704,
      "step": 148940
    },
    {
      "epoch": 2.978642562892453,
      "grad_norm": 0.11754994094371796,
      "learning_rate": 3.749550053993521e-07,
      "loss": 0.0728,
      "step": 148950
    },
    {
      "epoch": 2.9788425388953326,
      "grad_norm": 0.19400885701179504,
      "learning_rate": 3.7162207201802453e-07,
      "loss": 0.0595,
      "step": 148960
    },
    {
      "epoch": 2.9790425148982123,
      "grad_norm": 0.1734369546175003,
      "learning_rate": 3.6828913863669695e-07,
      "loss": 0.078,
      "step": 148970
    },
    {
      "epoch": 2.979242490901092,
      "grad_norm": 0.10327005386352539,
      "learning_rate": 3.649562052553694e-07,
      "loss": 0.0548,
      "step": 148980
    },
    {
      "epoch": 2.9794424669039716,
      "grad_norm": 0.239892840385437,
      "learning_rate": 3.616232718740418e-07,
      "loss": 0.0701,
      "step": 148990
    },
    {
      "epoch": 2.9796424429068513,
      "grad_norm": 0.12050516903400421,
      "learning_rate": 3.582903384927142e-07,
      "loss": 0.0735,
      "step": 149000
    },
    {
      "epoch": 2.9798424189097306,
      "grad_norm": 0.1090649887919426,
      "learning_rate": 3.5495740511138664e-07,
      "loss": 0.0928,
      "step": 149010
    },
    {
      "epoch": 2.9800423949126102,
      "grad_norm": 0.061245422810316086,
      "learning_rate": 3.5162447173005906e-07,
      "loss": 0.0716,
      "step": 149020
    },
    {
      "epoch": 2.98024237091549,
      "grad_norm": 0.07098821550607681,
      "learning_rate": 3.482915383487315e-07,
      "loss": 0.0585,
      "step": 149030
    },
    {
      "epoch": 2.9804423469183696,
      "grad_norm": 0.12671838700771332,
      "learning_rate": 3.449586049674039e-07,
      "loss": 0.0908,
      "step": 149040
    },
    {
      "epoch": 2.9806423229212493,
      "grad_norm": 0.16512654721736908,
      "learning_rate": 3.416256715860763e-07,
      "loss": 0.1021,
      "step": 149050
    },
    {
      "epoch": 2.980842298924129,
      "grad_norm": 0.0951138511300087,
      "learning_rate": 3.382927382047488e-07,
      "loss": 0.0602,
      "step": 149060
    },
    {
      "epoch": 2.9810422749270087,
      "grad_norm": 0.11917776614427567,
      "learning_rate": 3.349598048234212e-07,
      "loss": 0.0659,
      "step": 149070
    },
    {
      "epoch": 2.9812422509298884,
      "grad_norm": 0.07130606472492218,
      "learning_rate": 3.3162687144209364e-07,
      "loss": 0.0633,
      "step": 149080
    },
    {
      "epoch": 2.981442226932768,
      "grad_norm": 0.10504037886857986,
      "learning_rate": 3.2829393806076607e-07,
      "loss": 0.0684,
      "step": 149090
    },
    {
      "epoch": 2.9816422029356477,
      "grad_norm": 0.21740449965000153,
      "learning_rate": 3.249610046794385e-07,
      "loss": 0.0853,
      "step": 149100
    },
    {
      "epoch": 2.9818421789385274,
      "grad_norm": 0.19814813137054443,
      "learning_rate": 3.216280712981109e-07,
      "loss": 0.0892,
      "step": 149110
    },
    {
      "epoch": 2.982042154941407,
      "grad_norm": 0.0903962105512619,
      "learning_rate": 3.1829513791678333e-07,
      "loss": 0.0751,
      "step": 149120
    },
    {
      "epoch": 2.982242130944287,
      "grad_norm": 0.08407478779554367,
      "learning_rate": 3.1496220453545575e-07,
      "loss": 0.0626,
      "step": 149130
    },
    {
      "epoch": 2.9824421069471665,
      "grad_norm": 0.08895505219697952,
      "learning_rate": 3.116292711541282e-07,
      "loss": 0.0739,
      "step": 149140
    },
    {
      "epoch": 2.982642082950046,
      "grad_norm": 0.059862393885850906,
      "learning_rate": 3.0829633777280065e-07,
      "loss": 0.0501,
      "step": 149150
    },
    {
      "epoch": 2.982842058952926,
      "grad_norm": 0.19553899765014648,
      "learning_rate": 3.04963404391473e-07,
      "loss": 0.0438,
      "step": 149160
    },
    {
      "epoch": 2.9830420349558056,
      "grad_norm": 0.10591759532690048,
      "learning_rate": 3.016304710101455e-07,
      "loss": 0.0584,
      "step": 149170
    },
    {
      "epoch": 2.983242010958685,
      "grad_norm": 0.1746746152639389,
      "learning_rate": 2.9829753762881786e-07,
      "loss": 0.0642,
      "step": 149180
    },
    {
      "epoch": 2.9834419869615645,
      "grad_norm": 0.23291346430778503,
      "learning_rate": 2.9496460424749034e-07,
      "loss": 0.0774,
      "step": 149190
    },
    {
      "epoch": 2.983641962964444,
      "grad_norm": 0.16353020071983337,
      "learning_rate": 2.9163167086616276e-07,
      "loss": 0.0623,
      "step": 149200
    },
    {
      "epoch": 2.983841938967324,
      "grad_norm": 0.15481948852539062,
      "learning_rate": 2.882987374848352e-07,
      "loss": 0.0773,
      "step": 149210
    },
    {
      "epoch": 2.9840419149702035,
      "grad_norm": 0.19521042704582214,
      "learning_rate": 2.8529909744164033e-07,
      "loss": 0.0785,
      "step": 149220
    },
    {
      "epoch": 2.9842418909730832,
      "grad_norm": 0.06810589134693146,
      "learning_rate": 2.8196616406031275e-07,
      "loss": 0.105,
      "step": 149230
    },
    {
      "epoch": 2.984441866975963,
      "grad_norm": 0.08649678528308868,
      "learning_rate": 2.7863323067898523e-07,
      "loss": 0.1128,
      "step": 149240
    },
    {
      "epoch": 2.9846418429788426,
      "grad_norm": 0.12842465937137604,
      "learning_rate": 2.753002972976576e-07,
      "loss": 0.1006,
      "step": 149250
    },
    {
      "epoch": 2.9848418189817223,
      "grad_norm": 0.13717539608478546,
      "learning_rate": 2.7196736391633007e-07,
      "loss": 0.0374,
      "step": 149260
    },
    {
      "epoch": 2.985041794984602,
      "grad_norm": 0.2332773506641388,
      "learning_rate": 2.686344305350025e-07,
      "loss": 0.0687,
      "step": 149270
    },
    {
      "epoch": 2.9852417709874817,
      "grad_norm": 0.19874893128871918,
      "learning_rate": 2.653014971536749e-07,
      "loss": 0.0714,
      "step": 149280
    },
    {
      "epoch": 2.985441746990361,
      "grad_norm": 0.21018293499946594,
      "learning_rate": 2.6196856377234734e-07,
      "loss": 0.0617,
      "step": 149290
    },
    {
      "epoch": 2.9856417229932406,
      "grad_norm": 0.2538038492202759,
      "learning_rate": 2.5863563039101976e-07,
      "loss": 0.0855,
      "step": 149300
    },
    {
      "epoch": 2.9858416989961203,
      "grad_norm": 0.25775396823883057,
      "learning_rate": 2.553026970096922e-07,
      "loss": 0.0937,
      "step": 149310
    },
    {
      "epoch": 2.986041674999,
      "grad_norm": 0.1911240816116333,
      "learning_rate": 2.519697636283646e-07,
      "loss": 0.0725,
      "step": 149320
    },
    {
      "epoch": 2.9862416510018797,
      "grad_norm": 0.18050289154052734,
      "learning_rate": 2.48636830247037e-07,
      "loss": 0.0679,
      "step": 149330
    },
    {
      "epoch": 2.9864416270047593,
      "grad_norm": 0.17790035903453827,
      "learning_rate": 2.4530389686570945e-07,
      "loss": 0.0415,
      "step": 149340
    },
    {
      "epoch": 2.986641603007639,
      "grad_norm": 0.17340241372585297,
      "learning_rate": 2.419709634843819e-07,
      "loss": 0.077,
      "step": 149350
    },
    {
      "epoch": 2.9868415790105187,
      "grad_norm": 0.19940990209579468,
      "learning_rate": 2.386380301030543e-07,
      "loss": 0.0848,
      "step": 149360
    },
    {
      "epoch": 2.9870415550133984,
      "grad_norm": 0.09752029180526733,
      "learning_rate": 2.3530509672172676e-07,
      "loss": 0.0874,
      "step": 149370
    },
    {
      "epoch": 2.987241531016278,
      "grad_norm": 0.12103664875030518,
      "learning_rate": 2.3197216334039916e-07,
      "loss": 0.0599,
      "step": 149380
    },
    {
      "epoch": 2.987441507019158,
      "grad_norm": 0.1898518204689026,
      "learning_rate": 2.286392299590716e-07,
      "loss": 0.0604,
      "step": 149390
    },
    {
      "epoch": 2.9876414830220375,
      "grad_norm": 0.17482319474220276,
      "learning_rate": 2.25306296577744e-07,
      "loss": 0.074,
      "step": 149400
    },
    {
      "epoch": 2.987841459024917,
      "grad_norm": 0.07572142034769058,
      "learning_rate": 2.2197336319641645e-07,
      "loss": 0.0673,
      "step": 149410
    },
    {
      "epoch": 2.988041435027797,
      "grad_norm": 0.18926791846752167,
      "learning_rate": 2.1864042981508885e-07,
      "loss": 0.092,
      "step": 149420
    },
    {
      "epoch": 2.9882414110306765,
      "grad_norm": 0.21830351650714874,
      "learning_rate": 2.153074964337613e-07,
      "loss": 0.0985,
      "step": 149430
    },
    {
      "epoch": 2.988441387033556,
      "grad_norm": 0.08104870468378067,
      "learning_rate": 2.119745630524337e-07,
      "loss": 0.0553,
      "step": 149440
    },
    {
      "epoch": 2.988641363036436,
      "grad_norm": 0.08262576162815094,
      "learning_rate": 2.0864162967110614e-07,
      "loss": 0.069,
      "step": 149450
    },
    {
      "epoch": 2.988841339039315,
      "grad_norm": 0.1479986310005188,
      "learning_rate": 2.0530869628977859e-07,
      "loss": 0.0658,
      "step": 149460
    },
    {
      "epoch": 2.989041315042195,
      "grad_norm": 0.11611033231019974,
      "learning_rate": 2.0197576290845098e-07,
      "loss": 0.0489,
      "step": 149470
    },
    {
      "epoch": 2.9892412910450745,
      "grad_norm": 0.21346016228199005,
      "learning_rate": 1.9864282952712343e-07,
      "loss": 0.0574,
      "step": 149480
    },
    {
      "epoch": 2.989441267047954,
      "grad_norm": 0.21723324060440063,
      "learning_rate": 1.9530989614579585e-07,
      "loss": 0.1011,
      "step": 149490
    },
    {
      "epoch": 2.989641243050834,
      "grad_norm": 0.3603461980819702,
      "learning_rate": 1.9197696276446827e-07,
      "loss": 0.0623,
      "step": 149500
    },
    {
      "epoch": 2.9898412190537136,
      "grad_norm": 0.2688729465007782,
      "learning_rate": 1.8864402938314072e-07,
      "loss": 0.1158,
      "step": 149510
    },
    {
      "epoch": 2.9900411950565933,
      "grad_norm": 0.1478118896484375,
      "learning_rate": 1.8531109600181314e-07,
      "loss": 0.0946,
      "step": 149520
    },
    {
      "epoch": 2.990241171059473,
      "grad_norm": 0.10915133357048035,
      "learning_rate": 1.8197816262048556e-07,
      "loss": 0.0602,
      "step": 149530
    },
    {
      "epoch": 2.9904411470623526,
      "grad_norm": 0.10094069689512253,
      "learning_rate": 1.7864522923915799e-07,
      "loss": 0.0663,
      "step": 149540
    },
    {
      "epoch": 2.9906411230652323,
      "grad_norm": 0.1509220451116562,
      "learning_rate": 1.753122958578304e-07,
      "loss": 0.086,
      "step": 149550
    },
    {
      "epoch": 2.9908410990681116,
      "grad_norm": 0.12440403550863266,
      "learning_rate": 1.7197936247650283e-07,
      "loss": 0.0888,
      "step": 149560
    },
    {
      "epoch": 2.9910410750709913,
      "grad_norm": 0.15850830078125,
      "learning_rate": 1.6864642909517525e-07,
      "loss": 0.0648,
      "step": 149570
    },
    {
      "epoch": 2.991241051073871,
      "grad_norm": 0.10617618262767792,
      "learning_rate": 1.6531349571384767e-07,
      "loss": 0.0669,
      "step": 149580
    },
    {
      "epoch": 2.9914410270767506,
      "grad_norm": 0.27618899941444397,
      "learning_rate": 1.619805623325201e-07,
      "loss": 0.0667,
      "step": 149590
    },
    {
      "epoch": 2.9916410030796303,
      "grad_norm": 0.2195660024881363,
      "learning_rate": 1.5864762895119252e-07,
      "loss": 0.0589,
      "step": 149600
    },
    {
      "epoch": 2.99184097908251,
      "grad_norm": 0.11301100254058838,
      "learning_rate": 1.5531469556986496e-07,
      "loss": 0.0754,
      "step": 149610
    },
    {
      "epoch": 2.9920409550853897,
      "grad_norm": 0.11768769472837448,
      "learning_rate": 1.5198176218853739e-07,
      "loss": 0.0532,
      "step": 149620
    },
    {
      "epoch": 2.9922409310882694,
      "grad_norm": 0.10546211153268814,
      "learning_rate": 1.486488288072098e-07,
      "loss": 0.0571,
      "step": 149630
    },
    {
      "epoch": 2.992440907091149,
      "grad_norm": 0.26762762665748596,
      "learning_rate": 1.4531589542588223e-07,
      "loss": 0.0615,
      "step": 149640
    },
    {
      "epoch": 2.9926408830940288,
      "grad_norm": 0.12055408209562302,
      "learning_rate": 1.4198296204455465e-07,
      "loss": 0.041,
      "step": 149650
    },
    {
      "epoch": 2.9928408590969084,
      "grad_norm": 0.07602062076330185,
      "learning_rate": 1.386500286632271e-07,
      "loss": 0.0579,
      "step": 149660
    },
    {
      "epoch": 2.993040835099788,
      "grad_norm": 0.21128112077713013,
      "learning_rate": 1.3531709528189952e-07,
      "loss": 0.0673,
      "step": 149670
    },
    {
      "epoch": 2.993240811102668,
      "grad_norm": 0.0780186578631401,
      "learning_rate": 1.3198416190057194e-07,
      "loss": 0.0724,
      "step": 149680
    },
    {
      "epoch": 2.9934407871055475,
      "grad_norm": 0.19220109283924103,
      "learning_rate": 1.2865122851924436e-07,
      "loss": 0.0874,
      "step": 149690
    },
    {
      "epoch": 2.993640763108427,
      "grad_norm": 0.077864870429039,
      "learning_rate": 1.2531829513791679e-07,
      "loss": 0.0424,
      "step": 149700
    },
    {
      "epoch": 2.993840739111307,
      "grad_norm": 0.1707049012184143,
      "learning_rate": 1.219853617565892e-07,
      "loss": 0.0457,
      "step": 149710
    },
    {
      "epoch": 2.9940407151141866,
      "grad_norm": 0.14123402535915375,
      "learning_rate": 1.1865242837526166e-07,
      "loss": 0.0797,
      "step": 149720
    },
    {
      "epoch": 2.994240691117066,
      "grad_norm": 0.24861320853233337,
      "learning_rate": 1.1531949499393408e-07,
      "loss": 0.0788,
      "step": 149730
    },
    {
      "epoch": 2.9944406671199455,
      "grad_norm": 0.131759375333786,
      "learning_rate": 1.119865616126065e-07,
      "loss": 0.0531,
      "step": 149740
    },
    {
      "epoch": 2.994640643122825,
      "grad_norm": 0.05595758557319641,
      "learning_rate": 1.0865362823127892e-07,
      "loss": 0.0578,
      "step": 149750
    },
    {
      "epoch": 2.994840619125705,
      "grad_norm": 0.06793826073408127,
      "learning_rate": 1.0532069484995134e-07,
      "loss": 0.0515,
      "step": 149760
    },
    {
      "epoch": 2.9950405951285846,
      "grad_norm": 0.1784333884716034,
      "learning_rate": 1.0198776146862376e-07,
      "loss": 0.0817,
      "step": 149770
    },
    {
      "epoch": 2.9952405711314642,
      "grad_norm": 0.16317394375801086,
      "learning_rate": 9.86548280872962e-08,
      "loss": 0.0951,
      "step": 149780
    },
    {
      "epoch": 2.995440547134344,
      "grad_norm": 0.15915851294994354,
      "learning_rate": 9.532189470596862e-08,
      "loss": 0.0967,
      "step": 149790
    },
    {
      "epoch": 2.9956405231372236,
      "grad_norm": 0.15959642827510834,
      "learning_rate": 9.198896132464106e-08,
      "loss": 0.06,
      "step": 149800
    },
    {
      "epoch": 2.9958404991401033,
      "grad_norm": 0.21556740999221802,
      "learning_rate": 8.865602794331348e-08,
      "loss": 0.0888,
      "step": 149810
    },
    {
      "epoch": 2.996040475142983,
      "grad_norm": 0.13031525909900665,
      "learning_rate": 8.53230945619859e-08,
      "loss": 0.0671,
      "step": 149820
    },
    {
      "epoch": 2.9962404511458622,
      "grad_norm": 0.1289149820804596,
      "learning_rate": 8.199016118065832e-08,
      "loss": 0.0672,
      "step": 149830
    },
    {
      "epoch": 2.996440427148742,
      "grad_norm": 0.11625009030103683,
      "learning_rate": 7.865722779933074e-08,
      "loss": 0.0564,
      "step": 149840
    },
    {
      "epoch": 2.9966404031516216,
      "grad_norm": 0.2232034057378769,
      "learning_rate": 7.532429441800318e-08,
      "loss": 0.1038,
      "step": 149850
    },
    {
      "epoch": 2.9968403791545013,
      "grad_norm": 0.20392410457134247,
      "learning_rate": 7.199136103667561e-08,
      "loss": 0.0715,
      "step": 149860
    },
    {
      "epoch": 2.997040355157381,
      "grad_norm": 0.09302234649658203,
      "learning_rate": 6.865842765534803e-08,
      "loss": 0.0862,
      "step": 149870
    },
    {
      "epoch": 2.9972403311602607,
      "grad_norm": 0.1756611168384552,
      "learning_rate": 6.532549427402046e-08,
      "loss": 0.0995,
      "step": 149880
    },
    {
      "epoch": 2.9974403071631404,
      "grad_norm": 0.11565909534692764,
      "learning_rate": 6.199256089269288e-08,
      "loss": 0.0902,
      "step": 149890
    },
    {
      "epoch": 2.99764028316602,
      "grad_norm": 0.13925395905971527,
      "learning_rate": 5.86596275113653e-08,
      "loss": 0.0688,
      "step": 149900
    },
    {
      "epoch": 2.9978402591688997,
      "grad_norm": 0.10628163814544678,
      "learning_rate": 5.5326694130037734e-08,
      "loss": 0.0365,
      "step": 149910
    },
    {
      "epoch": 2.9980402351717794,
      "grad_norm": 0.19223102927207947,
      "learning_rate": 5.199376074871016e-08,
      "loss": 0.093,
      "step": 149920
    },
    {
      "epoch": 2.998240211174659,
      "grad_norm": 0.10813889652490616,
      "learning_rate": 4.8660827367382584e-08,
      "loss": 0.0599,
      "step": 149930
    },
    {
      "epoch": 2.998440187177539,
      "grad_norm": 0.21545203030109406,
      "learning_rate": 4.5327893986055005e-08,
      "loss": 0.0971,
      "step": 149940
    },
    {
      "epoch": 2.9986401631804185,
      "grad_norm": 0.12045866996049881,
      "learning_rate": 4.199496060472744e-08,
      "loss": 0.087,
      "step": 149950
    },
    {
      "epoch": 2.998840139183298,
      "grad_norm": 0.09471265226602554,
      "learning_rate": 3.866202722339986e-08,
      "loss": 0.0835,
      "step": 149960
    },
    {
      "epoch": 2.999040115186178,
      "grad_norm": 0.1923222690820694,
      "learning_rate": 3.5329093842072284e-08,
      "loss": 0.0973,
      "step": 149970
    },
    {
      "epoch": 2.9992400911890575,
      "grad_norm": 0.13984748721122742,
      "learning_rate": 3.199616046074471e-08,
      "loss": 0.0905,
      "step": 149980
    },
    {
      "epoch": 2.9994400671919372,
      "grad_norm": 0.25386685132980347,
      "learning_rate": 2.8663227079417137e-08,
      "loss": 0.169,
      "step": 149990
    },
    {
      "epoch": 2.9996400431948165,
      "grad_norm": 0.10043343156576157,
      "learning_rate": 2.5330293698089562e-08,
      "loss": 0.102,
      "step": 150000
    }
  ],
  "logging_steps": 10,
  "max_steps": 150018,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.6839882964992e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
